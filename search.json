[{"title":"About GNU/Linux","url":"/2025/06/28/misc/GNU-LINUX/","content":"GNU 项目 (GNU Project)GNU 项目（发音为 /ɡnuː/，类似 “g-noo”），由理查德·斯托曼 (Richard Stallman) 于 1983 年发起，其核心目标是创建一个完全由自由软件 (Free Software) 组成的、与 Unix 兼容的完整操作系统。这个操作系统被命名为 GNU。\n“GNU” 这个名字本身就是一个典型的黑客式幽默，它是一个递归缩写，全称为 “GNU’s Not Unix!”（GNU 不是 Unix!）。这个名字巧妙地表明了 GNU 的目标：它在技术上兼容 Unix，能够运行为 Unix 编写的软件，但在哲学上，它与当时商业化、封闭的 Unix 截然不同。\n核心理念：自由软件 (Free Software)要理解 GNU 项目，就必须理解其基石——“自由软件”的理念。这里的“自由” (Free) 指的是自由的权利 (Freedom)，而非“免费” (Free of charge)。\n理查德·斯托曼认为，软件用户应该拥有控制自己所使用软件的权利。他将这种权利具体化为四项基本自由：\n\n自由 0：无论出于任何目的，用户都有运行程序的自由。\n\n自由 1：用户有学习和修改程序源代码的自由，从而让程序真正为自己服务。(访问源代码是这项自由的前提。)\n\n自由 2：用户有重新分发软件副本的自由，从而可以帮助他人。\n\n自由 3：用户有将自己修改后的版本分发给他人的自由，从而让整个社区有机会从你的改进中受益。\n\n\n一个软件，只有当其用户享有全部这四项自由时，才能被称为“自由软件”。GNU 项目的所有产出都遵循这一原则。\nGNU 项目的主要组成部分为了构建一个完整的操作系统，GNU 项目开发了大量的核心软件组件。这些组件如今已成为几乎所有 Linux 发行版和许多其他开源系统的基石。\n\nGNU 工具链 (GNU Toolchain)这是 GNU 项目最核心、影响最深远的贡献之一，是软件开发的“基础设施”。\n\n\nGCC (GNU Compiler Collection)：GNU 编译器套装。最初是 C 语言编译器，现已支持 C++、Objective-C、Fortran、Go、Rust 等多种语言。它是世界上最重要、使用最广泛的编译器之一。\n\nGDB (GNU Debugger)：一款功能强大且应用广泛的编译型语言命令行调试工具。GDB 允许您“进入”另一个正在运行或崩溃的程序内部，查看其内部状态，并控制其执行流程。它主要用于 C、C++、Go、Rust、Ada 等编译型语言，是 Linux 和 Unix-like 系统下进行软件开发不可或缺的工具。\n\nMake：一个自动化构建工具，可以根据文件依赖关系自动执行编译链接等任务。\n\n\n\n核心应用程序与工具 (Core Applications &amp; Utilities)\n\n\nBash (Bourne-Again SHell)：GNU 的命令行外壳（Shell），是今天绝大多数 Linux 系统默认的交互界面。\n\nCoreutils (Core Utilities)：一套包含所有基础命令行工具的软件包，如 ls, cd, cp, mv, rm, cat 等。\n\n\n\nGNU 通用公共许可证 (GPL)\n\n\n为了在法律上保障软件的“自由”，斯托曼设计了 GPL (GNU General Public License)。这是一个具有“传染性”的许可证，它要求任何修改或分发受 GPL 保护的软件的人，也必须以 GPL 的形式分享其修改后的版本。\n这确保了自由软件的衍生品同样保持自由，防止其被商业公司闭源。\n\nGNU 与 Linux ：一个历史性的结合到了 90 年代初，GNU 项目已经基本完成了构建一个完整操作系统所需的所有组件——除了最核心的部分：内核 (Kernel)。\n\n内核是操作系统的“心脏”，负责管理硬件资源（CPU、内存、硬盘等），并为上层软件提供服务。\n\nGNU 项目自己的内核，名为 GNU Hurd，由于设计过于宏大复杂，开发进度一直非常缓慢。\n\n\n就在此时，1991年，一位名叫林纳斯·托瓦兹 (Linus Torvalds) 的芬兰大学生，出于个人兴趣编写了一个与 Unix 兼容的内核，并将其命名为 Linux。他将 Linux 内核以 GPL 许可证发布。\n这个行为带来了历史性的结合：\nLinux 内核 + GNU 项目的系统软件和工具 = 一个完整、可用的自由操作系统。\n这就是我们今天所熟知的“Linux”操作系统。或者说, 这个操作系统更准确的名称应该是 GNU/Linux，因为 GNU 贡献了除了内核之外的绝大部分组件，并且是整个自由软件理念的源头。\n","categories":["misc"],"tags":["misc"]},{"title":"双指针","url":"/2025/07/31/algorithms/TwoPointers/","content":"什么是双指针法？(What is the Two-Pointers Technique?)双指针（Two Pointers）是一种算法设计思想，它通过在数据结构（通常是数组或链表）上维护两个指针，并让它们以一定的规则移动，从而协同完成任务。\n\n这里的“指针”并非 C/C++ 中的内存地址指针，而更多是指索引 (index) 或迭代器 (iterator)，用来标记数据序列中的位置。\n\n核心目标：双指针法的主要目标通常是将一些需要嵌套循环（时间复杂度为 O(n²)）才能解决的问题，优化为只需一次遍历（时间复杂度为 O(n)）即可解决。它通过巧妙的指针移动，减少了不必要的计算和比较。\n通俗比喻：\n想象一下在一条长长的跑道上，有两个运动员。我们可以让他们：\n\n一个跑得快，一个跑得慢（快慢指针）。\n从跑道的两端同时出发，相向而行（左右指针）。\n都从起点出发，但保持一定距离，像一个“窗口”一样前进（滑动窗口）。\n\n通过观察这两个运动员的位置关系和他们所在位置的“风景”（数据），我们就能高效地解决问题。\n\n双指针法的三种主要模式双指针主要有以下三种经典的模式\n1. 快慢指针 (Fast &amp; Slow Pointers)这种模式下，两个指针从同一端点出发，但移动速度不同。快指针 fast 负责在前面探索，慢指针 slow 负责处理“已确认”的部分。\n典型应用1：移动零问题：将所有 0 移动到数组末尾，保持非零元素相对顺序。\n思想：\n\nslow 指针：指向下一个非零元素应该被放置的位置。\nfast 指针：遍历整个数组，寻找非零元素。\n\n过程：\n\nfast 向前移动，如果 nums[fast] 不是 0，就说明找到了一个需要保留的元素。\n将这个非零元素放到 slow 指针的位置 nums[slow] = nums[fast]。\nslow 指针前进一步，为下一个非零元素腾出位置。\nfast 无论如何都前进一步。\n\n优势：通过一次遍历就完成了元素的“去芜存菁”和重新排列。\n典型应用2：判断链表是否有环问题：给定一个链表，判断其中是否存在环。\n思想：\n\nslow 指针：每次移动一步。\nfast 指针：每次移动两步。\n\n过程：\n\n两个指针从链表头同时出发。\n如果在某个时刻，fast 指针追上了 slow 指针（即 fast == slow），说明链表中存在环。\n如果 fast 指针到达了链表的末尾（即 fast == nullptr 或 fast-&gt;next == nullptr），说明没有环。\n\n\n2. 左右指针 (Left &amp; Right Pointers)也称为“对撞指针”或“首尾指针”。两个指针分别位于数据序列的两端，然后根据特定条件向中间移动。这种模式通常适用于已经排好序的数组。\n典型应用：两数之和 II - 输入有序数组问题：在一个升序数组中，找到两个数，使它们的和等于目标值 target。\n思想：\n\nleft 指针：指向数组开头，即最小值。\nright 指针：指向数组末尾，即最大值。\n\n过程：\n\n计算 sum = nums[left] + nums[right]。\n如果 sum == target，恭喜，找到了！\n如果 sum &lt; target，说明当前的和太小了，需要增大总和，所以让 left 指针向右移动一位（left++）。\n如果 sum &gt; target，说明当前的和太大了，需要减小总和，所以让 right 指针向左移动一位（right--）。\n循环直到 left 和 right 相遇。\n\n优势：通过在两端逼近，每次迭代都能排除一个不可能的选项，将 O(n²) 的暴力搜索优化为 O(n)。\n示例:三数之和给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请你返回所有和为 0 且不重复的三元组。\nclass Solution {public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) {        vector&lt;vector&lt;int&gt;&gt; sum;        if(nums.size()&lt;3) return sum;        sort(nums.begin(),nums.end());        int n = nums.size();        for(int i= 0;i&lt;n-2;i++){            if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue;   // 去重逻辑1: 对于连着的同一个i只看一次            int j=i+1, k=n-1;   // 去重逻辑2: j的起点是i+1, 因为更小的j已经被当做i遍历过            while(j&lt;k){                // 方法1                // if(nums[j]+nums[k] == -nums[i]){                //     vector&lt;int&gt; temp = {nums[i],nums[j],nums[k]};                //     if(find(sum.begin(),sum.end(),temp) == sum.end())                //         sum.push_back({nums[i],nums[j],nums[k]});                // }  直接遍历去重会部分超时                // if(nums[j]+nums[k] &gt; -nums[i]) k--;                // else j++;                // 方法2                if(nums[j]+nums[k] == -nums[i]){                    sum.push_back({nums[i],nums[j],nums[k]});                    // 去重逻辑 3: 跳过所有与当前 j 相同的元素, 因为i不变，当j取的数的值与前一个相同时不用在计算                    while (j&lt;k &amp;&amp; nums[j] == nums[j + 1]) {                        j++;                    }                    // 去重逻辑 3: 跳过所有与当前 k 相同的元素                    while (j&lt;k &amp;&amp; nums[k] == nums[k - 1]) {                        k--;                    }                    j++;                    k--;                }                else if(nums[j]+nums[k] &gt; -nums[i]) k--;                else j++;                        }        }        return sum;    }};\n\n3. 滑动窗口 (Sliding Window)这可以看作是快慢指针的一种特例，两个指针 start 和 end 构成一个“窗口”。窗口通常会先扩大（移动 end 指针），然后在满足一定条件后缩小（移动 start 指针），整个过程就像一个窗口在数据上滑动。\n典型应用：长度最小的子数组问题：给定一个正整数数组和一个目标值 s，找出该数组中满足其和 ≥ s 的长度最小的连续子数组。\n思想：\n\nstart 指针：窗口的左边界。\nend 指针：窗口的右边界。\n维护一个变量 window_sum 记录窗口内元素的和。\n\n过程：\n\n扩大窗口：end 指针不断向右移动，并将新元素加入 window_sum。\n判断与收缩窗口：一旦 window_sum ≥ s，就说明找到了一个满足条件的窗口。\n记录下当前窗口的长度 end - start + 1，并与已记录的最小长度比较。\n尝试缩小窗口：从 window_sum 中减去 nums[start] 的值，并将 start 指针向右移动。\n持续缩小，直到 window_sum &lt; s，然后再去扩大窗口。\n重复此过程，直到 end 到达数组末尾。\n\n优势：巧妙地避免了对所有可能的子数组进行求和的暴力计算。每个元素最多被访问两次（一次被 end 指针扫过，一次被 start 指针扫过），时间复杂度为 O(n)。\n\n总结：何时考虑使用双指针？当遇到一个问题，特别是涉及数组或链表时，如果发现有以下特征，可以优先考虑双指针法：\n\n需要进行原地操作：要求空间复杂度为 O(1)，直接在原数组上修改，如“移动零”。\n涉及有序数组的配对问题：需要在有序数组中寻找满足特定和、差、积的数对，如“两数之和 II”。\n寻找连续子数组/子串的极值问题：要求满足某个条件的“最长”、“最短”、“最大”、“最小”的连续子数组，如“长度最小的子数组”、“无重复字符的最长子串”。\n链表问题：判断环、寻找中点、合并两个有序链表等。\n\n总之, 双指针法是一种“降维”思想，它将二维的搜索空间（嵌套循环）压缩到一维（线性扫描），是提升算法效率的强大工具。\n","categories":["algorithms"],"tags":["algorithms","Pointer"]},{"title":"内容分发网络（CDN）","url":"/2025/08/27/web/cdn/","content":"内容分发网络（Content Delivery Network, CDN）是一种构建在现有互联网基础之上的智能虚拟网络。它由分布在全球各地的大量边缘服务器（Edge Server）组成，旨在通过将网站内容缓存到离用户更近的服务器上，来更快速、更可靠地向用户交付内容。\n简单来说，CDN 就像一个遍布全球的“快递网络”。当您访问一个网站时，如果没有 CDN，您的请求需要直接发送到网站的“中心仓库”（即源服务器 Origin Server），无论这个仓库有多远，都可能导致访问延迟。而有了 CDN，您的请求会被智能地导向离您最近的“快递站点”（即边缘服务器），直接从这个站点获取内容，从而大大缩短了等待时间。\n\nCDN 的工作原理CDN 的核心目标是缩短数据传输的物理距离，从而减少延迟。其工作流程通常涉及以下几个关键步骤：\n1. 用户发起请求当用户在浏览器中输入网址并发起访问请求时，这个请求首先会由本地的 DNS（域名系统）服务器处理。\n2. 智能 DNS 解析配置了 CDN 服务的网站，其 DNS 解析过程会被 CDN 的全局负载均衡（GSLB）系统接管。该系统会根据用户的地理位置、网络状况以及各个边缘节点的负载情况，智能地选择一个最优化的边缘服务器，并将其 IP 地址返回给用户。\n\n这一步是实现“就近访问”的关键。通过智能调度，确保用户的请求被发送到响应速度最快的节点，而非地理位置绝对最近但可能拥堵的节点。\n\n3. 内容交付用户的浏览器在获取到最优边缘服务器的 IP 地址后，会直接向该服务器发起请求。\n\n缓存命中（Cache Hit）：如果该边缘服务器上已经缓存了用户请求的内容（例如图片、CSS 文件或视频），并且缓存尚未过期，服务器会立即将内容响应给用户。这是最理想、最快速的情况。\n缓存未命中（Cache Miss）：如果边缘服务器上没有缓存所需内容，或者缓存已过期，它会向源服务器发起请求，获取最新的内容。\n\n\n这个过程被称为“回源”。边缘服务器从源服务器获取内容后，会将其缓存在本地，以备后续相同请求使用，然后才将内容发送给用户。这样，下一个访问该内容的附近用户就能直接从缓存中获取，实现加速。\n\n\nCDN 的主要优势使用 CDN 可以为网站和应用带来多方面的显著优势：\n1. 提升网站性能和用户体验\n降低延迟：通过从离用户最近的边缘服务器提供内容，显著减少了数据传输时间，加快了页面加载速度。研究表明，网站加载速度的提升能有效降低跳出率，提升用户留存和转化率。\n\n2. 提高可用性和可靠性\n负载均衡：CDN 将访问流量分散到多个边缘服务器，避免了单一源服务器因流量过大而崩溃的风险。\n冗余备份：当某个边缘节点或服务器发生故障时，CDN 的智能调度系统会自动将流量切换到其他健康的节点，保障服务的连续性，实现高可用性。\n\n3. 增强网站安全性\nDDoS 攻击缓解：CDN 的分布式架构天然能够分散和吸收大规模的分布式拒绝服务（DDoS）攻击流量，保护源服务器不被直接攻击而瘫痪。许多 CDN 服务商还提供 Web 应用程序防火墙（WAF）等增值安全服务。\n隐藏源站 IP：由于所有流量都经过 CDN 节点，攻击者无法轻易获取源服务器的真实 IP 地址，从而增加了攻击难度。\n\n4. 降低带宽成本\n减少源站负载：大部分用户请求由 CDN 的边缘服务器处理，大大减少了回源的次数和数据量。这意味着源服务器所需的带宽显著降低，从而为网站所有者节省了大量的带宽成本。\n\n\nCDN 的关键技术CDN 的高效运作依赖于多种核心技术：\n1. 内容路由技术（负载均衡）这是 CDN 的大脑。它通过全局负载均衡（GSLB）和本地负载均衡（SLB）技术，实时监测全网的流量和节点状态，将用户请求精准地导向最佳服务节点。\n2. 内容分发与存储技术\n拉取模式（Pull）：由用户请求驱动，当边缘节点未命中缓存时主动回源拉取内容。这种模式部署简单，适用于内容更新不频繁的场景。\n推送模式（Push）：由网站管理员主动将内容从源站推送到所有边缘节点。这种模式适用于需要提前分发的大文件或热门内容，确保用户首次访问即可命中缓存。\n\n3. 缓存技术（Caching）CDN 的核心功能。通过复杂的缓存策略（如设置缓存过期时间 TTL - Time To Live），决定哪些内容被缓存、缓存多久，以在加速效果和内容新鲜度之间取得平衡。\n\n镜像站点与 CDN 的区别在一些游戏的官方网站上，您可能会看到类似这样的选项：\n\n下载点 1（亚洲服务器）\n下载点 2（欧洲服务器）\n下载点 3（北美服务器）\n\n这种方式被称为“镜像站点（Mirror Site）”。它确实是 CDN 的一种早期或简化形式，但与现代 CDN 存在关键区别。\n核心区别：手动选择 vs 自动智能调度CDN 和传统的下载镜像站，最核心的区别在于智能化和自动化程度。\n\n\n\n特性\n下载镜像（Mirror Site）\n内容分发网络（CDN）\n\n\n\n工作模式\n手动\n自动\n\n\n用户操作\n用户需要手动选择一个认为最快的下载链接。\n用户只需点击一个下载按钮，无需做任何选择。\n\n\n路由方式\n静态。链接固定指向某个服务器。\n动态、智能。CDN 系统会实时根据用户的地理位置、网络延迟、节点负载等因素，自动将用户请求路由到最优的边缘服务器。\n\n\n可靠性\n如果用户选择的某个镜像服务器宕机或拥堵，下载就会失败或变得很慢。\n高可靠性。如果某个节点出现问题，系统会自动切换到其他健康的节点，用户几乎无感知。\n\n\n效率\n依赖用户的个人判断，不一定能选到最优节点。\n通过全局负载均衡（GSLB）确保用户总是连接到当前最理想的服务器，效率最大化。\n\n\n","categories":["web"],"tags":["web"]},{"title":"域名解析(DNS)","url":"/2025/08/27/web/dns/","content":"什么是 DNS？—— 互联网的“电话簿”DNS（Domain Name System，域名系统）是互联网一项核心的服务。它最基本的功能，就是将人类易于记忆的域名（例如 www.google.com）翻译成计算机能够理解和处理的 IP 地址（例如 142.251.42.196）。\n这个过程就如同查一本巨大的电话簿：\n\n姓名（域名）：www.google.com\n电话号码（IP 地址）：142.251.42.196\n\n我们人类习惯于记住有意义的名字，而计算机在网络中通信则依赖于数字地址。DNS 就是连接这两者之间的桥梁，没有它，我们访问每个网站都需要输入一长串无规律的数字，互联网将变得极难使用。\n\nDNS 解析的核心参与者在一次完整的域名解析过程中，通常有四类服务器协同工作，像一个分工明确的团队：\n1. 递归解析器 (Recursive Resolver)也常被称为本地 DNS 服务器 (Local DNS)。它通常由您的网络服务提供商（ISP，例如中国电信）或公共服务商（如 Google 的 8.8.8.8、Cloudflare 的 1.1.1.1）提供。\n\n职责：它不直接拥有域名信息，而是作为用户的“代理”，负责接收用户的查询请求，并通过一系列查询，最终为用户找到并返回一个确切的 IP 地址。它会缓存查询结果，以加速后续的相同请求。\n\n2. 根域名服务器 (Root Server)位于 DNS 查询链的顶端，是整个域名系统的起点。全球只有 13 组根服务器（从 A 到 M 命名），但每组都在全球部署了大量镜像。\n\n职责：它不直接解析域名，而是告诉递归解析器下一步应该去哪里查询，即提供顶级域名服务器的地址。\n\n3. 顶级域名 (TLD) 服务器 (Top-Level Domain Server)负责管理特定类型的域名后缀，例如 .com、.org、.net，以及国家/地区代码如.cn（中国大陆）、.jp（日本）等。\n\n职责：当收到查询请求后（例如查询 google.com），它会指明负责管理这个具体域名的权威域名服务器的地址。\n\n4. 权威域名服务器 (Authoritative Server)这是查询链的最后一站。它真正存储着特定域名与其 IP 地址的对应关系（即 DNS 记录）。\n\n职责：当收到关于它所管辖域名（如 www.google.com）的查询时，它会给出最终的、权威的答案——目标的 IP 地址。\n\n\nDNS 解析的详细步骤（查询之旅）下面以您在浏览器中访问 www.google.com 为例，走一遍完整的 DNS 解析流程。这个过程融合了递归查询和迭代查询两种模式。\n\n背景：您的电脑向它的本地 DNS（递归解析器）发起的是一个“递归查询”，意思是“请你务必帮我找到答案”。而本地 DNS 向其他服务器发起的则是“迭代查询”，意思是“如果你不知道，请告诉我下一步该问谁”。\n\n\n1. 检查本地缓存\n操作：您的电脑在发起网络请求前，会首先检查自身的浏览器缓存和操作系统缓存（包括 Hosts 文件），看之前是否访问过 www.google.com 并留下了记录。\n原因：这是最快的响应方式。如果本地有记录且未过期，解析过程直接结束，电脑立即使用该 IP 地址发起访问。\n\n2. 发起递归查询\n操作：如果在本地缓存中未找到记录，您的电脑会将查询请求发送给预先配置好的本地 DNS 服务器（递归解析器）。\n原因：电脑将繁琐的查询任务“外包”给了专业的 DNS 服务器。\n\n3. 递归解析器的迭代查询之旅本地 DNS 服务器收到请求后，会开启一连串的迭代查询：\n\n(3a) 查询根域名服务器：本地 DNS 服务器向其中一个根域名服务器发出请求：“你好，请问谁知道 .com 域名的信息？” 根服务器回答：“我不知道 www.google.com 的 IP，但你可以去问负责 .com 的 TLD 服务器，它的地址是 XXX。”\n(3b) 查询顶级域名 (TLD) 服务器：本地 DNS 服务器转向 .com 的 TLD 服务器发出请求：“你好，请问谁知道 google.com 的信息？” TLD 服务器回答：“我不知道 www.google.com，但你可以去问 google.com 的权威域名服务器，它的地址是 YYY。”\n(3c) 查询权威域名服务器：本地 DNS 服务器最后向 google.com 的权威域名服务器发出请求：“你好，请问 www.google.com 的 IP 地址是什么？”\n\n4. 获得最终答案\n操作：权威域名服务器查询自己的记录，找到 www 这条主机记录对应的 IP 地址 142.251.42.196，并将其返回给本地 DNS 服务器。\n原因：权威服务器拥有最终解释权，它提供的答案是本次查询的终点。\n\n5. 返回结果并缓存\n操作：本地 DNS 服务器拿到了 IP 地址，它会先将这个对应关系缓存起来（以便下次有其他用户查询时能直接响应），然后将这个 IP 地址返回给您的电脑。\n原因：缓存是提升 DNS 解析效率的关键，可以避免对同一个域名进行重复的、从根开始的完整查询。\n\n6. 浏览器发起连接\n操作：您的电脑收到了 IP 地址 142.251.42.196，您的浏览器就可以利用这个地址向 Google 的服务器发起 TCP 连接，请求网页内容了。\n\n至此，一次完整的 DNS 域名解析过程就结束了。\n","categories":["web"],"tags":["web"]},{"title":"About Shell","url":"/2025/07/07/misc/Shell/","content":"什么是 ShellShell 是一个命令行解释器，它为用户提供了一个向操作系统内核发送请求以便运行程序的界面系统级程序。\n什么是 Shell 脚本/.sh 文件.sh 文件，全称为 Shell 脚本文件 (Shell Script File)，是一种为 Shell 编写的脚本程序。它的核心作用是将一系列需要执行的 Shell 命令按照顺序预先写在一个文件里，然后让 Shell 像执行剧本一样，从上到下自动地、依次地执行这些命令，从而实现任务的自动化。\n下面是一个简单的文件备份脚本：\n#!/bin/bash# 这是一个简单的文件备份脚本# --- 1. 定义变量 ---# 设置要备份的源目录和存放备份的目标目录SOURCE_DIR=\"/home/user/documents\"BACKUP_DIR=\"/mnt/backups/documents\"# 创建一个基于当前日期和时间的时间戳TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\")# 最终的备份路径FINAL_BACKUP_PATH=\"${BACKUP_DIR}/backup_${TIMESTAMP}\"# --- 2. 执行命令 ---# 在屏幕上打印信息，告知用户操作开始echo \"开始备份 ${SOURCE_DIR} 到 ${FINAL_BACKUP_PATH} ...\"# 创建一个带时间戳的新目录用于存放本次备份mkdir -p \"${FINAL_BACKUP_PATH}\"# 使用 rsync 命令（一个强大的文件复制工具）来执行备份# -a: 归档模式，保留所有文件属性# -v: 详细模式，显示过程# -h: 人性化显示大小rsync -avh \"${SOURCE_DIR}/\" \"${FINAL_BACKUP_PATH}/\"# --- 3. 结束 ---# 再次打印信息，告知用户操作完成echo \"备份完成！\"\n\n\n\n\n\n\n","categories":["misc"],"tags":["misc"]},{"title":"召回","url":"/2024/06/26/algorithms/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/","content":"基于物品的协同过滤 (Item-Based Collaborative Filtering, ItemCF)ItemCF的原理：如果用户喜欢物品 1，而且物品 1 与物品 2 相似，那么用户很可能也喜欢物品 2。\n这个原理非常直观。在现实生活中，如果你喜欢一部科幻电影（比如《星际穿越》），那么推荐系统很可能会向你推荐另一部评价很高、风格类似的科幻电影（比如《盗梦空间》），因为它假设这两部电影是”相似”的。ItemCF 就是将这种思想系统化和自动化。\n它的核心优势在于，物品之间的相似性在大多数情况下是相对稳定的，比用户兴趣的稳定性要高。因此，可以预先离线计算好物品之间的相似度，从而在线上实现快速推荐。\n当然，ItemCF 也有局限性。它无法发掘用户的潜在兴趣，推荐结果往往比较局限，新颖性不足。对于新物品还存在 冷启动 (Cold Start) 问题，因为它没有被评分，无法计算相似度。\n计算两个物品之间相似度的公式余弦相似度:\n\n在隐式反馈场景，即只要用户喜欢过（比如点击过）like(u,i)=1的时候, 公式进一步退化为最后一项。\n\n\n：代表我们想要计算相似度的两个物品（例如，电影A和电影B）。\n：喜欢物品  的所有用户的集合。\n：喜欢物品  的所有用户的集合。\n：同时喜欢物品  和  的所有用户的集合。这个交集是计算相似度的关键。\n：代表用户  对物品  的喜好程度。\n在隐式反馈场景中：如果用户  点击/播放/购买了物品 ，则 ，否则为 0。\n在显式反馈场景中： 可以是用户  对物品  的具体评分，比如 1 到 5 星。\n\n\n\n分子 (Numerator)\n含义：这部分计算的是两个物品被共同用户喜欢的程度的累积。\n步骤说明：\n\n找到所有同时喜欢过  和  的用户（即集合  中的每一个用户 ）。\n对于每一个这样的用户 ，取出他对  的喜好分  和他对  的喜好分 。\n将这两个分数相乘。\n将所有共同用户的计算结果（乘积）全部加起来。\n\n直观理解：如果共同喜欢这两个物品的用户，都给出了很高的评分，那么这个分子的值就会很大，说明这两个物品在”核心粉丝群”中的评价模式很一致。\n分母 (Denominator)\n含义：这部分是两个物品各自”热度”的体现，起到归一化 (Normalization) 的作用，旨在消除物品流行度带来的影响。\n步骤说明：\n\n分母由两部分相乘构成：\n第一部分：\n找到所有喜欢物品  的用户（集合 ）。\n计算每个用户对  喜好程度的平方，并把它们全部加起来。\n最后对这个总和开平方根。这在数学上被称为向量的 L2 范数 (L2-norm)。\n\n\n第二部分：\n对物品  进行完全相同的计算。\n\n\n\n\n\n直观理解：一个物品越热门，喜欢它的用户（ 或 ）就越多，它在分母上的值就越大。这就像一个惩罚项，可以降低超级热门物品与任何其他物品的相似度。\n预估用户对候选物品的兴趣计算出物品之间的相似度后，我们就可以为特定用户 u 预测他对某个候选物品 j 的兴趣度（或评分）了。\n基本思路：\n\n找到该用户 u 过去喜欢过的所有物品集合 S(u)。\n对于候选物品 j，计算它和各个 S(u) 集合中物品的相似度。\n用户 u 对物品 j 的兴趣度 P(u, j)，可以通过加权平均的方式计算得出。\n\n公式：\n\n\n 是物品 i 和物品 j 的相似度。\n 是用户 u 对物品 i 的喜好程度。\n 是用户 u 过去有过行为的物品集合。\n\n步骤说明：\n\n遍历用户历史行为：我们查看用户 u 过去喜欢的每一个物品 i 。\n查找相似度：找到物品 i 与目标物品 j 之间的相似度 。\n加权求和：将这个相似度作为权重，乘以用户对物品 i 的喜好程度。\n累加：将所有这些加权后的分数累加起来，就得到了用户 u 对物品 j 的最终兴趣预测分。分数越高，代表用户可能越喜欢它。\n\n利用索引在线上快速做召回在大型推荐系统中，物品数量可能达到百万甚至千万级别。如果每次推荐请求都实时计算所有物品的相似度和预测得分，计算量会非常巨大，无法满足线上服务的低延迟要求。\n问题： 线上服务要求在几十毫秒内返回推荐结果，实时计算是不可行的。\n解决方案：建立倒排索引 (Inverted Index)。\n具体做法：\n\n离线计算：在离线环境下，花费数小时甚至数天的时间，计算出所有物品两两之间的相似度。这是一个计算密集型任务。\n存储相似物品：对于每一个物品 i，我们筛选出与它最相似的 K 个物品，并将这个关系  存储起来。这个结构就是一个倒排索引：键（Key）是物品 i，值（Value）是一个列表，包含了与 i 最相似的物品及其相似度分数。\n线上召回 (Retrieval)：当一个用户 u 发出推荐请求时，系统执行以下快速操作：\na. 获取该用户最近有过行为的物品列表（例如，最近点击的 10 个商品）。\nb. 对于列表中的每一个物品 i，通过倒排索引，瞬间查到与 i 最相似的物品集合。\nc. 将所有这些相似物品集合汇总、去重、排序，然后生成最终的推荐列表。\n\n\n\n优势：\n通过预计算和索引，线上的推荐过程从复杂的”计算”任务转变为高效的”查找”任务，极大地降低了响应时间，满足了实时推荐的需求。\n基于模型的协同过滤 (Model-Based Collaborative Filtering, ModelCF)基于模型的协同过滤算法，通过构建用户和物品的潜在特征矩阵，旨在从稀疏的评分数据中学习到能够描述用户和物品特性的隐因子 (Latent Factors)来预测用户对物品的兴趣。\n矩阵分解 (Matrix Factorization, MF)矩阵分解是基于模型的协同过滤算法中的一种，它将用户-物品评分矩阵分解为两个低维矩阵的乘积，从而揭示用户和物品的潜在特征。\n矩阵分解假设用户对物品的评分行为是由一些潜在的、无法直接观测到的共同因素决定的。例如，在电影推荐中，这些隐因子可能代表着电影的”喜剧成分”、”动作片成分”、”艺术性”，以及用户对这些成分的偏好程度。\n它的目标是将原始的 用户-物品评分矩阵 R (大小为 m×n，m是用户数，n是物品数) 分解为两个低维度的 隐因子矩阵：用户因子矩阵 P (大小为 m×k)和物品因子矩阵 Q (大小为 n×k), 其中k是隐因子的数量，是一个远小于 m 和 n 的超参数 (k≪m,n)。\n通过这两个矩阵，我们可以用它们的乘积来近似重构原始的评分矩阵：\n\nP 矩阵：每一行  代表一个用户的 用户隐向量，描述了该用户在 k 个隐因子上的偏好程度。\n\nQ 矩阵：每一行  代表一个物品的 物品隐向量，描述了该物品在 k 个隐因子上的分布情况。\n\n\n预测评分：用户 u 对物品 i 的预测评分  就是他们对应隐向量的 点积 (Dot Product)：\n$\\hat{r}{ui} = p_u \\cdot q_i = \\sum{f=1}^{k} p_{uf} \\cdot q_{if}$\n如何进行分解？—— 模型学习由于原始评分矩阵 R 是高度稀疏的，我们无法直接进行像 奇异值分解 (Singular Value Decomposition, SVD) 这样的标准矩阵分解。因此，我们采用机器学习的方法来学习 P 和 Q 矩阵。\n\n定义目标函数 (Objective Function)：我们的目标是让预测评分 $\\hat{r}{ui}尽可能地接近已知的真实评分r{ui}$。因此，我们定义一个基于均方根误差 (RMSE) 的损失函数，并为了防止过拟合 (Overfitting)，加入 正则化项 (Regularization Term)。\n\n\n\n\nK：所有已知的用户-物品评分对的集合。\n\n：平方误差项，衡量预测与真实的差距。我们只对已知的评分进行计算。\n\n：L2 正则化项，用于惩罚隐向量中元素值过大的情况，增强模型的泛化能力。λ 是正则化系数。\n\n\n\n优化求解：常用的优化算法有两种：\n\n\n交替最小二乘法 (Alternating Least Squares, ALS)\n这是一个两阶段的迭代过程。首先，固定 Q 矩阵，此时目标函数是关于 P 的二次函数，可以直接求解得到最优的 P。然后，固定更新后的 P 矩阵，用同样的方法求解最优的 Q。\n\n交替进行这两个步骤，直到收敛。ALS 的优点是易于并行化实现，尤其适用于处理大规模的隐式反馈数据。\n\n\n\n随机梯度下降 (Stochastic Gradient Descent, SGD)\n随机选择一个已知的评分 (u,i)，计算损失函数对  和  的偏导数，并沿着梯度的反方向小步更新这两个向量。\n\n更新规则：\n\n\n其中， 是预测误差，η 是学习率。\n\n通过大量迭代，不断地对 P 和 Q 进行微调，直到损失函数收敛。这种方法实现简单，计算速度快。\n\n\n\n\n矩阵分解的优缺点优点：\n\n处理稀疏数据能力强：通过低维的隐因子表示，极大地缓解了数据稀疏问题。\n泛化能力好：能够发现数据中潜在的关联模式，预测精度通常高于近邻方法。\n可扩展性强：模型训练好后，预测新评分的计算成本很低。\n\n缺点：\n\n缺乏可解释性：学习到的隐因子通常没有明确的物理意义，难以向用户解释推荐的原因。\n冷启动问题依然存在：对于新用户或新物品，由于没有历史数据，无法为其生成隐向量。\n\n","categories":["algorithms"],"tags":["搜广推"]},{"title":"推荐系统基础","url":"/2024/06/26/algorithms/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","content":"推荐系统（Recommender System）是一种信息过滤系统（Information Filtering System），其核心目标是解决在海量数据环境中用户与物品（Items）之间的信息过载（Information Overload）问题。系统通过建模用户偏好与物品属性，预测用户对于其未曾接触过的物品的偏好程度或评分，从而实现个性化推荐。\n推荐系统的基本概念从数据来源、效果评估到商业目标和工程实践，推荐系统主要包括四个核心方面：\n1. 用户行为（User Behaviors）—— 推荐系统的信号与养料用户与推荐内容交互时产生的各种行为，是推荐系统赖以生存的数据信号，模型通过学习这些信号来理解用户的偏好。\n\n点击（Click）\n定义：用户点击了推荐给他的某个物品（如一篇文章、一个视频、一件商品）。\n解读：最常见、最容易获取的行为信号，通常被认为是弱正反馈。表明用户对标题或封面图产生了兴趣，但不代表一定喜欢内容本身。\n\n\n点赞（Like）\n定义：用户对内容按下了”赞”按钮。\n解读：比”点击”更强的正反馈信号，明确表达了用户对内容的认可和喜爱。\n\n\n收藏（Favorite / Collect）\n定义：用户将内容加入到自己的收藏夹或列表中。\n解读：非常强的正反馈信号，意味着内容具有长期价值。\n\n\n转发（Share / Forward）\n定义：用户将内容分享到其他平台或发送给朋友。\n解读：最强的正反馈信号之一，用户愿意用自己的社交信誉为其背书。\n\n\n\n\n小结：在构建推荐模型时，通常会给这些不同的行为赋予不同的权重（Weight），如”收藏”权重高于”点击”。\n\n\n2. 消费指标（Consumption Metrics）—— 衡量推荐算法好坏的尺子这些指标用于量化评估推荐系统在技术层面的表现，直接与用户行为挂钩。\n\n点击率（Click-Through Rate, CTR）\n定义：用户点击推荐内容的次数占总推荐曝光次数的比例。\n公式：CTR = 总点击次数 / 总曝光次数 × 100%\n解读：衡量推荐内容吸引力的核心指标，也是精排模型最常优化的目标之一。\n\n\n交互率（Engagement Rate）\n定义：用户与推荐内容发生”深度交互”的次数占总曝光次数的比例。\n公式：总交互次数 = w1 × 点击数 + w2 × 点赞数 + w3 × 收藏数 + ...\n解读：比 CTR 更全面，反映内容质量和用户满意度。\n\n\n\n\n3. 北极星指标（North Star Metric）—— 推荐系统服务的商业目标北极星指标是指引整个产品方向的最高层商业目标，推荐系统的所有优化最终都应服务于提升北极星指标。\n\n用户规模（User Scale）\n定义：如日活跃用户数（DAU）、月活跃用户数（MAU）。\n解读：好的推荐系统应提升用户留存率，扩大用户规模。\n\n\n消费（Consumption）\n定义：用户在产品中消费内容的总量。\n解读：如总观看时长、总阅读时长/篇数、总播放时长/曲数、总成交金额（GMV）等。\n\n\n发布（Publishing / Creation）\n定义：内容平台上内容创作者的发布数量和活跃度。\n解读：推荐系统要服务好消费者，也要服务好创作者，激励持续发布高质量内容。\n\n\n\n\n4. 实验流程（Experimentation Process）—— 科学迭代的必经之路用于验证新推荐算法或策略是否有效，并安全应用到全量用户。\n\n离线实验（Offline Experiment）\n定义：在历史日志数据上进行模型训练和评估。\n步骤：将日志分为训练集和测试集，训练新模型并评估离线指标（如 AUC, Precision, Recall）。\n优缺点：成本低、速度快、无风险，但与线上环境有差异。\n\n\nA/B 测试（A/B Testing）\n定义：将用户随机分组，线上同时运行不同算法，是验证算法效果的黄金标准。\n步骤：A 组用旧算法，B 组用新算法，比较线上指标。\n\n\n推全（Full Rollout / Deployment）\n定义：AB 测试证明新算法更优后，逐步部署到全部用户。\n步骤：通常灰度发布，逐步扩大覆盖比例，监控系统指标。\n\n\n\n\n推荐系统链路现代推荐系统采用多阶段排序（Multi-stage Ranking）架构，像漏斗一样分阶段筛选和排序，平衡效果与效率。\n召回（Recall）召回是整个推荐流程的第一步，也是效率要求最高的一步。\n\n目标：从海量物品库中快速筛选出与用户兴趣相关的候选集。此阶段追求“宁可错杀一千，不可放过一个”，重在覆盖率（召可回率），即确保用户可能感兴趣的物品尽量都在这个候选集里。\n输入：全量物品库（几万~上亿）。\n输出：初步候选集（几千）。\n方法：多路召回策略, 即通常会综合使用多种简单策略来共同组成候选集。\n协同过滤(Collaborative Filtering)：基于“物以类聚，人以群分”的思想，例如“购买了A的用户也购买了B, 给用户推荐他喜欢过的物品的相似物品”（Item-based）或“与您相似的用户喜欢C, 给用户推荐与他相似用户喜欢的东西”（User-based）。\n基于向量的召回 (Embedding-based)：目前最主流的方法。将用户和物品都表示为高维空间中的向量（Embedding）。通过高效的向量相似度检索（如 FAISS、Annoy），快速找到与用户向量最接近的物品向量。例如经典的双塔模型 (Two-Tower Model)。\n内容模型召回：根据物品本身的属性（如类别、标签、关键词）进行匹配。\n热门物品或趋势召回：对于新用户或兴趣不明确的用户，推荐近期热门的物品。\n\n\n为何需要此步骤:直接对全量物品进行复杂排序的计算成本是无法接受的。召回阶段通过简单、高效的模型，将计算范围缩小到千量级，为后续更复杂的排序模型做好准备。\n\n粗排（Coarse Ranking）\n目标：对召回候选集进行初步排序，，使用比召回更复杂、但比精排更简单的模型，进一步剔除相关性不高的物品，缩小候选集规模。\n输入：召回候选集（几千）。\n输出：更小的候选集（几百）。\n方法：简化机器学习模型（LR、GBDT、小型神经网络）。\n为何需要此步骤:它是一个承上启下的“中间层”。精排模型虽然效果好，但计算开销大，直接处理几千个物品依然很慢。粗排模型作为一个轻量级的排序模型，可以快速地为精排阶段减负。\n\n精排（Fine Ranking）精排是整个推荐链路中最为核心和复杂的环节，直接决定了推荐效果的天花板。\n\n目标：精准排序。利用强大的、复杂的模型，对粗排筛选出的几百个物品进行精准的点击率（CTR）、转化率（CVR）等指标的预测，并按照预测分值进行排序。此阶段重在准确率（Precision）。\n输入：粗排候选集（几百）。\n输出：一个带有精确预测分数的、排序后的列表（几百物品）。\n方法：大规模深度学习模型（Wide &amp; Deep、DeepFM、DIN 等）。\n为何需要此步骤:   在候选集规模已经大大减小的情况下，系统有充足的计算资源来运行复杂模型。这使得模型可以使用海量的特征，包括用户特征（年龄、性别、历史行为）、物品特征（类别、价格）、上下文特征（时间、地点）以及它们的交叉组合特征，从而做出最精准的判断。\n\n重排（Re-ranking）\n目标：优化与多样性。在精排结果的基础上，进行最终的列表调整。重排考虑的不仅是单个物品的得分，而是整个列表呈现给用户时的整体体验。\n输入：精排列表（几百）。\n输出：最终列表（几十）。\n方法：\n多样性（Diversity）：通过打散和插播策略，确保推荐结果中包含不同类别、不同风格的物品。例如，使用 MMR (Maximal Marginal Relevance) 算法，平衡物品的相关性和多样性。\n业务规则干预：推广新品、促销品，或者对某些物品进行降权（例如已购买的物品）。\n上下文感知：去除重复项，避免短时间内重复推荐。\n公平性（Fairness）：确保不同商家或内容创作者能获得合理的曝光机会。\n\n\n为何需要此步骤:   如果完全按照精排的预测分值排序，可能会出现结果高度相似（例如推荐一整排同款不同色的鞋子）、头部物品包揽所有流量、或忽略了新品曝光等问题。重排阶段就是为了解决这些问题，提升用户体验和满足业务需求。\n\n\n推荐系统的 AB 测试下列内容是在工业界进行大规模 A/B 测试时非常核心且高级的概念，反映了顶级互联网公司如何在高并发和快速迭代环境下科学、高效地优化产品和算法。\n1. 分层实验（Layered Experiments）这是一种能够大幅提升实验效率的流量分配机制，其核心思想在于将互不干扰的实验叠加在同一批用户上。\n\n基本思想：一个推荐系统可以被拆分成不同的“模块”或“层面”，例如：\n\nUI 层：负责按钮颜色、字体大小等界面展示。\n召回策略层：负责从海量物料中捞取候选集。\n排序模型层：负责对候选集进行精准排序。\n\n\n\n分层实验平台允许我们为这些不同的层面独立地开设实验。\n\n同层互斥(Mutually Exclusive within a Layer)：在同一个层内，实验之间是互斥的。这意味着一个用户在某个时刻，只能被分配到该层的一个实验组中。例如，在“排序模型层”，一个用户要么看到A模型的结果，要么看到B模型的结果，不可能同时看到两者。流量在该层内被完整切分。\n不同层正交 (Orthogonal between Layers)：在不同的层之间，实验是正交（独立）的。这意味着一个用户可以同时属于不同层的多个实验组。例如，一个用户可以同时是“UI层-红色按钮”实验组的成员，又是“排序模型层-新版模型B”实验组的成员。系统假设UI的改变和排序模型的改变是两个独立事件，它们的效果不会相互影响。\n\n\n优势：允许多个团队并行开展实验，大幅提升创新速度。\n\n2. Holdout 机制（Holdback 实验）这是一种用于衡量长期、累积影响的宏观实验方法，其视角超越了单次A/B测试的短期收益。\n\n基本思想：从全部用户中，永久性地分出一小部分（例如 1%\\5%）作为“绝对对照组”或“Holdout 组”。这个组的用户将永远不会体验到任何新的推荐功能或算法优化，他们使用的始终是一个非常稳定、原始的版本。而剩下 95%99% 的用户则会不断地体验到通过A/B测试胜出的新功能。\n作用：\n衡量部门的整体业务收益：单次的A/B测试衡量的是单个小改动的短期收益。但是，一个季度、一年下来，整个部门上线的几十上百个“胜出”的实验，它们累加起来的效果究竟有多大？会不会有些短期收益在长期来看会相互抵消，甚至产生负面作用（例如用户对某种策略产生疲劳）？\n步骤说明：通过在年底或季末比较“实验大盘用户”和“Holdout组用户”的核心业务指标（如留存率、总消费时长等），就可以清晰地衡量出，在这一整段时间里，整个推荐团队的所有努力共同创造的净业务价值。这为衡量团队的长期ROI（投资回报率）提供了最可靠的依据。\n\n\n比喻：Holdout 组就像科学实验中的”空白对照组”, 它为我们评估所有变量的“混合累积效应”提供了一个不变的基准。\n\n3. 实验推全（Full Rollout）与反转实验（Reverse Experiment）这是与实验生命周期管理相关的两个重要操作。\n实验推全 AB 测试胜出后，将新策略逐步推向全体用户，通常采用灰度发布。\n\n基本思想：当一个A/B测试（例如，新算法B vs. 老算法A）在经过足够长的时间和数据收集后，被验证为显著优于对照组时（例如，新算法B的点击率显著更高），决策者就会决定将这个新算法B的策略应用到100%的全体用户。这个过程就是“推全”。\n步骤说明：为了线上服务的稳定性，推全通常是逐步进行的（也称灰度发布），例如先推10%的流量，再到50%，最后到100%，并在此期间密切监控各项系统指标。\n\n反转实验 (Reverse Experiment)验证已上线老功能是否依然有效，或移除后是否有负面影响。\n\n基本思想：这是一种“回过头看”的实验，主要目的是验证已上线很久的老功能是否依然有效，或者说，移除它是否会带来损失。\n操作流程：假设“功能F”在一年已经全量上线了。现在，我们将以“全体用户（都有功能F）”作为基线，然后开启一个反向的AB测试：A组（对照组）：保持现状，拥有功能F。B组（实验组）：移除功能F，体验没有该功能的状态。\n为何需要此机制？\n确认长期价值：验证该功能是否至今仍在创造价值。如果移除后，B组的核心指标显著下跌，说明该功能依然重要。\n清理“技术债务”：如果移除后，B组的指标没有任何变化，甚至有所提升，这说明该功能可能已经“过时”或产生了不易察觉的负面影响。这为工程师安全地移除老旧代码、简化系统提供了强有力的数据支持，避免产品功能无限膨胀和代码腐化。\n\n\n\n参考论文: Tang, Diane, et al. “Overlapping experiment infrastructure: More, better, faster experimentation.” Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining. 2010. \n推荐系统的前世今生: https://www.bilibili.com/video/BV1EE421G7dg/\n","categories":["algorithms"],"tags":["搜广推"]},{"title":"聚类算法","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","content":"聚类算法的目标是在没有预先定义类别的情况下，将数据集划分为若干个有意义的群组, 使得同一类中的数据点彼此相似，而不同类中的数据点差异较大。\nK-均值聚类 (K-Means Clustering)K-means 聚类是一种非常流行且基础的 无监督学习 (Unsupervised Learning) 算法。它的主要目标是将一个给定的数据集根据数据点之间的相似性，自动划分为 K 个不同的 簇 (Cluster)。这里的”K”是一个需要预先指定的超参数，代表你希望最终得到的簇的数量。\n它的核心思想是 “物以类聚，人以群分”。它通过迭代的方式，不断地优化每个簇的中心点————即质心 (Centroid)，并根据数据点与质心的距离，将每个数据点分配给最近的簇。这个过程持续进行，直到质心的位置不再发生显著变化，或者达到了预设的迭代次数，此时我们认为聚类结果已经收敛。\n算法的目标是最小化簇内平方和(Within-Cluster Sum of Squares, WSS)，也被称为 惯性 (Inertia)。简单来说，就是让同一个簇内的数据点尽可能地紧密，不同簇之间的数据点尽可能地远离。\n算法步骤\n初始化 (Initialization)\n\n操作：从数据集中随机选择 K 个数据点作为初始的质心 (μ₁, μ₂, …, μ_K)。\n说明：这是算法的起点。质心的初始位置会影响算法的收敛速度和最终结果。因为是随机选择，所以多次运行 K-means 可能会得到不同的聚类结果。\n\n\n分配 (Assignment)\n\n操作：对于数据集中的每一个数据点 ，计算它到 K 个质心  的距离，并将其分配给距离最近的那个质心所在的簇 。\n说明：此步骤的目的是根据当前的质心位置，为每个数据点找到一个”归属”。最常用的距离度量是欧几里得距离 (Euclidean Distance)。其数学表达式为：在实际计算中，为了提高效率，通常使用平方欧几里得距离，因为它省去了开方的计算，并且不会改变距离的相对大小关系。\n\n\n更新 (Update)\n\n操作：对于每一个簇 ，重新计算其质心 。新的质心是该簇内所有数据点的均值。\n说明：在第二步中，簇内的成员发生了变化，原来的质心可能不再是簇的几何中心。因此，需要通过计算均值来更新质心，使其移动到簇内数据点的中心位置。新的质心计算公式为：其中  是簇  中数据点的数量。\n\n\n迭代 (Iteration)\n\n操作：重复执行第二步（分配）和第三步（更新）。\n说明：这个迭代过程会不断地优化数据点的分配和质心的位置。当满足以下任一条件时，算法停止：\n质心的位置不再发生变化（或变化非常小，小于一个预设的阈值）。\n数据点的分配不再改变。\n达到了预设的最大迭代次数。\n\n\n\n\n\n数学原理K-means 算法的最终目标是最小化一个目标函数 (Objective Function)，这个函数就是我们前面提到的簇内平方和 (WSS)。其数学表达式为：\n\n\n：目标函数，即总的 WSS。\n：簇的数量。\n：第  个簇。\n：第  个簇的质心。\n：属于簇  的一个数据点。\n：数据点  到其所属簇质心  的平方欧几里得距离。\n\n上述公式表示所有数据点与其所属簇质心之间的距离平方和。\n算法的两个核心步骤（分配和更新）正是为了以迭代的方式最小化这个  值：\n\n分配步骤：在保持质心  不变的情况下，将每个  分配给能使其  最小的簇。这一步是在对  进行优化。\n更新步骤：在保持簇分配  不变的情况下，为每个簇寻找一个新的质心 ，使得该簇内的平方和  最小。可以证明，这个最优的  就是簇内所有数据点的均值。\n\n这是一个典型的期望最大化 (Expectation-Maximization, EM) 思想的应用。\nK-means 的优缺点优点：\n\n简单高效：算法原理简单，容易实现，计算速度快。对于大规模数据集，其可伸缩性很好。\n解释性强：聚类结果直观，容易解释。\n\n缺点：\n\nK值需要预先指定：如何选择最优的 K 值是 K-means 的一个核心难题。\n对初始质心敏感：不同的初始质心可能会导致完全不同的聚类结果，甚至可能陷入局部最优解。\n对异常值敏感：因为质心是基于均值计算的，个别的异常值（离群点）会对质心的位置产生较大影响。\n对非球形簇效果不佳：K-means 倾向于发现大小相似、形状为球形的簇，对于形状不规则的簇、密度不均匀的簇效果较差。\n\nDBSCAN (Density-Based Spatial Clustering)DBSCAN，全称为 Density-Based Spatial Clustering of Applications with Noise（基于密度的含噪声应用空间聚类），是一种非常流行且强大的聚类算法。\n与 K-均值 (K-Means) 算法试图找到球状的簇并且每个点都必须属于一个簇不同，DBSCAN 的核心思想是：一个簇是数据空间中一个连续的高密度区域，并由低密度区域分隔开。\n这使得 DBSCAN 具有两大显著优势：\n\n能够发现任意形状的簇（例如，环形、S形），而不像 K-均值那样只能处理凸形的簇。\n能够自动识别并标记出噪声点（离群点），而不是强行将它们分配到某个簇中。\n\n核心概念要理解 DBSCAN 的工作原理，必须先掌握它的三个基本概念，这些概念都围绕着”密度”来定义。这需要我们先设定两个关键参数：\n\n半径  (Epsilon)： 定义了一个点的”邻域”范围。它是一个距离值，用来画一个圈，圈内的所有点都被认为是这个点的邻居。\n最小点数 MinPts： 定义了形成一个”高密度区域”所需要的点的最小数量阈值。\n\n基于这两个参数，我们可以定义三种类型的点：\n\n核心点 (Core Point)： 如果一个数据点  在其  半径的邻域内，包含了至少 MinPts 个点（包括  自身），那么  就是一个核心点。\n核心点是高密度区域的”内部成员”。它们是簇的”骨架”，簇就是从这些点开始生长和扩展的。\n\n\n边界点 (Border Point)： 如果一个数据点  不是核心点，但它落在了某个核心点  的  邻域内，那么  就是一个边界点。\n边界点位于簇的”边缘”。它们本身密度不够，但它们是某个核心点的”邻居”，因此可以被归入该核心点所在的簇。\n\n\n噪声点 (Noise Point)： 如果一个数据点既不是核心点，也不是边界点，那么它就是噪声点（或离群点）。\n这些点是稀疏区域中的孤立点，不属于任何一个簇。DBSCAN 能够将它们有效地识别并分离出来。\n\n\n\n工作流程DBSCAN 的聚类过程就像在一个区域里寻找”人群”，并将它们连接起来。\n\n选择起点： 从数据集中任意选择一个尚未被访问过的点 。\n算法会遍历所有点，所以从哪里开始并不影响最终结果，只会影响发现簇的顺序。\n\n\n判断点的类型： 检查点  的  邻域。\n情况一： 如果  是一个核心点（其邻域内的点数  MinPts）：\n创建一个新的簇，并将  分配给这个簇。\n然后，扩展这个簇：检查  的所有邻居点。对于每一个邻居点 ，如果  也是一个核心点，就将  的所有邻居也加入到待处理的队列中。这个过程不断进行，直到所有通过核心点连接起来的（密度可达的）点都被加入到同一个簇中。\n这是算法最关键的一步，称为密度可达性扩展。它确保了一个完整的、高密度的区域被完整地识别为一个簇。\n\n\n情况二： 如果  不是一个核心点：\n暂时将  标记为噪声点。\n这个点可能是真正的噪声，也可能是一个边界点。它未来的归属取决于它是否落入其他核心点的邻域内。如果后续在扩展其他簇时发现了它，它就会被吸纳为边界点并加入那个簇。\n\n\n\n\n重复过程： 继续选择下一个尚未被访问过的点，重复步骤2，直到数据集中所有的点都被访问过。\n完成聚类： 当所有点都被访问后，聚类过程结束。一些点被分配到不同的簇中，而另一些点则被最终标记为噪声。\n\nDBSCAN 的优缺点优点：\n\n无需指定簇数量： 与 K-均值不同，DBSCAN 可以自动确定簇的数量。\n可发现任意形状的簇： 其基于密度的特性使其不受簇形状的限制。\n对噪声不敏感： 能够有效地识别并处理离群点，这在金融欺诈检测等场景中非常有用。\n\n缺点：\n\n对参数敏感：  和 MinPts 的选择对结果影响巨大，调参可能需要经验和多次试验。\n不适合密度差异大的数据集： 如果数据集中不同簇的密度相差很大，DBSCAN 可能难以用一套全局的  和 MinPts 参数来正确地识别所有簇。\n高维数据下的问题： 在非常高的维度下（维度灾难），所有点之间的距离可能趋于一致，这使得基于距离的”密度”概念变得不那么有意义。\n\n谱聚类 (Spectral Clustering)谱聚类是一种基于图论的聚类方法，其核心思想是将聚类问题转化为图的分割问题。与传统的K-Means等基于距离的聚类算法不同，谱聚类能够识别任意形状的样本空间，并且对数据分布的适应性更强，因此在许多场景下表现优越。\n\n想象一下，我们有许多数据点，如何将它们分组？\n\n传统方法（如K-Means）：找到每个簇的中心点，然后将每个数据点分配给离它最近的中心点。这种方法隐含了一个假设：每个簇都是凸的（比如圆形或球形）。如果簇的形状是弯曲的、不规则的（例如月牙形），K-Means就很难处理。\n谱聚类的思路：将所有数据点看作是图（Graph）中的节点（Vertices）。如果两个点彼此相似（距离近），就在它们之间连接一条边（Edge），边的权重表示它们的相似度。这样，整个数据集就变成了一张”相似度图”。现在，聚类的任务变成了如何切割这张图，使得分割后的不同子图之间连接的边的权重之和尽可能小（类间相似度低），而每个子图内部的边的权重之和尽可能大（类内相似度高）。\n这个”切图”的思想就是谱聚类的精髓。它将一个在原始特征空间中难以解决的非线性问题，通过图论转化为了一个更容易处理的线性代数问题。\n\n\n谱聚类算法步骤原始数据 (N, P) ➔ [构建相似度图] ➔ 邻接矩阵 W (N, N) ➔ [计算D和L] ➔ 拉普拉斯矩阵 L_sym (N, N) ➔ [特征分解] ➔ 新特征矩阵 U (N, k) ➔ [K-Means聚类] ➔ 最终聚类标签 (N, 1)\n构建相似度图 (Construct Similarity Graph)将每一个数据点看作图中的一个节点 (Vertex)。根据数据点之间的”相似度”，在节点之间连接边 (Edge)。如果两个点非常相似，它们之间的边权重就高；反之则低。\n这是算法的奠基之举，它将原始的、可能呈非线性复杂分布的数据集，转化为了一个可以用图论工具分析的结构。图的结构（谁和谁相连，连接有多强）编码了数据的内在关联。\n如何定义”相似”并建图至关重要，常用方法有：\n\nk-近邻图 (k-NN Graph)：每个点只与它最近的 k 个点相连。这是最常用、最稳健的方法之一。\n\n全连接图 (Fully-connected Graph)：所有点之间都有连接，边的权重通常由高斯核函数  决定。你需要选择合适的  值。\n\nε-近邻图 (ε-neighborhood Graph)：连接所有距离在阈值 ε 内的点对。(有时会将k-近邻图和ε-近邻图结合使用)\n\n\n计算邻接矩阵 W 和度矩阵 D即将上一步构建的图用数学语言来描述, 将图的拓扑结构数字化、矩阵化，为下一步的计算做好准备。\n邻接矩阵 W：一个 N×N 的方阵（N 是数据点总数）， 就是节点 i 和节点 j 之间边的权重。如果两点不相连，则为0 (W是对称的稀疏矩阵)\n度矩阵 D：一个 N×N 的对角矩阵， 是节点 i 的”度”，即与它相连的所有边的权重之和 ()。\n计算拉普拉斯矩阵 L利用 W 和 D 计算拉普拉斯矩阵。为了获得最好的效果，我们通常计算对称标准化的拉普拉斯矩阵 (L_sym)。\n\n（其中  是单位矩阵）\n这是整个算法的核心。拉普拉斯矩阵是一个神奇的矩阵，它的特征值和特征向量（合称”谱”） 蕴含了图的最佳分割信息。可以说，这个矩阵内部就”藏着”如何切分图的答案。\n计算特征值和特征向量 (执行”谱”分析)对拉普拉斯矩阵 L 进行特征分解，求出其所有的特征值和对应的特征向量。\n这就是”谱聚类”中”谱”这个词的来源。我们通过这一步来”解锁”拉普拉斯矩阵中隐藏的分割信息。其中，最小的几个特征值对应的特征向量对我们来说最重要。\n降维与投影从上一步得到的所有特征向量中，选取与前 k 个最小特征值相对应的 k 个特征向量。然后，将这 k 个特征向量按列排成一个新的 N×k 的矩阵 U。\n这是一个降维的过程。它将每个原始数据点从它原来的特征空间，投影到了一个全新的、低维的”谱空间”中。在这个谱空间里，原始数据复杂的非线性结构被”拉平”和”理顺”，变得更容易被区分。矩阵 U 的每一行就是原始数据点在这个新空间里的新坐标。\n使用 K-Means 进行最终聚类将第5步得到的新矩阵 U 作为输入，对其每一行（即每个数据点的新坐标）运行一次标准的 K-Means 算法，将其聚为 k 个簇。\n在前几步谱聚类已经完成了最困难的”结构梳理”工作。在新空间中，不同簇的数据已经变得界限分明，因此一个像 K-Means 这样简单的算法就足以完成最后的”收尾”工作，为每个点分配最终的聚类标签。\n示例代码\n使用sklearn包的SpectralClustering\n\nimport numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import make_circlesfrom sklearn.cluster import SpectralClustering# 1. 生成数据集# 我们生成一个同心圆数据集# n_samples: 样本总数# factor: 内外圆之间的比例# noise: 噪声水平X, y_true = make_circles(n_samples=1000, factor=0.5, noise=0.05, random_state=0)# 2. 使用谱聚类进行聚类# n_clusters: 要找到的簇数# affinity: 构建邻接矩阵的方式。'rbf'是高斯核函数, 'nearest_neighbors'是k-NN图spectral = SpectralClustering(n_clusters=2,                               affinity='nearest_neighbors', # 使用k-NN构建图                              n_neighbors=20,             # k-NN的k值                              random_state=0)y_spectral = spectral.fit_predict(X)# 4. 可视化聚类结果plt.figure(figsize=(12, 6))plt.scatter(X[:, 0], X[:, 1], c=y_spectral, s=10, cmap='viridis')plt.title(\"Spectral Clustering (Success)\")plt.gca().set_aspect('equal', adjustable='box')plt.show()\n\n\n手写SpectralClustering\n\nimport numpy as np# 假设 kmeans 函数已经定义好# from somewhere import kmeans def spectral(W, k):    \"\"\"    谱聚类算法 (使用标准化的拉普拉斯矩阵)    这个函数实现了谱聚类的核心流程。    输入:        W: 邻接矩阵 (Adjacency Matrix)，一个 N-by-N 的对称矩阵，表示数据点之间的相似度。        k: 目标聚类的簇数。    输出:        idx: 每个数据点最终的簇标签，一个长度为 N 的一维向量。    \"\"\"        # 获取数据点的数量 N    N = W.shape[0]    # --- 步骤1: 计算度矩阵 D (Degree Matrix) ---    # 度矩阵 D 是一个对角矩阵，其对角线上的元素 D[i, i] 是邻接矩阵 W 第 i 行所有元素的和。    # 它代表了图中每个节点的\"连接总强度\"或\"度\"。    D = np.diag(np.sum(W, axis=1))    # --- 步骤2: 计算对称标准化的拉普拉斯矩阵 L_sym (Symmetric Normalized Laplacian) ---    # 这是整个算法最关键的一步。相比非标准化的拉普拉斯矩阵(L = D - W)，    # 标准化的版本对不同大小和密度的簇有更好的适应性，聚类效果更鲁棒。    # 公式为: L_sym = I - D^(-1/2) * W * D^(-1/2)        # 为了计算 D^(-1/2)，我们先计算 D 的平方根的逆。    # 这里加上一个极小的数 1e-10 是为了防止 D 的对角线上有0（孤立点），从而导致除以零的错误，保证数值稳定性。    D_inv_sqrt = np.linalg.inv(np.sqrt(D + 1e-10))        # 根据公式计算 L_sym。`@` 是 Python 中的矩阵乘法运算符。    L_sym = np.identity(N) - D_inv_sqrt @ W @ D_inv_sqrt    # --- 步骤3: 特征分解 (Eigendecomposition) ---    # 我们对 L_sym 进行特征分解，求解其特征值和特征向量。这是\"谱\"分析的核心。    # 拉普拉斯矩阵的谱（特征值）蕴含了图的结构信息。    # np.linalg.eigh 专门用于求解对称/厄米矩阵，性能更高，且保证返回的特征值是实数并已从小到大排序。    eigenvalues, eigenvectors = np.linalg.eigh(L_sym)    # --- 步骤4: 构建新的低维特征空间 U ---    # 根据谱聚类理论，我们选取与 k 个最小特征值相对应的特征向量。    # 由于 eigh 的结果已排序，我们直接取特征向量矩阵的前 k 列即可。    # 这 k 个特征向量构成了一个新的、低维的表示空间，原始数据的复杂结构在这个空间中被简化。    U = eigenvectors[:, :k]    # --- 步骤5: (推荐的最佳实践) 标准化新的特征矩阵 U ---    # 将矩阵 U 的每一行都标准化为单位长度（L2范数为1）。    # 这样做可以消除 K-Means 算法对向量长度的敏感性，使得聚类更多地关注点在超球面上的角度关系，    # 从而在新空间中取得更稳定、更准确的聚类效果。        # 计算每一行（每个数据点在新空间中的向量）的L2范数。    # keepdims=True 确保结果是 (N, 1) 的列向量，以便于下一步的广播除法。    norm = np.linalg.norm(U, axis=1, keepdims=True)        # 执行行标准化。同样加上一个极小的数防止除以零。    U_norm = U / (norm + 1e-10)    # --- 步骤6: 使用 K-Means 在新空间中进行最终聚类 ---    # 谱聚类已经完成了最困难的\"特征转换\"工作。    # 在这个新的特征空间 U_norm 中，数据点已经被变换得更容易被线性分割。    # 因此，我们调用一个简单的 K-Means 算法来完成最后的分类任务。    idx = kmeans(U_norm, k)    # 返回最终的聚类结果    return idx\n\n高斯混合模型 (Gaussian Mixture Model, GMM)","categories":["ML"]},{"title":"分类算法","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/","content":"分类算法的目标是构建一个模型，用于将新的、未见过的数据点分配到预定义的类别中。\n逻辑回归 (Logistic Regression)\n尽管它的名字中带有”回归”二字，但逻辑回归实际上是一种用于分类的监督学习算法，尤其在处理二分类问题时表现出色。\n\n逻辑回归是一种预测分析，它通过分析现有数据（自变量），来预测一个离散的、分类型的结果（因变量）。最常见的应用是二分类问题，例如预测一封邮件是否为垃圾邮件（是/否）、一个用户是否会点击广告（点击/不点击）、一个肿瘤是恶性的还是良性的（恶性/良性）。\n它的核心思想是：将输入的特征（features）进行线性组合，然后通过一个特殊的非线性函数——Sigmoid函数，将结果映射到 (0,1) 的区间内，这个结果可以被解释为”属于某个类别的概率”。\n核心原理逻辑回归的实现主要包含两个关键部分：预测函数和决策边界。\n预测函数：从线性回归到逻辑回归线性回归模型通常表示为：\n\n这里，y 的输出是连续的，可以是任何数值。但对于分类问题，我们需要一个介于0和1之间的概率值。\n为了解决这个问题，逻辑回归引入了 Sigmoid 函数（也称为 Logistic 函数）。\n\n操作：将线性回归的输出  作为 Sigmoid 函数的输入。\n\n目的：Sigmoid 函数能将任何实数输入”压缩”到 (0,1) 的范围内，这个输出值在逻辑回归中被赋予了概率的意义。\n\n\nSigmoid 函数的公式如下：\n\n将  代入，我们就得到了逻辑回归的预测函数（假设函数） ：\n\n这个  的输出值，就代表了给定输入  时，预测结果为正类（Positive Class, 通常记为 1） 的概率。例如， 意味着模型预测该样本有70%的概率属于类别1。\n\n逻辑回归和线性回归的根本区别就是, 逻辑回归在线性回归的基础上，通过一个 Sigmoid 函数的”包装”，巧妙地将一个回归问题转化为了一个分类问题。\n\n决策边界 (Decision Boundary)有了概率之后，我们如何做出最终的分类决策呢？这就需要一个决策边界来建立一个明确的规则，将模型输出的概率值转化为最终的分类结果。\n通常我们设定一个阈值（Threshold），最常用的阈值是 0.5。\n\n如果 ，则预测类别为 1 (正类)。\n\n如果 ，则预测类别为 0 (负类)。\n\n\n观察 Sigmoid 函数  的图像可以发现：\n\n当  时，。\n当  时，。\n\n因此，决策边界实际上是由  这条线决定的，也就是由  决定的。\n\n这个方程定义了一个超平面（在二维空间中是一条直线，三维中是一个平面），它将特征空间一分为二，一边是预测为1的区域，另一边是预测为0的区域。这个超平面就是模型的决策边界。\n\n重要提示：决策边界是模型属性（由参数  决定），而不是数据集的属性。模型训练的过程，本质上就是在寻找最佳的参数  来确定这个决策边界的位置和方向。\n\n如何训练模型：代价函数与梯度下降找到了模型的表达形式，接下来的问题是：如何确定最佳的参数  呢？答案是通过最小化一个代价函数 (Cost Function) 来学习。\n代价函数 (Cost Function)对于逻辑回归，我们不能使用线性回归中的均方误差（MSE）作为代价函数，因为当它与 Sigmoid 函数结合时，会形成一个非凸函数，存在很多局部最优解，不利于优化。\n因此，逻辑回归采用对数损失函数 (Log Loss)，也称为二元交叉熵 (Binary Cross-Entropy)。\n对于单个训练样本 ，其代价定义如下：\n\n这个分段函数可以优雅地合并成一个表达式：\n\n这个代价函数具有良好的数学特性。\n\n当真实标签  时，如果模型预测的概率  越接近1，代价就越接近0；如果预测越接近0，代价就趋于无穷大，从而对模型进行”惩罚”。\n当真实标签  时，逻辑正好相反。\n\n这样的设计确保了代价函数是一个凸函数，只有一个全局最优解。\n对于整个训练集（m个样本），总的代价函数  是所有样本代价的平均值：\n\n优化算法：梯度下降 (Gradient Descent)我们的目标是找到使  最小的参数 。梯度下降是最常用的优化算法之一。\n我们会从一个随机的  值开始，迭代地更新  的值，每次都沿着代价函数梯度的反方向（即下降最快的方向）移动一小步。通过迭代，逐步逼近代价函数的最小值点，从而找到最优的参数 。\n 的更新规则如下：\n\n其中：\n\n 是学习率 (Learning Rate)，控制每一步更新的步长。\n 是代价函数对参数  的偏导数（梯度）。\n\n经过数学推导，逻辑回归代价函数的梯度可以被简化为：\n\n所以，梯度下降的最终更新规则是：\n\n这个过程会一直重复，直到  的值收敛，即代价函数不再显著下降。\n逻辑回归的优劣势优势 (Pros)\n\n模型简单，速度快：实现简单，计算开销小，训练速度快，易于并行化。\n可解释性强：参数  的大小可以直观地反映不同特征对最终结果的影响程度，方便解释。\n输出结果是概率：不仅能给出分类结果，还能得到属于该类的概率，这在很多场景下非常有用（如风险评估）。\n对数据要求低：不需要满足严格的统计假设，如正态分布等。\n\n劣势 (Cons)\n\n容易欠拟合：模型形式相对简单，处理复杂非线性关系的能力有限，可能导致欠拟合。\n对特征工程要求高：需要手动进行特征组合和筛选，对数据中的非线性关系需要进行转换。\n假设特征间线性关系：它假设数据在”对数几率”（log-odds）上是线性的，如果这个假设不成立，模型表现会很差。\n对多重共线性敏感：如果特征之间高度相关，模型的稳定性和解释性会受到影响。\n\nK-近邻 (K-Nearest Neighbors, KNN)KNN 是一种监督学习算法，既可以用于分类任务，也可以用于回归任务。它的核心思想可以用一句非常朴素的话来概括：”近朱者赤，近墨者黑”。一个样本的类别，由它在特征空间中最邻近的 K 个邻居来决定。\n同时, KNN 是一种基于实例的学习 (Instance-based Learning)，也常被称为”懒惰学习“ (Lazy Learning) 算法。\n\n“基于实例”的含义：算法不会从训练数据中学习一个明确的判别函数（像逻辑回归那样得到一个参数化的模型 ）。相反，它只是简单地将整个训练数据集存储起来。\n\n“懒惰学习”的含义：它在训练阶段 (Training Phase) 不做任何计算，没有任何”学习”过程。所有的计算都推迟到预测阶段 (Prediction Phase)，即当一个新数据点需要被预测时，算法才开始工作。\n\n这与逻辑回归、线性回归等”积极学习” (Eager Learning) 算法形成鲜明对比，后者在训练阶段会努力学习出一个模型参数。\n\n\n\n核心工作原理KNN 的工作流程非常直观，可以分解为以下三个核心要素：距离度量、K 值的选择、以及决策规则。\n距离度量 (Distance Metric)为了找到新数据点的”邻居”，我们首先需要一种方法来衡量样本之间的”距离”或”相似度”。\n\n操作：当一个未标记的新数据点出现时，算法会计算它与训练集中每一个数据点之间的距离。\n目的：量化样本在特征空间中的远近关系。距离越小，代表两个样本越相似。\n\n最常用的距离度量是欧几里得距离 (Euclidean Distance)，也就是我们在二维或三维空间中熟悉的直线距离。对于两个样本点  和 ，它们之间的欧几里得距离为：\n\n除了欧氏距离，还有其他距离度量方法，如曼哈顿距离 (Manhattan Distance)、闵可夫斯基距离 (Minkowski Distance) 等，可以根据数据的特性来选择。\n\n重要提示：由于距离计算对数据的尺度非常敏感（例如，一个以”米”为单位的特征会比一个以”厘米”为单位的特征在数值上小很多），因此在使用 KNN 之前，对数据进行归一化 (Normalization) 或标准化 (Standardization) 通常是一个至关重要的预处理步骤。\n\nK 值的选择K 值代表我们要选择新数据点周围邻居的数量。这是一个需要我们手动指定的超参数。\n\n操作：在计算完新数据点与所有训练样本的距离后，我们对这些距离进行排序，并选出距离最近的 K 个样本，作为它的”邻居”。\n\n目的：K 值的选择直接决定了模型的复杂度和预测结果，对模型的性能有重大影响。\n\n较小的 K 值：模型会变得非常复杂，容易受到噪声数据的影响。例如，如果 K=1，新样本的类别将完全由距离它最近的一个点决定，这可能导致过拟合 (Overfitting)。\n\n较大的 K 值：模型会变得相对简单。如果 K 值过大（例如等于训练样本总数），模型可能会忽略数据中局部的、有意义的模式，导致欠拟合 (Underfitting)。\n\n\n选择最佳 K 值通常需要通过交叉验证等方法来评估不同 K 值下的模型性能。\n决策规则 (Decision Rule)找到了 K 个最近的邻居之后，我们如何利用它们来对新数据点进行预测呢？这取决于任务是分类还是回归。\n用于分类任务 (KNN Classification):\n\n决策规则：采用**”少数服从多数”**的投票原则。\n过程：查看这 K 个邻居分别属于哪个类别，然后选择其中出现次数最多的那个类别作为新数据点的预测类别。例如，如果 K=5，其中有 3 个邻居是”A类”，2 个邻居是”B类”，那么新数据点就被预测为”A类”。\n\n用于回归任务 (KNN Regression):\n\n决策规则：采用**”取平均值”**的方法。\n过程：将这 K 个邻居的数值（因变量的值）取平均值（或中位数），将这个平均值作为新数据点的预测值。例如，如果 K=5，这 5 个邻居的房价分别是 100万, 102万, 98万, 105万, 99万，那么新数据点的预测房价就是这五个数的平均值，即 100.8万。\n\nKNN算法的优劣势优势 (Pros)\n\n模型简单，易于理解和实现：算法的直觉性非常强，没有复杂的数学理论。\n无需训练：作为一种”懒惰学习”算法，它不需要耗时的训练过程。\n对数据分布没有假设：作为非参数模型，它不对数据的底层分布做任何假设，因此能适用于各种形状的决策边界。\n可以处理多分类问题：天然支持多分类任务，无需像某些算法一样做特殊处理。\n对异常值不敏感：在投票或取平均值的机制下，少数异常邻居点对最终结果的影响有限。\n\n劣势 (Cons)\n\n计算成本高，预测慢：在预测阶段，需要计算新样本与所有训练样本的距离，当数据集很大时，这会非常耗时。\n对内存需求大：需要存储整个训练数据集，对内存占用较大。\n对 K 值的选择敏感：K 值的选择对结果影响巨大，需要仔细调试。\n对不平衡样本敏感：如果某些类别的样本数量远多于其他类别，投票时会占据优势，导致预测偏向多数类。\n对特征尺度和无关特征敏感：距离计算会受到特征尺度的巨大影响，且高维空间中”距离”的定义可能会变得不那么有意义（维度灾难）。\n\n支持向量机 (Support Vector Machine, SVM)支持向量机 (Support Vector Machine, SVM)是一种经典的有监督学习算法，尤其在处理分类和回归问题上表现出色。它的核心思想非常直观且优雅：在数据点中寻找一个能够将不同类别分得最开、最完美的决策边界。\n核心思想：最大化”间隔” (Margin)想象一下，你有一些黑白两种颜色的豆子散落在桌面上，你需要画一条直线将它们分开。通常，你可能可以画出很多条线都能完成这个任务。但哪一条是最好的呢？\nSVM 的回答是：那条距离两边最近的豆子都最远的线是最好的。换句话说，这条线为两个类别创造了尽可能宽的”缓冲地带”或”街道”。这个”缓冲地带”的宽度，在SVM的术语里被称为间隔 (Margin)。\nSVM 的目标就是找到这个间隔最大的决策边界。这个决策边界在二维空间里是一条直线，在三维空间里是一个平面，在更高维的空间中则被称为超平面 (Hyperplane)。\n\n一个更大的间隔意味着我们对分类结果有更高的置信度。这个决策边界对于新的、未知的数据点具有更强的泛化能力，不容易因为数据的轻微扰动而产生误分类。\n\n关键概念：支持向量 (Support Vectors)在定义这个最大间隔时，你会发现，Margin的边界正好是由距离决策边界最近的那些数据点“支撑”起来的。这些位于间隔边界上的关键数据点，就被称为支持向量 (Support Vectors)。\n支持向量的独特之处在于：\n\n决定性作用：整个SVM模型只由支持向量决定。决策边界的位置完全取决于这些支持向量，而与其他数据点无关。\n高效性：即使训练数据集中有成千上万个点，真正对模型起作用的可能只有一小部分, 即支持向量。这使得SVM在存储和计算上都非常高效。\n\n你可以想象，只要这些”支撑”边界的点不移动，无论你增加或移动多少其他远离边界的点，决策边界都不会发生任何改变。\n核函数 (Kernel Function)\n到目前为止，我们讨论的都是数据点可以用一条直线（或一个平面）完美分开的情况，这被称为线性可分。但如果数据是类似一三象限和二四象限的点，我们便无法用一条直线将两者分开。这就是非线性数据。\n\nSVM 通过一个非常巧妙的”核技巧 (Kernel Trick)”来解决这个问题。\n\n核心思想：如果我们无法在当前维度上分割数据，那么我们可以将数据映射到一个更高的维度空间，在那里它们可能就变得线性可分了。\n\n一个直观的例子：想象一下在一张纸上（二维空间）有一些无法用直线分开的红点和蓝点。现在，你突然把这张纸向上弯曲，变成一个三维的曲面。从上往下看，这些点可能就神奇地可以用一个平面分开了。\n\n\n核函数是SVM中用于将低维数据映射到高维空间的一种数学工具。它允许SVM处理非线性边界的问题，通过将数据点从低维空间映射到高维空间，从而在新的空间中找到一个线性决策边界。\n常见的核函数 (Kernel Functions)：\n\n线性核 (Linear Kernel)：实际上就是不进行映射，用于处理本身就线性可分的数据。\n多项式核 (Polynomial Kernel)：将数据映射到多项式空间。\n高斯径向基函数核 (Radial Basis Function, RBF Kernel)：这是最常用、最强大的核函数之一。它能将数据映射到无限维空间，可以处理非常复杂的非线性边界。\n\n代码实现# 导入必要的库, svc 是 Support Vector Classifier的缩写from sklearn.svm import SVC# 创建SVM分类器svm_classifier = SVC(kernel='linear')# 训练模型svm_classifier.fit(X_train, y_train)# 预测y_pred = svm_classifier.predict(X_test)\n\nSVM 的优缺点优点\n\n在高维空间中非常有效：尤其当特征维度数量大于样本数量时。\n模型高效：由于只依赖于支持向量，模型占用的内存较少。\n泛化能力强：最大化间隔的原则使其不容易过拟合，对未知数据的预测能力强。\n通用性强：通过使用不同的核函数，可以灵活地解决各种线性和非线性问题。\n\n缺点\n\n对大规模训练样本效率不高：当训练样本数量巨大时（例如几十万甚至上百万），其计算复杂度会急剧增加。\n对参数和核函数的选择敏感：SVM的表现很大程度上依赖于核函数的选择以及一些超参数（如正则化参数C）的设定，需要通过交叉验证等方式进行仔细的调优。\n对缺失数据敏感：需要预先对数据进行完整的预处理。\n输出不直接包含概率：SVM的原始输出是类别的硬划分，而不是一个点属于某个类别的概率。虽然有方法可以进行扩展，但不是其原生功能。\n\n决策树 (Decision Tree)决策树是一种监督学习算法，同样可以用于分类和回归任务。它的模型结构非常直观，就像一个倒立的树，或者说是一个流程图。\n它的核心思想是通过一系列的“问题”或“决策”来对数据进行划分，最终导向一个结论。整个模型呈树形结构，包含以下几个关键部分：\n\n根节点 (Root Node)：代表整个数据集，是树的起点。\n内部节点 (Internal Node)：代表一个特征或属性上的判断。每个内部节点都会引出两个或多个分支。\n分支 (Branch)：代表基于内部节点判断的输出结果。叶节点 (Leaf Node)：代表最终的决策结果（在分类任务中是类别，在回归任务中是数值）。\n\n从根节点到任何一个叶节点的路径，都构成了一条决策规则。\n想象一下你决定“今天是否出门打篮球”的过程，这本身就是一个决策树：\n\n根节点：开始决策。\n第一个内部节点（问题）：“今天下雨吗？”\n分支 (是)：如果下雨，导向叶节点 -&gt; “不打球”。\n分支 (否)：如果不下雨，进入下一个内部节点。\n\n\n第二个内部节点（问题）：“有朋友一起吗？”\n分支 (是)：如果有，导向叶节点 -&gt; “去打球”。\n分支 (否)：如果没有，导向叶节点 -&gt; “不打球”。\n\n\n\n这个简单的流程就构成了一个决策树。机器学习中的决策树构建过程，就是让算法自动地、基于数据去学习出这样一个最优的决策流程。\n随机森林 (Random Forest)\n随机森林是决策树的“进化版”。它通过一种巧妙的集成思想，克服了单个决策树容易过拟合的缺点，从而在各种任务中都表现出极高的准确性和稳定性。\n\n随机森林是一种集成学习 (Ensemble Learning) 方法。集成学习的核心思想是“三个臭皮匠，顶个诸葛亮”——即通过构建并结合多个学习器（或模型）来完成学习任务，以获得比单一学习器更好的性能。\n它构建了多棵决策树，并将它们集成为一个“森林”。在进行预测时，森林中的每一棵树都会独立地给出一个预测结果，最后算法会综合所有树的预测来得出最终结论。\n\n对于分类任务：采用投票法，选择得票最多的类别作为最终结果。\n对于回归任务：采用平均法，将所有树的预测值取平均作为最终结果。\n\n这个“森林”不是由一堆相同的树组成的，而是由许多各不相同、具有多样性的决策树构成的。正是这种多样性，使得随机森林具有强大的泛化能力和鲁棒性。\n","categories":["ML"]},{"title":"评估指标","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/","content":"KL散度KL散度（Kullback-Leibler Divergence），也常被称为相对熵（Relative Entropy），是信息论和数理统计中一种重要的度量方式。它用于衡量两个概率分布之间的差异性。\n通俗地讲，KL散度可以告诉我们：当我们用一个近似的概率分布  来模拟一个真实的概率分布  时，会产生多少信息的损失。换句话说，它衡量的是用分布  来代替分布  所付出的“代价”。\n\nKL散度的值越小，表示两个分布越接近；当两个分布完全相同时，KL散度为0。\n\n数学定义与公式KL散度在离散型和连续型随机变量上有不同的数学表达形式，但其核心思想是一致的。\n1. 离散型概率分布对于两个离散的概率分布  和 ，从  到  的KL散度定义为：\n\n其中：\n\n 是随机变量  所有可能取值的集合。\n 是事件  的真实概率。\n 是事件  的近似概率或模型预测概率。\n\n步骤说明：\n\n计算比值 ：对于每一个可能的事件 ，计算其真实概率与近似概率的比值。这个比值反映了近似分布  相对于真实分布  的“偏差程度”。\n取对数：对该比值取对数。如果 ，对数值为正；如果 ，对数值为负。\n加权求和 ：用真实分布  对上述对数值进行加权。这意味着，我们更关心那些在真实世界中频繁发生（即  较大）的事件上，近似分布  表现得如何。如果一个高频事件被  赋予了很低的概率，那么它对总的KL散度贡献就很大，意味着信息损失严重。\n\nKL散度的重要特性\n非负性（Non-negativity）\n\nKL散度总是大于或等于0。\n只有当两个分布完全相同时，即对于所有的  都有 ，KL散度才等于0。这个特性使得它可以被用作衡量“差异”或“距离”的指标。\n\n\n不对称性（Asymmetry）\n\nKL散度一个非常关键的特性是不对称性，也就是说，从  到  的KL散度通常不等于从  到  的KL散度。\n正因为如此，KL散度并不是一个真正意义上的“距离”（因为距离度量通常需要满足对称性，例如欧氏距离中A到B的距离等于B到A的距离）。它是一种有方向的度量。\n\n\n\n\n直观理解不对称性：\n\n：衡量的是用  来近似  的信息损失。它会着重惩罚这样一种情况： 很大，而  很小。也就是说，“真实世界中经常发生，但你的模型却认为它几乎不发生”，这是一种严重的错误，会导致  的值急剧增大。\n：衡量的是用  来近似  的信息损失。它会着重惩罚另一种情况： 很大，而  很小。也就是说，“你的模型认为某事经常发生，但实际上它从不发生”。\n\n\nKL散度的应用KL散度在机器学习和数据科学领域有着广泛的应用，尤其是在处理概率模型时。\n\n变分自编码器（Variational Autoencoders, VAE）\n\n在VAE中，损失函数的一部分就是KL散度。它被用来衡量编码器产生的潜在空间分布（通常是一个高斯分布）与一个标准正态分布（先验分布）之间的差异。通过最小化KL散度，VAE能够学习到一个结构良好、易于采样的潜在空间，从而提升生成新样本的质量。\n\n\n评估生成模型\n\n在训练生成对抗网络（GANs）或其他生成模型时，有时会使用KL散度来评估生成的数据分布与真实数据分布的相似度。\n\n\n强化学习\n\n在一些高级的强化学习算法中（如TRPO、PPO），KL散度被用作一个约束条件，确保策略网络在每次更新时不会与旧策略偏离太远，从而保证训练过程的稳定性。\n\n\n信息检索\n\n在某些信息检索模型中，KL散度可以用来衡量一个文档与用户查询的相关性。将文档和查询都看作是词语的概率分布，KL散度可以度量它们之间的“距离”。\n\n\n\n","categories":["ML"]},{"title":"知识图谱","url":"/2025/07/08/misc/Fintech/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/","content":"知识图谱知识图谱是一种用图（Graph）结构来建模和存储现实世界中实体（Entity）、概念（Concept）及其之间复杂关系的知识库。它的核心目标是将互联网上非结构化的海量信息（如文本、图片）转化为结构化的知识，从而让机器能够像人类一样去理解和运用这些知识。\n这个概念在2012年被谷歌（Google）正式提出并应用于其搜索引擎，极大地优化了搜索结果的质量和用户的体验，使得搜索不再是简单的关键词匹配，而是能够理解问题的意图并直接给出答案。\n简单来说，知识图谱就是一张巨大的“知识之网”，网中的每个节点代表一个实体（比如一个人、一个地方、一部电影），而连接节点的边则代表它们之间的关系（比如“出生于”、“导演是”）。\n核心构成知识图谱的基本组成单位是“三元组（Triple）”，即“实体-关系-实体”或“实体-属性-属性值”的结构。\n\n实体（Entity）：指代现实世界中可识别、可区分的独立事物。在图中，实体表现为节点（Node）。\n\n例如：“爱因斯坦”、“《相对论》”、“德国”都是实体。\n\n\n关系（Relation）：描述不同实体之间存在的某种联系。在图中，关系表现为连接节点的边（Edge）。\n\n例如：“爱因斯坦”与“德国”之间的关系是“出生地”。“爱因斯坦”与“《相对论》”之间的关系是“提出者”。\n\n\n属性（Attribute）：描述单个实体所具有的内在特征。它是一种特殊的关系，其连接的不是另一个实体，而是一个具体的字面值（Literal）。\n\n例如：“爱因斯坦”的“出生日期”属性是“1879年3月14日”。\n属性也可以基于关系, 例如在 Neo4j 这样的图数据库中允许直接在边（Edge）上附加键值对（Key-Value）属性。这种方式称为属性图模型 (Property Graph)\n\n\n\n知识图谱与传统数据库的区别\n\n\n特性\n传统关系型数据库\n知识图谱（通常使用图数据库）\n\n\n\n数据模型\n基于预先定义的、严格的表格（Table）结构\n基于灵活的、无固定模式的图（Graph）结构\n\n\n核心焦点\n数据的存储和一致性\n知识的关联、推理和发现\n\n\n查询方式\n通过SQL进行复杂的表连接（JOIN）操作，当关系复杂时性能急剧下降\n直接通过图的遍历来查询关系，查询多层深度关系时性能极高\n\n\n灵活性\n结构死板，修改和扩展（Schema Change）成本高\n结构灵活，可以随时轻松地添加新的实体、属性和关系\n\n\n应用场景\n适合处理结构化、事务性强的数据，如ERP、财务报表\n适合处理高度互联、关系复杂的数据，如社交网络、金融风控\n\n\nNeo4j 图数据库Neo4j 是一个用 Java 开发的、开源的、高性能的原生图数据库管理系统（Graph Database Management System, GDBMS）。它秉承知识图谱的思想, 将数据以“图”的形式进行存储，而不是传统的表格（如MySQL）或键值对（如Redis）形式。\n\n原生图数据库： Neo4j 从底层设计就是为了高效地存储和处理图结构。它的存储引擎直接面向节点和关系，使得在查询深度关联数据（例如“朋友的朋友的朋友”）时，性能远超传统数据库。\n\nACID兼容：Neo4j 是一个完全事务性的数据库，支持ACID（原子性、一致性、隔离性、持久性）特性，保证了数据的可靠性和业务的一致性，可以用于企业级的生产环境。\n\n\nNeo4j 特别擅长处理数据之间存在复杂、多层、多变关系的应用场景。\n\n社交网络：分析好友关系、社群发现。\n金融风控：识别欺诈团伙、反洗钱、分析关联交易。\n推荐引擎：提供实时、精准、可解释的个性化推荐。\n知识图谱：构建和查询各领域（如医疗、电商、企业管理）的知识网络。\n网络与IT运维：分析网络拓扑、依赖关系和故障影响。\n\nCypher：为图而生的查询语言Cypher 是类SQL的用于 Neo4j 的声明式图查询语言，其设计哲学是让查询语句本身看起来就像一个图。它使用一种被称为“ASCII-Art”的语法，非常直观。例如\n// 查找所有在《黑客帝国》中出演的演员MATCH (actor:Person)-[:ACTED_IN]-&gt;(movie:Movie {title: '黑客帝国'})RETURN actor.name, movie.title\n\n\n() 用圆括号表示一个节点。\n[] 用方括号表示一个关系。\n–&gt; 或 &lt;– 表示关系的方向。\n: 后面跟着的是标签或关系类型。\n{} 用花括号表示属性。\nMATCH 是匹配图模式的关键字。\nRETURN 是指定返回结果的关键字。\n\npy2neo：连接 Python 与 Neo4j 的桥梁py2neo 是一个功能强大且维护活跃的 Python 客户端库（或称为“驱动”），专门用于与 Neo4j 数据库进行交互。它为 Python 开发者提供了一套简洁、优雅的API，使得在 Python 程序中操作 Neo4j 变得非常方便。\n\n数据库连接管理：轻松建立、管理与 Neo4j 数据库的连接。\n执行 Cypher 查询：可以直接在 Python 中执行原生的 Cypher 语句，并方便地处理返回的结果。\n图数据操作：提供了丰富的 API 来以编程方式创建、更新、删除节点和关系。\n对象图映射（Object-Graph Mapping, OGM）：类似于传统数据库的 ORM（Object-Relational Mapping）。它允许你将图中的节点定义为 Python 的类（Class），将节点属性映射为类的属性，从而可以用更面向对象的方式来操作图数据，而不仅仅是写 Cypher 字符串。\n与 Pandas, Jupyter 等数据科学生态集成：可以方便地将查询结果转换为 Pandas DataFrame，非常适合进行数据分析和可视化。\n\n示例如下:\nfrom py2neo import Graph, Node, Relationship# 1. 连接到 Neo4j 数据库# 默认情况下，Neo4j 启动在 bolt://localhost:7687，用户名为 neo4j# 请将 \"your_password\" 替换为你的 Neo4j 密码try:    graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"your_password\"))    print(\"成功连接到 Neo4j 数据库！\")except Exception as e:    print(f\"连接失败: {e}\")    exit()# 2. 清理数据库（可选，用于演示）print(\"清理数据库...\")graph.delete_all()# 3. 创建节点 (Node)# 创建两个 Person 节点alice = Node(\"Person\", name=\"Alice\", age=30)bob = Node(\"Person\", name=\"Bob\", age=32)# 创建一个 Company 节点google = Node(\"Company\", name=\"Google\")# 4. 创建关系 (Relationship)# 关系可以有自己的属性alice_knows_bob = Relationship(alice, \"KNOWS\", bob, since=2015)bob_works_for_google = Relationship(bob, \"WORKS_FOR\", google, position=\"Engineer\")# 5. 将创建的节点和关系写入数据库# graph.create() 是原子操作，会一次性创建所有内容print(\"正在创建节点和关系...\")graph.create(alice_knows_bob)graph.create(bob_works_for_google)print(\"创建完成！\")# 6. 执行 Cypher 查询print(\"\\n--- 开始查询 ---\")# 查询1: 找到所有年龄大于 31 岁的人query1 = \"MATCH (p:Person) WHERE p.age &gt; 31 RETURN p.name, p.age\"print(f\"执行查询: {query1}\")results1 = graph.run(query1)for record in results1:    print(f\"  找到的人: {record['p.name']}, 年龄: {record['p.age']}\")# 查询2: 找到所有为 Google 工作的人query2 = \"MATCH (p:Person)-[:WORKS_FOR]-&gt;(c:Company {name: 'Google'}) RETURN p.name, c.name\"print(f\"\\n执行查询: {query2}\")results2 = graph.run(query2)for record in results2:    print(f\"  {record['p.name']} 在 {record['c.name']} 工作。\")\n\n\n\n\n\n\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"感知机","url":"/2025/07/01/ai/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CNN/%E6%84%9F%E7%9F%A5%E6%9C%BA/","content":"感知机 (Perceptron) 是二分类的线性分类模型，属于判别模型。\n感知机模型感知机模型由以下几个部分组成：\n","categories":["NN"]},{"title":"隐私保护","url":"/2025/07/07/misc/Fintech/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/","content":"常见的隐私保护技术差分隐私(Differential Privacy, DP)差分隐私是一种保护个人数据隐私的技术，它通过在数据中添加噪声来保护个人隐私。差分隐私技术可以有效地保护个人数据隐私，同时保证数据分析的准确性。\n其核心思想可以用一个非常直观的方式来理解：在一个数据集中，无论是否包含某个特定个体的数据，对该数据集进行查询分析的结果都应该是极其相似的。\n换句话说，如果一个攻击者，哪怕他掌握了除你之外所有人的信息，也无法通过查询结果来判断你的个人信息是否存在于这个数据集中。通过在这种“无法区分”的模糊性中，差分隐私为每个人的数据提供了坚实的保护。\n它通过向查询结果中注入经过精确计算的随机噪声来实现这一目标。这种噪声足够大，可以掩盖任何单个个体对结果的贡献；但又足够小，使得从整体数据中得出的统计结论（如平均值、总数等）仍然保持其可用性。\nϵ-差分隐私 (ϵ-Differential Privacy)ϵ-差分隐私是差分隐私的一种最基础的形式，它通过向查询结果中注入经过精确计算的随机噪声来实现这一目标, 实现了将这种隐私保护程度进行精确的数学度量, 即:\n一个随机算法（或机制）M 被认为是满足 -差分隐私的，如果对于任意两个仅相差一个个体记录的“邻近”数据集  和 ，以及任意可能的输出结果子集 ，下面的不等式恒成立：\n\n\n：表示事件发生的概率。\n：表示在数据集  上应用随机算法  后的输出结果。\n：两个邻近数据集。例如， 包含了你的信息，而  中没有，其他所有人的信息都完全相同。\n (Epsilon)：这是一个核心参数，被称为“隐私预算” (Privacy Budget)。\n\n 是一个非负实数，它精确地控制着隐私保护的强度。\n\n更小的  意味着更强的隐私保护：当  趋近于 0 时， 趋近于 1。这意味着算法在包含或不包含你个人信息的数据集上，产生相同结果的概率几乎完全一样。攻击者几乎不可能分辨出你的数据是否存在。\n更大的  意味着更高的数据可用性：随着  的增大，隐私保护程度减弱。算法允许在两个邻近数据集上的输出结果有更大的差异，这意味着添加的噪声更少，查询结果更接近“真实值”，数据的统计可用性更高。\n\n联邦学习联邦学习是一种分布式机器学习技术，其核心思想是：在不将用户的本地数据上传到中央服务器的情况下，通过在多个独立的设备（如手机、电脑或物联网设备）上进行模型训练，共同构建一个全局的机器学习模型。\n简单来说，联邦学习实现了“数据不动，模型动”的理念。传统的机器学习需要将所有数据集中到一个服务器上进行训练，这引发了严重的数据隐私和安全问题。联邦学习通过将模型训练的过程分发到数据所在的本地设备，从而有效保护了用户数据的隐私。\n联邦学习的工作流程联邦学习的整个过程是一个迭代循环，通常包含以下几个关键步骤：\n第一步：模型初始化与分发\n\n中央服务器创建一个初始的机器学习模型（可以是一个基础模型，或是在公开数据集上预训练过的模型），并将其分发给所有参与训练的客户端设备（例如用户的手机）。\n\n此步骤为所有参与方提供了一个统一的训练起点，确保大家在同一个“起跑线”上开始优化模型。\n\n\n第二步：本地模型训练\n\n每个客户端设备使用自己的本地数据对接收到的模型进行训练。例如，手机上的输入法会使用用户本地的打字记录来训练语言预测模型。\n\n这是联邦学习保护隐私的关键。所有敏感的原始数据都保留在用户本地，从不离开设备。训练过程利用了这些数据来优化模型，使其适应特定用户的数据模式。\n\n\n第三步：模型更新的上传\n\n在本地训练完成后，每个客户端设备并不上传原始数据，而是只将模型的更新信息（例如模型的权重梯度或更新后的模型参数）发送回中央服务器。\n\n这些“更新信息”可以被看作是模型在本地学到的“知识”或“经验总结”，它们本身不包含具体的原始数据，从而在分享知识的同时保护了隐私。\n\n\n第四步：安全聚合 (Secure Aggregation)\n\n中央服务器收集来自所有（或部分）客户端的模型更新。然后，它使用一种聚合算法（最著名的是联邦平均算法 FedAvg）将这些更新整合起来，从而优化全局模型。\n\n联邦平均算法的基本思想是：将所有客户端上传的模型参数进行加权平均，以得到一个新的、性能更优的全局模型。\n\n\n聚合步骤的目的是汇集所有客户端的“智慧”。通过综合从不同数据集中学到的知识，全局模型变得比任何单一客户端的模型都更加稳健和泛化。\n\n\n第五步：全局模型的分发与迭代\n\n中央服务器将经过聚合优化的新版全局模型再次分发给所有客户端，以替代它们原有的旧模型。\n\n客户端获取到更新后的全局模型后，会进入下一轮的本地训练。整个过程（步骤2至步骤5）会重复进行多轮，直到全局模型的性能达到预设的目标或收敛稳定。通过这种迭代，模型性能得以持续提升。\n\n\n联邦学习的挑战系统异构性 (System Heterogeneity)：不同客户端设备的计算能力、存储空间和网络连接状况差异巨大，这给协同训练带来了困难。\n数据异构性 (Statistical Heterogeneity)：不同用户的数据分布通常是非独立同分布 (Non-IID) 的，这可能会导致模型训练不稳定或收敛缓慢。\n通信成本：虽然比上传原始数据少，但频繁的模型更新对于大规模设备网络仍然是一个不小的负担。\n安全风险：联邦学习并非绝对安全，它仍然可能面临模型逆向攻击（从模型更新中推断部分原始数据）等高级安全威胁，需要额外的隐私增强技术（如差分隐私、同态加密）来加固。\n同态加密同态加密是一种加密技术，它允许在加密的数据上进行计算，而无需解密数据。同态加密技术可以有效地保护个人数据隐私，同时保证数据分析的准确性。\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"第一章：基础概念","url":"/2025/08/27/system/computer-architecture/chapter1/","content":"第一章：基础概念这里是计算机体系结构基础概念的内容。 \n"},{"title":"GDB介绍及应用","url":"/2025/06/28/tools/gdb/gdb/","content":"","categories":["tools"],"tags":["tools"]},{"title":"智能投顾","url":"/2025/07/01/misc/Fintech/%E6%99%BA%E8%83%BD%E6%8A%95%E9%A1%BE/","content":"等权重投资组合（Equal Weight Portfolio, EW）等权重投资组合是一种简单的投资策略，它将资金平均分配给所有可用的资产。这意味着每个资产在投资组合中的权重是相同的。其根本原则是 “民主化”，即投资组合中的每一只股票或资产都拥有相同的”投票权”或重要性，无论这家公司的规模有多大（市值高低）、股价是高是低。\n\n    运作方式：一个简单的例子 \n    \n      假设你有 100,000元 资金，想要投资于一个由 4只股票（股票A、股票B、股票C、股票D）组成的投资组合。你的操作是将总投资比例（100%）除以资产的数量（4）, 最终每只股票的权重 = 100%/4=25%。接着将总资金乘以每项资产的权重, 最终投资到每只股票的金额 = 100,000元×25%=25,000元。\n随着时间的推移，由于股价波动，你的投资组合会自然偏离最初的等权重状态。假设股票A大涨，其市值在组合中占比可能上升到30%；而股票D下跌，其占比可能降至20%。为了维持等权重策略，您需要定期进行 “再平衡”。这意味着您需要：\n\n卖出一部分表现优异的资产（卖出一部分股票A）。\n买入一部分表现不佳的资产（增持一部分股票D）。\n\n通过这种操作，使每项资产的权重重新回到最初设定的25%。这个过程隐含了一种 “高卖低买” 的逆向投资逻辑。\n \n\n    \n  \n\n马科维茨投资组合策略 (Markowitz Portfolio Strategy, 也称作均值-方差模型 Mean-Variance, MV)这是现代投资组合理论的基石，是一种经典的静态优化策略。\n马科维茨策略的核心目标是在风险和收益之间找到最佳平衡。它不是在每个交易日都进行调整，而是基于对未来一段时间市场（如预期收益率和协方差）的预测，一次性计算出一个”最优”的资产配置比例。其优化目标通常是：\n\n在给定可接受的风险水平下，最大化预期收益。\n\n或在给定期望的收益水平下，最小化投资组合的风险（通常用方差来衡量）。\n\n\nMVO的数学目标函数MVO (均值-方差优化) 是指将MV理论付诸实践的数学优化过程. 这是一个计算过程或应用，旨在从有效前沿上找到一个具体的、最符合投资者目标的投资组合。\n核心步骤:\n\n输入: 提供具体的参数估计值，包括对未来资产收益的预期（均值）、对资产风险的预测（方差）以及资产间的协方差矩阵。\n\n设定目标: 定义一个明确的优化目标，例如：\n\n在满足最低预期收益率 R 的前提下，最小化投资组合的方差。\n\n在可接受的最大风险 V 内，最大化投资组合的预期收益。\n\n找到能最大化夏普比率 (Sharpe Ratio) 的投资组合（也称为切点组合）。\n\n\n\n\n求解: 使用数学规划求解器（如二次规划求解器）来计算出能达成该目标的精确投资权重。\n有效前沿（Efficient Frontier）指数梯度 (Exponential Gradient, EG)这是一种经典的在线投资组合（Online Portfolio） 算法，与静态的马科维茨模型有本质区别。它的假设是近期表现好的资产，在下一个交易日可能依然表现良好。\nEG 算法不需要对未来进行预测。它是一种自适应策略，在每个交易周期结束时，根据刚刚过去的这个周期里各个资产的真实表现来动态调整投资权重。其基本逻辑是：\n\n奖励赢家：对于上一期表现好的资产，增加其权重。\n\n惩罚输家：对于上一期表现差的资产，减少其权重。\n\n\n这个调整过程是通过乘法更新 (Multiplicative Updates)  来实现的，因此算法名称中带有 “Exponentiated”（指数化）。\n指数梯度算法步骤EG算法的详细步骤如下：\n\n初始化 (Initialization)\n\n在第1天开始时，我们没有任何信息，所以通常采用等权重投资组合。\n例如，如果有  只股票，每只股票的初始权重都是 。\n\n\n观察上一期收益 (Observe Last Period’s Return)\n\n在第  天收盘后，计算当天（即从  天收盘到  天收盘）每只股票的收益情况。\n用一个价格相对向量 $\\mathbf{y}t表示，其中每个元素y{t,i}是第i$ 只股票的当日价格变化率（例如，1.05 代表上涨 5%，0.98 代表下跌 2%）。\n\n\n更新权重 (Update the Weights)\n\n这是算法的核心。根据上一期的权重  和刚刚观察到的收益 ，计算下一期的未归一化新权重 。\n\n对于组合中的第  只股票，其新权重的计算公式为：\n$$\\hat{w}{t+1,i} = w{t,i} \\times \\exp(\\eta \\cdot y_{t,i})$$\n\n其中:\n\n：第  只股票在第  天的权重。\n：第  只股票在第  天的收益表现。\n：自然指数函数，实现”指数级”奖励。\n (eta)：学习率 (Learning Rate)，控制算法的”反应速度”。\n高 ：算法对近期收益反应剧烈，大幅增加赢家权重。\n低 ：算法反应温和，权重调整幅度较小。\n\n\n\n\n\n\n归一化 (Normalization)\n\n第3步计算出的权重相加通常不等于1。为了使其成为一个有效的投资组合，需要进行归一化。\n\n计算所有未归一化权重的总和：\n\n\n将每个未归一化权重除以总和，得到最终的、下一期的投资组合权重：\n\n\n\n\n\n原论文定理指数梯度（EG）算法遗憾界（Regret Bound）完整推导\n定理内容：假设存在一个固定的投资组合 ，以及一个价格相对向量序列 。对于所有的 ，都有  且 。EG() 算法的累计对数财富满足：\n\n证明过程：\n\n定义势函数变化量 ：\n令势函数为相对熵 ，其单步变化为根据相对熵定义 ，展开上式：\n\n代入 EG 算法更新规则：\nEG 算法的更新规则为取对数并整理得：代入  的表达式中：\n\n为  寻找上界：\n利用凸性不等式和对数不等式，可以得到\n\n推导  的最终上界：\n\n利用不等式 （令 ）：\n\n累加并得到最终结论：\n对  从  到  求和：由于  且 ，上式可放缩为移项整理，将  单独置于一边，并同除以 ，得证：\n\n\n在线牛顿步 (Online Newton Step, ONS)这同样是一种在线投资组合算法，可以看作是 EG 算法的一个更复杂、更强大的进阶版本。\n如果说 EG 算法只考虑了资产过去的收益（一阶信息，类似于梯度），那么 ONS 算法则试图利用更多的信息来做出更优的决策。它借鉴了优化理论中的牛顿法 (Newton Method)  的思想，不仅考虑了”哪个方向是好的”（一阶信息），还试图预估”往这个方向走多远是合适的”（二阶信息）。这使得 ONS 能够更积极地调整其投资组合，期望能更快地适应市场变化。\n\n梯度下降 (EG的思路): 只沿着当前最陡峭的方向（近期回报最高）走一小步。牛顿法 (ONS的思路): 不仅看方向，还通过分析地形的”曲率”（回报的协方差），来计算出一个更直接、通往最优点的”快捷方式”，从而能更快、更准地调整方向。\n\n在线牛顿步算法步骤ONS 算法的详细步骤如下：\n\n初始化 (Initialization)\n\n和 EG 一样，从一个等权重的投资组合开始，例如：\n\n\n观察上一期收益 (Observe Last Period’s Return)\n\n在第  天收盘后，观察并记录当天的收益向量 。\n\n\n更新累计信息 (Update Accumulated Information)\n\n这是 ONS 与 EG 最大的不同。ONS 会维护两个非常重要的累计变量：\n累计梯度向量 ：所有过去收益向量的总和。\n$$\\mathbf{b}t = \\mathbf{b}{t-1} + \\mathbf{y}_t$$\n\n累计二阶信息矩阵 ：一个  的矩阵，近似于所有过去收益的协方差矩阵。\n\n\n其中  是  的转置。\n\n\n\n\n\n\n计算理想组合方向 (Calculate Ideal Portfolio Direction)\n\nONS 使用累计的信息来计算一个理想的投资组合方向。这一步的核心是矩阵求逆，这也是”牛顿步”的体现：\n\n\n这里的 （矩阵  的逆）利用历史波动性和相关性信息，对简单的累计收益  进行了”扭曲”和”缩放”，从而给出一个更优的更新方向。\n\n\n\n投影与归一化 (Projection and Normalization)\n\n第4步计算出的  只是一个理想的方向，通常不满足投资组合的约束（权重加总为1，且权重为正）。\n需要一个额外的、复杂的投影步骤，将这个理想向量”投影”到有效的投资组合空间上，得到最终的权重 。\n\n\n\n优缺点优点：\n\n适应性更强：利用资产间的相关性信息，能比 EG 更快地适应市场变化。\n性能更优：在理论上和很多实际测试中，ONS 的长期累积回报通常高于 EG。\n理论基础好：拥有更强的理论性能保证（较低的”后悔值”）。\n\n缺点：\n\n计算成本极高：核心步骤涉及到  矩阵的求逆，其计算复杂度约为 。当资产数量  很大时（例如上百只股票），这几乎是不可行的。\n数值不稳定性：矩阵  可能因为数据问题变得不可逆或病态，导致计算失败或结果不稳定。实际应用中需要加入”正则化”等技巧来缓解此问题。\n\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"第二章：指令系统","url":"/2025/08/27/system/computer-architecture/chapter2/","content":"第二章：指令系统这里是计算机体系结构指令系统的内容。 \n"},{"title":"Linux入门","url":"/2025/06/29/system/linux/linux/","content":"Linux 目录结构与 Windows 使用多个盘符（C:、D:）不同，Linux 采用单一的树状目录结构。整个文件系统从一个根目录 / 开始，所有其他文件和目录都挂载在这个根目录下。这个结构遵循文件系统层次化标准 (FHS)。\n\n\n\n目录\n名称\n功能说明\n\n\n\n/\nRoot\n根目录，整个文件系统的起点，所有目录的父目录。\n\n\n/bin\nBinaries\n存放所有用户都能使用的基本命令（二进制文件），如 ls, cp, cat。\n\n\n/sbin\nSystem Binaries\n存放只有系统管理员（root用户）才能使用的系统管理命令，如 reboot, fdisk。\n\n\n/etc\nEtcetera\n存放系统和各种程序的配置文件。几乎所有服务的配置都在这里。\n\n\n/home\nHome\n用户主目录。每个普通用户在这里都有一个自己的文件夹，如 /home/ziyipei。\n\n\n/root\nRoot\n系统管理员（root用户）的主目录。\n\n\n/dev\nDevices\n存放设备文件。在 Linux 中，所有硬件设备（如硬盘、键盘）都以文件的形式存在于此。\n\n\n/var\nVariable\n存放经常变化的文件，如日志文件 (/var/log)、缓存文件 (/var/cache)。\n\n\n/tmp\nTemporary\n存放临时文件，系统重启后这里的文件通常会被清空。\n\n\n/usr\nUnix System Resources\n存放用户安装的应用程序、库文件和文档。这是系统中最大的目录之一。\n\n\n/boot\nBoot\n存放启动 Linux 系统所需的文件，包括 Linux 内核本身和引导加载程序 (GRUB)。\n\n\n/lib\nLibraries\n存放系统和程序运行所必需的共享库文件。\n\n\n/opt\nOptional\n用于存放可选的第三方软件包，比如手动安装的商业软件（如 Google Chrome）。\n\n\n/mnt, /media\nMount\n用于临时挂载外部设备，如 U 盘、移动硬盘、光驱等。\n\n\n常见命令汇总Linux 的强大之处在于其命令行界面 (CLI)。命令的基本格式为：command [options] [arguments]。\n\n\n\n命令\n功能说明\n示例\n\n\n\nls\n列出目录内容\nls -l（长格式显示），ls -a（显示隐藏文件）\n\n\ncd\n切换目录\ncd /home/ziyipei，cd ..（返回上一级）\n\n\npwd\n显示当前工作目录的绝对路径\npwd\n\n\nmkdir\n创建新目录\nmkdir documents\n\n\nrm\n删除文件或目录\nrm file.txt，rm -r directory（递归删除目录）\n\n\ncp\n复制文件或目录\ncp source.txt destination.txt\n\n\nmv\n移动或重命名文件/目录\nmv old_name.txt new_name.txt\n\n\ntouch\n创建空文件或更新文件时间戳\ntouch new_file.txt\n\n\ncat\n查看文件全部内容\ncat /etc/hosts\n\n\nless, more\n分页查看文件内容\nless /var/log/syslog\n\n\nhead, tail\n查看文件开头/结尾部分\ntail -n 20 file.txt（查看最后20行）\n\n\ngrep\n在文件中搜索指定文本\ngrep \"error\" /var/log/syslog\n\n\nsudo\n以管理员权限执行命令\nsudo apt update\n\n\nhistory\n查看历史命令及执行指定历史命令\nhistory，!序号（执行历史指令的指定序号的一条）\n\n\n常用终端快捷键\n\n\n快捷键\n功能说明\n\n\n\nTab\n自动补全命令、文件名或目录名（最重要、最常用）。\n\n\nCtrl + C\n强制中断并终止当前正在运行的程序。\n\n\nCtrl + L\n清空屏幕，效果等同于 clear 命令。\n\n\nCtrl + D\n退出当前的 Shell 会话，或表示输入结束 (EOF)。\n\n\nCtrl + A\n将光标移动到命令行的开头。\n\n\nCtrl + E\n将光标移动到命令行的结尾。\n\n\nCtrl + R\n反向搜索历史命令。\n\n\n上/下方向键\n浏览之前输入过的历史命令。\n\n\nCtrl + Z\n将当前前台运行的进程暂停并放到后台。\n\n\nCtrl + U\n清除从光标位置到行首的所有字符。\n\n\nCtrl + K\n清除从光标位置到行尾的所有字符。\n\n\nLinux内核Linux 内核是操作系统的核心，它是一个宏内核（Monolithic Kernel）架构的实现。其根本职责是作为硬件资源的唯一仲裁者和软件服务的提供者，为上层用户空间应用程序提供一个统一、抽象和安全的执行环境。\n内核的所有功能可以被逻辑地划分为如下几个相互协作的核心子系统。\n进程管理 (Process Management)进程管理子系统的核心目标是高效且公平地在多个并发任务之间共享 CPU 资源。\n\n核心抽象与数据结构\n\n进程 (Process)：不仅仅是一个“运行中的程序”，而是一个执行上下文的完整体现。在内核中，每个进程由一个 task_struct 结构体描述，它包含了进程状态、调度信息、内存映射、打开的文件描述符、凭证等所有必要信息。\n\n线程 (Thread)：是 CPU 调度的基本单位。Linux 内核实际上没有严格区分进程和线程，它们都由 task_struct 表示。通过 clone() 系统调用创建线程时，可以使其与父进程共享地址空间、文件描述符等资源，因此线程也被称为“轻量级进程”。\n\n\n\n进程调度器 (Process Scheduler)调度器是决定下一个在 CPU 上运行哪个任务的逻辑核心。主要的策略有下面三种:\n\nSCHED_OTHER (或 SCHED_NORMAL): 这是为普通分时进程设计的默认策略。在现代 Linux 内核中，它由完全公平调度器 (Completely Fair Scheduler, CFS) 实现。\n\nCFS 核心思想：它摒弃了传统的时间片（timeslice）概念，致力于为每个任务提供“理想的、无限精确的多任务 CPU”。它使用一个红黑树 (Red-Black Tree) 来组织所有可运行的任务，每次总是选择虚拟运行时间（vruntime）最小的任务来执行，从而达到近乎完美的公平性。\n\n\nSCHED_FIFO (First-In, First-Out)：这是一种实时（Real-time）调度策略。它没有时间片。一旦一个 FIFO 任务获得 CPU，它会一直运行，直到它主动阻塞（如等待 I/O）、主动调用 sched_yield() 放弃 CPU，或者被一个更高优先级的实时任务抢占。\n\nSCHED_RR (Round-Robin)：这是另一种实时调度策略。它与 FIFO 类似，但增加了时间片的概念。当一个 RR 任务的时间片用完后，如果同优先级队列中还有其他任务，它将被移动到队列末尾，让其他任务有机会运行。\n\n\n\n\n内存管理 (Memory Management)内存管理子系统的目标是高效、安全地管理系统的物理内存（RAM），并为每个进程提供独立的虚拟地址空间。其核心机制与组件如下：\n\n虚拟内存 (Virtual Memory)：这是现代操作系统的基石。内核为每个进程提供一个巨大、私有且连续的虚拟地址空间（例如，在 64 位系统上是 256TB）。这带来了几个好处：\n\n进程隔离：一个进程的内存访问不会干扰到其他进程或内核。\n\n简化编程：程序员无需关心物理内存的碎片化和具体位置。\n\n高效利用物理内存：通过按需分页 (Demand Paging)，只有在进程实际访问某块内存时，内核才会将其从磁盘加载到物理内存中。\n\n\n\n内存管理单元 (MMU)：这是一个硬件组件，负责将进程访问的虚拟地址实时地翻译成物理地址。内核的主要工作就是设置和管理 MMU 使用的页表 (Page Tables)。\n\n物理内存分配器：\n\n伙伴系统 (Buddy System)：这是内核管理物理页帧（Page Frame）的核心算法。它将所有空闲的物理内存页组织成 2 的幂次方大小的块（1, 2, 4, 8, … 页），能够高效地分配和回收连续的物理内存块，但容易产生内部碎片。\n\nSlab 分配器 (Slab Allocator)：它构建在伙伴系统之上，用于解决小对象的内存分配问题。Slab 维护着常用内核对象（如 inode, dentry, task_struct）的缓存池，避免了反复初始化和销毁对象的开销，并大大减少了内存碎片。\n\n\n\n\n虚拟文件系统 (Virtual File System, VFS)VFS 是一个至关重要的抽象层，其目标是为用户空间程序提供一个统一、标准的文件操作接口，屏蔽底层具体文件系统的实现差异。\nVFS 定义了一个通用文件模型，主要由四个核心对象组成：\n\n超级块 (Superblock)：代表一个已挂载的文件系统实例，存储该文件系统的元信息（如文件系统类型、块大小等）。\n\n索引节点 (Inode)：代表一个具体的文件或目录。它包含了文件的所有元数据，如权限、所有者、大小、时间戳以及指向数据块的指针，但不包含文件名。\n\n目录项 (Dentry)：代表一个目录条目，它将一个文件名与一个 Inode 关联起来，形成文件路径。Dentry 缓存（dcache）极大地加速了路径查找过程。\n\n文件对象 (File Object)：代表一个由进程打开的文件。它存储了文件指针（读写位置）、访问模式等与特定进程相关的信息。\n\n\n工作机制：当一个应用程序执行 open(“/path/to/file”) 系统调用时，VFS 会利用 dentry 缓存解析路径，找到每一级目录和最终文件的 inode，然后创建一个文件对象并返回一个文件描述符给应用程序。所有后续的 read(), write() 等操作都会通过这个文件对象，由 VFS 路由到具体文件系统（如 ext4, XFS, NFS）提供的实现函数上。\n网络协议栈 (Networking Stack)网络协议栈的目标是实现标准化的网络协议，使得 Linux 系统能够与世界各地的其他计算机进行通信。其核心架构与数据结构为：\n\nBSD 套接字接口 (BSD Socket API)：为应用程序提供了一套标准的网络编程接口（如 socket(), bind(), connect() 等），使其可以忽略底层网络实现的复杂性。\n\n分层架构：Linux 网络栈在逻辑上严格分层，与 TCP/IP 模型类似，主要包括：\n\n系统调用接口层：将用户空间的网络操作转换为内核操作。\n\n协议无关层：如 Socket 层。\n\n传输层：实现 TCP 和 UDP 协议。\n\n网络层：实现 IP 协议，负责路由和数据包转发。\n\n链路层/设备驱动层：与物理网络硬件（如网卡）交互。\n\n\n\n套接字缓冲区 (Socket Buffer, sk_buff)：这是网络栈中最核心的数据结构。一个 sk_buff 代表一个在网络栈中流动的数据包。当数据包从上层向下层传递时，各层协议会将自己的头部（Header）添加到 sk_buff 中；反之，当数据包从下层向上层传递时，各层会剥离自己的头部并进行处理。\n\n\n进程间通信 (Inter-Process Communication, IPC)由于进程之间地址空间是隔离的，IPC 子系统提供了多种机制，允许进程之间进行数据交换和同步。\n\n管道 (Pipes) 和命名管道 (FIFO)：提供半双工的字节流通信，是父子进程或有亲缘关系进程间通信的常用方式。\n\n信号 (Signals)：一种异步通知机制，用于向进程发送一个事件发生的信号（如 SIGKILL, SIGTERM）。\n\nSystem V IPC：一组传统的 IPC 机制，包括：\n\n消息队列 (Message Queues)：允许进程以消息的形式进行通信，克服了信号传递信息量少的缺点。\n\n信号量 (Semaphores)：一个计数器，用于控制多个进程对共享资源的访问，是经典的同步工具。\n\n共享内存 (Shared Memory)：允许两个或多个进程共享同一块物理内存。这是最快的 IPC 方式，因为它避免了内核的数据拷贝。\n\n\n\nPOSIX IPC：对 System V IPC 的改进和标准化。\n\n套接字 (Sockets)：特别是Unix 域套接字 (Unix Domain Sockets)，它在同一台主机上的进程间通信效率很高，并提供了与网络套接字一致的 API。\n\n\n","categories":["system"],"tags":["system"]},{"title":"风险控制","url":"/2025/07/11/misc/Fintech/%E9%A3%8E%E9%99%A9%E6%8E%A7%E5%88%B6/","content":"","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"用户","url":"/2025/08/12/system/linux/%E7%94%A8%E6%88%B7/","content":"Linux 用户账户基础在 Linux 和类 Unix 系统中，大致有三类用户角色: 超级用户 (root), 普通用户 (Regular User)和系统用户 (System User).\n\n超级用户 (root) : UID 为 0, 拥有系统的最高、无限制的权限。可以执行任何操作，包括修改系统文件、管理所有用户和进程。\n普通用户 (Regular User)：UID通常从 1000 开始, 权限受限, 默认只能在自己的家目录 (/home/username) 内自由读写文件，对系统级的文件和目录只有读取权限或完全没有权限。\n我们执行日常任务，如开发、浏览网页、文档处理通常处在这一层级\n\n\n系统用户 (System User)：UID 通常在 1 到 999 之间, 这些用户不是为人类交互设计的。它们被各种系统服务（如 www-data 用于 Apache/Nginx，postfix 用于邮件服务）所使用，以便以受限的权限运行，从而提高系统安全性。\n\n登录 (Login)：创建全新的会话“登录”是指用户向系统证明自己身份（认证），并由系统为其创建一个全新的、隔离的工作会话（Session）的过程。其可以分为本地登录和远程登录两类. \n本地登录 (Local Login): 指直接在连接到计算机的物理设备上登录。\n远程登录 (Remote Login): 指通过网络从一台计算机连接到另一台计算机。常见的远程登录方式有SSH登录\n\nSSH (Secure Shell)：是进行远程服务器管理的最主要、最安全的方式。\n\n使用 SSH 客户端命令 ssh username@hostname_or_ip。服务器会要求你通过密码或 SSH 密钥进行认证。\n\n与本地登录一样，SSH 成功认证后会在远程服务器上为你启动一个全新的 登录 Shell。\n\n\n\n\n用户切换 (Switching)：在现有会话中改变身份\n(那我为什么不创建一个新的shell登录呢)\n\n“切换”是指在一个已经登录的会话中，临时获取另一个用户的身份和权限，而无需退出当前会话。\n","categories":["system"],"tags":["system"]},{"title":"CVXOPT","url":"/2025/07/04/lang/python/CVXOPT/","content":"CVXOPT 是一个用于凸优化问题的 Python 库。它提供了一系列用于求解凸优化问题的函数，包括线性规划、二次规划、二次约束等。CVXOPT 的 API 设计得非常直观，使得用户可以方便地定义和求解各种凸优化问题。\n二次规划 (QP)二次规划 (Quadratic Programming, QP) 是一种常见的凸优化问题，其目标函数为二次函数，约束条件为线性不等式。在 CVXOPT 中提供了 QP solver 来求解 QP 问题。\n\n在金融领域，二次规划常用于资产组合优化。\n\n下面我们来拆解一下这个词：\n\nQ - Quadratic (二次的)\n\n“二次”指的是问题的核心目标像一个”碗”或者”山谷”。它的数学表达式里包含变量的平方，比如 。\n\n为什么”碗”这个形状很重要？因为它只有一个最低点。求解器的任务就是精准地找到这个碗底。如果是个平面，那就没有最低点了；如果坑坑洼洼，就会有很多个局部最低点，难以抉择。二次问题（QP）保证了我们能找到那个唯一的、全局的最低点。\n\n\n\nP - Programming (规划)\n\n这里的”规划”不是指我们平时说的写代码（Programming）。它是一个历史悠久的数学术语，意思是”做计划”或者”寻找最优方案”。\n\n所以，”二次规划”指的就是为二次型问题寻找最优解决方案的计划。\n\n\n\nSolver (求解器)\n\n这个最好理解，它就是执行这个计划的工具或引擎。你把问题描述给它，它内部有一套非常高效的算法，能自动、快速地帮你找到答案。\n\n\n\n总结: 一个 QP 求解器 (QP Solver)，就是一个专门用来寻找”碗状”问题最低点的自动化数学工具。你需要做的就是告诉它你的”碗”长什么样（目标），以及你必须遵守的”规则边界”（约束），然后它就能帮你找到在这些边界内的最低点在哪里。\nQP solver流程示例问题描述求解以下 QP 问题。\n目标函数 (Minimize)：\n约束条件 (Subject to)：\n\n\n\n\n\n“碗”就是目标函数: \n“规则边界”就是约束条件: , , 和 \nCVXOPT 里的 solvers.qp 就是那个能解决这个问题的求解器。\n我们把使用这个库想象成 “给一个很厉害但一板一眼的厨师下订单” 的过程。这位厨师（CVXOPT）厨艺高超，但你必须用他唯一能看懂的、格式固定的订单（矩阵）来告诉他你要什么。\n整个过程分为三步：\n第 1 步：用大白话描述你的”目标”和”规则”这一步是给自己看的，先理清思路。\n\n我的目标是什么？(Objective)\n我想要一个”菜”（由原料  和  组成），它的”成本”由公式  决定。我的目标是让这个成本最低。\n\n我有什么规则？(Constraints)\n\n规则1：原料  的用量不能是负数 ()。\n规则2：原料  的用量也不能是负数 ()。\n规则3：两种原料的总用量必须正好是 1 ()。\n\n\n\n第 2 步：把”目标”和”规则”翻译成”厨师的订单格式”（矩阵）这是最关键的一步。这位厨师（CVXOPT）不认识我们的大白话，他只认识一张叫 P, q, G, h, A, b 的标准订单。我们必须把信息填进去。\n\n填写 P 和 q (描述你的”目标”)\n厨师通过 P 和 q 来理解你想要的那个”成本函数”（那个”碗”）。\n\nP 矩阵描述成本函数里二次项（带平方的项）的部分，它决定了”碗”的形状。\nq 矩阵描述成本函数里一次项（不带平方的项）的部分，它决定了”碗”的位置。\n\n怎么填: 根据数学规则(后面介绍)，我们计算出\n\n填写 G 和 h (描述你的”不严格”规则)\n厨师通过 G 和 h 来理解所有”小于等于”或”大于等于”的规则。\n我们的规则是  和 。订单格式要求写成”小于等于”，所以我们改写成  和 。\n怎么填: 我们把这个信息填入订单，得到\n\n填写 A 和 b (描述你的”死规定”)\n厨师通过 A 和 b 来理解所有”必须正好等于”的死规定。\n我们的死规定是 。\n怎么填: 我们把这个信息填入订单，得到\n\n\n现在，我们的订单填好了！我们已经成功把我们的想法，翻译成了计算机能懂的语言。\n第 3 步：用 Python 代码把”订单”交给”厨师”这一步就是写代码，把我们刚刚整理好的矩阵告诉 CVXOPT。\nfrom cvxopt import matrix, solvers# --- 把我们翻译好的订单内容写下来 ---# 这是告诉厨师，我们目标\"碗\"的形状和位置P = matrix([[4.0, 1.0], [1.0, 2.0]])q = matrix([1.0, 1.0])# 这是我们设定的\"不能超过\"的规则G = matrix([[-1.0, 0.0], [0.0, -1.0]])h = matrix([0.0, 0.0])# 这是我们设定的\"必须等于\"的死规定A = matrix([[1.0, 1.0]])b = matrix(1.0)# --- 把这张\"订单\"正式交给\"厨师\"（求解器），让他开始工作 ---sol = solvers.qp(P, q, G, h, A, b)# --- 查看\"厨师\"给出的最终配方（最优解） ---# sol['x'] 里就是我们想要的 x1 和 x2 的最佳用量print(\"找到了能让成本最低的原料配比：\")print(sol['x'])\n\n\n数学规则目标函数要理解这些矩阵的含义，首先需要了解 cvxopt.solvers.qp 所求解的二次规划问题的标准数学形式。其目标是找到一个向量 ，使得：\n\n最小化 (Minimize)：\n约束条件 (Subject to)：其中  表示逐元素小于等于。\n\n下面我们来逐一解释每个矩阵和向量的含义。\n矩阵和向量的含义\nP 和 q：定义目标函数\n这两个参数共同构成了你需要最小化的目标函数，它是一个二次函数。\n\nP (Matrix, 矩阵)：\n这是一个  的半正定矩阵（positive semi-definite），其中  是你要求解的变量  的维度。\n矩阵  描述了目标函数中所有变量的二次关系。在数学上， 是目标函数  的海森矩阵 (Hessian Matrix)，即由目标函数的二阶偏导数组成的方阵，描述了函数的局部曲率。\n格式：在 cvxopt 中， 必须是 cvxopt.matrix 类型。\n计算方法：\n写出目标函数 。\n计算  对所有变量的一阶偏导（梯度 ）：\n计算二阶偏导，构成海森矩阵 ：\n\n\n\n\n\n\n\n\n    为什么有  \n    \n      数学上，在目标函数中加入  是一个惯例。这样做可以使得求导后的形式变得简洁（例如，），但它不影响最优点的位置。cvxopt 的标准形式包含了这个 ，所以在定义  时，你不需要自己再乘以2。\n \n\n    \n  \n\nq (Vector, 向量)：\n这是一个  的向量。\n向量  描述了目标函数中所有变量的线性关系。它是在剥离了二次项和常数项后，与  线性组合的系数向量。它影响了目标函数曲面的位置。\n格式： 也必须是 cvxopt.matrix 类型。\n计算方法：\n审视目标函数 。\n找出所有只与变量一次幂相乘的项：。\n将这部分写成向量内积的形式 ：\n对比系数可得 。\n\n\n结果：\n\n\n\n\nG 和 h：定义不等式约束\n这两个参数共同定义了问题中的不等式约束。标准形式  要求所有不等式都是”小于等于”的形式，并且每一行代表一个独立的约束。 符号代表逐元素比较。\n\nG (Matrix, 矩阵)：\n\n这是一个  的矩阵，其中  是不等式约束的数量。\n 的每一行定义了一个线性不等式。例如， 的第一行和  的第一个元素共同定义了第一个约束：\n格式：cvxopt.matrix 类型。\n\n\nh (Vector, 向量)：\n\n这是一个  的向量。\n作用： 包含了  个不等式约束的右侧边界值。\n格式：cvxopt.matrix 类型。\n\n\n计算方法：\n\n逐一标准化：将每一个不等式约束都转换为  的形式。\n\n\n约束1：\n约束2：\n\n\n提取系数行向量(每个约束中x的系数)：\n\n\n对于 ，系数行向量是 ，右侧常数是 0。\n对于 ，系数行向量是 ，右侧常数是 0。\n\n\n堆叠成矩阵：将所有系数行向量按顺序堆叠，形成矩阵 ，右侧常数堆叠成向量 。\n\n\n结果：\n\n\n\n\nA 和 b：定义等式约束\n这两个参数共同定义了问题中的等式约束（）。\n\nA (Matrix, 矩阵)：\n\n这是一个  的矩阵，其中  是等式约束的数量。\n作用： 的每一行定义了一个线性等式约束。\n格式：cvxopt.matrix 类型。\n\n\nb (Vector, 向量)：\n\n这是一个  的向量。\n作用： 包含了  个等式约束右侧的目标值。\n格式：cvxopt.matrix 类型。\n\n\n计算方法 (与G,h类似)：\n\n审视等式：本例只有一个等式约束 。\n提取系数行向量：，右侧常数为 1。\n堆叠成矩阵：本例只有一行。\n\n\n结果：\n\n\n\n\n\n  \n总结：\n\n：描述了你想最小化的”成本”函数。\n：设定了变量  的活动范围（例如  可以写成 ）。\n：设定了变量  必须满足的精确关系（例如 ）。\n\n","categories":["language"],"tags":["language","python"]},{"title":"Docker介绍及应用","url":"/2025/06/28/tools/docker/docker/","content":"Docker 是一种开源的应用容器引擎，它彻底改变了现代软件的开发、交付和运行方式。通过将应用程序及其所有依赖项打包到一个标准化的单元中，即容器 (Container)，Docker 确保了应用程序在任何环境中都能以相同的方式运行。\n\n在 Docker 出现之前，软件开发和运维团队经常面临一个经典难题：“在我电脑上明明是好的啊！” (“It works on my machine!”)。这个问题源于开发、测试和生产环境之间的差异，例如操作系统版本、依赖库、环境变量配置等不同，导致应用程序在一个地方能跑，换个地方就出错。而Docker 的诞生正是为了解决这一痛点。它通过“集装箱化”的思想，提供了一个标准、一致的运行环境。\n\nDocker 的三大核心概念要理解 Docker，必须掌握它的三个基本组成部分：镜像 (Image)、容器 (Container) 和 仓库 (Registry)。\n镜像 (Image)镜像是 Docker 的“构建”部分，它是一个只读的模板，用于创建 Docker 容器。\n\n定义：一个镜像是一个轻量级、可执行的软件包，其中包含了运行某个软件所需的一切：代码、运行时环境、系统工具、系统库和设置。\n\n特性：镜像是分层的，并且是不可变的。任何对镜像的修改都会创建一个新的镜像层。\n\n类比：如果说容器是面向对象编程中的一个“对象 (Object)”，那么镜像就是创建这个对象的“类 (Class)”。\n\n\n容器 (Container)容器是 Docker 的“运行”部分，它是从镜像创建出来的运行实例。\n\n定义：容器是镜像的运行时实例。我们可以对容器进行启动、停止、删除等操作。每个容器都是相互隔离的、保证安全的平台。\n\n特性：容器是可写的，并且拥有自己独立的文件系统、网络和进程空间，与宿主机系统和其他容器隔离开来。(注意docker只是操作系统级的虚拟化。所有容器仍然共享宿主机的操作系统内核, 而不是像虚拟机那样各自拥有独立的操作系统内核)\n\n类比：接上一个比喻，如果镜像是“类”，那么容器就是通过 new 这个类而创建出来的“实例对象”。同一个镜像可以创建出任意多个功能完全相同的容器。\n\n\n仓库 (Registry)仓库是 Docker 的“分发”部分，用于集中存放和分发镜像。\n\n定义：一个集中的存储、分发镜像的服务。最著名的公共仓库是 Docker Hub，它也是 Docker 官方维护的默认仓库。此外，每个人也可以搭建自己的私有仓库。\n\n类比：我们可以把仓库看作是代码界的 GitHub。开发者将代码上传到 GitHub，其他人可以下载使用；同样，开发者可以将镜像推送到 Docker Hub，其他人可以拉取使用。\n\n\n","categories":["tools"],"tags":["tools"]},{"title":"yield","url":"/2025/06/28/lang/python/yield/","content":"yield 是 Python 中一个功能强大的关键字，它主要用于创建生成器 (Generator)。理解 yield 的关键在于理解生成器是如何工作的。简而言之，当一个函数包含 yield 关键字时，它就不再是一个普通的函数，而是一个生成器函数。\n\n    生成器是一种特殊的迭代器 \n    \n      与一次性计算并返回所有结果的普通函数不同，生成器函数会返回一个生成器对象。这个对象可以按需、逐个地“生成”结果，而不是一次性将所有结果都存储在内存中, 它是一种惰性求值的迭代器。\n\n普通函数 (return): 执行 -&gt; 计算所有结果 -&gt; 返回结果 -&gt; 结束。\n\n生成器函数 (yield): 调用 -&gt; 返回一个生成器对象 (不执行代码) -&gt; 迭代时, 当执行到 yield才“产出”一个值并暂停 -&gt; 等待下一次迭代 -&gt; 从暂停处继续执行。\n\n\n\n    \n  \n\nyield示例下面的simple_generator函数内部包含了 yield，所以它现在是一个生成器函数。\ndef simple_generator():    print(\"生成器开始执行...\")    yield 1        print(\"生成器继续执行...\")    yield 2        print(\"生成器最后一次执行...\")    yield 3        print(\"生成器执行结束。\")# 调用生成器函数，返回一个生成器对象my_gen = simple_generator()print(type(my_gen))print(my_gen)\n当执行上述代码时, 输出并不会包含\"生成器开始执行...\"等内部代码. 因为yield的存在, 它只是创建并返回了一个生成器对象，这个对象处于“待命”状态。\n&lt;class 'generator'&gt;&lt;generator object simple_generator at 0x...&gt;\n而当采用next()函数或者for循环时, 才能来驱动生成器执行并获取其产出的值。\n# 重新创建一个生成器对象for value in simple_generator():    print(f\"For 循环获取到的值: {value}\")\n输出结果如下:\n生成器开始执行...For 循环获取到的值: 1生成器继续执行...For 循环获取到的值: 2生成器最后一次执行...For 循环获取到的值: 3生成器执行结束。\n\nyield优势\n极高的内存效率: 这是 yield 最突出的优点。生成器按需生成值，在任何时刻只有一个值存在于内存中。对于处理大规模数据集、文件流或无穷序列，这是至关重要的。\n能够处理无限序列由于其“懒加载”的特性，你可以轻松定义一个无限序列的生成器，这是列表或元组无法做到的。\n代码逻辑更清晰、简洁对于需要维护内部状态的复杂迭代逻辑（例如，遍历一个树状结构），使用生成器函数通常比自己实现一个迭代器类（包含 __iter__ 和 __next__ 方法）要简单得多，代码也更具可读性。\n\n","categories":["language"],"tags":["language","python"]},{"title":"Bayes Nets -- Bayesian Networks(11)","url":"/2025/08/23/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/11/","content":"上一讲(概率论基础)我们学到，只要有完整的联合概率分布，我们就能回答任何概率问题。但同时也暴露了一个致命问题：这个联合分布表的大小会随着变量数量的增加而指数级增长，在现实问题中完全不可行。\n这一讲的核心就是解决这个问题：如何利用变量间的独立性关系，来紧凑、高效地表示一个完整的联合概率分布。这个解决方案就是贝叶斯网络 (Bayesian Networks)。\n不过在介绍贝叶斯网络之前, 我们先介绍在其之上的一个概念, 概率图模型.\n概率图模型概率图模型（Probabilistic Graphical Model，PGM）是一种用图结构来表示和推断多元随机变量之间条件独立性的概率模型。图模型提供了一种直观且有效的方式来描述高维空间中的概率分布，通过图结构表示随机变量之间的关系，使得模型的参数量得以减少。\n\n概率论负责处理不确定性和随机性, 图论提供了一种直观且强大的数据结构，用来表示变量之间的依赖关系。\n\n条件概率考虑一个由  个离散随机变量  组成的随机向量 ，其中每个变量都有  个可能的取值，其联合概率在高维空间中的分布很难直接建模。在没有任何独立性假设的情况下，我们需要为每一种组合分配一个概率值。每个变量有  个可能的取值，因此有  种可能的组合。由于概率的总和必须等于1，所以最后一个概率值可以通过对其他概率值进行补充得到，因此，我们需要  个参数。\n当  且  时，参数量(约为 )将远远超出目前计算机的存储能力。为了有效减少参数量，可以使用独立性假设。一个  维随机向量  的联合概率可以分解为  个条件概率的乘积。如果某些变量之间存在条件独立性，参数量就可以显著减少。\n对于一个  维随机向量 ，其联合概率可以分解为条件概率的乘积：\n\n它被称为概率的链式法则 (Chain Rule of Probability)。它将一个复杂的多维联合概率问题，分解成了一系列更简单的一维条件概率的乘积。\n\n    概率回忆 \n    \n      什么是概率分布: 一个概率分布描述了一个随机变量所有可能取值及其对应的概率。我们通常用一个数学函数****来精确地描述这个对应关系，这个函数被称为概率质量函数 (PMF)（对于离散型变量）或概率密度函数 (PDF)（对于连续型变量）。\n因此对于上述公式, p(x)=…是一个以 x 为变量的函数表达式, 这个函数的功能是，你给它任何一个可能的具体向量值 x, 它就能告诉你这个特定向量值发生的概率; 而这个函数本身，完整地刻画了随机向量 X 的概率分布(因此在离散情况下假如让你求类似的表达式, 也就是让你求出所有可能情况的分布)。\n\n大写粗体字母 ：代表一个随机向量 (Random Vector)\n\n它是一个变量，其值是随机的，并且是一个向量。可以把它想象成一个“容器”或一个“抽象概念”\n如果我们同时掷两枚骰子，可以用一个二维随机向量  来描述这个随机事件。X 代表了从 (1,1) 到 (6,6) 所有36种可能结果的整个概率空间。\n\n\n小写粗体字母 ：代表随机向量的一个具体实现 (Realization) 或观测值\n\n它是从随机向量 X 的所有可能性中取出的一个特定的、具体的数值向量。\n如果我们实际掷了一次两枚骰子，得到的结果是第一枚为3点，第二枚为5点，那么这次观测值就是 x=(3,5)。这个 x 就是随机向量 X 的一个具体实现。\n\n\n\n\n    \n  \n\n其中， 表示变量  的取值。通过这种分解，我们可以将原本需要  个参数的问题，降低到对每个变量的条件概率的参数的数量之和。如果某些变量之间存在条件独立关系，那么相应的条件概率的参数量就可以大幅减少。\n概率图模型中，贝叶斯网络和马尔可夫网络都利用了这种条件独立性的结构，以更紧凑的方式表示联合概率分布，从而提高了模型的可解释性和计算效率。\n条件独立条件独立是指在给定某个特定条件（或第三个事件）C 已经发生的前提下，两个事件（或随机变量）A 和 B 变得独立。这意味着，一旦我们知道了条件 C 的信息，事件 A 的发生与否，就对事件 B 在该条件下的概率没有影响了。你可以把它理解为一种有条件的独立性。\n对于三个事件 A, B, 和 C，A 与 B 在给定 C 的条件下条件独立当且仅当下列二者之一成立：\n\n\n\n\n\n    举个例子 \n    \n      想象一下一个简单的医疗情景：\n事件 A：病人有发烧的症状。\n事件 B：病人有咳嗽的症状。\n事件 C：病人患有流感。\n首先，我们不考虑任何其他信息，只看事件 A（发烧）和事件 B（咳嗽）。问题是, 发烧和咳嗽是相互独立的吗？\n答案当然不是。如果一个病人有发烧，你会自然地认为他生病了，比如感冒或流感。而这些疾病通常也会伴随着咳嗽。因此，发烧的存在增加了病人有咳嗽的可能性。反之亦然。\n我们可以用因果关系来理解：因为流感这种病因可能同时导致发烧和咳嗽这两种症状。当流感这个“共同原因”未知时，两种症状看起来是相互关联的。\n现在，我们引入条件 C。假设我们已经通过化验或其他诊断方法，确定病人患有流感。此时的问题是, 在已经知道病人患有流感的前提下，发烧和咳嗽还相互依赖吗？\n答案当然是不再依赖。在这种情况下，我们已经找到了导致这两种症状的根本原因——流感。流感这个疾病本身就可以独立地引发发烧，也可以独立地引发咳嗽。\n你已经知道病人有流感了，那么发烧这个症状的出现，并不会给你提供更多关于咳嗽的额外信息。因为你已经知道他们都有可能由流感引起。\n因此, 条件独立关注的是在“幕后黑手”已经被揭示出来的前提下，两个事件的关系。一旦这个共同原因被确定，它们之间的表观关联就被“解释掉了”，从而变得独立。\n \n\n    \n  \n\n下面我们将条件独立引入之前的条件概率和联合概率：\n首先, 根据条件概率公式, 有:\n通过假设条件独立并引入条件独立性假设，可以减少参数量\n例如，在已知  时， 和  独立，即有：\n\n\n\n\n\n\n在已知  和  时， 也和  独立，即有：\n\n\n\n这样可以将联合概率分解为四个局部条件概率的乘积，从而减少参数量：\n\n 的参数数量为 1;  的参数数量为 2（在给定  的条件下）;  的参数数量为 2（在给定  的条件下）;  的参数数量为 4（在给定  和  的条件下, 因为 和 组合有四种情况）\n所以总的独立参数数量为  , 远小于指数级参数。\n概率图模型的总体框架\n从图中可以看出, 概率图模型涉及到三个基本问题: \n\n表示问题：这个问题涉及如何选择和设计图结构，以有效地表示变量之间的依赖关系。在贝叶斯网络中，这通常涉及到选择合适的有向边，而在马尔可夫网络中，涉及到选择无向边。图结构的选择直接影响了概率模型的表达能力和推断效率。\n\n学习问题：学习问题可以进一步分为两个部分：图结构的学习和参数的学习。在图结构的学习中，目标是从数据中推断出最合适的图结构，描述变量之间的依赖关系。在参数的学习中，已知图结构的情况下，目标是估计模型中的参数，使得模型与观测数据的拟合最好。\n\n推断问题：推断问题涉及在给定部分变量的观测值时，计算其他变量的条件概率分布。这可以通过贝叶斯推断、变分推断等方法来解决。推断在概率图模型中是一个关键的任务，因为它允许我们根据观测到的证据来推断未观测到的变量的状态，从而进行概率推理。\n\n\n贝叶斯网络\n有向图模型（Directed Graphical Models）是概率图模型的一类，其中最为知名的代表是贝叶斯网络。这种模型在处理多变量概率关系方面表现出色，提供了一种直观、清晰的方法来描述随机变量之间的因果关系。\n\n根据我们前面提到的内容 ,一个包含 n 个变量、每个变量有 d 个取值的联合概览分布表需要  个条目来存储信息, 极度耗费空间。\n贝叶斯网利用条件概率和条件独立性的思想，将这个大表分解为：\n\n一个有向无环图 (Directed Acyclic Graph - DAG)：用于直观地表示变量之间的依赖关系。\n\n节点 (Nodes)：图中的每个节点代表一个随机变量。这个变量可以是离散的（例如：天气是晴天、阴天还是雨天），也可以是连续的（例如：温度）。\n\n有向边 (Edges)：从节点 A 指向 B 的箭头通常表示 A 对 B 有直接影响。A 被称为 B 的父节点 (parent)。\n\n箭头不一定代表严格的因果关系，它只表示变量之间可能存在某种概率上的依赖。\n\n\n\n\n一组小的条件概率表 (Conditional Probability Tables - CPTs)：每个变量都附有一个CPT，描述了它在其父节点取不同值时的概率分布。\n\n每个节点 X 都有一个与之关联的CPT，即 。\n\n这个表列出了在给定其所有父节点所有可能取值组合的情况下，节点 X 本身取每个值的概率。\n\n\n没有父节点的节点（根节点），其CPT就是一个简单的先验概率分布 。\n\n\n\n\n有向图模型/贝叶斯网络最核心的优势在于，在这个情境下一个变量的取值只与它的父节点有关, 因此能够将所有变量的复杂联合概率分布分解为一系列更简单的局部条件概率分布的乘积。具体来说，整个网络的联合概率可以表示为：\n这个公式的含义是，计算所有变量同时发生的总概率时，我们只需要计算每个变量在其父节点发生的条件下的概率，然后将它们全部相乘。在这样的情况下, 原本指数级增长的参数数量，大幅降低到只与每个节点的父节点数量相关的程度，从而使大规模模型的构建和学习变得可行。\n几类应用上述思维导图中列出了一些典型的有向图模型，它们在不同领域有广泛应用：\n\n朴素贝叶斯模型（Naive Bayes Model）\n\n\n特点：这是一种最简单的贝叶斯网络，它有一个根节点（通常代表类别），所有其他叶子节点（代表特征）都直接从这个根节点引出, 就像一棵两层的树一样。\n\n核心假设：它做出了一个非常“朴素”的假设——在给定类别的情况下，所有特征之间是相互独立的。\n\n应用：虽然假设很强，但它在文本分类和垃圾邮件过滤等领域表现出奇的好。\n\n\n\n隐马尔可夫模型（Hidden Markov Model, HMM）, 这个我们之后会涉及到\n\n\n特点：专门用于处理序列数据。它包含一个隐藏状态序列和一个可观测序列。隐藏状态是不可见的，但它们决定了可观测序列的生成。\n\n核心假设：它遵循马尔可夫假设——当前隐藏状态只依赖于前一个隐藏状态。\n\n应用：广泛用于语音识别、自然语言处理中的序列标注（如词性标注）等。\n\n\n\n深度信念网络（Deep Belief Network, DBN）\n\n\n特点：它是一种生成式概率模型，连接了经典图模型和现代深度学习。它由多层受限玻尔兹曼机（RBM）堆叠而成。\n\n核心思想：通过分层的方式学习数据的高维表示，每层都捕捉了数据中更抽象的特征。\n\n应用：在深度学习兴起初期，常用于无监督预训练，以提高神经网络的性能。\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Intro to AI, Rational Agents","url":"/2025/08/03/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/1/","content":"第一章笔记是该课程的开篇介绍, 核心是定义什么是智能体 (Agent) 以及智能体所处的环境 (Environment)\n智能体 (Agents)AI的中心问题是创建一个理性的智能体 (rational agent) 。理性智能体是一个拥有目标或偏好，并试图执行一系列行动以期在这些目标下获得最佳（或最优）期望结果的实体 。\n\n智能体的“理性”并非指无所不知或完美，而是在其知识范围内做出最优的期望选择。\n\n智能体的构成与环境：\n\n智能体存在于一个环境 (environment) 中，该环境是针对特定智能体实例的 。\n\n智能体通过传感器 (sensors) 与环境交互，并通过执行器 (actuators) 对环境施加影响 。\n\n智能体与其所处的环境共同构成一个世界 (world) 。例如，一个跳棋程序的“世界”就是虚拟棋盘和对手 。\n\n\n\n环境类型 (Types of Environments)智能体的设计在很大程度上取决于其所处环境的类型 。因此，理解环境的属性至关重要。根据不同的分类依据, 智能体所处的环境可以有如下几种: \n\n可观察性 (Observability)：\n\n在完全可观察 (fully observable) 的环境中，智能体完全了解其状态 。\n\n在部分可观察 (partially observable) 的环境中，智能体无法获得关于状态的全部信息，因此必须维护一个对世界状态的内部估计 。\n\n\n\n确定性 (Determinism)：\n\n在确定性 (deterministic) 环境中，在特定状态下执行一个行动只有一个确定的结果 。\n\n在随机性 (stochastic) 环境中，转移模型存在不确定性，即一个行动可能有多个不同概率的结果 。\n\n\n\n智能体数量 (Number of Agents)：\n\n在多智能体 (multi-agent) 环境中，一个智能体需要与其他智能体共同行动 。为了避免行为被其他智能体预测，它可能需要将其行动随机化 (randomize) 。\n\n\n动态性 (Dynamism)：\n\n如果环境在智能体行动时不会发生变化，则称之为静态 (static) 环境 。\n\n动态 (dynamic) 环境则会随着智能体的交互而改变 。\n\n\n\n物理规则 (Physics)：\n\n如果环境具有已知的物理规则 (known physics)，智能体就了解其转移模型（即使是随机的），并可以在规划时利用这些知识 。\n\n如果物理规则是未知的 (unknown)，智能体则需要通过有目的的行动来学习这些动态规律 。\n\n\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Bayes Nets -- Inference(12)","url":"/2025/08/23/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/12/","content":"上一讲我们学会了如何用贝叶斯网络来紧凑地表示一个复杂的联合概率分布。这一讲的核心问题是：有了这个紧凑的表示，我们如何高效地进行计算，从而回答概率查询(也就是推理问题)？\n\n推理问题可以分为精确推理和近似推理, 这一节我们考虑精确推理\n\n首先, 假如我们有一个完整的联合概率分布表, 只需要查表就可以得到所要的结果, 但是在贝叶斯网络的基础上, 我们有一种更智能的算法，能够在不生成完整联合分布的情况下完成推理。这个算法就是变量消除 (Variable Elimination)。\n变量消除 (Variable Elimination)变量消除是一种高效的精确推理算法，其核心思想是通过重新排列计算顺序来避免重复计算。\n当我们想计算某个变量的边缘概率或条件概率时，不需要先计算出整个联合概率分布，而是通过将求和操作推入乘积内部，逐一消去无关的变量，从而大大降低计算复杂度。这个过程被称为“求和-乘积”算法（Sum-Product Algorithm）。\n整个过程可以概括为以下四个主要步骤：\n\n初始化: 将贝叶斯网络中的每一个条件概率表（CPT）视为一个独立的因子（Factor）。这些因子是关于其所依赖变量的函数。\n\n迭代消除变量: 根据预定的消除顺序，逐一处理每个需要被消除的变量。对于每个待消除的变量，执行以下操作：\n\n\n\n找出相关因子：找到所有包含该变量的因子。\n\n因子相乘：将这些相关因子全部相乘，生成一个新的、更大的临时因子。\n\n求和消除：对这个新的临时因子，关于待消除的变量进行求和（或积分）。这个操作的结果是一个不包含该变量的新因子。\n\n更新因子集：将原始的相关因子从集合中移除，并将新生成的因子加入到集合中。\n\n\n\n重复直至求出目标: 重复第二步，直到所有需要被消除的变量都被处理完毕。此时，剩下的因子只包含我们所查询的目标变量（以及任何给定的证据变量）。\n\n最终计算与归一化: 将所有剩余的因子相乘，得到一个包含目标变量边缘概率的最终因子。如果需要计算条件概率，最后一步还要进行归一化处理，使所有可能结果的概率之和为1。\n\n\n\n示例分析让我们通过一个简单的”草地湿润”例子来展示变量消除的过程。\n假设我们有一个包含四个二元变量（真/假）的贝叶斯网络：\n\nC：多云（Cloudy）\nS：洒水器打开（Sprinkler On） \nR：下雨（Rain）\nW：草地湿润（Grass is Wet）\n\n这个网络的依赖关系如下图所示：\n\nC→S\nC→R  \nS→W\nR→W\n\n对应的条件概率表（CPT）如下（为了便于计算，我们使用简单的数值）：\n:\n\n\n\n\n:\n\n\n\nC\nS=T\nS=F\n\n\n\nT\n0.1\n0.9\n\n\nF\n0.5\n0.5\n\n\n:\n\n\n\nC\nR=T\nR=F\n\n\n\nT\n0.8\n0.2\n\n\nF\n0.1\n0.9\n\n\n:\n\n\n\nS\nR\nW=T\nW=F\n\n\n\nT\nT\n0.99\n0.01\n\n\nT\nF\n0.9\n0.1\n\n\nF\nT\n0.9\n0.1\n\n\nF\nF\n0.0\n1.0\n\n\n我们的目标是：计算草地湿润的边缘概率 。\n变量消除法的具体过程：\n步骤 1: 建立联合概率分布表达式\n首先，根据贝叶斯网络的结构，我们可以使用链式法则将整个网络的联合概率分布表示为所有节点的条件概率的乘积：\n\n步骤 2: 设定求和表达式\n为了得到 ，我们需要对除了 W 以外的所有变量进行求和（即积分），并将 W 的状态设定为 T：\n\n如果直接进行计算，我们需要构建一个包含  种组合的巨大表格，然后逐行求和。变量消除法通过改变求和顺序来优化这个过程。\n步骤 3: 确定消除顺序和重写表达式\n变量消除法的关键是将求和操作推入乘积内部。我们可以选择一个合适的消除顺序（例如，在本例中我们按 C→R→S 的顺序进行消除），将上一步的表达式改写为：\n\n为什么要这样做？这样改写后，我们每次只对表达式中的一小部分进行求和，而不是对整个联合概率分布求和。每次求和的结果是一个新的”因子”或”表格”，这个新表格的维度比原始联合分布小得多。\n步骤 4: 逐个消除变量\n\n消除变量 C\n\n我们首先计算表达式中与 C 相关的那一部分：\n\n这个新的因子  是一个关于 S 和 R 的表格。它代表了  的联合概率分布。\n我们来计算  表格中的每一项：\n：\n：\n：\n：\n\n消除变量 R\n\n将上一步得到的  因子与  相乘，并对 R 求和。我们得到一个新的因子 ：\n\n：\n：\n\n消除变量 S\n\n最后，我们对剩下的因子  进行求和，得到最终结果 ：\n\n结论和总结：通过变量消除法，我们成功计算出了  的精确值，为 0.62235。\n计算代价对比1. 暴力计算法的计算量目标：计算 \n步骤 1: 构建完整的联合概率分布表为了计算联合概率分布 ，我们需要为每个可能的变量组合（ 种组合）计算其概率值。\n每一行的计算都需要将四个概率相乘：。这涉及到 3 次乘法。\n例如，计算第一行 ： （3次乘法）\n总乘法次数：16 行 × 3 次乘法/行 = 48 次乘法。\n步骤 2: 对变量 C, S, R 求和在得到完整的16行联合概率表之后，我们需要找出所有 W=T 的行（共有  行），然后将它们的概率值相加。\n总加法次数：将 8 个数字相加需要 7 次加法。\n暴力计算法总结\n总计算量：48 次乘法 + 7 次加法 = 55 次运算\n内存需求：需要存储一个包含 16 行的完整联合概率表\n\n2. 变量消除法的计算量现在我们回顾一下变量消除法的每一步，并统计运算次数。\n步骤 1: 消除变量 C，生成因子 这个因子  是一个  的表格，有 4 个条目。计算每个条目都需要一次求和，求和的每一项都是三个概率的乘积。\n例如：\n计算一个条目所需的运算：\n\n方括号内各有 2 次乘法，共  次乘法\n两个方括号相加，需要 1 次加法\n\n总运算量：4 个条目 × (4 次乘法 + 1 次加法) = 16 次乘法 + 4 次加法\n内存需求：生成一个包含 4 行的新表 \n步骤 2: 消除变量 R，生成因子 这个因子  是一个  的表格，有 2 个条目。\n例如：\n计算一个条目所需的运算：\n\n方括号内各有 1 次乘法，共  次乘法\n两个方括号相加，需要 1 次加法\n\n总运算量：2 个条目 × (2 次乘法 + 1 次加法) = 4 次乘法 + 2 次加法\n内存需求：生成一个包含 2 行的新表 \n步骤 3: 消除变量 S，得到最终结果 \n总运算量：1 次加法\n变量消除法总结\n总乘法次数：16 + 4 = 20 次乘法\n总加法次数：4 + 2 + 1 = 7 次加法\n总计算量：20 次乘法 + 7 次加法 = 27 次运算\n内存需求：在整个计算过程中，我们创建的最大的中间表是 ，它只有 4 行\n\n信念传播（Belief Propagation, BP）信念传播 (Belief Propagation, BP) 是一种在概率图模型（如贝叶斯网络或马尔可夫随机场）上进行推断的算法。它的核心思想可以被形象地描述为：图中的每个节点都是一个独立的计算单元，它们通过相互之间“传递消息” (passing messages) 来不断更新自己对某个变量状态的“信念” (belief)。\n\n信念 (Belief)：指的是一个节点（变量）的边际概率分布 (Marginal Probability Distribution)。简单来说，就是综合了图中所有可用信息后，我们对这个变量取不同值的可能性有多大的判断。\n\n消息 (Message)：一个节点传递给其邻居节点的信息。这个消息总结了除了从那个邻居接收到的信息之外，它所知道的所有其他信息。这就像是在说：“嘿，这是我从其他所有人那里听到的所有消息汇总，现在我告诉你，但不包括你告诉我的那部分。”\n\n\n信念传播算法通过一个迭代的消息传递过程来计算每个节点的信念。我们可以把它分为两种主要情况：\n在树状结构图上：精确推断当概率图的结构是一个树 (Tree) 或者 多义树 (Polytree)（即图中没有任何无向环路）时，信念传播是一种精确推断算法。它能准确地计算出每个变量的边际概率。\n步骤说明：\n初始化: 随机选择一个根节点。\n消息收集 (从叶到根): 从图的叶子节点开始，每个节点收集来自其子节点的所有消息，然后计算并向其父节点发送一条新的消息。这个过程一直持续到根节点收到了来自其所有子节点的消息。\n消息分发 (从根到叶): 根节点收到所有消息后，开始向其子节点分发消息。然后，每个节点再根据从父节点收到的消息，计算并向它的子节点继续分发消息，直到消息传递到所有的叶子节点。\n计算信念: 当每个节点都收到了来自其所有邻居的消息后，它就可以利用这些消息来计算自己的最终信念（即边际概率）。\n为什么是精确的？ 因为在树状结构中，从任何一个邻居传来的信息路径都是唯一的，信息不会“绕一圈”回来，所以消息的传递不会产生冗余或循环依赖，保证了计算的准确性。\n在带环路的图上：环路信念传播 (Loopy Belief Propagation)当图中存在环路 (Cycles) 时，情况就变得复杂了。一个节点发出的消息可能会沿着环路绕一圈后，又以某种形式传回给自己。这违反了标准信念传播算法的基本假设。\n在这种情况下，我们使用的算法被称为 环路信念传播 (Loopy Belief Propagation, LBP)。\n核心思想: 尽管理论上不再保证准确性，但我们可以假装图没有环路，然后像在树上一样，让所有节点并行地、迭代地向邻居发送消息。\n步骤说明:\n初始化: 用随机值或均匀分布初始化所有消息。\n迭代更新: 在每一步迭代中，每个节点都根据它上一轮从邻居那里收到的消息，计算并更新它将要发送给邻居的新消息。\n重复: 重复这个过程，直到消息收敛（即消息值不再有明显变化）或者达到预设的最大迭代次数。\n计算信念: 算法停止后，用最后一次迭代的消息来估算每个节点的信念。\n结果: LBP 是一种近似推断算法。它不保证能收敛，即使收敛了，其计算出的信念也只是真实边际概率的一个近似值。然而，在实践中，LBP 在许多应用（如计算机视觉、纠错码领域）中都表现得非常出色，常常能给出很好的近似结果。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Bayes Nets -- Sampling(13)","url":"/2025/08/25/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/13/","content":"上一讲我们学习了变量消除等算法，它们能精确地计算出概率查询的结果。但我们也知道，精确推理在最坏情况下是NP难的，对于非常庞大和复杂的贝叶斯网络，精确计算仍然是不可行的。\n这一讲的核心思想是：当我们无法承担精确计算的巨大代价时，我们可以退而求其次，通过生成大量随机样本来“近似”地估算概率。这种方法被称为近似推理 (Approximate Inference)，而采样 (Sampling) 是实现它的核心技术。\n先验采样 (Prior Sampling)和拒绝采样 (Rejection Sampling)先验采样是最基础、最简单的采样方法, 它直接模拟贝叶斯网络的生成过程来创建一个完整的样本。\n算法流程为: \n\n按照贝叶斯网络的拓扑顺序（从父节点到子节点）遍历所有变量。\n\n对于每个变量 X，根据其条件概率表 （此时其所有父节点的值都已被采样确定），随机采样一个值赋给 X。\n\n重复此过程，直到所有变量都被赋值，就得到了一个完整的样本。\n\n\n显而易见, 这种方法非常低效，尤其是在处理带证据的查询时。如果我们想计算 ，而 $P(-t) 的概率只有1%。那么，先验采样生成的样本中，大约有99%的样本都会因为 T=+t 而与证据不符，这些样本最终都会被丢弃。为了得到足够多的有效样本，我们需要生成海量的总样本，造成巨大的计算浪费。\n而拒绝采样就是对先验采样的一个简单优化。它在生成样本的过程中，一旦发现某个变量的采样值与证据不符，就立刻停止并拒绝这个样本，然后重新开始一个新的。\n它避免了为那些注定要被丢弃的样本浪费后续的计算时间。然而, 虽然有所改进，但它仍然没有解决根本问题。在证据本身是小概率事件的情况下，绝大多数的采样尝试仍然会在早期就被拒绝，效率依然很低。\n似然加权 (Likelihood Weighting)这是本次讲义介绍的第一个真正实用的采样算法，它保证了生成的每一个样本都与证据相符。\n核心思想：我们不再随机地生成所有变量的值，而是强制将所有证据变量的值固定为观测到的值。但是，这种“强行设定”会扭曲样本的原始概率分布。为了修正这个偏差，我们为每个样本引入一个权重 (weight)。\n\n证据变量指的是值固定的变量, 例如中的C; 非证据变量是需要被采样的变量, 例如上述概率公式中的S。\n\n算法流程（以计算  为例）：\n\n初始化：将样本权重 w 设为 1.0。将证据变量 C 和 E 的值固定为 +c 和 +e。\n\n遍历变量（按拓扑序）：\n\n对于非证据变量（如 T 和 S）：像先验采样一样，根据其父节点的值进行随机采样。\n\n对于证据变量（如 C 和 E）：不进行采样。而是，将当前样本的权重 w 乘以该证据变量在其父节点取相应值时的条件概率。\n\n例如，当处理到 C 时，我们将权重更新为 w = w * P(+c | tⱼ)，其中 tⱼ 是 T 在当前样本中的采样值。这个乘法操作的含义是：“在给定父节点 tⱼ 的情况下，我们观测到 +c 这个证据的可能性有多大？”这个可能性就被作为权重的一部分。\n\n\n\n最终计算：在收集了足够多的带权样本后，我们不再是简单地计数，而是计算加权计数。例如，要计算 ，我们将所有 T=+t 的样本的权重相加，然后除以所有样本的总权重。\n\n\n原理推导首先我们给出结论，似然加权方法之所以具有一致性，是因为它通过为样本分配权重，巧妙地使加权后的采样分布等同于真实的全联合概率分布。这意味着，通过对这些加权样本进行求和或计算平均值，我们能够得到对真实概率分布的无偏估计。\n\n采样分布 \n\n这个公式描述了似然加权算法生成一个特定样本的概率：\n\n其中：\n\nz：需要采样的变量集合\ne：固定的证据变量集合\n显然，这两组变量的并集就是网络中的所有变量。\n\n解释：在似然加权中，我们只对非证据变量进行采样。这个公式是所有被采样变量()的条件概率乘积。例如，如果W是证据变量，那么C,S,R是被采样的变量。这个采样的分布就是。\n\n样本权重 \n\n这个公式定义了每个生成样本的权重：\n\n解释：这个权重是所有证据变量()的条件概率的乘积，每个证据变量的条件概率是基于其在当前样本中的父节点值。这个权重衡量了当前生成的样本与已知证据的一致程度。\n\n联合分布的一致性证明\n\n这是证明似然加权正确性的核心：\n\n解释：当我们将采样分布和样本权重相乘时，我们得到的是所有变量（包括被采样的和证据）的条件概率乘积。这正是贝叶斯网络中全联合概率分布的定义：\n\n当这两部分的结果相乘时，它们精确地、完整地重建了原始的全联合概率分布。这就是为什么加权后的采样分布能够无偏地代表真实的联合概率分布，从而保证了算法的一致性。因此，我们可以得出结论：\n\n示例分析\n网络结构：C→S, C→R, S→W, R→W\n\n查询目标：计算 P(C=T∣S=T,W=T)，即在洒水器打开(S=True)且草地湿润(W=True)的情况下，多云(C=True)的概率\n\n证据变量：e={S=T,W=T}\n\n非证据变量：Z={C,R}\n\n\n条件概率表如下: \nP(C):\n\n\n\nC\nP(C)\n\n\n\nT\n0.5\n\n\nP(S∣C):\n\n\n\nC\nP(S=T∣C)\n\n\n\nT\n0.1\n\n\nF\n0.5\n\n\nP(R∣C):\n\n\n\nC\nP(R=T∣C)\n\n\n\nT\n0.8\n\n\nF\n0.2\n\n\nP(W∣S,R):\n\n\n\nS\nR\nP(W=T∣S,R)\n\n\n\nT\nT\n0.99\n\n\nT\nF\n0.9\n\n\n下面展示似然加权生成一个样本的全过程: \n\n初始化\n\n\n证据：S=T,W=T\n样本权重：w=1.0\n\n\n处理变量 C\n\n\nC是非证据变量，需采样\n根据P(C)采样，结果：C=F\n当前样本：{C=F}，w=1.0\n\n\n处理变量 S\n\n\nS为证据变量(S=T)\n更新权重：w = w × P(S=T∣C=F) = 1.0 × 0.5 = 0.5\n当前样本：{C=F}，w=0.5\n\n\n处理变量 R\n\n\nR是非证据变量，需采样\n根据P(R∣C=F)采样，结果：R=T\n当前样本：{C=F,R=T}，w=0.5\n\n\n处理变量 W\n\n\nW为证据变量(W=T)\n更新权重：w = w × P(W=T∣S=T,R=T) = 0.5 × 0.99 = 0.495\n最终样本：{C=F,R=T}，w=0.495\n\n下面验证”加权采样分布 = 真实联合概率”：\n\n采样概率SWS(z,e)：\n\nSWS = P(C=F) × P(R=T∣C=F) = (1-0.5) × 0.2 = 0.1\n\n\n样本权重w(z,e)：\n\nw = P(S=T∣C=F) × P(W=T∣S=T,R=T) = 0.5 × 0.99 = 0.495\n\n\n两者相乘：\n\nSWS × w = 0.1 × 0.495 = 0.0495\n\n\n真实联合概率P(z,e)：\n\nP(C=F,S=T,R=T,W=T) = P(C=F) × P(S=T∣C=F) × P(R=T∣C=F) × P(W=T∣S=T,R=T)\n= 0.5 × 0.5 × 0.2 × 0.99 = 0.0495\n\n\n\n可以看出验证的结果是两者完全相等. \n重复上述过程多次后，使用以下公式计算：\nP(C=T∣S=T,W=T) ≈ 所有的样本的权重之和所有样本的权重总和\n这个例子展示了似然加权如何通过采样和加权来模拟真实的联合概率分布，从而计算出所需的条件概率。\n缺点与不足似然加权最大的不足之处是上游变量的值不受下游证据的影响。由于采样过程是前向的（从上游到下游），在对某个变量进行采样时，我们无法利用其子节点（下游）的证据信息。\n这意味着如果证据变量位于网络中许多独立的下游节点，每个证据都会使最终的权重呈指数级下降。这可能导致权重变得极小，从而引发数值上的不稳定问题。\n同时, 当大多数样本的权重都非常小时，最终的概率估计可能完全由一个或少数几个权重异常大的“幸运”样本决定。这会导致估计的方差很高，结果不稳定。\n这个局限性意味着似然加权在进行诊断式推理（从结果推断原因）时效率很低。它生成样本的方式和证据是脱节的，只能在最后通过权重来“亡羊补牢”，这导致了大量的计算浪费。\n\n    举个栗子 \n    \n      例如, 让我们构建一个非常简单的贝叶斯网络来模拟交通事故。\n\n上游变量 (原因): D (司机分心 - Distracted)，可能取值为 T (是) 或 F (否)。\n\n下游变量 (结果): A (发生事故 - Accident)，可能取值为 T (是) 或 F (否)。\n\n\n此时的网络结构为: D→A (司机分心会导致事故)\n假设的概率:\n\nP(D=T)=0.1 (在正常情况下，司机分心的概率是10%)\n\nP(A=T∣D=T)=0.6 (如果司机分心，发生事故的概率是60%)\n\nP(A=T∣D=F)=0.01 (如果司机没分心，发生事故的概率是1%)\n\n\n现在，我们有了一个下游证据：确实发生了一场事故 (A=T)。我们的目标是推断上游原因：司机当时分心的概率是多少？即 P(D=T∣A=T)。\n从直觉上，既然事故已经发生了，那么司机分心的可能性应该会远高于平时的10%。\n现在我们来看似然加权算法是如何一步步处理这个问题的，并观察其局限性。\n第1步：采样上游变量 D : 算法开始生成第一个样本。它遇到的第一个变量是 D。算法会问：“我应该如何为 D 采样？”\n由于采样过程是纯粹前向的，它完全看不到下游已经发生的事故证据 A=T。它唯一能依据的就是 D 的先验概率分布 P(D)。\n\n有 10% 的概率，它会采样得到 D=T。\n\n有 90% 的概率，它会采样得到 D=F。\n\n\n这就是问题的核心所在！尽管我们知道事故已经发生，这应该让我们更倾向于相信司机分心了，但算法在采样 D 的时候，完全忽略了这个信息。它依然会花费 90% 的精力去生成“司机没有分心”这种与证据非常不符的样本。\n第2步：计算权重\n在采样完 D 之后，算法才会考虑证据 A=T，并用它来计算权重。\n\n情况一 (90%的概率发生): 算法在上一步采样得到 D=F。此时的权重 w=P(A=T∣D=F)=0.01。这是一个极低的权重。\n\n情况二 (10%的概率发生): 算法在上一步采样得到 D=T。此时的权重 w=P(A=T∣D=T)=0.6。这是一个相对高很多的权重。\n\n\n通过上面的过程，我们可以清晰地看到这个局限性体现在哪里：\n\n盲目采样：算法在生成样本的“构思”阶段是盲目的。它像一个不知道最终结局的编剧，按照通常的概率写故事的开头（采样上游变量）。\n\n效率低下：算法花费了大量的计算资源（90%的样本）去探索那些几乎不可能导致已知证据（事故）发生的情况（司机没分心）。这些样本最终只会得到一个微不足道的权重，对最终结果的贡献极小。\n\n结果被“幸运样本”主导：最终的概率估计，几乎完全依赖于那少数（10%）采样到了 D=T 的“幸运样本”。如果样本总数不够多，我们可能采不到足够多的幸运样本，导致最终结果的方差很大，非常不稳定。\n\n\n\n    \n  \n\n吉布斯采样 (Gibbs Sampling)这是一种完全不同的采样策略，属于马尔可夫链蒙特卡洛 (Markov Chain Monte Carlo - MCMC) 方法的一种。\n\n为了理解吉布斯采样，首先要理解它所属的 MCMC 方法是什么意思: 蒙特卡洛 (Monte Carlo)指代任何依赖于重复随机采样的算法。而马尔可夫链 (Markov Chain)指的是一个状态序列，其中下一个状态的概率只取决于当前状态，而与之前的任何状态都无关\n\n与似然加权那种“一气呵成”的前向采样不同，吉布斯采样的核心思想是迭代式地修正（Iterative Refinement）。它不试图一次性生成一个完美的样本，而是从一个随机的、不完美的完整状态开始, 通过轮流地、逐个地对变量进行重新采样来不断修正这个状态。在经过足够多的修正后，这个状态就会稳定下来，并开始在真实的目标概率分布附近“徘徊”。此时的状态就可以被当作一个有效的样本。\n基本的算法流程如下：\n\n初始化：从一个随机的完整状态 x 开始（但证据变量的值是固定的）。\n\n迭代循环：\n\n选择一个非证据变量 Zᵢ。\n\n重新采样：将 Zᵢ 的当前值“清空”，然后根据所有其他变量的当前值，为 Zᵢ 重新采样一个新值。这个新值来自于条件概率分布 ，其中 mb(Z_i) 是 Zᵢ 的马尔可夫毯 (Markov Blanket)（即它的父节点、子节点、以及子节点的其他父节点）。\n\n\n\n收集样本：每完成一次（或若干次）这样的重采样，当前的状态 x 就被当作一个样本记录下来。\n\n\n其优势在于, 吉布斯采样在每次重采样时，都会同时考虑“上游”和“下游”的变量（通过马尔可夫毯），因此信息可以在整个网络中双向传播。这使得它在处理似然加权遇到的“下游证据”问题时通常表现得更好。\n示例分析网络结构如下: , , , \n查询目标: \n\n证据变量 (E):  (值是固定的)\n\n非证据变量 (Z):  (我们需要对它们进行迭代采样)\n\n概率表 (CPT): 我们继续使用之前例子中的概率。\n\n\n吉布斯采样 (Gibbs Sampling) 流程为: \n步骤 1: 初始化\n\n固定证据: 我们将 S 的值锁定为 T，将 W 的值锁定为 T。\n\n随机初始化: 我们为所有非证据变量  随机赋一个初始值。\n\n比如，我们随机选择 C=F 和 R=F。现在，我们的马尔可夫链的初始状态是：。\n\n\n\n步骤 2: 迭代循环: 我们将轮流对非证据变量 C 和 R 进行重新采样。\n首先是第 1 轮迭代\nPart A: 重新采样变量 C\n\n“冻结”其他变量: 将其他所有变量的值固定在当前状态：。\n\n计算条件概率: 我们需要计算 。\n\n\n\n\n\n\n\n\n归一化并采样:\n (约 5%)\n (约 95%)\n根据这个概率，我们为 C 重新采样。有极大概率我们会采样到 C=F。假设我们这次采样的结果就是 C=F。此时更新状态: 系统的当前状态现在是  (这次 C 的值恰好没变)。\nPart B: 重新采样变量 R\n\n“冻结”其他变量: 将其他变量的值固定在当前最新的状态：。\n\n计算条件概率: 我们需要计算 。\n\n\n\n\n\n\n归一化并采样:\n (约 22%)\n (约 78%)\n根据这个概率，我们为 R 重新采样。假设这次我们采样的结果是 R=F。然后更新状态: 第1轮迭代结束，系统的最终状态是 。\n在之后的第 2 轮迭代 (及后续)中, 我们会重复上面的过程。在第2轮迭代开始时，我们会先重新采样 C，此时它将基于  来计算条件概率（与第一轮相同）。然后，我们会根据新采样的 C 值和固定的证据，再次为 R 重新采样。\n随着迭代的进行，状态  会不断在各种可能的值之间跳转，但跳转的频率会符合它们在证据  下的真实后验概率。\n步骤 3: 收集样本并得出结论\n在经过足够长的”热身”期后，我们开始记录每一轮迭代结束时的状态。例如，我们可能收集到以下10,000个样本（只记录非证据变量）：\n\n\n\n…\n\n…\n最后，我们要回答查询 。我们只需要在收集到的10,000个样本中，计算出 C=T 的样本所占的比例即可\n理论证明, 只要这个过程重复足够多次，算法生成的样本分布最终会收敛到真实的后验概率分布 。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"HMMs -- Markov Chains, HMMs(14)","url":"/2025/08/25/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/14/","content":"之前的贝叶斯网络（如警报系统）处理的是一个“快照”式的静态世界。而现实世界是不断变化的，比如天气、股票价格、机器人的位置等等。马尔可夫模型就是用来描述这种随时间演化的随机过程的经典工具。\n马尔可夫模型可以被看作是一种链式的、无限长的贝叶斯网络。它专注于表示变量在时间维度上的依赖关系。现在我们从处理静态的、一次性的概率问题，转变为处理动态的、随时间演化的概率问题中。\n马尔可夫模型 (Markov Models)一个马尔科夫过程是指状态间的转移仅依赖于前n个状态的过程。这个过程被称之为n阶马尔科夫模型，其中n是影响下一个状态选择的（前）n个状态。最简单的马尔科夫过程是一阶模型，它的状态选择仅与前一个状态有关。\n\n这里要注意它与确定性系统并不相同，因为下一个状态的选择由相应的概率决定，并不是确定性的。\n\n在下面的内容中, 我们用一个一阶马尔可夫模型来描述一个随时间变化的状态序列。我们用一系列带时间戳的随机变量来表示状态，如 ，其中 假设 代表第 i 天的天气。\n根据一阶马尔科夫性质, 未来的状态只依赖于当前状态，而与过去的所有状态都无关。这也被称为“无记忆性 (memoryless property)”。数学表示为：\n\n直观理解：要知道明天的天气，我只需要知道今天的天气就够了，昨天、前天的天气信息对于预测明天不再提供额外帮助。\n\n我们要研究的模型的组成部分：\n\n初始分布 (Initial Distribution)：，描述了在时间起点（第0天）时，系统处于各个状态的概率。\n\n转移模型 (Transition Model)：，描述了从一个状态转移到下一个状态的概率。\n\n\n\n\n平稳性假设 (Stationary Assumption)：通常我们假设转移模型是不随时间变化的。也就是说，从“晴天”到“雨天”的概率，无论是今天到明天，还是明年到后年，都是一样的。这个假设使得我们只需要一张转移概率表就可以描述整个无限长的过程。\n\n在这样的情景下, 联合概率计算变为为：\n\n\n这个公式再次体现了紧凑表示的威力。我们只需要初始分布和一张转移表，就可以计算任意长度序列的概率，而不需要一个指数级大小的联合分布表。\n\n迷你前向算法 (The Mini-Forward Algorithm)这是在马尔可夫模型中进行时间推断 (Temporal Inference) 的基础算法。它的目标是计算在未来某个时间点 t，系统处于各个状态的概率分布 。其核心思想为：通过迭代的方式，一步步地将概率分布“向前推进”。\n递推公式：\n首先, 我们从已知的初始分布  开始。利用上面的公式，我们可以计算出 。然后，再用刚刚算出的  作为输入，计算出 。以此类推，直到我们计算出所需时间点的概率分布。\n稳态分布 (Stationary Distribution)一个自然的问题是：随着时间无限推移，这个系统最终会达到一个什么样的状态？这个最终的、不再变化的概率分布就是稳态分布。\n其定义如下: 一个概率分布  是稳态的，如果它在经过一次时间转移后保持不变。\n其数学表示为：\n利用稳态分布, 我们可以将稳态的定义代入迷你前向算法的递推公式中，得到一个关于未知稳态概率的方程组, 此时结合概率分布和为1的基本约束, 往往就能解出这个稳态概率的值。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"HMMs (Forward Algorithm, Viterbi Algorithm)(15)","url":"/2025/08/26/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/15/","content":"上一讲我们学习了如何对一个状态完全可观察的、随时间演化的系统进行建模和预测。然而，在现实世界中，我们往往无法直接观察到系统的真实状态，只能通过一些间接的、带有噪声的观测来进行推断。\n这一讲的核心就是解决这个问题：当系统的真实状态是“隐藏”的时，我们如何通过一系列的观测证据来推断这个隐藏状态？ 这个强大的工具就是隐马尔可夫模型 (Hidden Markov Models - HMMs)。\n\n马尔可夫模型 (Markov Model)：我们能直接看到每天的天气（状态）。隐马尔可夫模型 (Hidden Markov Model)：我们看不到真实的天气（状态是隐藏的），但我们每天能看到天气预报（证据/观测）。我们需要根据天气预报来推断真实的天气。\n\n隐马尔可夫模型 (Hidden Markov Models)\nHMM 在马尔可夫模型的基础上，增加了一层可观测的证据变量 (evidence variable)****\n\n状态变量 (State Variable)：，代表在时间 i 的隐藏状态（例如，真实天气）。\n\n证据变量 (Evidence Variable)：，代表在时间 i 的可观测证据（例如，天气预报）。\n\n\n因此, 一个平稳的 HMM 可以由三个部分紧凑地表示：\n\n初始分布：，和马尔可夫模型一样。\n\n转移模型：，和马尔可夫模型一样。\n\n传感器模型 (Sensor Model)：，这是新增的部分。它描述了在给定真实状态 Wᵢ 的情况下，观测到证据 Fᵢ 的概率。\n\n\n另一方面, 对于HMM模型, 由于我们往往无法直接得到隐藏状态, 所以更关注两个概念: \n\n置信度 (Belief) B(Wₜ): 在观测到截至时刻 t 的所有证据后，对状态 Wₜ 的概率分布。即, B(Wₜ) = P(Wₜ|f₁,…,fₜ)\n\n预测置信度 (Predicted Belief) B’(Wₜ): 在观测到截至时刻 t-1 的证据后，对状态 Wₜ 的概率分布。即, B’(Wₜ) = P(Wₜ|f₁,…,fₜ₋₁)\n\n\n更多时候, 我们使用  代表整个HMM, 其中:\n\nA：状态转移概率矩阵, 表示从一个隐藏状态转移到另一个隐藏状态的概率。\n如果有 N 个隐藏状态，A 是一个 N×N 的矩阵，其中 A[i][j] 表示从状态 i 转移到状态 j 的概率。\n\n\nB：观测概率矩阵（或称发射概率矩阵）: 表示在某个隐藏状态下，生成某个观测值的概率。\n如果有 M 个可能的观测值，B 是一个 N×M 的矩阵，其中 B[i][k] 表示在隐藏状态 i 下观察到观测值 k 的概率。\n\n\nπ：初始状态概率向量: 表示系统在时间 t=1 时处于每个隐藏状态的概率。\nπ[i] 是系统一开始处于状态 i 的概率。\n\n\n\n前向算法在隐马尔可夫模型中，我们拥有一系列随时间变化的、不可直接观测的隐藏状态（例如，每天的真实天气 ），以及在每个时间点上可以观测到的证据（例如，天气预报 ）。\n前向算法的核心目标是计算在观测到所有历史证据后，当前隐藏状态的概率分布。这个分布就是我们前面提到的置信度（Belief）。换句话说，算法要计算的是 ，即在已知从第1天到第t天的所有天气预报的情况下，第t天真实天气的概率分布。\n前向算法通过一个迭代过程，从  计算出 。这个过程可以分解为两个关键步骤：时间流逝更新(Time Elapse Update) 和 观测更新 (Observation Update)\n第一步：时间流逝更新 (Time Elapse Update)目标：从当前时刻 i 的置信度  推导出下一时刻 i+1 的预测置信度 。这一步相当于在没有看到新证据之前，对未来状态进行预测。\n推导过程如下：\n\n从定义出发：我们想要求解 。\n\n\n引入上一时刻的状态 ：为了将  引入计算，我们使用边缘化（Marginalization），对  的所有可能取值  进行求和: \n\n这个公式的意义是，”在已知历史证据的情况下，下一状态为  的概率”等于”在同样证据下，当前状态为某个具体值  且下一状态为  的所有可能情况的概率之和”。\n\n\n\n应用条件概率的链式法则：将联合概率  分解: \n\n\n这是条件概率的基本性质，将联合概率分解为两个条件的乘积。\n\n利用HMM的条件独立性假设：HMM假设未来的状态  仅依赖于当前状态 ，而与过去的所有证据  无关。这被称为马尔可夫性。\n\n因此， 可以简化为 ，这就是转移模型（Transition Model）。\n\n\n\n识别置信度：同时，我们发现  正是当前置信度  的定义。\n\n\n得出最终公式：将简化后的项代入，得到时间更新的最终形式: \n\n这个公式表明，对下一状态的预测是所有可能当前状态的置信度 ，按照它们各自转移到下一状态的概率  进行加权求和的结果。\n\n\n第二步：观测更新 (Observation Update)目标：在获得 i+1 时刻的新证据  后，将预测置信度  更新为真实置信度 。\n推导过程如下：\n\n从定义出发：我们想要求解 。\n\n\n应用贝叶斯法则（或条件概率定义）：\n\n我们将求解目标中的条件  移到分子中，形成一个联合概率。\n\n\n\n引入归一化技巧：分母  是一个常数，因为它不随  的变化而改变。为了简化计算，我们可以暂时忽略它，用比例关系  来表示: \n\n\n这意味着  的分布形状由分子决定，我们可以在所有计算完成后再进行归一化，使其概率和为1。\n\n接着再次应用链式法则：对分子进行分解: \n\n\n\n利用HMM的条件独立性假设：HMM假设当前证据  仅依赖于当前状态 ，而与过去的状态和证据无关。\n\n\n因此， 可以简化为 ，这被称为传感器模型（Sensor Model）。\n\n\n识别预测置信度：同时，我们发现  正是我们在第一步中计算出的预测置信度 。\n\n\n得出最终公式：将简化后的项代入，得到观测更新的最终形式, 即: \n\n这个公式的意义是，结合新证据后的置信度，与”预测置信度”和”新证据在该状态下的出现概率”的乘积成正比。如果观测到的证据在某个状态下很可能发生，那么这个状态的置信度就会相应提高。\n\n\n前向算法的核心通过将上述两个步骤结合起来，我们就得到了一个从  计算  的完整迭代公式：\n\n\n这个公式就是前向算法的核心。从初始置信度  开始，我们可以通过这个公式逐步递推，计算出任何时刻 t 的置信度分布 。在计算出每个  的非归一化值后，只需将所有可能状态的概率值相加，再用每个值除以这个总和，即可完成归一化，得到最终的概率分布。\n示例分析我们首先需要定义模型的三个核心部分：初始分布、转移模型和传感器模型。\n\n初始置信度 表示第0天的天气概率分布。\n\n\n\n\n\n\n\n\n\nsun\n0.8\n\n\nrain\n0.2\n\n\n\n转移模型 表示从今天的天气转移到明天天气的概率。\n\n|   |  |  ||—–|——-|————|| sun | sun   | 0.6        || sun | rain  | 0.4        || rain| sun   | 0.1        || rain| rain  | 0.9        |\n\n传感器模型 表示在某种真实天气下，观测到特定天气预报的概率。\n\n|   |    |  ||—–|——-|———–|| sun | good  | 0.8       || sun | bad   | 0.2       || rain| good  | 0.3       || rain| bad   | 0.7       |\n我们的目标是计算第1天的置信度 ，假设我们观测到第1天的天气预报是”good” 。\n整个计算过程遵循前向算法的两个核心步骤：时间流逝更新和观测更新。\n第一步是时间流逝更新（预测）: 根据第0天的置信度 ，预测第1天的天气概率分布 ，此时我们尚未考虑第1天的天气预报。\n公式为：\n第1天是晴天的预测概率，等于”第0天是晴天且第1天也是晴天”的概率，加上”第0天是雨天但第1天是晴天”的概率。\n\n\n经过时间更新后，我们得到的预测置信度为：\n\n\n\n\n\n\n\n\nsun\n0.5\n\n\nrain\n0.5\n\n\n这表明，在不考虑任何新证据的情况下，我们预测第1天晴天和雨天的概率各占一半。\n第二步是观测更新（修正）: 现在我们引入观测证据 ，用它来修正我们的预测，得到最终的置信度 。\n公式为：\n\n\n在第二步之后, 我们得到了未经归一化的置信度值：sun为0.4，rain为0.15。\n第三步是归一化, 将上述结果转换为合法的概率分布（即各项概率之和为1）。\n计算总和：0.4 + 0.15 = 0.55\n归一化：\n经过完整的计算，我们得到第1天的最终置信度分布  如下：\n\n\n\n\n\n\n\n\nsun\n8/11 (≈ 0.727)\n\n\nrain\n3/11 (≈ 0.273)\n\n\n最开始，我们对第1天的天气预测是晴雨概率各占50% 。然而，当我们观测到”预报为good”这个证据后，我们对”第1天是晴天”的信心大大增加，从50% (1/2) 上升到了约73% (8/11)。这完全符合直觉，因为晴天时出现”good”预报的概率（0.8）远高于雨天时（0.3）。这个例子清晰地展示了前向算法是如何融合历史信息和当前证据来动态更新对隐藏状态的信念的。\n维特比算法（Viterbi Algorithm）前向算法回答的是“在时刻 N，最可能的状态是什么？”。而 Viterbi 算法回答的是一个不同但同样重要的问题：“给定从时刻1到 N 的所有观测，最可能的状态序列是什么？”\n换句话说，算法旨在找到一个完整的隐藏状态序列（一条路径），使得这个序列在给定观测证据的情况下出现的概率最大 。\n公式化表达即为寻找最可能的隐藏状态序列 $x_{1:N}^。x_{1:N}^ = \\arg\\max_{x_{1:N}} P(x_{1:N} | e_{1:N})$\n\n想象一下，你每天都会收到一份天气预报（观测证据），但你无法直接知道每天的真实天气（隐藏状态）。几天过后，你手上有一系列的预报记录，比如“（好，好，坏）”。你现在想推断出这几天最可能发生的真实天气序列是什么。是“（晴，晴，雨）”还是“（晴，雨，雨）”？\n\n维特比算法采用动态规划来解决这个问题。其核心思想可以概括为一句话：\n“如果要找在时刻 t 到达状态 A 的最优路径，我们只需要知道在时刻 t-1 到达所有可能前置状态（A, B, C, …）的最优路径即可。”\n我们不需要关心到达状态 B 或 C 的完整历史路径是什么，只需要知道它们各自由最优路径到达自己的概率是多少。然后我们就可以计算从 A 到 A, 从 B 到 A 和从 C 到 A 的新得分，选择其中更高分的那条作为到达 A 的最优路径。\n基本步骤假设我们有一个隐藏马尔可夫模型，它由以下要素组成：\n\n隐藏状态集合 ：我们无法直接观察到的状态。\n\n观测状态集合 ：我们能够直接观察到的结果。\n\n初始状态概率 ：模型在时间 t=1 时处于每个隐藏状态的概率。\n\n状态转移概率矩阵 ：从隐藏状态  转移到  的概率。\n\n发射概率矩阵 ：在隐藏状态  下观察到观测  的概率。\n\n\n维特比算法的目标是找到最有可能的隐藏状态序列 ，使得  的值最大，其中  是已知的观测序列。\n维特比算法分为四个主要步骤：初始化、递归计算、终结和回溯。\n步骤一：初始化\n在第一个时间步 t=1，我们计算到达每个隐藏状态  的最大概率。这个概率是该状态的初始概率  与在该状态下观测到第一个观测值  的发射概率  的乘积。\n操作：对于每个隐藏状态 ，计算维特比变量 : \n这一步是为动态规划的起点做准备。我们计算了所有可能的路径中，在时间 t=1 结束于状态  的最大概率。\n步骤二：递归计算\n从时间步 t=2 到 T，我们对每个时间步和每个隐藏状态进行迭代计算。对于每个状态 ，我们需要考虑所有从上一个时间步 t-1 的状态  转移到  的可能性，并选择其中概率最大的路径。\n操作：对于每个时间步 t (2≤t≤T) 和每个隐藏状态 ，计算维特比变量  和回溯指针 。\n数学公式:\n 的计算： 寻找了从前一个时间步的任意状态  到达当前状态  的最可能路径。然后将其乘以在当前状态  下观测到  的概率 ，得到在时间 t 结束于状态  的整体最大概率。\n 的计算：它记录了在时间 t 达到状态  的最可能路径是从时间 t-1 的哪个状态  转移过来的。这个回溯指针是最终重建路径的关键。\n步骤三：终结在处理完所有时间步后，我们找到最后一个时间步 T 中，概率最大的那个状态，这将是我们的最优路径的终点。\n操作：找到在时间 t=T 时，所有维特比变量  中的最大值。\n数学公式：\n\n解释：$P^是整个观测序列下，最有可能隐藏状态序列的概率。q_T^$ 是该最优序列的最后一个状态。\n步骤四：回溯\n这是重建最优路径的关键步骤。我们从最后一个状态  开始，利用之前记录的回溯指针  逆向推导出整个序列。\n操作：从 t=T 向 t=1 循环，通过回溯指针确定前一个状态。\n数学公式：\n\n这一步利用了动态规划的特性。由于我们在每一步都记录了最优的前驱状态，我们只需要从终点倒推，就能唯一地确定一条由局部最优解构成的全局最优路径。\n示例分析让我们用一个经典的”天气-心情”例子来演示维特比算法。\n\n隐藏状态：晴天雨天\n\n观测序列：开心难过开心\n\n\n参数：\n\n初始概率 ：晴天, 雨天\n\n转移概率 ：\n\n晴天晴天\n\n晴天雨天\n\n雨天晴天\n\n雨天雨天\n\n\n\n发射概率 ：\n\n开心晴天\n\n难过晴天\n\n开心雨天\n\n难过雨天\n\n\n\n\n计算过程如下：\n\n时间步  (观测：开心): 初始概率乘发射概率来实现初始化\n\n晴天晴天晴天开心\n雨天雨天雨天开心\n这样, 我们计算了第一天是晴天（概率0.48）和雨天（概率0.12）的各自最大概率路径。\n\n时间步  (观测：难过): 计算  和 \n\n晴天晴天晴天晴天雨天雨天晴天晴天难过\n\n晴天晴天 （因为 ）\n雨天晴天晴天雨天雨天雨天雨天雨天难过\n\n雨天晴天 （因为 ）\n在第二天，我们分别计算了结束于”晴天”和”雨天”的两种可能路径的最大概率。我们发现，要到达”晴天”状态，最可能的前一天状态是”晴天”；要到达”雨天”状态，最可能的前一天状态也是”晴天”。\n\n时间步  (观测：开心): 计算  和 \n\n晴天晴天晴天晴天雨天雨天晴天晴天开心\n\n晴天晴天\n雨天晴天晴天雨天雨天雨天雨天雨天开心\n\n雨天雨天\n\n终结和回溯\n\n比较 晴天 和 雨天, 有\n因此，最优路径的最后一个状态是 晴天。\n最后我们回溯路径即可得到结果：\n晴天\n$q_2^=\\psi_3(q_3^)=\\psi_3(晴天)=晴天$\n$q_1^=\\psi_2(q_2^)=\\psi_2(晴天)=晴天$\n因此, 最有可能的隐藏状态序列是：{晴天, 晴天, 晴天}。\n应用领域维特比算法因其高效和准确性，在许多领域有广泛应用，例如：\n\n语音识别：根据声学模型（隐藏状态）和声音信号（观测）找到最可能的单词序列。\n\n自然语言处理：\n\n用于词性标注（Part-of-Speech Tagging），根据单词序列（观测）找到最可能的词性序列（隐藏状态）。\n用于命名实体识别（Named Entity Recognition），根据文本序列（观测）找到最可能的实体序列（隐藏状态）。\n\n\n生物信息学：用于基因识别，根据 DNA 序列（观测）找到编码区和非编码区（隐藏状态）。\n\n无线通信：在编码理论中用于信道解码。\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Particle Filtering, Utility Theory(16)","url":"/2025/08/26/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/16/","content":"我们已经学习了隐马尔可夫模型（HMMs），但当状态空间变得非常大或连续时，精确的前向算法在计算上变得不可行。粒子滤波提供了一种强大的近似推理方法来解决这个问题, 是HMMs的“采样”版本。。\n粒子滤波粒子滤波的核心目标是，在一个动态系统中，根据一系列带噪音的、不完整的观测数据，实时地、近似地追踪一个我们无法直接看到的隐藏状态。\n它专门用于解决那些状态空间巨大或连续的问题，例如：\n\n机器人定位：机器人在一个连续的2D或3D空间中的精确位置。\n\n物体追踪：追踪雷达信号中飞机的精确位置和速度。\n\n金融预测：追踪一个经济体背后那个复杂且不可见的“真实状态”。\n\n\n在这些问题中，像前向算法那样的精确算法因为需要处理无限或天文数字级别的状态而完全不可行。\n其核心思想是, 用“群体智慧”近似“真实情况”, 放弃了为每个可能状态计算精确概率的想法，转而采用一种基于采样的“群体模拟”思想\n在HMM模型下的步骤\nHMM是描述问题的“理论框架”，而粒子滤波则是解决这个框架下特定问题的一种实用算法\n\n首先, 我们再次阐述HMM的模型结构:\n\n隐藏状态 ()：我们关心但无法直接观测的变量（例如，物体的真实位置）。\n\n观测证据 ()：我们能实际测量到的数据（例如，摄像头的读数）。\n\n初始分布 ()：描述了在最开始时，隐藏状态的概率分布。\n\n转移模型 ()：描述了隐藏状态随时间演变的规律（例如，物体如何从一个位置移动到另一个位置）。\n\n发射模型 ()：描述了在某个隐藏状态下，产生特定观测证据的概率（例如，在某个真实位置，摄像头读数为某值的概率）。\n\n\nHMM的目标之一：计算在给定所有历史观测证据  的情况下，当前隐藏状态  的概率分布，即 。当状态空间巨大时，粒子滤波就是实现这一目标的强大工具。\n而粒子滤波的每一步, 恰恰精确地对应了HMM框架的每一个组成部分：\n\n初始化 (Initialization)算法操作：生成 N 个初始粒子，每个粒子代表一个对初始隐藏状态的猜测。\n\nHMM中的对应：这个过程直接使用了HMM的初始分布 。算法会根据  来进行采样。如果初始分布是均匀的，粒子就会被均匀地撒在所有可能的状态上；如果初始分布集中在某个区域，那么大部分粒子就会被生成在该区域。\n\n提议 (Proposal)算法操作：对于现有的每一个粒子，预测它在下一个时间步的位置。这也被称为时间流逝更新。\n\nHMM中的对应：这个预测过程完全由HMM的转移模型  驱动。对于一个当前状态为  的粒子，算法会从条件概率分布  中随机采样一个新的状态 ，作为该粒子移动后的新位置。\n\n加权 (Weighting)算法操作：在粒子完成移动后，我们获取了新的观测证据 。现在，我们需要根据这个新证据为每一个粒子打分（赋予权重）。\n\nHMM中的对应：这个打分过程精确地使用了HMM的发射模型 。对于一个预测位置为  的粒子，它的权重正比于 。这意味着，如果一个粒子的预测位置能够很好地”解释”我们看到的证据，它的权重就高；反之则权重低。\n\n重采样 (Resampling)算法操作：淘汰低权重的粒子，复制高权重的粒子，生成新一代的粒子群。\n\nHMM中的对应：这一步是整个滤波（Filtering）过程的核心。它将由发射模型提供的信息（即权重）”吸收”到粒子群中，使得新的粒子群能够更好地近似后验概率分布 。具体步骤是从旧的粒子中进行有放回的随机抽样来生成新100个粒子。一个粒子被抽中的概率正比于它的权重。这是实现”用观测来修正预测”的关键机制。\n效用与决策 (Utilities &amp; Decision Networks)这部分将我们从单纯的“信念推理”带入到“理性决策”的领域。\n理性偏好 (Rational Preferences)核心问题：一个理性智能体应该如何做出选择？讲义指出，它必须遵循最大化期望效用 (Maximum Expected Utility) 的原则。\n换句话说, 它必须遵从以下五条理性的公理 (Axioms of Rationality)：\n\n可排序性 (Orderability)：对于任意两个选项，总能做出偏好判断。\n\n传递性 (Transitivity)：偏好不能形成循环。\n\n连续性 (Continuity)：对于不同偏好的选项，总能找到一个概率组合使其等价。\n\n可替代性 (Substitutability)：如果两个选项等价，那么它们在更复杂的选择中可以相互替换。\n\n单调性 (Monotonicity)：如果更喜欢A而不是B，那么在其他条件相同时，会选择获得A概率更高的那个选项。\n\n\n如果一个智能体的偏好满足这些公理，那么必然存在一个实值效用函数 U，使得智能体的行为可以被描述为在最大化这个函数的期望值。\n决策网络 (Decision Networks)决策网络是贝叶斯网络的一个扩展，它将概率、行动和效用整合到了一个统一的图形模型中, 可以被看作是贝叶斯网络和期望最大化 (Expectimax) 算法的结合体 。\n其具有三种节点类型：\n\n机会节点 (Chance Nodes)：椭圆形，代表随机变量，和贝叶斯网络中的节点一样。\n\n行动节点 (Action Nodes)：矩形，代表智能体可以选择的行动。\n\n效用节点 (Utility Nodes)：菱形，代表最终的效用值。效用节点是决策网络的核心，它没有子节点，其父节点通常是行动节点和一些机会节点 。它的作用是根据其父节点的状态（即采取的行动和随机事件的结果）输出一个数值，这个数值代表了智能体在该情况下的“满意度”或“回报” 。\n\n\n使用决策网络的最终目标是选择能带来最大期望效用 (Maximum Expected Utility, MEU) 的行动。这个过程可以通过一个清晰的、分步骤的算法来实现：\n\n第一步：实例化证据并进行概率推理(计算)\n\n首先，我们将所有已知的证据（例如，天气预报是“坏”）在网络中进行实例化 。然后，利用贝叶斯网络的推理算法（如变量消除或采样），计算出效用节点的所有机会父节点的后验概率分布 。\n这一步的目的是更新我们对世界状态的信念。例如，当我们得知天气预报是“坏”时，下雨的概率会比不知道预报时更高。我们需要这个更新后的概率来更准确地评估行动的后果。\n\n第二步：为每个可能的行动计算期望效用接下来，我们遍历行动节点中的每一个可能行动。对于每个行动 ，我们根据第一步计算出的后验概率，计算其期望效用  。计算公式如下：\n\n\n其中：\n 是当前考虑的行动。\n 是已知的证据。\n 是效用节点的所有机会父节点的各种状态组合。\n 是在给定证据  的情况下，这些机会节点处于特定状态组合的后验概率。\n 是在采取行动  且机会事件为  时，效用节点给出的具体效用值。\n这个公式本质上是在计算一个加权平均值 。我们将每种可能结果的效用值，乘以该结果发生的概率，然后将所有可能结果的加权效用相加，就得到了采取该行动的平均期望回报。\n第三步：选择最优行动\n最后，我们比较所有行动的期望效用，并选择那个能够产生最高期望效用的行动 。这个最高的期望效用值就是 。\n\n这一步是最终的决策环节。作为一个理性的智能体，我们选择那个在统计上最有可能给我们带来最佳结果的行动。\n示例分析\n这个例子的目标是，在已知”天气预报是坏消息” () 的前提下，计算出能带来最大期望效用 (MEU) 的行动。\n第一步：明确已知信息:\n在采取行动前，我们已经通过贝叶斯网络推理获得了关键信息, 即后验概率 (Posterior Probabilities)给定预报为”坏”，实际天气的概率分布如下。\n\n\n\n\n\n\n效用表 (Utility Table)：不同行动和天气组合下的效用值如下。\n\n (不带伞，天晴，完美)\n\n (不带伞，下雨，最糟)\n\n (带伞，天晴，有点累赘)\n\n (带伞，下雨，非常明智)\n\n\n第二步：计算每个行动的期望效用 (EU)\n我们使用期望效用公式  来分别评估两个行动。\n\n行动：不带伞 (leave)这个行动的期望效用是两种天气结果（晴天和雨天）的效用与其相应概率的加权和。\n\n\n\n\n这个计算告诉我们，在预报为坏的情况下，如果不带伞，我们平均可以期望获得 34 个单位的效用。这个值综合了 34% 的概率获得 100 效用和 66% 的概率获得 0 效用的情况。\n\n行动：带伞 (take)同理，我们计算带伞这一行动的期望效用。\n\n\n\n\n这个计算表明，如果带伞，我们平均可以期望获得 53 个单位的效用。它平衡了”天晴时带伞有点麻烦”（效用20）和”下雨时带伞非常有用”（效用70）这两种可能性。\n第三步：选择最优行动最后一步是比较两个行动的期望效用，并选择值最大的那个。\n\n\n结论：因为行动”带伞 (take)”的期望效用 (53) 大于”不带伞 (leave)” (34)，所以理性的决策是带伞\n完美信息价值 (Value of Perfect Information - VPI)在决策时，我们常常面临一个问题：是否值得花成本去获取更多的信息？\n完美信息的价值 (VPI) 就是一个用来量化“新信息能给我们的决策带来多大好处”的工具 。VPI 的核心思想是计算在获取新证据之前和获取新证据之后，最大期望效用的差值 。\nVPI 的计算公式定义为：\n其中：\n\n 是仅基于当前证据  所能得到的最大期望效用。\n 是在决定观察新证据变量  （但还不知道  的具体值）之后，我们期望能得到的最大期望效用。它的计算方式是：\n\n这里  是观察到新证据具体值为  的概率， 是当我们同时拥有旧证据  和新证据  时的最大期望效用。\n\n\n\n示例分析 : 是否要看天气预报？假设我们一开始没有任何证据（ 为空集 ），我们想知道”看天气预报”这个信息的价值是多少。\n下面我们先计算无证据时的 MEU：\n首先，我们用先验概率  计算 。假设  。\n\n\n 。\n下面我们计算获取新信息后的期望 MEU：\n我们需要计算如果我们看了天气预报 (F)，期望的 MEU 是多少。我们需要知道  的分布，假设 ， 。\n我们已经计算出  。假设我们同样可以计算出  。\n那么，期望的 MEU 是：\n\n\n计算 VPI：  。\n这个结果意味着，天气预报这个”完美信息”平均能给我们的决策带来 7.78 个效用单位的提升。如果获取预报的成本（例如时间、金钱）低于这个值，那么我们就应该去获取它 。\nVPI 的重要性质\n非负性：。获取新信息永远不会让你的期望决策变得更糟，最差也是保持不变 。\n非可加性：。通常情况下，不同信息之间的价值不是简单相加的，因为它们可能包含重叠或互补的信息 。\n顺序无关性：。获取一组信息的总价值与你观察它们的顺序无关 。\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- Informed Search - A* and Heuristics","url":"/2025/08/08/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/3/","content":"无信息搜索（如UCS）虽然能保证找到最优解，但它像是在黑暗中摸索，会向所有方向均匀扩展，效率低下。如果我们能给智能体一些关于“目标大概在哪个方向”的提示，搜索就能变得更高效。这种提示就是启发式 (Heuristics)。\n启发式 (Heuristics)启发式是一个函数 h(n)，它接收一个状态 n 作为输入，输出一个对“从状态 n 到达目标的剩余成本”的估计值。\n启发式的来源：松弛问题 (Relaxed Problem)好的启发式通常来自于对原问题的“松弛” (Relaxed Problem)\n松弛问题是通过移除原问题的一些约束得到的简化版问题。下面以吃豆人寻路示例：\n\n原问题：吃豆人必须在迷宫中穿行，不能穿墙。\n\n约束：不能穿墙。\n\n松弛：我们移除“不能穿墙” 这个约束。\n\n松弛问题：在一个没有墙的开放网格中，从A点到B点的最短路径是什么？\n\n松弛问题的精确解：这个解就是曼哈顿距离 (|x₁ - x₂| + |y₁ - y₂|) 。\n\n\n原问题比松弛问题有更多的约束（比如有墙），所以在原问题中从 n 到目标的真实最短路径成本 ，必然大于或等于在松弛问题中的最短路径成本。\n因此，松弛问题的解 h(n) 永远不会高估真实成本，即 。这正是我们稍后会讲到的可采纳性 (Admissibility) 的关键特征。\n综上所述, 对应吃豆人问题, 曼哈顿距离 (|x₁ - x₂| + |y₁ - y₂|) 是在原问题的松弛版（无墙迷宫）中的精确解，因此它可以作为原问题（有墙迷宫）的一个估计值。这种通过简化问题来获得估计值的方法，是设计启发式函数的一条重要原则。\n两种有信息搜索策略有信息搜索策略 (Informed Search) 是基于启发式信息来指导搜索的策略。\n贪婪/贪心搜索 (Greedy Search)这是一种完全由启发式驱动的“短视”策略。它在选择下一个要扩展的节点时，只看 h(n) 的值，即它认为“离目标最近”的那个 。\n前沿表示：和UCS一样使用优先队列，但优先级由 h(n) 决定 。\n它的特点是不完备且不最优：贪婪搜索完全不考虑已经走过的路径成本 g(n)。它可能会被一个看似离目标很近、但实际上需要绕远路的陷阱所吸引，从而找不到解，或者找到一个成本很高的解。\nA* 搜索 (A* Search)A* 搜索结合了 UCS 和贪婪搜索的优点，它选择估计的总成本  最低的节点进行扩展, 这个函数同时考虑了过去和未来 。\n这里的\n\n：从起点到当前节点的实际已知成本（UCS的部分）。\n\n：从当前节点到目标的估计剩余成本（贪婪搜索的部分）。\n\n\nA* 搜索的特点是完备且最优（在特定条件下）, 选择的是估计总路径成本最低的节点, 被誉为“集大成者”，因为它既考虑了已付出的代价（通过 g(n)），又具有前瞻性（通过 h(n)），因此在效率和最优性上取得了完美的平衡。\n启发式的性质A* 搜索的完备性和最优性并非无条件的，它严重依赖于启发式函数 h(n) 的质量。\n可采纳性 (Admissibility)一个启发式是可采纳的，当且仅当它从不高估到目标的真实成本。即对于所有节点 n，$0 \\le h(n) \\le h^(n)，其中h^(n)$ 是从 n 到目标的真实最低成本。\n可采纳性是保证 A* 树搜索 (Tree Search) 最优性的关键条件。\n一个“乐观”的启发式函数是可采纳的, 同时一个好的启发式函数也要在足够乐观的同时尽可能客观(即启发式函数要在较小的里面挑选更大的)。它可能会告诉你“目标(启发函数值)比实际更近”，但绝不会告诉你“目标比实际更远”。这种乐观使得A*算法不会过早地放弃一条可能通往最优解的、当前看起来成本较高的路径。\n一致性 (Consistency)一致性是一个更强的条件。它要求启发式不仅不能高估到目标的总距离，也不能高估任意一步的成本。对于任意节点 A 和其子节点 C，从 A 到 C 的启发式成本差，不应大于 A 到 C 的实际行动成本 。数学上表示为： 。\n一致性是保证 A* 图搜索 (Graph Search) 最优性的关键条件 。\n支配性 (Dominance)如果对于所有节点 n，启发式 ，那么我们说  支配 。\n在所有可采纳的启发式中，值越大的（即越接近真实成本 $h^(n)$ 的）启发式越好，因为它能提供更精确的引导，让 A 扩展更少的节点。\n组合启发式的思想：多个可采纳（或一致）的启发式的最大值，仍然是一个可采纳（或一致）的启发式，并且它会支配所有单个的启发式。这为我们构建更好的启发式提供了一种实用的方法。\n\n图搜索 (Graph Search)在之前的笔记中，我们讨论的算法（DFS, BFS, UCS, A*）都可以在两种模式下运行：树搜索模式和图搜索模式。\n树搜索 (Tree Search)：它不检查是否重复访问了同一个状态。\n图搜索 (Graph Search)：这是对树搜索的优化。它会记录所有已经访问并扩展过的状态，以避免重复工作。\n从中可见, 树搜索有两个严重的问题，尤其是在状态空间图包含环路 (cycles) 或多条路径到达同一状态时：\n\n无限循环：如果状态空间中有环（例如 A -&gt; B -&gt; C -&gt; A），一个简单的树搜索（特别是DFS）可能会永远地在这个环里打转，永远找不到解，导致算法不完备 。\n\n冗余工作：即使没有环路，也常常存在多条不同的路径可以到达同一个状态。树搜索会把每一条路径都当作一个全新的节点来探索，导致对同一个状态及其后续路径进行大量重复计算，极大地浪费时间 。\n\n\n而图搜索通过在算法中维护一个额外的集合，通常称为 reached 或 closed set（已达集合）来优化这个问题, 其步骤如下: \n\n初始化一个空的 reached 集合。\n\n当算法从前沿 (frontier) 中取出一个节点准备扩展时，首先检查该节点所代表的状态是否已经在 reached 集合中。\n\n\n\n如果在，则跳过这个节点，不进行扩展，直接进入下一次循环。\n\n如果不在，则将该状态加入 reached 集合，然后正常扩展该节点，将其子节点加入前沿。\n\n\n通过这个简单的机制，图搜索保证了每个状态最多只会被扩展一次，从而避免了无限循环和冗余计算。\n然而, 图搜索的一个附带问题是，即使使用可采纳的启发式，它也往往会破坏 A* 的最优性, 例如下图:\n在上面的例子中，很明显最佳路径是遵循 S → A → C → G，总路径成本为 1+1+3=5。通往目标的其他唯一路径 S → B → C → G 的路径成本为 1+2+3=6。然而，由于节点 A 的启发式值远大于节点 B 的启发式值，节点 C 首先沿着第二条次优路径作为节点 B 的子节点被展开。然后它被放入”已到达”集合中，因此 A 图搜索在它作为节点 A 的子节点访问时未能重新展开它，所以它永远找不到最优解。因此，为了在 A 图搜索下保持最优性，我们需要比可采纳性更强的性质, 也就是之前提到的一致性. \n\n这也为我们设计更加严格的启发式函数提出了挑战\n\n下图为一个启发式函数的设计示例\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- State Spaces, Uninformed Search","url":"/2025/08/04/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/2/","content":"为了让一个理性的规划智能体能够行动，我们首先需要一种数学化的方式来描述它所处的环境 。搜索问题 (Search Problem) 的核心就是：给定智能体当前的状态，如何以最优的方式找到一条路径，到达满足其目标的新状态 。\n搜索问题的形式化定义一个搜索问题由以下六个核心要素构成 ：\n\n状态空间 (State Space)：在一个特定世界中所有可能状态的集合 。\n行动集合 (Actions)：在每个状态下，智能体可以采取的一系列行动 。\n转移模型 (Transition Model)：描述了当在当前状态下采取一个特定行动后，会转移到哪个新状态 。\n行动成本 (Action Cost)：从一个状态转移到另一个状态所产生的代价 。\n初始状态 (Start State)：智能体最初所处的状态 。\n目标测试 (Goal Test)：一个函数，用于判断给定的状态是否是目标状态 。\n\n状态空间 (State Space)状态空间 (State Space) 是搜索问题中最重要的概念之一 。它定义了在特定世界中所有可能的状态 。其中主要区分两种状态空间：世界状态 vs. 搜索状态\n\n世界状态 (World State) 包含了一个状态的所有信息 。    \n搜索状态 (Search State) 只包含对规划必要的信息，这主要是为了节省空间 。\n\n状态空间图和搜索树(State Space Graph and Search Tree)这是理解搜索算法如何工作的两个关键结构。\n\n状态空间图 (State Space Graph)\n\n节点是状态，有向边是行动 。\n\n每个状态在图中只出现一次 。\n\n\n\n搜索树 (Search Tree)\n\n节点不仅代表一个状态，更代表一条从初始状态到达该状态的完整路径 。\n\n由于从起点到同一个状态可能有多条路径，因此同一个状态可能在树中出现多次 。\n\n算法在解决问题时，会按需 (on-demand) 构建搜索树，只存储和扩展当前需要处理的节点（即“前沿”），从而应对其巨大的潜在规模 。\n\n\n\n\n\n无信息搜索 (Uninformed Search)当智能体对目标状态的位置没有任何先验知识时，它只能采用无信息搜索策略 。这些策略都基于上述提到的通用的树搜索 (Tree Search) 框架，即维护一个待扩展节点的前沿 (frontier)，并根据不同策略选择下一个要扩展的节点 。\n树搜索框架 (Tree Search)树搜索不是一次性构建整个搜索树，而是通过维护和扩展前沿来逐步、动态地构建这棵树，这个框架可以被概括为以下几个步骤：\n1.初始化前沿：搜索开始时，将包含初始状态的节点（即搜索树的根节点）放入前沿。这是我们探索的起点 。\n2.循环探索：只要前沿不为空（意味着还有未探索的路径），就继续循环。如果前沿为空，则说明所有可达路径都已探索完毕，但仍未找到目标，因此搜索失败 。\n3.选择并移除节点：根据预设的策略，从前沿中选择一个节点并将其移除。正是这个选择策略，决定了搜索算法是DFS、BFS还是UCS。\n4.目标测试：检查刚刚移除的节点是否包含目标状态。如果是，那么从该节点回溯至根节点的路径就是我们找到的解决方案，搜索成功结束 。\n5.扩展节点：如果上一步的节点不是目标，我们就对其进行“扩展”。这意味着，我们会考虑从该节点所代表的状态出发，可以执行的所有行动，并为每个行动在原先的节点基础上加上一个新的子节点（代表新的路径和新的状态）。然后，将这些新生成的子节点加入到前沿中，等待未来的探索 。\n\n    示例 \n    \n      假设我们的目标是从城市 S 到达城市 G。\n\n初始状态: 前沿 (Frontier): [ Node(S) ] , 此时我们的探索列表里只有一个起点。\n\n第 1 轮循环:\n\n移除: 算法从前沿中选择并移除 Node(S)。\n\n当前前沿: [ ] (暂时为空)\n\n目标测试: S 是不是目标 G？不是。\n\n扩展: 我们对 Node(S) 进行扩展。假设从 S 可以到达 A 和 B。\n\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;A) 和 Node(S-&gt;B)。\n\n加入前沿: 将这两个新节点加入前沿。\n\n当前前沿: [ Node(S-&gt;A), Node(S-&gt;B) ]\n\n\n\n第 2 轮循环 (假设使用BFS策略，选择最浅的节点):\n\n移除: 算法从前沿中选择并移除 Node(S-&gt;A)。\n\n当前前沿: [ Node(S-&gt;B) ]\n\n目标测试: A 是不是目标 G？不是。\n\n扩展: 我们对 Node(S-&gt;A) 进行扩展。假设从 A 可以到达 C 和 D。\n\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;A-&gt;C) 和 Node(S-&gt;A-&gt;D)。\n\n加入前沿: 将这两个新节点加入前沿。\n\n当前前沿: [ Node(S-&gt;B), Node(S-&gt;A-&gt;C), Node(S-&gt;A-&gt;D) ]\n\n\n\n第 3 轮循环 (继续使用BFS策略):\n\n移除: 算法从前沿中选择并移除 Node(S-&gt;B)。\n\n当前前沿: [ Node(S-&gt;A-&gt;C), Node(S-&gt;A-&gt;D) ]\n\n目标测试: B 是不是目标 G？不是。\n\n扩展: 我们对 Node(S-&gt;B) 进行扩展。假设从 B 可以到达 E 和 G。\n\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;B-&gt;E) 和 Node(S-&gt;B-&gt;G)。\n\n加入前沿: 将这两个新节点加入前沿。\n\n当前前沿: [ Node(S-&gt;A-&gt;C), Node(S-&gt;A-&gt;D), Node(S-&gt;B-&gt;E), Node(S-&gt;B-&gt;G) ]\n\n\n\n第 4 轮循环:\n\n移除: 算法从前沿中选择并移除 Node(S-&gt;A-&gt;C)… 这个过程会继续下去。\n\n直到某一次循环，比如第 N 轮：\n\n移除: 算法从前沿中选择并移除 Node(S-&gt;B-&gt;G)。\n\n目标测试: G 是不是目标 G？是的！\n\n返回结果: 搜索成功，返回 Node(S-&gt;B-&gt;G)。通过这个节点，我们可以回溯出完整的路径是 S -&gt; B -&gt; G。\n\n\n\n\n总之, 这里的移除一个节点，并不是把它丢弃或忘记，而是把它从“待办事项”列表（前沿）中拿出来，准备对其进行处理。\n而扩展一个节点，就是基于当前路径，探索所有下一步的可能性, 例如查看状态A所有可能的行动（比如可以去B、C、D），然后为每一个行动生成一个新的子节点。\n \n\n    \n  \n\n# pseudocode for tree searchfunction TREE-SEARCH(problem, frontier) return a solution or failure    frontier ← INSERT(MAKE-NODE(INITIAL-STATE[problem]), frontier)    while not IS-EMPTY(frontier) do        node ← POP(frontier)        if problem.IS-GOAL(node.STATE) then            return node        end        for each child-node in EXPAND(problem, node) do            add child-node to frontier        end    end    return failurefunction EXPAND(problem, node) yields nodes    s← node.STATE    for each action in problem.ACTIONS(s) do        s′ ← problem.RESULT(s, action)    end    yield NODE(STATE=s′, PARENT=node, ACTION=action)\n\n三种核心策略\n对于每种策略，我们也将介绍其一些基本性质，从以下几个方面进行说明：每种搜索策略的完备性————如果搜索问题存在解，该策略是否在无限计算资源下保证能找到解？每种搜索策略的最优性————如果搜索问题存在解，该策略是否能找到最优解？每种搜索策略的时间和空间复杂度分支因子 b - 每次从前沿队列中取出一个节点并用其子节点替换时，前沿节点数量增加的量是 O(b)。在搜索树的深度 k 处，存在 O(b^k)个节点。\n\n\n深度优先搜索 (Depth-First Search - DFS)\n\n描述：总是选择最深的前沿节点进行扩展 。\n\n前沿表示：使用后进先出 (LIFO) 栈，因为它总是优先处理最新加入的节点（即更深的节点） 。\n\n性质：\n\n完备性：不完备。如果状态空间图中存在环路，搜索树可能会无限深，导致DFS陷入死循环 。\n\n最优性：不最优。它找到的是搜索树中“最左侧”的解，不考虑路径成本 。\n\n\n\n时间复杂度：，其中 b 是分支因子，m 是最大深度 。\n\n空间复杂度：。这是它的主要优势，因为它只需要存储一条路径上的节点 。\n\n\n\n\n\n一条路径的最大长度是 m。在这条路径上的每个节点，最多在生成的时候扩展了 b-1 个兄弟节点存储在前沿（栈）中，等待当前路径探索失败后回溯时使用。因此，总共需要存储的节点数大约是\n\n\n广度优先搜索 (Breadth-First Search - BFS)\n\n描述：总是选择最浅的前沿节点进行扩展 。\n\n前沿表示：使用先进先出 (FIFO) 队列，以保证按层级顺序访问节点 。\n\n性质：\n\n完备性：完备。因为它保证会搜索到最浅的解所在的有限深度 s 。\n\n最优性：当所有行动成本相同时，它是最优的，因为它找到的是深度最浅的解 。\n\n\n\n时间复杂度：，其中 s 是最浅解的深度 。\n\n空间复杂度：。这是它的主要缺点，前沿需要存储整层的节点 。\n\n\n\n一致成本搜索 (Uniform Cost Search - UCS)\n\n描述：UCS 是 BFS 的一个重要泛化，它从“找到步数最少的路径”升级为“找到成本最低的路径”, 其总是选择从初始状态到当前节点路径成本最低的前沿节点进行扩展 。\n\nUCS 的策略与著名的 Dijkstra 算法完全相同。主要区别在于，UCS 在找到第一个目标状态时就停止，而 Dijkstra 算法会继续运行，直到找到从起点到图中所有节点的最短路径。\n\n\n前沿表示：使用基于堆的优队列 (Priority Queue)，节点的优先级由其路径成本决定 。\n\n每个节点被放入优先队列时，它的优先级被设定为其从初始状态到该节点的路径成本。\n\n优先队列的特性保证了成本最低的节点总是位于队列的“顶部”。\n\n当算法需要选择下一个节点时，它只需从队列顶部取出一个即可。\n\n当新的子节点被加入队列时，优先队列会自动根据它们的路径成本进行内部排序（“重新洗牌”），以确保成本最低的节点始终在最前面。\n\n\n\n性质：\n\n完备性：完备（只要存在有限成本的解） 。\n\n最优性：最优（只要行动成本非负）。因为它按路径成本递增的顺序扩展节点 。\n\n负成本问题：如果存在负成本的边，UCS 的最优性保证就会失效，因为它可能先找到一条看起来成本低的路径，但之后却发现另一条更长的路径因为有负成本边而总成本更低。\n\n\n\n\n时间复杂度：\n\n：最优解的路径成本。\n\n：任意两个节点之间最小的行动成本（必须大于0）。\n\n$C^/\\epsilon：这个比值可以理解为最优路径的有效深度。它粗略地告诉我们，要凑够最优成本C^，在最理想的情况下（即每一步都走成本最低的\\epsilon路径），大约需要走多少步。如果所有行动成本都是，那么\\epsilon=1，C^*=s，这个比值就等于最浅解的深度，复杂度就退化为的O(b^s)$\n\n这个“有效深度”的概念，将 UCS 的行为与 BFS 统一了起来。BFS 是在探索一个“深度圈”，而 UCS 是在探索一个**“成本圈”**。 就是这个成本圈的半径的近似度量。\n\n\n\n空间复杂度： \n\n和 BFS 类似，UCS 的空间瓶颈在于前沿 (frontier) 的大小。在即将找到成本为 $C^的最优解时，前沿中会包含大量路径成本约等于C^$ 的节点。\n\n\n\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Games -- Trees, Minimax, Pruning","url":"/2025/08/11/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/5/","content":"进入新的一章, 我们从单智能体环境（智能体与一个被动的世界互动）进入到多智能体的对抗性搜索 (Adversarial Search) 环境中。在这里，环境中存在其他智能体（对手），它们会主动采取行动来阻挠我方目标的实现。\n当存在一个理性对手时，一个智能体不能再简单地寻找一条通往目标的路径。它必须假设对手也会采取最优的行动来对抗自己。因此，智能体的策略必须是：在所有可能的对手回应中，选择那个能保证自己获得“最坏情况下的最好结果”的行动。\n对抗搜索与博弈树 (Adversarial Search &amp; Game Trees)对抗搜索问题通常被形式化为博弈 (Games)。这些博弈是零和 (zero-sum) 的，意味着一个玩家的收益就是另一个玩家的损失。\n思考这类游戏最简单的方式是将其定义为单个变量值，其中一方或智能体试图最大化，而另一方或智能体试图最小化，从而形成直接竞争。在《吃豆人》中，这个变量是你的得分，你试图通过快速高效地吃豆子来最大化得分，而鬼魂则试图通过首先吃掉你来最小化得分。许多常见的家用游戏也属于这类游戏：如Checkers(跳棋), Chess(国际象棋), Go(围棋)等. \n与返回全面计划的常规搜索不同，对抗性搜索返回一个策略或政策，它仅根据我们的智能体及其对手的某种配置推荐最佳可能的移动。\n而博弈树 (Game Tree), 就是表示博弈的一种形象方式。其具有以下几个组成部分: \n\n节点 (Nodes)：代表博弈中的状态 (states)。\n\n边 (Edges)：代表玩家可以采取的行动 (moves)。\n\n叶节点 (Terminal Nodes)：代表博弈结束的状态，每个叶节点都有一个效用值 (utility value)，表示该结局对第一个玩家（通常称为MAX）的好坏程度。\n\n\nMinimax 算法Minimax 是在对抗博弈中找到最优策略的基础算法, 该算法基于一个激励性的假设运行，即我们面对的对手会采取最优行为，并且始终执行对我们最不利的移动。\n同时, 它的名字完美地概括了其核心逻辑：最大化 (Maximize) 自己在对手最小化 (Minimize) 自己收益后的得分。\n玩家角色：\n\nMAX 玩家：试图最大化最终的效用值。\n\nMIN 玩家：试图最小化MAX玩家的最终效用值。\n\n\n算法流程（自底向上递归） ：\n\n生成博弈树：从当前状态开始，一直向下探索到博弈结束的终端状态。\n\n计算终端节点的效用：根据游戏规则，为每个终端状态（叶节点）分配一个效用值。\n\n递归回溯：从叶节点开始，逐层向上计算每个非终端节点的Minimax值。\n\n对于 MIN 节点：该节点的Minimax值是其所有子节点中的最小值。\n\n对于 MAX 节点：该节点的Minimax值是其所有子节点中的最大值。\n\n\n\n做出决策：在根节点，MAX玩家选择那个通往具有最高Minimax值的子节点的行动。\n\n\n\n在实现中，minimax 的行为与深度优先搜索类似，计算节点的值的顺序与 DFS 相同，从最左边的终端节点开始，依次向右迭代。更精确地说，它对游戏树进行后序遍历。\n\nMinimax算法可以为任何有限的、确定性的、完全信息下的双人零和博弈找到最优的行动策略。但它的缺点是必须遍历整个博弈树，时间复杂度为 ，在像国际象棋这样复杂的博弈中是不可行的。\n\nAlpha-Beta 剪枝 (Alpha-Beta Pruning)Alpha-Beta剪枝是Minimax算法的一个极其重要的优化，它可以在不影响最终决策的情况下，剪掉博弈树中大量不必要的分支。\n其核心思想是, 在搜索过程中，如果一个分支的探索结果已经被证明不可能比当前已找到的最佳选择更好，那么就没有必要再继续探索这个分支了。\n两个关键变量：\n\nα (Alpha)：在从根节点到当前节点的路径上，MAX玩家目前能确保获得的最低分数。\n\nβ (Beta)：在从根节点到当前节点的路径上，MIN玩家目前能确保获得的最高分数（即MAX玩家能获得分数的上限）。\n\n\n剪枝规则 ：\n\nAlpha 剪枝 (在MIN节点)：如果一个MIN节点的某个子节点的值 v 小于或等于当前路径上的 α 值，那么这个MIN节点就可以被剪枝了。\n\n因为我们知道MAX玩家在MIN的同一层其他兄弟上已经有了一个至少能得到 α 的选择。而当前这个MIN节点保证了MAX玩家最多只能得到 v（因为MIN会选择最小的）。既然 ，MAX玩家就绝不会选择走向这个MIN节点的路径。因此，该MIN节点的其他子节点无需再探索。\n\n\n\n\n如图, 当探索完左侧节点3之后, MAX根节点已经至少得到了3, 而中间的MIN节点此时最好情况也是2, 因此MAX根本不需要考虑这个节点的其余子节点\n\nBeta 剪枝 (在MAX节点)：如果一个MAX节点的某个子节点的值 v 大于或等于当前路径上的 β 值，那么这个MAX节点就可以被剪枝了。\n\n因为我们知道MIN玩家在更高层已经有了一个能把MAX玩家的得分限制在 β 以下的选择。而当前这个MAX节点至少能得到 v。既然 ，MIN玩家就绝不会让游戏走到这个MAX节点的路径上来。因此，该MAX节点的其他子节点无需再探索。\n\n\n\n需要注意的是, 剪枝的效率高度依赖于行动的顺序。如果总是先探索最好的行动，Alpha-Beta剪枝可以将需要探索的节点数从  减少到大约 ，这相当于将可搜索的深度加倍，是一个巨大的提升。\n评估函数 (Evaluation Functions)为什么需要评估函数？—— 现实的妥协Minimax 和 Alpha-Beta 剪枝算法在理论上是完美的，它们能为任何有限的、确定性的博弈找到最优解。但这里有一个巨大的现实障碍：计算资源的限制。\n对于像国际象棋（分支因子约35，深度可达80层）或围棋这样的复杂博弈，其完整的博弈树比宇宙中的原子还要多。即使是最高效的 Alpha-Beta 剪枝算法，也无法在有限的时间内（比如比赛规定的几分钟内）搜索到游戏的终局。\n既然我们无法“看到”游戏的结局，我们就必须在某个点停止搜索，并对当前的局面进行“估算”。这个“估算”就是通过评估函数来完成的。\n简单来说，评估函数是我们在无法进行完美、完整的逻辑推演时，所采用的一种基于经验和特征的、不完美的“直觉”判断。\n定义评估函数是一个启发式函数，它接收一个非终端的游戏状态（例如，一个中盘的棋局）作为输入，并输出一个数值，这个数值估计了该状态对 MAX 玩家的最终效用值。\n它将一个非终端节点“伪装”成一个终端节点。当 Alpha-Beta 搜索达到预设的深度限制 (depth limit) 时，它就不再继续向下扩展，而是调用评估函数来为这个“叶”节点打分。这个分数随后会被用于 Minimax 的回溯计算中。\n与启发式 h(n) 的区别：\n\n在A*搜索中，启发式 h(n) 估计的是从当前状态到目标的剩余成本。\n\n在博弈中，评估函数估计的是从当前状态开始，如果双方都下得很好，最终整个游戏的结局对MAX玩家的效用。\n\n\n\n如何设计评估函数？一个好的评估函数需要能够快速而准确地判断局势的优劣。这通常通过以下步骤实现：\n\n提取特征 (Features)：\n\n\n首先，我们需要从游戏状态中提取出一系列能够反映局势优劣的关键特征。\n\n国际象棋示例：\n\n棋子自身优势 (Material Advantage)：这是最基础的特征。通常会给每个棋子赋一个分值（例如，兵=1，马=3，象=3，车=5，后=9），然后计算双方棋子分值的差。\n\n棋子位置和机动性 (Piece Position &amp; Mobility)：一个位于中心位置的马比在角落里的马更有价值。一个能够移动到很多位置的棋子比被困住的棋子更有价值。\n\n兵形结构 (Pawn Structure)：是否存在孤兵、叠兵等弱点。\n\n\n\n\n\n加权线性函数 (Weighted Linear Function)：\n\n\n常见的做法是将这些特征组合成一个加权线性函数，来计算总的评估值。\n\n₁₁₂₂ₙₙ\n\n：当前的游戏状态。\n\nᵢ：第 i 个特征在状态 s 下的数值（例如，f₁ 可能是白方棋子总分减去黑方棋子总分）。\n\nᵢ：第 i 个特征的权重。这个权重反映了该特征在决定胜负中的重要性。例如，王的安全性的权重可能比兵形结构的权重要高。\n\n\n\n\n这些特征和权重的选择，是深层领域知识的体现。在国际象棋中，它们来自于数百年人类大师对弈经验的总结。在现代AI中，这些权重也可以通过机器学习的方法，让程序通过分析大量的棋局数据（甚至是自我对弈）来自动学习和优化。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Games -- Expectimax, Monte Carlo Tree Search","url":"/2025/08/12/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/6/","content":"这一讲涉及到的是一个更复杂、也更贴近现实的博弈世界。核心的转变是：从处理确定性的、纯粹策略对抗的博弈，转向包含随机性或机会元素 (chance) 的博弈。\n在之前的Minimax博弈中，只有两个玩家：MAX和MIN。MAX的每一个行动，MIN都会用最优的策略来回应。然而，在许多现实世界的博弈中，例如扑克或双陆棋，结果不仅仅取决于你和对手的选择，还取决于机会——比如你摸到什么牌，或者掷出什么样的骰子。\n为了在这种不确定的环境中做出理性决策，我们不能再简单地假设最坏情况的发生，而是需要计算期望的结果。\nExpectimaxExpectimax 是 Minimax 算法的一个直接扩展，专门用于处理包含机会节点的博弈。\n在博弈树中，除了原有的MAX节点（我方决策）和MIN节点（对手决策），我们引入了机会节点。\n机会节点代表了环境中的随机事件（如掷骰子）。从机会节点出发的每条边代表一个可能发生的随机结果，并且每条边都关联一个概率。\n例如, 在一个掷骰子的游戏中，机会节点会有6个子节点，分别对应掷出1到6点，每个子节点的概率都是1/6。\n在Expectimax 的计算规则中, MAX 节和MIN 节点都与 MINIMAX一致, 选择效用最大/最小的节点, 核心区别在于机会节点：机会节点的值不是取最大或最小值，而是计算其所有子节点效用的期望值 (Expected Value)，即加权平均值。\n\n公式：ᵢᵢ\n\n另外值得注意的是, 在Expectimax中，评估函数的绝对数值变得至关重要. \n以往在Minimax中，评估函数的相对顺序占据主导。只要 EVAL(A) &gt; EVAL(B)，我们就会选择A。\n但在Expectimax中，因为我们要计算加权平均值，所以一个评估值为100和一个评估值为10，在计算期望时会产生截然不同的结果。一个微小的可能性乘以一个巨大的回报（或损失），可能会完全改变最终的期望效用。\nExpectimax 同样需要遍历博弈树，其时间复杂度与Minimax类似，为 （其中 b 现在也包括了机会节点的分支）。对于分支因子巨大（如围棋）或深度很深的博弈，它仍然是不可行的\n蒙特卡洛树搜索 (Monte Carlo Tree Search - MCTS)传统的博弈算法，如 Minimax 和 Alpha-Beta 剪枝，试图通过深度搜索和逻辑推理来找到最佳行动。它们就像一个深思熟虑的棋手，试图穷尽所有可能性来评估一个局面的好坏。然而，当博弈变得极其复杂时（例如，围棋的分支因子高达361），这种“深度思考”在计算上是不可行的。\n蒙特卡洛树搜索 (MCTS) 采用了一种截然不同的、更接近人类直觉的策略。它放弃了对博弈树的完整遍历，转而通过进行大量、快速、随机的模拟对局 (playouts) 来评估一个局面的潜力。\n\n想象一下，你正在下一个你不太懂的棋。为了决定下一步怎么走，你不在脑海里进行复杂的逻辑推演，而是采用一种更简单的方法：对于每个可能的下一步，你都和朋友快速地、随机地把这盘棋下完，下个几百盘。最后，你发现从某个特定的第一步出发，你赢的次数最多。于是，你就决定走这一步。\n\n这就是 MCTS 的精髓：用统计上的成功概率来代替静态的、手工设计的评估函数。\nMCTS 的四个核心步骤MCTS 算法通过一个不断重复的循环来逐步构建一棵不对称的、聚焦于有希望区域的搜索树。每一次循环都包含以下四个步骤：\n\n选择 (Selection): 在已经构建的搜索树中，找到一个最有潜力的、值得进一步探索的“叶”节点。\n\n\n从根节点（当前真实的游戏局面）开始，算法会根据一个选择策略，一层一层地向下走。这个策略必须巧妙地平衡两个目标：\n\n利用 (Exploitation)：倾向于选择那些过去表现很好（胜率高）的节点。\n\n探索 (Exploration)：也要给那些探索次数较少的节点一些机会，因为它们可能潜力巨大，只是我们还没发现。\n\n\n\n常用策略：UCT (Upper Confidence bounds applied to Trees) 是一种非常流行的选择策略，它通过一个公式来计算每个节点的“紧迫性”，完美地平衡了利用和探索。\n\n\n\n扩展 (Expansion): 当“选择”步骤到达一个叶节点时，我们需要扩展这棵树的边界。\n\n\n算法会为这个叶节点创建一个或多个新的子节点，代表从该局面出发可以采取的、之前从未探索过的行动。\n\n\n模拟 (Simulation / Playout): 快速地对新扩展的节点进行一次“价值评估”。\n\n\n从新扩展的某个子节点开始，算法会进行一次完全随机（或者基于一个非常简单的策略）的快速对局，直到游戏分出胜负。这个过程不需要动脑筋，只需要速度快。\n模拟（Simulation） 阶段完全脱离了已有的博弈树。它从一个新节点（树的叶子）出发，进入一个“想象中的”对局。它不需要再访问树中的任何其他节点，也不需要构建新的树节点。它只是在一个临时的游戏状态副本上，一路“走到底”。\n\n\n反向传播 (Backpropagation): 将模拟的结果反馈给搜索树，更新我们的“知识库”。\n\n\n模拟的结果（赢或输）会沿着“选择”阶段的路径，从下至上地传回根节点。路径上的每一个节点都会更新它们的统计数据，例如赢的次数 (wins)和总模拟次数 (visits)\n\n这个“选择 -&gt; 扩展 -&gt; 模拟 -&gt; 反向传播”的循环会进行成千上万次。当分配的时间用尽时, 此时经过大量的迭代后，根节点的每个子节点都积累了大量的统计数据。最终，算法会选择那个被访问次数最多且胜率也较高的子节点所对应的行动。\nUCT (Upper Confidence bounds applied to Trees) - 应用于树的上置信界UCT 并不是一个全新的算法，而是将 UCB (Upper Confidence Bound) 公式具体应用到蒙特卡洛树搜索 (MCTS) 的”选择 (Selection)”阶段的策略。为了更好地理解UCT，我们先介绍其理论基础——UCB算法。\nUCB 算法基础UCB (Upper Confidence Bound) 是一种通用的决策算法，专门用于解决多臂老虎机问题 (Multi-Armed Bandit Problem)。这个问题正是”探索与利用”困境的经典模型。\n\n想象一下，你走进一家赌场，面前有多台老虎机（Slot Machine）, 这些老虎机看起来一模一样，但每台老虎机吐出奖励的概率（或者说奖励的期望值）是不同的，而且这个概率对你来说是未知的。你的目标是在有限的尝试次数内，最大化你获得的总奖励。\n\n而UCB 为每一个可选项（比如，每一台老虎机，或者 MCTS 中的每一步棋）计算一个综合分数：\nUCB 分数 = 当前平均回报 + 探索奖励\n1. 当前平均回报 (Exploitation Term)\n含义：该选项到目前为止的平均表现\n在MCTS中：节点的当前胜率 (赢的次数 / 总访问次数)\n作用：值越高，说明该选项在过去的试验中表现越好，越有理由”利用”它\n\n2. 探索奖励 (Exploration Term)\n含义：鼓励尝试那些被选择次数较少的选项的奖励项\n特点：奖励大小与该选项被访问的次数成反比\n作用：访问次数越少，不确定性越大，探索其潜在价值的收益越高\n\n3. 决策机制算法选择UCB分数最高的选项，自动在”已被证明是好的”和”可能是更好的未知选项”之间做出权衡。\nUCT 在 MCTS 中的应用在 MCTS 的选择步骤中，当算法从一个非叶节点（父节点P）向下选择子节点时，它将P的所有子节点视为一个”多臂老虎机问题”。算法为每个子节点C计算UCT值，并选择值最高的子节点继续探索。\nUCT 公式详解\n公式组成部分：利用项：\n\n：子节点赢得的模拟次数\n：子节点被访问的总次数\n这个比值就是子节点的当前胜率\n\n探索项：\n\n：父节点被访问的总次数\n：子节点被访问的总次数\n：探索常数，可调的超参数，用于平衡探索和利用的权重\n\n公式工作原理：\n探索阶段：当子节点的访问次数很小时，分母很小，导致探索项的值很大，该节点更有可能被选中（鼓励探索）\n\n利用阶段：随着子节点被访问次数的增加，探索项逐渐减小，节点选择更多地取决于其胜率（鼓励利用）\n\n平衡机制：探索常数控制探索与利用的平衡程度，较大的值倾向于更多探索，较小的值倾向于更多利用\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- Local Search","url":"/2025/08/08/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/4/","content":"局部搜索 (Local Search)概述与前几讲（如A*搜索）不同，局部搜索算法解决的是另一类问题。在之前的搜索中，我们不仅关心是否能到达目标，还关心如何到达，即找到一条完整的路径 。\n然而，在很多问题中，我们只关心最终的解决方案状态，而不关心到达该状态的具体步骤 。\n局部搜索 (Local Search) 就是为这类问题设计的。它不维护从起点开始的路径，而是从一个完整的、可能是随机的配置（状态）开始，然后通过一系列局部的、微小的修改，逐步改进这个配置，直到找到一个满足约束或优化了某个目标函数 (objective function) 的状态 。\n爬山算法 (Hill-climbing)这是最基础的局部搜索算法。它非常“贪婪”，在当前状态下，它会审视所有邻近的状态，并选择那个能使目标函数值提升最大的方向移动一步 。这个过程也被称为最陡峭上升 (steepest-ascent)。\n它不维护搜索树, 只保留当前的状态，内存开销极小 。\n它的缺点是容易陷入困境：由于其“贪婪”的本性，一旦到达一个局部最大值，它就会因为周围没有更高的点而“卡住”，错误地认为已经找到了顶峰 。同样，它也可能在“高原”上迷失方向 。\n其伪代码如下\nfunction HILL-CLIMBING(problem) returns a state    current &lt;- make-node(problem.initial-state)    loop do        neighbor &lt;- a highest-valued successor of current        if neighbor.value ≤ current.value then            return current.state        current &lt;- neighbor\n\n其变体与改进有如下两种：\n\n随机爬山法 (Stochastic Hill-Climbing)：不是选择最好的上坡方向，而是在所有可能的上坡方向中随机选择一个。这增加了探索性，有时能找到更好的解，但通常需要更多步数 。\n\n随机重启爬山法 (Random-Restart Hill-Climbing)：这是解决局部最大值问题的最有效方法之一。它多次从一个随机生成的初始状态开始运行爬山法。如果一次搜索陷入了局部最大值，就放弃它，重新开始一次新的搜索。这个方法在理论上是完备的，因为只要有足够多的重启次数，总有一次会从全局最大值的“山坡”上开始攀登 。\n\n\n模拟退火 (Simulated Annealing)模拟退火是一种更智能的算法，它试图结合爬山法的效率和随机游走的完备性 。它的核心思想是：在搜索初期，允许一些“坏”的移动（即走向目标函数值更低的状态），以帮助算法“跳出”局部最大值的陷阱 。\n算法机制：\n\n接受好移动：如果一个随机选择的移动能提升目标函数值，则总是接受它 。\n\n概率性接受坏移动：如果移动会降低目标函数值，则以一定的概率接受它 。\n\n温度 (Temperature)：这个接受概率由一个叫做“温度”的参数 T 控制。在开始时，T 很高，接受“坏”移动的概率也较高，算法有更多的探索性。随着时间的推移，T 会根据一个“退火时间表 (schedule)”逐渐降低，使得算法越来越倾向于只接受“好”的移动，最终稳定在某个最大值上 。\n\n\n理论保证：如果温度下降得足够慢，模拟退火理论上能以趋近于1的概率找到全局最优解 。\n局部束搜索 (Local Beam Search)这是爬山法的一个变种，但它不是只维护一个当前状态，而是同时维护 k 个状态（称为一个“束”或“线程”）\n它不是简单地并行运行 k 次独立的爬山法 。在每一步，算法会生成这 k 个状态的所有后继状态，然后从这些所有的后继状态中，选择最好的 k 个作为下一代的新状态束 。\n这种机制允许信息在不同的搜索路径之间共享。如果某个状态（线程）进入了一个很有希望的区域，它的优良后代就有可能被选中，从而“吸引”其他搜索力量向这个区域集中 。\n\n遗传算法 (Genetic Algorithms)遗传算法是一种受生物进化论启发的局部搜索技术，可以看作是局部束搜索 (Local Beam Search) 的一种高级变体。\n与传统的爬山法或模拟退火不同，遗传算法不是只维护一个或少数几个状态，而是维护一整个种群 (Population) 的状态。这个种群会像生物世界一样，经历一代又一代的进化，通过选择 (Selection)、交叉 (Crossover) 和变异 (Mutation)，最终演化出适应环境的、高质量的解决方案。\n其关键概念如下:\n\n个体 (Individual)：种群中的每一个成员，代表了问题的一个完整解（状态）。\n\n基因编码 (Encoding)：每个个体需要被编码成一个字符串，这就像生物的DNA。讲义中以8皇后问题为例，一个解决方案（棋盘布局）被编码为一个8位数字串，如 24748552，其中第 i 个数字代表第 i 列上皇后的行号。\n\n适应度函数 (Fitness Function)：这就是局部搜索中的目标函数。它用来评估每个个体的“优劣”程度。对于8皇后问题，适应度函数计算的是不互相攻击的皇后对的数量。一个完美的解，其适应度为 (8*7)/2 = 28。\n\n\n\n下面以上图的八皇后问题来展示遗传算法的核心流程:\n\n步骤 (a): 初始种群 (Initial Population)\n\n算法从一个随机生成的、包含 k 个个体的种群开始。这为进化提供了最初的“基因库”。\n图中展示了4个随机生成的8皇后棋盘布局的编码。\n\n\n步骤 (b): 适应度评估 (Fitness Function)\n\n使用适应度函数评估种群中每个个体的“好坏”。这个评价值决定了个体在下一轮繁殖中被选中的概率。\n\n图中计算了4个个体的适应度（24, 23, 20, 11），并根据适应度高低计算出它们被选中的概率（31%, 29%, 26%, 14%）。\n\n\n\n步骤 (c): 选择 (Selection)\n\n模拟“适者生存”的过程。适应度越高的个体，越有可能被选中作为“父母”来繁殖下一代。\n\n根据(b)中的概率，进行了4次随机选择，选出了两对“父母”。注意，适应度较高的个体 32752411 被选中了两次，而最低的 32543213 未被选中。\n\n\n\n步骤 (d): 交叉 (Crossover)\n\n这是遗传算法最核心、最强大的环节。算法为每一对父母随机选择一个交叉点，然后将它们的“基因串”在该点切开并交换后半部分，从而创造出两个全新的子代。\n\n为什么交叉如此重要？ 它允许在不同父代中独立进化出的优良“基因片段”（即解决方案的好的局部结构）被组合在一起，从而有潜力创造出远优于其父代的全新解决方案。\n\n父代 32752411 和 24748552 在第3位后交叉，生成了子代 32748552。这个子代继承了第一个父代的前3个皇后位置和第二个父代的后5个皇后位置。\n\n\n\n\n步骤 (e): 变异 (Mutation)\n\n在子代生成后，其基因串上的每一个位置都有一个很小的概率发生随机突变。\n\n为什么需要变异？ 变异为种群引入了新的基因多样性，有助于防止算法过早收敛到某个局部最优解，增加了跳出陷阱、找到全局最优解的可能性。\n\n图中，有三个子代的基因发生了突变（方框标出的数字）。\n\n\n\n\n这个“评估 -&gt; 选择 -&gt; 交叉 -&gt; 变异”的循环会不断重复，直到找到一个满足条件的解，或者达到预设的迭代次数。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Logic -- Propositional Logic and Planning","url":"/2025/08/12/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/7/","content":"之前的智能体（如搜索智能体）虽然能解决问题，但它们的“知识”是隐式的, 内嵌在状态表示、行动函数和启发式函数中。而从这一讲开始，我们将探索如何让智能体拥有显式的、声明式的知识，并利用这些知识进行推理\n基于知识的智能体 (Knowledge-Based Agent)它的核心组件是一个知识库 (Knowledge Base - KB)，这是一个由形式化语言写成的语句 (sentences) 的集合。\n整个智能体的工作模式为: \n\n告知 (TELL)：将新的知识（来自感知、学习或直接告知）以语句的形式添加到知识库中。\n\n询问 (ASK)：通过一个通用的推理引擎 (Inference Engine) 向知识库提问，推导出新的结论来指导行动。\n\n\n这是一种声明式 (Declarative) 的方法。我们只需要描述“世界是怎样的”，而不需要编写具体的“如何做”的代码。一个通用的推理算法可以解决所有可回答的问题，这极大地提高了智能体的灵活性和可扩展性。\n逻辑的基本概念为了让智能体能够“知道”事情，我们需要一种精确的语言。逻辑就是这样一种语言，它由两个基本部分组成：\n\n语法 (Syntax): 语法是一套规则，它规定了什么样的符号组合是合法的语句。\n\n就像英语语法规定了 “x &gt; y” 是合法的，而 “x &gt; y =” 不是。语法只关心句子的形式，不关心其含义。\n\n\n语义 (Semantics): 语义定义了语句的含义。它通过将语句与**“可能的世界” (Possible Worlds)** 或**“模型” (Models)** 联系起来，来确定一个语句的真假。\n\n可能的世界/模型：一个模型代表了世界的一种具体状态。在命题逻辑中，一个模型就是对所有命题符号的一个真值指派（例如，{P=真, Q=假}）。\n\n真值 (Truth)：语义的核心是定义一个语句在哪个模型中为真，在哪个模型中为假。\n\n\n\n\n命题逻辑 (Propositional Logic)这是我们学习的第一个形式化逻辑语言。\n语法：由命题符号 (X₁, X₂…) 和五个逻辑连接词 (¬, ∧, ∨, =&gt;, ⇔) 构成。\n\n需要额外注意的是 =&gt;(蕴含, implication)：“如果A，那么B”。这是最容易混淆的一个。它只有在一种情况下为假：当 A 为真而 B 为假时。\n\n语义：通过真值表来定义。一个模型就是对所有命题符号的一个真/假赋值。\n推理 (Inference)推理是一个计算过程，它通过应用推理规则从已有的语句中推导出新的语句。其有两种主要方法：\n\n模型检验 (Model Checking)：通过枚举所有可能的模型来检查蕴含关系是否成立。对于命题逻辑是可行的，因为模型数量有限。\n\n定理证明 (Theorem Proving)：应用推理规则（如三段论）来构建一个从前提到结论的证明 (proof) 链条。\n\n\n而蕴含 (Entailment)是逻辑推理的核心目标。它的意思是：在所有使得 α 为真的模型中，β 也必然为真。\n\n定义：α |= β (读作 “alpha entails beta”)\n\n与蕴含 (=&gt;) 的区别 ：\n\nα =&gt; β 是一个逻辑语句，它本身可以在某个模型中为真或为假。\n\nα |= β 是一个关于两个语句之间关系的断言，它要么成立，要么不成立。\n\n\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Markov Decision Process, MDP(17)","url":"/2025/08/30/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/17/","content":"强化学习任务通常使用马尔可夫决策过程（MDP）来描述。MDP 是一个为具有不确定性的序贯决策问题提供数学模型的框架。其核心在于一个智能体（Agent）与环境（Environment）的持续交互：智能体感知当前状态，执行一个动作，环境随之转移到一个新的状态，并给予智能体一个奖励。这个循环不断持续，智能体的目标是学习一个最优策略，以最大化其长期累积奖励。\n\n所谓序贯决策，指的是决策者需要连续不断地做出决策，并且每个决策都会影响到未来的结果。\n\n参考内容: MDP与强化学习\n马尔可夫决策过程 (MDP)一个MDP由以下几个核心要素构成：\n\n状态集合 (A set of states S)：智能体可能所处的所有状态。\n行动集合 (A set of actions A)：智能体在每个状态下可以采取的行动。\n转移函数 (A transition function T(s, a, s’))：这是对世界动态的概率性描述。T(s, a, s’) = P(s’ | s, a) 表示在状态 s 执行行动 a 后，转移到状态 s’ 的概率。\n奖励函数 (A reward function R(s, a, s’))：描述了智能体从状态 s 采取行动 a 并转移到状态 s’ 后获得的即时奖励。这个奖励反映了智能体的“偏好”。智能体的目标是最大化其长期累积奖励，而不是眼前的单步奖励。\n折扣因子 (A discount factor γ)：一个介于0和1之间的数，用于平衡即时奖励和未来奖励的重要性。\nγ 越接近1，智能体越有“远见”，会更看重未来的长期回报。\nγ 越接近0，智能体越“短视”，只关心眼前的即时奖励。\n一个在时间步 t 发生的奖励 R，其价值会被折扣为 \n它保证了即使在一个无限时间的过程中，效用的总和也是一个有限值，从而使问题在数学上是可解的。\n\n\n\n策略（Policy, π）一个策略 π 是一个从状态到行动的映射，即 π(s) = a。它告诉智能体在每个状态下应该做什么。一个最优策略 π* 则是那个能够最大化期望的总折扣奖励(Discounted Cumulative Reward)，也称为回报（Return）的策略。\n回报与折扣（Return &amp; Discounting）一个状态序列的效用被定义为所有奖励的折扣总和：\n当 0 &lt; γ &lt; 1 时，这个无限序列的和是有限的，其上界为 ，其中  是可能的最大单步奖励\n价值函数为了评估一个策略的好坏，我们使用价值函数来量化一个状态或一个”状态-动作”对的长期价值。\n\n最优状态价值函数 (Optimal Value Function, $U^(s)或V^(s)：代表从状态s$ 出发，并从此遵循最优策略，所能获得的期望总回报。\n\n最优动作价值函数 (Optimal Q-Value Function, )：代表在状态  采取动作  后，再遵循最优策略，所能获得的期望总回报。\n\n这也被称为 (s, a) 对的 Q值 (Q-value)。\n\n\n\n这两者之间的关系非常直观：一个状态的最优价值，等于从该状态出发所有可能的动作中，能带来的最优动作价值的最大值。\n$U^(s)= \\max_a Q^(s,a)$\n贝尔曼方程 (The Bellman Equation)贝尔曼方程是 MDP 中最核心的方程，它通过一种递归的方式将一个状态的价值与其后续状态的价值关联起来，是求解 MDP 的基础 。\n贝尔曼期望方程 (Bellman Expectation Equation)用途：用于评估一个已知且固定的策略 π。它回答的问题是：”如果我遵循这个策略，每个状态/动作的长期价值是多少？” 。\n\n状态价值函数 ()：计算在遵循策略 π 时，状态 s 的期望回报。\n\n\n\n动作价值函数 ()：计算在状态 s 执行动作 a 后，继续遵循策略 π 所带来的期望回报。\n\n\n贝尔曼最优方程 (Bellman Optimality Equation)用途：用于求解最优价值函数，它定义了一个价值函数在最优时必须满足的条件。它回答的问题是：”在所有可能的策略中，每个状态/动作能达到的最大价值是多少？”\n\n最优状态价值函数 ($v^(s)或U^(s)$)：计算状态 s 在所有策略中可能达到的最大期望回报。\n\n$v^(s) = \\max_a(R(s,a) + γ\\sum_{s’∈S} P(s’|s,a)⋅v^(s’))$\n\n最优动作价值函数 ($q^(s,a)或Q^(s,a)$)：计算在状态 s 执行动作 a 后，按照最优策略执行所带来的最大期望回报。\n\n$q^(s,a) = R(s,a) + γ\\sum_{s’∈S} P(s’|s,a)⋅v^(s’)$\n因为我们的研究方向是最优解, 因此后续的分析中主要关注贝尔曼最优方程。而贝尔曼最优方程可以被看作是动态规划的两步：\n\n计算期望：对于每个动作 a，计算其期望价值 （类似于Expectimax算法中的机会节点）。\n\n取最大值：选择那个使 $Q^(s,a)最大的动作，其价值就是U^(s)$（类似于最大化节点）。\n\n\n到这里, 我们不要忘记核心目标是找到求解贝尔曼方程的方法，从而找到最优策略。这通常通过动态规划算法实现，我们将在下一讲学习具体的算法，如值迭代 (Value Iteration) 和策略迭代 (Policy Iteration)。\n除此之外, 还可以通过强化学习的方法解决MDP问题。它们的核心区别是环境是否已知, 这是区分传统 MDP 解决方法（如动态规划）和强化学习方法的关键点。\n如果 MDP 的所有要素（S,A,T,R,γ）都是已知的：\n\n这种情况下，我们称之为基于模型的（Model-Based） 方法。我们可以使用动态规划（Dynamic Programming） 等方法直接计算出最优策略，例如通过价值迭代（Value Iteration）或策略迭代（Policy Iteration）。\n\n如果 MDP 的转移概率 P 和/或奖励函数 R 是未知的：\n\n这在现实世界中非常常见。例如，我们不知道机器人执行“向北”指令后，具体会以多大概率到达哪个新位置。智能体必须通过**与环境的实际交互（试错）**来学习。\n\n强化学习正是为了解决这类问题而生的。它是一套无模型（Model-Free） 或试图学习模型的算法。智能体在未知的环境中，通过不断地尝试、观察结果（下一个状态和奖励），逐步地学习和改进自己的策略。\n\n常见的 RL 算法：\n\nQ-Learning 和 SARSA 这类基于价值的算法，通过估计每个“状态-动作”对的价值来学习策略。\n策略梯度（Policy Gradient） 方法，直接对策略函数进行优化。\n深度强化学习（Deep Reinforcement Learning, DRL），如 DQN、A3C 等，将深度学习与强化学习结合，使其能够处理高维度的状态空间（例如，直接从游戏屏幕的像素学习）。\n\n\n\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Dynamic Programming for MDP (18)","url":"/2025/08/30/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/18/","content":"上一讲我们定义了MDP，并得到了一个核心的数学关系——贝尔曼方程 (Bellman Equation)，它描述了最优状态价值的递归性质。这一讲的核心问题是：我们如何通过计算来求解这些贝尔曼方程，从而最终找到最优策略 π*？\n由于贝尔曼方程是一组非线性的联立方程，直接求解非常困难。因此，我们采用动态规划 (Dynamic Programming) 的思想，通过迭代的方式逐步逼近最优的效用值和策略。这一讲介绍了两种实现这一思想的经典算法。\n策略迭代 (Policy Iteration)在介绍策略迭代之前，我们先引入一个概念——策略评估 (Policy Evaluation)。策略评估的目标是计算给定策略 π 的状态价值函数 V(π)。\n\n上一讲我们提到贝尔曼方程分为贝尔曼最优方程和贝尔曼期望方程，策略评估的目标是计算给定策略 π 的状态价值函数 V(π)，即贝尔曼期望方程。\n\n策略评估策略评估的基本思路是从任意一个状态价值函数开始，依据给定的策略，结合贝尔曼期望方程、状态转移概率和奖励同步迭代更新状态价值函数，直至其收敛，得到该策略下最终的状态价值函数。\n假设在第 t 轮迭代已经计算出了所有状态的状态价值 V^t(s’)，那么在第 t+1 轮可以利用第 t 轮计算出的状态价值计算出第 t+1 轮的状态价值 V^{t+1}(s)。这是通过贝尔曼期望方程来完成的，即通过 Bellman expectation backup 进行迭代\n\n理解迭代过程首先, 上面的迭代公式由贝尔曼期望方程得到: \n\n这是一个陈述或一个平衡状态的定义。它描述了一个事实：对于一个给定的策略 π，其”真实”的价值函数  必须满足这种自洽性。\n这个公式可以看作是一个由 N 个方程组成的方程组（N是状态的数量）。在方程的左边和右边出现的  是同一个未知数。它表达的是：”一个状态的真实价值（左边），等于遵循策略后所有可能后续状态的期望价值（右边）”。\n而迭代方程则将 替换为  ，得到：\n\n根本原因在于, 贝尔曼算子（由第一个式子的右半部分定义）是一个压缩映射(符合迭代收敛的条件), 这个数学性质保证了，我们可以通过第二个式子描述的迭代方法，来找到第一个式子定义的那个唯一解。\n随着 k 越来越大，我们计算出的估计值  会收敛 (converge) 到那个”真实”的价值 。\n当  时，。我们把一个寻找平衡点的问题，转化成了一个保证能走到平衡点的计算流程。\n\n压缩映射定理保证了，只要一个算子是压缩的，那么它有且仅有一个不动点（即 v_pi 是唯一存在的）; 从任何初始点（任何初始猜测 v_0）开始，反复应用这个算子，最终都必定会收敛到这个唯一的不动点。\n\n示例分析下面通过一个具体的示例理解策略评估的过程。\n这是一个经典的Grid World的例子。有一个4x4的16宫格。只有左上和右下的格子是终止格子。\n\n状态 (S): 14个可移动的格子。左上角 (0,0) 和右下角 (3,3) 是终止状态。\n\n动作 (A): {上, 下, 左, 右}。\n\n策略 (π): 一个固定的随机策略。在任何一个非终止状态下，智能体都以均等的概率（各25%）选择上、下、左、右四个动作中的一个。\n\n奖励 (R): 每次移动的即时奖励为 -1。\n\n折扣因子 (γ): γ=1。这意味着未来的惩罚和当前的惩罚同等重要。\n\n目标: 我们的目标是评估这个随机策略，即计算出在这个策略下，从每一个格子出发，到达终点所期望的累积总回报（也就是状态价值函数 ）。\n\n\n图片左侧展示了价值函数从 k=0 开始的迭代计算过程。这个计算的核心是反复使用贝尔曼期望方程进行更新。对于这个特定的例子，更新公式为：\n$$V^{k+1}(s)=-1+(0.25\\cdot V^k(s’{up})+0.25\\cdot V^k(s’{down})+0.25\\cdot V^k(s’{left})+0.25\\cdot V^k(s’{right}))$$\n其中，$s’{up}s’{down}$ 等表示上一迭代中四个邻居格子的价值。\n下面展示k = 0 时的迭代: \n\n初始化所有非终止状态的价值为 0。这是一个任意的起点。\n此时，因为所有格子的价值都一样，所以看不出任何格子的好坏。\n\nk = 1 时的迭代: \n\n对所有非终止格子应用一次更新公式, 利用上一步的价值计算这一步的价值。\n计算: \n所有的非终止格子的价值都变成了 -1。这代表了”走一步”所付出的代价。此时，我们只考虑了即时奖励，还没有考虑未来的奖励。\n\nk = 2 时的迭代: \n\n使用 k=1 的价值来计算 k=2 的价值。价值的差异开始出现。\n\n计算示例 (以第(0,1)格为例):\n\n四个邻居状态：\n(0,0): 终止状态，价值为0\n(1,1): 价值为-1\n(0,2): 价值为-1\n(0,1): 往左撞墙，价值为-1\n\n\n\n\n\n\n分析: 靠近终止状态（价值为0）的格子，其价值变得”不那么负”，因为它们有25%的概率一步就”逃离”并停止付出代价。而离终止状态远的格子，比如中心位置，其价值会变得更负（-2.0），因为它周围都是需要继续付出代价的格子。\n\n\nk = 3 时的迭代: \n\n随着迭代的继续，价值信息会像波一样从终止状态向远处传播。\n迭代次数越多，价值函数就考虑得越”长远”。一个格子的价值反映了从它出发，在随机策略下平均需要走多少步才能到达终点。例如，在 k=∞ 时，中心的四个格子价值收敛为-20，表示从那里出发平均需要”走”20步才能结束。而紧邻终点的格子价值为-14，因为它们离”出口”更近。\n\n\n回到策略迭代既然我们已经根据策略评估计算出了价值函数，那么我们就可以根据价值函数来改进策略。这就是策略迭代的过程。\n如何调整呢？最简单的方法就是贪婪法。考虑一种如下的贪婪策略：个体在某个状态下选择的行为是其能够到达后续所有可能的状态中状态价值最大的那个状态。如上面的图右边。当计算出最终的状态价值后发现，第二行第一个格子周围的价值分别是0,-18,-20，此时用贪婪法，调整行动策略为向状态价值为0的方向移动，而不是随机移动。也就是图中箭头向上。而此时第二行第二个格子周围的价值分别是-14,-14,-20, -20。那么整行动策略为向状态价值为-14的方向移动，也就是图中的向左向上。\n图片右侧展示的内容就是策略迭代 (Policy Iteration) 思想的实际运用。这一列的箭头表示，如果我们根据左侧计算出的当前价值 来做出“贪心”决策，我们应该选择哪个方向。所谓“贪心”，就是选择能移动到的那个价值最高的邻居格子。\n演变过程如下:\n\nk = 0: 因为所有邻居价值都是0，所以往哪走都一样，策略是随机的。\n\nk = 1: 邻居中只有终止状态的价值（0）高于其他格子（-1），所以所有邻近终止状态的格子，其贪心策略都指向了终止状态。\n\nk = 2, 3…: 随着价值函数的精确化，贪心策略也变得越来越明确。箭头开始清晰地指向通往最近的终止状态的最短路径。\n\nk = 10, ∞: 此时，贪心策略已经稳定下来，不再改变。这个最终稳定下来的策略，就是该问题的最优策略 π*\n\n\n\n因此策略迭代分为两步: \n\n策略评估 (Policy Evaluation)\n\n对于当前固定的策略 ，我们需要计算出它所对应的真实的状态价值函数 。这个过程本身是一个迭代计算，通过反复应用贝尔曼期望方程的更新规则来进行，直到价值函数收敛。\n计算公式 (迭代形式):\n\n在这个内循环中，我们不断用上一轮的价值估计  来计算新一轮的价值估计 ，直到  和  之间的差异足够小（小于某个阈值 ）。\n\n策略改进 (Policy Improvement)\n\n我们利用上一步评估出的价值函数 ，对每一个状态的动作选择进行贪心 (Greedy) 的优化。\n首先, 对于每个状态 ，我们先计算出所有可能的动作  的动作价值 。这个q值代表了，如果仅在当前这一步选择动作 ，然后后续继续遵循旧策略 ，所能带来的期望总回报。\n\n然后，我们为状态  选择那个能够带来最大 q 值的动作，作为我们新策略  的选择。\n\n\n价值迭代 (Value Iteration)价值迭代算法的目标非常纯粹：它旨在直接计算出每个状态的最优价值 。它认为，只要我们知道了每个状态的“终极价值”，那么在任何状态下，选择能通往更高价值邻居的动作，自然就是最优策略。\n价值迭代的引擎只有一个，就是反复执行贝尔曼最优方程 (Bellman Optimality Equation) 的更新操作。\n\n然后直接提取最优策略 :\n\n\n最后, 我们总结这一讲的两种策略:\n\n值迭代是在价值空间中进行搜索。它通过贝尔曼更新，逐步将效用函数逼近最优效用函数。\n\n策略迭代则是在策略空间中进行搜索。它通过“评估-改进”的循环，一步步地跳向更优的策略。\n\n\n他们都涉及到了动态规划的本质：利用问题的最优子结构（一个状态的价值依赖于其后继状态的价值），并通过迭代的方式，将后继状态的价值信息“备份”回当前状态，最终求解出全局最优解。\n另一方面, 这两个算法都假设我们完全知道MDP的模型（即转移函数 T 和奖励函数 R）。它们是所谓的“基于模型的”方法。这为后续学习强化学习奠定了基础。\n强化学习研究的核心问题之一就是：当智能体不知道这些模型时，如何通过与环境的交互来学习到最优策略。我们将会看到，强化学习中的许多算法，都可以被看作是值迭代或策略迭代的无模型 (model-free) 版本。\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"计算理论简介","url":"/2025/09/15/algorithms/Computing%20Theory/Index/","content":"计算理论是计算机科学的基石，它试图从根本上回答三个关于“计算”这一过程的终极问题：\n\n能做什么？什么是算法？（可计算性, 不可判定性）\n用什么模型来做？（自动机与模型）\n能多快/多好地做？（复杂性）(本课程未涉及)\n\n这门学科本质上是数学的一个分支，它使用严谨的、抽象的数学模型来探索计算的本质、能力和极限 \n该课程安排在大三秋冬学期, 参考课本为《Elements of the Theory of Computation》. 课程的宏观框架如下: \n一、 数学预备知识（基础）\n在深入探讨计算理论之前，课程首先介绍了所需的基础数学语言和概念。这部分对应课本的第1章。\n核心内容：集合、关系、函数、有穷与无穷集合 、基本的证明技术（如数学归纳法、鸽巢原理和对角化方法）、字母表与语言，以及算法的初步介绍 。\n二、 形式语言与自动机理论\n这是计算理论的第一大核心板块。它主要研究“受限制的计算模型” ，探索它们的能力边界，这些模型在电路设计和编译器（如词法分析）等领域有实际应用 。这部分对应第2章和第3章。\n正则语言 (Regular Languages)：\n\n计算模型：使用有穷自动机 (Finite Automata) ，包括确定型（DFA）和非确定型（NFA） 。\n语言表示：使用正则表达式 (Regular Expressions) 。\n关键结果：证明了非确定型有穷自动机、确定型有穷自动机和正则表达式三者在表达能力上是等价的 。\n研究问题：状态最小化 、正则语言的泵定理（Pumping Lemma）以及如何证明一个语言不是正则的 。\n\n上下文无关语言 (Context-Free Languages)：\n\n计算模型：使用下推自动机 (Pushdown Automata) 。这是一种比有穷自动机更强，增加了“栈”（一种下推存储器）的计算模型 。\n语言表示：使用上下文无关文法 (Context-Free Grammars) 。\n\n上下文无关语言 (Context-Free Languages)：\n\n计算模型：使用下推自动机 (Pushdown Automata) 。这是一种比有穷自动机更强，增加了“栈”（一种下推存储器）的计算模型 。\n语言表示：使用上下文无关文法 (Context-Free Grammars) 。\n研究问题：语法分析（Parsing）与语法分析树（Parse Trees） 、文法的歧义性（Ambiguity）、以及上下文无关语言的泵定理。\n\n三、 可计算性理论 (Computability Theory)\n这是计算理论的第二大核心板块。它旨在建立一个“算法的一般模型”，并利用这个模型来回答计算机科学的根本问题：什么是可计算的？什么是不可计算的？这部分对应第4章和第5章。\n通用计算模型 (General Model of Computation)：\n\n核心模型：Turing 机 (Turing Machine) 。图灵机被视为描述任意算法的通用框架 。\n研究内容：引入Turing机的变种（如多带Turing机、随机存取Turing机） ，并证明它们在计算能力上都等价于基本的Turing机模型 。这也引出了 Church-Turing 论题 。\n\n不可判定性 (Undecidability)：\n\n核心问题：研究那些被证明“根本不可能用计算机解决”的问题 。\n关键结果：证明停机问题 (The Halting Problem) 是不可判定的 。\n研究内容：讨论其他不可判定的问题，如与文法或铺砖问题相关的不可解问题 。\n\n最后一部分是计算复杂性理论 (Complexity Theory), 这是计算理论的第三大核心板块。它研究那些可计算的问题，并根据其解决所需的资源（主要是时间或空间）来对其进行分类，探讨哪些问题存在“实际可行的算法”; 这部分定义了计算复杂性的概念，如P类问题、NP类问题、NPC问题和NP完全问题等, 由于课时安排暂且按下不表. \n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"正则语言与有限自动机","url":"/2025/09/15/algorithms/Computing%20Theory/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%9C%89%E9%99%90%E8%87%AA%E5%8A%A8%E6%9C%BA/","content":"","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"条款5：优先选用 auto, 而非显式型别声明","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/auto/%E6%9D%A1%E6%AC%BE5%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20auto,%20%E8%80%8C%E9%9D%9E%E6%98%BE%E5%BC%8F%E5%9E%8B%E5%88%AB%E5%A3%B0%E6%98%8E/","content":"在现代C++开发中, auto 关键字通过要求初始化、正确推导类型以及适应代码重构，避免了许多由于显式类型声明而导致的微妙的正确性和效率问题, 应当作为大部分情况下的首选项来使用。\nstd::functionstd::function 是 C++11 引入的一个非常强大且核心的工具，位于  头文件中。\n它是一个通用的、多态的函数包装器。它的核心价值在于，它可以用一个统一的类型来存储、传递和调用任何符合特定函数签名的“可调用对象”。\nstd::function 是什么？在 C++ 中，“可调用对象”（Callable Object）有多种形式，例如：\n\n普通函数\n函数指针\nLambda 表达式\n函数对象（Functor，即重载了 operator() 的类实例）\n类的成员函数（需要绑定到特定对象实例上）\n\nstd::function 是一个类模板，它提供了一个统一的类型来“包装”所有这些不同类型的可调用对象，只要它们的调用签名（即参数列表和返回值类型）相匹配, 例如:\n#include &lt;functional&gt;// 定义一个 std::function 变量 'func'// 它可以持有任何“接受一个 int 和一个 double，并返回一个 bool”的可调用对象std::function&lt;bool(int, double)&gt; func;\n\n为什么需要 std::function？在 C++11 之前，存储不同类型的可调用对象非常困难，因为它们各自拥有完全不同的、不兼容的 C++ 类型：函数指针的类型是 R(*)(Args…); 每个 Lambda 表达式都有一个由编译器生成的、独一无二的匿名闭包类型; 每个函数对象都有其自定义的类类型（例如 MyFunctor）。\n如果没有 std::function，我们无法创建一个变量或一个容器（如 std::vector）来同时持有上述这些不同类型的对象，即使它们的调用签名完全相同。\n而 std::function 提供了单一的、具体的类型（例如 std::function&lt;void(int)&gt;），它可以持有任何符合 void(int) 签名的可调用物。它实现了“类型擦除”（Type Erasure）机制，隐藏了底层可调用对象的原始类型，只暴露统一的调用接口。\n使用示例假设我们需要一个可以执行“接受一个 int 并返回 bool”操作的包装器, 我们可以让 myFunc 持有以下任何一种对象。\nstd::function&lt;bool(int)&gt; myFunc;// 1. 普通函数bool isEven(int x) {    return x % 2 == 0;}myFunc = isEven;  // 这里 myFunc 直接持有了函数 isEven 的指针。std::cout &lt;&lt; \"函数调用: \" &lt;&lt; myFunc(10) &lt;&lt; std::endl; // 输出 1 (true)// 2. Lambda 表达式（可以带状态）int divisor = 3;auto isDivisible = [divisor](int x) -&gt; bool {    return x % divisor == 0;};myFunc = isDivisible;  // 这是 std::function 最强大的用途之一。它能够存储 Lambda 表达式，包括 Lambda 捕获的状态（这里捕获了 divisor）。std::cout &lt;&lt; \"Lambda 调用: \" &lt;&lt; myFunc(9) &lt;&lt; std::endl; // 输出 1 (true)// 3. 函数对象struct IsGreaterThan {    int limit;    IsGreaterThan(int val) : limit(val) {}    bool operator()(int x) const {        return x &gt; limit;    }};IsGreaterThan comparator(100);myFunc = comparator;  // std::function 会在内部存储 comparator 对象的一个副本（或移动后的版本）。std::cout &lt;&lt; \"Functor 调用: \" &lt;&lt; myFunc(101) &lt;&lt; std::endl; // 输出 1 (true)\n\n最后, 需要注意的是 std::function 不是零成本抽象。为了实现类型擦除和存储任意可调用对象（特别是带状态的 Lambda），它通常需要在堆上进行动态内存分配（尽管许多实现带有“小缓冲区优化”(SBO) 来避免对小型对象的堆分配）。\n且调用 std::function 通常涉及一次间接函数调用（类似于虚函数调用），这比直接函数调用或模板化的函数调用要慢。\nauto可以解决未初始化变量问题在 C++ 中，显式声明类型允许变量不被初始化，这可能导致不确定的行为。而 auto 通过类型推导工作，它必须从变量的初始化物中推导类型。这就带来一个巨大的优势：使用 auto 声明的变量必须被初始化，否则代码将无法通过编译。\nint x; // 有潜在的未初始化风险auto x; // 编译错误！必须有初始化物auto x = 0; // 没问题，x 被明确定义\n这从根本上消除了一整类由于忘记初始化而导致的问题。\nauto处理冗长及编译器才知的类型auto 可以极大地简化代码，特别是当类型名称非常冗长或难以书写时。例如，在 C++98 中获取迭代器所指向的值的类型非常繁琐, 而使用 auto，代码变得清晰简洁：\ntypename std::iterator_traits&lt;It&gt;::value_type currValue = *b;auto currValue = *b;\n更重要的是，有些类型只有编译器知道，开发者根本无法显式写出，最典型的例子就是 lambda 表达式生成的闭包 (closure) 类型。auto 是存储闭包的理想且唯一直接的方式。\n当然, 虽然可以使用 std::function 来存储闭包，但这与 auto 相比存在显著差异：\n\nauto：使用 auto 声明的、存储闭包的变量与该闭包是同一类型，它占用的内存量与闭包完全相同。\nstd::function：这是一个模板的实例，它占有固定尺寸的内存。如果这个尺寸对于它要存储的闭包不够用，std::function 的构造函数会分配堆内存来存储该闭包。\n\n因此，std::function 的方法通常比 auto 方法占用更多内存，速度更慢（可能导致堆分配和间接函数调用），而 auto 则避免了这些开销。\nauto避免“类型捷径”带来的正确性与效率问题这是优先选用 auto 最有力的论据之一。开发者在显式指定类型时，有时会不经意间写下“错误”的类型，这可能导致隐式类型转换，从而引发正确性或效率问题。auto 可以保证推导出正确的类型。\n一个示例是下面的v.size() 与 unsigned 的陷阱:\n标准规定 std::vector::size() 返回的类型是 std::vector::size_type。但在实际编码中，很多程序员会“偷懒”地将其存储在 unsigned 中。\nstd::vector&lt;int&gt; v;unsigned sz = v.size(); // 显式类型，但可能不正确\n这种写法存在移植性问题。例如，在32位 Windows 上，unsigned 和 std::vector::size_type 都是32位；但在64位 Windows 上，unsigned 仍然是32位，而 size_type 却是64位。如果容器中的元素超过 ，这段代码在64位系统上就会表现异常。\n使用 auto 则完全避免了这个问题，它保证推导出正确的类型：\nauto sz = v.size(); // 正确，sz 的类型是 std::vector&lt;int&gt;::size_type\n\n还有个示例是遍历 std::unordered_map 的陷阱:\n在遍历 std::unordered_map 时，很多程序员会写出如下代码：\nstd::unordered_map&lt;std::string, int&gt; m;for (const std::pair&lt;std::string, int&gt;&amp; p : m) {    // ...}\n这段代码看起来完全合理，但其实是错误的。std::unordered_map 中键值对的实际类型是 std::pair&lt;const std::string, int&gt;（因为键是 const 的），这与循环变量 p 的类型 std::pair&lt;std::string, int&gt; 并不匹配。\n为了让代码通过编译，编译器会在循环的每次迭代中，复制哈希表中的元素来创建一个临时对象，然后将引用 p 绑定到那个临时对象上。这会导致不必要的复制开销，而且如果对 p 取址，得到的将是一个指向临时对象的指针。\n使用 auto 可以轻松解决这个微妙的错误：\nfor (const auto&amp; p : m) {    // ...}\nauto 会被正确推导为 std::pair&lt;const std::string, int&gt;，引用 p 会被直接绑定到 map 中的元素，既高效又正确。\n同时, 使用 auto 的代码更具适应性。如果一个函数的返回类型发生了变化（例如，从 int 改为 long），调用该函数并将结果存储在 auto 变量中的客户端代码，在下次编译时会自动更新变量类型。如果代码显式指定了 int，则需要开发者手动查找并修改所有调用点。\n\n最后, 虽然有些开发者担心 auto 会降低代码的可读性（因为无法一眼看出类型），但现代 IDE 通常可以显示推导出的类型。而且在很多情况下，了解变量的抽象概念（例如它是一个“容器”或“计数器”）比知道它的精确类型更重要，这可以通过良好的变量命名来传达。\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款6：auto 推导的型别不符合要求时，使用带显式型别的初始化物习惯用法","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/auto/%E6%9D%A1%E6%AC%BE6%20-%20%20auto%20%E6%8E%A8%E5%AF%BC%E7%9A%84%E5%9E%8B%E5%88%AB%E4%B8%8D%E7%AC%A6%E5%90%88%E8%A6%81%E6%B1%82%E6%97%B6%EF%BC%8C%E4%BD%BF%E7%94%A8%20%E5%B8%A6%E6%98%BE%E5%BC%8F%E5%9E%8B%E5%88%AB%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E7%89%A9%E4%B9%A0%E6%83%AF%E7%94%A8%E6%B3%95/","content":"虽然 auto 是一个强大的工具（如条款5所述），但它推导出的类型有时会与程序员的直觉或意图不符。这种情况尤其容易发生在涉及“隐形”代理类（proxy class）的表达式中。\n\n什么是代理类: 在 C++ 中，代理类（Proxy Class）是一种设计模式的实现，属于结构型设计模式的一种。它的主要作用是为某个对象提供一个替代者或中介，以控制对该对象的访问。这个模式被称为代理模式（Proxy Pattern）。广为人知的std::shared_ptr即是这一类\n\nauto遇到代理类下面使用 std::vector 作为核心示例。假设我们有一个函数返回 std::vector，并且我们想获取第五个元素, 下面的代码可以正常运行。\nstd::vector&lt;bool&gt; features(const Widget&amp; w);Widget w;bool highPriority = features(w)[5]; // 显式声明类型为 boolprocessWidget(w, highPriority); // 正常运行\n然而，如果只是简单地将 bool 替换为 auto，就会导致未定义行为：\nauto highPriority = features(w)[5]; // 类型推导processWidget(w, highPriority); // 未定义行为！\n究其原因, 在于使用auto推断遇到了std::vector的代理类, 而不是bool类型。\nstd::vector 是标准库中的一个特化版本，它为了节省空间，将每个布尔值存储为一个比特位。由于 C++ 禁止对单个比特位（bit）进行引用，因此 std::vector 的 operator[] 并不会返回 bool&amp;。相反，它返回一个扮演 bool&amp; 角色的代理类对象，这个类的类型是 std::vector::reference。\n这个 std::vector::reference 代理对象被设计为可以隐式转换为 bool（即它所代表的比特位的值）。对于前一类代码bool highPriority = ...，在这行代码中，features(w)[5] 返回一个 std::vector::reference 对象。为了初始化 bool 类型的变量 highPriority，这个代理对象会执行向 bool 的隐式类型转换。因此，highPriority 得到了第5个比特位的值，一切正常。\n而在后者中, features(w) 返回的是一个临时对象 (一个右值 std::vector)。且operator[] 返回的 std::vector::reference 代理对象（现在被 highPriority 持有）其内部实现通常包含一个指向那个临时向量所管理的机器字的指针。在 auto highPriority = ... 这条语句的末尾，features(w) 返回的临时 std::vector 对象被析构了。这导致 highPriority（那个代理对象）现在内部持有一个空悬指针 (dangling pointer)。当这个含有空悬指针的 highPriority 对象在后续代码（如 processWidget）中被使用时，就会产生未定义行为。\n因此, 我们要避免写出auto someVar = 隐形”代理型别表达式的代码。\n解决方案：带显式型别的初始化物习惯用法auto 本身并不是问题所在；问题在于它推导出的类型（代理类）不是我们想要的类型（值 bool）。\n条款6提出的解决方案是继续使用 auto，但通过显式类型转换来“引导” auto 推导出我们想要的类型。这种方法被称为“带显式型别的初始化物习惯用法”（explicitly typed initializer idiom）。\n// 通过 static_cast&lt;bool&gt;(...) 强制调用该代理对象的向 bool 的类型转换运算符auto highPriority = static_cast&lt;bool&gt;(features(w)[5]);\n\n这种习惯用法不仅限于解决代理类问题，它还可以用来明确表达程序员的意图，使那些故意的类型转换在代码中更加清晰可见\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款10：优先选用限定作用域的枚举型别，而非不限作用域的枚举型别","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE10%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E9%99%90%E5%AE%9A%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%9A%84%E6%9E%9A%E4%B8%BE%E5%9E%8B%E5%88%AB%EF%BC%8C%E8%80%8C%E9%9D%9E%E4%B8%8D%E9%99%90%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%9A%84%E6%9E%9A%E4%B8%BE%E5%9E%8B%E5%88%AB/","content":"C++98 风格的枚举（现在称为不限作用域的枚举型别）存在两个主要缺陷。C++11 引入的限定作用域的枚举型别（也称“枚举类”）则直接解决了这两个问题。\n了解枚举在 C++ 中，枚举 (Enumeration, 简称 enum) 是一种用户自定义的数据类型，它允许我们为一组相关的整型常量赋予具有描述性的名称。\n使用枚举的主要目的是增强代码的可读性和类型安全，避免在代码中直接使用“魔术数字”（Magic Numbers，即未经解释的字面常量）。\nC++ 语言中存在两种截然不同的枚举类型：\n\n不限定作用域的枚举（Unscoped Enumerations，也称为 C 风格枚举）\n限定作用域的枚举（Scoped Enumerations，C++11 引入，使用 enum class 关键字）\n\n不限定作用域的枚举 (C 风格)这是从 C 语言继承而来的传统枚举, 它使用 enum 关键字定义。\n// 定义一个表示颜色的枚举enum Color {    RED,    // 默认值为 0    GREEN,  // 默认值为 1    BLUE    // 默认值为 2};enum Status {    Pending = 10,    Processing,   // 未指定，值为前一个 + 1，即 11    Completed = 20,    Failed        // 值为 21};\n这里我们定义了一个名为 Color 的新类型。RED、GREEN 和 BLUE 是这个类型的枚举器（Enumerators）。其赋值的默认规则是，第一个枚举器（RED）的值为 0，后续枚举器依次递增 1; 我们也可以为枚举器指定具体的值，如 Pending = 10, Completed = 20。\n尽管 C 风格枚举提高了可读性，但它在 C++ 中存在两大严重问题：\n\n缺陷一：作用域污染 (Scope Pollution): C 风格枚举的枚举器会泄漏到其外围作用域（例如，全局作用域或所在的命名空间/类）。\n\nenum Color { RED, GREEN, BLUE };enum TrafficLight { RED, YELLOW, GREEN }; // 编译错误！// 错误原因：RED 和 GREEN 在同一作用域内被重复定义了。// 编译器无法区分 Color 的 RED 和 TrafficLight 的 RED。\n\n缺陷二：弱类型与隐式转换 (Weak Typing): C 风格枚举的枚举器会自动地、隐式地转换为整型（如 int）。这破坏了类型安全。\n\nColor myColor = RED;int colorValue = myColor; // 合法，myColor (值为 0) 被隐式转换为 int 0if (myColor == 0) { // 合法，但不推荐    // ...}// 更糟糕的是，不同枚举类型之间也可能进行比较（只要它们底层值相同）TrafficLight light = RED; // 假设 TrafficLight 的 RED 也是 0if (myColor == light) { // 编译通过！    // 这种比较在逻辑上是无意义的，但编译器允许}\n\n限定作用域的枚举 (C++11 enum class)为了解决上述所有问题，C++11 引入了“限定作用域的枚举”，也称为“枚举类”。这是在现代 C++ 中定义枚举的首选方式。它使用 enum class 关键字（或者等效的 enum struct）来定义。\nenum class Color {    RED,    GREEN,    BLUE};enum class TrafficLight {    RED,    YELLOW,    GREEN};\n\n它的优势一是强作用域 (Strongly Scoped): enum class 的枚举器被严格限制在枚举类型的花括号内，不会泄漏到外部作用域。不过也正因此, 访问这些枚举器时，必须使用枚举类型名称作为限定符。\n// 必须通过类型名::枚举器 来访问Color myColor = Color::RED; TrafficLight light = TrafficLight::RED;// 编译通过！// Color::RED 和 TrafficLight::RED 位于不同作用域，互不干扰。Color c = RED; // 编译错误！RED 不在当前作用域中。\n\n优势二是强类型，禁止隐式转换为整型. 这是 enum class 提供的最关键的类型安全保证。\nColor myColor = Color::RED;int colorValue = myColor; // 编译错误！                        // 无法将 Color 类型隐式转换为 intif (myColor == 0) { // 编译错误！                  // 无法在 Color 类型和 int 类型之间进行比较}// 不同枚举类型之间也不能比较if (myColor == TrafficLight::RED) { // 编译错误！}\n\n\n如果确实需要将枚举值转换为整数，我们必须使用显式类型转换（通常是 static_cast）。强制使用 static_cast 表明程序员是有意图地要将这个具有强类型的枚举值转换为一个普通的整数，这使得代码意图更加清晰。\n\n两者的底层类型在C++98的默认情况下，编译器会为枚举选择一个足够大的整数类型（如 int）来存储所有枚举值, 但这必须要求枚举定义完成之后(也就是C++98无法实现枚举的前向声明)。但在 C++11 中，我们可以为两种枚举（C 风格和 enum class）显式指定底层存储类型, 主要的好处在于: \n\n内存控制： 当枚举值范围很小时（例如 0-255），可以指定一个小的类型（如 std::uint8_t，即无符号 8 位整数），这在定义大型数组或内存敏感的结构体时非常重要。\nAPI 兼容性： 确保与需要特定整数宽度（如 32 位）的 C API 或库函数兼容。\n前向声明： enum 如果指定了底层类型，就可以被前向声明（在头文件中提前声明类型，而在 .cpp 中定义具体内容）。\n限定作用域(enum class)的枚举默认的底层类型是 int , 由于底层类型总是已知的（要么是默认的 int，要么是用户指定的），因此它们总是可以被前置声明(总之限定作用域的枚举更优越) 。\n不限作用域(enum)的枚举没有默认的底层类型, 因此必须显式指定了底层类型，不限作用域的枚举才可以被前置声明 。\n\n\n\n// 语法：enum class 类型名 : 底层整数类型 { ... };// 这个枚举将使用一个 8 位的无符号字节来存储enum class CompactColor : std::uint8_t {    RED,    GREEN,    BLUE};","categories":["language"],"tags":["language","CPP"]},{"title":"条款 15 - 只要有可能使用 constexpr, 就使用它","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE15%20-%20%E5%8F%AA%E8%A6%81%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BD%BF%E7%94%A8%20constexpr,%20%E5%B0%B1%E4%BD%BF%E7%94%A8%E5%AE%83/","content":"constexpr（Constant Expression，常量表达式）是 C++11 引入的一个至关重要的关键字，它允许我们将计算的执行时机从运行时 (Runtime) 提前到编译时 (Compile Time)。\n这不仅仅是一项微小的优化，它从根本上改变了 C++ 的编程范式，使得在编译阶段进行复杂的计算和逻辑判断成为可能，从而提高了程序的运行效率并增强了编译期的检查能力。\nconstexpr 对象/变量当 constexpr 应用于对象时，它实际上是 const 属性的加强版。\nconst 对象：一个被声明为 const 的对象，其值在初始化后不能被修改。但是，它的初始值不一定在编译期就已知。它可以由一个运行时才计算出的值来初始化。\nint sz;const auto arraySize = sz; // 合法，但 arraySize 的值在编译期未知// std::array&lt;int, arraySize&gt; data; // 错误！arraySize 不是编译期常量\n\nconstexpr 对象：该对象不仅是 const 的，而且其值必须在编译期就已知（准确地说是“翻译期间”可知）。并且所有 constexpr 对象都是 const 对象，但并非所有 const 对象都是 constexpr 对象。正因如此, 它强制要求该变量必须在编译时被一个“常量表达式”初始化\n由于其值在编译期已知，constexpr 对象拥有特权，它们可以被用在 C++ 要求“整型常量表达式”的任何语境中，例如指定数组的尺寸（C-style 数组，非 std::vector）int arr[N] (这里的 N 必须是编译期常量)、作为模板的非类型参数(Non-Type Template Arguments) std::array&lt;int, N&gt; (这里的 N 必须是编译期常量)、枚举量的初始化值等。\nconstexpr auto arraySize2 = 10; // 没问题，10 是编译期常量std::array&lt;int, arraySize2&gt; data; // 没问题！\n\nconstexpr 函数当 constexpr 应用于函数时，其含义变得更加灵活: 首先, 一个 constexpr 函数不一定返回编译期已知的结果。\n\n如果一个 constexpr 函数被调用时，传入的实参都是编译期常量，那么该函数的产出结果也将是一个编译期常量。\n如果它被调用时，传入的参数中至少有一个是运行时才已知的值，那么该函数将会在运行时被执行，其行为和结果都与普通函数无异。\n\n这是 constexpr 函数最强大的特性：只需编写一次函数，它就可以同时服务于编译期和运行时两种场景。\n// 一个 constexpr 阶乘函数constexpr long long factorial(int n) {    return (n &lt;= 1) ? 1 : (n * factorial(n - 1));}// === 场景 1: 编译时使用 ===// 因为参数 5 是一个编译期常量（字面量），// 编译器会直接在编译期间计算 factorial(5)，即 120。constexpr long long F5 = factorial(5);// 下面这行代码在编译后，等同于 std::array&lt;int, 120&gt; arr;std::array&lt;int, factorial(5)&gt; arr; // === 场景 2: 运行时使用 ===std::cout &lt;&lt; \"请输入一个数字: \";int x;std::cin &gt;&gt; x; // x 是一个运行时变量// 编译器无法在编译时知道 x 的值，// 于是 factorial(x) 会像一个普通函数一样，在程序运行时被调用和计算。long long result = factorial(x); std::cout &lt;&lt; \"结果是: \" &lt;&lt; result &lt;&lt; std::endl;\n我们只编写了一个 factorial 函数，但它既能用于需要编译期常量的模板参数（场景1），也能用于处理运行时的用户输入（场景2）。这就是 constexpr 函数的核心价值。\n\n需要注意的是, 上面那个 factorial 示例就是 C++11 风格的。在 C++11 中，constexpr 函数几乎是“函数式”的。它内部只能包含一个单独的 return 语句, 不允许有局部变量、循环，只允许使用（极其复杂的）递归和三元运算符（?:）来实现逻辑。而C++14后的constexpr 函数基本与正常函数无异\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款16：保证 const 成员函数的线程安全性","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE16%20-%20%E4%BF%9D%E8%AF%81%20const%20%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7/","content":"mutable关键字mutable（意为“可变的”）是一个存储说明符关键字，它的唯一目的就是“突破 const 限制”。\n我们知道，一个被 const 修饰的成员函数（例如 void myFunction() const;）向调用者承诺：“这个函数不会修改对象的任何成员变量。”. 然而, 因为 mutable 用于修饰类的非静态数据成员, 一旦一个成员变量被声明为 mutable，那么即使在一个 const 成员函数中，这个变量也可以被修改。\n也就是说, mutable 是 const 这个规则的一个“例外条款”。\nclass MyClass {private:    int regularValue;    mutable int mutableValue; // 被 mutable 修饰public:    MyClass(int v1, int v2) : regularValue(v1), mutableValue(v2) {}    void regularFunc() {        regularValue = 100;   // OK：普通函数可以修改普通成员        mutableValue = 200;   // OK：普通函数当然也可以修改 mutable 成员    }    void constFunc() const {        // regularValue = 100; // 编译错误！const 函数不能修改非 mutable 成员        mutableValue = 200;   // 正确！mutable 成员可以在 const 函数中被修改    }};\n为什么需要 mutable？你可能会问：const 函数的意义不就是“不修改”吗？允许修改岂不是违背了初衷？这里引出了 C++ 中关于 “const” 的两个重要概念：\n\n按位 Const (Bitwise Constness)：这是编译器默认的实现方式。只要一个成员函数没有修改对象内存布局中的任何一个 bit（位），它就是 const 的。\n逻辑 Const (Logical Constness)：这是开发者和调用者所期望的。只要一个成员函数没有修改对象的“外部可见的逻辑状态”，它就应该是 const 的。\n\n在大多数情况下，两者是一致的。但有时，为了维持“逻辑上的不变”，我们可能需要修改一些“内部实现上的细节”。mutable 就是用来实现“逻辑 Const”的工具。\nmutable用例用例 1：缓存 (Caching) / 延迟计算 (Memoization)假设你有一个类，它有个函数需要执行非常昂贵的计算，但这个计算结果在对象生命周期内是固定的。\nclass ExpensiveCalculator {private:    SomeInputData data;        // 用于缓存计算结果    mutable double cachedResult;     mutable bool cacheValid = false; // 跟踪缓存是否有效    double expensiveCalculation() const {        // ... 执行非常复杂和耗时的计算 ...        return 42.0;     }public:    double getValue() const { // 这是一个 const 函数，因为它逻辑上不改变计算器的状态        if (!cacheValid) {            // 这是修改操作，但它只发生在 const 函数内部            cachedResult = expensiveCalculation(); // 必须是 mutable            cacheValid = true;                     // 必须是 mutable        }        return cachedResult;    }};\ngetValue() 承诺自己是 const 的，因为它返回的值（逻辑状态）始终是相同的。但是为了提高性能，它在内部使用了 mutable 变量来缓存结果。从外部调用者看来，这个对象没有发生任何逻辑上的改变, 尽管内部的确发生了一些无关紧要的优化类型的变量改变.\n用例 2：用于 Mutex假设我们有一个类，它的大多数成员函数都是 const（因为它们只是读取数据），但我们希望这些读取操作在多线程环境下是安全的。\nclass ThreadSafeReader {private:    std::string sharedData = \"Data\";    mutable std::mutex dataMutex; // 关键！Mutex 必须是 mutable 的public:    std::string getData() const { // 这是一个 const 成员函数                // 我们需要锁，因为可能有其他线程（通过非 const 函数）正在写入 sharedData        // 但是 lock() 是一个“非 const”操作（它会修改 mutex 内部的状态）        // 为了能在 const 函数 getData() 内部调用 dataMutex.lock()，        // dataMutex 必须被声明为 mutable。                std::lock_guard&lt;std::mutex&gt; guard(dataMutex); // 这在编译上是合法的                return sharedData;    }    void setData(const std::string&amp; s) {        std::lock_guard&lt;std::mutex&gt; guard(dataMutex);        sharedData = s;    }};\n在这个例子中，getData() 从逻辑上看是 const 的（它只是返回数据，不改变类的逻辑状态）。但是为了保证线程安全，它必须对内部的 dataMutex 进行 lock() 操作。lock() 操作会修改 mutex 对象本身的状态。因此，为了让编译器允许 const 函数修改 mutex 成员，这个 mutex 必须被声明为 mutable。\n这是 mutable 最常见、最标准的用途之一：允许 const 成员函数获取锁以实现线程安全。\nmutex 互斥量mutex 不是关键字，它是 C++11 在  头文件中提供的一个类，全称为 Mutual Exclusion（互斥）。\n它是多线程编程中的一种同步原语（Synchronization Primitive）, 其核心作用是保护共享资源，以防止多个线程同时访问和修改该资源时引发的竞态条件 (Race Condition)。\n为什么需要 mutex？在多线程程序中，如果多个线程同时尝试修改同一个变量（例如一个全局计数器 counter），就会发生问题。\n一个简单的 counter++ 操作在底层汇编中通常至少包含三个步骤：\n\n读取 (Read)：将 counter 的当前值从内存加载到 CPU 寄存器。\n修改 (Modify)：在寄存器中将该值加 1。\n写回 (Write)：将寄存器中的新值写回到内存中的 counter 位置。\n\n竞态条件示例：假设 counter 当前为 10, 首先线程 A 读取 counter得到 10（此时发生上下文切换）, 线程 B 读取 counter (也得到 10); 接着线程 B 修改寄存器变为 11并写回 11 到 counter; 然后再切回线程 A(不同线程执行时间有差异), 线程 A 仍然拿着旧值 10修改寄存器变为 11并写回 11 到 counter。\n最后的结果是两个线程都执行了 ++ 操作，但 counter 的最终结果是 11，而不是预期的 12。数据损坏了。\nMutex 如何工作？mutex 通过提供两个核心操作 lock() 和 unlock() 来解决这个问题。\n我们可以把共享资源（如 counter）想象成一个“秘密会议室”，而 mutex 就是挂在门上的“唯一的锁”。\n\n临界区 (Critical Section)：那段必须被保护起来、不允许并发执行的代码（如 counter++）被称为“临界区”。\nlock()：当一个线程想要进入临界区时，它必须先尝试获取锁，即调用 my_mutex.lock()。如果锁可用，该线程获取锁，然后进入临界区; 如果锁已被其他线程持有，该线程将阻塞 (Block)，直到那个线程释放锁。\nunlock()：当线程完成临界区的工作后，它必须释放锁，即调用 my_mutex.unlock()，以便其他正在等待的线程可以获取它。\n\n通过这种机制，mutex 确保了在任何时刻，只有一个线程能够进入临界区，从而保证了操作的原子性 (Atomicity)。\n现代 C++ 中的安全用法：RAII 与 std::lock_guard手动调用 lock() 和 unlock() 是非常危险的。如果在 lock() 之后、unlock() 之前，代码抛出了一个异常，那么 unlock() 将永远不会被调用，这个锁将永久锁定，所有其他等待该锁的线程将无限期阻塞（称为死锁 Deadlock）。\n为了解决这个问题，C++ 提供了 RAII（资源获取即初始化）模式的封装类：std::lock_guard。\n#include &lt;mutex&gt;#include &lt;thread&gt;int counter = 0;std::mutex mtx; // 全局互斥量，用于保护 countervoid thread_task() {    for (int i = 0; i &lt; 10000; ++i) {        // 安全的做法：使用 lock_guard        // 1. 当 guard 对象被创建时（构造函数），它自动调用 mtx.lock()        std::lock_guard&lt;std::mutex&gt; guard(mtx);                counter++; // 这里是临界区，现在是线程安全的                // 2. 当 guard 离开作用域时（在 '}' 处），其析构函数被自动调用，        //    析构函数会自动调用 mtx.unlock()。        //    即使 counter++ 抛出异常（虽然 int++ 不会），析构函数也会被调用，保证解锁。    }}\nstd::lock_guard 利用了 C++ 的构造函数和析构函数机制。在构造时自动加锁，在析构时（无论函数是正常返回还是因异常退出）自动解锁，从而完美地保证了锁的释放。\nstd::atomic我们之前讨论了 mutex（互斥锁）。mutex 采用阻塞 (Blocking), 是解决多线程数据竞争的一种重量级的同步机制。而 std::atomic 提供了一种非阻塞 (Non-Blocking) 的同步方式。下面我们先了解一下 std::atomic \n\n多线程阻塞这种“挂起”和“唤醒”操作涉及到了操作系统内核态与用户态的切换，这是一个非常昂贵（高延迟）的操作。对于那些需要频繁更新、但冲突并不严重的共享变量（例如一个全局访问计数器），使用 mutex 就像“杀鸡用牛刀”，开销太大了。\n\nstd::atomic 是 C++11 引入的一个极其重要的特性，它位于  头文件中。它是 C++ 底层内存模型和原子操作的基石，也是实现无锁编程 (Lock-Free Programming) 的核心工具。\nstd::atomic 提供了一种能力，使得对某个变量的简单操作（如读、写、增、减、交换等）可以原子性 (Atomically) 地完成。它依赖于 CPU 硬件层面提供的原子指令 (Atomic Instructions)（例如 x86 上的 LOCK CMPXCHG）。这些特殊的 CPU 指令可以在硬件层面保证一个“读-改-写”的操作序列在执行的中途不会被任何其他线程打断（即它是原子的）。\n当一个变量被声明为 std::atomic 时，编译器会确保对这个变量的所有操作都转化为这些特殊的原子 CPU 指令，而不是我们之前担心的普通的“读、改、写”三部曲。\n上述示例中采用std::atomic的同款代码如下:\n#include &lt;atomic&gt;std::atomic&lt;int&gt; atomic_counter(0); // 将 counter 封装为 atomic 类型void task() {    atomic_counter++; // 这一行代码会被编译成一条单一的、原子的 CPU 指令                       // (例如在 x86 上是 \"LOCK XADD\")                           // 或者使用等效的 fetch_add，语义更清晰：    atomic_counter.fetch_add(1); // 以原子的方式“取回当前值并加1”}\n在 atomic 版本中，当多个线程同时执行 atomic_counter.fetch_add(1) 时，CPU 硬件会保证这些指令依次排队执行，一个完成了下一个才能开始（在极小的 CPU 指令时间尺度上），它们不会像普通 ++ 那样发生“读-改-写”步骤的交错。\n最重要的是，这个过程完全在用户态完成，没有线程会被操作系统挂起（阻塞）。如果发生冲突，线程通常只会进行几次“自旋 (Spin)”（即 CPU 空转几个周期再试一次），这比内核调度的开销小得多。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款14：只要函数不会发射异常，就为其加上 noexcept 声明","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE14%20-%20%E5%8F%AA%E8%A6%81%E5%87%BD%E6%95%B0%E4%B8%8D%E4%BC%9A%E5%8F%91%E5%B0%84%E5%BC%82%E5%B8%B8%EF%BC%8C%E5%B0%B1%E4%B8%BA%E5%85%B6%E5%8A%A0%E4%B8%8A%20noexcept%20%E5%A3%B0%E6%98%8E/","content":"正如标题所指出的, noexcept 是一个关键的函数接口规范，它能带来显著的编译器优化，并对移动语义的实现至关重要。\n\n在 C++11 之前，C++98 提供了异常规格（如 throw(SomeException) 或 throw()），但这套机制要求开发者列出函数可能抛出的所有异常类型，这在实践中难以维护，且编译器通常不会严格检查其一致性，导致该特性最终被普遍弃用。实际上, 开发者真正关心的信息是二元的：一个函数是否可能发射异常。noexcept 声明就是 C++11 中用于保证函数不会发射异常的工具\n\n核心动机：编译器优化为函数添加 noexcept 声明的最直接动机是，它允许编译器生成更优的目标代码。这源于 noexcept 和 C++98 的 throw() 在违反承诺时的不同处理方式：\n\nint f(int x) throw(); (C++98 风格)：如果在运行时，一个异常企图逸出 f 的作用域，程序会中止，但在中止前，调用栈必须被“展开”（unwound）至 f 的调用方。\n\nint f(int x) noexcept; (C++11 风格)：如果一个异常企图逸出 f 的作用域，程序也会中止，但标准规定栈只是可能会被开解。\n\n\n这个“必须开解”与“可能开解”的区别对优化器至关重要。对于一个 noexcept 函数，编译器在生成代码时，无需在异常逸出函数时将执行期栈保持在可开解状态，也无需保证函数内的所有对象以其构造顺序的逆序完成析构。这种灵活性使得优化器可以生成更精简、更高效的代码。而没有 noexcept 声明的函数则无法享受这种优化。\n关键用例：noexcept 与移动语义noexcept 最重要的实际应用在于它与移动语义的交互。许多 C++11 的功能（特别是标准库容器）为了性能会优先选用移动操作而非复制操作，但前提是它们必须保证不破坏 C++98 代码所依赖的异常安全承诺。\n以 std::vector::push_back 为例：当向 std::vector 添加一个新元素，而此时其 size() 等于 capacity() 时，vector 必须分配一块新的、更大的内存，并将所有旧元素转移到新内存中。\n\nC++98 (复制)：在 C++98 中，这个转移是通过复制元素完成的。这提供了强异常安全保证：如果在复制第 n+1 个元素时抛出异常（例如内存不足），vector 可以保持在原始状态（因为旧内存中的元素都还在, 旧内存中的元素直至所有的元素被成功复制入新内存以后，才会被执行析构），保证了数据的不变性。\nC++11 (移动)：在 C++11 中，使用移动操作来转移元素会高效得多。但是，移动操作通常会“掏空”源对象。如果在移动了 n 个元素后，在移动第 n+1 个元素时抛出异常，此时操作无法回滚：旧内存中的前 n 个元素已被移走（处于无效状态），而新内存也没有完全构建好。这破坏了强异常安全保证。\n\n为了解决这个冲突，std::vector::push_back 等函数在 C++11 中遵循一个规则：它们只会在元素的移动构造函数被显式声明为 noexcept 时，才会使用移动操作。如果移动构造函数没有 noexcept 声明（意味着它可能会抛出异常），vector 将退回到使用（更慢的）复制操作，以确保强异常安全保证不被破坏。\n\nstd::vector::push_back 采取了这种“能移动则移动，必须复制才复制” (move if you can, but copy if you must) 策略, 而它并不是标准库中唯一这样做的函数。 C++98 中其他因为强异常安全保证而酷炫的函数 (std::vector:: reserve, std::deque::insert 等）的行为也是这样。所有这些函数都把其中 C++98 的复制操作替换成了 C++11 中的移动操作，但仅在已经移动操作不会发射异常(声明为noexcept)的前提下。\n\n连锁效应：swap 函数前面的规则似乎已经很完备, 然而, 对于模板（template）或管理其他类型成员的复合类型（composite types），我们编写函数时（如 swap），并不知道它所操作的底层类型是否会抛出异常。这就是 noexcept(expression) 这种用法（条件 noexcept）的用武之地。这里的关键是区分：\n\nnoexcept 关键字（修饰符）：放在函数声明的末尾，告诉编译器这个函数是否承诺不抛出异常。\n\nnoexcept(expression) 运算符：一个在编译期求值的运算符。如果 C++ 编译器确定 expression 表达式（它并不会真的执行这个表达式，只是分析它）保证不会抛出异常（即表达式本身是 noexcept 的），那么这个运算符返回 true；否则返回 false。\n\n\n下面是针对数组和pair的条件noexcept示例:\ntemplate &lt;class T, size_t N&gt; void swap(T (&amp;a)[N], T (&amp;b)[N])     noexcept(noexcept(swap(*a, *b))); template &lt;class T1, class T2 &gt; struct pair {     void swap(pair&amp; p) noexcept(noexcept(swap(first, p.first)) &amp;&amp;                                 noexcept(swap(second, p.second)));     // ...};\n第一个模板代码是一个针对 C 风格数组（具有相同类型 T 和相同大小 N）的 swap 函数模板的特化版本。我们知道, 要交换两个数组，其实现（例如 std::swap 对数组的实现）通常是遍历数组，并对数组中的每一个对应元素执行 swap 操作。\n而这个数组 swap 函数是否会抛出异常？这完全取决于它在循环内部调用的 swap(a[i], b[i]) 是否会抛出异常。如果交换一个 T 类型的元素（swap(T&amp;, T&amp;)）是 noexcept 的，那么交换整个数组（循环执行N次）也自然是 noexcept 的。反之，如果交换 T 可能会抛异常，那么这个数组 swap 函数也必须被视为可能抛异常。\n这便是代码noexcept(noexcept(swap(*a, *b)))的意义, 内部的 noexcept(swap(*a, *b))是一个 noexcept 运算符, 它检查是否调用类型 T 的 swap（即 swap(T&amp;, T&amp;)）被声明为 noexcept. 如果是，noexcept 运算符返回 true; 外部的 noexcept(…)是一个 noexcept 修饰符, 它接收内部运算符返回的 bool 值（true 或 false）并决定是否修饰函数。第二个示例同理\n通过使用条件 noexcept，这些模板（数组 swap）和复合类型（pair）能够将其自身的异常规范建立在其所依赖的底层类型的异常规范之上。\n\n最后还要区分“异常中立”函数：大多数函数本身不抛出异常，但它们调用的其他函数可能会抛出异常。这种“路过”异常的函数被称为“异常中立” (exception-neutral) 的，它们也不应该被声明为 noexcept。\n\n\n在 C++11 中，默认规定内存释放函数和所有的析构函数（无论是用户定义的，还是编译器自动生成的）都隐式地具备 noexcept 性质。\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 17 - 理解特种成员函数的生成机制","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE17%20-%20%E7%90%86%E8%A7%A3%E7%89%B9%E7%A7%8D%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%9F%E6%88%90%E6%9C%BA%E5%88%B6/","content":"“特种成员函数”指的是那些C++编译器在特定情况下会自动生成的成员函数。在C++11之后, 特种成员函数指的是默认构造函数, 析构函数, 拷贝构造函数, 拷贝赋值运算符, 移动构造函数, 移动赋值运算符。一般来说, 这些函数仅在代码中需要它们，且程序员没有显式声明它们时才会被自动生成。同时, 这些函数的自动生成存在一些机制, 下面我们来详细了解一下。\n移动操作的生成规则编译器仅在同时满足以下所有三个条件时，才会为类生成移动操作（移动构造函数和移动赋值运算符） ：\n\n类中没有用户声明的拷贝操作（拷贝构造函数或拷贝赋值运算符）。\n类中没有用户声明的移动操作（移动构造函数或移动赋值运算符）。\n类中没有用户声明的析构函数。\n\n针对上述内容, 解释如下: \n首先, 如果程序员为一个类编写了拷贝操作，这表明默认的、按成员拷贝的方式不适用于该类。编译器据此推断，默认的、按成员移动的方式很可能也不适用，因此不再自动生成移动操作 。\n而如果程序员编写了析构函数，这通常意味着该类在进行某种需要手动清理的资源管理，这正是C++98“三法则”（Rule of Three）的核心思想。在这种情况下，编译器假定默认的成员移动操作是不正确的，因此也会禁止生成移动操作。\n\n三法则是指, 如果你声明了拷贝构造函数、拷贝赋值运算符，或析构函数中的任何一个，你就得同时声明所有三个函数。\n\n拷贝操作的生成规则如果用户为一个类声明了移动操作（移动构造函数或移动赋值运算符），编译器会将拷贝操作（拷贝构造函数和拷贝赋值运算符）删除（即 delete）。\n其逻辑是，如果一个类需要自定义的移动逻辑，那么简单的按成员拷贝很可能是不正确的。为了防止意外调用了行为不正确的拷贝函数，编译器选择直接将其删除，而不是简单地不生成。\n但是, 为了兼容部分C++98代码, 如果用户声明了析构函数或复制构造函数，编译器仍然会自动生成复制赋值运算符\n强制生成函数：= default如果因为上述规则，某个特种成员函数没有被自动生成（例如，因为声明了析构函数而导致移动操作被抑制），但我们确信编译器生成的默认实现正是所需要的，可以使用 = default 来显式地要求编译器生成默认版本 。\nclass Base {public:    virtual ~Base() = default;  // 一旦用户声明了析构函数，移动操作的自动生成就被抑制了     // 因此还需要制编译器生成被抑制的移动操作    Base(Base&amp;&amp;) = default;    Base&amp; operator=(Base&amp;&amp;) = default;    // 为了可移动，最好也把复制操作加上    Base(const Base&amp;) = default;    Base&amp; operator=(const Base&amp;) = default;};\n\n其他规则默认构造函数仅当类中不包含用户声明的构造函数时才生成。\n另外, 一个需要特别注意的规则是：类中的成员函数模板（例如一个接受任意类型的构造函数模板）永远不会抑制编译器生成任何特种成员函数 \n","categories":["language"],"tags":["language","CPP"]},{"title":"条款8：优先选用 nullptr, 而非 NULL 或者0","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE8%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20nullptr,%20%E8%80%8C%E9%9D%9E%20NULL/","content":"首先, 我们需要开门见山地指出,  0 和 NULL 都不具备指针类型, 它们的本质是整数，只是依赖于上下文（Context）被“特殊看待”为空指针\n\n0 的类型是 int：它是一个整数字面常量。C++ 只是在语言层面做一个不得已的“变通”：仅在上下文强制要求指针的语境中，才将 0 勉强解释为空指针。但在重载决议等情况下，它的“真实身份”——int——会优先被匹配。\nNULL 的类型是整型：NULL 是一个预处理宏，它在 C++ 中通常被定义为 0（一个 int）或 0L（一个 long）。因此，NULL 也不是指针类型，它是一个整型字面量。\n\n不区分三者最大的隐患：重载决议失败假设有三个重载函数：\nvoid f(int);    // 重载版本 #1void f(bool);   // 重载版本 #2void f(void*);  // 重载版本 #3 (接受指针)\n分析 f(0) 和 f(NULL)：\n\n调用 f(0)：由于 0 的类型是 int，它与 f(int) 构成完美匹配。因此，编译器会毫不犹豫地选择调用重载版本 #1。它永远不会调用 f(void*)。\n调用 f(NULL)：由于 NULL 通常被定义为 0（一个 int），这与调用 f(0) 的情况完全相同。编译器依然会选择 f(int)。\n\n这完全违背了程序员的意图。程序员传入 0 或 NULL 的本意是想传递一个“空指针”，希望调用版本 #3，但结果却调用了 int 版本。\nC++11 引入的 nullptr 解决了这个问题。nullptr 的类型不是整型。它的实际类型是 std::nullptr_t,并且 std::nullptr_t 可以隐式转换为所有裸指针类型（如 void*, int*, Widget* 等）。\n当调用 f(nullptr) 时，nullptr 无法被匹配为 f(int) 或 f(bool)。但它可以被隐式转换为 void*，因此它精确地匹配并调用了重载版本 #3，这完全符合程序员的意图。\n提升代码清晰度：auto 与 nullptr在现代 C++ 中，auto 的广泛使用使得 0 和 NULL 的歧义性更加突出。例如:\nauto result = findRecord(/* ... */);if (result == 0) { /* ... */ } // 这是什么意思?if (result == nullptr) { /* ... */ } // 意思很明确\n分析 result == 0：当读者看到这行代码时，无法立即判断 result 的类型。findRecord 返回的 result 究竟是一个指针类型，还是一个整型（例如，错误码或计数）？代码存在歧义。\n分析 result == nullptr：这行代码则毫无歧义。它能通过编译的唯一前提是 result 必须是一个指针类型（或智能指针等支持与 nullptr 比较的类型）。这极大地提升了代码的清晰度。\n保证模板类型推导的正确性0 和 NULL 最大的失败在于模板类型推导。当它们被传递给模板时，编译器会推导它们的“真实”类型（即整型），而不是程序员“期望”的空指针。这种类型上的差异导致了在泛型代码中（如模板函数）传递空指针意图时，只有 nullptr 能够保证类型安全和编译成功。\n??? \n","categories":["language"],"tags":["language","CPP"]},{"title":"条款9：优先选用别名声明，而非 typedef","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE9%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E5%88%AB%E5%90%8D%E5%A3%B0%E6%98%8E%EF%BC%8C%E8%80%8C%E9%9D%9E%20typedef/","content":"在 C++ 中，typedef 和 C++11 引入的“别名声明”（Alias Declaration）都用于创建类型同义词。例如，以下两行代码在功能上是完全等效的：\n// C++98 的做法typedef std::unique_ptr&lt;std::unordered_map&lt;std::string, std::string&gt;&gt; UPtrMapSS; [cite: 723]// C++11 的做法：别名声明using UPtrMapSS = std::unique_ptr&lt;std::unordered_map&lt;std::string, std::string&gt;&gt;; [cite: 726]\n尽管两者功能相同，但条款9强烈建议优先选用别名声明（using），主要原因在于它对模板的完美支持以及在模板元编程中的易用性。\n易读性(次要)对于复杂的类型，特别是函数指针，using 的语法通常更直观、更易于阅读。\n// Typedef：类型名称（FP）被“包围”在中间，阅读顺序不自然typedef void (*FP)(int, const std::string&amp;); [cite: 728]// 别名声明：语法更像赋值，左侧是新名称，右侧是原类型，逻辑清晰using FP = void (*)(int, const std::string&amp;); [cite: 729]\n\n核心优势：对模板的支持别名声明最重要且最具压倒性的优势在于它可以被模板化，而 typedef 不能 。通过 using 创建的模板化类型同义词被称为别名模板 (Alias Template)。\n如果我们想创建一个自定义分配器的 std::list 的同义词，使用别名模板非常简单：\ntemplate&lt;typename T&gt;using MyAllocList = std::list&lt;T, MyAlloc&lt;T&gt;&gt;;MyAllocList&lt;Widget&gt; lw; //\n而由于 typedef 不能被模板化，为了在 C++98 中实现相同的效果，我们必须使用一个繁琐的变通方法：将 typedef 嵌套在一个模板化的 struct 内部 ：\ntemplate&lt;typename T&gt;struct MyAllocList {    typedef std::list&lt;T, MyAlloc&lt;T&gt;&gt; type; };\n这种方法不仅更复杂，而且客户端代码在使用时也必须通过 ::type 来获取真正的类型，并且常常需要与 typename 关键字配合。\n\n当一个类型依赖于模板参数（如 MyAllocList::type 依赖于 T）时，这个类型被称为依赖类型 (dependent type) 。C++ 规则要求，对于依赖类型，必须在其前面显式添加 typename 关键字，以告知编译器这个依赖名称是一个类型，而不是一个数据成员或别的什么 。\n\n// 使用 typedef 版本的代码template&lt;typename T&gt;class Widget {private:    // 必须使用 \"typename\" 和 \"::type\"    typename MyAllocList&lt;T&gt;::type list; [cite: 740, 742, 743]};// 使用别名模板版本的代码template&lt;typename T&gt;class Widget {private:    // 代码更简洁，无需 typename 和 ::type    MyAllocList&lt;T&gt; list; [cite: 747]};\n别名模板完美地解决了这个问题。当编译器看到 MyAllocList 时，它知道 MyAllocList 是一个别名模板，因此 MyAllocList 必然是一个类型。它不再是一个“依赖类型”（在C++的定义中），因此不再需要 typename 关键字，也不需要 ::type 后缀 \n","categories":["language"],"tags":["language","CPP"]},{"title":"条款4：掌握查看型别推导结果的方法","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE4%20-%20%20%E6%8E%8C%E6%8F%A1%E6%9F%A5%E7%9C%8B%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC%E7%BB%93%E6%9E%9C%E7%9A%84%E6%96%B9%E6%B3%95/","content":"typeid介绍typeid 是一个 C++ 内置的运算符（就像 sizeof 或 decltype 一样）, 是 C++ 运行时类型识别（Runtime Type Information, RTTI）机制的核心组成部分。它允许你的程序在代码运行时查询一个对象的动态类型（Dynamic Type）, 当然也可以进行静态类型的查询。\n\nRTTI 并非没有代价（它会给对象增加额外的开销，主要是虚函数表 vtable 中的类型信息指针），因此大多数 C++ 编译器允许你通过选项（如 GCC/Clang 的 -fno-rtti）来禁用它。如果 RTTI 被禁用，typeid 在某些情况下（尤其是多态类型）将无法按预期工作。\n\n具体来说, 它可以用于获取一个类型或一个表达式的类型信息。它有两种使用形式：\n\ntypeid(Type)：直接传递一个类型名称, 如std::cout &lt;&lt; (typeid(int).name()) &lt;&lt; std::endl;   // 输出 \"int\" 。\ntypeid(expression)：传递一个表达式（例如一个变量名）,下面主要考虑这一点 。\n\n不过, typeid 的真正威力体现在它处理**多态（Polymorphic）**类型时的能力。一个类如果拥有至少一个 virtual 函数，它就是多态类型。\n\n情况一：非多态类型（或静态类型查询）\n\n当你对一个非多态类型（如 int、struct，或没有虚函数的类），或者对一个指针（ptr）本身（而不是它指向的内容 *ptr），或者对一个类型名称使用 typeid 时，它返回的是静态类型（Static Type）。\n静态类型是对象在编译时被声明的类型。这个操作是在编译期完成的。\nint x = 10;std::string s = \"hello\";// 这些都是静态类型查询std::cout &lt;&lt; (typeid(int).name()) &lt;&lt; std::endl;   // 输出 \"int\" (或其修饰名)std::cout &lt;&lt; (typeid(x).name()) &lt;&lt; std::endl;     // x 是 int，输出 \"int\"std::cout &lt;&lt; (typeid(s).name()) &lt;&lt; std::endl;     // 输出 \"std::string\" (或其修饰名)\n\n\n情况二：多态类型（动态类型查询）\n\n这是 typeid 最重要的用途。当你将 typeid 应用于一个多态类型的左值表达式（通常是对一个基类指针或引用的解引用）时，它会执行运行时查询，以确定该对象的动态类型（Dynamic Type）。\n动态类型是对象在内存中被创建时的“真正”类型，即其派生最深的类型 (most derived type)。\n#include &lt;iostream&gt;#include &lt;typeinfo&gt; // 必须包含此头文件struct Base {    virtual void foo() {} // 关键：必须有虚函数才能成为多态类型    virtual ~Base() {}};struct Derived : public Base {    void foo() override {}};struct OtherDerived : public Base {    void foo() override {}};int main() {    Base b_obj;    Derived d_obj;    Base* ptr_b = new Derived(); // 基类指针，指向派生类对象    // --- 静态类型 vs 动态类型 ---    // 1. ptr_b 本身是一个指针变量，变量类型是 Base* (非多态)    // 静态类型查询：    std::cout &lt;&lt; (typeid(ptr_b).name()) &lt;&lt; std::endl;     // 输出: \"Base *\" (或其修饰名，如 \"P4Base\")    // 2. *ptr_b 是对指针的解引用，这是一个多态类型的左值    // 动态类型查询：    std::cout &lt;&lt; (typeid(*ptr_b).name()) &lt;&lt; std::endl;     // 输出: \"Derived\" (或其修饰名，如 \"7Derived\")    // 尽管 ptr_b 是 Base*，RTTI 发现它实际指向一个 Derived 对象    delete ptr_b;}\n\n在这种情况下, 如果 typeid 运算符被应用于一个指向多态类型的空指针的解引用，它将抛出一个 std::bad_typeid 异常。\nBase* null_b_ptr = nullptr;try {    typeid(*null_b_ptr); // 试图解引用一个多态类型的空指针} catch (const std::bad_typeid&amp; e) {    std::cout &lt;&lt; \"Caught exception: \" &lt;&lt; e.what() &lt;&lt; std::endl;}\n\nstd::type_info 类std::type_info：是一个定义在  头文件中的类。前面的 typeid 运算符的返回值就是一个对 std::type_info 对象的常量引用 (const std::type_info&amp;), 这个对象中存储了关于特定类型的信息。\nC++ 标准保证对于程序中的每一种类型，都只有一个 std::type_info 对象实例与之对应。这使得我们可以安全地使用 == 和 != 来比较它们。\nstd::type_info 类的主要成员函数包括：\n\noperator== 和 operator!=：用于比较两个类型是否相同, 例如typeid(*ptr) == typeid(Derived)。\nname()：返回一个 const char*，代表该类型的名称。\n值得注意的是, C++ 标准没有规定这个名称的具体格式，它只要求这个名称是唯一的。在实际中，大多数编译器会返回一个“修饰过的名称”（mangled name）, 有时候并不易读（例如，7MyClass 而不是 MyClass）。\n这个函数主要用于调试和日志记录，不应该依赖它返回的字符串内容来进行程序逻辑判断（例如，不要写 if (strcmp(typeid(T).name(), “MyClass”) == 0)）。\n\n\n\nBoostBoost 库是一个庞大、高质量、经过同行评审（peer-reviewed）且可移植的 C++ 库集合, 我们可以将其理解为 C++ 标准库的“扩展包”和“试验场”。许多在 Boost 库中经过多年开发、测试和广泛使用的组件，最终被 C++ 标准委员会采纳，并成为了 C++ 标准库的一部分, 例如: \n\n智能指针 (Smart Pointers)： C++11 中的 std::shared_ptr 和 std::weak_ptr 直接源自 Boost 中的 boost::shared_ptr。\n\n线程库 (Threading)： C++11 的 std::thread, std::mutex 等多线程工具，其设计和 API 大量借鉴了 Boost.Thread 库。\n\n可选值：C++17 的 std::optional 源于 boost::optional。\n\n类型特征 (Type Traits)：C++11  头文件中的许多工具，最早在 Boost.TypeTraits 中实现。\n\n函数对象包装器：C++11 的 std::function 源于 boost::function。\n\n\nBoost.TypeIndexBoost.TypeIndex 是 Boost 库中的一个具体组件（子库），它提供了一套可移植的、功能更强的**运行时类型识别（RTTI）**机制，旨在作为 C++ 标准 RTTI（即 typeid 操作符和 std::type_info 类）的替代品或增强版。\n为什么需要 TypeIndex？（标准 RTTI 的问题）要理解 Boost.TypeIndex 的价值，首先必须了解 C++ 标准 typeid 的局限性：\n\n不可移植的类型名称：C++ 标准只规定 typeid(T).name() 必须返回一个字符串，但没有规定这个字符串的具体内容。在实际中，不同编译器返回的是“重整”（mangled）后的内部名称。例如，对于 std::vector, GCC/Clang 可能返回类似：St6vectorIiSaIiEE, 而MSVC 可能返回类似：.NSt3__16vectorIiNS_9allocatorIiEEEE. 这种字符串对开发者来说几乎不可读，且在不同平台和编译器之间完全不一致，导致调试和日志记录非常困难。\n\n对 RTTI 开关的依赖：typeid 的功能依赖于编译器开启 RTTI 选项。在许多高性能、游戏开发或嵌入式项目中，开发者会选择关闭 RTTI（例如在 GCC/Clang 上使用 -fno-rtti 标志）来减少二进制文件大小和潜在的虚函数表开销。而一旦 RTTI 被关闭，typeid 对多态类型（带有虚函数的类）的操作将失效（通常会导致编译错误或运行时异常），这使得依赖 typeid 的代码不具备健壮性。\n\nCVR 限定符的丢失：标准的 typeid 在计算类型时，会自动忽略顶层的 const（常量）、volatile（易失）和 reference（引用）限定符（统称 CVR 限定符）。例如，typeid(int)、typeid(const int) 和 typeid(const int&amp;) 这三者返回的 std::type_info 对象是完全相同的，它们都代表 int 类型。在某些需要精确类型区分的元编程或泛型编程场景中，这是致命的缺陷。\n\n\nBoost.TypeIndex 的解决方案Boost.TypeIndex 通过引入核心类 boost::typeindex::type_index 来解决上述所有问题：\n\n可移植的“美化”名称 (Pretty Name)：Boost.TypeIndex 提供了 .pretty_name() 成员函数, 无论在哪个编译器上，也不论 RTTI 是否开启，它都会尽最大努力返回一个人类可读的、统一的类型名称。例如，对于 std::vector，它将一致地返回字符串 “std::vector&lt;int, std::allocator &gt;” （或类似的清晰形式），而不是混乱的重整名称。\n\n独立于 RTTI 开关：Boost.TypeIndex 具有智能的回退机制. 如果 RTTI 开启：它在内部优先使用 typeid，以获得最高效、最准确的多态类型识别; 如果 RTTI 关闭：它会自动切换到一套基于编译时模板元编程的机制来模拟类型信息（对于非多态类型）。这使得代码无论在哪种编译配置下都能工作。\n\n保留 CVR 限定符：Boost.TypeIndex 提供了两种获取类型信息的方式，以满足不同需求：\n\nboost::typeindex::type_id()：\n功能说明：这个函数模拟标准 typeid 的行为，返回去除 CVR 限定符后的基础类型。适用于需要“模糊”匹配类型的场景。\n\n\nboost::typeindex::type_id_with_cvr()：\n功能说明：这是关键的增强功能。它返回包含 CVR 限定符的精确类型。\n\n\n例如：type_id_with_cvr&lt;const int&amp;&gt;() 返回的 type_index 对象的 .pretty_name() 将是 “int const&amp;”，这与 type_id_with_cvr()（返回 “int”）是截然不同的，从而允许开发者进行精确的类型区分。\n\n\n\n不同阶段用来查看编译器类型推导结果的技术了解了上述内容之后, 我们可以总结出三种在软件开发不同阶段(撰写代码阶段、编译阶段和运行时阶段)用来查看编译器类型推导结果的技术。这些方法可以帮助开发者确认模板、auto 或 decltype 推导出的类型是否符合预期。\n\nIDE 编辑器\n\n在IDE的代码编辑器中，将鼠标指针悬停在变量、参数或函数上时，编辑器通常会显示该实体的推导类型 。\n其局限性在于, 这种方法需要代码基本处于可编译状态，因为IDE依赖内嵌的编译器前端来进行分析 。对于简单的类型（如int）显示良好，但对于复杂的类型，IDE显示的型别信息可能非常冗长且难以阅读，实用性会降低 。\n\n编译器诊断信息\n\n我们可以通过故意制造一个编译错误，来迫使编译器在诊断信息中报告出它所推导出的类型 。\n一种方式是, 我们声明一个类模板，但不去定义它（例如 template&lt;typename T&gt; class TD;）。\n接着尝试使用你想查看的类型来具现这个模板（例如，TD&lt;decltype(x)&gt; xType;） 。\n编译器在试图创建 xType 对象时，会因为 TD 是一个不完整类型 (incomplete type) 而报错，错误信息中几乎必然会包含 T 被推导出的完整类型（例如 “aggregate ‘TD xType’ has incomplete type”）。\n\n运行时输出\n\n一种不太可靠的方法是使用typeid, 例如通过typeid(x).name() 来在运行时打印类型名称。然而, 根据C++标准，std::type_info::name 在处理类型时，会如同函数按值传递形参一样。这意味着它会忽略类型的引用（&amp;）属性，并移除顶层的 const 和 volatile 修饰符(CVR丢失)。这会导致输出错误的类型，例如，一个 const Widget* const&amp; 类型可能会被错误地报告为 const Widget*(详见条款1的情况2部分):\n// 模板函数定义template&lt;typename T&gt; void f(const T&amp; param); // 一个返回 std::vector 的工厂函数std::vector&lt;Widget&gt; createVec(); // 使用工厂函数返回值初始化 vwconst auto vw = createVec(); if (!vw.empty()) {     // 调用模板函数    f(&amp;vw[0]); }template&lt;typename T&gt; void f(const T&amp; param) {     using std::cout;     cout &lt;&lt; \"T = \" &lt;&lt; typeid(T).name() &lt;&lt; '\\n';       // 显示 T 的类型    cout &lt;&lt; \"param = \" &lt;&lt; typeid(param).name() &lt;&lt; '\\n'; // 显示 param 的类型}\n上述结果的输出为:T = class Widget const * param = class Widget const *而显而易见, 在模板 f 中，形参 param 被声明为 const T&amp;。无论 T 被推导成什么，param 的类型都应该是在 T 的基础上增加了 const 和 &amp; 限定符（或者根据引用折叠规则）。T 和 param（即 const T&amp;）不可能是同一个类型。\n出现这个问题的原因就在于std::type_info::name的腐化性(丢失CVR): C++ 标准规定，typeid 在返回 name() 之前，会像**函数按值传递（pass-by-value）**那样来处理它获取到的类型。\n应用到我们的例子：根据原理, 我们推导出了T = const Widget*和param = const (const Widget*) &amp;. 对于 typeid(T), 它分析 const Widget*。这是一个指针类型，不是引用，它的 const 是底层的（指向 const），不是顶层的。因此，按值传递规则不会移除任何东西。\n但是对于 typeid(param), 它分析 const Widget* const &amp;, 首先 &amp; 被移除，类型变为 const Widget* const (一个指向 const Widget 的 const 指针)。接着因为该类型有一个顶层的 const（即指针本身的常量性）。这个 const 被移除。结果是和T一样的const Widget* 。\n更可靠的方法 (Boost.TypeIndex)：一个更准确的运行时解决方案是使用 Boost 库的 TypeIndex 。\n使用 boost::typeindex::type_id_with_cvr&lt;T&gt;().pretty_name()  可以获取一个包含人类可读的、精确类型表示的字符串。其名称中的 “cvr” 表明它会保留 const、volatile 和引用饰词，从而提供准确的类型信息 。\n#include &lt;boost/type_index.hpp&gt; // 引入 Boost.TypeIndex 库#include &lt;iostream&gt;           using std::cout; // 导入 Boost.TypeIndex 的核心函数，用于获取包含 const/volatile/&amp; 的精确类型using boost::typeindex::type_id_with_cvr; template&lt;typename T&gt;void f(const T&amp; param) {     cout &lt;&lt; \"T  = \"          &lt;&lt; type_id_with_cvr&lt;T&gt;().pretty_name()          &lt;&lt; '\\n';     // 2. 显示 param 的类型    // 在这个函数签名中，param 的类型永远是 const T&amp;。    cout &lt;&lt; \"param = \"          &lt;&lt; type_id_with_cvr&lt;decltype(param)&gt;().pretty_name()          &lt;&lt; '\\n'; }int main() {    int x = 10;    const int cx = 20;    const int&amp; rx = x;    cout &lt;&lt; \"--- 调用 f(x) --- (x 是 int)\\n\";    f(x);     cout &lt;&lt; \"\\n--- 调用 f(cx) --- (cx 是 const int)\\n\";    f(cx);    cout &lt;&lt; \"\\n--- 调用 f(rx) --- (rx 是 const int&amp;)\\n\";    f(rx);    cout &lt;&lt; \"\\n--- 调用 f(42) --- (42 是右值)\\n\";    f(42);     return 0;}","categories":["language"],"tags":["language","CPP"]},{"title":"条款 18 - 使用 std::unique_ptr 管理具备专属所有权的资源","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE18%20-%20%E4%BD%BF%E7%94%A8%20std%20%20unique_ptr%20%E7%AE%A1%E7%90%86%E5%85%B7%E5%A4%87%E4%B8%93%E5%B1%9E%E6%89%80%E6%9C%89%E6%9D%83%E7%9A%84%E8%B5%84%E6%BA%90/","content":"进入现代C++, 传统的指针由于容易出现资源泄露等缺点, 智能指针成为了管理资源的重要工具. C++11 中共有四种智能指针：std::auto _ptr, std::unique_ptr, std::shared_ptr 和 std: :weak_ptr。所有这些智能指针都是为管理动态分配对象的生命期而设计的，其中, std::unique_ptr 是一种独占式智能指针, 它确保在任何时候只有一个指针指向资源. 这使得 std::unique_ptr 成为了管理具备专属所有权的资源的理想选择.\n而且在一般情况下, std::unique_ptr 应该是智能指针的默认首选, 它在效率上也几乎与裸指针无异 \n\nstd::auto_ptr 是从 C++98 中残留下来的弃用特性, 现在已经基本被std::unique_ptr 所替代.\n\n专属所有权与移动语义std::unique_ptr 体现了“专属所有权”的概念，即一个非空的 std::unique_ptr 总是拥有其所指向的资源 。任何时刻，资源都只有一个所有者。这确保了资源的安全释放，避免了内存泄漏和悬空指针的问题。\n轻量且高效：在默认情况下（即使用 delete 作为删除器），std::unique_ptr 的尺寸与裸指针完全相同，并且其操作（如解引用）的执行效率也与裸指针相同 。这使得它即使在对性能和内存要求极为苛刻的场景下也同样适用 。\n移动专属 (Move-Only)：std::unique_ptr 不允许复制, 如果你尝试复制一个 std::unique_ptr，代码将无法通过编译。这是为了保证所有权的唯一性。因此要转移资源的所有权，只能且必须使用 std::move 。当一个 std::unique_ptr 被移动后，源指针将被置为 nullptr 。\n自动资源管理：当一个 std::unique_ptr 被销毁时（例如离开作用域），它会自动销毁其所拥有的资源 。默认情况下，它通过在其内部的裸指针上调用 delete 来完成这一操作 。\n典型用例：工厂函数std::unique_ptr 最常见的用法之一，是作为工厂函数的返回类型 。工厂函数通常在堆上创建一个对象并返回一个指向它的指针，而调用者则负责该对象的生命周期, 这与 std::unique_ptr 的专属所有权语义完美契合。工厂函数通过返回一个std::unique_ptr，清晰地将新创建的对象的所有权转移给调用方 。\n// 假设 Investment 是一个多态基类class Investment { ... };// 工厂函数返回一个 unique_ptr，将所有权转移给调用者template&lt;typename... Ts&gt;std::unique_ptr&lt;Investment&gt; makeInvestment(Ts&amp;&amp;... params);{    // 调用工厂函数，获取资源的所有权    auto pInvestment = makeInvestment(arguments);    } // pInvestment 在此处离开作用域，其管理的 Investment 对象被自动销毁\n调用方的代码将变得非常安全和简洁，因为当 pInvestment 离开作用域时，std::unique_ptr 的析构函数会自动确保资源被正确释放，即使在发生异常时也是如此 。\n自定义删除器std::unique_ptr 不仅限于使用 delete 来释放资源，它还支持自定义删除器 (custom deleter) 。删除器可以是任意函数或函数对象（包括 lambda 表达式），用于在 std::unique_ptr 销毁时执行特定的清理操作。自定义删除器的类型是 std::unique_ptr 模板的第二个参数 。\n// 自定义删除器，在删除前先写入日志auto delInvmt = [](Investment* pInvestment) {    makeLogEntry(pInvestment);    delete pInvestment;};// 在 unique_ptr 的类型中指定删除器的类型std::unique_ptr&lt;Investment, decltype(delInvmt)&gt;    pInv(nullptr, delInvmt);\n需要注意的是, 自定义删除器可能会增加 std::unique_ptr 的尺寸 。\n函数指针删除器：如果删除器是一个函数指针，std::unique_ptr 的尺寸通常会从一个字长（裸指针的大小）增加到两个字长（一个用于裸指针，一个用于函数指针）。\n函数对象删除器（包括 lambda）：如果删除器是一个函数对象，其尺寸取决于该函数对象中存储了多少状态。如果是一个无捕获的 lambda，它不包含任何状态，编译器通常可以将其完全优化掉，此时 std::unique_ptr 的尺寸不会增加，仍然和一个裸指针一样大 。\n因此，当需要自定义删除器时，使用无捕获的 lambda 是比使用函数指针更高效的选择 。\nstd::unique_ptr 的两种形式：单个对象与数组std::unique_ptr 提供两种形式：一种用于单个对象，一种用于数组 。\n\nstd::unique_ptr：用于单个对象。它提供了 operator* 和 operator-&gt;。\n\nstd::unique_ptr&lt;T[]&gt;：用于数组。它提供了 operator[] 索引运算符，但不提供 * 和 -&gt; 。\n\n\n不过, 在现代 C++ 中，std::array、std::vector 和 std::string 等标准容器几乎总是比裸数组更好的选择，因此 std::unique_ptr&lt;T[]&gt; 的使用场景非常有限 。\n转换为 std::shared_ptrstd::unique_ptr 的一个非常吸引人的特性是，它可以方便且高效地转换为 std::shared_ptr。\n并且通常来说, std::unique_ptr 是构建 std::shared_ptr 的完美来源。这使得 std::unique_ptr 成为工厂函数的理想返回类型。工厂函数返回一个高效的 std::unique_ptr，将专属所有权交给调用者。如果调用者后续需要共享这个资源，他们可以自行决定将其转换为 std::shared_ptr，从而将所有权模型从专属升级为共享 。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 23：理解 std::move std::forward","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE23%20-%20%20%E7%90%86%E8%A7%A3%20move%20%E5%92%8C%20forward/","content":"移动语义 (Move Semantics) 和 完美转发 (Perfect Forwarding) 是 C++11 中引入的两个革命性特性，它们共同解决了 C++ 中长期存在的资源管理效率和泛型编程（模板）中的参数传递问题。\n移动语义 (Move Semantics)在 C++11 之前，我们只有“拷贝语义”。当我们处理包含堆内存（如指针指向的数据、文件句柄、网络套接字等）的对象时，拷贝操作（通过拷贝构造函数或拷贝赋值运算符）通常意味着“深拷贝”——即分配一块新内存，并将数据完整拷贝过去。\n考虑一个返回 std::vector 的函数：\nstd::vector&lt;int&gt; create_large_vector() {    std::vector&lt;int&gt; temp_vec(1000000); // 假设分配了大量数据    // ... 填充数据 ...    return temp_vec; // [C++03] 在这里，temp_vec (左值) 将被拷贝到一个“返回值临时对象”(右值)}// [C++03] 调用：std::vector&lt;int&gt; my_vec = create_large_vector(); // [C++03] “返回值临时对象”(右值) 又被拷贝到 my_vec 中。\n\n在 C++03 中，这个过程涉及两次昂贵的深拷贝。但我们知道，函数内的 temp_vec 和那个“返回值临时对象”在语句结束时都将被销毁。我们其实并不需要拷贝它们内部的数据，我们只需要把数据（即指向堆内存的指针）转移给 my_vec 就行了。\n这个问题的解决方案就是移动语义. 它允许一个对象将其内部资源（如指针）的“所有权”转移 (transfer) 给另一个对象，而不是拷贝它们。这是一种“窃取”或“掠夺”资源的方式，它之所以安全，是因为我们只对那些“即将被销毁”的对象（即右值）执行此操作。\n因此, 一个类现在可以定义专门处理右值参数的版本：移动构造函数: MyClass(MyClass&amp;&amp; other)和移动赋值运算符: MyClass&amp; operator=(MyClass&amp;&amp; other)\n它们的实现逻辑如下：\n\n窃取资源： 将 other 对象的内部资源（例如，指向数据的指针 other.data_ptr）直接拷贝（浅拷贝）到 this 对象（this-&gt;data_ptr = other.data_ptr）。\n\n置空源对象： 将 other 原对象的指针设置为 nullptr (other.data_ptr = nullptr;)。\n\n这是至关重要的安全步骤。因为 other 仍然是一个有效的对象，它在作用域结束时会被析构。如果不将其指针置空，other 的析构函数会释放掉那块内存，导致 this 对象持有一个悬空指针。将其置空后，other 的析构函数调用 delete nullptr;（这是安全的），而资源的所有权已成功转移给 this。\n\n\n\nstd::move对于右值, 编译器会自动调用移动构造函数或移动赋值运算符. 而对于左值, 我们不能直接将一个它传递给一个只接受右值引用的函数（如移动构造函数）。解决方法是, 使用 std::move 来显式请求移动\nstd::move 不做任何移动操作。它仅仅是一个强制类型转换：它将其参数（无论左值还是右值）无条件地转换为一个右值引用。\n这相当于你对编译器说：“我保证，我不再使用这个左值变量了，请你把它当作一个临时对象（右值）来处理，你可以随意窃取它的资源。”\n对于上述示例, 我们可以将 create_large_vector 函数修改为：\nstd::vector&lt;int&gt; create_large_vector() {    std::vector&lt;int&gt; temp_vec(1000000); // 假设分配了大量数据    // ... 填充数据 ...    return std::move(temp_vec); // [C++11] 在这里，temp_vec (左值) 将被移动到一个“返回值临时对象”(右值), 因此不会触发深拷贝, 将 O(N) 的资源拷贝操作降维到 O(1) 的指针交换操作。}\nstd::move后仅保证右值, 不保证可移动在 C++ 开发中，我们被教导“尽可能使用 const”，这是一个良好的编程习惯。同时，为了优化性能，现代 C++（遵循《Effective Modern C++》条款 41 等指导原则）建议我们利用移动语义。然而，当这两个原则被错误地结合时，可能会产生与预期不符的行为。\n假设我们正在编写一个 Annotation (注解) 类，它在内部存储一个字符串。根据条款 41 的建议（针对既需要拷贝也需要移动赋值的“sink”参数），我们采用按值传递（pass-by-value）参数，然后将其 std::move 到数据成员中，以此来高效处理左值（拷贝）和右值（移动）实参\n同时, 因为这个构造函数仅仅是读取 text 的值（用于移动），而不会在函数体内对其进行逻辑上的修改。遵循“尽可能使用 const”的旧习惯，我们将这个按值传递的参数标记为 const：\nclass Annotation {public:    // 按值传递 text    explicit Annotation(const std::string text)         : value(std::move(text)) // 将 text 的内容“移动”到 value 中    { }private:    std::string value;};\n结果是, 这段代码可以顺利地编译、链接并运行。并且，成员变量 value 最终确实包含了传入的 text 的内容。然而，一个关键的优化丢失了：text 并没有被移动，它被拷贝到了 value 中。\n我们迫切想知道, 为什么移动（Move）变成了拷贝（Copy）？\n这个行为是 C++ 类型系统和重载解析 (Overload Resolution) 共同作用的结果，并且这种设计对于维持“常量正确性”至关重要。\n我们一步一步分析, std::move 本身不执行任何“移动”操作。它是一个无条件的类型转换工具（cast）。它的唯一工作就是将其接收的参数（通常是一个左值）强制转换为一个右值引用（rvalue reference）\n这里的关键点在于，当 std::move 转换一个 const 变量时，其“常量性”（const-ness）会被保留。\n在我们的例子中，形参 text 的类型是 const std::string（这是一个左值）; std::move(text) 的调用将其转换为右值, 转换的结果类型是const std::string&amp;&amp; （一个指向 const std::string 的右值引用）。\n当编译器尝试使用这个结果（一个 const 右值）来初始化成员 value (类型为 std::string) 时，它会检查 std::string 的可用构造函数，主要有两个候选者：\nclass string { public:    // 1. 移动构造函数 (Move Constructor)    //    它接受一个“非 const 的”右值引用 (string&amp;&amp;)    string(string&amp;&amp; rhs);     // 2. 拷贝构造函数 (Copy Constructor)    //    它接受一个“const 的”左值引用 (const string&amp;)    string(const string&amp; rhs); };\n对于移动构造函数, 我们的参数类型是 const std::string&amp;&amp; (const 右值)。而移动构造函数需要 string&amp;&amp; (非 const 右值)。而C++ 不允许将 const 对象绑定到非 const 引用上，因为移动构造函数必须能够修改其参数（例如，将其内部指针设为 null）, 显然对一个 const 对象执行“窃取”操作是违反常量正确性的。\n而对于第二个拷贝构造函数, C++ 语言规则允许一个 const 左值引用（const T&amp;）绑定到一个 const 右值（const T&amp;&amp;）, 所以编译器别无选择，只能调用拷贝构造函数，导致了数据拷贝而非移动。\n这个案例带来了两个至关重要的经验：\n\n不要对计划移动的对象声明 const: 如果你希望能够从一个对象中“移出”数据（即允许该对象被修改并置于一个有效的、但未指定的状态），那么该对象本身绝对不能被声明为 const。任何对 const 对象的“移动”尝试都会悄无声息地降级为一次“拷贝”操作。\n\nstd::move 不保证“可移动性”: std::move 并不执行移动，它只负责类型转换。它告诉编译器：“请把这个对象当作右值来处理”。它不保证转换后的右值一定能匹配到移动构造函数或移动赋值运算符。如本例所示，如果源对象是 const，它最终只会匹配到拷贝操作。\n\n\n完美转发 (Perfect Forwarding)完美转发解决的是一个在模板（泛型编程）中遇到的不同问题: 转发时的值类别丢失\n假设我们要编写一个“工厂函数”（或任何包装函数），它接受一些参数，然后用这些参数去构造另一个类型的对象（例如 std::make_unique 或 std::vector::emplace_back）。\n\n工厂函数（Factory Function）是一种封装对象创建过程的函数，它的核心目的是：将对象的构造逻辑从使用者那里抽离出来，让你通过调用一个函数来获得所需的对象，而不需要关心它是如何被创建的。\n\n我们希望：\n\n如果工厂函数收到了一个左值，它应该传递一个左值给最终的构造函数（触发拷贝）。\n如果工厂函数收到了一个右值，它应该传递一个右值给最终的构造函数（触发移动）。\n\n// process 根据参数是左值还是右值进行了重载void process(const Widget&amp; lvalArg);  // 处理左值void process(Widget&amp;&amp; rvalArg);        // 处理右值// logAndProcess 是一个函数模板，用于记录日志并转发参数template&lt;typename T&gt;void logAndProcess(T&amp;&amp; param){    // 取得当前时间    auto now = std::chrono::system_clock::now();     makelogEntry(\"Calling 'process'\", now);    // 将 param 完美转发给 process 函数    process(std::forward&lt;T&gt;(param));}// 考虑两种调用 logAndProcess 的情形，一种向其传入左值，一种向其传入右值Widget w;logAndProcess(w);             // 传入左值logAndProcess(std::move(w));  // 传入右值\n\n在 logAndProcess 内，形参 param 被传递给函数 process。而 process 依据其形参是左值还是右值类型进行了重载。所以我们很自然地会期望：\n\n当调用 logAndProcess 时若传入的是个左值（如 w），则该左值在被传递给 process 函数时仍被当作一个左值。\n而当调用 logAndProcess 时若传入的是个右值（如 std::move(w)），则会调用 process 取用右值类型的那个重载版本。\n\n但是，有一个关键规则：所有（具名的）函数形参皆为左值(即使它是右值引用类型)，param 亦不例外。\n\n一个值被传递给函数后，在函数内部它就“落地”了，有了一个具体的名字和一块内存。只要有了这两样东西，它就变成了左值，以便在函数体内稳定地使用。与之不同, 函数返回值的类型情况取决于返回类型如果返回类型是非引用/右值引用, 则返回值是右值; 如果是左值引用则是左值\n\n因此，如果在 logAndProcess 函数体内只是简单地调用 process(param)，那么 process 的所有调用都会调用取用左值类型的那个重载版本（因为 param 本身是左值），即使我们传给 logAndProcess 的是一个右值。\n为了避免这种结果，就需要一种机制：当且仅当用来初始化 param 的实参（即传递给 logAndProcess 的实参）是一个右值时，才把 param 强制转换成右值类型。这恰恰就是 std::forward 所做的一切。\nstd::forward：有条件的类型转换这就是为何说 std::forward 是有条件的强制类型转换：仅当它的实参（param）最初是使用一个右值完成初始化时，它才会执行向右值类型的强制类型转换。(也就是说它会”转发“实参的类型保持不变)\n你可能会疑惑，std::forward 何以知晓其参数是否通过右值完成初始化？一句话：该信息是被编码到 logAndProcess(也就是上一层的函数) 的模板形参 T 中的, 该模板参数 T 被传递给 std::forward 后，随即由后者将编码的信息恢复出来，从而决定是返回一个左值引用还是右值引用。\n回到 std::forward 本身, 它有两个参数: 模板参数（尖括号里的 T）和函数实参（圆括号里的变量，比如 param）, 其中模板参数T的作用是告诉 std::forward 调用者传进来的原始实参类型是什么; 而函数实参则是要被转发的对象, 两者结合即可用模板参数还原它的原始值类别。\nstd::move 与 std::forward：语义的明确区分综上所述, std::move 和 std::forward 都是强制型别转换，唯一不同就在于 std::move 始终实施强制型别转换，而 std::forward 仅仅有时会实施。\n更为重要的是，使用 std::move 和 std::forward 所要传达的语义完全不同：\n\nstd::move：传达的意思是无条件地向右值类型强制转换。这典型地用于为移动操作做铺垫（“我确定要移动这个对象，请将其视为右值”）。\n\nstd::forward：传达的意思是有条件的强制类型转换（仅仅对绑定到右值的引用实施转换）。这专门用于传递（转发）一个对象到另一个函数，并在此过程中保持该对象原始的左值性 (lvalueness) 或右值性 (rvalueness)。\n\n\n这是两个非常不同的行为。这两个行为是如此不同，因而我们最好使用两个不同的函数（以及函数名字）来明确区分这两者。在移动构造函数（或移动赋值运算符）内部，我们确定要将来源对象（rhs）的成员视为右值进行“窃取”，因此我们应该总是使用 std::move 来表达这种无条件的移动意图。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 24：区分万能引用和右值引用","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE24%20-%20%E5%8C%BA%E5%88%86%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%92%8C%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8/","content":"回忆左值（Lvalue）和右值（Rvalue）左值（Lvalue）表示一个有名字、可寻址、在表达式结束后仍然存在的对象。其特点是：\n\n可以出现在赋值语句的左边：x = 5;\n可以取地址：&amp;x\n通常是变量、数组元素、对象成员、函数形参等\n\n右值（Rvalue）表示一个临时值，通常在表达式中短暂存在，不能取地址。其特点是：\n\n只能出现在赋值语句的右边：x = 5;\n通常是字面量、临时对象、表达式结果\n不具备持久性，生命周期短\n可以移动（move），而不能复制（copy）\n\n基于此, 我们可以得到右值引用 (Rvalue Reference): T&amp;&amp;. 这是一种新的引用类型，用 &amp;&amp; 表示。它有一个关键特性：它只能绑定到右值（临时对象）。这使得我们可以在函数重载时区分传入的是左值还是右值：\nvoid foo(const MyClass&amp; obj); // 版本 1: 接受左值 (const引用也可以接受右值，但这是题外话)void foo(MyClass&amp;&amp; obj);      // 版本 2: (C++11 新增) 只接受右值\n更进一步地, 右值还可以继续划分: 右值 (rvalue) = 纯右值 (prvalue) + 将亡值 (xvalue)\n其中纯右值是没有名字的临时值或返回非引用的函数, 而将亡值特指资源即将被销毁的对象，通常是右值引用表达式即std::move(obj)或者返回T&amp;&amp;类型的函数返回值.\n万能引用（Universal Reference）/ 转发引用（Forwarding Reference）万能引用（转发引用）是一种特殊的引用，它既可以绑定到左值，也可以绑定到右值。它在语法上看起来与右值引用完全相同（都是使用 &amp;&amp;），但它只在非常特定的上下文中出现，并且遵循一套完全不同的类型推导规则。\n一个参数要成为“万能引用”，必须同时满足以下两个条件：\n\n必须涉及模板类型推导或者auto类型推导： 这个引用必须依赖于一个正在被推导的模板参数T或者auto。\n参数的声明形式必须是 T&amp;&amp;： 必须是这个精确的形式。不能有 const，也不能是其他任何形式。\n\nvoid f(Widget&amp;&amp; param);   // 没有类型推导，是右值引用Widget&amp;&amp; var1 = Widget();  // 右值引用auto&amp;&amp; var2 = var1;    // auto类型推导, 是万能引用template&lt;typename T&gt; void f(std::vector&lt;T&gt;&amp;&amp; param);   // 非精确形式, 是右值引用std: :vector&lt;int&gt; v; f(v); // 此时会错误！不能给右值引用绑定左值template&lt;typename T&gt; void f(const T&amp;&amp; param);   // 非精确形式, 是个右值引用template&lt;typename T&gt; void f(T&amp;&amp; param); // 模板参数推导+精确形式, 是万能引用Widget w; f(w);               // 传递左值, param为左值引用Widget&amp;f (std::move(w));   // 传递右值, param为右值引用Widget&amp;&amp;\n\n万能引用如何工作：特殊的类型推导与引用折叠万能引用的“魔力”来自于它在模板类型推导中使用的特殊规则，以及 C++ 的**引用折叠（Reference Collapsing）**规则。\n当我们使用 template&lt;typename T&gt; void func(T&amp;&amp; param) 时：\n\n情况一：传递一个左值\n\n假设我们有一个左值变量：MyClass widget; 我们调用：func(widget);\n\n类型推导（关键规则）： 当一个左值（类型为 A）被传递给一个 T&amp;&amp; 形式的万能引用时，模板参数 T 被推导为 A&amp; (一个左值引用)。在本例中，T 被推导为 MyClass&amp;。\n\n实例化参数类型： 编译器将 T (即 MyClass&amp;) 替换回参数声明 T&amp;&amp; 中，得到(MyClass&amp;) &amp;&amp;\n\n引用折叠： C++ 不允许“引用的引用”。编译器使用“引用折叠”规则来简化它。折叠规则是（简单来说）：只要有 &amp; 出现，最终就折叠为 &amp;。只有当两者都是 &amp;&amp; 时，才折叠为 &amp;&amp;。\n\nA&amp; &amp; -&gt; A&amp;\n\nA&amp; &amp;&amp; -&gt; A&amp; （我们命中的规则）\n\nA&amp;&amp; &amp; -&gt; A&amp;\n\nA&amp;&amp; &amp;&amp; -&gt; A&amp;&amp;\n\n\n\n最终函数签名： 折叠后，func 被实例化的版本是：void func(MyClass&amp; param);, 结果是函数变成了一个接受左值引用的函数，它成功地绑定到了我们传入的左值 widget 上。\n\n\n\n情况二：传递一个右值\n\n假设我们传递一个临时对象（右值）：func(MyClass());\n\n类型推导（关键规则）： 当一个**右值（类型为 A）**被传递给一个 T&amp;&amp; 形式的万能引用时，模板参数 T 被推导为 A (一个普通的、非引用的类型)。本例中，T 被推导为 MyClass。\n\n实例化参数类型： 编译器将 T (即 MyClass) 替换回参数声明 T&amp;&amp; 中，得到：(MyClass) &amp;&amp;，即 MyClass&amp;&amp;。(注意这里不需要发生折叠)\n\n最终函数签名： func 被实例化的版本是：void func(MyClass&amp;&amp; param);函数变成了一个接受右值引用的函数，它成功地绑定到了我们传入的右值临时对象上。\n\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 28 - 理解引用折叠","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE28%20-%20%E7%90%86%E8%A7%A3%E5%BC%95%E7%94%A8%E6%8A%98%E5%8F%A0/","content":"这一条款是对之前条款的理论原理呈现, 揭示了支撑万能引用和 std::forward工作的底层核心机制。这个机制就是引用折叠 (Reference Collapsing, 在之前的条款24中已有介绍)\n引用折叠会在四种语境中发生：模板实例化、auto 类型生成、创建和运用 typedef 和别名声明，以及 decltype。\n详细内容请参考条款24。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 30 - 熟悉完美转发的失败情形","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE30%20-%20%E7%86%9F%E6%82%89%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%83%85%E5%BD%A2/","content":"“完美转发”是 C++11 中一个极其强大的特性，但它并非在所有情况下都“完美”。该条款的核心是揭示几种完美转发会失败或产生非预期行为的边界情况，并提供相应的解决方案。\n什么是完美转发失败完美转发的理想目标是：一个转发函数 fwd 在接收某个表达式 expr 时，其行为应与将 expr 直接传递给目标函数 f 的行为完全相同。\nf(expression);      // 直接调用fwd(expression);    // 通过转发函数间接调用\n当直接调用成功，而间接调用却失败（例如，无法通过编译，或调用了错误的重载版本）时，就称完美转发失败。\n失败的根本原因在于，编译器在处理fwd(expression)时，必须先推导fwd的模板参数类型，而这个推导过程不考虑最终目标函数f的形参类型。而在直接调用f(expression)时，编译器会同时看到实参和形参，并可以进行必要的隐式类型转换。当类型推导失败或推导出“错误”的类型时，完美转发就会失败。\n五种导致完美转发失败的实参\n大括号初始化物 (Braced Initializers): 直接将 {} 初始化列表传递给目标函数通常是合法的，但通过转发函数传递则会失败。\n\nvoid f(const std::vector&lt;int&gt;&amp; v);f({1, 2, 3}); // 成功：\"{1,2,3}\"被隐式转换为 std::vector&lt;int&gt;template&lt;typename T&gt;void fwd(T&amp;&amp; param) { f(std::forward&lt;T&gt;(param)); }fwd({1, 2, 3}); // 错误！\n原因在于, 将 {…} 传递给一个未声明为 std::initializer_list 的函数模板参数，属于C++标准中的非推导语境 (non-deduced context)。编译器被禁止从 {1, 2, 3} 中为 fwd 的模板参数 T 推导出类型。由于类型推导失败，代码无法通过编译。\n解决方案也很简单, 先使用 auto 将大括号初始化物创建为一个 std::initializer_list 对象，再将该对象传递给转发函数。\nauto il = {1, 2, 3};fwd(il); // 成功：il 被推导为 std::initializer_list&lt;int&gt;\n\n\n以 0 或 NULL 表示的空指针直接调用时，0 或 NULL 可能会被正确解释为空指针，但转发时则不行。\n\n原因是, 如条款8所述，0 和 NULL 的真实类型是整型（int 或 long）。模板类型推导会忠实地将其推导为整型，而不是指针类型。当这个错误的整型被转发给期望指针的目标函数时，就会发生类型不匹配的错误。\n解决方案是使用 nullptr 代替 0 或 NULL。nullptr 的类型是 std::nullptr_t，它可以被正确地推导并转发。\n\n仅有声明的整型 static const 成员变量在类中声明但未在实现文件中定义的整型 static const 成员，可以直接作为值使用，但不能通过完美转发传递。\n\nclass Widget {public:    static const std::size_t MinVals = 28; // 仅有声明};f(Widget::MinVals); // 成功：编译器直接替换为值 28fwd(Widget::MinVals); // 错误：通常会导致链接失败\n完美转发是通过引用（万能引用 T&amp;&amp;）来接受参数的。传递引用在底层实现上通常等同于传递指针，这意味着被引用的对象必须有明确的内存地址。仅有声明的 static const 成员变量，编译器通常会通过“常数传播”优化直接使用其值，而不会为其分配内存地址。因此，当 fwd 尝试获取其引用时，链接器会因为找不到该变量的定义而报错。\n解决方案是在实现文件中为该成员变量提供定义即可\n// 在 Widget 的 .cpp 文件中const std::size_t Widget::MinVals; // 无需再次指定值\n\n\n重载的函数名字和模板名字直接将一个重载函数的名字传递给目标函数是合法的，但通过转发函数传递则会失败。\n\nvoid f(int (*pf)(int)); // f 接受一个函数指针int processVal(int);int processVal(int, int);f(processVal); // 成功：编译器根据f的签名选择了 int(int) 版本fwd(processVal); // 错误！\n原因是, processVal 这个名字本身代表一个函数重载集，它没有一个确定的类型。在直接调用 f 时，编译器可以根据 f 的参数类型（int (*)(int)）来确定应该选用哪个重载版本。但在调用 fwd 时，编译器只看到了实参 processVal，由于其类型不确定，模板类型推导 T 失败。函数模板的名字也存在同样的问题。\n解决方案：手动指定需要转发的是哪一个重载版本或模板实例(确定类型)，例如通过创建一个函数指针来消除歧义。\nusing ProcessFuncType = int (*)(int);ProcessFuncType processValPtr = processVal;fwd(processValPtr); // 成功\n\n\n位域 (Bitfields)可以直接将位域作为值传递给函数，但不能通过完美转发传递。\n什么是位域: 位域是 C/C++ 中的一种数据结构特性，它允许我们在一个结构体（struct）或联合体（union）中，为一个成员变量指定其占用的二进制位数（bit）。它是一种空间优化技术，主要用于将多个小的、通常是标志位或状态值的变量打包到单个机器字（如一个字节或一个整数）中，从而极大地节省内存空间。\n\n\n\nstruct IPv4Header { std::uint32_t totalLength:16; };void f(std::size_t s);IPv4Header h;f(h.totalLength); // 成功fwd(h.totalLength); // 错误！\n原因：C++标准禁止将非 const 引用绑定到位域。因为位域可能只占一个字节中的几个比特，它没有自己独立的内存地址，而引用在底层通常是作为指针实现的。既然无法获取一个比特位的地址，自然也无法将其绑定到非 const 引用上。完美转发函数 fwd 的参数 T&amp;&amp; 是一个引用，因此该调用失败。\n解决方案：传递位域值的副本。任何接受位域的函数实际上接收的都是其值的副本，因此可以手动创建这个副本再传递。\nauto length = static_cast&lt;std::uint16_t&gt;(h.totalLength);fwd(length); // 成功","categories":["language"],"tags":["language","CPP"]},{"title":"条款 27 - 熟悉依万能引用型别进行重载的替代方案","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE27%20-%20%E7%86%9F%E6%82%89%E4%BE%9D%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%9E%8B%E5%88%AB%E8%BF%9B%E8%A1%8C%E9%87%8D%E8%BD%BD%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/","content":"条款26明确指出，对万能引用进行重载是一个坏主意，因为它过于“贪婪”，会意外地匹配到许多本意是想调用其他重载函数的调用。本条款则提供了多种替代方案，让我们可以在需要区分处理不同类型的同时，安全地使用万能引用的强大功能。\n简单的替代方案在介绍复杂技术之前，有几种简单的替代方法：\n\n舍弃重载，使用不同函数名：这是最简单的办法。与其重载 logAndAdd(T&amp;&amp;) 和 logAndAdd(int)，不如创建两个名字不同的函数，如 logAndAddName 和 logAndAddByIdx。这完全避免了重载决议的问题。但它的缺点是无法用于构造函数，因为构造函数的名称是固定的。\n\n传递 const T&amp;：放弃完美转发，回归 C++98 的 const T&amp; 传参方式(同样可以接受左值和右值)。这种方法简单，但牺牲了完美转发带来的效率（例如，无法移动右值，也无法避免为字符串字面量等创建临时对象）。\n\n传值：将参数按值传递。这在某些情况下能够提升性能，但其适用场景和利弊权衡非常复杂（条款41有详细讨论），并非一个通用的解决方案。\n\n\n标签分派 (Tag Dispatch)标签分派是一种在编译期根据类型的某些“属性”（而非类型本身）来选择不同函数实现的技术。它通过创建一系列空的“标签”类型（通常是空结构体 struct），并利用函数重载机制，让编译器根据传入的标签类型自动选择最优或最正确的代码路径。这是一种强大且经典的模板元编程技术，可以完美解决重载问题。\n理解标签分派为了在将标签分派和万能引用结合时不至于困惑, 我们先思考一个更自然的问题: 为何需要标签分派？\n我们都知道 C++标准库中的 std::advance 函数, 这个函数的作用是将一个迭代器前进 n 步。而不同容器的迭代器性能天差地别：\n\n随机访问迭代器 (Random Access Iterator)：例如 std::vector::iterator。它可以进行常数时间 O(1) 的跳跃，直接使用 it += n 即可。\n双向迭代器 (Bidirectional Iterator)：例如 std::list::iterator。它只能一步一步地前进或后退，前进 n 步需要 O(n) 的时间，即执行 n 次 ++it。\n前向迭代器 (Forward Iterator)：例如 std::forward_list::iterator。它只能一步一步地前进，同样需要 O(n) 的时间。\n\n现在，如果我们想自己实现一个泛型的 my_advance 函数，该怎么做？一个朴素的想法可能是这样的：\ntemplate&lt;typename InputIterator, typename Distance&gt;void my_advance_naive(InputIterator&amp; it, Distance n) {    // 这种实现对所有迭代器都有效，但对随机访问迭代器来说效率极低！    while (n &gt; 0) {        ++it;        --n;    }}\n显然, 这个实现对于 std::vector::iterator 来说太慢了。我们希望当传入的迭代器是随机访问迭代器时，能自动调用 it += n。\n那我们该如何判断迭代器的类型呢？在函数体内使用 if 判断是运行时行为，并且我们无法在编译期根据这个条件选择不同的代码。而我们想要的是编译期就能确定最佳策略，没有任何运行时开销。这就是标签分派大显身手的地方。\n标签分派的实现步骤实现标签分派通常包含以下四个步骤：\n\n创建标签 (Tags)\n\n首先，定义一组空结构体，它们的存在仅仅是为了在类型系统中作为“标签”，以区分不同的特性。对于迭代器，C++标准库已经为我们定义好了这些标签（在  头文件中）：\n// 位于 std 命名空间struct input_iterator_tag {};struct output_iterator_tag {};struct forward_iterator_tag : public input_iterator_tag {};struct bidirectional_iterator_tag : public forward_iterator_tag {};struct random_access_iterator_tag : public bidirectional_iterator_tag {};// 注意：这些标签之间有继承关系，这使得一个随机访问迭代器同时也可以被视为一个双向迭代器，依此类推。\n\n\n关联类型与标签 (Type Traits)我们需要一种机制来查询一个类型（比如一个迭代器）对应的标签是什么。这就是类型萃取 (Type Traits) 的作用。\n\nC++标准库提供了 std::iterator_traits，它可以提取出任何迭代器的属性，其中就包括它的迭代器类别 (iterator category)。例如, std::iterator_traits&lt;std::vector::iterator&gt;::iterator_category 的类型是 std::random_access_iterator_tag。\n\n实现多个“工作”函数 (Worker Functions)接下来，我们编写多个内部辅助函数。这些函数执行实际的工作，并且它们根据不同的标签类型进行重载。\n\n// 这是 my_advance 的内部实现，用户不直接调用namespace detail {// 版本1：为随机访问迭代器特化的实现template&lt;typename RandomAccessIterator, typename Distance&gt;void my_advance_impl(RandomAccessIterator&amp; it, Distance n, std::random_access_iterator_tag) {    std::cout &lt;&lt; \"Using random access iterator implementation (O(1))\\n\";    it += n; // 高效的 O(1) 操作}// 版本2：为双向迭代器特化的实现template&lt;typename BidirectionalIterator, typename Distance&gt;void my_advance_impl(BidirectionalIterator&amp; it, Distance n, std::bidirectional_iterator_tag) {    std::cout &lt;&lt; \"Using bidirectional iterator implementation (O(n))\\n\";    if (n &gt;= 0) {        while (n-- &gt; 0) ++it;    } else {        while (n++ &lt; 0) --it;    }}// 版本3：为输入/前向迭代器特化的实现template&lt;typename InputIterator, typename Distance&gt;void my_advance_impl(InputIterator&amp; it, Distance n, std::input_iterator_tag) {    std::cout &lt;&lt; \"Using input iterator implementation (O(n))\\n\";    // (为简化，假设 n &gt;= 0)    while (n-- &gt; 0) ++it;}} // namespace detail\n我们定义了三个名为 my_advance_impl 的重载函数。它们唯一的区别是第三个参数的类型，分别是不同的迭代器标签。编译器在编译时会根据传入的标签类型，精确地选择其中一个版本。\n\n创建“分派”函数/公开函数 (Dispatcher Function)最后，我们创建一个公开的、用户调用的接口函数。这个函数不执行任何实际工作，它的唯一任务就是：获取迭代器的类型标签, 创建一个该标签类型的临时对象, 然后调用内部的“工作”函数，并将这个标签对象作为参数传进去，从而触发正确的重载。\n\ntemplate&lt;typename InputIterator, typename Distance&gt;void my_advance(InputIterator&amp; it, Distance n) {    // 步骤1：通过 iterator_traits 获取迭代器的类别（即标签类型）    using category = typename std::iterator_traits&lt;InputIterator&gt;::iterator_category;    // 步骤2 &amp; 3：调用内部实现，并传入一个标签类型的临时对象 category{}    // 编译器会根据 category{} 的类型来选择正确的 my_advance_impl 重载版本    detail::my_advance_impl(it, n, category{});}\n这里实现编译期决定调用的关键在于: category 是一个类型，而不是一个变量。关于类型的所有决策，都是在编译期由编译器完成的，而不是在程序运行时。\n\n当然, 在现代C++中, 我们有了更直接的工具: if constexpr (C++17), 可以在编译期进行分支判断，代码可以写在同一个函数内，更简洁; Concepts (C++20), 提供了更强大的模板约束能力，可以直接在函数声明中要求类型的属性，使得重载更加清晰。\n\nlogAndAdd 示例分析// 为了处理左值引用，我们需要 std::remove_referencetemplate&lt;typename T&gt;void logAndAdd(T&amp;&amp; name) {    logAndAddImpl(        std::forward&lt;T&gt;(name),        // 根据 name 的类型（移除引用后）是否为整型来创建标签        std::is_integral&lt;typename std::remove_reference&lt;T&gt;::type&gt;()    );}// 实现版本1：为非整型准备（标签类型为 std::false_type）template&lt;typename T&gt;void logAndAddImpl(T&amp;&amp; name, std::false_type) {    names.emplace(std::forward&lt;T&gt;(name));}// 实现版本2：为整型准备（标签类型为 std::true_type）void logAndAddImpl(int idx, std::true_type) {    names.emplace(nameFromIdx(idx));}\n当 logAndAdd 被调用时，std::is_integral 会在编译期判断传入的参数类型是否为整型。如果传入的是 std::string，is_integral 的结果是 std::false_type，于是编译器会选择匹配 std::false_type 的 logAndAddImpl 版本。而如果传入的是 int，is_integral 的结果是 std::true_type，于是编译器会选择匹配 std::true_type 的 logAndAddImpl 版本。\n由于公开的 logAndAdd 函数没有被重载，从而避免了条款26中的问题。真正的重载发生在实现函数 logAndAddImpl 上，但由于其签名中包含了不同的标签类型，重载决议可以精确无误地进行。\n类型萃取上述代码中, 我们使用了 std::iterator_traits 来获取迭代器的类型标签, 使用 std::remove_reference 来移除引用, 这些都是类型萃取工具, 因此下面我们对此进行详细的解释, 学习这一现代C++泛型编程中不可或缺的一部分。\n类型萃取 (Type Traits) 是一种在编译期查询和获取一个类型（Type）的各种属性（Traits）的编程技术。你可以把它想象成一个内置于C++编译器的“类型信息查询系统”。\n它的核心思想是：为给定的类型 T，提供一个统一的接口（通常是一个模板类），通过这个接口，我们可以在编译期间得到关于 T 的各种信息，例如：\n\n这个类型是不是一个整数？（is_integral）\n这个类型是不是一个指针？（is_pointer）\n如果去掉这个类型的 const 限定符，它会是什么类型？（remove_const）\n两个类型是不是完全相同？（is_same）\n\n这些查询完全在编译期进行，不会产生任何运行时开销。编译器会利用查询结果来生成最优化的代码。\n为什么需要类型萃取？前面我们使用的“标签分派”技术就是利用了类型萃取的能力, 它可以根据类型的属性, 选择不同的实现路径, 从而实现编译期的多态。这便是类型萃取的一个重要应用场景: 在泛型编程中，我们经常需要编写一个模板函数来处理各种不同的类型。然而，不同类型往往需要不同的处理方式才能达到最佳性能或保证正确性。\n下面这个例子再帮助我们强化一下:假设我们要写一个泛型函数 my_copy，将一个数组的元素拷贝到另一个数组。一个简单通用的实现是逐个元素拷贝:\ntemplate&lt;typename T&gt;void my_copy_simple(T* dest, const T* src, size_t n) {    for (size_t i = 0; i &lt; n; ++i) {        dest[i] = src[i]; // 逐个调用赋值操作符    }}\n这个实现是正确的，但不是最高效的。对于像 int, char, double 这样的普通旧数据类型 (Plain Old Data, POD)，或者更现代的说法是可平凡拷贝的类型 (Trivially Copyable Types)，它们没有复杂的构造、析构或赋值逻辑，其内存布局就是一串字节。对于这些类型，使用 C 语言的 memcpy 函数进行内存块的整体拷贝会快得多。\n但问题来了：我们的 my_copy 函数如何在编译期知道类型 T 是否是“可平凡拷贝的”呢？我们不能用 if (some_runtime_check)，因为这会带来运行时开销，而且我们希望为不同类型生成完全不同的机器码。这正是类型萃取要解决的问题。我们可以利用类型萃取来“询问”编译器关于类型 T 的信息：\n#include &lt;type_traits&gt; // C++11 之后，所有类型萃取工具都在这里#include &lt;cstring&gt;template&lt;typename T&gt;void my_copy_optimized(T* dest, const T* src, size_t n) {    // 在编译期查询 T 是否是可平凡拷贝的    if constexpr (std::is_trivially_copyable_v&lt;T&gt;) {        // 如果是，编译器只会生成这部分代码        memcpy(dest, src, n * sizeof(T));    } else {        // 如果不是，编译器只会生成这部分代码        for (size_t i = 0; i &lt; n; ++i) {            dest[i] = src[i];        }    }}\n这里的std::is_trivially_copyable_v 是一个类型萃取。它是一个编译期常量，如果 T 是可平凡拷贝的，它的值就是 true，否则是 false。而if constexpr (C++17) 指示编译器在编译时进行判断。如果条件为 true，else 分支的代码甚至不会被编译，反之亦然。这样就实现了为不同类型属性生成不同代码路径的目的。\n类型萃取是如何实现的？类型萃取的核心机制是 模板特化 (Template Specialization)。我们通过定义一个基础模板（提供默认值），然后为我们感兴趣的特定类型提供特化版本（提供特定的值）。\ntemplate&lt;typename T&gt;struct is_pointer {    static const bool value = false;};template&lt;typename T&gt;struct is_pointer&lt;T*&gt; { // 这个 &lt;T*&gt; 就是特化    static const bool value = true;};\n当编译器遇到 is_pointer 时，它无法匹配特化版本 &lt;T*&gt;，所以会使用基础模板，得到 value = false。\n当编译器遇到 is_pointer&lt;int*&gt; 时，它发现这完美匹配特化版本 &lt;T*&gt;（此时 T 是 int），于是它会使用这个特化版本，得到 value = true。\n为了使用起来更方便（不用写 ::value），C++14之后通常会提供一个变量模板, 这样，我们就可以直接写 is_pointer_v&lt;int*&gt; 来获取 true\ntemplate&lt;typename T&gt;constexpr bool is_pointer_v = is_pointer&lt;T&gt;::value;\n\nC++标准库中的类型萃取C++标准库在  头文件中提供了极其丰富的一套工具，可以分为几大类：\n\n主类型类别 (Primary Type Categories): 判断一个类型属于哪个大的分类。\n\nstd::is_void\nstd::is_integral (是否为整数类型)\nstd::is_floating_point (是否为浮点数类型)\nstd::is_array (是否为数组类型)\nstd::is_pointer (是否为指针类型)\nstd::is_class (是否为类类型)\nstd::is_function (是否为函数类型)\n\n\n类型属性 (Type Properties): 查询类型的具体属性。\n\nstd::is_const (是否为 const 类型)\nstd::is_volatile (是否为 volatile 类型)\nstd::is_trivial (是否为平凡类型)\nstd::is_trivially_copyable (是否可平凡拷贝)\nstd::is_abstract (是否为抽象类)\nstd::is_constructible&lt;T, Args…&gt; (T是否能用Args…参数构造)\n\n\n类型关系 (Type Relationships): 比较两个类型之间的关系。\n\nstd::is_same&lt;T, U&gt; (T和U是否是同一类型)\nstd::is_base_of&lt;Base, Derived&gt; (Base是否是Derived的基类)\nstd::is_convertible&lt;From, To&gt; (From类型是否能隐式转换为To类型)\n\n\n类型修改 (Type Modifications): 在编译期对一个类型进行“计算”，得到一个新类型。\n\nstd::remove_const::type -&gt; std::remove_const_t\nstd::add_const::type -&gt; std::add_const_t\nstd::remove_reference::type -&gt; std::remove_reference_t\nstd::add_pointer::type -&gt; std::add_pointer_t\nstd::decay::type -&gt; std::decay_t (模拟按值传参时的类型退化)\n\n\n\n约束模板：std::enable_if对于构造函数等无法使用标签分派的场景，我们可以使用 std::enable_if 来约束模板，这项技术是基于 SFINAE（Substitution Failure Is Not An Error，替换失败并非错误）规则。\nstd::enable_if 可以根据一个编译期条件，来决定一个模板是否“存在”。如果条件为 false，模板就会在重载决议中被“禁用”或“移除”，编译器会假装它不存在。\nSFINAESFINAE 是 “Substitution Failure Is Not An Error” 的缩写，其中文直译为**“替换失败并非错误”**。\n这是一个 C++ 编译器的规则，指的是在为模板进行类型推导和参数替换时，如果某个替换导致了无效的代码（例如，调用了不存在的成员函数或使用了不存在的类型），编译器不会立即报错并停止编译，而是会静默地将这个模板从重载决议的候选集中移除，然后继续尝试其他可行的重载。这个特性是实现 C++ 类型萃取（Type Traits）和许多高级模板技术的基础。\n我们可以拆解这个过程如下: \n\n模板实例化与替换 (Template Instantiation and Substitution)当你调用一个模板函数时，编译器会根据你提供的参数推导出模板参数的具体类型。例如，调用 template void func(T arg); 时使用 func(123)，编译器会推导出 T 是 int。然后，编译器会用 int 替换 (substitute) 模板定义中所有的 T。\n\n替换失败 (Substitution Failure)在替换过程中，如果生成的代码在语法上是无效的，就称之为“替换失败”。常见的替换失败场景包括：\n\n\n\n访问一个不存在的嵌套类型：例如，模板代码使用了 typename T::inner_type，但 T 被替换为 int，而 int 并没有 inner_type。\n调用一个不存在的成员函数：模板代码调用了 arg.foo()，但传入的参数类型没有 foo() 成员。\n使用了不满足 static_assert 或其他编译期断言的类型。\n\n\n并非错误 (Is Not An Error)这是 SFINAE 的关键。一个替换失败并不会让编译器立刻报错。相反，编译器会认为：“好吧，这个模板函数对于给定的参数是不可行的，我将它从候选列表中移除，看看有没有其他同名的函数或模板可以匹配这次调用。”\n\n如果所有的候选函数（包括普通函数和模板）都因为不匹配或 SFINAE 而被排除了，那么最终编译器才会报告一个“没有匹配的函数”的错误。\nstd::enable_if：SFINAE 的主要工具在实践中，我们很少直接依赖隐式的替换失败，而是通过一个标准库工具 std::enable_if 来主动、清晰地触发 SFINAE。\nstd::enable_if 是一个条件编译的辅助模板。它的定义大致如下：\n// 如果 B 为 true, std::enable_if&lt;B, T&gt; 会有一个名为 type 的成员，其类型为 Ttemplate&lt;bool B, class T = void&gt;struct enable_if {};// 特化版本：当 B 为 true 时template&lt;class T&gt;struct enable_if&lt;true, T&gt; {    using type = T;};\n当第一个模板参数 B 为 true 时，std::enable_if&lt;true, T&gt; 结构体内部会有一个 type 成员。如果 B 为 false，则会匹配基础模板，而基础模板是空的，里面没有 type 成员。当我们试图访问一个不存在的 type 成员时，就会触发“替换失败”。\n从 C++14 开始，我们通常使用别名 std::enable_if_t&lt;B, T&gt;，它等价于 typename std::enable_if&lt;B, T&gt;::type。\n下面是一个例子，我们编写一个函数，使其只对整数类型（integral types）有效。\n#include &lt;iostream&gt;#include &lt;type_traits&gt; // for std::is_integral, std::enable_if_t// 方式一：作为返回类型（最常见）// 如果 T 是整数，返回类型为 void；否则，替换失败。template&lt;typename T&gt;std::enable_if_t&lt;std::is_integral_v&lt;T&gt;, void&gt;process(T value) {    std::cout &lt;&lt; \"Processing an integral value: \" &lt;&lt; value &lt;&lt; std::endl;}// 方式二：作为函数参数// 如果 T 是浮点数，这个重载版本才有效template&lt;typename T&gt;void process(T value, std::enable_if_t&lt;std::is_floating_point_v&lt;T&gt;&gt;* = nullptr) {    std::cout &lt;&lt; \"Processing a floating point value: \" &lt;&lt; value &lt;&lt; std::endl;}方式三：作为模板参数（C++11及以后）template&lt;typename T, typename = std::enable_if_t&lt;std::is_arithmetic_v&lt;T&gt;&gt;&gt;void some_other_func(T value) {    // ...}int main() {    process(10);      // 调用第一个版本，T=int, std::is_integral_v&lt;int&gt; is true    process(3.14);    // 调用第二个版本，T=double, std::is_floating_point_v&lt;double&gt; is true    // process(\"hello\"); // 编译错误！两个 process 模板都因 SFINAE 被排除了                       // 没有匹配的函数    return 0;}\n当调用 process(10) 时，编译器尝试匹配两个 process 模板。对于第一个模板，T 推导为 int。std::is_integral_v 是 true，所以 std::enable_if_t&lt;true, void&gt; 成功替换为 void。函数签名为 void process(int)。这是一个有效的候选。\n对于第二个模板，T 推导为 int。std::is_floating_point_v 是 false，std::enable_if_t 试图访问不存在的 type 成员，导致替换失败。此模板被移除。最终，只有第一个模板是唯一候选，因此被调用。\n当调用 process(3.14) 时，情况正好相反，第一个模板被 SFINAE 排除，第二个模板成为唯一候选。\nSFINAE 的局限性与现代C++的演进尽管 SFINAE 非常强大，但它也有明显的缺点：\n\n复杂的语法：typename std::enable_if&lt;…&gt;::type 这样的代码非常冗长且不直观。\n糟糕的错误信息：当所有重载都因为 SFINAE 被排除时，编译器通常会给出一个非常庞大且难以理解的错误报告，因为它会列出所有尝试过的失败的模板，而不是告诉开发者“你传入的类型不满足整数的要求”。\n概念表达能力弱：它是一种“曲线救国”的方式来表达对模板参数的约束，而不是直接地描述。\n\n为了解决这些问题，现代 C++ 提供了更好的工具：\nif constexpr (C++17): if constexpr 允许在函数体内部进行编译期分支。它不是选择不同的函数重载，而是在一个函数模板内部丢弃不符合条件的代码块。\ntemplate&lt;typename T&gt;void process_modern(T value) {    if constexpr (std::is_integral_v&lt;T&gt;) {        std::cout &lt;&lt; \"Integral value (if constexpr): \" &lt;&lt; value &lt;&lt; std::endl;    } else if constexpr (std::is_floating_point_v&lt;T&gt;) {        std::cout &lt;&lt; \"Floating point value (if constexpr): \" &lt;&lt; value &lt;&lt; std::endl;    } else {        // 在编译时就给出清晰的错误        static_assert(std::is_arithmetic_v&lt;T&gt;, \"process_modern only accepts arithmetic types\");    }}\n不同在于, SFINAE 在重载决议阶段起作用，用于选择哪个函数。if constexpr 在模板实例化后起作用，用于决定函数体内哪些代码被编译, 不过后者需要将逻辑聚合在一个函数内。\nConcepts (C++20): C++20 引入的 Concepts 是 SFINAE 的终极替代品。它允许我们直接、清晰地在模板定义上声明其参数必须满足的约束。\n#include &lt;iostream&gt;#include &lt;concepts&gt; // for std::integral// 使用 requires 子句来约束模板参数 Ttemplate&lt;typename T&gt;requires std::integral&lt;T&gt;void process_concepts(T value) {    std::cout &lt;&lt; \"Processing an integral value (concepts): \" &lt;&lt; value &lt;&lt; std::endl;}template&lt;typename T&gt;requires std::floating_point&lt;T&gt;void process_concepts(T value) {    std::cout &lt;&lt; \"Processing a floating point value (concepts): \" &lt;&lt; value &lt;&lt; std::endl;}\n使用requires关键字, 语法极其清晰易读。且当约束不满足时，编译器会给出非常明确的错误信息，例如：“process_concepts(std::string) failed because std::string does not satisfy the concept std::integral”。\n回到上一条款的示例条款26中的 Person 类，其完美转发构造函数会意外“劫持”拷贝构造函数的调用。我们的目标是：仅当传入的类型不是 Person 或其派生类时，才启用这个完美转发构造函数。\n#include &lt;type_traits&gt; // for std::enable_if, std::is_base_of, std::decay etc.// 前面提到的方式三class Person {public:    template&lt;        typename T,        // 仅当 T 不是 Person 或其派生类时，这个模板才有效        typename = std::enable_if_t&lt;            !std::is_base_of&lt;Person, std::decay_t&lt;T&gt;&gt;::value        &gt;    &gt;    explicit Person(T&amp;&amp; n);    // ... 其他构造函数};\n这里的 std::decay_t用于移除类型 T 的引用和 const/volatile 限定符，得到其“纯粹”的类型; std::is_base_of&lt;Base, Derived&gt;用于判断 Base 是否为 Derived 的基类（或类型相同）。\n当尝试拷贝 Person p 时（auto clone(p);），编译器会尝试匹配完美转发构造函数，此时 T 被推导为 Person&amp;。因此std::decay_t&lt;Person&amp;&gt; 的结果是 Person, !std::is_base_of&lt;…&gt;::value 为 false。\n正是这个 std::enable_if_t 导致了“替换失败”。根据 SFINAE 规则，这不是一个编译错误，而是简单地将这个构造函数模板从候选列表中移除。此时，唯一剩下的候选者就是编译器生成的拷贝构造函数，它被正确地选中了。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 26 - 避免依万能引用型别进行重载","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE26%20-%20%E9%81%BF%E5%85%8D%E4%BE%9D%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%9E%8B%E5%88%AB%E8%BF%9B%E8%A1%8C%E9%87%8D%E8%BD%BD/","content":"这一讲开门见山: 将一个接受万能引用参数的函数或模板与其他函数进行重载，是一个非常危险的设计，因为它几乎总是会导致意想不到的行为和难以理解的编译错误。\n核心问题：万能引用的“贪婪”万能引用（在模板中声明为 T&amp;&amp;）之所以危险，是因为它过于“贪婪”。根据C++的模板类型推导和重载决议规则，万能引用可以为几乎任何类型的实参生成一个精确匹配 (Exact Match) 的函数实例。\n在重载决议中，精确匹配的优先级非常高，高于那些需要类型提升（如 short 到 int）、类型转换（如派生类到基类）或添加 const 的匹配。这意味着，一旦万能引用版本的重载成为候选，它就会像磁铁一样“吸走”大量本意是想调用其他重载版本的函数调用。\n示例一：logAndAdd —— 万能引用与常规函数的重载这个例子展示了最直接的问题。假设我们有一个高效的、使用万能引用的 logAndAdd 函数，同时为了方便，我们又重载了一个接受 int 索引的版本, 当我们用一个 short 类型的变量来调用它时: \n// 全局数据std::multiset&lt;std::string&gt; names;// 重载版本 1: 万能引用template&lt;typename T&gt;void logAndAdd(T&amp;&amp; name) {    names.emplace(std::forward&lt;T&gt;(name));}// 重载版本 2: intvoid logAndAdd(int idx) {    names.emplace(nameFromIdx(idx));}short nameIdx;// ...logAndAdd(nameIdx); // 错误！调用的是万能引用版本\n首先, 程序员的意图非常明确，short 是一个整数类型，应该调用 logAndAdd(int idx) 这个版本。而重载决议过程却不是这样的. 它会尝试下列两种匹配\n对于尝试匹配 logAndAdd(int)：short 到 int 的转换是类型提升 (Promotion)，这是一个合法的匹配，但不是精确匹配。\n而对于匹配 logAndAdd(T&amp;&amp;)：编译器可以为万能引用实例化一个版本，其中 T 被推导为 short&amp;。这个 logAndAdd(short&amp;) 的实例对于 short 类型的实参来说是精确匹配 (Exact Match)。\n由于精确匹配的优先级高于类型提升，编译器选择了万能引用版本的 logAndAdd。也就是说, 在万能引用版本的函数体内，代码尝试用一个 short 去构造 names（一个 std::multisetstd::string）中的 std::string。由于不存在从 short 到 std::string 的构造函数，代码最终在 emplace 这一步编译失败。这个错误信息通常非常复杂，因为它发生在模板的深层实例化中，让程序员难以定位问题的根源。\n示例二：Person 构造函数 —— 完美转发构造函数的危险这个例子揭示了一个更微妙、更危险的问题。当一个类的构造函数被重载为万能引用时（通常被称为“完美转发构造函数”），它会“劫持”类的拷贝和移动机制。\nclass Person {public:    // 完美转发构造函数    template&lt;typename T&gt;    explicit Person(T&amp;&amp; n) : name(std::forward&lt;T&gt;(n)) {}    explicit Person(int idx) : name(nameFromIdx(idx)) {}        // 编译器会自动生成拷贝和移动构造函数};Person p(\"Nancy\");auto cloneOfP(p); // 或者Person cloneOfP(p), 意图是调用拷贝构造函数\n当客户端代码尝试拷贝一个 Person 对象时, 程序员希望调用编译器生成的拷贝构造函数 Person(const Person&amp;)。此时重载决议过程如下：\n\n匹配拷贝构造函数：实参 p 的类型是 Person（一个非 const 左值）。为了匹配拷贝构造函数的参数 const Person&amp;，需要为 p 添加 const 限定符。这是一个合法的匹配，但不是精确匹配。\n匹配完美转发构造函数：编译器可以为万能引用构造函数实例化一个版本，其中 T 被推导为 Person&amp;。这个 Person(Person&amp;) 的实例对于 Person 类型的左值实参 p 来说是精确匹配。\n\n同样，精确匹配胜出。编译器选择了完美转发构造函数，而不是拷贝构造函数。在完美转发构造函数体内，代码尝试用 p（一个 Person 对象）来初始化 name（一个 std::string 成员）。这当然会失败，并产生一堆令人费解的错误信息。\n在这个例子里, 完美转发构造函数破坏了类的基本功能（拷贝）。它同样会劫持派生类对基类的拷贝和移动调用，导致继承体系出现问题。\n总而言之, 在设计函数和类时，应极力避免将接受万能引用的版本与其他版本进行重载。在下一讲条款27会详细介绍如何处理那些确实需要类似重载行为的场景，例如使用标签分派、static_assert 或 C++20 的 concepts 等技术来约束模板，从而安全地实现期望的功能。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 20 - 对类似 std::shared_ptr 但有可能空悬的指针使用 std::weak_ptr","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE20%20-%20%E5%AF%B9%E7%B1%BB%E4%BC%BC%20std%20shared_ptr%20%E4%BD%86%E6%9C%89%E5%8F%AF%E8%83%BD%E7%A9%BA%20%E6%82%AC%E7%9A%84%E6%8C%87%E9%92%88%E4%BD%BF%E7%94%A8%20std%20weak_ptr/","content":"","categories":["language"],"tags":["language","CPP"]},{"title":"条款 21 - 优先选用 std::make_unique 和 std::make_shared, 而非直接使用 new","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE21%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20std%20make_unique%E5%92%8Cstd%20make_shared,%20%E8%80%8C%E9%9D%9E%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%20new/","content":"三大make系列函数","categories":["language"],"tags":["language","CPP"]},{"title":"条款 29 - 假定移动操作不存在、成本高、未使用","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE29%20-%20%E5%81%87%E5%AE%9A%E7%A7%BB%E5%8A%A8%E6%93%8D%E4%BD%9C%E4%B8%8D%E5%AD%98%E5%9C%A8%E3%80%81%E6%88%90%E6%9C%AC%E9%AB%98%E3%80%81%E6%9C%AA%E4%BD%BF%E7%94%A8/","content":"该条款旨在为开发者对C++11移动语义的性能预期“降温”，提醒我们移动语义并非万能的性能优化选择。在编写代码时，尤其是在编写通用代码（如模板）时，更安全的做法是假定移动操作可能不存在、可能成本高昂，或者在特定上下文中可能不会被使用。\n移动语义是C++11的标志性特性，它允许编译器用成本低廉的移动操作来代替昂贵的复制操作，甚至在某些情况下，只需重新编译C++98的代码就能获得性能提升 。然而，这种“传奇”般的描述常常掩盖了现实中的复杂性。本条款的目的就是揭示这些复杂性，让我们对移动语义有一个更现实的期望。\n移动语义可能不会带来好处的四种场景在以下几种情况中，你将无法从移动语义中获得预期的性能增益：\n\n没有移动操作 (No move operations): 待移动的对象根本没有提供移动操作（移动构造函数和移动赋值运算符）。\n\n实际上, 许多为C++11之前编写的遗留代码中的类没有移动操作。即使在C++11中，如果一个类显式声明了复制操作、移动操作或析构函数中的任何一个，编译器都不会自动为其生成移动操作（参见条款17）。\n当代码请求移动一个没有移动操作的对象时，编译器会退而求其次，转而执行复制操作 。\n\n移动未能更快 (Move is not faster): 待移动的对象虽然提供了移动操作，但其实现并不比复制操作更快。\n\n例如 std::array 的内容是直接存储在对象内部的，不像 std::vector 那样在堆上分配内存并只持有一个指针。因此，移动一个 std::array 必须逐个移动其内部的所有元素, 这是一个线性时间的操作，其成本与复制一个 std::array 相当，远非人们想象中“像复制指针一样快” 。\n再比如 std::string 与小型字符串优化 (SSO), 许多 std::string 的实现采用了SSO技术，即将短字符串直接存储在 std::string 对象内部的缓冲区中，避免了堆内存分配。当移动一个采用了SSO的短字符串时，其操作本质上就是复制内部缓冲区，因此其成本与复制操作并无区别 。\n\n移动不可用 (Move is not available): 在某些需要强异常安全保证的语境下，移动操作只有在被声明为 noexcept 时才会被调用。\n\n以 std::vector 扩容为例，如果元素的移动构造函数可能会抛出异常，vector 在移动了一半元素后若发生异常，将无法恢复到原始状态，破坏了强异常安全保证。为了维持异常安全，如果一个类型的移动操作没有被标记为 noexcept，那么在这些需要强异常安全的场景中（如 std::vector 扩容），编译器会强制调用复制操作，即使移动操作本身存在且可能更高效 。\n\n源对象是个左值 (Source object is an lvalue): 移动操作的源通常必须是右值（例如，临时对象或通过 std::move 转换的对象。如果尝试从一个左值“移动”，实际上会触发复制操作，除非显式使用了 std::move\n\n最后需要指出, 本条款的建议并非是完全放弃对移动语义的依赖，而是要采取一种审慎的态度。在通用代码中（如模板）：由于你无法预知将要处理的类型 T 是否支持高效且不抛异常的移动，最安全的做法是假定移动成本高昂，像在C++98中那样谨慎地对待复制操作 。\n而在特定代码中, 如果你明确知道正在使用的类型（例如 std::vector 或 std::string）的移动语义细节，并且确定它们在你的使用场景中是高效且会被调用的，那么你完全可以依赖移动语义来提升性能 。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 25 - 针对右值引用实施 std move, 针对万能引用实施 std forward","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE25%20-%20%E9%92%88%E5%AF%B9%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E5%AE%9E%E6%96%BD%20std%20move,%20%E9%92%88%E5%AF%B9%E4%B8%87%20%E8%83%BD%E5%BC%95%E7%94%A8%E5%AE%9E%E6%96%BD%20std%20forward/","content":"我们在条款23了解了std::move 与 std::forward, 而条款25提供了一个简单、强大且几乎永远正确的指导方针，用于决定何时使用 std::move 以及何时使用 std::forward, 那就是:\n\n对右值引用，总是使用 std::move 来进行转发。\n对万能引用，总是使用 std::forward 来进行转发。\n\nstd::move 用于右值引用右值引用（如 Widget&amp;&amp;）在形参中有一个明确的特性：它只能绑定到右值，即那些可以被移动的对象。虽然形参本身（例如 rhs）是一个左值，但我们确切地知道它所引用的对象是临时的或被显式标记为可移动的。\n因此，当我们要将这个形参传递给其他函数（例如，在构造函数中初始化成员）时，我们应该无条件地将其转换为右值，以触发移动操作。std::move 就是执行这种无条件转换的工具。\n如下, 在移动构造函数中，形参 rhs 是一个右值引用。我们使用 std::move 来移动其成员 name 和 p 到当前对象的成员中。\nclass Widget {public:    Widget(Widget&amp;&amp; rhs) // rhs 是右值引用      : name(std::move(rhs.name)), // 对 rhs 的成员实施移动        p(std::move(rhs.p))    { ... }private:    std::string name;    std::shared_ptr&lt;SomeDataStructure&gt; p;};\n\n这个指导方针也适用于按值返回的函数。当你在 return 语句中返回一个绑定到右值引用的形参对象时，应该相应地使用 std::move 来避免拷贝, 提升效率。\nMatrix operator+(Matrix&amp;&amp; lhs, const Matrix&amp; rhs) {    lhs += rhs;    return std::move(lhs); // 将 lhs 移动到返回值中}\n\n然而, 如果你的 return 语句中返回的是局部变量, 千万不要对局部变量使用 std::move, 例如这样的代码\nWidget makeWidget() {    Widget w;    // ...    return std::move(w); // 错误的做法！}\n上述两者之所以不同, 是因为 C++ 编译器具有返回值优化(Return Value Optimization, RVO) 机制。对于 return w; 这样的语句，编译器通常可以直接在为函数返回值分配的内存中构造 局部变量w，从而完全避免任何复制或移动操作。同时, C++标准规定，在 return 语句中，局部变量会被自动视为右值。这意味着 return w; 的行为等同于 return std::move(w);\n如果使用 std::move(w) 会将 w 转换为右值引用。返回一个局部对象的引用会阻止编译器执行 RVO。因此，添加 std::move 不仅没有好处，反而可能阻止一项重要的编译器优化，弄巧成拙, 导致性能下降。\n而返回形参时, 由于形参不是函数内部创建的局部对象, 被视为左值，且不受RVO规则的约束。为了触发移动，你必须使用 std::move\nstd::forward 用于万能引用万能引用（在模板中声明为 T&amp;&amp;）则不同，它既可以绑定到右值，也可以绑定到左值。我们需要在转发它时保留其原始的左/右值属性。如果原始实参是右值，我们就应该将其作为右值转发；如果原始实参是左值，我们就应该将其作为左值转发 。\n因此, std::forward 正是执行这种有条件的转换的工具。它会检查模板参数 T 的推导类型，并仅在原始实参是右值的情况下，才将形参转换为右值。\n如下,在一个接受万能引用的 setName 函数中，我们使用 std::forward 来将 newName 转发给成员 name 的赋值运算符, 从而确保了当 setName 接收到右值时，会触发 std::string 的移动赋值；而当接收到左值时，则触发复制赋值。\nclass Widget {public:    template&lt;typename T&gt;    void setName(T&amp;&amp; newName) { // newName 是万能引用        name = std::forward&lt;T&gt;(newName); // 转发 newName    }    // ...};std::string getWidgetName(); // 工厂函数，返回右值Widget w;w.setName(getWidgetName()); // 调用时传入右值，setName 内部发生移动赋值auto n = getWidgetName();w.setName(n); // 调用时传入左值 n，setName 内部发生复制赋值\n\n如果在万能引用上误用 std::move，将导致一个严重的bug：它会无条件地将形参转换为右值，即使调用者传入的是一个左值。这会导致调用者的局部变量被意外“掏空” \n\n同理, 当你在 return 语句中返回一个绑定到万能引用形参的对象时，应该相应地使用 std::forward。这里的情况与上述的std::move一致\ntemplate&lt;typename T&gt;Fraction reduceAndCopy(T&amp;&amp; frac) // frac 是一个万能引用{    frac.reduce();    // 关键：按值返回，但使用 std::forward 转发 frac    return std::forward&lt;T&gt;(frac); }","categories":["language"],"tags":["language","CPP"]},{"title":"条款 19 - 使用 std::shared_ptr 管理具备共享所有权的资源","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE19%20-%20%E4%BD%BF%E7%94%A8%20std%20shared_ptr%20%E7%AE%A1%E7%90%86%E5%85%B7%E5%A4%87%E5%85%B1%E4%BA%AB%E6%89%80%E6%9C%89%E6%9D%83%E7%9A%84%E8%B5%84%E6%BA%90/","content":"不同于std::unique_ptr，std::shared_ptr 是一种用于管理共享所有权资源的智能指针。当多个代码块需要共同拥有和管理同一个对象的生命周期，并且希望在该对象的最后一个使用者结束使用时自动销毁它，std::shared_ptr 就是理想的选择。它实现了类似垃圾回收的自动内存管理，但其析构是确定性的。\n工作原理：引用计数std::shared_ptr 的核心机制是引用计数 (reference counting)。而引用计数的关键在于控制块 (Control Block)：每一个由 std::shared_ptr 管理的资源都有一个与之关联的、在堆上分配的“控制块”。这个控制块中包含一个引用计数值，用来跟踪有多少个 std::shared_ptr 正指向该资源 。\n当一个新的 std::shared_ptr 通过直接构造, 拷贝构造或拷贝赋值指向一个资源时，其引用计数值会递增（原子操作）。当一个 std::shared_ptr 被析构或被赋值为指向另一个资源时，其原指向资源的引用计数值会递减（原子操作）。\n当引用计数值减至 0 时，意味着不再有 std::shared_ptr 指向该资源，最后一个递减计数的 std::shared_ptr 会负责销毁该资源 。\n注意, 不能说 std::shared_ptr 的构造函数一定会增加引用计数, 因为从一个已有 std: :shared_ptr 移动构造一个新的std::shared ptr 会将源 std: shared ptr 置空, 结果是不需要进行任何引用计数操作。从这里也可以看出来移动操作要比拷贝操作快不少\n性能与内存开销std::shared_ptr 并非零开销，其成本主要体现在：\n\n尺寸：一个 std::shared_ptr 对象的大小是裸指针的两倍 。一个指针用于指向资源，另一个指针用于指向控制块 。\n\n控制块分配：控制块本身需要在堆上动态分配内存。不过，条款21中介绍的 std::make_shared 可以避免这次额外的分配。\n\n原子操作：引用计数的增减必须是原子操作，因为不同线程可能同时对指向同一资源的 std::shared_ptr 进行操作。原子操作通常比非原子操作要慢 。\n\n\n自定义删除器与 std::unique_ptr 类似，std::shared_ptr 也支持自定义删除器。但两者之间存在一个关键区别：std::shared_ptr 的删除器类型不是其类型的一部分 。\n这意味着不同删除器的 std::shared_ptr 具有完全相同的类型。这使得它们可以被存储在同一个容器中（例如 std::vector&lt;std::shared_ptr&gt;），提供了比 std::unique_ptr 更高的灵活性 。\n另一点不同，是自定义析构器不会改变 std::shared_ptr 的尺寸。无论析构器是怎样的型别，std::shared_ptr 对象的尺寸都相当于裸指针的两倍. 这是因为自定义删除器被存储在堆上的控制块中，而不是 std::shared_ptr 对象本身内部。更进一步, std::shared_ptr 的第二个指针所指的控制块包含下列许多信息:\n一个对象的控制块由创建首个指涉到该对象的 std::shared_ptr 来确定。此外, 控制块的基本规则如下:\n\nstd::make_shared（参见条款 21）总是创建一个控制块。std::make_shared 会生成一个用于管理所涉及新对象的控制块，因为在调用 std::make_shared 的时刻，显然不会有针对该对象的控制块存在。\n\n从具备专属所有权的指针（即 std::unique_ptr 或 std::auto_ptr 指针）出发构造一个 std::shared_ptr 会创建一个控制块。专属所有权指针不使用控制块，因此对于其所指涉的对象来说，不应存在控制块。作为构造过程的一部分，std::shared_ptr 被指定了其所指涉对象的所有权，因此那个专属所有权的智能指针会被置空。\n\n当 std::shared_ptr 的构造函数使用裸指针作为实参调用时，它会创建一个控制块。这个看起来平平无奇的点会造成一种致命的错误。例如:\n\n\nauto pw = new Widget; // pw 是一个裸指针// 错误！为同一个裸指针创建了两个控制块std::shared_ptr&lt;Widget&gt; spw1(pw); // 为 *pw 创建一个控制块，引用计数为 1std::shared_ptr&lt;Widget&gt; spw2(pw); // 也为 *pw 创建一个控制块，引用计数为 1\nspw1 和 spw2 各自创建了一个独立的控制块。它们都认为自己是 *pw 的唯一所有者群体。当 spw1 被销毁时，它会发现其引用计数变为0，于是它会 delete pw。之后，当 spw2 被销毁时，它也会发现其引用计数变为0，于是它会再次 delete pw。对同一个指针进行两次删除会导致未定义行为。\n因此, 永远不要用同一个裸指针来初始化多个 std::shared_ptr, 而是应该通过复制一个已存在的 std::shared_ptr 来创建新的 std::shared_ptr，以确保它们共享同一个控制块。\nthis 指针问题与 std::enable_shared_from_this","categories":["language"],"tags":["language","CPP"]},{"title":"条款2：理解 auto 型别推导","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE2%20-%20%E7%90%86%E8%A7%A3%20auto%20%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC/","content":"首先我们抛出这一讲的核心思想: auto 类型推导几乎就是模板类型推导, 除了稍后会介绍到的唯一区别之外\n两者概念性的转换这种对应关系可以通过一个概念性的转换来理解。例如, 对于前一讲介绍的函数模板调用：\ntemplate&lt;typename T&gt;void f(ParamType param);f(expr); // 编译器利用 expr 推导 T 和 ParamType\n\n一个使用auto声明的变量可以被看作是这个模式的变体，其中auto扮演了模板中的T，而变量的类型修饰符（如const、&amp;等）和T一起则扮演了ParamType 。\n例如，以下auto声明：\nauto x = 27;const auto cx = x;const auto&amp; rx = x;\n在概念上，编译器为了推导它们的类型，其行为就如同为每个声明生成了一个模板并用初始化物调用它一样 ：\n// 概念上为推导 x 的类型可以理解为存在以下模板template&lt;typename T&gt;void func_for_x(T param);func_for_x(27); // param 的类型就是 x 的类型// 概念上为推导 cx 的类型template&lt;typename T&gt;void func_for_cx(const T param);func_for_cx(x); // param 的类型就是 cx 的类型// 概念上为推导 rx 的类型template&lt;typename T&gt;void func_for_rx(const T&amp; param);func_for_rx(x); // param 的类型就是 rx 的类型\n\nauto的三种推导情况因为auto类型推导与模板类型推导机制相同，条款1中划分的三种推导情况也完全适用于auto。\n\n情况1：类型修饰符是指针或引用（但非万能引用）\n\n此时推导规则与模板相同，初始化表达式的引用性和const属性会被保留。\nconst auto&amp; rx = x; // rx 是一个非万能引用 [cite: 278]\n\n\n情况2：类型修饰符是万能引用\n\n当使用auto&amp;&amp;时，左值和右值初始化物会被区别对待，推导出不同的类型。\nauto&amp;&amp; uref1 = x;  // x 是 int 且是左值, uref1 类型为 int&amp; [cite: 279]auto&amp;&amp; uref3 = 27; // 27 是 int 且是右值, uref3 类型为 int&amp;&amp; [cite: 279]\n\n\n情况3：类型修饰符既非指针也非引用\n\n此时推导规则也与模板相同，初始化表达式的引用性、const和volatile属性都会被忽略。\nauto x = 27; // 情况3 (x既非指针也非引用) [cite: 276]const auto cx = x; // cx 也属于情况3 [cite: 277]\n同样地，数组和函数名在auto类型推导中也会退化成指针，除非auto被声明为引用。\nconst char name[] = \"R. N. Briggs\";    // name 的类别是 const char[13]auto arr1 = name; // arr1 的类别是 const char*auto&amp; arr2 = name; // arr2 的类别是 const char (&amp;)[13]void someFunc(int, double); // someFunc 是个函数，类别是 void(int, double)auto func1 = someFunc; // func1 的类别是 void (*)(int, double)auto&amp; func2 = someFunc; // func2 的类别是 void (&amp;)(int, double)\n\n唯一的例外：大括号初始化表达式 {}auto类型推导和模板类型推导真正的唯一区别在于它们如何处理用大括号括起来的初始化表达式。\n正如在条款7中提到的, 在C++11中，有多种语法可以初始化一个int：\nint x1 = 27;int x2(27);int x3 = {27};int x4{27};\n\n当把int替换为auto时，前两种写法的行为符合预期，变量被推导为int。然而，后两种使用大括号的写法，会触发一条针对auto的特殊推导规则：当用于auto声明的变量的初始化表达式是用大括号括起时，推导所得的类型就是std::initializer_list 。\nauto x1 = 27;   // 类型是 int [cite: 291]auto x2(27);  // 类型是 int [cite: 293]auto x3 = {27}; // 类型是 std::initializer_list&lt;int&gt; [cite: 293]auto x4{27};  // 类型是 std::initializer_list&lt;int&gt; [cite: 294]\n\n这个特殊规则是auto独有的。如果将同样的大括号初始化物传递给一个函数模板，类型推导会失败，代码将无法通过编译; 而auto则可以\nauto x = {11, 23, 9}; // x 的类型是 std::initializer_list&lt;int&gt; [cite: 300]template&lt;typename T&gt;void f(T param);f({11, 23, 9}); // 错误！无法为 T 推导出类型\n在lambda表达式中的特殊不过需要注意的是，这条关于大括号的特殊规则仅适用于auto变量声明。在C++14中，当auto被用于推导函数返回值或用于lambda表达式的形参时，它遵循的是模板类型推导的规则，而非auto的特殊规则 。\n因此，一个返回大括号初始化表达式的函数将无法通过编译，因为它遵循的是模板类型推导，而模板类型推导无法处理这种情况 。\n// C++14auto createInitList() {    return {1, 2, 3}; // 错误！无法为 {1, 2, 3} 完成类型推导 }std:: vector&lt;int&gt; v; auto resetV =     [&amp;v ](const auto&amp; newValue) { v = newValue; } ; // (++14 合法)    resetV({ 1, 2, 3 }) ; // 错误！无法为{ 1, 2, 3} 完成型别推导\n\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款1 ：理解模板型别推导","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE1%20-%20%E7%90%86%E8%A7%A3%E6%A8%A1%E6%9D%BF%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC/","content":"如果一个复杂系统的用户对于该系统的运作方式一无所知，然而却对其提供的服务表示满意，这就充分说明系统设计得好。如果从这样的角度来看， C++的模板型别推导取得了极大的成功。\n模板的型别推导，是现代C++最广泛应用的特性之一 ———— auto的基础。也就是说，如果你对C++98 推导模板型别的运作方式感觉满意，那么你也会自然而然地愉快接受C++11 中推导 auto 型别的运作方式。而坏消息则是，当模板型别推导规则应用于auto语境时，它们不像应用于模板时那么符合直觉。出于这个缘故，了解作为auto 基础的模板型别推导的方方面面就变得相当重要了。 \n不过在学习类型推导之前, 我们有必要复习一下const的基础用法\nconst 的基本用法最简单的形式是定义一个常量。一旦初始化，它的值就不能再被改变。这个概念很简单，但当 const 和指针、引用以及模板结合时，情况就变得复杂了。\nconst int MAX_SIZE = 100;// MAX_SIZE = 200; // 编译错误！不能修改 const 变量\n\nconst与指针const 与指针的结合有两种关键形式，理解它们的区别是核心。我们可以通过 const 的位置来判断它的作用对象(距离最近的或者左侧的那个)。\n\n首先是指向常量的指针，也称为“底层 const” (low-level const)。\n\nconst int* ptr;   // 距离最近的是int, 所以const修饰的是int// 或者 (效果完全相同)int const* ptr;   // 左侧的是int, 所以const修饰的是intint a = 10;int b = 20;const int* ptr = &amp;a;// *ptr = 15; // 编译错误！不能通过 ptr 修改 a 的值ptr = &amp;b;    // 正确。ptr 可以指向另一个地址\n含义：你不能通过这个指针 ptr 来修改它所指向的数据。但是，你可以让这个指针 ptr 指向别处。\n\n常量指针 (Constant Pointer), 也称为“顶层 const” (top-level const)。\n\nint* const ptr = &amp;a; // 必须在声明时初始化; 左侧是int*, 所以const修饰的是int*int a = 10;int b = 20;int* const ptr = &amp;a;*ptr = 15; // 正确！可以通过 ptr 修改 a 的值，现在 a 变成 15// ptr = &amp;b; // 编译错误！不能修改 ptr 指向的地址\n\n含义：指针 ptr 本身的值（即它存储的地址）是不能被修改的。它必须永远指向初始化时的那个地址。但是，你可以通过它来修改它所指向的数据（前提是数据本身不是 const）。\n此外, 指向常量的常量指针 (Constant Pointer to Constant Data)是上面两种情况的结合。指针 ptr 本身的指向和它指向的数据都不能被修改。\nconst int* const ptr = &amp;a;\n\nconst 与引用const 与引用的关系比较简单，因为引用本身就像一个别名，它不能被“重新绑定”到另一个对象，所以只有类似“指向常量的指针”也就是底层调用这一种情况。\nint a = 10;const int&amp; ref = a;  // 距离最近的是int, 所以const修饰的是int// ref = 20; // 编译错误！不能通过 const 引用修改数据a = 30;    // 正确。原始变量可以修改，ref 的值也会跟着变为 30\n\nconst int&amp; 是一个非常重要的编程惯用法。当按引用传递函数参数时，如果函数不需要修改这个参数，强烈建议形参使用 const 引用。这有两个好处：首先是安全, 防止函数内部意外修改了外部数据。其次还高效：避免了按值传递时创建对象的拷贝开销。同时也具有灵活性, 可以接受临时对象（右值）。\n模板型别推导所谓 C++ 模板参数推导的核心目标是：编译器必须为模板参数（如 T）找到一个（唯一的）类型，使得当这个 T 被替换回函数签名后，形成的形参（Parameter）类型能够合法地接收（绑定）我们传入的实参（Argument）。\n模板函数在推导类型 T 时，参数的 const 属性是否被保留，取决于函数参数 param 的声明方式。下列讨论针对的一般形式如下\ntemplate&lt;typename T&gt; void f(ParamType param); f(expr);   // 从 expr 来推导 T 和 ParamType 的型别\n情况 1：按值传递 (T param)首先, 将实参的引用部分忽略.\n接着, 当函数参数是按值传递时，实参的 const 属性会被忽略。这是因为按值传递会创建一个新的对象，而新对象的 const 属性与实参无关。\n\n若实参是个volatile 对象，同忽略之(volatile 对象不常用，它们一般仅用于实现设备驱动程序)。\n\ntemplate&lt;typename T&gt;void f(T param) {    // ...}int x = 10;const int cx = x;const int&amp; rx = x;f(x);  // T 被推导为 int, param 的类型是 intf(cx); // T 被推导为 int, param 的类型是 int (cx 的 const 被忽略)f(rx); // T 被推导为 int, param 的类型是 int (rx 的 const 和引用都被忽略)\n考虑这种情况： expr是个指涉到 const 对象的 const 指针，且 expr按值传给 param:\ntemplate&lt;typename T&gt; void f(T param);  // param 仍按值传递const char* const ptr = \"Fun with pointers\";  // ptr 指涉到 const 对象的 const 指针f(ptr);  // 传递型别为 canst char* canst 的实参\n这里，位于星号右侧的 const 将 ptr 声明为 const: ptr 不可以指涉到其他内存位置，也不可将 ptr 置为 null。而位于星号左侧的 const 则将 ptr 指涉到的对象（那个字符串）为const, 即该字符串不可修改。可 ptr 被传递给 f 时，这个指针本身将会按比特复制给param。换言之，ptr这个指针自己会被按值传递。依照按值传递形参的型别推导规则，ptr 的const性会被忽略，param 的型别会被推导为 canst char*，即一个可修改的、指涉到一个 const 字符串的指针。即对于上述示例, 在型别推导的过程中，ptr指涉到的对象的常量性会得到保留，但其自身的常量性则会在以复制方式创建新指针param的过程中被忽略。\n情况 2：按指针或引用传递 (T&amp; 或 T*)当函数参数是指针或引用时，引用实参的 const 属性或者指针所指数据的const属性会被保留并成为类型 T 的一部分\ntemplate&lt;typename T&gt;void f_ref(T&amp; param) {    // ...}template&lt;typename T&gt;void f_ptr(T* param) {    // ...}int x = 10;const int cx = x;f_ref(x);  // T 被推导为 int, param 的类型是 int&amp;f_ref(cx); // T 被推导为 const int, param 的类型是 const int&amp;const int* px = &amp;x;int* const ppx = &amp;x;f_ptr(&amp;x); // T 被推导为 int, param 的类型是 int*f_ptr(px); // T 被推导为 const int, param 的类型是 const int*f_ptr(ppx); // T 被推导为 int, param 的类型是 int*; 因为传递指针本质也是按指针拷贝(拷贝指针a的值也就是变量的地址到指针b), 而这里的指针具有常量性, 因此在按值拷贝的过程中会失去; 上一个示例的const修饰的不是指针所以在指针的按值拷贝过程中不会失去\n在这个过程中，编译器就像在解一个方程. 再例如: \n// 模板函数定义template&lt;typename T&gt; void f(const T&amp; param); // 一个返回 std::vector 的工厂函数std::vector&lt;Widget&gt; createVec(); // 使用工厂函数返回值初始化 vwconst auto vw = createVec(); if (!vw.empty()) {     // 调用模板函数    f(&amp;vw[0]); }\n\n函数模板（签名）: template void f(const T&amp; param);\n形参类型 (P): const T&amp;\n实参类型 (A): const Widget*\n\n下面我们求解 T：根据规则, T 获取实参的底层const属性, 同时因为传入指针而形参不存在指针, 编译器自然假设 T = const Widget*。\n接着将 T 替换回形参 P ( const T&amp; )后得到形参类型：param 的类型变为 const (const Widget*) &amp;, 这也通常被读作 const Widget* const &amp;。(这是一个“对 [指向 const Widget 的 const 指针] 的 const 引用”)\n尝试绑定：编译器再次尝试将实参 (A) 绑定到这个新生成的形参 (P) 上：此时实参 (A): const Widget*; 形参 (P): const (const Widget*) &amp; (即 const Widget* const &amp;)\n因为实参类型 const Widget* 与形参期望引用的核心类型的主体 const Widget* 完全匹配。没有发生任何丢弃常量性的危险操作; 同时我们的实参（&amp;vw[0] 的结果）是一个临时产生的指针，它是一个右值 (rvalue)。C++ 规定，右值不能绑定到非 const 的左值引用 (non-const lvalue reference)，但它们可以完美地绑定到 const 的左值引用 (const lvalue reference)。我们的形参 const (const Widget*) &amp; 正是一个 const 左值引用，因此它可以合法地绑定来自实参的右值。\n情况 3：按万能引用传递 (T&amp;&amp; param)这种情况更为特殊，但规则与情况2类似：const 属性会被保留。\ntemplate&lt;typename T&gt;void f_forward(T&amp;&amp; param) {    // ...}int x = 10;const int cx = x;f_forward(x);  // T 被推导为 int&amp;f_forward(cx); // T 被推导为 const int&amp;\n\n详细情况线上略\n数组实参和字符指针以上已经基本讨论完模板型别推导的主流情况，但还有一个边缘情况值得了解。这种情况是：数组型别有别千指针型别，尽管有时它们看起来可以互换。形成这种假象的主要原因是，在很多语境下，数组会退化成指涉到其首元素的指针。\n函数实参和函数指针总之, 在模板型别推导过程中，数组或函数型别的实参会退化成对应的指针，除非它们被用来初始化引用\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款7：区别使用( )与{ }创建对象","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE7%20-%20%E5%8C%BA%E5%88%AB%E4%BD%BF%E7%94%A8(%20)%E4%B8%8E%7B%20%7D%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1/","content":"复习初始化语法在 C++11 中, 进行对象初始化的语法大致可以分为三类:\n\n使用小括号, 如 int x(10);\n使用大括号, 如 int x{10};\n使用等号, 如 int x = 10;当然, 很多情况下也可以使用一个等号和大括号来初始化对象, 如：int z = { o } ; , 下面的讨论我们将忽略这种”等号加大括号“语法，因为 C++ 通常会把它和只有大括号的语法同样处理。\n\n容易引起歧义的是, 使用等号来书写初始化语句往往会让 C++新手误以为这里面会发生一次赋值，但实际上却是没有的。我们要明白, 初始化和赋值这两种行为背后调用的是不同的函数：\nWidget w1;  // 调用的是默认构造函数Widget W2 = w1;  // 不是赋值而是初始化, 调用的是拷贝构造函数w1 = W2;   // 是赋值, 调用的是拷贝赋值运算符\n\n统一初始化尽管有了那么多初始化语法，但在 C++98 中却仍然没有办法来表达某些想要进行的初始化。比如，之前是没有办法直接指定 STL 容器在创建时持有N个特定集合的值的(比如持有 1 、3 、5)\n为了着手解除众多的初始化语法带来的困惑，也为了解决这些语法不能覆盖所有初始化场景的问题， C++11 引入了统一初始化：单一的、至少从概念上可以用于一切场合的初始化语法。它的基础是大括号形式的初始化\n使用大括号来指定容器的初始内容是非常简单的：\nstd: :vector&lt;int&gt; v{ 1, 3, 5 }; std: :vector&lt;int&gt; v2 = { 1, 3, 5 };  // 与上述等价\n大括号同样可以用来为非静态成员指定默认初始化值，这项能力（在 C++11 中新增）也可以使用 “=” 的初始化语法，却不能使用小括号：\nclass Widget { private:     int x{ 0 };     int y = 0;     // int z(0) 不可行!}; \n\n另一方面, 不可复制的对象（如 std::atomic 型别的对象，参见条款 40）可以采用大括号和小括号来进行初始化，却不能使用 “=” 来初始化. \nstd::atomic&lt;int&gt; ai{ 0 };  // 可行std::atomic&lt;int&gt; ai2(0);  // 可行std::atomic&lt;int&gt; ai3 = 0;  // 错误\n\n这么一来，就很容易理解为何大括号初始化被冠以“统一” 之名了。在 C++的各种初始化表达式的写法中，只有大括号适用所有场合。\n禁止内建型别之间进行隐式窄化型别转换大括号初始化有一项新特性，就是它禁止内建型别之间进行隐式窄化型别转换(narrowing conversion) 。如果大括号内的表达式无法保证能够采用进行初始化的对象来表达，则代码不能通过编译：\ndouble x, y, z; int sum{ x + y + z }; // 错误，double 型别之和在大括号内无法窄化转换为 int 表达\n而采用小括号和“=”的初始化则不会进行窄化型别转换检查，因为如果那样的话就会破坏太多的遗留代码了：\nint sum2( x + y + z) ;  // 没问题（表达式的值被截断为 intint sum3 = x + y + z;   // 同上\n\n最令人苦恼之解析语法 (mostvexing parse) 免疫。大括号初始化的另一项值得一提的特征是，它对于 C++ 的最令人苦恼之解析语法 (mostvexing parse) 免疫。 C++ 规定：任何能够解析为声明的都要解析为声明，而这会带来副作用。所谓最令人苦恼之解析语法就是说，程序员本来想要以默认方式构造一个对象，结果却不小心声明了一个函数。这个错误的根本原因在于构造函数调用语法。\n当你想以传参方式调用构造函数时，可以这样写：widget w1(10);\n但如果你试图用对等语法来调用一个没有形参的 Widget 构造函数的话，那结果却变成了声明了一个函数而非对象：Widget w2 (); \n这个语句实际上声名了一个名为 w2 、返回widget对象的函数！\n由于函数声明不能使用大括号来指定形参列表，所以使用大括号来完成对象的默认构造没有上面这个问题：widget w3{}; // 调用没有形参的构造函数\n大括号的缺陷关于大括号初始化，也说了不少了。这种语法可以应用的语境最为宽泛，可以阻止隐式窄化型别转换，还对最令人苦恼之解析语法免疫。那么，为什么本章的章名不干脆换成“优先选用大括号初始化语法”之类呢？\n大括号初始化的缺陷在于伴随它有时会出现的意外行为, 这种行为源于大括号初始化物、std::initializer_list 以及构造函数重载决议之间的纠结关系。这几者之间的相互作用可以使得代码看起来是要做某一件事，但实际上是在做另一件事。\n先认识 std::initializer_liststd::initializer_list（初始化列表）是一个轻量级的类模板，它的主要目的是让我们可以方便地使用花括号 {} 来初始化对象或向函数传递一组值。它是 C++11 中统一初始化 (Uniform Initialization) 语法的重要基石。\n下面我们介绍它的几个特性: \n\n轻量级代理 (Lightweight Proxy): std::initializer_list 本身不拥有它所表示的元素。它更像一个“代理”或“视图”，内部通常只包含两个成员：一个指向元素序列头部的指针，以及一个表示元素数量的计数器。这些元素本身被编译器存放在一个临时的、只读的数组中。因为 std::initializer_list 只是“指向”这个临时数组，所以它的创建和拷贝开销非常小。\n同质性 (Homogeneous): 一个 std::initializer_list 对象中的所有元素都必须是 T 类型，或者可以隐式转换为 T 类型。例如，std::initializer_list 只能持有整数。\n只读性 (Read-only): 你不能修改通过 std::initializer_list 访问的元素。它提供的迭代器是 const 迭代器，返回的是对 const T 的引用。这保证了初始化数据源的安全性。\n\n大括号初始化 auto 类型变量当使用 auto 声明变量时，大括号初始化会导致一个可能出人意料的结果。具体细节可以参考条款2：理解auto型别推导。简单来说，如果用大括号初始化表达式来初始化一个 auto 型别的变量，那么推导出来的型别就会是 std::initializer_list。但如果使用相同的表达式来初始化一个非 auto 型别的变量，或者用小括号或”=”的方式来初始化 auto 型别的变量，auto 就会推导出你想要的型别\n规则：编译器强烈优先选择 std::initializer_list 构造函数首先, 在构造函数被调用时, 如果形参中没有任何一个具备 std:: initializer_list 型别,那么小括号和大括号的意义就没有区别：\nclass Widget { public:     Widget(int i, bool b); // 构造函数的形参中没有任何一个具备 std::initializer_list 型别    Widget(int i, double d); // std::initializer_list 型别}; Widget w1(10, true);  // 调用的是第一个构造函数Widget w2{10, true};  // 调用的还是第一个构造函数Widget w3(10, 0.0);  // 调用的是第二个构造函数Widget w4{10, 0.0};  // 调用的还是第二个构造函数\n然而, 当使用大括号初始化语法进行对象构造时，如果类中存在一个或多个构造函数接受 std::initializer_list 作为参数，编译器会强烈优先选择这些重载版本。这种偏好非常强烈，以至于它会覆盖其他看起来更匹配的构造函数，甚至包括复制和移动构造函数 。\n同时, 编译器还会尽一切可能将大括号内的参数转换为 std::initializer_list 中元素的类型，即使这意味着需要进行类型转换。\n#include &lt;initializer_list&gt;class Widget {public:    Widget(int i, double d) { /* ... */ }  // #1    Widget(std::string str) { /* ... */ } // #2    // initializer_list 构造函数，但元素类型会导致窄化    Widget(std::initializer_list&lt;bool&gt; il) { /* ... */ } };int main() {    Widget w0(10, 5.0);  // 小括号正常匹配    Widget w1{\"Hello\"};  // 调用#2    Widget w2{10, 5.0}; // 错误！}\n上述示例中, 我们可以看到, 如果大括号初始化语法中,编译器会优先调用 std::initializer_list 构造函数。在此基础上又分为两种情况: \n\n窄化转换导致编译失败（“否决”行为）\nw2这个场景展示的是，即使存在一个其他方面看起来很匹配的构造函数，但只要 std::initializer_list 版本的构造函数可以通过窄化转换来匹配，编译器就会优先尝试它，并且假如在此过程中因为窄化转换被禁止而报错，编译器就不会再考虑其他选项而直接编译失败。\n\n\n非窄化转换导致调用普通构造函数\n这个场景展示的是，当大括号内的参数**完全无法被转换(而不是窄化转换失败)**为 std::initializer_list 的元素类型时，编译器会放弃initializer_list 构造函数，回到正常的重载决议流程中，并选择其他匹配的构造函数。\n\n\n\n总之，即使存在精确匹配的普通构造函数，只要 std::initializer_list 版本的构造函数可以通过非窄化转换被调用，编译器就会选择它。不过如果转换是窄化的，则调用会失败，即使其他构造函数可以成功匹配 。\n另一个方向是, 即使是平常会执行复制或移动的构造函数也可能被带有 std:: initializer_list 型别形参的构造函数劫持：\nclass Widget { public:     Widget(int i, bool b);     Widget(int i, doubled);     Widget(std: :initializer_list&lt;long double&gt; il);    operator float() const; // 强制转换成 float 型别}; Widget w1(w4);  // 使用小括号，调用的是拷贝构造函数Widget w2{w4};  // /／ 使用大括号，优先调用的是带有 std::initializer_list 型别形参的构造函数(即使看起来像拷贝构造). 这里w4的返回值被强制转换为float, 随后float又被强制转换为long doubeWidget w3(std::move(w4));  // 同理 Widget w4{std::move(w4)};  // 同理\n\n特殊情况：空大括号 {}需要注意的是, 上述情况有个例外: 当使用一对空大括号 {} 进行初始化时，如果类同时拥有默认构造函数和 std::initializer_list 构造函数，C++ 规定优先调用默认构造函数。空大括号被解释为“没有参数”，而不是“一个空的 std::initializer_list” 。\nWidget w2{}; // 调用默认构造函数 Widget w4({});   // 调用 std::initializer_list 构造函数 Widget w5{{}};  // 同上 \n如果你确实想用一个空的列表来调用 std::initializer_list 构造函数，需要将空大括号作为参数显式传递 。\n经典案例: std::vector 的初始化对于我们今天讨论的大括号还是小括号初始化, 直接受到影响的一个类就是 std::vector\nstd::vector 有多个可以重载的构造函数, 其中一个构造函数的形参中没有任何一个具备 std:: initializer_list 型别的构造函数，它允许你指定容器的初始尺寸，以及一个初始化时让所有元素拥有的值; 但它还有个带 std: :initializer_list 型别形参的构造函数，允许你逐个指定容器中的元素值。\n因此, 如果你要创建一个元素为数值型别的 std:: vector(比如 std::vector), 并传递了两个实参给构造函数的话，你把这两个实参用小括号还是大括号括起来，结果会大相径庭：\n// 创建一个包含 10 个元素的 vector，每个元素的值都是 20 std::vector&lt;int&gt; v1(10, 20);// 创建一个包含 2 个元素的 vector，元素值分别为 10 和 20 std::vector&lt;int&gt; v2{10, 20};\n\n在上述示例中, 我们可以看到, v1 使用小括号，调用了指定容器尺寸和初始值的构造函数 。而 v2 使用大括号，由于 std::vector 有一个接受 std::initializer_list 的构造函数，编译器优先选择了这个版本 。\n启示对于类的设计者而言，一个核心结论是，在设计构造函数时必须意识到 std::initializer_list 带来的影响。\n如果在重载的构造函数中，有任何一个接受 std::initializer_list 类型的形参，那么使用大括号初始化的客户端代码将极有可能只会匹配到这个版本的构造函数 。这种行为的优先级非常高，以至于它不仅仅是与其他重载版本竞争，而是可能完全掩盖它们，导致其他构造函数“连露脸的机会都不给” 。\n因此，最佳实践是设计类的构造函数时，应确保客户无论使用小括号还是大括号，都不会意外地改变被调用的重载版本。从这个角度看，std::vector 的接口设计常被视为一个反面教材，应当从中吸取教训 。\n对于使用类的程序员来说，在创建对象时应该仔细思考是选用小括号 () 还是大括号 {} 初始化。目前并没有一个统一的定论，因为两种方式各有优劣，开发者通常会根据自己的偏好选择一种作为默认风格。\n偏好使用大括号 {} 的开发者 看重的是其更广泛的适用场景、能够禁止隐式的窄化类型转换，以及对 C++“最令人苦恼的解析语法”免疫的特性 。他们也承认，在某些特定情况下（例如为 std::vector 指定初始尺寸和元素值），使用小括号是必需的 。\n偏好使用小括号 () 的开发者 则倾向于保持与 C++98 语法的传统一致性 。这样做可以避免因 auto 类型推导产生的意外（即推导为 std::initializer_list），并且不会意外地触发接受 std::initializer_list 的构造函数 。他们同样承认，在某些场景下（例如用一组初始值创建容器），必须使用大括号 。\n最终，由于两种风格各有合理的理由，最好的建议是开发者可以根据团队的偏好任选一种，并在此后的代码中保持一致 。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款3：理解 decltype","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE3%20-%20%E7%90%86%E8%A7%A3%20decltype/","content":"decltype 是 C++11 引入的一个非常重要的关键字. 作为一个类型说明符 (type specifier), 它是 “declared type” (声明的类型) 的缩写, 也是 C++ 泛型编程（模板）和类型推导系统中至关重要的一块拼图。\n它的核心功能是：在编译时检查一个表达式，并“返回”该表达式所对应的确切类型，但并不会实际计算（执行）这个表达式。\n不过在介绍decltype之前, 我们先介绍一下返回值类型后置语法。\n返回值类型后置语法”（Trailing Return Type Syntax）“返回值类型后置语法”（Trailing Return Type Syntax）是 C++11 引入的一种语法，用于定义函数的返回值类型。它的基本形式是在函数参数列表后面使用 -&gt; 符号，后面跟着返回值类型, 而原先返回值类型的位置则使用auto作为占位符。\n// 经典语法return_type function_name(parameters);int add(int a, int b);// 后置语法auto function_name(parameters) -&gt; return_type;auto add(int a, int b) -&gt; int;\n\n对于像 int add(int a, int b) 这样的简单函数，新语法看起来更冗长，似乎毫无必要。那么，C++ 委员会为什么要引入这种语法呢？\n\n原因一：解决模板中依赖参数类型的返回类型推导\n\n这是引入该语法的最主要动机。在 C++11 之前，当我们编写模板函数时，如果返回类型依赖于参数的类型，我们就很难（甚至不可能）正确地声明它。\n假设我们要写一个模板函数 add，它接受两个不同类型的参数，并返回它们相加后的结果类型。例如，add(int, double) 应该返回 double。在 C++11 中，我们可以使用 decltype 来推导表达式的类型。因此我们很自然地会尝试这样写（使用经典语法）：\n// C++03/C++11 经典语法的“错误”尝试template&lt;typename T, typename U&gt;decltype(a + b) add(T a, U b); // 编译失败！\n但是, 因为在编译器解析到 decltype(a + b) 时，它处于函数声明的最前端。此时，参数 a 和 b 尚未进入作用域（Scope），编译器根本不知道 a 和 b 是什么，因此无法计算 a + b 的类型。\nC++11 引入的后置语法完美地解决了这个问题。通过将返回类型“拖尾”到参数列表之后，当编译器解析到 -&gt; 后面的 decltype 部分时，参数 a 和 b 已经声明并且位于作用域内了。这样做使得指定返回类型时可以使用函数的形参\ntemplate&lt;typename T, typename U&gt;auto add(T a, U b) -&gt; decltype(a + b) // 完全正确！{    return a + b;}\n其过程为: 当编译器看到 auto 时，它知道这是一个占位符，真正的返回类型在后面 –&gt; 编译器解析参数列表 (T a, U b)。此时，变量 a 和 b 被声明 –&gt; 编译器解析 -&gt; decltype(a + b)。由于 a 和 b 此时在作用域内，decltype 可以成功推导出 a + b 的结果类型（例如，如果是 int 和 double，则推导出 double）–&gt; 这个推导出的类型（double）将替换掉前面的占位符 auto。\n\n虽然 C++14 引入了更简洁的 auto 返回类型推导（auto add(T a, U b) { return a + b; }），但在 C++11 中，后置语法是解决此问题的唯一标准方法。\n\n\n原因二：提高复杂函数声明的可读性\n\nC++ 的经典函数声明语法（尤其是涉及函数指针或C风格数组指针时）是出了名的难以阅读（通常需要“从里向外”的“螺旋法则”来解析）。例如, 假设你要声明一个函数 foo，它接受一个 int，并返回一个“指向函数的指针”，该指针指向的函数接受 (int, int) 并返回 void。\n// 经典语法：非常难以阅读和书写void (*foo(int))(int, int);\n而使用后置语法，这个声明变得像从左到右阅读的普通句子一样清晰：\n// 后置语法：清晰易读auto foo(int) -&gt; void(*)(int, int);\n\n\n原因三：与 Lambda 表达式语法保持一致\n\nC++11 同时引入了 Lambda 表达式。当 Lambda 表达式需要显式指定返回类型时，它们必须使用后置语法（因为 Lambda 没有“函数名”可以在其前面放置类型）。\nauto my_lambda = [](int a, int b) -&gt; double {    if (b == 0) return 0.0;    return static_cast&lt;double&gt;(a) / b;};\n让普通函数也支持这种语法，使得 C++ 的可调用对象（函数和 Lambda）在外观上更加统一和现代化。\n为什么需要 decltype？（与 auto 的对比）在 C++11 中，我们已经有了 auto 关键字用于自动类型推导，但 auto 有一个特性：根据我们前面提到的条款1, 它在不加任何修饰使用时会“衰变”(decay)。这意味着 auto 会丢弃顶层的 const、volatile 以及引用 (&amp;)。\nconst int x = 10;const int&amp; ref_x = x;auto a = x;     // a 的类型是 int (const 被丢弃)auto b = ref_x; // b 的类型是 int (const 和引用 &amp; 都被丢弃，b 成了 x 的一个副本)\n但在很多泛型编程场景下，我们不希望类型被“衰变”，我们希望得到变量被声明时的确切类型。\n因为 decltype 保留精确类型, 因此它的作用就是获取那个确切的类型，而不会丢弃引用或 const\nconst int x = 10;const int&amp; ref_x = x;decltype(x) c = x;     // c 的类型是 const int (保留 const)decltype(ref_x) d = ref_x; // d 的类型是 const int&amp; (保留 const 和引用)                         // d 只是 ref_x 的一个别名，而不是副本。\n\ndecltype 的核心规则首先, decltype(expr)是一个类型说明符, 就像 int、std::string 一样, 必须出现在声明或类型别名等需要类型的地方。\ndecltype 的行为规则非常精确，但也有些微妙。它的行为取决于你给它的是一个“实体名称”还是一个更复杂的“表达式”。\n\n参数是实体（变量、函数参数等）\n\n如果传递给 decltype 的是一个没有被括号括起来的变量名、函数参数名或类成员名, decltype 返回该实体在声明时的确切类型。\nint i = 5;const int ci = 10;const double&amp; rd = 3.14;static int s_var;decltype(i)    type_i;    // 类型是: intdecltype(ci)   type_ci;   // 类型是: const intdecltype(rd)   type_rd = rd; // 类型是: const double&amp;decltype(s_var) type_s;   // 类型是: int (注意：static 不属于类型的一部分)\n\n\n参数是表达式（或函数调用）\n\n如果传递给 decltype 的是除规则1以外的任何东西——比如一个函数调用、一个算术运算，或者被额外括号括起来的变量, 那么 decltype 的结果将取决于该表达式的值类别 (Value Category)。\n\n如果表达式的结果是一个 prvalue (纯右值)，decltype 返回该值的类型 T。\n\n如果表达式的结果是一个 lvalue (左值)，decltype 返回 T&amp; (对该类型的左值引用)。\n\n如果表达式的结果是一个 xvalue (消亡值)，decltype 返回 T&amp;&amp; (对该类型的右值引用)。\n\n\nint i = 10;int* p = &amp;i;// 1. 纯右值 (prvalue) -&gt; Tdecltype(i + 5) type_add; // i + 5 产生一个临时的 int (纯右值)，所以类型是 int// 2. 左值 (lvalue) -&gt; T&amp;decltype(*p) type_ptr_deref = i; // *p (指针解引用) 是一个左值，类型是 int&amp;                               // (注意：这里 type_ptr_deref 成为了 i 的引用)// 3. 消亡值 (xvalue) -&gt; T&amp;&amp;decltype(std::move(i)) type_move; // std::move(i) 的结果是 int&amp;&amp; (消亡值)，所以类型是 int&amp;&amp;\n\n关键陷阱：decltype(x) vs decltype((x))这是 decltype 中最著名、也最容易混淆的知识点。它完美地展示了规则1和规则2的区别：\n对于 decltype(x)：\n\nx 是一个实体名称，没有被括号括起来。\n\n它匹配规则 1。\n\n结果是 x 被声明的类型，即 int。\n\n\n对于 decltype((x))：\n\n(x) 不是一个实体名称，它是一个表达式。（在C++标准中，任何用括号括起来的变量都被视为一个表达式）。\n\n任何具名变量（如 x）的表达式（如 (x)）都是一个左值 (lvalue)。\n\n它匹配规则 2（lvalue 情况）。\n\n结果是 T&amp;，其中 T 是 x 的类型 (int)。因此，结果是 int&amp;。\n\n\n这个细微的差别在模板元编程中至关重要，因为它允许我们检测一个表达式是否是左值。\ndecltype 的主要应用场景第一点就是我们上面提到过的泛型编程与返回值类型后置, 即auto add(T a, U b) -&gt; decltype(a + b);. 需要注意的是: a + b 是一个表达式。它产生一个纯右值 (prvalue)。根据规则 2，decltype 返回其结果类型 T（例如 int + double = double）。这个 double 类型被用于 -&gt; 之后的返回类型声明。\n第二点是 C++14 的 decltype(auto): decltype 本身是一个类型说明符，而 C++14 更进一步，引入了 decltype(auto) 语法。它告诉编译器：“请使用 auto 占位，但在推导时，请严格应用 decltype 的规则（而不是 auto 的衰变规则）。”\n这对于完美转发包装函数的返回值至关重要，它可以精确地保持被调用函数返回的是值、左值引用还是右值引用。\n// C++14：这个包装器完美地返回了 func(t) 所返回的一切，包括引用template&lt;typename F, typename... Args&gt;decltype(auto) forwardWrapper(F func, Args&amp;&amp;... args) {    return func(std::forward&lt;Args&gt;(args)...);}int g_var = 10;int&amp; get_g_var() { return g_var; }//...decltype(auto) ref = forwardWrapper(get_g_var); // ref 的类型被正确推导为 int&amp;","categories":["language"],"tags":["language","CPP"]},{"url":"/2025/09/25/web/Computer%20Network/%E5%8D%8F%E8%AE%AE/","content":"ARP协议ARP (Address Resolution Protocol)，即“地址解析协议”, 用于在一个局域网（LAN）内，将一个已知的IP地址（逻辑地址）解析（翻译）成对应的MAC地址（物理地址）。\n当主机A想要给同一局域网内的主机B发送数据时，主机A通常只知道主机B的IP地址（例如，你在ping 192.168.1.101）。但是，数据在局域网内最终是以数据帧的形式传播的，而帧的头部必须包含目标MAC地址。交换机根据这个MAC地址来转发帧。因此，主机A在发送数据之前，必须先获得主机B的MAC地址。\nARP的工作原理ARP的工作过程可以分为两个核心步骤：ARP请求 和 ARP应答。我们通过一个例子来说明。\n假设局域网内有两台主机：\n\n主机A: IP地址 192.168.1.100，MAC地址 AA-AA-AA-AA-AA-AA\n主机B: IP地址 192.168.1.101，MAC地址 BB-BB-BB-BB-BB-BB\n\n现在，主机A 想要向 主机B 发送数据。\n步骤1：检查ARP缓存主机A首先会检查自己的 ARP缓存表（ARP Cache）。这是一个存储了近期IP地址与MAC地址映射关系的动态表格(为了提高效率，避免每次通信都进行一次广播查询)。\n如果找到 192.168.1.101 对应的MAC地址，则直接使用该地址封装数据帧并发送，整个ARP过程结束; 如果没有找到，则进入下一步。\n步骤2：发送ARP请求（广播）主机A会在局域网内发送一个 ARP请求（ARP Request） 报文。\n这个请求的核心信息是：“谁的IP地址是 192.168.1.101？请告诉我的IP地址 192.168.1.100，我的MAC地址是 AA-AA-AA-AA-AA-AA”。\n这个ARP请求报文会被封装在一个以太网帧中。这个帧的特殊之处在于源MAC地址是主机A的MAC地址 (AA-AA-AA-AA-AA-AA), 目标MAC地址却是一个特殊的广播地址 (FF-FF-FF-FF-FF-FF)。使用广播地址意味着这个帧会被发送到该局域网内的所有设备。\n步骤3：网络中所有主机处理ARP请求局域网内的所有设备（包括主机B和其他主机）都会接收到这个广播帧。\n其他主机会检查ARP请求中的目标IP地址（192.168.1.101），发现与自身的IP地址不符，因此会静默丢弃这个请求，不作任何响应。\n而主机发现ARP请求中的目标IP地址正是自己的IP地址, 执行下一个阶段。\n步骤4：发送ARP应答（单播）主机B在确认请求是发给自己的之后，会构造一个 ARP应答（ARP Reply） 报文。\n报文内容：应答的核心信息是：“我就是 192.168.1.101，我的MAC地址是 BB-BB-BB-BB-BB-BB”。\n这个ARP应答报文也会被封装在一个以太网帧中，但这次是单播：源MAC地址是主机B的MAC地址 (BB-BB-BB-BB-BB-BB), 目标MAC地址是主机A的MAC地址 (AA-AA-AA-AA-AA-AA)。主机B之所以知道主机A的MAC地址，是因为它在最初的ARP请求中已经包含了。\n单播可以直接将应答信息发送给请求者（主机A），而不需要再打扰网络中的其他设备。\n步骤5：更新ARP缓存并通信主机A收到主机B的ARP应答后，就获取了 192.168.1.101 对应的MAC地址 BB-BB-BB-BB-BB-BB。\n接着, 主机A会将这个映射关系存入自己的ARP缓存表，并设置一个老化时间（例如2分钟）。在老化时间内，再次向 192.168.1.101 发送数据时，就可以直接从缓存中查找，无需再次发送ARP请求。\n主机A现在可以愉快地将数据封装成以太网帧（目标MAC为BB-BB-BB-BB-BB-BB），并通过交换机准确地发送给主机B了。\n总之, ARP 协议可以认为是网络层在与数据链路层交互时所使用的一个“工具”或“接口”, 利用网络层的IP地址获取数据链路层的MAC地址，以便在物理网络上进行通信\nARP 数据报格式IP协议IP地址: 可以在网络环境中, 唯一标识一台主机端口号: 可以在网络的一台主机中, 唯一标识一个进程IP地址+端口号: 可以在网络环境中, 唯一标识一台主机的一个进程\nTCP三次握手与四次挥手TCP 协议中至关重要的两个过程：三次握手（用于建立连接）和四次挥手（用于断开连接）是确保 TCP 协议实现可靠、面向连接的通信基础。\nTCP 报文段在开始之前，我们先了解几个 TCP 头部中起关键作用的标志位 (Flags)：\n\nSYN (Synchronize): 请求建立连接。在三次握手中的前两次会使用。\nACK (Acknowledgement): 确认号字段有效。表示对收到数据的确认。\nFIN (Finish): 请求断开连接。表示发送方已经没有数据要发送了。\nseq (Sequence Number): 序列号。用于标识 TCP 数据段中数据的字节流顺序。\nack (Acknowledgement Number): 确认号。表示期望收到对方下一个数据段的起始序列号。\n\n三次握手 (Three-Way Handshake)TCP 是一个面向连接的协议，在数据传输开始前，客户端和服务器必须先建立一个可靠的连接。这个过程就是“三次握手”。\n核心目的是确认双方的收发能力, 确保客户端能发能收，服务器也能发能收; 还可以同步初始序列号 (ISN), 双方协商一个初始序列号，为后续可靠的数据传输做准备。\n\n第一次握手 (Client → Server)\n\n动作：客户端向服务器发送一个连接请求报文段。\n标志位：SYN = 1, ACK = 0。\n序列号：客户端随机选择一个初始序列号 seq = x。\n状态：客户端进入 SYN_SENT 状态。\n含义：“你好，服务器。我想和你建立连接，我的初始序列号是 x。”\n\n\n第二次握手 (Server → Client)\n\n动作：服务器收到客户端的请求后，回复一个确认报文段。\n标志位：SYN = 1, ACK = 1。\n序列号：服务器也随机选择一个自己的初始序列号 seq = y。\n确认号：ack = x + 1。这个值表示“我已成功收到你的序列号 x，希望下一个收到的数据从 x+1 开始”。\n状态：服务器进入 SYN_RCVD 状态。\n含义：“好的，我收到了你的请求。我也准备好了，我的初始序列号是 y。同时，我确认收到了你的 x。”\n\n\n第三次握手 (Client → Server)\n\n动作：客户端收到服务器的确认后，再发送一个确认报文段。\n标志位：SYN = 0, ACK = 1。\n序列号：seq = x + 1。\n确认号：ack = y + 1。表示“我已成功收到你的序列号 y，希望下一个收到的数据从 y+1 开始”。\n状态：客户端进入 ESTABLISHED 状态。服务器收到这个确认后，也进入 ESTABLISHED 状态。\n含义：“好的，我收到了你的确认。现在连接正式建立，我们可以开始传输数据了。”\n\n\n\n为什么需要三次握手，而不是两次？这是为了防止已失效的连接请求报文段(第一次)突然又传送到了服务器，从而产生错误。如果是两次握手，服务器收到这个失效的请求后会立即建立连接，并等待客户端发送数据，这会浪费服务器资源。而三次握手时，客户端不会对这个过时的确认进行响应，服务器也就不会建立错误的连接。\n四次挥手 (Four-Way Handshake)当数据传输结束后，通信双方都可以发起请求来终止连接。由于 TCP 连接是全双工的（数据可以在两个方向上同时传输），因此断开连接需要双方各自关闭自己的发送通道。这个过程就是“四次挥手”。\n核心目的是安全、优雅地关闭连接，确保双方所有待发送的数据都已发送完毕。\n\n第一次挥手 (Client → Server)\n\n动作：客户端（主动关闭方）发送一个连接释放报文段。\n标志位：FIN = 1。\n序列号：seq = u (u 是客户端已发送数据的最后一个字节的序列号+1)。\n状态：客户端进入 FIN_WAIT_1 状态。\n含义：“我这边的数据已经全部发送完了，我要关闭发送通道了。”\n\n\n第二次挥手 (Server → Client)\n\n动作：服务器（被动关闭方）收到 FIN 后，发送一个确认报文段。\n标志位：ACK = 1。\n确认号：ack = u + 1。\n状态：服务器进入 CLOSE_WAIT 状态。客户端收到后，进入 FIN_WAIT_2 状态。\n含义：“收到了你的关闭请求。但请等一下，我可能还有数据没有发完。”\n注意：此时连接处于半关闭 (Half-Close) 状态。客户端不能再发送数据，但服务器仍然可以向客户端发送数据, 客户端可以接受。\n\n\n第三次挥手 (Server → Client)\n\n动作：服务器确认自己所有的数据也发送完毕后，向客户端发送一个连接释放报文段。\n标志位：FIN = 1, ACK = 1。\n序列号：seq = v (v 是服务器已发送数据的最后一个字节的序列号+1)。\n确认号：ack = u + 1。\n状态：服务器进入 LAST_ACK 状态，等待客户端的最后确认。\n含义：“我这边的数据也全部发送完了，现在我也要关闭发送通道了。”\n\n\n第四次挥手 (Client → Server)\n\n动作：客户端收到服务器的 FIN 后，发送最后一个确认报文段。\n标志位：ACK = 1。\n确认号：ack = v + 1。\n状态：客户端进入 TIME_WAIT 状态。经过 2MSL（两倍报文最大生存时间）后，客户端才进入 CLOSED 状态。服务器收到这个 ACK 后，立即进入 CLOSED 状态。\n含义：“好的，我也收到了你的关闭请求。连接正式关闭。”\n\n\n\n为什么挥手需要四次？因为 TCP 是全双工的。当一方（客户端）发送 FIN 请求关闭时，只表示它不会再发送数据了，但仍然可以接收数据。另一方（服务器）收到后，会先回复一个 ACK 确认，但它可能还有数据需要处理和发送，所以不能立即发送自己的 FIN。只有当服务器也准备好关闭时，才会发送自己的 FIN。因此，ACK 和 FIN 通常是分开发送的，这就构成了四次挥手。\n为什么客户端最后要进入 TIME_WAIT 状态并等待 2MSL？确保最后的 ACK 能到达服务器：如果这个 ACK 丢失，服务器会超时重传 FIN。TIME_WAIT 状态可以确保客户端有足够的时间来响应这个重传，从而使服务器能够正常关闭; 另一方面，等待 2MSL 可以确保本次连接中产生的所有报文段都从网络中消失，从而避免影响到下一个使用相同端口号的新连接。\nTCP连接状态图\n这张图精准地描述了一个 TCP 连接从创建到销毁的整个生命周期中所有可能的状态，以及在不同事件（如收到一个数据包、应用程序发起一个操作）驱动下，状态之间是如何转换的。\n\n方框：代表 TCP 连接可能处于的状态 (State)，例如 LISTEN, ESTABLISHED。\n箭头：代表状态的转换 (Transition)。\n箭头上的文字：代表触发这个转换的事件 (Event) 或 动作 (Action)。\n\n整个过程可以分为三个主要部分：\n\n连接建立（三次握手）：图的上半部分，从 CLOSED 到 ESTABLISHED。\n数据传输：中间的核心状态 ESTABLISHED。\n连接断开（四次挥手）：图的下半部分，从 ESTABLISHED 回到 CLOSED。\n\n第一阶段：连接建立（三次握手）\n这个过程涉及两方：客户端（主动打开方） 和 服务器（被动打开方）。\n\n服务器的路径（被动打开）\n\nCLOSED → LISTEN：初始状态是 CLOSED（关闭）, 服务器调用 listen() 函数后，进入 LISTEN 状态，开始监听指定的端口，等待客户端的连接请求。\nLISTEN → SYN_RCVD：\n事件：在 LISTEN 状态下，服务器收到了一个来自客户端的 SYN 请求报文。\n动作：服务器发送自己的 SYN 和对客户端 SYN 的 ACK 作为响应（即第二次握手）。\n转换：服务器状态变为 SYN_RCVD (SYN Received)，表示已收到连接请求，正在等待客户端的最终确认。\n\n\nSYN_RCVD → ESTABLISHED：\n事件：在 SYN_RCVD 状态下，服务器收到了客户端发来的 ACK 确认报文（即第三次握手）。\n转换：服务器状态变为 ESTABLISHED，表示连接已成功建立，可以开始数据传输。\n\n\n\n\n客户端的路径（主动打开）\n\nCLOSED → SYN_SENT：初始状态是 CLOSED, 客户端调用 connect() 函数，主动打开连接，并发送一个 SYN 请求报文（即第一次握手）, 此时客户端状态变为 SYN_SENT (SYN Sent)，表示已发送连接请求，正在等待服务器的响应。\nSYN_SENT → ESTABLISHED：\n事件：在 SYN_SENT 状态下，客户端收到了服务器的 SYN 和 ACK 报文（即第二次握手）。\n动作：客户端发送最后一个 ACK 确认报文（即第三次握手）。\n转换：客户端状态变为 ESTABLISHED，连接成功建立。\n\n\n\n\n\n第二阶段：数据传输\nESTABLISHED：这是整个 TCP 连接的核心状态。当客户端和服务器都处于此状态时，它们可以自由地、双向地进行数据传输。图中的“数据传送阶段”指的就是这个状态。\n第三阶段：连接断开（四次挥手）\n这个过程同样涉及两方：主动关闭方和被动关闭方。我们以客户端主动关闭为例。\n\n客户端的路径（主动关闭方）\n\nESTABLISHED → FIN_WAIT_1：\n动作：客户端应用程序调用 close()，主动关闭连接，发送一个 FIN 报文，表示自己没有数据要发送了。\n转换：客户端进入 FIN_WAIT_1 状态。\n\n\nFIN_WAIT_1 → FIN_WAIT_2：\n事件：客户端收到了服务器对自己 FIN 报文的 ACK 确认。\n转换：客户端进入 FIN_WAIT_2 状态。此时连接处于半关闭状态，客户端不能再发送数据，但可以接收来自服务器的数据。\n\n\nFIN_WAIT_2 → TIME_WAIT：\n事件：客户端收到了服务器发送的 FIN 报文，表示服务器也准备关闭连接了。\n动作：客户端发送最后一个 ACK 作为确认。\n转换：客户端进入 TIME_WAIT 状态。\n\n\nTIME_WAIT → CLOSED：\n事件：TIME_WAIT 是一个等待状态，通常会持续 2MSL（两倍报文最大生存时间）。\n目的：确保网络中所有与此连接相关的报文都已消失，并能处理可能丢失的最后一个 ACK。\n转换：等待计时结束后，连接彻底关闭，状态回到 CLOSED。\n\n\n\n\n服务器的路径（被动关闭方）\n\nESTABLISHED → CLOSE_WAIT：\n事件：服务器收到了来自客户端的 FIN 报文。\n动作：服务器发送一个 ACK 进行确认。\n转换：服务器进入 CLOSE_WAIT 状态。这个状态告诉上层应用程序：“对方已经关闭了连接，请处理剩余的数据并准备关闭”。\n\n\nCLOSE_WAIT → LAST_ACK：\n动作：服务器的应用程序完成数据处理后，调用 close()，发送自己的 FIN 报文。\n转换：服务器进入 LAST_ACK 状态，等待客户端的最后确认。\n\n\nLAST_ACK → CLOSED：\n事件：服务器收到了客户端发来的最后一个 ACK。\n转换：服务器状态变为 CLOSED，连接彻底关闭。\n\n\n\n\n\n图中还包含了一些特殊的状态转换，例如：\n\n同时打开 (SYN_SENT → SYN_RCVD)：双方同时向对方发送 SYN 请求，这种情况比较罕见。\n同时关闭 (FIN_WAIT_1 → CLOSING)：双方同时向对方发送 FIN 请求，会进入 CLOSING 状态，等待收到对方的 ACK 后再进入 TIME_WAIT。\n\n"},{"title":"预备知识","url":"/2025/09/14/algorithms/Computing%20Theory/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/","content":"集合 (Sets)基本定义与性质集合 (Set)：一个无序的元素集合 (An unordered collection of elements) 。\n空集 (Empty set)：记作 Ø 。\n子集 (Subset)：表示一个集合是否被另一个集合所包含。其严格定义为：S⊆T⇔(∀x∈S⇒x∈T)。任何集合都是其自身的子集 。\n集合相等 (Equal Sets)：两个集合相等当且仅当它们包含完全相同的元素。这等价于两个集合互为子集：S=T⇔(S⊆T)∧(T⊆S)。例如，集合 {1,2,3} 和 {3,2,1} 是相等的，因为元素的顺序无关紧要 。\n集合运算 (Set Operations)并集 (Union)：A∪B={x:x∈A or x∈B} 。\n交集 (Intersection) ：A∩B={x:x∈A and x∈B} 。如果两个集合的交集为空，则称它们不相交 (disjoint) 。\n补集 (Complement)：，其中  是全集 (Universal Set)。\n差集 (Difference)：A-B={x:x∈A and x∉B} 。例如 B-A 。\n对称差 (Symmetric Difference) : A∆B={x:x∈A or x∈B but not both} , 表示两个集合中只属于其中一个集合但不同时属于两个集合的元素所组成的集合, 是异或运算 (XOR) 的结果。\n集合恒等式这些恒等式是集合运算的基本定律 ：\n幂等律 (Idempotent Law) ：A∩A=A, A∪A=A 。\n交换律 (Commutative Law) ：A∪B=B∪A, A∩B=B∩A 。\n结合律 (Associative Law) ：A∪(B∪C)=(A∪B)∪C, A∩(B∩C)=(A∩B)∩C 。\n分配律 (Distributive Law) ：A∪(B∩C)=(A∪B)∩(A∪C) , A∩(B∪C)=(A∩B)∪(A∩C) 。\n吸收律 (Absorption Law) ：A∪(A∩B)=A, A∩(A∪B)=A 。\n德摩根定律 (De Morgan’s Law) ：A−(B∪C)=(A−B)∩(A−C), A−(B∩C)=(A−B)∪(A−C) 。\n幂集 (Power Set)定义：一个集合 A 的幂集是 A 的所有子集的集合 (Set of all subsets of A)，记作 。\n符号表示： = {T|T⊆A}。\n示例：如果集合 S 是 {x, y, z} ，那么它的幂集是 \n\\${{\\emptyset,\\{x\\},\\{y\\},\\{z\\},\\{x,y\\},\\{x,z\\},\\{y,z\\},\\{x,y,z\\}}}\\$\n\n划分 (Partition)定义：一个非空集合 A 的划分 (partition) 是  的一个子集  ，它需要满足以下三个条件：\n 本身不为空集 ()。\n 中任意两个不同的成员（它们本身是集合）的交集为空集。\n 中所有成员的并集等于 A ()。\n示例：集合 {1,2,3} 有五种划分 ：\n\n({1}, {2}, {3})\n({1,2}, {3})\n({1,3}, {2})\n({2,3}, {1})\n({1,2,3})\n\n关系与函数 (Relations and Functions)关系 (Relations)基本概念有序对 (Ordered Pair)：一个包含两个元素的对 (a,b)，其中元素的顺序是重要的 。两个有序对相等当且仅当它们的对应元素分别相等：(a,b)=(c,d)⇔(a=c)∧(b=d) 。\n笛卡尔积 (Cartesian Product)：两个集合 A 和 B 的笛卡尔积 A×B 是所有可能有序对的集合，定义为 A×B={(a,b)∣a∈A∧b∈B}。\n二元关系 (Binary Relation)：一个从集合 A 到集合 B 的二元关系 R 是笛卡尔积 A×B 的一个子集 (R⊆A×B)。\n关系的运算 (Operations of Relations)逆 (Inverse)：如果 R 是一个从 A 到 B 的关系 (R⊆A×B)，那么它的逆关系  是一个从 B 到 A 的关系 (⊆B×A) 。\n复合 (Composition)：给定从 A 到 B 的关系 R 和从 B 到 C 的关系 S，它们的复合关系 R∘S 是一个从 A 到 C 的关系。其定义为：R∘S={(a,c)∣∃b∈B,(a,b)∈R ∧ (b,c)∈S}。\n定义域与值域 (Domain and Range): \n定义域 (Domain)：一个关系的定义域是该关系中所有输入值的集合 。值域 (Range)：一个关系的值域是该关系中所有输出值的集合。\n函数 (Functions)定义 (Definition): 函数是一种特殊的二元关系 。一个从 A 到 B 的函数 f:A→B 必须满足两个条件：它是一个关系，即f⊆A×B; 对于集合 A 中的每一个元素 a，在集合 B 中都存在唯一一个元素 b，使得 (a,b)∈f。通常，我们将 (a,b)∈f 记作 f(a)=b 。\n函数类型 (Types of Functions)\n\n单射 (One-to-one / Injective)：如果定义域中任意两个不同的元素，它们在值域中的像也不同，即 ∀a,b∈A∧a≠b⇒f(a)≠f(b) 。\n满射 (Onto / Surjective)：如果值域中的每一个元素都至少是定义域中一个元素的像，即 ∀b∈B, ∃a∈A such that f(a)=b 。\n双射 (Bijective / One-to-one correspondence)：一个函数如果既是单射又是满射，则称其为双射。\n\n特殊类型的二元关系 (Special Types of Binary Relations)关系的表示方法有向图 (Directed Graph): 可以将集合 A 上的任意关系 R 表示为一个有向图。图中的节点 (node) 代表集合 A 中的每个元素。如果存在有序对 ，则从节点 a 到节点 b 画一条箭头 (arrow)，也称为图的边。\n矩阵 (Matrix): 二元关系也可以用逻辑矩阵来表示。矩阵的行和列分别对应关系中两个集合的元素。矩阵中的元素  定义如下：\n\n如果 ，则 。\n如果 ，则 。\n\n关系的基本性质对于一个定义在集合 A 上的关系 R (即，R⊆A×A)，它可能具有以下性质：\n自反性 (Reflexive)：对于 A 中的任意元素 a，都有 (a,a)∈R。对称性 (Symmetric)：如果 (a,b)∈R，那么一定有 (b,a)∈R。反对称性 (Antisymmetric)：如果 (a,b)∈R 且 (b,a)∈R，那么一定有 a=b。传递性 (Transitive)：如果 (a,b)∈R 且 (b,c)∈R，那么一定有 (a,c)**∈R。\n同时还需要掌握关系的性质对应到矩阵和有向图的表示.\n等价关系 (Equivalence Relation)定义：一个关系如果同时满足自反性、对称性和传递性，则称其为等价关系。\n等价类 (Equivalence Classes)：对于元素 a，其等价类 [a] 被定义为集合中所有与 a 等价的元素的集合(可以和a构成等价关系的元素的集合)，即 [a]={b∣(a,b)∈R}。在图表示中，一个等价类对应一个完全连接的”簇”。\n例如，可以有 a ~ b ⟺ a ≡ b (mod 3)，根据这个关系，整数可以被划分为三个等价类：[0] = {…, -6, -3, 0, 3, 6, …}（模 3 余 0）[1] = {…, -5, -2, 1, 4, 7, …}（模 3 余 1）[2] = {…, -4, -1, 2, 5, 8, …}（模 3 余 2）\n用图表示就是完全连接簇, 每个等价类就形成一个完全图（每两个节点之间都有边）\n与划分的关系 (Partition)：一个重要的定理指出，任何集合 A 上的等价关系，其所有等价类的集合构成了对集合 A 的一个划分。\n序关系 (Order Relations)偏序 (Partial Order): 一个关系 ≤ 如果同时满足自反性、反对称性和传递性，则称其为偏序关系。\n相关概念：\n\n最小元素 (Least element)：如果对集合中所有元素 b，都有 a≤b。\n极小元素 (Minimal element)：如果不存在异于 a 的元素 b 使得 b≤a(可以存在不可比的元素)\n最大元素 (Greatest element)：如果对集合中所有元素 b，都有 b≤a。\n极大元素 (Maximal element)：如果不存在异于 a 的元素 b 使得 a≤b。\n\n全序 (Total Order): 如果一个偏序关系满足对于集合中任意两个元素 a 和 b，都有 a≤b 或 b≤a 成立（即任意两个元素都可比较），那么这个关系被称为全序或线性序 (linear ordering)。\n有限集与无限集 (Finite and Infinite Sets)集合的等势与基数等势 (Equinumerous)：如果两个集合 A 和 B 之间存在一个双射函数 (bijective function)，则称它们是等势的 (equinumerous)，记作 A∼B 。等势关系是一种等价关系，满足自反性、对称性和传递性 。\n基数 (Cardinality)：基数是衡量集合中元素“数量”的一个概念。如果两个集合等势，那么它们的基数相同 。集合 A 的基数通常表示为 ∣A∣ 。广义基数理论允许我们区分不同类型的无穷大。\n有限集与无限集: 有限集 (Finite Set)指拥有有限数量成员的集合; 无限集 (Infinite Set)指不是有限集的集合。无限集又可以进一步分为可数无限和不可数无限。\n可数无限集 (Countably Infinite Sets)定义：如果一个集合与自然数集 N 等势，则称该集合是可数无限的 (countably infinite)。其基数记为 。\n希尔伯特旅馆悖论 (Hilbert’s paradox)：这是一个著名的思想实验，用来说明可数无限集的反直觉性质。即使旅馆客满（有无限个房间且都住着人），它仍然可以容纳：\n\n有限个新客人\n无限个新客人\n无限辆巴士，每辆巴士载有无限个新客人\n\n性质与示例：\n\n定理：可数无限个可数无限集的并集仍然是可数无限的。\n\n三种方法证明了集合 N×N 是可数无限的：\n\n对角线法图示\n构造一个双射函数\n构造两个方向的单射函数来证明基数相等\n\n不可数集与康托定理 (Uncountable Sets and Cantor’s Theorem)不可数集 (Uncountable Set)：如果一个无限集的基数大于自然数集 N 的基数，则称其为不可数集。\n定理：实数集 R 是不可数的，即 |R| &gt; |N|。\n有趣的是，开区间 (0,1) 与整个实数集 R 是等势的，可以通过反正切函数构造一个双射来证明。\n连续统假设 (Continuum hypothesis)：该假设由康托提出，它断言不存在一个基数严格介于整数基数 (ℵ₀) 和实数基数 (ℵ₁) 之间。\n康托定理 (Cantor’s Theorem)：这是一个基础性的定理，它指出对于任何集合 A，其基数严格小于其幂集 P(A) 的基数，即 card(A) &lt; card(P(A))。\n\n这意味着不存在”最大的无穷大”。\n该定理的证明使用了对角线法，通过构造一个特殊的集合 B = {x∈A | x∉f(x)} 来证明任何从 A 到其幂集 P(A) 的函数 f 都不可能是满射的。\n一个直接的推论是：自然数集的幂集 2ᴺ 是不可数的。\n\n三种基本证明技巧 (Three Fundamental Proof Techniques)数学归纳法 (The Principle of Mathematical Induction)这是一种用于证明关于自然数的命题的标准方法。\n原理：令 A 为一个自然数集合，如果满足以下两个条件：\n\n0∈A\n对于任意自然数 n，如果 {0,1,2,…,n}⊆A，那么 n+1∈A\n\n则 A 包含所有自然数。\n证明步骤通常包含三个部分：\n\n基础步骤 (Base Case)：证明命题 P(1)（或P(0)）成立\n归纳假设 (Inductive Hypothesis)：假设命题 P(k) 对于某个 k 成立\n归纳步骤 (Inductive Step)：证明 P(k+1) 也成立\n\n鸽巢原理 (The Pigeonhole Principle)该原理描述了一个简单但在证明中非常有用的数量关系。\n定义有两种形式：\n\n函数形式：如果 A 和 B 是有限集且 |A|&gt;|B|，那么不存在从 A 到 B 的单射函数\n物品形式：如果有 m 个物体要放入 n 个箱子，且 m&gt;n，那么至少有一个箱子包含至少两个物体\n\n示例：讲义中用该原理证明了”对于球体上的任意五个点，必定存在一个闭合的半球包含其中至少四个点”。\n证明：讲义本身提供了一个使用数学归纳法来证明鸽巢原理的过程。\n对角线法 (The Diagonalization Principle)这是一种由康托首创的强大证明技巧，常用于证明无限集的不可数性。\n核心思想：\n\n给定一个集合 A 上的二元关系 R，我们可以为每个元素 a∈A 定义一个”行集合” Ra={b|b∈A∧(a,b)∈R}\n通过考察对角线上的元素，我们可以构造一个新的”对角集合” D={a|a∈A∧(a,a)∉R}\n对角线法的关键在于，构造出的集合 D 与任何一个行集合 Ra 都不同\n\n重要应用：\n\n证明康托定理：\n\n假设存在一个从集合 A 到其幂集 P(A) 的双射函数 f\n构造对角集合 B={x∈A|x∉f(x)}\n这个集合 B 属于 P(A)，但不可能等于任何一个 f(x)\n由此产生矛盾，证明了函数 f 不可能是满射\n\n\n证明实数集 R 的不可数性：\n\n假设实数集是可数的，将其所有成员列成无限序列 r₀,r₁,r₂,…\n通过对角线法构造新实数 d，使其小数点后第 n 位与 rn 的第 n 位不同\n构造出的数 d 必然不在序列中，从而产生矛盾\n\n\n证明 2ᴺ 的不可数性：\n\n假设 2ᴺ 是可数的，将其成员表示为列表 R₀,R₁,R₂,…\n构造对角集合 D={n∈N|n∉Rn}\n集合 D 是 N 的子集，但与列表中的任何 Rn 都不同，产生矛盾\n\n\n\n闭包 (Closure)闭包的基本思想闭包的核心思想是：将一个集合进行扩展，使其在某种运算下具有”封闭”的性质，并且这种扩展是最小的。\n示例：\n自然数集 N 在减法运算下是不封闭的，因为两个自然数相减的结果不一定是自然数（例如，1-2=-1∉N）。\n整数集 Z 在减法运算下是封闭的。Z 是包含了 N 且在减法运算下封闭的最小集合。\n因此，我们称 Z 是 N 在减法运算下的闭包（closure）。\n关系的闭包 (Closures of Relations)这个概念同样可以应用于二元关系，即寻找一个最小的扩展关系，使其满足某些性质（如自反性、对称性、传递性）。\n自反传递闭包 (Reflexive Transitive Closure)表示符号：关系 R 的自反传递闭包通常记作 R*。\n定义：R* 是一个包含所有有序对 (a,b) 的集合，其中在 R 的有向图表示中，存在一条从 a 到 b 的路径（path）。路径的长度可以为0（即 a 到 a 自身）。\n性质：\n\nR* 包含了原始关系 R（R⊆R*）\nR* 本身是自反的和传递的\nR* 是包含了 R 并且满足自反性和传递性的最小关系\n\n传递闭包 (Transitive Closure)表示符号：关系 R 的传递闭包通常记作 R+。\n定义：R+ 是包含了 R 并且是传递的最小关系。它与 R* 的区别在于，R+ 不要求必须是自反的（即路径长度必须大于0）。\n形式化条件：一个关系是 R 的传递闭包 R+，必须满足：\n\nR⊆R+\nR+ 是传递的\n对于任何其他包含了 R 并且是传递的关系 R’，都有 R+⊆R’\n\n字母表与语言 (Alphabet and Language)本节是连接前面纯数学概念与后续计算理论核心内容的桥梁 。它形式化地定义了计算机科学中用于信息编码的基本单位：符号、字符串和语言 。\n字母表与字符串 (Alphabet and Strings)字母表 (Alphabet)定义：字母表（记作 Σ）是一个任意的有限集合。\n符号 (Symbol)：字母表中的元素被称为符号。\n示例：\n\n二进制字母表：Σ = {0,1}\n英文字母表：Σ = {a,b,c}\n\n字符串 (Strings) 及其运算定义：字符串 (String) 是由字母表中的符号组成的有限序列。字符串也常被称为词 (Word)。\n\n这里需要知道, 由一个非空字母表所能构成的字符串集合是无限的, 但是我们只把有限长度的字母组合叫做字符串, 也就是说, 一个无限长的 aaaa… 序列根据这个标准定义，不被认为是一个“字符串”\n\n空字符串 (Empty string)：不含任何符号的特殊字符串，记作 e。\nΣ* ：表示在字母表 Σ 上所有可能字符串的集合，包括空字符串 e。(也被称为字母表 Σ 的 克林闭包（Kleene Closure）)\n\n因此Σ*永远不为空集(至少包含e)\n\n字符串运算：\n\n连接 (Concatenation)：将两个字符串 x 和 y 首尾相连形成新字符串 xy。空字符串是连接运算的单位元，即对于任意字符串 w，we = ew = w。\n幂 (Exponentiation)：字符串 w 的 i 次幂 w^i 表示 w 自身连接 i 次。w^0 = e。\n逆序 (Reversal)：字符串 w 的逆序 w^R 是将 w 中的符号顺序颠倒。例如，如果 w = ua(a ∈ Σ), 则 w^R = au^R(递归定义)。\n\n语言 (Language)定义：一个语言 L 是在某个字母表 Σ 上所有字符串的集合 Σ 的一个任意子集* (L ⊆ Σ*)。\n示例：\n\n空语言 ∅\n只包含空字符串的语言 {e}\n字母表本身 Σ 以及 Σ* 都是合法的语言\n\n语言可以是：\n\n有限语言：通过明确列出所有字符串来定义\n无限语言：通过描述字符串应满足的性质来定义，例如 L = {a^n b^n | n ≥ 1}\n\n关于数量的重要定理\n对于任意非空有限字母表 Σ，其上所有字符串的集合 Σ* 是可数无限的。\n任何一个语言 L (作为 Σ* 的子集) 都是可数的。\n在 Σ 上所有可能语言的总数是不可数无限的，其基数与实数集相同。\n\n语言的运算标准集合运算：\n\n并集\n交集\n差集\n补集 (L = Σ* − L)\n\n语言特有运算：\n\n连接 (Concatenation)：L₁L₂ = {w₁w₂ | w₁ ∈ L₁ ∧ w₂ ∈ L₂}\n\n幂 (Exponentiation)：\n\nL⁰ = {e}\nL^(i+1) = LL^i\n\n\n克林星号/闭包 (Kleene Star)：\n\nL* = L⁰ ∪ L¹ ∪ L² ∪ ⋅⋅⋅\n表示由 L 中字符串进行任意次数（包括零次）连接所能形成的所有字符串的集合\nL* 是 L 在连接运算下的闭包\n\n\n正闭包 (Positive Closure)：\n\nL⁺ = L¹ ∪ L² ∪ L³ ∪ ⋅⋅⋅\n与 L* 的唯一区别是不包含零次连接，即不包含空字符串 e (除非 e 本身在 L 中)\n\n\n\n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"Vim","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Vim/","content":"","categories":["system","linux"],"tags":["system"]},{"title":"gcc","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/gcc/","content":"GCC 编译的四个阶段一个 C 语言源文件要变成可执行文件，需要经过预处理 (Preprocessing)、编译 (Compilation)、汇编 (Assembly) 和 链接 (Linking) 这四个核心步骤。\n当你执行一个简单的命令 gcc hello.c -o hello 时，GCC 实际上在后台为你自动完成了所有四个步骤, 分别是:\n第一步：预处理 (Preprocessing): 这个阶段处理源代码中以 # 开头的指令。它不关心代码的语法，只是对文本进行简单的替换和处理。\n\n输入文件: C 源文件，例如 hello.c\n输出文件: 经过预处理的 C 文件，通常以 .i 为后缀，例如 hello.i\nGCC 命令: gcc -E hello.c -o hello.i\n因为这里只展示预处理, -E 选项告诉 GCC 在预处理完成后就停止，不要进行后续步骤。\n-o 选项指定输出文件的名称, 这里是 hello.i\n\n\n主要工作内容：\n展开宏定义: 将所有 #define 定义的宏进行文本替换。\n处理条件编译: 根据 #if, #ifdef, #else, #endif 等指令，选择性地保留或移除代码段。\n包含头文件: 将 #include 指定的头文件内容原封不动地插入到源文件中。\n删除注释和多余空白: 移除代码中所有的注释 (// … 和 /* … */)、不必要的空行和空白字符。\n\n\n\n经过这个阶段，hello.i 文件会变成一个不包含任何宏、头文件引用或注释的“纯净”C代码文件。\n第二步：编译 (Compilation)这是整个编译过程中最核心的阶段，它将预处理后的 C 代码翻译成特定于目标平台的汇编代码。\n\n输入文件: 预处理后的文件，例如 hello.i\n输出文件: 汇编代码文件，通常以 .s 为后缀，例如 hello.s\nGCC 命令: gcc -S hello.i -o hello.s\n-S 选项告诉 GCC 在生成汇编代码后就停止。\n\n\n主要工作内容：\n词法分析: 将源代码分解成一个个独立的“记号”(tokens)，如关键字、标识符、操作符等。\n语法分析: 根据 C 语言的语法规则，将记号组织成一棵“语法树”，并检查是否存在语法错误（例如，括号不匹配、缺少分号等）。\n语义分析: 检查代码的语义是否正确（例如，类型是否匹配、变量是否已声明）。\n代码优化: 对生成的中间代码进行优化，以提高程序的运行速度和减小体积。\n生成汇编代码: 将优化后的代码转换成目标平台的汇编语言。\n\n\n\n这个阶段涉及复杂的分析和优化过程，通常是整个流程中消耗时间和系统资源最多的部分。\n第三步 ：汇编 (Assembly): 汇编阶段将人类可读的汇编代码转换成机器可以执行的二进制指令。\n\n输入文件: 汇编代码文件，例如 hello.s\n输出文件: 可重定位目标文件 (Relocatable Object File)，在 Linux/macOS 中通常以 .o 为后缀，在 Windows 中为 .obj，例如 hello.o。\nGCC 命令: gcc -c hello.s -o hello.o\n-c 选项告诉 GCC 在生成目标文件后就停止。\n由于汇编过程也包含了预处理和编译两个阶段，所以 -c 选项也会触发这两个阶段的执行, 也就是可以 gcc -c hello.c -o hello.o 来直接生成目标文件。\n\n\n主要工作内容：\n指令翻译: 将每一条汇编指令（如 mov, add, jmp）翻译成其对应的二进制机器码。\n生成目标文件: 将机器码以及符号表、重定位信息等打包成一个特定格式的目标文件（在 Linux 中通常是 ELF 格式）。此时，文件中的代码和数据地址都是相对的，而不是最终的绝对内存地址。\n\n\n\n第四步：链接 (Linking): 链接是创建可执行文件的最后一步。它将多个目标文件以及程序所需的库文件（如标准库）的二进制代码(.o 文件)组合在一起。\n\n输入文件: 一个或多个目标文件 (.o) 和所需的库文件。\n输出文件: 可执行文件，在 Linux/macOS 中默认为 a.out，也可以通过 -o 指定名称（如 hello）。\nGCC 命令: gcc hello.o -o hello\n不带 -E, -S, -c 等选项时，GCC 默认执行所有四个步骤，并最终进行链接。\n\n\n主要工作内容：\n合并段: 将所有输入目标文件中的相同类型的段（如代码段 .text、数据段 .data）合并到最终可执行文件中的一个大段中。\n符号解析与地址回填 (重定位):\n解析: 找到代码中引用的函数和变量（例如 printf 函数）在其他目标文件或库文件中的确切位置。\n回填: 在汇编阶段，函数调用和变量访问的地址是未知的。链接器会计算出它们在虚拟内存中的最终地址，并修改代码中的占位符，使其指向正确的内存地址。这个过程就是图片中提到的地址回填。\n\n\n\n\n\ngcc编译常用参数当头文件和源码不在一个目录下时，需要指定头文件的搜索路径\n\n-I 选项: 用于指定头文件的搜索路径。可以多次使用这个选项来添加多个路径。\n\n例如：gcc -I /path/to/headers -o hello hello.c\n这会告诉 GCC 在编译 hello.c 时，先去 /path/to/headers 目录下查找头文件。\n\n\n-c \t\t\t只做预处理，编译，汇编。得到二进制文件\n\n-g \t\t\t编译时添加调试文件，用于gdb调试\n\n-Wall \t\t显示所有警告信息\n\n-D  \t\t向程序中“动态”注册宏定义\n\n-l\t\t\t指定动态库库名\n\n-L\t\t\t指定动态库路径\n\n\n静态库和动态库静态库在文件中静态展开, 动态库在运行时才被加载到内存中前者在编译时就被链接到可执行文件中, 因此内存占用大, 但是速度快; 后者在运行时才被链接到可执行文件中, 因此内存占用小, 但是速度较慢\n静态库制作及使用静态库名字以lib开头，以.a结尾例如：libmylib.a\n静态库生成指令: ar rcs [lib名称.a] [用于生成库的.o文件]ar rcs libmylib.a file1.o file2.o制作静态库的步骤: \n\n编写静态库的源文件\n编译源文件生成.o文件(二进制指令), 例如: gcc -c add.c -o add.o\n使用ar命令将.o文件打包成静态库\n\n静态库的使用：gcc test.c libmylib.a -o a.out, 如果静态库和可执行文件不在同一个目录下, 则需要指定静态库的路径, 例如: gcc test.c ./lib/libmylib.a -o a.out\n还要注意的一点是, 静态库在引入使用时需要配套的头文件, 也就是代码最上方的#include因为头文件是给编译器看的, 编译器需要根据头文件中的函数声明和变量定义来进行编译; 而静态库中的.o文件是给链接器看的, 链接器需要根据.o文件中的符号表来进行链接; \n如果没有头文件: 编译器会因为找不到函数的声明而报错，提示“函数未定义”或“隐式声明”(undeclared/implicit function)，导致编译失败。编译器根本不知道这个函数的存在，也就无法生成正确的目标文件 (.o)。\n\n当你从第三方获取一个库时，通常会得到 .a (或 .lib) 文件和一系列的 .h 文件，这两部分都必须正确配置到你的项目中才能成功使用。\n\n动态库制作制作动态库的步骤\n\n   编译生成位置无关的.o文件gcc -c add.c -o add.o -fPIC使用这个参数过后，生成的函数就和位置无关，挂上@plt标识，等待动态绑定. 这里的-fPIC是Position Independent Code的缩写, 表示生成位置无关的代码, 可以被加载到任意内存地址执行.\n\n   使用 gcc -shared制作动态库gcc -shared -o [lib库名.so] [用于生成库的.o文件]\n\n   链接可执行程序, 同时指定所使用的动态库。gcc test.c -o a.out -l mymath -L ./lib -I /path/to/headers -Wl,-rpath,’$ORIGIN/lib’\n\n\n\n-l:指定库名 \n-L:指定库路径, 只在链接时使用, 运行时需要通过-Wl,-rpath,’$ORIGIN/lib’指定动态库的搜索路径\n-I:可能会需要指定头文件的搜索路径\n-Wl,-rpath,’指定动态库的搜索路径这里的ORIGIN表示可执行文件所在的目录\n加上-Wl,-rpath,’$ORIGIN/lib’在可执行文件中直接指定动态库的搜索路径.\n\n\n\n\n   运行可执行程序./a.out注意\n运行时, 动态库需要在系统的库搜索路径中, 如果不加-Wl,-rpath,’$ORIGIN/lib’, 则需要通过设置LD_LIBRARY_PATH环境变量来指定动态库的搜索路径. 或者移动自制的动态库到系统的库搜索路径中.\n\n\n\n静态库和动态库的函数地址解析","categories":["system","linux"],"tags":["system"]},{"title":"GDB","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/gdb/","content":"使用gdb之前，要求对文件进行编译时增加-g参数，加了这个参数过后生成的编译文件会大一些，这是因为增加了gdb调试内容\n基础指令：\n-g：使用该参数编译可以执行文件，得到调试表。\ngdb ./a.out: 开始调试\nlist/l： l 1  列出源码, 因为分页显示, 后续直接l即可\nb：\tb 20\t在20行位置设置断点。\nrun/r:\t运行程序\nn/next: 下一条指令（会越过函数）\ns/step: 单步执行下一条指令（会进入函数）\np/print：p i  查看变量的值。\ncontinue：继续执行断点后续指令, 跳转到下一个断点。\nfinish：结束当前函数调用。 \nquit：退出gdb当前调试。\n其他指令：\nrun：若报错段错误, 则不需要设置断点进入gdb后直接使用run查找段错误出现位置。\nset args： 如果main有命令行参数, 设置main函数命令行参数 （在 start、run 之前）\n\n也可以通过 run 字串1 字串2 …: 设置main函数命令行参数\n\ninfo b: 查看断点信息表\nb 20 if i = 5：\t设置条件断点。\nptype：查看变量类型。\nbt：列出当前程序正存活着的栈帧。\nframe： 根据栈帧编号，切换栈帧。\ndisplay：设置跟踪变量\nundisplay：取消设置跟踪变量。使用跟踪变量的编号。\nlayout: 用于切换 TUI（Text User Interface）模式下的窗口布局的工具，让你可以更直观地查看源代码、汇编代码和寄存器信息\n\nlayout src：显示源代码窗口。\nlayout asm：显示汇编代码窗口。\nlayout regs：显示寄存器窗口，通常与源代码或汇编一起显示。\nlayout split：同时显示源代码和汇编代码。\n\n","categories":["system","linux"],"tags":["system"]},{"title":"基本命令与认识Linux","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E4%B8%8E%E8%AE%A4%E8%AF%86Linux/","content":"Linux命令基础习惯date 显示系统当前时间, 本质是通过shell解释器调用 /bin/date.execat /etc/shells\t查看当前可使用的shellecho $SHELL\t查看当前使用的shell, echo是回声命令, 用于将参数输出到标准输出\n键盘快捷键:Ctrl+A\t将光标移动到行首Ctrl+E\t将光标移动到行尾Ctrl+L\t清屏Ctrl+U\t删除整行方向键\t 移动光标注意BACKSPACE删除的是光标前一个字符, 而DELETE删除的是光标后一个字符\n类Unix系统目录pwd\t查看当前所在目录, 同时当前目录也会显示在当前系统环境和$符号之间Linux系统目录常见项：\n\nbin：存放二进制可执行文件\nboot：存放开机启动程序\ndev：存放设备文件, 字符设备如键盘、块设备如磁盘(注意WSL没有, 它并不直接访问物理硬件设备)\nhome：存放普通用户\netc：用户信息和系统配置文件 passwd、group\nlib：库文件：libc.so.6\nroot：管理员宿主目录（家目录）\nusr：(unix software resource)用户资源管理目录, 可以是第三方软件\n\n目录和文件操作pwd 查看当前所在目录cd – 返回上一个目录cd ~\t返回用户家目录cd /\t返回根目录\n相对路径：\n\n.\t当前目录\n..\t上一级目录绝对路径: /\t根目录\n\nls\t列出当前文件夹下目录项(ls dirname显示dirname下目录项)ls -R\t递归列出所有子目录下的文件ls -Rl\t递归列出并展示详细信息ls -a\t显示所有文件, 包括隐藏文件ls -l\t显示目录项详细信息如上图所示, 详细信息依次代表文件权限, 硬链接计数, 所有者  所属组, 大小(单位字节), 时间, 文件名/文件夹名\n其中文件权限字符串如上述图所示共有十位, 如-rw-r–r–(序号1234567890), 其中:1代表文件类型, 如-代表普通文件, d代表目录234代表所有者读-写-执行权限, 如rw-代表所有者有读写权限, 无执行权限567代表同组用户读写执行权限890代表其他人读写执行权限\nLinux系统文件类型： 7种\n\n普通文件：-\n目录文件：d\n字符设备文件：c\n块设备文件：b \n软连接：l\n管道文件：p\n套接字：s\n\nwhich instruct 查看instruct命令所在系统 $PATH 环境变量中的位置mkdir dirname\t新建目录touch filename   创建名为filename的空文件rm filename  删除文件rm dirname -r  递归删除目录mv filename dirname  移动文件filename到dirname目录下mv dirname1 dirname2  移动目录dirname1到dirname2目录下cp filename dirname  复制文件到目录dirname下cp dirname1 dirname2  复制目录dirname1到dirname2目录下cp -r dirname1 dirname2  递归复制目录dirname1到dirname2目录下cp -a dirname1 dirname2  递归完全复制目录dirname1到dirname2目录下, 保留相同的文件属性, 包括时间, 权限, 软硬链接等\ncat filename 查看文件内容tac filename 逆转查看文件内容cat 读取终端，就是回显echovim filename  编辑文件filename(使用vim编辑器)\nmore filename 分页查看文件内容(空格翻页，回车一行, q退出)less filename 和上面more类似\nhead -n filename  查看文件前n行tail -n filename  查看文件后n行\ntree  查看当前目录结构树tree dirname  查看dirname目录结构树\n软链接和硬链接ln -s file file.s 创建一个软链接(软链接就像windows下的快捷方式, 在相同的目录下创建另一个可以访问到file的文件)\n\n如果是用相对路径创建软连接, 则软连接指向的是file文件的相对路径, 这意味着如果file文件移动了, 软连接就会失效\n如果是用绝对路径创建软连接, 则软连接指向的是file文件的绝对路径, 这意味着无论file文件移动到哪里, 软连接都不会失效\n\nln file file.h 创建一个硬链接(硬链接就像windows下的复制, 在相同的目录下创建另一个可以访问到file的文件)\n\n创建硬链接后，文件的硬链接计数+1\n硬链接特点是修改文件内容, 硬链接文件的内容也会改变, 因为它们指向的是同一个 inode\n删除一个硬链接时，文件的硬链接计数-1，当这个计数减为0时，才会删除这个文件\n\n文件名与 inode在 Linux 文件系统中，一个文件由两部分组成：\n文件名 (Filename)：我们用来识别和访问文件的名称。\ninode (索引节点)：一个存储文件元数据（metadata）的数据结构，包括文件大小、所有者、权限、创建时间以及最重要的——指向磁盘上存储文件真实数据的块的指针。\n可以这样理解：文件名是给人看的标签，而 inode 才是文件的“身份证”。一个文件名必定指向一个 inode，通过 inode 才能找到文件的实际内容。\n硬链接的本质是给一个已存在的 inode 分配一个新的文件名。换句话说，它创建了一个指向同一个 inode 的新指针。\n当你创建一个硬链接时，你并没有复制文件的内容，只是增加了一个引用该文件内容的方式。硬链接和源文件拥有完全相同的 inode 号\n而软链接（也叫符号链接）则完全不同。它是一个独立的新文件，拥有自己的 inode。这个文件的内容很特殊，它存储的是另一个文件或目录的路径。它就像 Windows 系统中的“快捷方式”。\n用户和用户组whoami 查看当前用户\nchmod 修改权限操作, 主要有两种方法:第一种，文字设定法chmod [who] [+|-|=] [mode] filename操作对象who可以是下述字母中的任一个或者它们的组合u \t\t表示”用户(user)”，即文件或目录的所有者g \t\t表示”同组(group)用户”，即与文件所有者有相同组ID的所有用户o\t\t表示”其他(others)用户”a\t\t表示”所有(all)用户”，它是系统默认值\n操作符号可以是：+\t添加某个权限-\t取消某个权限=\t赋予给定权限并取消其他所有权限（如果有的话）例如, chmod u+rwx filename  给文件filename的所有者添加读写执行权限\n第二种，数字设定法chmod 操作码 filename  (直接用操作码修改文件权限)\n例如, 对于file的权限-rw- rw- r– 421 421 421三个组的权限都用二进制编号，比如要设置当前用户对文件的读写和执行权限，则当前用户的操作权限为4（读）+ 2（写）+ 1（执行） = 7. 用户组和其他用户的权限设置也是一样的\n对于file的当前权限-rw-rw-r–, 我们设置如下：所有者 \t\trwx = 7所有者所在组\trw = 6其他用户\t\tr = 4操作码就是764, 即chmod 764 filename\nsudo adduser newusername 添加新用户sudo chown username filename 修改文件所有者su username 切换当前用户为usernamesudo addgroup groupname 添加新的用户组sudo chgrp groupname filename  修改文件所属用户组sudo chown username:groupname filename  同时修改文件所属用户和用户组sudo deluser username 删除用户sudo delgroup groupname 删除用户组\nsudo su 切换root用户sudo passwd username   设置用户密码\nfind 命令find命令：找文件, 表达式为find [path] [option] action\n\n-maxdepth 指定搜索深度。应作为第一个参数出现。\n例如, find ./ -maxdepth 1 -name “file.jpg”, 查找当前目录下的所有后缀为.jpg且文件名包含file的文件\n\n\n-type 按文件类型搜索  d/p/s/c/b/l/ f:普通文件\n例如, find / -type f  查找根目录下的所有普通文件\n\n\n-name 按文件名搜索\n例如, find / -name “*.jpg”  查找根目录下的所有后缀为.jpg的文件\n\n\n-size 按文件大小搜索, 单位：k、M、G\n例如, find /home/ziyipei -size +20M -size -50M\n这里要注意，两个size一个都不能少，还有就是文件大小单位对大小写敏感\n\n\n-user 按文件所有者搜索\n-group 按文件所属用户组搜索\n-perm 按文件权限搜索\n-mtime 按文件修改时间搜索, 指的是文件内容最后一次修改的时间(modification), 单位：天(-n 表示n天内修改的文件, +n 表示n天前修改的文件)\n例如, find /home/ziyipei -mtime -10  查找/home/ziyipei目录下最近10天内修改的文件\n\n\n-atime 按文件访问时间搜索, 指的是文件最后一次被访问的时间, 单位：天\n如果使用-amin则单位为分钟, -amin -10 表示最近10分钟内访问的文件\n\n\n-ctime 按文件状态改变时间搜索, 指的是文件元数据最后一次改变的时间(change), 单位：天\n-exec 将find搜索的结果集执行某一指定命令。\nfind /usr/ -name ‘tmp‘ -exec ls -ld {} ;\n这里的{}表示find搜索到的结果, ;表示命令结束, 一般修改的地方就是-exec和;之间的命令, 其余的不变\n\n\n-ok: 以交互式的方式 将find搜索的结果集执行某一指定命令\n\n-grep和xargsgrep命令：在文件中搜索指定的字符串, 默认是在当前目录下搜索, 也可以指定目录或者文件搜索\n\n-r 递归搜索\n-i 忽略大小写\n-n 显示匹配行的行号例如, grep -r ‘copy’ ./ -n, 递归查找当前目录下的所有文件中包含copy的行, 并显示行号grep -r ‘copy’ ./README.md -n, 查找README.md文件中包含copy的行, 并显示行号\n\nps监控后台进程工作情况，默认只显示当前可以和用户交互的进程ps aux, 显示所有进程的详细信息, 包括进程ID、用户、CPU占用率、内存占用率、启动时间、命令等(其中a表示所有进程, u表示用户, x表示显示所有进程)ps aux | grep ‘root’  将进程结果集通过管道传递给grep命令, 查找包含root的进程(注意使用grep搜索进程，有一条结果是搜索进程本身)\nxargs：用于将前一个命令的输出作为后一个命令的参数(不加-)可以和find结合, 将find搜索的结果集执行某一指定命令: find /usr/ -name ‘tmp‘ | xargs ls -ld , 这里的ls -l 表示对find搜索到的每个文件执行ls -l命令可以等价于find … -exec ls -l {} ;不同点在于当结果集合很大的时候，xargs会对结果进行分段处理, 所以性能好些. 但xargs也有缺陷，xargs默认用空格来分割结果集，当文件名有空格的时候，会因为文件名被切割失效所以当文件名中包含空格时，我们可以使用以下方法来避免这个问题：\n\n使用 -0 选项来使得xargs指定文件名的结束符为 null 字符\n使用 find 命令的 -print0 选项来输出 null 字符结尾的文件名\n例如, find /usr/ -name ‘tmp‘ -print0 | xargs -0 ls -l\n第一个-print0指定结果集分隔为null，第二个-0指定xargs分隔为null\n\n\n\n创建名字带空格的文件方法:第一个方法，文件名加引号第二个方法，转义空格为’\\ ‘\n软件包安装下面只介绍利用互联网安装软件包的方法, 使用安装包进行软件安装先略过sudo apt install softname 一般的安装软件, 也可以使用别的包管理工具, 如yum, dnf等sudo apt update 更新软件列表sudo apt remove softname 卸载软件\n压缩和打包压缩命令有两个: gzip和bzip2. 两者都需要配合tar打包命令使用, 而且这两个压缩的缺陷都是只能对单个文件进行压缩，一来不能压目录，二来不能打包\n第一种压缩方式：gziptar zcvf 要生成的压缩包名 压缩材料 (这里压缩包名一般以.tar.gz结尾)\n\n例如, tar zcvf test.tar.gz test.txt, 压缩test.txt文件, 生成test.tar.gz压缩包上述命令实际上执行了两步，一个是gzip进行压缩: gzip filename (解压是gunzip zipfilename)另一个是使用tar打包, 一般我们直接使用tar zcvf 来打包压缩, 不需要先压缩再打包\n\n所以tar zcvf 是两条指令的结合版本. 对zcvf进行解释：z:zip，压缩c:create，创建v:vision，显示压缩过程，可以去掉，直接用zcf，但这样不显示压缩过程f:file，文件\nfile filename 查看文件来源\n第二种压缩方式：bzip2tar jcvf 要生成的压缩包名 压缩材料 (这里压缩包名一般以.tar.bz2结尾)\n\n例如, tar jcvf test.tar.bz2 test.txt, 压缩test.txt文件, 生成test.tar.bz2压缩包上述命令实际上执行了两步，一个是bzip2进行压缩: bzip2 filename (解压是bunzip2 zipfilename)另一个是使用tar打包\n\n可以看出两者的区别只在于压缩命令不同, gzip用的是z, bzip2用的是j, 其余的包括生成文件的后缀也一样\n解压：将压缩命令中的c –&gt; xtar zxvf 压缩材料    使用gzip解压tar jxvf 压缩材料\t\t使用bzip2解压\n此外, 还可以通过Linux和Windows通用的rar和zip压缩, 但需要先安装: sudo apt install rar zip\nrar a -r newdir.rar dir, 压缩dir目录, 生成newdir.rar压缩包(a表示添加, -r表示递归压缩子目录)unrar x newdir.rar  解压rar文件zip -r newdir.zip dir, 压缩dir目录, 生成newdir.zip压缩包(-r表示递归压缩子目录)unzip newdir.zip  解压zip文件\nsudo aptitude show softname  查看软件安装信息\n其他命令env 查看环境变量env | grep ‘PATH’  和管道, grep结合查看环境变量中PATH的值jobs 查看操作系统当前运行了哪些用户作业kill  杀死进程, 例如 kill -9 1234, 这里的-9表示强制杀死进程, 1234表示进程ID\ntop 文字版任务管理器ifconfig 查看网卡信息man  系统参考手册man n name   在系统手册第n章查看name, 主要是以下几章:\n\n第一章是基本命令\n第二章是系统调用\n第三章是库函数\n第五章是文件格式和约定\n\nalias  给命令起别名, 例如 alias ll=’ls -l’, 这样就可以使用ll命令来代替ls -l\n","categories":["system","linux"],"tags":["system"]},{"title":"进程间通信","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/","content":"Linux操作系统支持的进程间通信（IPC）机制主要包括以下几种：\n","categories":["system","linux"],"tags":["system"]},{"title":"文件和系统调用","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E6%96%87%E4%BB%B6%E5%92%8C%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"系统调用简介和实现什么是系统调用(system call)系统调用，顾名思义，说的是操作系统提供给用户程序调用的一组特殊接口，用户程序可以通过这个特殊接口来获得操作系统内核提供的服务\n\n系统调用的实现系统调用是属于操作系统内核的一部分，必须以某种方式提供给进程让它们去调用，相应的操作系统也有不同的运行级别–用户态和内核态，内核态可以毫无限制的访问各种资源，而用户态下的用户进程的各种操作都有限制，显然, 属于内核的系统调用是运行在内核态下，那么如何切换到内核态呢？\n答案是软件中断(trap)，操作系统一般是通过软件中断从用户态切换到内核态\n系统调用和库函数的区别系统调用是操作系统内核提供的接口，用户程序通过这些接口来请求内核提供的服务，而库函数是编程语言提供的一组预定义函数，这些函数封装了一些常用的操作，简化了编程工作\n库函数主要由两类函数组成：\n\n不需要调用系统调用不需要切换到内核空间即可完成函数全部功能，如strcpy、bzero等字符串操作函数\n\n需要调用系统调用需要切换到内核空间，这类函数通过封装系统调用去实现相应的功能，如print、fread等\n\n\n错误处理函数errno 是一个在 C 语言及其派生语言（如 C++）的标准库中使用的全局变量或宏，用于存储操作系统或库函数在执行过程中遇到的最近一次错误代码(类型为int), 不同的错误码表示不同的含义。\n#include &lt;stdio.h&gt;#include &lt;errno.h&gt;  // 也可以#include &lt;cerrno&gt; (C++)void example_perror() {    FILE *fp;    fp = fopen(\"non_existent_file.txt\", \"r\");    if (fp == NULL) {        // 仅需传入一个自定义前缀字符串        perror(\"文件读取失败\");                // 预期输出可能类似于: 文件读取失败: No such file or directory    } else {        fclose(fp);    }}\n\n虚拟地址空间如图是一张 Linux 进程地址空间布局图, 核心划分是内核区与用户区:\n\n\n\n区域\n地址范围\n作用与特性\n\n\n\n内核区 (Kernel Space)\n3G 到 4G\n存放 Linux 内核的代码和数据。它是受保护的，用于运行内核程序，如内存管理、进程管理、设备驱动和 VFS（虚拟文件系统）。用户程序不能直接读写这块区域，否则会触发段错误。\n\n\n用户区 (User Space)\n0 到 3G\n存放用户程序的代码和数据。这是 int main(…) 函数及其代码、数据、堆栈等执行的地方。用户程序的大部分操作都在这个区域内进行。\n\n\n下面我们再介绍用户区内存段（ELF 文件加载区）:\n用户区从底部（低地址 0）向上依次排列着由 ELF（Executable and Linkable Format，可执行文件格式）文件加载而来的各个数据段：\n\n代码和数据段 (Code &amp; Data)这三个段通常是静态分配的，它们的大小在程序编译时就已经确定：\n\n\n.text (代码段)：存放程序的机器指令（二进制机器指令）。该区域是只读的，以防止程序意外修改自己的代码。\n\n图中标注：受保护的地址 (0∼4K)，这是为了捕获对空指针的解引用操作，防止低地址被使用。\n\n\n.rodata / .data (已初始化全局变量)：存放程序中已初始化的全局变量和静态变量。\n\n.bss (未初始化全局变量)：存放程序中未初始化的全局变量和静态变量。在程序加载时，这些变量会被清零处理。\n\n\n这几个段共同构成了程序的基本静态结构，其中代码段的只读保护是程序安全的重要保障。\n\n堆空间 (Heap): 用于程序的动态内存分配（如 C 语言中的 malloc 或 C++ 中的 new）。\n\n它从低地址向高地址（图中的向上箭头）增长，其大小在程序运行时动态变化。并且堆空间通常是用户区中最大的一块区域。\n\n共享库/动态库 (Shared Libraries/Dynamic Libraries): 存放程序运行时需要链接的共享库文件（如 libc.so - C 标准库）。\n\n多个进程可以共享同一份库的代码和数据，从而节省物理内存。共享库通过系统调用（如 execve）或动态加载器，将 C 标准库、Linux 系统 I/O 函数等加载到这里，供用户代码调用。\n\n而静态库的代码则直接链接到程序的代码段中, 存储在.text 段内。\n\n\n栈空间 (Stack): 用于存放函数调用时的局部变量、函数参数、返回地址等。\n\n它从高地址向低地址（图中的向下箭头）增长。栈空间相对较小，一旦耗尽会导致栈溢出（Stack Overflow）。\n\n堆和栈的对向增长（一个向上，一个向下）机制可以有效地利用中间的虚拟地址空间，并在它们相遇之前，为程序提供了最大的灵活性。\n\n\n命令行参数和环境变量: 位于用户区最高端，存放着程序启动时传递给 main 函数的参数（如 argc,argv[…]）和系统的环境变量（env）。\n\n文件描述符如图展示了 Linux 进程如何通过文件描述符 (File Descriptor, FD) 机制来管理和访问文件及 I/O 资源。\n文件描述符的本质是一个非负整数（通常是 0 到 1023 之间），它在进程的上下文中，是用来唯一标识一个打开的文件、套接字（socket） 或其他 I/O 资源(本质上它们都是文件)的索引。\n右图的文件描述符表存储在PCB中, PCB(process control block)是每个 Linux 进程都有的进程控制块，它位于内核区(Linux kernel)内, 包含了一个指向该进程文件描述符表的指针。\n\n\n\n文件描述符 (FD)\n名称\n对应 I/O 资源\n默认用途\n\n\n\n0\nSTDIN_FILENO\n标准输入\n默认为只读模式，通常指向键盘输入或文件重定向。\n\n\n1\nSTDOUT_FILENO\n标准输出\n默认为只写模式，通常指向终端显示或文件重定向。\n\n\n2\nSTDERR_FILENO\n标准错误\n默认为只写模式，用于输出程序的错误和诊断信息。\n\n\n3 及以上\n正常文件 I/O\n文件、套接字、管道等\n用于进程通过 open()、socket() 等系统调用打开的资源。\n\n\n如图所示, FD 0、FD 1、FD 2 是所有进程默认打开的三个标准流. 而当程序调用 open() 或 socket() 等系统调用(进入内核态)打开一个新的 I/O 资源时，内核会在PCB中查找该进程的文件描述符表。它会从 3 开始，寻找最小且当前未被占用的整数作为新的文件描述符分配给该资源。\n简而言之，用户进程不直接操作文件，而是操作文件描述符，由内核负责将这个数字与实际的 I/O 资源关联起来\n常用文件IO函数open函数#include &lt;sys/types.h&gt;#include &lt;sys.stat.h&gt;#include &lt;fcntl.h&gt;int open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);参数：    pathname：文件的路径及文件名    flags：打开文件的行为标识(只读、只写、可读可写)    mode：这个参数只有在文件不存在时有效,指新建文件时指定文件的权限(数字指定, 如 0644代表rw-r--r--)返回值：      成功：返回打开的文件描述符      失败：-1\n其中flags参数常用的取值有：必选项 (Access Modes)\n\n\n\n取值 (Flag)\n含义 (Meaning)\n\n\n\nO_RDONLY\n以只读的方式打开\n\n\nO_WRONLY\n以只写的方式打开\n\n\nO_RDWR\n以可读、可写的方式打开\n\n\n可选项 (Creation/Status Flags): 可以和必选项按位或（使用 | 运算符）起来使用。\n\n\n\n取值 (Flag)\n含义 (Meaning)\n\n\n\nO_CREAT\n文件不存在则创建文件，使用此选项时需使用 mode 说明文件的权限\n\n\nO_EXCL\n如果同时指定了 O_CREAT，且文件已经存在，则出错\n\n\nO_TRUNC\n如果文件存在，则清空文件内容\n\n\nO_APPEND\n写文件时，数据添加到文件末尾\n\n\nO_NONBLOCK\n对于设备文件，以 O_NONBLOCK 方式打开可以做非阻塞 I/O\n\n\n// 打开和关闭文件int main(void){    int fd = -1;    // 1. 以只读的方式打开一个文件，如果文件不存在就报错    fd = open(\"txt\", O_RDONLY);     // 2. 以只写的方式打开一个文件，如果文件存在就直接打开，如果文件不存在就新建一个文件    /fd = open(\"txt\", O_WRONLY | O_CREAT, 0644);     // 3. 以只写的方式打开一个文件，如果文件存在就报错，如果文件不存在就新建一个文件    fd = open(\"txt\", O_WRONLY | O_CREAT | O_EXCL, 0644);     // 4. 以读写的方式打开一个文件，如果文件存在就打开，如果文件不存在就新建一个文件    fd = open(\"txt\", O_RDWR | O_CREAT, 0644);     // 5. O_TRUNC 清空文件内容    // 如果文件不存在就新建一个文件，如果文件存在就打开之后清空    fd = open(\"txt\", O_WRONLY | O_TRUNC | O_CREAT, 0644);     // 6. O_APPEND 追加的方式    // 以只写和追加的方式打开一个文件，如果文件不存在会报错    fd = open(\"txt\", O_WRONLY | O_APPEND);     close(fd);    return 0;}\n\nclose函数#include &lt;unistd.h&gt;int close(int fd);功能：    关闭已打开的文件参数：    fd：文件描述符，open()的返回值返回值：    成功：0    失败：-1，并设置errno\n\nwrite函数#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);功能：    把指定数目的数据写到文件(fd), 注意 write() 函数会覆盖从当前文件偏移量开始的现有数据(与 lseek() 函数结合使用时尤为重要)。参数：    fd：文件描述符    buf：数据首地址    count：写入数据的长度(字节)返回值：    成功：实际写入数据的字节个数    失败：-1\n示例代码:\n// 写文件int main(void){    int fd = -1;    int ret = -1;  // write的返回值        char *str = \"hello itcast\";        // 1. 以只写的方式打开一个文件, 如果文件不存在就新建一个文件    fd = open(\"txt\", O_WRONLY | O_CREAT, 0644);    if (-1 == fd)    {        perror(\"open\");        return 1;    }        printf(\"fd = %d\\n\", fd);        // 2. 写文件    ret = write(fd, str, strlen(str));    if (-1 == ret)    {        perror(\"write\");        return 1;    }        printf(\"write len: %d\\n\", ret);        // 3. 关闭文件    close(fd);        return 0;}\n\nread函数#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);功能：    把指定数目的数据读到内存(缓冲区)参数：    fd：文件描述符    buf：内存首地址, 用于存储读取到的数据    count：读取的字节个数返回值：    成功：实际读取到的字节个数    失败：-1\n示例代码:\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;     // 包含 read, close 函数#include &lt;fcntl.h&gt;      // 包含 O_RDONLY, O_CREAT 等宏#include &lt;errno.h&gt;      // 包含 errno 定义#define BUF_SIZE 100    // 定义读取缓冲区的大小int main(void){    int fd = -1;    ssize_t ret = -1;       // 使用 ssize_t 类型存储 read/write 返回值    char buffer[BUF_SIZE] = {0}; // 用于存储读取到的数据，并初始化为 0    // 1. 以只读的方式打开一个文件    fd = open(\"data.txt\", O_RDONLY);     if (-1 == fd)    {        perror(\"open:\");        return 1; // 退出程序并返回错误码    }    printf(\"成功打开文件，文件描述符 (FD) 为: %d\\n\", fd);        // 2. 读取文件    // 从 fd 对应文件中读取最多 BUF_SIZE-1 个字节到 buffer 中    ret = read(fd, buffer, BUF_SIZE - 1); // 留出 1 字节用于添加字符串结束符 '\\0'    if (-1 == ret)    {        perror(\"read:\");        // read 失败后，必须关闭文件，否则会造成资源泄露。        close(fd);         return 1;    }        // 3. 处理读取结果        // 步骤说明：将读取到的字节数 ret 对应的位置设为字符串结束符 '\\0'，    // 以便将读取到的数据作为一个C字符串打印出来，确保打印的准确性。    buffer[ret] = '\\0';         printf(\"读取到的字节长度 (ret): %zd\\n\", ret);    printf(\"文件内容:\\n%s\\n\", buffer);        // 4. 关闭文件    close(fd);        return 0;}\n\nlseek函数#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;typedef long off_t;  // 32位系统中off_t是long类型, 64位系统中是long long类型, long是4字节, long long是8字节off_t lseek(int fd, off_t offset, int whence);功能:    改变文件的偏移量, 实现文件的随机访问(这很重要, lseek()本身不进行读写操作，它唯一的作用是修改内核记录的文件偏移量)参数:    fd: 文件描述符    offset: 根据 whence 来移动的位数(偏移量), 可以是正数, 也可以是负数,        如果正数, 则相对于 whence 往右移动, 如果是负数, 则相对于 whence 往左移动。    whence: 其取值如下:        SEEK_SET: 从文件开头移动 offset 个字节        SEEK_CUR: 从当前位置移动 offset 个字节        SEEK_END: 从文件末尾移动 offset 个字节返回值:    若 lseek 成功执行, 返回新的偏移量(绝对偏移量, 即从文件开头算起的字节数)    如果失败, 返回 -1\n\n如果 lseek() 将文件偏移量设置到当前文件末尾之后（例如文件长 10 字节，你 lseek 到 100），然后执行 write 操作，文件尺寸会增大到 101 字节。中间跳过的 90 个字节是未初始化的，通常被称为“文件空洞”（File Hole）。\n\n示例代码:\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;void lseek_example() {    int fd;    char buffer[20] = {0};    ssize_t ret;    // 我们假设已经有一个名为 sample.txt 的文件，内容为: 0123456789    fd = open(\"sample.txt\", O_RDWR);    if (fd == -1) {        perror(\"open sample.txt\");        return;    }        // 1. 使用 SEEK_SET     // 步骤说明：SEEK_SET 表示从文件起始位置 (0) 开始计算偏移量。    off_t new_offset = lseek(fd, 4, SEEK_SET);    if (new_offset == -1) {        perror(\"lseek SEEK_SET failed\");    } else {        printf(\"1. SEEK_SET: 成功将偏移量设置为: %ld\\n\", new_offset); // 输出 4            // 从当前位置 (4) 读取 3 个字节        ret = read(fd, buffer, 3);         buffer[ret] = '\\0';        printf(\"   读取内容: %s (从 '4' 开始读 3 个)\\n\", buffer); // 输出 456    }    // 此时文件偏移量位于 4 + 3 = 7 处        // 2. 使用 SEEK_CUR    // 步骤说明：SEEK_CUR 表示从当前偏移量 (7) 开始计算偏移量。    new_offset = lseek(fd, 2, SEEK_CUR);    if (new_offset == -1) {        perror(\"lseek SEEK_CUR failed\");    } else {        printf(\"2. SEEK_CUR: 成功将偏移量移动到: %ld\\n\", new_offset); // lseek 成功后，它返回的是新的绝对偏移量, 因此输出 9            // 从当前位置 (9) 写入数据 'A'        ret = write(fd, \"A\", 1);         printf(\"  写入内容: A\\n\"); // sample.txt 变为 012345678A    }    // 此时文件偏移量位于 9 + 1 = 10 处    // 3. 使用 SEEK_END    // 步骤说明：SEEK_END 表示从文件末尾开始计算偏移量。    new_offset = lseek(fd, 0, SEEK_END);  // 0 表示不移动，即只是定位到文件末尾。    if (new_offset == -1) {        perror(\"lseek SEEK_END failed\");    } else {        printf(\"3. SEEK_END: 成功将偏移量移动到文件末尾: %ld\\n\", new_offset); // 输出 10            // 从文件末尾写入数据 'Z'，这将增大文件尺寸        ret = write(fd, \"Z\", 1);        printf(\"在文件末尾追加内容: Z\\n\"); // sample.txt 变为012345678AZ    }    // 此时文件偏移量位于 10 + 1 = 11 处    close(fd);    printf(\"--- 文件操作完成 ---\\n\");    // 实际文件内容现在为 012345678AZ}\n\n文件描述符复制在 Linux/Unix 系统编程中，dup() 和 dup2() 是两个重要的系统调用，用于复制（或称为重定向）文件描述符。\ndup函数#include &lt;unistd.h&gt;int dup(int oldfd);功能:    用于根据旧的文件描述符复制出一个新的文件描述符, 原始的文件描述符 oldfd 和新的文件描述符都将指向同一个文件参数:    oldfd: 需要复制的文件描述符返回值:    成功: 返回新的文件描述符    失败: -1\nint main(void){     int fd = -1;    int newfd = -1;    // 1. 打开文件    fd = open(\"txt\", O_RDWR | O_CREAT, 0644);    if (-1 == fd)    {         perror(\"open\");         return 1;     }     printf(\"fd = %d\\n\", fd);     // 文件描述符复制     newfd = dup(fd);     if (-1 == newfd)     {         perror(\"dup\");        return 1;     }     printf(\"newfd = %d\\n\", newfd);     // 2. 操作     write(fd, \"ABCDEFG\", 7);     write(newfd, \"1234567\", 7);     // 3. 关闭文件描述符     close(fd);     close(newfd);     return 0;}\n由于 newfd 和 fd 指向同一个文件, 共享同一文件偏移量，因此这次写入操作将从上一次写入结束的位置开始。也就是说，1234567 会紧接着 ABCDEFG 写入文件，文件内容最终是 ABCDEFG1234567\ndup2函数#include &lt;unistd.h&gt;int dup2(int oldfd, int newfd);功能:    将 oldfd 复制到 newfd, 并且newfd 的值可以人为指定. 如果 newfd 已经被打开, 则先调用 close() 关闭此描述符，断开它与原文件的关联，然后再使用这个合法的数字作为新的文件描述符。参数:    oldfd: 需要复制的文件描述符    newfd: 目标文件描述符, 这个描述符的值可以指定。返回值:    成功: 返回新的文件描述符    失败: -1\n\ndup2() 最常见的用途是将标准 I/O 流（FD 0、1、2）重定向到文件。\nint file_fd = open(\"output.log\", O_WRONLY | O_CREAT | O_TRUNC, 0644); if (file_fd == -1) { /* 错误处理 */ }// 步骤说明：使用 dup2 将 标准输出 (FD 1) 替换为 file_fd 指向的文件。// 1. 如果 FD 1 已经打开（通常是终端），dup2 会先关闭它, 意味着无法通过FD 1 连接到终端。// 2. 然后，它使 FD 1 指向和 file_fd 相同的资源。dup2(file_fd, 1); // 现在，所有原本写入标准输出 (原先的FD 1) 的数据，都会被写入 output.log 文件中。printf(\"这条信息现在写入了 output.log 文件中。\\n\"); close(file_fd); // 关闭原始的文件描述符，但 FD 1 作为新的log文件描述符仍然有效\nfcntl函数#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* arg */);功能:    改变已打开的文件的性质，fcntl 针对文件描述符提供控制功能参数:    fd: 文件描述符    cmd: 控制命令        F_DUPFD: 复制文件描述符，类似于 dup()        F_GETFD: 获取文件描述符标志        F_SETFD: 设置文件描述符标志        F_GETFL: 获取文件状态标志和访问模式        F_SETFL: 设置文件状态标志返回值:    成功: 返回值取决于具体的 cmd    失败: -1\n\n目录相关操作","categories":["system","linux"],"tags":["system"]},{"title":"进程","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E8%BF%9B%E7%A8%8B/","content":"进程和程序 (Process and Program)程序(Program)是一组指令的集合，通常存储在磁盘等静态存储介质上。它本身是静态的、被动的，不占用系统的运行资源（如CPU时间、内存等）。\n进程(Process)是程序的一次执行实例。当程序被加载到内存中并开始执行时，就创建了一个进程。它是动态的、活动的，是操作系统资源分配（如内存、文件句柄）和CPU调度的基本单位(更精确的说法是将线程视为独立调度单位)。\n进程的状态 (Process States)在三态模型中，进程状态分为三个基本状态，即：运行态、就绪态、阻塞态；在五态模型中，进程状态分为五个基本状态，即：新建态、终止态、运行态、就绪态、阻塞态；\nps 命令ps (Process Status) 命令用于显示当前系统的进程快照，即执行命令那一刻的进程信息。通常使用ps aux来显示所有用户的(a)、包含完整格式的、包括无终端进程(x)在内的所有进程的详细状态(u)。\ntop 命令top 命令用于动态显示系统中各个进程的资源占用情况，默认每隔几秒刷新一次。它提供了一个实时的视图，可以看到 CPU 和内存的使用情况，以及各个进程的状态。\nkill 命令kill 命令用于向进程发送终止进程的信号（Signal）, 常见的流程为:\n\n使用 ps 或 top 找到目标进程的ID（PID）。\n执行 kill 。\n如果进程没有响应，可以执行 kill -9  强制终止。\n\n进程号和相关函数 (Process IDs and Related Functions)在操作系统内部，每个进程都有唯一的标识符和关联信息。在编程中，我们可以通过特定的函数来获取这些信息。\n\n进程ID (PID)：每个进程都有一个唯一的非负整数标识符。\n父进程ID (PPID)：标识创建当前进程的那个进程。所有进程（除了初始的 init 进程）都是由其他进程创建的。\n进程组ID (PGID)：进程组是一个或多个进程的集合。通常，同一个作业（Job）中的所有进程属于同一个进程组。\n\n在C语言等编程环境中，可以通过以下标准函数获取这些ID：\ngetpid(): 获取当前进程的ID。\n原型：pid_t getpid(void);\n说明：该函数不接受参数，并返回调用它的进程的PID。pid_t 通常是一个整数类型。\ngetppid(): 获取当前进程的父进程的ID。\n原型：pid_t getppid(void);\n说明：返回创建当前进程的那个父进程的PID。\ngetpgid(): 获取指定进程的进程组ID。\n原型：pid_t getpgid(pid_t pid);\n说明：如果参数 pid 为0，则返回当前进程的进程组ID。否则，返回PID为 pid 的进程的进程组ID。\n进程的创建 (Process Creation)在 Linux/Unix-like 操作系统中，创建一个新进程的主要方式是通过 fork() 系统调用。\nfork() 的工作机制非常独特：它会创建一个与调用它的进程（称为父进程）几乎一模一样的新进程（称为子进程）。这个子进程是父进程的一个副本，它从 fork() 调用返回之后开始执行。\n#include &lt;unistd.h&gt;pid_t fork(void);功能:    从一个已存在的进程中创建一个新进程(子进程), 该子进程是调用进程(父进程)的一个副本参数:     无返回值:    成功时, 在父进程中返回子进程的 PID, 在子进程中返回 0    失败时, 返回 -1, 并设置 errno\n#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int main(void){    //创建子进程    fork();    printf(\"hello world\\n\");    return 0;}\n上述代码编译执行后会输出两次 “hello world”，原因在于当父进程调用 fork() 时，操作系统会创建一个几乎与父进程完全相同的子进程, 这两个进程（父进程和子进程）在创建完毕后都会从 fork() 调用处返回, 继续执行 fork() 下一行的后续代码，因此 printf(“hello world\\n”); 这行代码会被父子进程执行两次。\n循环创建进程 (Creating Processes in a Loop)当 fork() 被放置在循环中时, 会创建多个子进程, 每个子进程又会继续执行循环体内的代码, 这可能会导致指数级增长的进程数量。\nfor (int i = 0; i &lt; 3; i++) {    fork();    // ...}\n如上, 原始进程 P0 调用 fork()，创建子进程 C1。现在有两个进程：P0 和 C1, 在第2次循环 (i=1)中P0 和 C1 都会 继续执行循环产生共计四个进程, 接着又会产生更多进程……\n也就是说, 在循环中直接调用 fork() 会导致进程数量呈指数级增长。如果不加控制，这种代码会迅速耗尽系统资源，形成所谓的“fork 炸弹”（Fork Bomb），可能导致系统崩溃。因此，在实际应用中，通常会结合 if 判断 fork() 的返回值，确保只有父进程（或特定进程）继续创建新的子进程。\nfor (int i = 0; i &lt; 3; i++) {    pid_t pid = fork();    if (pid &gt; 0) {        // 父进程继续创建子进程        continue;    } else if (pid == 0) {        // 子进程跳出循环，避免继续创建子进程        break;    } else {        // 处理 fork() 失败的情况        perror(\"fork failed\");        exit(1);    }}\n\n父子进程关系 (Parent-Child Process Relationship)通过 fork() 创建的进程之间形成了明确的父子关系，这种关系是进程管理的基础。子进程在创建时会继承父进程的大部分资源和属性，包括：\n\n进程地址空间的副本（下文详述）。\n打开的文件描述符（File Descriptors）(因此也共享文件偏移量)。\n环境变量。\n当前工作目录。\n用户ID (UID) 和组ID (GID)。\n\n另一方面, 虽然子进程是父进程的副本，但它们是两个独立的进程，拥有自己独特的属性：\n\n进程ID (PID)：子进程有自己唯一的 PID。\n父进程ID (PPID)：子进程的 PPID 是其父进程的 PID。\n资源统计：CPU时间、内存使用等资源消耗是独立计算的。\n\n父进程的责任：父进程通常需要负责“回收”子进程的资源。当子进程结束后，它会变成一个僵尸进程 (Zombie Process)，直到父进程通过 wait() 或 waitpid() 系统调用获取其退出状态后，子进程才会彻底消失。如果父进程不执行此操作，僵尸进程会一直占用系统资源。\n父子进程地址空间 (Parent-Child Address Space)进程地址空间是指进程可以访问的内存区域，包括代码段、数据段、堆和栈。父子进程的地址空间遵循以下几个原则：\n独立性原则：fork() 之后，父进程和子进程拥有各自独立的地址空间。任何一方对其地址空间中的数据（如变量）进行修改，都不会影响到另一方。\n读时共享, 写时复制 (Copy-on-Write, COW): 虽然逻辑上地址空间是独立的，但操作系统为了提高效率，并不会在 fork() 时立即完整地复制父进程的所有物理内存页给子进程。\n相反, 当 fork() 创建子进程时，子进程的虚拟地址空间与父进程相同，并且它们共享相同的物理内存页。这些内存页被内核标记为“只读”。\n当父进程或子进程尝试写入某个共享的内存页时，会触发一个缺页异常 (Page Fault)。内核捕获到这个异常，此时才会为写入方复制一份该内存页的副本，并将该副本映射到其地址空间，然后执行写入操作。\n这些原则使得 fork() 的创建速度非常快，因为它避免了大量不必要的内存复制; 同时还兼具智能性：如果子进程创建后立即调用 exec() 系列函数来执行一个新程序（这是一种非常常见的模式），那么之前的地址空间会被完全替换。COW 机制避免了在这种情况下进行无用的内存复制，极大地提升了系统性能。\nCOW机制的示例// 父子进程地址空间int main(void){    int var = 88;    pid_t pid = -1;    // 创建一个子进程    pid = fork();    if (-1 == pid)    {        perror(\"fork\");        return 1;    }    if (0 == pid)    {        // 子进程        sleep(1);        printf(\"子进程睡醒之后 var = %d\\n\", var); //88    }    else    {        // 父进程        printf(\"父进程之前 var = %d\\n\", var); //88        var++;        printf(\"父进程之后 var = %d\\n\", var); //89    }    return 0;}\n可以看到, 在 fork() 之前，父子进程共享变量 var 的内存页; 父进程执行 var++; 将其私有 var 从 88 改为 89。此时，COW 触发，内核为父进程分配了一个新的内存页来存放父进程的 var=89, 而子进程的 var 仍然指向原来的内存页，值仍为 88。父子进程各自拥有独立的 var 变量，互不影响。\n进程的终止 (Process Termination)进程终止是指一个进程完成其任务并退出运行的过程。进程可以通过多种方式终止，包括正常退出和异常终止。\n进程的正常退出通常是通过调用 exit() 函数或者 _exit() 函数来实现的。\n#include &lt;stdlib.h&gt;void exit(int status);#include &lt;unistd.h&gt;void _exit(int status);功能:    终止调用进程, 并将状态码 status 返回给父进程参数:    status: 进程的退出状态码, 一般传入0表示正常退出\n这两者的主要区别在于，exit() 是一个C 标准库 libc 中的库函数, 会执行标准I/O缓冲区的清理工作（如刷新缓冲区、关闭文件等），而 _exit() 是一个系统调用，由内核直接处理, 直接终止进程，不进行任何清理操作。\n因此, exit()主要用于进程的正常退出, 清理资源; 而 _exit() 通常用于在子进程中调用，以确保子进程终止时不会影响父进程的资源状态。\n等待子进程退出的函数当一个子进程结束其生命周期时，它的父进程有责任去“回收”它。这个回收过程主要有两个目的：\n获取子进程的退出状态：父进程可以了解到子进程是正常结束的，还是因为某个错误或信号而异常终止的，以及它的返回值是什么。\n清理子进程的资源：通过执行等待函数，父进程通知内核它已经知晓子进程的状态，内核此时可以彻底释放子进程在进程表中占用的条目和其他资源。\n如果父进程不执行这个回收操作，那么已经终止的子进程将变成一个僵尸进程，持续占用系统资源。因此，使用 wait() 或 waitpid() 函数是健壮的并发程序设计中必不可少的一环。\nwait() 函数wait 函数是的最基本的方法\n#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;pid_t wait(int *wstatus);功能:    阻塞父进程(调用进程), 直到其任意一个子进程终止参数:    wstatus: 一个指向int类型的指针, 是传出参数, 用于存储子进程的退出状态信息. 如果不关心子进程的退出状态, 可以传入 NULL. 我们可以使用一组宏来解析这个状态值：        WIFEXITED(wstatus)：如果子进程是正常退出的，则返回真。        WEXITSTATUS(wstatus)：如果 WIFEXITED 为真，这个宏会返回子进程的退出码（即 main 函数的 return 值或 exit() 的参数）。        WIFSIGNALED(wstatus)：如果子进程是因信号而异常终止的，则返回真。        WTERMSIG(wstatus)：如果 WIFSIGNALED 为真，这个宏会返回导致子进程终止的信号编号。返回值:    成功时, 返回终止的子进程的 PID    失败时, 返回 -1, 并设置 errno\n\nwaitpid() 函数waitpid 函数是 wait 函数的一个更强大、更灵活的版本。它可以等待指定的子进程，并且可以选择非阻塞的方式进行等待。\n#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;pid_t waitpid(pid_t pid, int *wstatus, int options);功能:    等待指定的子进程终止, 或者在非阻塞模式下检查子进程的状态参数:    pid: 指定要等待的子进程的 PID。它有几种特殊的取值:        pid &gt; 0: 等待 PID 等于 pid 的子进程。        pid == 0: 等待与调用进程在同一进程组中的任意子进程。        pid &lt; -1: 等待进程组 ID 等于 -pid 的任意子进程。        pid == -1: 等同于 wait()，等待任意子进程。    wstatus: 一个指向 int 类型的指针, 用于存储子进程的退出状态信息. 如果不关心子进程的退出状态, 可以传入 NULL.    options: 控制 waitpid 行为的选项, 常用的选项包括:        WNOHANG: 非阻塞模式, 如果当前没有子进程终止, 则立即返回0, 而不是阻塞等待.        WUNTRACED: 如果子进程被停止(如接收到 SIGSTOP 信号), 也会返回其状态.返回值:    成功时, 返回终止的子进程的 PID. 如果使用 WNOHANG 选项且没有子进程终止, 则返回 0    失败时, 返回 -1, 并设置 errno\n\n僵尸进程 &amp; 孤儿进程 (Zombie Process &amp; Orphan Process)这两个概念是理解进程生命周期管理的关键。\n僵尸进程 (Zombie Process)\n\n定义：一个已经执行完毕、终止运行，但其父进程尚未通过 wait() 或 waitpid() 回收它的进程。\n\n产生原因：子进程先于父进程结束, 子进程结束后，其在内核进程表中的条目（包含PID、退出状态等信息）需要被保留，直到父进程读取这些信息。\n\n状态：在 ps 或 top 命令中，状态通常显示为 Z (Zombie)。\n\n危害：僵尸进程本身不占用CPU或内存，但它会占用进程表中的一个位置(PID)。如果系统中存在大量僵尸进程，可能会耗尽可用的PID资源，导致无法创建新进程。\n\n解决方法：父进程必须调用 wait 或 waitpid 来回收子进程。如果父进程异常退出，其子僵尸进程会被 init 进程（PID为1）接管并自动回收。\n\n\n孤儿进程 (Orphan Process)\n\n定义：一个父进程已经终止，但它自身还在运行的子进程。\n\n产生原因：父进程先于子进程结束。\n\n生命周期：当一个进程变成孤儿进程后，为了确保它最终能被回收，操作系统会将其过继给 init 进程(在现代系统中可能是 systemd)，其PPID变为1。\n\n“领养”过程：init 进程会自动成为所有孤儿进程的新的父进程。init 进程有一个循环，会定期调用 wait 来回收它所有已终止的子进程（包括它领养的这些孤儿进程）。\n\n结论：孤儿进程不会对系统造成危害，因为它们会被 init 进程妥善管理和回收，不会变成僵尸进程。\n\n\n进程替换 (Process Replacement)在 Unix/Linux 系统中，进程替换是指一个进程通过调用进程替换函数来加载并执行一个新的程序，从而替换掉当前进程的地址空间、代码和数据, 同时保留其原有的进程ID和其他系统资源（如文件描述符、信号处理程序等），从而实现了进程的动态更新。\n常用的进程替换函数是 exec 函数族. 在替换后, 以下几个关键点需要注意:\n\n进程 ID 不变： 这是 exec 与 fork 的最大区别。fork 创建一个新进程，exec 是在当前进程上加载新程序。\n地址空间替换： 当前进程的整个用户区地址空间（包括 .text、.data、堆、栈等）都会被新的程序代码和数据覆盖和替换。\n成功不返回： 如果 exec 函数调用成功，新的程序将从其自己的 main() 函数开始执行，exec 函数永远不会返回。只有在 exec 调用失败时，它才会返回 −1。\n文件描述符保留： 默认情况下，所有打开的文件描述符（包括标准输入 FD 0、标准输出 FD 1 等）都会被新程序继承。\n\nexec 族函数有六个主要成员（execl、execlp、execle、execv、execvp、execvpe），它们的区别主要在于如何传递参数和如何查找程序：\n\n\n\n函数名\n参数传递方式\n环境变量传递\n程序查找方式\n\n\n\nexecl\n可变参数列表(l)\n使用当前环境变量\n需要提供完整路径\n\n\nexeclp\n可变参数列表(l)\n使用当前环境变量\n使用 PATH 环境变量查找程序(p)\n\n\nexecle\n可变参数列表(l)\n需要提供环境变量(e)\n需要提供完整路径\n\n\nexecv\n参数数组(v)\n使用当前环境变量\n需要提供完整路径\n\n\nexecvp\n参数数组(v)\n使用当前环境变量\n使用 PATH 环境变量查找程序(p)\n\n\nexecvpe\n参数数组(v)\n需要提供环境变量(e)\n使用 PATH 环境变量查找程序(p)\n\n\nexeclp() 函数该函数通常用来调用系统的可执行程序，如：cat、ls、date\n#include &lt;unistd.h&gt;int execlp(const  char *file，const  char *arg，...)功能:    用于在当前进程中执行一个新的程序, 替换当前进程的地址空间参数:    file: 要执行的程序的文件名, 如果不包含路径, 则会在 PATH 环境变量指定的目录中查找    arg: 可变参数列表, 代表传递给新程序的参数. 第一个参数是程序的名称, 后面的参数是传递给程序的命令行参数. 最后一个参数必须是 NULL, 以标识参数列表的结束.返回值:    成功时, 不返回, 因为当前进程的地址空间被新程序替换    失败时, 返回 -1, 并设置 errno\n#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;int main(void){    pid_t pid = fork();    if(pid &lt; 0)    {        //fork失败        perror(\"fork\");        exit(1);    }    else if(pid == 0)    {        //子进程        execlp(\"ls\",\"ls\",\"-l\",\"-h\",NULL); // 第一个是新进程的文件名, 第二个是传递给新进程的argv[0], 后面是参数列表, 最后一个必须是NULL        // 因为执行ls时第一个参数也是ls, 所以这里共传递两个\"ls\"        perror(\"execlp error\");  //如果execlp成功，下面的不执行        exit(1);    }    else if(pid &gt; 0)    {    //父进程    sleep(1);    printf(\"我是父进程:%d\\n\",getpid());    wait(NULL); //等待子进程退出    }    return 0;}\n需要注意的是, exec 函数族中的任何一个函数（如 execlp, execl 等）执行成功，它将永远不会返回到调用它的原函数或原程序。 \n这是因为 exec 的本质是进程替换（Process Replacement），而不是函数调用或程序跳转。一旦 exec 函数成功后，当前进程的地址空间已经被新程序完全替换，这个进程的PC地址被设置为新进程的的 main() 函数。因此，任何在 exec 调用之后的代码都不会被执行，除非 exec 调用失败。\n不过, 原先的父进程通常仍然需要 wait（或 waitpid） 来等待子进程结束并回收资源。因为父子关系仍然存在，新程序执行完毕后，它也会调用 exit() 或 return，导致子进程终止, 进而影响父进程。\nexecl() 函数#include &lt;unistd.h&gt;int execl(const char *path, const char *arg, ...);功能:    用于在当前进程中执行一个新的程序, 替换当前进程的地址空间参数:    path: 要执行的程序的完整路径, 通常用来执行自己当前目录下的可执行文件    arg: 可变参数列表, 代表传递给新程序的参数. 第一个参数是程序的名称, 后面的参数是传递给程序的命令行参数. 最后一个参数必须是 NULL, 以标识参数列表的结束.返回值:    成功时, 不返回, 因为当前进程的地址空间被新程序替换    失败时, 返回 -1, 并设置 errno\n#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;int main(void){    pid_t pid = fork();    if(pid &lt; 0)    {        //fork失败        perror(\"fork\");        exit(1);    }    else if(pid == 0)    {        //子进程        execl(\"./wait\",\"wait\",NULL);        perror(\"execlp error\");  //如果execl成功，下面的不执行        exit(1);    }    else if(pid &gt; 0)    {        //父进程        sleep(1);        printf(\"我是父进程:%d\\n\",getpid());        wait(NULL); //等待子进程退出    }    return 0;}\n\nfork 和 exec 的协作在 Linux 中，启动一个新的程序(例如在 Shell 中调用 ls.exe)通常是一个两步过程，它们必须配合使用：\n\nfork()： 父进程(这里的shell)调用 fork，创建一个子进程。\nexec()： 子进程调用 exec 族函数，将自己替换成新的程序(如 ls)。\n父进程等待： 父进程通常会调用 wait() 等待子进程执行完毕并退出。\n\n这种 fork + exec 模式是 Linux/Unix 操作系统构建命令行环境和启动新应用的基石。\n","categories":["system","linux"],"tags":["system"]},{"title":"vector","url":"/2025/09/23/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/vector/","content":"std::vector 是 C++ 标准模板库 (STL) 中最常用的序列容器之一。它提供了动态数组的功能，允许在运行时动态调整大小，并且支持高效的随机访问。\n#include &lt;vector&gt;std::vector&lt;T&gt; vector_name;\n\nT: 存储的元素类型。\n\n常用接口添加元素std::vector 有两个向末尾添加元素的方法：push_back 和 emplace_back。\n\npush_back(T&amp;&amp; value)：接受一个已经构造好的对象，然后将其拷贝或移动到容器的末尾。\nemplace_back(Args&amp;&amp;… args)：接受构造对象所需的参数，然后在容器的末尾直接构造这个对象。它避免了创建临时对象再进行拷贝或移动的开销，效率更高。\n\n删除元素在 C++ 中，vector 的 erase 函数用于删除元素，它有两种主要的参数形式, 都是传递迭代器类型参数\niterator erase(iterator position);iterator erase(iterator first, iterator last);\n第一种: 删除 position 所指向的单个元素, 返回一个迭代器，指向被删除元素之后的下一个元素。第二种: 删除从 first 到 last（不包括 last）之间的所有元素, 返回一个迭代器，指向被删除区域之后的第一个元素。\n需要十分注意的点: \n\n删除成功后容器的迭代器失效, 不过erase()的返回值会返回指向下一个元素的迭代器, 这在for循环中必须额外处理, 使得只有在删除失败时才it++\n删除操作会导致后续元素前移，容器大小(size)减小，但容量(capacity)不变。\n\n另外, erase()函数不接受反向迭代器作为参数, 只能传递正向迭代器. 为了传递反向迭代器, 需要使用 base() 方法将其转换为正向迭代器, 但要注意转换后的迭代器指向的是反向迭代器所指元素的下一个位置。\nstd::vector&lt;int&gt; v = {1, 2, 3, 4, 5};auto rit = v.rbegin() ; // 指向元素 5v.erase(rit.base() - 1); // 删除元素 5// rit 现在无效，需要重新获取rit = v.rbegin(); // 现在指向新的最后一个元素 4\nrit.base() 返回的是当前反向迭代器指向元素的下一个位置(正向来看)，所以你需要减去 1 才能正确删除 rit 所指的元素。\n同时, 由于 erase() 返回的是正向迭代器, 如果需要继续使用反向迭代器, 只能重新获取反向迭代器而不能直接重新赋值.\n正向迭代器标准处理流程for (auto it = lst.begin(); it != lst.end();) {        if (*it % 2 == 0) {            it = lst.erase(it);  // 删除后，it指向下一个元素        } else {            ++it;                // 未删除时手动递增        }    }\n\n查找元素在 C++ 中，vector 本身并没有内建的查找函数，但我们可以使用 STL 提供的算法来实现查找功能\nstd::find: 查找等于某个值的元素，返回找到的元素的迭代器(成功)或末尾迭代器(失败), 输入参数是迭代器(查找范围)的始末位置和要查找的值。\nauto it = std::find(v.begin(), v.end(), target);if (it != v.end()) { /* 找到了 */ }\n\nstd::binary_search: 用于已排序的 vector，判断某个值是否存在, 但只能返回bool值代表是否存在而不能定位。\nstd::sort(v.begin(), v.end());bool found = std::binary_search(v.begin(), v.end(), target);\n迭代器遍历反向迭代器: 指的是从容器的末尾向前遍历元素的迭代器。C++ STL 提供了 rbegin() 和 rend() 成员函数来获取反向迭代器, 它们分别指向容器的最后一个元素和第一个元素之前的位置。\nfor (auto rit = v.rbegin(); rit != v.rend(); ++rit) {    std::cout &lt;&lt; *rit &lt;&lt; \" \";}\n\n底层实现std::vector 底层通常是通过一个动态分配的数组来实现的。它维护了三个关键属性：\n\n_start: 指向数组的起始位置。\n_finish: 指向当前最后一个元素的下一个位置。\n_end_of_storage: 指向分配的内存的末尾。\n\n下面是一个简化版的 std::vector 实现示例，展示了其核心机制：\n#include &lt;cstddef&gt;   // for size_t#include &lt;memory&gt;    // for std::allocator, std::uninitialized_copy, etc. (高级实现)#include &lt;utility&gt;   // for std::move#include &lt;stdexcept&gt; // for std::out_of_range#include &lt;iostream&gt;  // for debugging outputtemplate &lt;typename T&gt;class MyVector {public:    // --- 1. 构造函数, 析构函数, 和赋值运算符 (Rule of Five) ---    // 默认构造函数    MyVector() noexcept : _start(nullptr), _finish(nullptr), _end_of_storage(nullptr) {        std::cout &lt;&lt; \"[Default Constructor]\\n\";    }    // 拷贝构造函数    MyVector(const MyVector&amp; other) {        std::cout &lt;&lt; \"[Copy Constructor]\\n\";        // 分配足够大的新空间        _start = new T[other.size()];        // 逐个拷贝元素        std::uninitialized_copy(other._start, other._finish, _start);        _finish = _start + other.size();        _end_of_storage = _finish; // 容量等于大小    }    // 移动构造函数    MyVector(MyVector&amp;&amp; other) noexcept        : _start(other._start), _finish(other._finish), _end_of_storage(other._end_of_storage) {        std::cout &lt;&lt; \"[Move Constructor]\\n\";        // “窃取”资源后，将源对象置为空状态，防止其析构函数释放我们刚窃取的内存        other._start = other._finish = other._end_of_storage = nullptr;    }    // 拷贝赋值运算符 (使用 copy-and-swap 惯用法)    MyVector&amp; operator=(const MyVector&amp; other) {        std::cout &lt;&lt; \"[Copy Assignment Operator]\\n\";        if (this != &amp;other) {            MyVector temp(other); // 调用拷贝构造函数            swap(*this, temp);   // 交换内部指针        }        return *this;    }    // 移动赋值运算符    MyVector&amp; operator=(MyVector&amp;&amp; other) noexcept {        std::cout &lt;&lt; \"[Move Assignment Operator]\\n\";        if (this != &amp;other) {            free(); // 释放当前对象的资源            // 窃取源对象的资源            _start = other._start;            _finish = other._finish;            _end_of_storage = other._end_of_storage;            // 将源对象置空            other._start = other._finish = other._end_of_storage = nullptr;        }        return *this;    }    // 析构函数    ~MyVector() {        std::cout &lt;&lt; \"[Destructor] Cleaning up \" &lt;&lt; size() &lt;&lt; \" elements.\\n\";        free();    }    // --- 2. 容量相关 ---    size_t size() const noexcept { return _finish - _start; }    size_t capacity() const noexcept { return _end_of_storage - _start; }    bool empty() const noexcept { return _start == _finish; }    // --- 3. 元素访问 ---    T&amp; operator[](size_t n) { return _start[n]; }    const T&amp; operator[](size_t n) const { return _start[n]; }    // --- 4. 修改器 ---    void push_back(const T&amp; value) { // 拷贝版本        std::cout &lt;&lt; \"push_back (copy)\\n\";        if (_finish == _end_of_storage) {            reallocate();        }        // 使用 placement new 在已分配的原始内存上构造对象        new (_finish) T(value);        ++_finish;    }    void push_back(T&amp;&amp; value) { // 移动版本        std::cout &lt;&lt; \"push_back (move)\\n\";        if (_finish == _end_of_storage) {            reallocate();        }        // 使用 placement new 并通过 std::move 转发，调用移动构造函数        new (_finish) T(std::move(value));        ++_finish;    }    // --- 5. 迭代器 (简化版，仅为指针) ---    T* begin() noexcept { return _start; }    T* end() noexcept { return _finish; }    const T* begin() const noexcept { return _start; }    const T* end() const noexcept { return _finish; }private:    // --- 6. 私有辅助函数 ---    void free() {        if (_start) {            // 必须先手动调用析构函数            for (T* p = _start; p != _finish; ++p) {                p-&gt;~T();            }            // 再释放原始内存            delete[] reinterpret_cast&lt;char*&gt;(_start);        }    }    void reallocate() {        // 策略：容量为0时分配1，否则加倍, 这里是两倍的策略        size_t new_capacity = size() == 0 ? 1 : 2 * capacity();        size_t old_size = size();                // 分配原始内存，注意这里用 char* 是为了避免调用T的默认构造        T* new_start = reinterpret_cast&lt;T*&gt;(new char[new_capacity * sizeof(T)]);                // 移动旧元素到新内存        // 使用 std::uninitialized_move 来处理移动并构造，更安全高效        for(size_t i = 0; i &lt; old_size; ++i) {            new (new_start + i) T(std::move(_start[i]));        }        // 释放旧内存        free();        // 更新指针        _start = new_start;        _finish = _start + old_size;        _end_of_storage = _start + new_capacity;    }    // 友元函数，用于 copy-and-swap    friend void swap(MyVector&amp; first, MyVector&amp; second) noexcept {        using std::swap;        swap(first._start, second._start);        swap(first._finish, second._finish);        swap(first._end_of_storage, second._end_of_storage);    }    T* _start;  // 指向数据的起始位置    T* _finish;  // 指向当前最后一个元素的下一个位置    T* _end_of_storage;  // 指向分配的内存的末尾};\n\n这里的std::uninitialized_copy和std::uninitialized_move是C++标准库中的两个函数模板，分别用于在未初始化的内存区域中拷贝和移动对象。它们通常用于容器类的实现中，以便在分配新内存后正确地构造对象。\n底层实现的关键：size vs capacity要深入理解 std::vector，就必须明白它内部的内存管理机制，这涉及到两个核心概念：大小 (size) 和 容量 (capacity)。\n\n大小 (Size)：指容器中当前实际存储的元素数量。你可以通过 size() 成员函数获取。\n容量 (Capacity)：指在不重新分配内存的情况下，容器最多可以容纳的元素数量。你可以通过 capacity() 成员函数获取。\n\n可以在上述实现中看到, size 是通过 _finish - _start 计算得到的, 而 capacity 是通过 _end_of_storage - _start 计算得到的。\n当你向 vector 添加元素时（例如通过 push_back），如果当前的 size 达到了 capacity，vector 会调用 reallocate() 函数来分配一块更大的内存区域，通常是当前容量的两倍。然后，它会将旧元素移动到新内存中，并释放旧内存。\n这个过程是昂贵的，因为它涉及内存分配和所有元素的移动。但是，由于每次扩容都是指数级增长，这种昂贵的操作不会频繁发生。因此，push_back 的平均时间复杂度（摊还时间复杂度）依然是 O(1)。\n","categories":["language"],"tags":["language","cpp"]},{"title":"Socket编程","url":"/2025/09/25/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/socket%E7%BC%96%E7%A8%8B/","content":"预备知识网络字节序在计算机内存中，当一个数据类型（比如一个 32 位的整数 int）占用多个字节时，就存在一个如何排列这些字节的顺序问题，这就是字节序 (Byte Order) 或 Endianness (端序)。\n主要有两种字节序：\n\n小端字节序 (Little-Endian)：将数据的低位字节存放在内存的低地址处。这是目前绝大多数本地个人电脑（如 Intel, AMD 的 x86/x64 架构）使用的方式。\n大端字节序 (Big-Endian)：将数据的高位字节存放在内存的低地址处。这更符合人类的阅读习惯（从高位读到低位）。一些服务器、网络设备和早期的 PowerPC, MIPS 架构使用这种方式。\n\n举个例子：存储 16 位的整数 0x1234 (十进制的 4660)\n这里 0x12 是高位字节, 0x34 是低位字节。\n小端存储：内存低地址 -&gt; 0x34; 内存高地址 -&gt; 0x12大端存储：内存低地址 -&gt; 0x12; 内存高地址 -&gt; 0x34\n如果只是本地数据的读取, 小端序或者大端序都可以自洽; 但是假如涉及到不同端序设备的网络通信, 双方的端序不同步会产生难以想象的后果. 为了避免这种混乱，TCP/IP 协议规定：所有在网络上传输的数据都必须统一使用大端字节序。这个统一的标准就被称为 网络字节序 (Network Byte Order)。\n操作系统提供了一套标准的函数来在这两种字节序之间进行转换：\n\n\n\n函数\n功能\n说明\n\n\n\nhtons()\nHost to Network Short\n将一个 **16 位（short）**的数从主机字节序转换到网络字节序。主要用于端口号。\n\n\nhtonl()\nHost to Network Long\n将一个 **32 位（long）**的数从主机字节序转换到网络字节序。主要用于 IPv4 地址。\n\n\nntohs()\nNetwork to Host Short\n将一个 16 位的数从网络字节序转换到主机字节序。\n\n\nntohl()\nNetwork to Host Long\n将一个 32 位的数从网络字节序转换到主机字节序。\n\n\n核心原则：在发送数据前，所有非字符型数据（如端口号、IP地址整数值）都应该使用 hton*() 系列函数转换为网络字节序(操作系统在调用 hton*() 和 ntoh*() 系列函数时，会自动根据主机的字节序进行正确的转换)；在接收到数据后，应该使用 ntoh*() 系列函数转换回主机字节序再使用。\nIP 地址转换函数我们已经知道，IP 地址(这里还是指传统的IPv4)有两种表示格式：\n\n点分十进制字符串格式 (Presentation Format)：方便人类阅读，例如 “192.168.10.1”。\n整数格式 (Network Format)：方便计算机处理，是一个 32 位的无符号整数，并且是网络字节序。\n\n我们需要一组函数来在这两种格式之间进行转换, 这些函数定义在 &lt;arpa/inet.h&gt; 中:\n\nint inet_pton(int af, const char *src, void *dst);\n\n功能：将字符串 (p) 格式的 IP 地址转换为网络 (n) 整数格式。pton 即 “IP to net”。\naf: 地址族，AF_INET 或 AF_INET6。\nsrc: 指向 IP 地址字符串的指针。\ndst: 指向转换后存放结果的内存地址（例如 struct in_addr 的地址）。\n返回值为1代表成功; 0代表传入的src没有指向一个有效的IP地址; -1代表失败\n\n\nconst char *inet_ntop(int af, const void *src, char *dst, socklen_t size);\n\n功能：将网络 (n) 整数格式的 IP 地址转换为字符串 (p) 格式。ntop 即 “net to IP”。\n\n\n\nsockaddr 数据结构socket 编程接口（如 bind, connect）需要被设计成通用的，以便能够处理多种不同的网络协议（IPv4, IPv6, UNIX Domain Socket 等）。每种协议的地址结构都不同，例如：\n\nIPv4 地址需要：协议族、16 位端口号、32 位 IP 地址。\nIPv6 地址需要：协议族、16 位端口号、128 位 IP 地址，以及流信息和范围 ID。\n\n如果为每种协议都设计一套独立的函数，如 bind_ipv4(), bind_ipv6()，那将非常繁琐。\n为了解决这个问题，Socket API 设计了一个“基类”结构体 struct sockaddr。\nstruct sockaddr {    sa_family_t sa_family;  // 地址族 (AF_INET, AF_INET6, ...)    char        sa_data[14]; // 存放地址数据的区域};\n这是一个通用的、但内容模糊的结构体。我们几乎从不直接填充它。它的 sa_data 区域设计得足够大，可以容纳当时最常见的地址类型。\n更常见的是, 我们使用专门用于 IPv4 的更清晰的 struct sockaddr_in: \n#include &lt;arpa/inet.h&gt; // 需要引入socket头文件struct sockaddr_in {    sa_family_t    sin_family; // 地址族, 必须是 AF_INET    in_port_t      sin_port;   // 16位端口号 (必须是网络字节序, 因此要使用htons转换一下)    struct in_addr sin_addr;   // 32位IP地址结构体 (内含一个整数, 必须是网络字节序)    char           sin_zero[8]; // 填充位, 必须全部置为0(默认不需要处理), 为了让此结构与sockaddr等长};// 这里 struct in_addr 内部只有一个成员：uint32_t s_addr;\n\n在实际使用过程中, 我们需要明确初始化sockaddr_in结构体, 根据客户端和服务端分别初始化如下:\n#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;cstring&gt; // for memset// 假设我们已经创建好了 socket 文件描述符 fd// int fd = socket(AF_INET, SOCK_STREAM, 0);// 1. 声明一个 sockaddr_in 结构体变量struct sockaddr_in server_addr;// 2.将结构体清零memset(&amp;server_addr, 0, sizeof(server_addr));// 3. 设置地址族为 IPv4server_addr.sin_family = AF_INET;// 4. 设置服务器的端口号// htons(9527) -&gt; 将端口号从主机字节序转换到网络字节序server_addr.sin_port = htons(9527);// 5. 设置服务器的 IP 地址// 使用 inet_pton 将点分十进制的 IP 字符串转换为网络字节序的整数// 并直接存入 server_addr.sin_addr 结构体中if (inet_pton(AF_INET, \"192.157.22.45\", &amp;server_addr.sin_addr) &lt;= 0) {    // 转换失败处理    perror(\"inet_pton failed\");    // exit or return}// 6. 现在，server_addr 已经准备就绪，可以用于 connect 函数// connect(fd, (struct sockaddr *)&amp;server_addr, sizeof(server_addr));\n#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;cstring&gt; // for memset// 假设我们已经创建好了 socket 文件描述符 fd// int fd = socket(AF_INET, SOCK_STREAM, 0);// 1. 声明一个 sockaddr_in 结构体变量struct sockaddr_in local_addr;// 2.【关键】将结构体清零memset(&amp;local_addr, 0, sizeof(local_addr));// 3. 设置地址族为 IPv4local_addr.sin_family = AF_INET;// 4. 设置服务器要监听的端口号local_addr.sin_port = htons(9527);// 5. 设置服务器的 IP 地址// 使用 INADDR_ANY 这个宏，它代表 \"0.0.0.0\", 这意味着监听本机所有网络接口（如有线网卡、无线网卡）上的连接请求// htonl() 将这个 32 位的地址从主机字节序转换到网络字节序local_addr.sin_addr.s_addr = htonl(INADDR_ANY);// 6. 现在，local_addr 已经准备就绪，可以用于 bind 函数// bind(fd, (struct sockaddr *)&amp;local_addr, sizeof(local_addr));\n\n网络套接字函数socket模型创建流程\n如图, 一个完整的通信流程会涉及到(至少)三个socket,其中客户端一个, 服务端两个. 客户端的比较直接, 我们主要关注服务端\n具体流程是, 当服务器端调用socket()函数时会产生一个监听套接字 (Listening Socket)，而accept函数会阻塞监听套接字监听客户端连接，当有客户端过来连接的时候 该函数会返回一个新的套接字, 称作已连接套接字 (Connected Socket)去和客户端连接\n监听套接字 (Listening Socket)\n\n创建者：socket() 函数。\n配置者：bind() 和 listen() 函数。\n核心职责：作为一个“连接工厂”，它的唯一使命是在指定的 IP:Port 上监听并接收客户端发来的连接请求（TCP协议中的 SYN 包）。\n数据交互：它从不参与应用层数据的收发。你永远不会对一个监听套接字使用 send() 或 recv() 函数。\n生命周期：通常在服务器程序启动时创建，并一直存在，直到服务器程序关闭。对于一个服务器而言，一个端口上通常只有一个监听套接字。\n\n已连接套接字 (Connected Socket)\n\n创建者：accept() 函数。\n核心职责：作为与某一个特定客户端进行通信的专属通道。所有与该客户端的应用层数据（HTTP 请求、数据库查询、聊天消息等）都通过这个套接字进行 send() 和 recv()。\n数据交互：它是数据传输的实际执行者。\n生命周期：当一个客户端连接成功时被创建，当与这个客户端的通信结束时（客户端断开或服务器主动关闭），这个套接字就会被 close() 销毁。一个繁忙的服务器会频繁地创建和销毁成百上千个这样的套接字。\n\n正是这种“一个监听，多个连接”的模式，构成了所有网络服务器能够高效服务于众多客户端的基础架构。\nsocket() 函数socket套接字本意是插座, 意味着在数据通信过程中socket必须是成对出现的(客户端和服务端)\nsocket() 函数的作用是在操作系统内核中创建一个通信的端点，并返回一个指向该端点的文件描述符 (File Descriptor)。\n你可以将这个过程理解为向操作系统申请一部“电话机”。这部“电话机”本身还不知道要打给谁（没有目标地址），也不知道自己的号码（没有绑定端口），但它是后续所有通信操作的基础。在类 Unix 系统（如 Linux）中，这个返回的文件描述符与其他文件（如磁盘文件、管道）的描述符一样，可以被 read(), write(), close() 等函数操作, 本质上也是一个文件。\n函数原型 (Function Prototype)及参数和返回值socket() 函数通常在 C 语言的头文件 &lt;sys/socket.h&gt; 中定义。其标准原型如下：\n#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt; int socket(int domain, int type, int protocol);\n这个函数接收三个整数类型的参数，并返回一个整数。\n\ndomain：协议族这个参数用于指定 Socket 使用的协议族 (Protocol Family)。它决定了通信的地址格式和底层协议的范畴。\n\n换句话说, 这个参数告诉操作系统你打算进行哪一类的通信，例如是基于 IPv4 的互联网通信，还是基于 IPv6，或者是仅限于本机内部的通信。\n常用值(主要是AF_INET)：\n\nAF_INET (Address Family Internet): 这是最常用的值，表示使用 IPv4 协议族。网络地址将由 32 位的 IPv4 地址和 16 位的端口号组成。\n\nAF_INET6: 表示使用 IPv6 协议族。网络地址将由 128 位的 IPv6 地址和 16 位的端口号组成。\n\nAF_UNIX (或 AF_LOCAL): 用于本机内部进程间通信 (IPC)。它不使用网络协议，而是通过文件系统中的一个特殊文件（socket 文件）来进行数据交换，效率非常高。\n\n\n\ntype：套接字类型这个参数用于指定 Socket 的服务类型 (Service Type)，它决定了通信的语义和行为。使用这个参数需要明确你需要的通信方式是可靠的、面向连接的（像打电话），还是快速的、无连接的（像寄明信片）。\n\n常用值：\n\nSOCK_STREAM (Stream Socket): 流式套接字, 提供面向连接、可靠的、基于字节流的服务。它通常与 TCP 协议配合使用。\n\n数据传输前必须先建立连接。它保证数据传输是有序的、无差错的、无重复的。数据像水流一样，没有边界，你发送 100 字节，对方可能一次性收到 100 字节，也可能先收到 40 字节再收到 60 字节。\n适用场景：绝大多数应用，如网页浏览 (HTTP)、文件传输 (FTP)、邮件发送等。\n\n\nSOCK_DGRAM (Datagram Socket): 数据报套接字, 提供无连接、不可靠的、基于数据报的服务。它通常与 UDP 协议配合使用。\n\n通信前不需要建立连接。每个数据包（数据报）都是独立的，有自己的目标地址。它不保证数据能到达，也不保证到达的顺序。\n适用场景：对实时性要求高、能容忍少量丢包的场景，如在线游戏、视频直播、DNS 查询。\n\n\n\n\nprotocol：具体协议这个参数用于指定在前两个参数确定的协议族和套接字类型下，还想进一步使用的具体协议。因为在某些协议族中，可能有多种协议支持同一种套接字类型。这个参数允许你精确指定。\n\n不过大部分情况下使用 0 即可：这是最常用的值。表示让操作系统根据 domain 和 type 的组合自动选择默认的协议, 等同于下列手动指定:socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);    // 创建tcp的socksocket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);    // 创建udp的sock\n\n返回值 (Return Value)\n\n成功时：返回一个非负整数，这个整数就是套接字描述符 (Socket Descriptor)，也常被称为文件描述符。它是这个新创建的 Socket 的唯一标识。后续所有的 Socket 相关函数（如 bind(), connect(), listen() 等）都将使用这个描述符作为参数。\n失败时：返回 -1。同时，全局变量 errno 会被设置为一个特定的错误码，以指示失败的原因。我们可以通过 perror() 函数或 strerror(errno) 来查看具体的错误信息。常见的错误原因包括：权限不足、协议不支持、系统资源耗尽等。\nsocket()函数简单示例#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;errno.h&gt; // For errno variable#include &lt;string.h&gt; // For strerror functionint main() {    int tcp_socket_fd;    int udp_socket_fd;    // --- 1. 创建一个用于 IPv4 的 TCP 套接字 ---    // 步骤说明：调用 socket 函数，指定协议族为 AF_INET (IPv4)，    // 类型为 SOCK_STREAM (TCP)，协议让系统自动选择 (0)。    tcp_socket_fd = socket(AF_INET, SOCK_STREAM, 0);    // 步骤说明：检查返回值。如果为 -1，则表示创建失败。    // 使用 perror 可以打印出更详细的错误原因。    if (tcp_socket_fd == -1) {        perror(\"Create TCP socket failed\");        exit(EXIT_FAILURE);    }    printf(\"TCP socket created successfully! File Descriptor: %d\\n\", tcp_socket_fd);    // --- 2. 创建一个用于 IPv4 的 UDP 套接字 ---    // 步骤说明：与上面类似，只是将套接字类型改为 SOCK_DGRAM (UDP)。    udp_socket_fd = socket(AF_INET, SOCK_DGRAM, 0);        if (udp_socket_fd == -1) {        perror(\"Create UDP socket failed\");        exit(EXIT_FAILURE);    }    printf(\"UDP socket created successfully! File Descriptor: %d\\n\", udp_socket_fd);    // ... 之后可以对这两个 socket_fd 进行 bind, connect, send, recv 等操作 ...        // 最后需要关闭套接字    // close(tcp_socket_fd);    // close(udp_socket_fd);    return 0;}\nbind()函数bind 函数的作用是给套接字“绑定”一个地址。在我们之前的比喻中，socket() 函数只是创建了一个“电话机”，而 bind 函数就是向电信局申请一个具体的电话号码（IP 地址 + 端口号）并分配给这部电话机。\n对于服务器来说，这是一个必须的步骤，因为客户端必须知道服务器的“地址”才能发起连接。\n函数原型及参数解释如下:\n#include &lt;sys/socket.h&gt;int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\n\nint sockfd: 由 socket() 函数返回的套接字文件描述符。\nconst struct sockaddr *addr: 由const可知是传入参数, 是一个指向 sockaddr 结构体的指针。这正是我们之前讨论过的“预备知识”的应用。我们通常会创建一个 struct sockaddr_in (for IPv4) 变量，填充好 sin_family, sin_port (端口) 和 sin_addr (IP 地址)，然后将其指针强制转换为 (struct sockaddr *) 再传递给 bind。\nsocklen_t addrlen: addr 指向的地址结构体的确切大小，通常使用 sizeof(struct sockaddr_in)。\n返回值: 成功返回 0; 失败返回 -1，并设置全局变量 errno。常见的失败原因包括：端口已被占用 (EADDRINUSE)、没有权限绑定该地址 (EACCES)等。\n\n需要注意的是, bind 是服务器端专用的函数（客户端通常不需要），它在 socket() 创建套接字之后、listen() 开始监听之前被调用。\nlisten() 函数listen 函数的作用是让套接字进入“被动监听”模式以及设置最多同时连接数。一个普通的套接字（由 socket() 创建）既可以主动发起连接（作为客户端），也可以被动接收连接（作为服务器）。一旦调用 listen，这个套接字就从一个“主动”套接字转变为一个“被动”的、专门用于接收连接请求的监听套接字。\n在我们之前的比喻中，这相当于把公司的总机电话设置为“等待来电”状态，并告诉交换机系统，可以开始向这个号码派发来电了。\n函数原型及参数解释: \n#include &lt;sys/socket.h&gt;int listen(int sockfd, int backlog);\n\nint sockfd:: 已经被 bind() 绑定了地址的套接字文件描述符。\nint backlog:一个非常重要的参数，它规定了内核为这个监听套接字维护的“待处理连接队列”的最大长度。当服务器非常繁忙，来不及 accept() 新的连接时，新来的连接请求会先被放入这个队列中排队。如果队列已满，新的客户端连接请求可能会被拒绝。这个值的大小需要根据服务器的负载能力来设置，一个常见的值是 SOMAXCONN (一个由系统定义的较大值)。\n返回值: 成功返回 0; 失败返回 -1，并设置 errno。\n\n同样, listen 也是服务器端专用的函数，在 bind() 之后、accept() 之前被调用。\naccept() 函数accept 函数是服务器从“待处理连接队列”中取出一个连接请求，并创建一个全新的套接字来与该客户端通信。accept 接收的 sockfd 是监听套接字，而它返回的是一个全新的已连接套接字。\n这是一个阻塞函数：如果队列中没有已完成的连接，程序会在这里暂停，直到有客户端连接进来为止。\n函数原型及参数解释:\n#include &lt;sys/socket.h&gt;int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\n\nint sockfd: 正在监听的那个监听套接字的文件描述符。\nstruct sockaddr addr (可选): 没有const, 因此很大可能(实际上也就是)传出参数, 是一个指向 sockaddr 结构体的指针，用于*接收客户端的地址信息。当函数成功返回时，内核会把发起连接的客户端的 IP 和端口填充到这个结构体中。如果你不关心客户端的地址，可以把它设为 NULL。\nsocklen_t *addrlen (可选): 一个指向 socklen_t 变量的指针。在调用前，你需要把它指向的变量设置为 addr 指向的缓冲区的最大长度 (sizeof(struct sockaddr_in))。函数返回后，这个变量的值会变为客户端地址结构体的实际长度。如果 addr 是 NULL，这个参数也应为 NULL。\n返回值; 成功返回一个新的非负整数，这个整数就是新创建的已连接套接字的文件描述符。后续与该客户端的所有通信（send/recv）都将使用这个新的描述符; 失败返回 -1，并设置 errno。\n\naccept 也是服务器端专用的函数，通常在 listen() 之后的一个主循环中被反复调用。\nconnect() 函数connect 函数由客户端调用，用于向指定的服务器地址发起一个主动的连接请求。\n这个函数会触发 TCP 协议的三次握手过程。它也是一个阻塞函数，在三次握手成功建立连接、或者超时/失败之前，程序会一直等待。\n函数原型及参数解释:\n#include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\n\nint sockfd: 客户端自己的、由 socket() 创建的套接字文件描述符。\nconst struct sockaddr *addr: 传入参数, 一个指向 sockaddr 结构体的指针，里面包含了服务器的 IP 地址和端口号。客户端必须准确地填充这个结构体，才能找到正确的服务器。\nsocklen_t addrlen: addr 指向的服务器地址结构体的确切大小。\n返回值: 成功返回 0。此时 TCP 连接已成功建立; 失败返回 -1，并设置 errno。常见的失败原因包括：服务器拒绝连接 (ECONNREFUSED)、网络不可达 (ENETUNREACH)、连接超时 (ETIMEDOUT)等。\n\nconnect 是客户端专用的函数，在 socket() 创建套-接字之后被调用。\nClient-Server 示例下面是一个简单的 TCP 客户端-服务器示例，展示了如何使用上述的 socket 函数进行基本的网络通信。\n服务端/* * 程序名：server.cpp，一个简单的TCP回显服务器。 * 功能：接收客户端的请求报文，将其转换为大写后，再发回给客户端。 */#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;// 处理业务的主函数void HandleRequest(int client_sockfd);int main(int argc, char *argv[]){    if (argc != 2)    {        std::cout &lt;&lt; \"Using: ./server port\\nExample: ./server 5005\\n\\n\";        return -1;    }    // 第1步：创建服务端的socket。    int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_sockfd == -1)    {        perror(\"socket\");        return -1;    }    // 第2步：把服务端用于通信的地址和端口绑定到socket上。    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 任意ip地址    serv_addr.sin_port = htons(atoi(argv[1]));     // 指定端口    if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0)    {        perror(\"bind\");        close(listen_sockfd);        return -1;    }    // 第3步：把socket设置为监听模式。    if (listen(listen_sockfd, 5) != 0)    {        perror(\"listen\");        close(listen_sockfd);        return -1;    }    std::cout &lt;&lt; \"Server is listening on port \" &lt;&lt; argv[1] &lt;&lt; \"...\" &lt;&lt; std::endl;    // 第4步：接受客户端的连接。    while (true) // 主循环，使服务器可以一直接收新的连接    {        struct sockaddr_in client_addr;        socklen_t len = sizeof(client_addr);        // accept()会阻塞，直到有客户端连接上来        int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);  // 当有客户端连接时，accept() 函数会把客户端的地址信息（如 IP 和端口）填充到 client_addr 结构体里, 可以用于后续日志、鉴权等操作。        if (client_sockfd &lt; 0)        {            perror(\"accept\");            continue; // 继续等待下一个连接        }        char ipstr[INET_ADDRSTRLEN];        inet_ntop(AF_INET, &amp;client_addr.sin_addr, ipstr, sizeof(ipstr));        std::cout &lt;&lt; \"Client \" &lt;&lt; ipstr &lt;&lt; \" connected.\" &lt;&lt; std::endl;        // 调用主函数处理与客户端的通信        HandleRequest(client_sockfd);        // 然而只有HandleRequest函数返回后，才会继续回到这里，等待下一个客户端连接, 这意味着服务器是串行处理每个客户端的请求的    }    // 在实际应用中，服务器通常不会执行到这里，除非有明确的关闭指令    close(listen_sockfd);    return 0;}// 主函数，与客户端进行读写交互void HandleRequest(int client_sockfd){    char buffer[1024];    while (true)    {        memset(buffer, 0, sizeof(buffer));        // 接收客户端的请求报文 (read)        ssize_t bytes_received = read(client_sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0)        {            std::cout &lt;&lt; \"Received from client: \" &lt;&lt; buffer &lt;&lt; std::endl;            // 处理请求：将字符串转换为大写            for (int i = 0; buffer[i]; ++i)            {                buffer[i] = toupper(buffer[i]);            }            // 回应数据给客户端 (write)            if (write(client_sockfd, buffer, strlen(buffer)) &lt;= 0)            {                perror(\"write\");                break;            }            std::cout &lt;&lt; \"Sent to client: \" &lt;&lt; buffer &lt;&lt; std::endl;        }        else if (bytes_received == 0)        {            // read()返回0表示客户端已关闭连接            std::cout &lt;&lt; \"Client disconnected.\" &lt;&lt; std::endl;            break;        }        else        {            // read()返回-1表示发生错误            perror(\"read\");            break;        }    }    // 结束连接 (close)    close(client_sockfd);}\n客户端/* * 程序名：client.cpp，一个简单的TCP客户端。 * 功能：向服务端发送请求，并接收服务端的回应。 */#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char *argv[]){    if (argc != 3)    {        std::cout &lt;&lt; \"Using: ./client ip port\\nExample: ./client 127.0.0.1 5005\\n\\n\";        return -1;    }    // 第1步：创建客户端的socket。    int sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (sockfd == -1)    {        perror(\"socket\");        return -1;    }    // 第2步：向服务器发起连接请求。    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(atoi(argv[2])); // 服务器端口    if (inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr) &lt;= 0)    {        perror(\"inet_pton\");        close(sockfd);        return -1;    }    // connect()会阻塞，直到连接成功或失败    if (connect(sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0)    {        perror(\"connect\");        close(sockfd);        return -1;    }    std::cout &lt;&lt; \"Connected to server \" &lt;&lt; argv[1] &lt;&lt; \":\" &lt;&lt; argv[2] &lt;&lt; std::endl;    // 第3步：与服务端通讯。    char buffer[1024];    std::string input;        std::cout &lt;&lt; \"Enter a message (or 'exit' to quit): \";    while (getline(std::cin, input) &amp;&amp; input != \"exit\")    {        // 请求数据 (write)        if (write(sockfd, input.c_str(), input.length()) &lt;= 0)        {            perror(\"write\");            break;        }        // 接收服务端的回应报文 (read)        memset(buffer, 0, sizeof(buffer));        ssize_t bytes_received = read(sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0)        {            std::cout &lt;&lt; \"Server response: \" &lt;&lt; buffer &lt;&lt; std::endl;        }        else if (bytes_received == 0)        {            std::cout &lt;&lt; \"Server disconnected.\" &lt;&lt; std::endl;            break;        }        else        {            perror(\"read\");            break;        }        std::cout &lt;&lt; \"\\nEnter a message (or 'exit' to quit): \";    }    // 第4步：关闭socket，结束连接。    close(sockfd);    std::cout &lt;&lt; \"Connection closed.\" &lt;&lt; std::endl;    return 0;}\n\n端口复用在开发和测试服务器程序时，肯定会遇到一个经典问题：第一次启动了服务器，它成功 bind() 到 5005 端口并开始 listen(); 接着通过 Ctrl+C 强制关闭了服务器; 然后立刻尝试重新启动服务器。\n此时，bind() 函数调用失败，程序打印出错误信息：bind: Address already in use。我们不得不等待几十秒甚至几分钟后，才能再次成功启动服务器。这个问题在开发调试阶段非常影响效率，在生产环境中也可能导致服务中断时间变长。\n这个现象的根本原因在于 TCP 协议的一个重要状态：TIME_WAIT。\n回想TCP 四次挥手：当一个 TCP 连接被关闭时（例如服务器或客户端程序退出），主动关闭连接的一方会进入 TIME_WAIT 状态。这个状态会持续一段时间，通常是 2 * MSL (Maximum Segment Lifetime，报文最大生存时间)，在 Linux 系统上一般是 60 秒。\n当我们的服务器程序关闭后，它所使用的套接字（绑定了例如 127.0.0.1:5005）就进入了 TIME_WAIT 状态。在此期间，操作系统认为这个端口仍然是“被占用的”，因此不允许任何新的套接字再次 bind() 到完全相同的地址和端口上。\n为了解决这个问题，Socket API 提供了一个非常有用的选项：SO_REUSEADDR。\n在设置 SO_REUSEADDR 选项后，它会告诉操作系统内核：“请允许我 bind()到一个正处于 TIME_WAIT 状态的端口”。它放宽了 bind 函数的校验规则，使得服务器可以在关闭后立刻重启，绕过 TIME_WAIT 状态对 bind 的限制。\n这对于需要高可用性和快速重启的服务器应用程序来说，是必须设置的一个选项。\n要启用端口复用，我们需要在 bind() 函数被调用之前，使用 setsockopt() 函数来设置监听套接字的属性, 其函数原型如下:\n#include &lt;sys/socket.h&gt;int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen);\n\nint sockfd: 要设置的套接字文件描述符（这里是我们的 listen_sockfd）。\nint level: 选项所在的协议层。对于端口复用，应设置为 SOL_SOCKET，表示在通用套接字层进行设置。\nint optname: 选项的名称。这里我们使用 SO_REUSEADDR。\nconst void *optval: 一个指向变量的指针，该变量包含了我们想设置的选项的值。对于开关型选项 SO_REUSEADDR，我们通常用一个值为 1 的 int 变量来表示“开启”。\nsocklen_t optlen: optval 指向的变量的大小，即 sizeof(int)。\n\n下面是一个启用端口复用的示例代码片段，展示了如何在创建监听套接字后、调用 bind() 之前设置 SO_REUSEADDR 选项:\n/* * server.cpp 中 main 函数的相关部分 */// 第1步：创建服务端的socket。int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);if (listen_sockfd == -1){    perror(\"socket\");    return -1;}// ======================= 在这里添加端口复用设置 =======================// 作用：允许服务器在关闭后立即重启，而不会因为 TIME_WAIT 状态导致 \"Address already in use\"int opt = 1;if (setsockopt(listen_sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt)) != 0){    perror(\"setsockopt\");    close(listen_sockfd);    return -1;}// ====================================================================// 第2步：把服务端用于通信的地址和端口绑定到socket上。struct sockaddr_in serv_addr;// ... (后面的 bind, listen, accept 代码与之前完全相同)if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0){    // ...}\n\n总之, 端口复用 (SO_REUSEADDR) 是一个健壮的 TCP 服务器程序必备的特性。它通过 setsockopt 函数进行设置，允许程序重新绑定到处于 TIME_WAIT 状态的端口，从而解决了服务器因异常关闭而无法立即重启的问题，极大地提高了开发效率和服务的可用性。\n","categories":["web","language","C++"],"tags":["web","C++"]},{"title":"字符串","url":"/2025/09/03/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2/","content":"std::string 是 C++ 标准库中用于处理字符串的类，位于  头文件中，命名空间为 std\n\n在 C++ 中，强烈建议使用 string 类表示字符串，因为它是真正的字符串类型。而在 C 语言中实际上没有字符串类型，只是用字符数组和字符指针来模拟字符串，而且后者不太安全\n\n\nchar* (C 风格字符串)：本身没有成员函数，不能使用 .size() 或 .length()。要获取其长度，必须使用 C 语言的库函数 strlen()，这个函数定义在  (或 C 的 &lt;string.h&gt;) 头文件中。  \n\n\nC++ 字符串末尾没有 \\0 字符。事实上，除了 C 语言外，其他语言都是将字符串本身及其长度存在内存中，因此不用 \\0 标记结尾\n\n其迭代器是随机访问迭代器, 支持跳跃式访问\n定义和初始化#include &lt;string&gt;using namespace std;string s1;          // 空字符串string s2(\"Hello\"); // 用C字符串初始化string s2 = \"Hello\";string s5 = {\"C++11\"}; // C++11列表初始化string s3(s2);      // 拷贝构造string s4(5, 'a');  // 5个'a'： \"aaaaa\"（重复字符串）\n\n\n当 std::string str 这行代码执行完毕后，变量 str 已经拥有了一个确定的、合法的、可用的值。它不是未定义的、也不是指向 null 的 ( RAII 的体现 )。std::string 的默认构造函数会将字符串初始化为一个空字符串 (Empty String),  具有以下明确的属性：\n值为 “”：它不包含任何字符。\n长度为 0：调用 str.length() 或 str.size() 会返回 0。\n是“空的”：调用 str.empty() 会返回 true。\n是有效的：可以立即对它进行各种操作，而不会导致程序错误。\n\n\n因为 std::string 是一个 类 (Class)，而不是像 int 或 char[] 这样的基础数据类型。在 C++ 中，当一个类的对象被创建时，会自动调用其相应的构造函数 (Constructor) 来进行初始化。\n\n访问和赋值char c1 = s[0];     // 通过[]访问（不检查越界）, 但注意此时s[i]返回的是char类型的单个字符char c2 = s.at(1);  // 通过at()访问（越界抛出异常）char front = s.front(); // 首字符（C++11）char back = s.back();   // 尾字符（C++11）string s;s = \"Hello\";        // 直接赋值s[0] = 'J';s.assign(\"World\");  // assign函数赋值（string类的方法）s.assign(s, 1, 3); // 从s2的索引1开始取3个字符：\"orl\"赋值给s\n在赋值时和 C 字符串的差别:\nchar char1[20];char char2[20] = \"jaguar\";string str1;string str2;char1 = char2;                // illegalstr1 = str2;                  // legal\n\nC 风格字符串 (char[]) 本质是“数组”,  当声明 char char1[20]; 时，实际是在内存的栈上请求了一块连续的、包含 20 个 char 类型元素的空间。char1 这个名字就代表了这块内存的起始地址。 \n\n尝试执行 char1 = char2; 时，实际上是在命令编译器：“请把 char1 这个地址常量，修改为 char2 这个地址常量所代表的地址”。这在逻辑上是行不通的，也是 C/C++ 语法所禁止的。编译器会报错，通常提示“表达式必须是可修改的左值”或“数组类型不可赋值”。\n\n\n字符串长度int len = s.size();  // 或 s.length()int len = s.length();bool isEmpty = s.empty(); // 是否为空s.clear();           // 清空字符串s.reserve(100);      // 预分配内存\n\n字符串连接string s = \"Hello\";s += \" World\";      // 追加字符串s.append(\"!!\");     // 追加：\"Hello World!!\"s.push_back('!');   // 追加单个字符string str3;str3 = str1 + str2;\n\n字符串比较string a = \"apple\", b = \"banana\";if (a == b) { /* ... */ } // 直接比较，同理&gt;和&lt;、&lt;=等也一样，比较字典顺序int cmp = a.compare(b);   // 返回0（相等）、正数（a &gt; b）、负数（a &lt; b）\n\n关于单引号和双引号:\n\n\n\n符号\n用途\n类型\n内存内容\n示例\n\n\n\n‘ ‘\n单个字符\nchar\nASCII 值\n‘A’\n\n\n“ “\n字符串\nconst char*\n字符序列 + \\0\n“Hello”\n\n\n因此对于string类型的s, 下列代码不正确s[i] == “V”而应该是s[i] == ‘V’\n子串操作substr() 函数\n\n获取子字符串：s.substr(pos, len)\n参数：\npos：起始索引。\nlen：长度（可选，默认到字符串末尾）( 不是终点位置!!! 已知终点算长度要 pos-start)\n\n\n\nstring s = \"Hello World\";string sub1 = s.substr(6);    // \"World\"（从索引6开始到结尾）string sub2 = s.substr(0, 5); // \"Hello\"（从0开始取5个字符）\n\n插入和删除s.insert(5, \" INSERTED \"); // 在索引5插入字符串s.erase(5, 8);             // 从索引5删除8个字符, (pos, length)s.erase(s.begin() + 2);   // 删除迭代器指向的字符\n\n字符串输入和输出std::string s;std::cin &gt;&gt; s; // 默认停止读取空格，分隔多单词输入std::getline(std::cin, s); // 读取整行内容，包括空格std::string s(\"Hello\");std::cout &lt;&lt; s &lt;&lt; std::endl; // 输出 \"Hello\"\n\n\n如果 cin 之后用到 getline，由于 cin 遇到空白字符时就停止往后读，输入流里可能还有未被读取的换行符，而 getline 将会读取一行字符串，直到遇到换行符。所以在使用 getline 前，应当先用 cin.get() 读取换行符（这个函数的功能是读取单个字符），然后再用 getline。\n\n","categories":["language"],"tags":["language","cpp"]},{"title":"Thread线程库中的资源问题","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/2.%20Thread%E7%BA%BF%E7%A8%8B%E5%BA%93%E4%B8%AD%E7%9A%84%E8%B5%84%E6%BA%90%E9%97%AE%E9%A2%98/","content":"在单线程程序中，对象的创建和销毁顺序是可预测的。但在多线程程序中，新线程的执行时机是不确定的。它可能在创建它的函数返回之前、之中或之后才真正开始运行。“数据未定义错误”的根源就是，程序员错误地假设了新线程会比它所需要的数据“死”得更早，但事实往往相反。\n下面这些问题的本质原因在于: 线程的生命周期与其访问的数据的生命周期不匹配，导致线程访问了无效的内存\n数据未定义的情况传递临时变量#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int&amp; x) {    x += 1;}int main() {    std::thread t(foo, 1); // 传递临时变量    t.join();    return 0;}\n上述代码中，foo函数接受一个整数引用作为参数，并对其加 1。但在线程创建时，传入的1是一个临时变量，在std::thread解析参数时，该临时变量会被销毁，导致foo访问了已销毁的对象，产生未定义行为。解决方案是使用 std::ref 传递一个持久化变量的引用：\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;functional&gt;void foo(int&amp; x) {    x += 1;}int main() {    int x = 1;    std::thread t(foo, std::ref(x)); // 传递变量的引用    t.join();    return 0;}\n注意这里必须传入引用而不是值，否则根据线程的规则, 线程会访问一个临时对象的副本，而不是原始对象。\n\nstd::thread 的构造函数在接收参数时，默认情况下会复制 (copy) 或 移动 (move) 传递给它的参数。它会将这些参数的副本存储在线程内部，然后在新的线程上下文中，将这些副本传递给你指定的函数。也就是说, 它是不支持通过变量名直接引用传参的, 如果想实现引用传参, 必须使用 std::ref 或 std::cref 包装一下。\n\n传递指针或引用指向局部变量的问题#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int* ptr) {    std::cout &lt;&lt; *ptr &lt;&lt; std::endl; // 访问完全可能已经被销毁的指针}int main() {    int x = 1;    std::thread t(foo, &amp;x); // 传递指向局部变量的指针    t.detach();    return 0;}\n一个解决策略是使用std::shared_ptr，避免手动管理内存\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;memory&gt;void foo(std::shared_ptr&lt;int&gt; ptr) {    std::cout &lt;&lt; *ptr &lt;&lt; std::endl;}int main() {    auto ptr = std::make_shared&lt;int&gt;(1);    std::thread t(foo, ptr);    t.join();    return 0;}\n这里的 std::shared_ptr 确保了对象的生命周期与线程的生命周期同步，避免了访问已销毁对象的问题。\n传递指针或引用指向已释放的内存的问题#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int&amp; x) {    std::cout &lt;&lt; x &lt;&lt; std::endl;}int main() {    int* ptr = new int(1);    std::thread t(foo, *ptr); // 传递已释放的内存    delete ptr;    t.join();    return 0;}\n在线程 t 启动前，ptr有可能已被delete，导致foo访问了已释放的内存，行为未定义.解决方法是确保在线程的生命周期内，指针或引用指向的内存不被释放, 即对调join()和delete的顺序\n类成员函数作为入口函数，类对象被提前释放#include &lt;iostream&gt;#include &lt;thread&gt;class MyClass {public:    void func() {        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" started\" &lt;&lt; std::endl;        // do some work        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" finished\" &lt;&lt; std::endl;    }};int main() {    MyClass obj;    std::thread t(&amp;MyClass::func, &amp;obj);    return 0;} // obj 被销毁，可能导致线程崩溃\n这里在 main 结束时，obj 被销毁，导致 t 访问已销毁的对象，可能崩溃。解决方法还是使用使用 std::shared_ptr 管理生命周期：\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;memory&gt;class MyClass {public:    void func() {        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" started\" &lt;&lt; std::endl;        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" finished\" &lt;&lt; std::endl;    }};int main() {    auto obj = std::make_shared&lt;MyClass&gt;();    std::thread t(&amp;MyClass::func, obj);    t.join();    return 0;}\n\n两条时间线正如开头所说, 这些情况的本质原因在于一个线程尝试访问一个在它访问的那个时刻，其生命周期已经结束（或者可能已经结束）的数据对象。\n为了避免这种问题, 在多线程编程中，你必须在脑海里清晰地分出两条并行且速度不一的“时间线”：\n数据的时间线：这是指变量或对象从被创建到被销毁的整个过程。这条时间线的终点是由 C++ 的作用域和内存管理规则严格决定的。\n\n局部变量/对象：其生命周期严格绑定在创建它的那个作用域 {} 内。函数返回或作用域结束，它就立刻死亡。\n临时对象：生命周期更短，通常只在创建它的那一个完整语句内有效。语句结束，它就死亡。\n堆对象 (new)：生命周期从 new 开始，到 delete 被调用时结束。它的死亡时刻由程序员手动决定。\n\n线程的时间线：这是指一个线程从被创建到其任务执行完毕的整个过程。这条时间线的启动和结束相对于创建它的代码来说，是异步的、不确定的。你只知道它在 std::thread 对象被创建后“某个时间点”开始，在任务执行完毕后“某个时间点”结束。\n而上述提到的未定义行为，都爆发于这两条时间线的交叉点上，并且是一场“死亡竞赛”：“数据的死亡” 与 “线程的访问” 之间在赛跑。如果“数据的死亡”先于“线程的访问”到达，程序就会崩溃。\n传递局部变量的指针：\n\n数据的死亡时刻：创建局部变量的函数返回时。\n线程的访问时刻：不确定，很可能在函数返回之后。\n竞赛结果：数据几乎总是先死。线程访问的是无效的栈内存。\n\n传递临时变量的指针：\n\n数据的死亡时刻：创建线程的语句结束时。\n线程的访问时刻：不确定，但几乎总是在该语句结束之后。\n竞赛结果：数据总是先死。这是最危险的情况，因为数据生命周期极短。\n\n提前 delete 堆内存：\n\n数据的死亡时刻：主线程执行到 delete 时。\n线程的访问时刻：不确定，与主线程并发。\n竞赛结果：这是一场真正的竞赛。delete 和线程的访问哪个先发生完全不确定。只要有任何可能 delete 先发生，代码就是错误的。\n\n类对象提前释放：\n\n数据的死亡时刻：类对象所在的作用域结束时。\n线程的访问时刻：不确定，很可能在作用域结束之后。\n竞赛结果：和局部变量一样，数据几乎总是先死。线程通过悬空的 this 指针访问成员。\n\n通用的解决方案：强制同步生命周期既然问题的本质是生命周期不匹配，那么解决方案的本质就是强制让它们的生命周期匹配起来。程序员的责任就是确保这场“死亡竞赛”永远不会发生。\n通用的方法是：通过同步机制，确保在线程的整个生命周期内，它所访问的数据的生命周期也持续有效。具体手段包括：\n延长数据的生命周期：\n\n按值传参：不传递指针或引用，而是直接复制一份数据给线程。这样线程就拥有了数据的独立副本，副本的生命周期和线程自身绑定，与原始数据无关。\n使用智能指针 std::shared_ptr：将堆上的数据交由 std::shared_ptr 管理。只要线程还持有 shared_ptr 的副本，数据就不会被释放。\n\n缩短（或同步）线程的生命周期：\n\n使用 thread::join()：这是最核心的同步工具。join() 的作用就是强制让“创建者的代码流”停下来，等待“线程的时间线”结束。这样就保证了在函数返回、作用域结束、对象销毁之前，线程一定已经完成了对该数据的访问。\n\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"Makefile","url":"/2025/09/24/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/makefile/","content":"makefile： 用于管理项目。\n文件命名：只能是 makefile 或者 Makefile配置完成后直接使用 make 命令执行\n1 个规则：\n\t目标：依赖条件\n\t（一个tab缩进）命令\n\n要求: 目标的时间必须晚于依赖条件的时间，否则，更新目标      依赖条件如果不存在，找寻新的规则去产生依赖条件。\nALL：指定 makefile 的终极目标。(因为makefile默认第一个目标文件为终极目标, 防止将中间文件放在第一个造成执行中断)\n2 个函数：\n\tsrc = $(wildcard ./*.c): 匹配当前工作目录下的所有.c 文件。将文件名组成列表，赋值给变量 src (例如src = add.c sub.c div1.c)\n\n\tobj = $(patsubst %.c, %.o, $(src)): 将参数3($(src))中，包含参数1(%.c)的部分，替换为参数2(%.o)。 obj = add.o sub.o div1.o\n\n在脚本语言中对一个对象使用$表示取其值\n\nclean:\t(没有依赖)\n\t-rm -rf $(obj) a.out\t\n上述脚本可以实现调用make clean即可清除.o文件\n“-”：作用是，删除不存在文件时，不报错。顺序执行结束。\n\n3 个自动变量：\n$@: 在规则的命令中，表示规则中的目标。\n$^: 在规则的命令中，表示所有依赖条件。\n$&lt;: 在规则的命令中，表示第一个依赖条件。如果将该变量应用在模式规则中，它可将依赖条件列表中的依赖依次取出，套用模式规则。\n也就是上面三者用在命令中, 代指命令上一行的目标和依赖\n模式规则：\n\n\t%.o:%.c\n\t   gcc -c $&lt; -o %@\n  \n含义是对于所有目标为.o文件的对象, 根据.c文件来执行gcc -c (%.c) -o (%.o)\n\n静态模式规则：\n\n\t$(obj):%.o:%.c\n\t   gcc -c $&lt; -o %@\t\n\n只对obj所指的对象执行这条命令\n\n伪目标：\n\n\t.PHONY: clean ALL\n防止文件中出现同名clean和ALL的文件阻碍make\n\n参数：\n\t-n：模拟执行make、make clean 命令。\n\n\t-f：指定文件执行 make 命令。\n\nmakefile实现增量执行, 其检测原理：修改文件后，文件的修改时间发生变化，会出现目标文件的时间早于作为依赖材料的时间，出现这种情况的文件会重新编译。修改sub.c后，sub.o的时间就早于sub.c ，a.out的时间也早于sub.o的时间了，于是重新编译这俩文件了。\n还有一点, 编译时的参数，-g,-Wall这些，也可以放在makefile里面. 一份最终的makefile示例如下:\nsrc = $(wildcard *.c) # 搜索当前目录下所有 .c 文件obj = $(patsubst %.c, %.o, $(src)) # 将所有 .c 文件转换为对应的 .o 文件名myArgs = -Wall -g # 编译参数：显示所有警告并生成调试信息ALL: a.out # 默认目标$(obj): %.o: %.c    gcc -c $&lt; -o $@ $(myArgs) # 编译每个 .c 文件为 .o 文件并加入编译参数a.out: $(obj)    gcc $^ -o $@ $(myArgs) # 链接所有 .o 文件生成最终可执行文件 a.outclean:    rm -rf $(obj) a.out # 清理所有生成的文件.PHONY: clean ALL # 声明伪目标，避免与同名文件冲突\n\nexportexport 是 GNU Make 中一个非常重要的指令，它的核心作用是控制变量如何从一个 Makefile 传递到它的子 Make 进程中。\n为什么需要 export？\n在大型项目中，我们通常会将代码和 Makefile 分散在不同的子目录中。顶层的 Makefile 负责调用子目录中的 Makefile 来完成局部的编译任务。这种通过一个 make 进程调用另一个 make 进程的方式，被称为递归 Make (Recursive Make) 或子 Make (Sub-make)。\n这时就出现了一个问题：默认情况下，父 Makefile 中定义的变量，在子 Make 进程中是不可见的。export 指令就是为了解决这个问题而存在的。\nexport 的作用与 Shell 脚本中的 export 命令非常相似。它将一个 Make 变量“导出”为一个环境变量，这个环境变量对 make 启动的所有子进程（包括 Shell 命令和子 Make 进程）都是可见的。\n当顶层 make 调用子目录的 make 时, make 会为这个子 make 命令创建一个新的进程。在创建这个子进程之前，make 会将所有通过 export 指令导出的变量设置到该子进程的环境中。\n子 make 进程启动后，会从它的环境中读取这些变量，并将它们当作自己在 Makefile 中定义的变量来使用。\n简而言之：export 是父 Makefile 向子 Makefile 传递变量的桥梁。\nexport 的使用示例假设我们有一个简单的项目结构如下：\n项目结构:project/├── Makefile          # 顶层 Makefile└── subdir/    ├── main.c    └── Makefile      # 子 Makefile\n不使用 export 的顶层 Makefile 可能如下所示：\n# 顶层 MakefileCC = gccCFLAGS = -Wall -gall:\t$(MAKE) -C subdir\n子 Makefile 可能如下所示：\n# 子 Makefileall: mainmain: main.c\t$(CC) $(CFLAGS) -o main main.cclean:\trm -f main\n在这个例子中，顶层 Makefile 定义了编译器 (GCC)和编译选项 (CFLAGS)，但是子 Makefile 并不知道这些变量，因为它们没有被传递过去。\n如果我们想让子 Makefile 使用顶层 Makefile 中定义的变量，我们可以使用 export 指令：\n# 顶层 Makefileexport CC = gccexport CFLAGS = -Wall -gall:\t$(MAKE) -C subdir\n现在，当顶层 Makefile 调用子 Makefile 时，子 Makefile 可以访问 CC 和 CFLAGS 变量，并使用它们来编译代码。\n不同语法形式\n先定义，后导出: VAR = valueexport VAR\n这种方式最清晰，易于阅读和维护。\n定义时直接导出:export VAR = value\n全部导出:export\n如果 export 后面不跟任何变量名，它会导出当前 Makefile 中定义的所有变量。这通常被认为是不良实践，因为它可能会意外地将一些不希望传递的内部变量传递给子 Make，导致难以调试的错误。明确地导出需要的变量是更好的选择。\n\n与 export 相对的是 unexport，它用于取消一个变量的导出。\n如果一个变量是通过环境传入 make 的（例如，你在 shell 中 export CFLAGS=”-O3”），make 默认会把它再次 export 给子 Make。如果你不希望某个子 Make 继承这个环境变量，就可以使用 unexport。\n","categories":["system","linux"],"tags":["system"]},{"title":"互斥量和原子操作解决多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/3.%20%E4%BA%92%E6%96%A5%E9%87%8F%E5%92%8C%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E8%A7%A3%E5%86%B3%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB/","content":"在多个线程中共享数据时，需要注意线程安全问题。如果多个线程同时访问同一个变量，并且其中至少有一个线程对该变量进行了写操作，那么就会出现数据竞争问题。数据竞争可能会导致程序崩溃、产生未定义的结果，或者得到错误的结果。为了避免数据竞争问题，需要使用同步机制来确保多个线程之间对共享数据的访问是安全的。常见的同步机制包括互斥量、条件变量、原子操作等。\n互斥量问题的根源：竞争条件 (Race Condition)在介绍解决方案之前，我们必须清晰地理解问题所在。当多个线程同时访问和修改同一个共享数据时，就会产生竞争条件。我们来看一个最经典的例子：多个线程同时对一个全局计数器进行递增操作。\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;int g_counter = 0; // 全局共享变量void increment() {    for (int i = 0; i &lt; 100000; ++i) {        g_counter++; // &lt;--- 问题的核心：临界区    }}int main() {    std::vector&lt;std::thread&gt; threads;    for (int i = 0; i &lt; 10; ++i) {        threads.push_back(std::thread(increment));    }    for (auto&amp; th : threads) {        th.join();    }    // 理论上，10个线程每个加10万次，结果应该是 1,000,000    // 但实际运行结果会是一个小于一百万的随机数    std::cout &lt;&lt; \"Final counter value: \" &lt;&lt; g_counter &lt;&lt; std::endl;         return 0;}\n实际结果出错的原因在于,  g_counter++ 这一行代码在底层并不是一个原子操作 (Atomic Operation)。它至少包含三个步骤：\n\n读取 (Read)：从内存中读取 g_counter 的当前值到一个CPU寄存器。\n修改 (Modify)：在CPU寄存器中将该值加 1。\n写入 (Write)：将寄存器中的新值写回到内存中的 g_counter。\n\n想象一下两个线程同时执行的场景：\n\n线程A 读取 g_counter 的值（假设为 100）到它的寄存器。\n在线程A修改之前, 线程B 也读取 g_counter 的值（此时内存中仍然是 100）到它的寄存器。\n线程B 在自己的寄存器中加 1（变为 101），并将其写回内存。现在 g_counter 的值是 101。\n由于线程运行的异步性, 此时线程A才对它自己的寄存器（值仍然是 100）加 1，得到 101。\n线程A 将 101 写回到内存。g_counter 的值仍然是 101。\n\n最终结果： 两个线程都执行了 ++ 操作，但计数器只增加了 1。这就是数据竞争导致的最终结果不一致。这块访问共享资源的代码 g_counter++，我们称之为临界区 (Critical Section)。我们的目标就是保护它。\n解决方案：互斥量 (std::mutex)互斥量，顾名思义，就是互斥访问 (Mutual Exclusion)。它就像一把锁，用来保护一段代码（临界区）。其基本规则如下：\n\n一个线程想要进入临界区，必须先拿到互斥量(锁)。如果锁被其他线程占用，当前线程就会阻塞等待，直到锁被释放。\n如果锁可用，当前线程就会拿到锁，进入临界区执行操作。\n在此期间，如果其他线程也想进入，它们会发现锁被占用，只能在外面阻塞等待，直到锁被释放。\n第一个线程执行完临界区代码后，会释放锁 (unlock)，把锁放回原处。\n等待的线程中会有一个拿到锁，进入临界区执行操作。\n\n通过这种方式，我们保证了在任何时刻，只有一个线程能进入临界区。\n互斥量的基本使用首先需要引入头文件: #include &lt;mutex&gt;\n手动调用 lock() 和 unlock()这是最基本的使用方式，需要在临界区代码前后手动调用 lock() 和 unlock() 方法。\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;mutex&gt;int g_counter = 0;std::mutex g_mutex; // 创建一个全局互斥量void safe_increment() {    for (int i = 0; i &lt; 100000; ++i) {        g_mutex.lock();   // 在访问共享数据前加锁        g_counter++;        g_mutex.unlock(); // 在访问结束后解锁    }}// ... main 函数与之前相同，只是调用 safe_increment\n但这种手动管理的方式有致命缺陷：如果在 lock() 和 unlock() 之间发生异常，unlock() 就永远不会被调用，导致互斥量被永久锁定，所有其他等待该锁的线程都会被无限期阻塞，这被称为死锁 (Deadlock)。\nstd::lock_guard (推荐的现代方法)为了解决手动解锁的风险，C++ 标准库提供了 std::lock_guard，它完美地利用了 RAII (Resource Acquisition Is Initialization，资源获取即初始化) 的思想。\nstd::lock_guard 是一个类模板，它的工作方式是：\n\n在构造时：它会自动接收一个 std::mutex 对象，并在构造函数调用该对象的 lock() 方法。\n在析构时：当 lock_guard 对象离开其作用域时（例如，在代码块 {} 的末尾），它的析构函数会自动被调用，并在析构函数中调用 unlock() 方法。\nstd::lock_guard对象不能复制或移动，因此它只能在局部作用域中使用。\nstd::lock_guard 的职责是在其生命周期内“拥有”一个互斥锁。如果它能被复制，那么我们就会有两个 lock_guard 对象都认为自己拥有同一个锁。当这两个对象离开作用域时，它们的析构函数都会尝试去调用 unlock()。对一个已经解锁的互斥量再次解锁是未定义行为，会导致程序错误。因此，从逻辑上讲，复制 lock_guard 是不安全的，所以 C++ 禁止了这种行为。\n“移动”一个对象意味着将资源的所有权从一个对象转移到另一个对象。如果 std::lock_guard 可以被移动（例如，从一个函数返回），那么“解锁”这个行为的发生地点就不再是创建锁的那个原始、清晰的局部作用域了，而是转移到了一个不确定的新作用域。std::lock_guard 的设计目标就是简单和绝对的安全。它的理念是：“锁在哪里创建，就必须在哪里被释放，绝不允许所有权转移”。禁止移动特性，就是为了强制执行这种简单、可预测、不会出错的模式。\n正是因为 std::lock_guard 不能被复制或移动，它的应用场景就被严格地限制在了创建它的那个局部作用域 (local scope) 内。这意味着你不能将 std::lock_guard 作为函数参数按值传递; 不能从一个函数返回一个 std::lock_guard 对象; 不能把它存入一个容器（如 std::vector）; 也不能把它作为一个类的成员变量，然后在不同实例间赋值或转移。\n这个限制不是一个缺陷，而是一个特性。它通过牺牲灵活性来换取极致的简单和安全，杜绝了因锁的所有权混乱而导致的死锁或未定义行为。它是一个“做一件事并把它做到完美”的工具。****\n\n\n\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;mutex&gt;int g_counter = 0;std::mutex g_mutex;void best_safe_increment() {    for (int i = 0; i &lt; 100000; ++i) {        // 创建 lock_guard 对象，它在构造时自动锁住 g_mutex        std::lock_guard&lt;std::mutex&gt; lock(g_mutex);                g_counter++;                // 当 lock 对象离开这个作用域时（for循环的本次迭代结束），        // 它的析构函数会自动调用 g_mutex.unlock()        // 即使 g_counter++ 抛出异常，也能保证解锁！    }}// ... main 函数与之前相同，只是调用 best_safe_increment\n需要注意的是, 我们应该保持临界区简短：加锁会阻塞其他线程，影响并发性能。因此，被锁定的代码块应该尽可能小，只包含必要的操作，然后尽快释放锁\nstd::unique_lock (推荐的现代方法)std::unique_lock 是一个更强大、更灵活的锁管理器。它与 std::lock_guard 的核心区别在于：std::unique_lock 实现了可移动 (movable) 的所有权语义，并提供了更丰富的手动操作接口。\n可移动，不可复制 (Movable, Non-copyable): std::unique_lock 像 std::unique_ptr 一样，遵循唯一所有权模型。你不能复制它，但可以移动它，从而实现锁的所有权转移。\nstd::unique_lock&lt;std::mutex&gt; create_lock() {    std::unique_lock&lt;std::mutex&gt; u_lock(g_mutex);    // ... do something ...    return u_lock; // 所有权被转移出去 (隐式移动)}void another_function() {    std::unique_lock&lt;std::mutex&gt; received_lock = create_lock();    // 现在 received_lock 拥有锁，当它离开作用域时会负责解锁}\n\n延迟锁定 (Deferred Locking): std::lock_guard 在构造时必须锁定。而 std::unique_lock 可以选择在构造时不锁定，之后再手动锁定。\nstd::unique_lock&lt;std::mutex&gt; u_lock(g_mutex, std::defer_lock);// 此时互斥量 g_mutex 并未被锁定// ... 在未来的某个时刻 ...u_lock.lock(); // 手动加锁\n\n手动控制: std::unique_lock 允许你在其生命周期内手动调用 lock() 和 unlock()。这允许你实现更细粒度的锁定策略：在不需要锁的时候提前释放它，以提高并发性。\nstd::unique_lock&lt;std::mutex&gt; u_lock(g_mutex); // 立即锁定// ... 执行一小部分需要锁的代码 ...u_lock.unlock(); // 提前解锁，让其他线程可以工作// ... 执行很长的、不需要锁的代码 ...u_lock.lock(); // 再次加锁// ... 执行另一部分需要锁的代码 ...// 函数结束时，如果 u_lock 仍持有锁，RAII 机制会保证它被解锁\n\n与条件变量 (std::condition_variable) 配合使用: 这是 std::unique_lock 最重要的用途。条件变量的 wait() 方法要求传入一个 std::unique_lock。因为它需要在等待时原子地解锁互斥量，并在被唤醒后自动重新加锁。std::lock_guard 无法提供这种手动解锁和重新加锁的灵活性。\n死锁 (Deadlock) 问题死锁是指两个或多个线程在执行过程中，因争夺资源而造成的一种互相等待的僵局。在这种状态下，如果没有外力干预，这些线程都将无法向前推进，导致整个程序或系统的相关部分被“冻结”。而在编程中, 死锁争夺的资源就是互斥量 (mutex)。\n例如下列代码\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;std::mutex mutex_A;  // 互斥量 Astd::mutex mutex_B;  // 互斥量 Bint account_A = 1000;int account_B = 2000;// 线程1: 尝试从 A 转账到 Bvoid transfer_A_to_B() {    mutex_A.lock(); // 1. 成功锁住 mutex_A    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // 模拟一些操作    mutex_B.lock(); // 3. 尝试锁住 mutex_B，但它被线程2持有，于是线程1开始阻塞等待    // ... 转账操作 ...    mutex_A.unlock();    mutex_B.unlock();}// 线程2: 尝试从 B 转账到 Avoid transfer_B_to_A() {    mutex_B.lock(); // 2. 成功锁住 mutex_B    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // 模拟一些操作    mutex_A.lock(); // 4. 尝试锁住 mutex_A，但它被线程1持有，于是线程2开始阻塞等待    // ... 转账操作 ...    mutex_B.unlock();    mutex_A.unlock();}int main() {    std::thread t1(transfer_A_to_B);    std::thread t2(transfer_B_to_A);    t1.join();    t2.join();    std::cout &lt;&lt; \"All transfers finished.\\n\"; // 这句话可能永远不会被打印    return 0;}\n上述示例的结局是线程1 持有 mutex_A，等待 mutex_B; 线程2 持有 mutex_B，等待 mutex_A。两个线程都将永远等待下去，程序被挂起。\n死锁的四个必要条件一个死锁的发生，必须同时满足以下四个条件（被称为“Coffman条件”）：\n\n互斥条件 (Mutual Exclusion)：资源不能被共享，在任意时刻，一个资源只能被一个线程持有。 (互斥量天生就满足此条件)\n持有并等待条件 (Hold and Wait)：一个线程至少持有一个资源，并且正在请求其它线程持有的资源。 (例如，线程1持有A，等待B)\n不可剥夺条件 (No Preemption)：资源不能被强制地从一个线程中抢占，只能由持有它的线程自愿释放。 (你不能强制线程1释放mutex_A)\n循环等待条件 (Circular Wait)：存在一个线程的等待链，使得 P1 等待 P2 的资源，P2 等待 P3 的资源，… ，Pn 等待 P1 的资源，形成一个环路。 (我们的例子中 T1 -&gt; T2 -&gt; T1 就是一个环)\n\n避免死锁的方法避免死锁的思路就是破坏这四个条件中的至少一个, 最常见和最实用的方法是破坏“循环等待”条件。\n\n按固定顺序加锁 (最常用的方法)这是解决死锁问题的黄金法则。规定程序中所有需要同时锁住多个互斥量的地方，都必须严格按照相同的全局顺序来获取锁。\n\n例如，我们可以规定，总是先锁地址较小的那个互斥量。\n// 假设 mutex_A 的地址 &lt; mutex_B 的地址void safe_transfer() { // 两个线程都调用这一个函数    // 总是先锁地址较小的 mutex_A，再锁地址较大的 mutex_B    std::lock_guard&lt;std::mutex&gt; lock_a(mutex_A);     std::this_thread::sleep_for(std::chrono::milliseconds(10));    std::lock_guard&lt;std::mutex&gt; lock_b(mutex_B);    // ... 执行转账操作 ...}\n在这个修正版中，无论是A到B还是B到A的转账，都会先尝试锁mutex_A，再尝试锁mutex_B。这样，当一个线程成功锁住mutex_A后，另一个线程会因为无法锁住mutex_A而直接等待，它根本没有机会去锁住mutex_B，因此循环等待的条件被破坏，死锁不会发生。2. 使用 std::lock (C++11/17 推荐)手动管理锁的顺序可能很复杂且容易出错。C++标准库提供了一个完美的工具 std::lock，它可以一次性原子地锁住多个互斥量，并且内部实现了避免死锁的算法。\nvoid best_safe_transfer() {    // std::lock 会以一种避免死锁的方式锁住两个互斥量    std::lock(mutex_A, mutex_B);    // 使用 std::adopt_lock 参数告诉 lock_guard，互斥量已经被锁住，    // 它只需要负责在析构时解锁即可。    std::lock_guard&lt;std::mutex&gt; guard_a(mutex_A, std::adopt_lock);    std::lock_guard&lt;std::mutex&gt; guard_b(mutex_B, std::adopt_lock);    // ... 执行转账操作 ...}\n这是目前处理多个互斥量加锁问题的最安全、最推荐的方案。\n\n其他策略\n\n\n破坏“持有并等待”：尝试一次性获取所有需要的锁（std::lock就是这样做的），如果不能，就释放所有已持有的锁并重试。这可以使用 std::unique_lock 的 try_lock 方法实现，但逻辑更复杂。\n减少锁的粒度：尽量不要长时间持有锁，尤其不要在持有锁的时候做耗时操作（如文件I/O），让临界区尽可能小。\n避免嵌套锁：尽量避免在一个锁的作用域内再去获取另一个锁，如果不可避免，请严格遵守加锁顺序。\n\n原子操作上述属于传统的解决方案, 即是使用互斥锁 (std::mutex) 来保护共享数据，确保同一时间只有一个线程可以访问 counter。然而，互斥锁是操作系统层面的同步原语，涉及系统调用，可能会导致线程阻塞和上下文切换，开销相对较大。\nstd::atomic 提供了一种更轻量级、更底层的解决方案。它利用现代 CPU 提供的特殊原子指令（如 LOCK CMPXCHG），在硬件层面保证单个操作的原子性 (Atomicity)，从而避免数据竞争，且通常比互斥锁性能更高。\nstd::atomic 是一个模板类，它包装了一个 T 类型的值，并确保对这个值的所有操作都是原子的。原子操作是指一个从所有其他线程的角度来看不可分割的操作。它要么完全执行，要么完全不执行，不存在任何中间状态被其他线程观察到。\n\nstd::atomic 定义在  头文件中。\n\n基本用法与操作#include &lt;atomic&gt;std::atomic&lt;int&gt; atomic_counter(0);  // 声明一个原子整数并初始化为 0std::atomic&lt;bool&gt; is_ready(false);  // 声明一个原子布尔值并初始化为 false\nstd::atomic 的成员函数可以分为几类：\n\n写入与读取 (Store and Load)\nstore(value): 原子地将 value 写入原子对象(也就是赋值)。\nload(): 原子地读取原子对象的值(也就是取值)。\n常用的赋值和读取操作符被重载，通常会调用这两个函数。\n\n\n读-修改-写 (Read-Modify-Write, RMW) 操作: 这是 std::atomic 最强大的功能，它将读取、修改、写入三个步骤合并为一个不可分割的原子操作。\nexchange(value): 原子地将原子对象的值替换为 value，并返回替换前的旧值。\nfetch_add(arg), fetch_sub(arg): 原子地给当前值加上/减去 arg，并返回操作前的旧值。重载的 ++, –, +=, -= 等操作符通常调用它们。\n\n\ncompare_exchange_strong(expected, desired) / compare_exchange_weak(expected, desired): 这是最核心的 RMW 操作（比较并交换，CAS）。工作流程：\n比较原子对象的当前值与 expected 的值。\n如果相等，则将原子对象的值修改为 desired，并返回 true。\n如果不相等，则将 expected 的值更新为原子对象的当前值，并返回 false。\nstrong vs weak: strong 保证如果值相等，交换就一定成功。weak 版本在某些平台上性能更好，但即使值相等也可能“伪失败”（spurious failure），即返回 false。因此 weak 版本通常用在循环中。\n\n\n\n\n\natomic_counter.store(10); // 等同于 atomic_counter = 10;int current_val = atomic_counter.load(); // 等同于 int current_val = atomic_counter;// 解决最开始的计数器问题std::atomic&lt;int&gt; counter(0);counter++; // 原子操作，不会产生数据竞争std::atomic&lt;int&gt; val(10);int expected = 10;int desired = 20;// 尝试将 val 从 10 原子地更新为 20if (val.compare_exchange_strong(expected, desired)) {    // 成功，val 现在是 20} else {    // 失败，可能是因为其他线程修改了 val    // 此时 expected 的值会被更新为 val 的当前值}\n\n内存序 (Memory Ordering)原子性仅仅保证了单个操作的不可分割性，但并未规定该操作与其他内存读写操作之间的顺序。为了性能，编译器和 CPU 可能会对指令进行重排序。在单线程中，这毫无问题。但在多线程中，这种重排可能会导致灾难性的后果。\n// 共享变量int shared_data = 0;std::atomic&lt;bool&gt; data_ready = false;// 线程 A: 生产者void producer() {    shared_data = 42;                   // 操作 A    data_ready.store(true);             // 操作 B}// 线程 B: 消费者void consumer() {    if (data_ready.load()) {            // 操作 C        assert(shared_data == 42);      // 操作 D    }}\n从程序员的逻辑来看，producer 中 A 操作一定先于 B 操作。consumer 只有在 C 操作读到 true 之后，才会执行 D 操作。因此，assert 应该永远不会失败。\n但现实是, 编译器或 CPU 可能会认为操作 A 和 B 互不依赖，为了优化，可能会将它们的执行顺序重排。producer 的实际执行顺序可能变成：\n// 重排后的生产者void producer_reordered() {    data_ready.store(true);             // 操作 B    shared_data = 42;                   // 操作 A}\n也就是当线程 B 执行 assert(shared_data == 42)时, shared_data 还是 0，断言失败！\n内存序就是用来约束这种重排序，确保多线程间操作的可见性顺序。它的本质是一种内存屏障。内存屏障是一种指令，它告诉编译器和 CPU：“任何指令都不能跨越我这个屏障进行重排”。\nstd::memory_order 枚举定义了六种内存序模型：\n\n宽松序 (std::memory_order_relaxed):最弱的内存序, 只保证当前原子操作的原子性，不提供任何额外的同步或排序保证。其他线程可能以任意顺序观察到内存的修改, 指令可以在任意时间点执行, 也可以被重排。\n\n适用场景: 只关心单个原子变量的修改，不依赖它来同步其他数据。例如，简单地增加一个计数器，只在最后才读取它的值。\n\n\n获取-释放语序 (Acquire-Release Semantics): 这是实现线程间同步最常用的模型，通常成对出现。\n\nstd::memory_order_release:用于写入/存储操作。它确保在当前线程中，所有位于此 release 操作之前的内存写入（无论是原子还是非原子的），对于在其他线程中对同一个原子变量执行 acquire 操作的线程都是可见的, 换句话说, 它是一个向上的屏障, 在此 release 操作之前的所有内存写入，都不能被重排到这个操作之后(编译期)。\n实际上, 这个命令还有硬件层面的含义, 即将执行该指令的CPU核心（例如核心A）的缓存中，所有在此之前的写入（包括 shared_data = 42），刷新到共享内存系统中。\n\n\nstd::memory_order_acquire:用于读取/加载操作。它确保在当前线程中，所有位于此 acquire 操作之后的内存读取，都能看到由其他线程中对同一个原子变量执行 release 操作的线程所写入的数据。换句话说, 它是一个向下的屏障, 在此 acquire 操作之后的所有内存读取，都不能被重排到这个操作之前。\n在硬件层面, 执行该指令的CPU核心（例如核心B）在加载 shared_data 的值时，先使自己的本地缓存无效 (invalidate)，然后去共享内存系统中获取最新的值。\n\n\nstd::memory_order_acq_rel:用于读-修改-写操作，同时具备 acquire 和 release 的特性。\n\n\n顺序一致性 (std::memory_order_seq_cst):最强的内存序，也是默认的内存序。它不仅提供 acquire-release 的所有保证，还额外保证所有线程都以相同的顺序观察到所有 seq_cst 操作。它在所有线程之间建立了一个单一的、全局的操作总顺序。这个最容易理解，但通常也是性能开销最大的，因为它限制了编译器和 CPU 的优化能力。\n\n\n对比\n\n\n特性\nstd::atomic\nstd::mutex\n\n\n\n保护对象\n单个变量 (如int, bool, 指针)\n一段代码块 (临界区)，可包含多个变量和复杂逻辑\n\n\n实现原理\n通常是硬件级别的原子指令 (无锁)\n通常是操作系统级别的内核对象 (可能涉及线程阻塞)\n\n\n性能开销\n较低，适合高频访问\n较高，不适合高频、短小的临界区\n\n\n使用场景\n简单的标志位、计数器、指针等细粒度同步\n保护复杂数据结构或一系列必须整体执行的操作\n\n\n死锁风险\n无\n有 (如果加锁顺序不当)\n\n\n当需要保护的是一个独立的、简单的内置类型（如标志、计数器）时，优先使用 std::atomic。\n当需要保护一个复杂的数据结构（如 std::vector）或需要将一系列操作（例如，从一个 vector 中移除元素并更新大小）作为一个不可分割的事务来执行时，必须使用 std::mutex。\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"Thread线程库的基本使用","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1.%20Thread%E7%BA%BF%E7%A8%8B%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","content":"C++11 标准的发布是一个里程碑，它首次将线程支持纳入了标准库。这意味着开发者终于可以编写跨平台的、标准化的多线程程序了。在使用 std::thread 之前，必须包含头文件 : #include &lt;thread&gt;\n创建和启动线程在 C++11 中，创建一个 std::thread 对象的同时，新线程就已经开始执行了, 同时主线程立即、不阻塞地继续往下执行,** 新线程和主线程并行**执行(这就有可能导致两个线程流同时执行而引发的资源竞争问题)\nstd::thread 的构造函数接受一个可调用对象（如函数、Lambda表达式、函数对象等）作为线程的入口点，后面跟着传递给该可调用对象的所有参数, 即std::thread t(function_name, args...);例如, 下面的例子传入thread的是一个函数\n#include &lt;iostream&gt;#include &lt;thread&gt;// 线程要执行的函数void task() {    std::cout &lt;&lt; \"Hello from a new thread!\" &lt;&lt; std::endl;}int main() {    // 1. 创建一个 thread 对象 t，并传入函数名 task    // 2. 线程 t 立刻开始执行 task() 函数    std::thread t(task);    // 等待线程 t 执行完毕（后面会详细讲）    t.join();     return 0;}\n我们也可以直接传入lambda表达式\n#include &lt;iostream&gt;#include &lt;thread&gt;int main() {    // 直接将 Lambda 表达式作为参数传递    std::thread t([]() {        std::cout &lt;&lt; \"Hello from a lambda thread!\" &lt;&lt; std::endl;    });    t.join();    return 0;}\n\n等待线程完成 (join)当你需要确保一个线程在主线程继续执行之前完成它的所有工作时，就需要使用 join() 方法。join() 的行为是：阻塞调用它的线程（例如主线程），直到被调用的线程（例如 t）执行结束。\n使用阻塞的好处是, 一方面可以实现同步：确保子线程的工作成果在主线程的后续步骤中是可用的; 另一方面也确保资源安全：防止主线程退出导致整个进程结束，而子线程可能还在执行，从而被强行终止。\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;void long_running_task() {    std::cout &lt;&lt; \"Task started...\" &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(2)); // 模拟耗时操作    std::cout &lt;&lt; \"Task finished!\" &lt;&lt; std::endl;}int main() {    std::thread t(long_running_task);    std::cout &lt;&lt; \"Main thread is waiting for the task to finish.\" &lt;&lt; std::endl;    t.join(); // 主线程会在这里阻塞，直到 long_running_task 执行完毕    std::cout &lt;&lt; \"Task has been joined. Main thread continues.\" &lt;&lt; std::endl;    return 0;}\n一个 std::thread 对象只能被 join 一次。调用 join() 后，该线程对象不再与任何活动的执行线程相关联，其状态变为“不可加入” (joinable() 会返回 false)。\n检查线程是否可加入 (joinable)joinable()方法返回一个布尔值，如果线程可以被 join()或 detach()，则返回true，否则返回 false。如果我们试图对一个不可加入的线程调用 join()或 detach()，则会抛出一个 std::system_error异常。\n下面是更安全的做法:\n#include &lt;iostream&gt;#include &lt;thread&gt;void foo() {        std::cout &lt;&lt; \"Thread started\" &lt;&lt; std::endl;}int main() {        std::thread t(foo);        if (t.joinable()) {        t.join();        }        std::cout &lt;&lt; \"Thread joined\" &lt;&lt; std::endl;        return 0;}\n\n分离线程 (detach)如果你不关心线程何时结束，也不需要等待它的结果，你可以选择“分离”它。\ndetach() 的行为是：将 std::thread 对象与实际执行的线程“断开连接”。 之后，这个线程会在后台独立运行，而 std::thread 对象本身不再代表这个线程。\n其优点在于, 主线程无需等待，可以立即继续执行自己的任务。\n但是同样具有风险：你失去了对该线程的控制。你无法再 join 它。更重要的是，如果主线程（或整个程序）退出了，所有分离的线程都会被操作系统粗暴地终止，不管它们是否完成了任务。这可能导致资源泄露或数据损坏。\n例如, 你有一个分离的线程，它的任务是向一个文件中写入 1000 行日志\nvoid log_writer_task() {    std::ofstream log_file(\"my_app.log\");    for (int i = 0; i &lt; 1000; ++i) {        log_file &lt;&lt; \"Log entry \" &lt;&lt; i &lt;&lt; std::endl;        // 假设在这里有一些微小的延迟    }    // 正常情况下，函数结束时 log_file 的析构函数会自动关闭文件}int main() {    std::thread logger(log_writer_task);    logger.detach(); // 分离日志线程    std::cout &lt;&lt; \"Main function finished quickly!\" &lt;&lt; std::endl;    return 0; // main函数立即退出}\n当logger 线程被创建并分离，开始向 my_app.log 文件写入数据。然而 main 函数执行得非常快，几乎立刻就结束了, 此时进程开始关闭，操作系统发现 logger 线程还在运行，于是强行终止它。一种可能是情况是 logger 线程只写入了 150 行日志，就被终止了, 造成数据损坏。\n再例如, 一个分离的线程在堆上分配了内存，或者获取了一个数据库连接。\nvoid resource_task() {    // 1. 获取资源    DatabaseConnection* db_conn = new DatabaseConnection(\"my_db\");        // 2. 使用资源执行一些操作    db_conn-&gt;executeQuery(\"UPDATE users SET last_login = NOW() WHERE id = 1;\");    // 3. 释放资源    delete db_conn; // 关键的清理步骤}int main() {    std::thread t(resource_task);    t.detach();    // main 很快结束    return 0;}\nmain 函数很可能在 resource_task 线程执行到 delete db_conn; 之前就退出了, 线程被终止, 导致delete db_conn; 这行代码永远没有机会被执行, 造成资源泄露.\n因此，使用 detach 的基本原则是：只对那些执行非常简单、不访问共享数据、不涉及需要清理的资源，并且允许被随时终止的“辅助性”任务使用。 对于任何核心的、需要确保完成的任务，都应该使用 join()。\nRAII 与 std::thread 的所有权一个非常重要的规则是：一个 std::thread 对象在析构时，如果它仍然是 joinable()（即既没有被 join 也没被 detach），那么程序的行为是调用 std::terminate()，导致程序崩溃。\n这是为了防止开发者忘记处理线程而导致的资源泄露和未定义行为。\n// 错误示例：将导致程序崩溃void problematic_function() {    std::thread t([]() { /* do something */ });    // 函数结束时，t 将被析构    // 因为 t 既没有 join 也没有 detach，程序会调用 std::terminate}\n这强制我们必须对创建的每一个 std::thread 对象负责，在其生命周期结束前，明确地调用 join() 或 detach()。这种思想也体现了 C++ 的 RAII（Resource Acquisition Is Initialization，资源获取即初始化） 原则。\nthread_local 变量C++11 引入了 thread_local 关键字，用于创建线程私有的、具有静态生命周期的变量。。每个线程都会有自己独立的 thread_local 变量实例，互不干扰。\n线程私有性 (Thread Privacy): 这是 thread_local 最核心的特性。每个线程都拥有变量的独立实例。一个线程对它的 thread_local 变量进行任何修改，都绝对不会影响到其他线程中的同名变量。\n静态存储期 (Static Storage Duration): thread_local 变量的生命周期与它所在的线程绑定。它在线程首次使用该变量时被创建和初始化，并在线程结束时被销毁。这意味着，对于一个特定的线程，这个变量的值在函数调用之间是持久的。\n使用范围 (Usage Scope): thread_local 可以用于修饰命名空间作用域的变量（全局变量）、文件静态变量、函数静态变量以及类的静态成员变量。它不能用于修饰非静态的局部变量或类的非静态成员。\n它非常适合用于解决那些“需要全局访问，但又不希望线程间共享”的场景，例如：\n\n线程安全的计数器或日志记录器。\n每个线程独立的随机数生成器（避免锁和种子问题）。\n线程级别的缓存或错误码。\n\n\n在 thread_local 出现之前，我们在多线程编程中处理变量时面临一个两难的境地：\n全局变量/静态变量：\n\n优点：生命周期是整个程序，可以在任何函数中访问。\n\n缺点：所有线程共享同一个实例。如果多个线程同时修改它，就会产生竞争条件 (Race Condition)，必须使用互斥锁 (std::mutex) 等同步机制来保护，这会增加代码复杂性并降低性能。\n\n\n局部变量：\n\n优点：位于函数栈上，是线程私有的，不存在竞争问题。\n\n缺点：生命周期仅限于函数的单次调用。函数返回后，变量就被销毁了，无法在多次函数调用之间为同一个线程保持状态。\n\n\n这时就出现了一个需求空白：如果我需要一个变量，它能像全局变量一样在多次函数调用间保持自己的状态，但又希望它像局部变量一样是线程私有的，避免加锁，该怎么办？\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;// 声明一个线程局部变量thread_local int thread_id = 0;void thread_function(int id) {    thread_id = id; // 每个线程设置自己的 thread_id    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 模拟工作    std::cout &lt;&lt; \"Thread \" &lt;&lt; id &lt;&lt; \" has thread_local id: \" &lt;&lt; thread_id &lt;&lt; std::endl;}int main() {    std::thread t1(thread_function, 1);    std::thread t2(thread_function, 2);    std::thread t3(thread_function, 3);    t1.join();    t2.join();    t3.join();    return 0;}\n上述代码中，虽然所有线程都访问同一个 thread_local 变量 thread_id，但每个线程都有自己独立的实例。线程 1 设置 thread_id 为 1，线程 2 设置为 2，线程 3 设置为 3。它们互不干扰，输出结果会显示每个线程的独立值。\n同时, 虽然 thread_local 名称中有 “local” 一词, 但它并不是局部变量。它的作用域仍然是声明它的文件或函数内，但它的生命周期是整个线程的运行期间。每个线程在第一次访问 thread_local 变量时，都会初始化它，并且在该线程结束时销毁它。\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"条件变量和多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/5.%20%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB/","content":"条件变量 (Condition Variable) 是一种同步原语，它允许一个或多个线程等待（阻塞），直到另一个线程修改了某个共享状态并通知它们。\n它的核心思想不是为了“锁住”资源，而是提供一种“等待-通知” (Wait-Notify) 机制。线程可以高效地等待某个特定条件 (Condition) 变为真，而无需通过循环不断地检查（这种低效的方式称为忙等待 (Busy-Waiting)）。\n为了安全地检查和修改这个共享状态，条件变量必须与一个互斥锁 (Mutex) 协同工作。\n一个典型的条件变量工作流程包含以下三个核心部分：\n\n互斥锁 (std::mutex)：用于保护被检查的共享数据（即“条件”）。\n共享数据/条件：一个或多个线程需要等待其状态发生改变的变量。例如，一个表示任务队列是否为空的布尔值或整数。\n条件变量 (std::condition_variable)：负责阻塞等待线程和唤醒它们。\n\n其主要操作有两个：\n\nwait(lock): 等待操作。调用该函数的线程会执行以下原子操作：\n\n释放传入的 lock（互斥锁）。\n阻塞当前线程，使其进入等待状态。\n当被其他线程通过 notify 唤醒时，它会重新获取 lock，然后 wait 函数才会返回。\n\n\nnotify_one() / notify_all(): 通知操作。\n\nnotify_one(): 唤醒一个正在等待的线程。具体唤醒哪一个是不确定的。\nnotify_all(): 唤醒所有正在等待的线程。\n\n\n\n生产者-消费者模型这是并发编程中最经典的模型之一，用于解耦生产者（创建数据或任务的线程）和消费者（处理数据或任务的线程）。\n\n生产者 (Producer)：负责生成数据并将其放入一个共享的缓冲区（如队列）。\n消费者 (Consumer)：负责从缓冲区中取出数据并进行处理。\n共享缓冲区 (Shared Buffer)：连接生产者和消费者的中间数据结构。\n\n这个模型需要解决以下两个核心同步问题：\n\n缓冲区为空时：消费者不能进行消费，必须等待，直到生产者放入了新的数据。\n缓冲区为满时：生产者不能继续生产，必须等待，直到消费者取走了数据，为新数据腾出空间。\n互斥访问：任何时刻，只能有一个线程（无论是生产者还是消费者）在访问缓冲区，以避免数据损坏。\n\n互斥锁可以解决第3个问题，而条件变量则完美地解决了第1和第2个问题。\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;template&lt;typename T&gt;class BlockingQueue {public:    // 构造函数，指定队列容量    explicit BlockingQueue(size_t capacity) : capacity_(capacity) {}    // 生产者调用：向队列中放入一个元素    void produce(const T&amp; item) {        std::unique_lock&lt;std::mutex&gt; lock(mtx_); // std::unique_lock 是一个 RAII 风格的锁管理器，它在构造时自动加锁，在析构时（即离开作用域时）自动解锁，非常安全        // 等待直到队列不满        // 使用 Lambda 谓词，自动处理虚假唤醒        cond_producer_.wait(lock, [this] {            return buffer_.size() &lt; capacity_;        });        // 将元素放入缓冲区        buffer_.push(item);        std::cout &lt;&lt; \"生产者 \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" 生产了 \" &lt;&lt; item &lt;&lt; \", 队列大小: \" &lt;&lt; buffer_.size() &lt;&lt; std::endl;        // 通知一个等待的消费者        cond_consumer_.notify_one();    }    // 消费者调用：从队列中取出一个元素    T consume() {        std::unique_lock&lt;std::mutex&gt; lock(mtx_);        // 等待直到队列不空, 等待时会释放 lock 锁, 让其他线程有机会修改共享状态        cond_consumer_.wait(lock, [this] {            return !buffer_.empty();        });        // 从缓冲区取出元素        T item = buffer_.front();        buffer_.pop();        std::cout &lt;&lt; \"消费者 \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" 消费了 \" &lt;&lt; item &lt;&lt; \", 队列大小: \" &lt;&lt; buffer_.size() &lt;&lt; std::endl;        // 通知一个等待的生产者        cond_producer_.notify_one();        return item;    }private:    size_t capacity_;    std::queue&lt;T&gt; buffer_;        // 底层使用 std::queue 存储数据（共享资源）    std::mutex mtx_;              // 互斥锁，用于保护对 buffer_ 的访问    std::condition_variable cond_producer_; // 用于生产者等待的条件变量    std::condition_variable cond_consumer_; // 用于消费者等待的条件变量};int main() {    // 创建一个容量为 5 的阻塞队列    BlockingQueue&lt;int&gt; bq(5);    // 创建两个生产者线程    std::thread producer1([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.produce(i);            std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 模拟生产耗时        }    });    std::thread producer2([&amp;]() {        for (int i = 10; i &lt; 20; ++i) {            bq.produce(i);            std::this_thread::sleep_for(std::chrono::milliseconds(150));        }    });    // 创建两个消费者线程    std::thread consumer1([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.consume();            std::this_thread::sleep_for(std::chrono::milliseconds(200)); // 模拟消费耗时        }    });    std::thread consumer2([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.consume();            std::this_thread::sleep_for(std::chrono::milliseconds(250));        }    });    // 等待所有线程结束    producer1.join();    producer2.join();    consumer1.join();    consumer2.join();    return 0;}\n上述示例的cond_producer_.wait(lock, ...)是生产者的核心等待逻辑。wait 函数会检查传入的 Lambda 表达式 [this] { return buffer_.size() &lt; capacity_; }。如果条件为真 (队列不满)：wait 函数立即返回，线程继续向下执行; 如果条件为假 (队列已满)：线程会原子地释放 lock, 进入阻塞/等待状态，等待被 notify 唤醒。\nnotify_one() 的核心作用是唤醒一个正在等待的线程。它就像一个信号，告诉等待中的线程：“你等待的条件可能已经满足了，快醒来检查一下吧！”. 唤醒的线程会重新获取 lock 锁，然后检查条件是否满足。如果条件满足，线程会继续执行；如果条件不满足，线程会再次进入等待状态。\n例如, 如果没有 cond_consumer_.notify_one()，那些因队列为空而睡眠的消费者线程将永远不会知道有新数据到来，它们会一直“睡”下去，导致程序死锁。\n虚假唤醒虚假唤醒指的是，一个正在条件变量上等待 (cv.wait()) 的线程，在没有任何其他线程调用 notify_one() 或 notify_all() 的情况下，被意外地唤醒。\n换句话说，线程“无缘无故”地从等待状态中醒来，但它所等待的那个条件 (Condition) 实际上仍然不满足。\n这是一个真实存在且需要正确处理的并发问题。POSIX 标准和 C++ 标准都明确允许这种情况发生，因此程序员必须在代码中防范它。这种情况出现的原因通常与操作系统内核的线程调度实现有关(例如系统中断：等待中的线程可能会被一些不相关的系统事件（如 POSIX 信号）中断，导致其从内核的等待队列中被唤醒。)\n处理虚假唤醒的“黄金法则”是：永远在循环中调用 wait()。下面的一种错误情况是:\n// 线程可能会在虚假唤醒后错误地继续执行std::unique_lock&lt;std::mutex&gt; lock(mtx);if (buffer_.empty()) {   // 一开始检查过是空, 进入函数体, 等待被 notify 唤醒    cond_consumer_.wait(lock); // 如果在这里被虚假唤醒，if 语句已执行过，不会再次检查, 但是如果是虚假唤醒, 完全有可能还是空}// 危险！程序可能在这里尝试从空队列中取数据T item = buffer_.front();buffer_.pop();\n正确的做法是使用 while 循环来包裹 wait, 确保在被 notify 唤醒后, 条件再次被检查:\nstd::unique_lock&lt;std::mutex&gt; lock(mtx);// 使用 while 循环来包裹 waitwhile (buffer_.empty()) {    cond_consumer_.wait(lock);}// 安全！从 wait 返回后，循环条件会再次被检查。// 只有当 buffer_.empty() 为 false 时，循环才会退出。T item = buffer_.front();buffer_.pop();\n更推荐的做法是使用 wait 的谓词版本: C++ 标准库为我们提供了更优雅的解决方案, wait 函数有一个重载版本，可以接受一个谓词 (Predicate)，通常是一个 Lambda 表达式。\nstd::unique_lock&lt;std::mutex&gt; lock(mtx);// 这个 wait 内部已经为我们实现好了 while 循环// 它只会在 lambda 表达式返回 true 时才会返回cond_consumer_.wait(lock, [this] {     return !buffer_.empty(); });// 绝对安全！T item = buffer_.front();buffer_.pop();\n这个版本在功能上等价于 while 循环，但代码更简洁，意图更清晰，并且能有效避免程序员忘记写循环。\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"线程池","url":"/2025/09/23/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/6.%20%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"线程池 (Thread Pool) 是一种并发设计模式，它预先创建并维护一组可复用的工作线程，而不是在需要时才创建新线程。这些线程“池化”在一起，等待执行分配给它们的任务。\n它的核心思想是将“任务的提交”与“任务的执行”解耦。应用程序的各个部分可以将任务提交给线程池，而无需关心任务具体由哪个线程执行、何时执行。\n一个典型的线程池包含以下几个关键部分：\n\n任务队列 (std::queue)：一个用于存放待执行任务的缓冲区\n它必须是线程安全的。这通常通过一个互斥锁 (std::mutex) 和一个条件变量 (std::condition_variable) 来实现, 这正是我们之前讨论的生产者-消费者模型的完美应用.\n任务提交者是生产者，将任务放入队列。\n工作线程是消费者，从队列中取出任务执行。\n任务类型 (TaskType)：为了让线程池能执行任意类型的任务，通常使用 std::function&lt;void()&gt; 来包装任务。这使得线程池可以接受普通函数、Lambda 表达式、成员函数等任何可调用对象。\n\n\n工作线程 (std::vectorstd::thread)：一组预先创建的、可以循环执行任务的线程。\n线程池管理器 (ThreadPool)：一个类，用于封装整个线程池的逻辑, 负责创建、管理和销毁线程池本身，并向任务队列中添加新任务。\n\n为什么要使用线程池为了理解线程池的价值，我们首先要看看不使用线程池的原始做法有什么问题。原始做法是：“需要时创建，用完后销毁”。\nvoid some_task() { /* ... */ }// 每当有一个新任务，就创建一个新线程std::thread t(some_task);t.join(); // 或者 t.detach();\n这种做法存在两个致命的缺陷：\n\n高昂的资源开销：\n创建开销：线程的创建和销毁是重量级操作，需要调用操作系统内核 API，分配和回收线程栈等内存资源，这个过程相对耗时。\n上下文切换开销：如果任务数量巨大，短时间内创建大量线程，会导致 CPU 在这些线程之间频繁进行上下文切换，这会消耗大量 CPU 时间，反而降低了程序的整体性能。\n\n\n资源耗尽风险：操作系统能够创建的线程数量是有限的。如果不加限制地为每个任务都创建一个线程，当并发请求量激增时，很容易耗尽系统内存和线程资源，最终导致程序崩溃或系统瘫痪。\n\n线程池正是为了解决以上两个问题而生的。\n工作流程\n初始化：\n\n创建一个线程池对象，并指定线程数量（例如，CPU 核心数）。\n线程池立即创建指定数量的工作线程。\n每个工作线程都启动并进入一个无限循环，尝试从任务队列中获取任务。\n\n\n等待任务：由于任务队列初始为空，所有工作线程都会在条件变量上 wait()，进入阻塞状态，等待新任务的到来。它们不消耗 CPU 时间。\n\n提交任务：外部代码（例如 main 函数）调用线程池的 enqueue() 方法，传入一个任务。\n\nenqueue() 方法会获取任务队列的锁，将任务 push 进队列，然后释放锁。\n之后，它调用条件变量的 notify_one()，唤醒一个正在等待的工作线程。\n\n\n执行任务：\n\n被唤醒的线程从 wait() 返回，重新获取锁，从队列中 pop 一个任务，然后释放锁。\n线程开始执行取出的任务。任务执行完毕后，线程不会退出，而是返回到无限循环的开始，再次尝试从任务队列获取下一个任务，如果队列为空，则再次进入等待状态。\n\n\n销毁：\n\n当程序希望关闭线程池时，会调用 shutdown() 方法(或者析构函数)。\n管理器设置一个停止标志位，并调用 notify_all() 唤醒所有工作线程。\n工作线程被唤醒后，检查到停止标志，于是退出无限循环。\n管理器 join() 所有工作线程，等待它们全部安全退出。\n\n\n\n线程池示例#include&lt;iostream&gt;#include&lt;thread&gt;#include&lt;mutex&gt;#include&lt;queue&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;condition_variable&gt;#include&lt;functional&gt;class ThreadPool{public:    ThreadPool(int NumThreads): stop(false){  // 初始化并启动线程池。        for(int i=0;i&lt;NumThreads;i++){            // 这里构造的是多个线程, 因此是并发构造的            threads.emplace_back([this]{  // emplace_back 直接传入参数后自动构造线程对象(就地构造)                while(1){  // while的作用是持续监听任务队列, 让每个工作线程在完成一个任务后，不会立即退出，而是返回到循环的起点，继续尝试从任务队列中获取下一个任务。                    std::unique_lock&lt;std::mutex&gt; lock(mtx); // 有可能要操作任务队列, 所以要加锁                    condition.wait(lock, [this]{                        return !tasks.empty() || stop; // 线程会在此处等待，直到 Lambda 谓词返回 true。在等待期间，lock 会被自动释放，允许其他线程（如 enqueue 函数）获取锁并向队列中添加任务。                    });                    // 线程被唤醒后向下执行                    if(stop&amp;&amp;tasks.empty()) return;                    std::function&lt;void()&gt; task(std::move(tasks.front()));  // 从任务队列中取出一个任务                    tasks.pop();                    lock.unlock(); // 执行任务之前手动解锁。因为任务 task() 的执行可能非常耗时，如果在执行期间一直持有着锁，其他工作线程将无法从队列中获取新任务，会大大降低线程池的并发效率。                    task(); // 执行任务                }            });        }    }    ~ThreadPool(){  // 安全地关闭线程池，确保所有任务执行完毕，所有线程都已退出。        {            std::unique_lock&lt;std::mutex&gt; lock(mtx);            stop = true;        }        condition.notify_all(); // 唤醒所有正在等待的线程。因为有些线程可能因为队列为空而处于睡眠状态，设置 stop 标志后，必须将它们全部唤醒，以便它们能够检查到 stop == true 并进入退出流程。        for(auto&amp; t: threads) t.join();  //遍历所有线程句柄，并对每个线程调用 join()。主线程（执行析构函数的线程）会在此处阻塞，一个一个串行等待, 直到所有工作线程都执行完毕并完全退出。    }    template&lt;class F, class... Args&gt;  // 模板函数使之可以接受任意类型的任务函数和参数    void enqueue(F&amp;&amp; f, Args&amp;&amp; ... args){  // 向线程池提交一个新任务。        // 队列只接受std::function&lt;void()&gt;, 因此使用bind()将所有不同形式的函数调用全部“适配”成了 std::function&lt;void()&gt; 这种统一的、可以被存储在队列中的格式. 当你调用这个新对象时，它会在内部自动用之前绑定的参数去调用原始的函数。        std::function&lt;void()&gt; task = std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);        {            std::unique_lock&lt;std::mutex&gt; lock(mtx); // 加锁, 确保在添加任务到队列时不会被其他线程同时修改            tasks.emplace(std::move(task)); // 将新创建的 task 移动到任务队列 tasks 的末尾。        }        condition.notify_one();  // 通知一个正在 condition.wait() 上等待的工作线程。告诉它“有新任务来了，快醒来工作”。    }private:    std::vector&lt;std::thread&gt; threads;  // 线程容器。存放所有预先创建的工作线程对象。    std::queue&lt;std::function&lt;void()&gt;&gt; tasks; // 任务队列。这是一个线程安全的队列，用于存放待执行的任务。外部代码（生产者）将任务放入此队列，工作线程（消费者）从此队列取出任务。    std::mutex mtx;  // 互斥锁。用于保护对任务队列 tasks 的并发访问，确保线程安全。    std::condition_variable condition;  // 条件变量。用于实现线程间的同步。当任务队列为空时，工作线程在此变量上等待；当新任务被添加时，通过此变量通知等待的线程。    bool stop;  // 停止标志。一个布尔标志，用于通知所有线程池准备关闭，以便它们能够安全退出。};int main(){    ThreadPool pool(4);    for(int i=0;i&lt;10;i++){        pool.enqueue([i]{            std::cout &lt;&lt; \"task :\" &lt;&lt; i &lt;&lt; \"is runing\" &lt;&lt; std::endl;            std::this_thread::sleep_for(std::chrono::seconds(1));            std::cout &lt;&lt; \"task :\" &lt;&lt; i &lt;&lt; \"is done\" &lt;&lt; std::endl;        });    }}","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"异步/并发编程模型","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/7.%20%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","content":"在C++并发编程中，核心挑战之一是在不同线程间安全、高效地传递数据。特别是当一个线程（生产者/Provider）需要将一个计算结果（值或异常）传递给另一个线程（消费者/Consumer）时。std::future, std::promise, std::packaged_task, 和 std::async 共同构成了一个异步编程模型，其设计哲学是关注点分离 (Separation of Concerns)，将任务的执行、结果的传递和线程的管理清晰地解耦。\n核心组件：数据通信的 foundational elementsstd::future 和 std::promise 是实现异步数据传递最基础的两个构建块，它们分别代表了共享状态的“读取端”和“写入端”。\nstd::future：未来的凭证/读取端口std::future 是一个模板类，可以看作是一个异步结果的代理或占位符。当你启动一个异步任务时，你会立即得到一个 std::future 对象。这个对象本身并没有包含计算结果，但它承诺在未来的某个时刻，你可以通过它来获取结果。\n主要操作：\n\nget():这是 std::future 最核心的函数, 它会阻塞当前线程，直到异步任务完成并返回结果（或抛出异常）。\nget() 只能被调用一次。调用后，std::future 对象的状态会变为无效。\n\n\nwait():阻塞当前线程，直到结果可用，但不获取结果. 这个函数可以多次调用。\nwait_for() / wait_until():等待一段时间或等到一个指定的时间点。如果在超时前结果准备好了，它会返回 std::future_status::ready。\nvalid():检查 std::future 对象是否与一个共享状态关联，即是否有效。在调用 get() 之后，valid() 会返回 false。\n\n你不能直接创建一个 std::future，它总是通过以下三种方式之一获得：\n\nstd::promise 的 get_future() 方法。\nstd::packaged_task 的 get_future() 方法。\nstd::async 函数的返回值。\n\nstd::promise：一个承诺/写入端口std::promise 对象可以被看作是一个可以被写入一次的容器，它承诺在未来的某个时刻会提供一个 T 类型的值(或异常), 从而使关联的 std::future 变为就绪状态。\n主要操作:\n\n关联Future: 调用std::future get_future()来创建共享状态，并返回一个与该 promise 相关联的 std::future 对象。此方法对于每个 promise 对象只能调用一次。\n设置结果:\nvoid set_value(const T&amp; value) / void set_value(T&amp;&amp; value): 将一个值存入共享状态，并使关联的 std::future 变为就绪状态。\nvoid set_exception(std::exception_ptr p): 将一个异常存入共享状态，并使关联的 std::future 变为就绪状态。\n这些设置操作同样是一次性的。对同一个 promise 多次调用 set_value 或 set_exception 会抛出异常。\n\n\n\n工作流程：\n\n在发起任务的线程（消费者线程）中创建一个 std::promise 对象。\n消费者线程通过调用 promise.get_future() 来获取一个与之关联的 std::future 对象, 并等待该 future 变为就绪状态。\n消费者线程将 std::promise 对象（通常通过移动 std::move）传递给将要执行异步任务的新线程(生产者线程)。\n通常通过 std::thread 的构造函数传递 promise, 此时工作函数需要接收 promise 对象作为参数。\n\n\n新线程执行计算，当得到结果后，调用 promise.set_value(result) 将结果存入 promise。如果发生错误，可以调用 promise.set_exception(exception_ptr) 来存入一个异常。\n一旦 set_value() 或 set_exception() 被调用，与之关联的 std::future 就会变为“就绪” (ready) 状态。\n此时，在消费者线程中对 future 调用的 get() 将会立即返回结果（或抛出异常），不再阻塞。\n\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;#include &lt;chrono&gt;void compute_task(std::promise&lt;int&gt; p) {    try {        std::cout &lt;&lt; \"Worker thread is performing calculations...\" &lt;&lt; std::endl;        std::this_thread::sleep_for(std::chrono::seconds(2));        int result = 42;        // 承诺兑现，将结果放入 promise        p.set_value(result);     } catch (...) {        // 如果发生异常，可以将异常放入 promise        p.set_exception(std::current_exception());    }}int main() {  // 消费者线程    // 1. 创建一个 promise 对象    std::promise&lt;int&gt; p;  // 这里的int是任务的返回类型    // 2. 从 promise 获取 future，这是结果的“读取端”    std::future&lt;int&gt; f = p.get_future();  // 连接 promise 和 future    // 3. 创建一个新线程，并将 promise 的所有权转移给它    std::thread worker(compute_task, std::move(p));  // compute_task函数需要接收promise对象作为参数    std::cout &lt;&lt; \"Main thread is waiting for the result...\" &lt;&lt; std::endl;    // 4. 在主线程中调用 get() 等待结果    int result = f.get();  // // 这里会阻塞，直到 worker 线程调用了 p.set_value()    std::cout &lt;&lt; \"The result from worker thread is: \" &lt;&lt; result &lt;&lt; std::endl;    worker.join();    return 0;}\n这里的main 线程创建了 promise 和 future，将 promise 移动到子线程，然后自己持有 future 等待结果; worker 线程接收 promise 对象，执行任务，最后通过 p.set_value(42) 履行承诺，这个动作会唤醒在 f.get() 处阻塞的 main 线程。\n高级抽象：任务与结果的绑定std::packaged_task 和 std::async 是在 promise/future 基础上构建的更高级抽象，它们将任务的执行与结果的传递机制更紧密地结合起来。\nstd::packaged_task&lt;T(Args…)&gt;：可调用对象与未来的封装std::packaged_task 是一个模板类，它将任意可调用对象 (Callable Object) 与 promise/future 机制进行封装。它的主要目的是将一个函数的执行与其返回值的异步传递自动化。其模板参数是一个函数签名，例如 int(int, double)。\n内部机制:\n\n构造: 当你用一个函数（如 my_func）创建一个 std::packaged_task&lt;T(Args…)&gt; task(my_func) 时，task 内部会创建一个 std::promise。\n获取Future: 调用 task.get_future() 会返回与这个内部 promise 相关联的 std::future。\n执行: packaged_task 对象本身是可调用的 (operator())。当你执行 task(args…) 时，它会调用其内部包装的函数 my_func(args…), 捕获 my_func 的返回值, 并自动使用该返回值调用内部 promise 的 set_value() 方法。如果 my_func 抛出异常，它会捕获异常并调用 set_exception()。\n\n工作流程：\n\n创建一个可调用对象（例如一个函数或 Lambda）并用这个可调用对象来初始化一个 std::packaged_task。\n通过 task.get_future() 获取与之关联的 std::future。\n将 packaged_task 对象移动到新线程。\n在新线程中，像普通函数一样执行这个 task 对象。\n任务执行完毕后，其返回值会自动被 packaged_task 捕获并传递给关联的 future。\n\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;#include &lt;cmath&gt;// 一个耗时的计算任务long long calculate_factorial(int n) {    long long res = 1;    for (int i = 2; i &lt;= n; ++i) {        res *= i;    }    std::cout &lt;&lt; \"Task finished calculation.\" &lt;&lt; std::endl;    return res;}int main() {    // 1. 将函数包装成一个 packaged_task, 模板参数是函数的签名：long long(int)    std::packaged_task&lt;long long(int)&gt; task(calculate_factorial);    // 2. 从 task 获取 future    std::future&lt;long long&gt; f = task.get_future();    // 3. 将 task 移动到新线程    // 注意：这里传递的是 task 本身，而不是函数    std::thread worker(std::move(task), 10); // 计算 10!    std::cout &lt;&lt; \"Main thread is waiting for the factorial result...\" &lt;&lt; std::endl;    // 4. 等待并获取结果    long long result = f.get();    std::cout &lt;&lt; \"Factorial of 10 is: \" &lt;&lt; result &lt;&lt; std::endl;    worker.join();    return 0;}\n相比\nstd::asyncstd::async 是一个函数模板，用于以异步方式（可能在一个单独的线程中）启动一个任务。它将线程创建、任务执行和结果返回的所有细节都封装了起来, 相比于直接使用 std::thread，std::async 提供了一种更高层次、更方便的抽象，特别适用于那些需要从异步任务中获取返回值的场景。\n简单来说，std::async 做了两件事：\n\n启动一个可调用对象（如函数、lambda表达式）：它允许你安排一个任务去执行，而不必立即等待它完成。\n返回一个 std::future 对象：这个 std::future 对象是一个“未来的凭证”，它最终会持有异步任务的返回值。你可以通过这个 future 在稍后的时间点获取结果。\n\n这种模型被称为基于任务的并行 (Task-Based Parallelism)，你关心的是“要完成什么任务”，而不是“具体要在哪个线程上完成”。\n基本用法std::async 的基本语法如下：\ntemplate&lt; class Function, class... Args &gt;std::future&lt;std::result_of_t&lt;std::decay_t&lt;Function&gt;(std::decay_t&lt;Args&gt;...)&gt;&gt;    async( Function&amp;&amp; f, Args&amp;&amp;... args );// 这里std::decay_t是类型萃取, 用于去掉引用、cv限定符和数组类型, 得到原始类型; 最终std::future的模板参数就是传入函数的返回类型\n让我们通过一个简单的例子来理解它的工作方式: 假设我们有一个耗时的计算任务，我们不希望主线程被阻塞。\n#include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;#include &lt;chrono&gt;// 一个模拟耗时计算的函数int time_consuming_calculation(int x) {    std::cout &lt;&lt; \"Worker thread is calculating...\" &lt;&lt; std::endl;    // 模拟耗时2秒    std::this_thread::sleep_for(std::chrono::seconds(2));    return x * x;}int main() {    std::cout &lt;&lt; \"Main thread started.\" &lt;&lt; std::endl;    // 1. 启动异步任务    // 通过 std::async 启动 time_consuming_calculation 函数，并传递参数 5。    // 这会立即返回一个 std::future&lt;int&gt; 对象。    std::future&lt;int&gt; future_result = std::async(time_consuming_calculation, 5);    // 2. 主线程继续执行其他任务    // 在异步任务执行的同时，主线程可以做别的事情。    std::cout &lt;&lt; \"Main thread is doing other work while waiting for the result...\" &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(1)); // 模拟其他工作    // 3. 获取异步任务的结果    // 调用 future_result.get() 来获取结果。    // 如果此时异步任务还没有完成，.get() 会阻塞当前线程，直到结果可用。    std::cout &lt;&lt; \"Main thread is waiting for the result...\" &lt;&lt; std::endl;    int result = future_result.get(); // .get() 会阻塞直到任务完成    std::cout &lt;&lt; \"The result is: \" &lt;&lt; result &lt;&lt; std::endl;    std::cout &lt;&lt; \"Main thread finished.\" &lt;&lt; std::endl;    return 0;}\n\nstd::async(time_consuming_calculation, 5)：这行代码请求异步执行 time_consuming_calculation(5)。它可能会立即创建一个新线程来运行这个函数。\nstd::future future_result：std::async 返回一个 std::future 对象。int 类型表示我们期望从异步任务中获得一个整数返回值。\nfuture_result.get()：这是关键部分。当主线程需要计算结果时，它调用 .get()。\n如果此时工作线程已经计算完毕，.get() 会立即返回结果。\n如果工作线程仍在计算，.get() 会阻塞主线程，直到计算完成并返回结果。\n注意：get() 只能被调用一次。再次调用会导致未定义行为。\n\n\n\n启动策略 (Launch Policy)std::async 的行为可以通过一个可选的“启动策略”参数来控制。这是一个非常重要的特性。\n// 明确指定启动策略auto future = std::async(std::launch::async, my_function);\n主要的启动策略有两种：\n\nstd::launch::async: 保证异步执行。系统必须创建一个新的线程来执行任务。当你需要真正的并行计算时，这是最常用的策略。\nstd::launch::deferred: 延迟执行。任务不会立即在任何线程上启动。相反，它只会在返回的 std::future 对象上调用 .get() 或 .wait() 时，才会在调用 .get() 的那个线程上同步执行。用于实现惰性求值（Lazy Evaluation），即直到你真正需要结果时才进行计算。\n\n默认策略：std::launch::async | std::launch::deferred\n这是 std::async 的默认行为。它给予了标准库实现的灵活性，可以根据系统负载或其他条件自行决定是创建一个新线程（async）还是延迟执行（deferred）。然而, 这种不确定性可能导致程序行为难以预测。如果你需要保证并行性，强烈建议明确指定 std::launch::async。\nstd::async 与 std::thread 的对比\n\n\n特性\nstd::thread\nstd::async\n\n\n\n抽象层次\n低层次，直接操作线程\n高层次，关注于”任务”\n\n\n返回值\n没有直接获取返回值的机制（需借助 std::promise 或共享变量）\n通过返回的 std::future 对象轻松获取返回值\n\n\n异常处理\n如果线程函数抛出异常且未被捕获，程序会调用 std::terminate 终止\n异常会被 std::future 捕获，并在调用 .get() 时重新抛出\n\n\n线程管理\n需要手动调用 join() 或 detach()，否则程序在 std::thread 对象析构时终止\nstd::future 的析构函数会阻塞，直到异步任务完成，避免了线程被意外销毁\n\n\n系统开销\n总是创建一个新的操作系统线程\n(默认策略下) 可能不会创建新线程，由系统决定，可能更高效\n\n\n总结默认选择 std::async: 对于大多数“执行一个函数并获取其结果”的场景，std::async 因其简洁、安全（自动异常传递和资源管理）而成为首选。\n需要任务队列时选择 std::packaged_task: 当你需要将任务对象化，以便存储、传递和由通用的执行器（如线程池）稍后执行时，std::packaged_task 是正确的工具。\n需要手动信号控制时选择 std::promise: 当结果的产生不与单个函数的返回直接对应，而是取决于复杂的逻辑或外部事件时，std::promise 提供了必要的底层控制能力。\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"条款31：避免默认捕获模式","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE31%20-%20%E9%81%BF%E5%85%8D%E9%BB%98%E8%AE%A4%E6%8D%95%E8%8E%B7%E6%A8%A1%E5%BC%8F/","content":"lambda 表达式Lambda 表达式（Lambda Expression）是一种在需要函数的地方，可以就地定义匿名函数对象的便捷方式。它本质上是一个可调用的代码单元，可以像函数一样使用，但无需为其命名(当然也可以为其命名)。它允许你编写简短、内联的函数，特别适用于作为算法或异步调用的参数，从而让代码更简洁、更具表现力。\n为何需要 Lambda？在 C++11 之前，如果你想向一个算法（如 std::sort 或 std::find_if）传递自定义逻辑，通常有两种方法：定义一个独立的函数或者定义一个函数对象（Functor）\n// 定义函数, 缺点：函数定义与调用点分离，降低了代码的可读性；可能会污染命名空间。bool isOdd(int n) {    return n % 2 != 0;}// ...std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), isOdd);// 定义函数对象, 缺点：语法非常冗长，为了一个简单的操作就需要定义一个完整的类。struct IsOddFunctor {    bool operator()(int n) const {        return n % 2 != 0;    }};// ...std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), IsOddFunctor());\nLambda 表达式正是为了解决这些问题而生的。 它允许你将执行逻辑直接写在调用的地方：\nstd::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), [](int n) {    return n % 2 != 0;});\n这样做代码紧凑、逻辑清晰，定义与使用紧密相连\n语法解析Lambda 表达式的完整语法结构如下： capture specifiers -&gt; return_type { body }, 其中很多部分是可选的。我们来逐一分解：\n\n 捕获列表 (Capture Clause)这是 Lambda 表达式最强大的功能之一。它定义了 Lambda 函数体内部可以访问哪些来自其外部作用域的变量，以及如何访问它们。\n\n\n\n\n捕获方式\n说明\n\n\n\n[]\n不捕获任何外部变量。\n\n\n[=]\n按值捕获 (by copy)。所有外部变量都以只读副本的形式在函数体内可用。\n\n\n[&amp;]\n按引用捕获 (by reference)。所有外部变量都以引用的形式在函数体内可用，可以修改。\n\n\n[this]\n捕获 this 指针。允许在 Lambda 体内访问当前对象的成员变量和函数。\n\n\n[a, &amp;b]\n显式捕获。只捕获变量 a（按值）和 b（按引用）。\n\n\n[=, &amp;b]\n混合捕获。默认按值捕获，但显式指定 b 按引用捕获。\n\n\n[&amp;, a]\n混合捕获。默认按引用捕获，但显式指定 a 按值捕获。\n\n\n[val = expr] (C++14+)\n带初始化的捕获（或称广义捕获）。允许创建一个新的变量 val 并用 expr 初始化，该变量仅在 Lambda 体内可见。这对于移动捕获（move capture）尤其重要。\n\n\n需要注意的是, [&amp;] 和 [=] 被称为默认捕获模式 (Default Capture Modes)。当你在捕获列表中使用它们而不指名具体变量时，就为 Lambda 设定了一个“自动捕获”的规则, 所有外部的变量都会在使用时被自动捕获. 这个规则在提供便利的同时也可能导致一些问题, 这就是这一讲所提出的.\n\n全局变量 (Global variables)和静态变量 (Static variables)不需要被捕获, 因为它们已经在全局作用域中定义, 可以直接在 Lambda 表达式中使用。\n\n\n( ) 参数列表 (Parameter List)与普通函数的参数列表完全相同。如果 Lambda 不需要参数，() 可以省略（但如果使用了 mutable 或 -&gt; return_type，则不能省略）。\n\n[]() { std::cout &lt;&lt; \"No params.\" &lt;&lt; std::endl; }[](int x, int y) { return x + y; }\n\n\nspecifiers (可选) 说明符\n\n\nmutable：默认情况下，对于按值捕获的变量，Lambda 体内不能修改它们（它们是 const 的副本）。使用 mutable 关键字可以取消这个限制，允许你修改这些副本。\n\nint count = 0;auto counter = [count]() mutable {    count++; // OK with mutable    std::cout &lt;&lt; count &lt;&lt; std::endl;};counter(); // 输出 1counter(); // 输出 2std::cout &lt;&lt; count &lt;&lt; std::endl; // 仍然输出 0，因为修改的是副本\n\nnoexcept, constexpr (C++17+) 等：与普通函数类似，用于指定异常规范或编译期求值。\n\n\n-&gt; return_type (可选) 返回类型通常情况下，编译器可以根据函数体中的 return 语句自动推导出 Lambda 的返回类型。因此，这个部分是可选的。只有在少数复杂情况下（例如期望的返回类型与推导出的不同且可以通过转换实现），才需要显式指定返回类型。\n\n// 自动推导返回类型为 double[](double a) { return a * 1.5; }// 显式指定返回类型为 double[](int a) -&gt; double {    if (a &gt; 0) return a;    return 0.0; // 多个返回语句，但类型可统一推导}\n\n\n{ } 函数体 (Function Body): Lambda 表达式的具体执行代码，与普通函数的函数体一样。\n\nLambda 的本质：闭包 (Closure)理解 Lambda 的关键在于知道它在底层是如何工作的。每当你写下一个 Lambda 表达式，编译器都会自动生成一个唯一的、匿名的类类型，这个类被称为“闭包类型”（Closure Type）。\nLambda 表达式本身创建了一个该类型的对象，称为“闭包对象”。这个闭包类重载了 operator()，使得其对象可以像函数一样被调用。函数体就是 Lambda 的 {} 中的代码。\n而所有被捕获的变量，都会成为这个闭包类的成员变量。\n\n按值捕获 [x] -&gt; 成为成员变量 int x;\n按引用捕获 [&amp;y] -&gt; 成为成员变量 int&amp; y;\n\n例如, 以下lambda表达式会生成这样的闭包类:\nint x = 10;int y = 20;auto my_lambda = [x, &amp;y](int z) { y = x + z; };// 编译器生成的（概念上的）等价物class __Lambda_XYZ_Compiler_Generated {public:    // 构造函数捕获变量    __Lambda_XYZ_Compiler_Generated(int x_val, int&amp; y_ref)        : x(x_val), y(y_ref) {}    // 重载 operator()    void operator()(int z) const {        y = x + z; // 在函数体内使用成员变量    }private:    int x;   // 按值捕获的成员    int&amp; y;  // 按引用捕获的成员};// 创建闭包对象auto my_lambda = __Lambda_XYZ_Compiler_Generated(x, y);\n\n应用场景\n配合 STL 算法（最常见的用途）\n\n#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;std::vector&lt;int&gt; v = {5, -1, 42, 8, 7};// 1. 自定义排序int factor = 10;std::sort(v.begin(), v.end(), [factor](int a, int b) {    // 按与 factor 的距离排序    return std::abs(a - factor) &lt; std::abs(b - factor);});// 2. 查找第一个满足条件的元素auto it = std::find_if(v.begin(), v.end(), [](int n) {    return n &gt; 40;});if (it != v.end()) {    std::cout &lt;&lt; \"Found: \" &lt;&lt; *it &lt;&lt; std::endl; // 输出 Found: 42}// 3. 遍历std::for_each(v.begin(), v.end(), [](int n){    std::cout &lt;&lt; n &lt;&lt; \" \";});\n\n\n泛型 Lambda (C++14): 使用 auto 关键字作为参数类型，可以让 Lambda 成为一个模板\n\nauto generic_add = [](auto a, auto b) {    return a + b;};int sum_int = generic_add(5, 3);          // 8double sum_double = generic_add(1.5, 2.5);  // 4.0std::string s1 = \"hello\", s2 = \" world\";std::string s3 = generic_add(s1, s2); // \"hello world\"\n\n\n带初始化的捕获 (C++14): 对于移动（move）一个只能移动的对象（如 std::unique_ptr）到 Lambda 内部非常有用\n\n#include &lt;memory&gt;auto ptr = std::make_unique&lt;int&gt;(100);// 将 ptr 的所有权移入 Lambdaauto my_lambda = [p = std::move(ptr)]() {    std::cout &lt;&lt; \"Value inside lambda: \" &lt;&lt; *p &lt;&lt; std::endl;};my_lambda();// 此处 ptr 已经是 nullptr，因为所有权已经移交\n\n避免默认捕获模式回到标题, 该条款的核心论点是，C++11 提供的两种默认捕获模式——按引用默认捕获 [&amp;] 和 按值默认捕获 [=] 都存在风险，应当避免使用。取而代之的，是显式捕获（explicit capture），即明确列出 lambda 表达式所依赖的所有外部变量\n按引用默认捕获 ([&amp;]) 的风险：悬垂引用这是最直接也最危险的问题。按引用捕获会导致闭包（lambda 表达式创建的运行时对象）包含指向局部变量或函数参数的引用。如果闭包的生命周期超过了这些局部变量或参数的生命周期，那么闭包内的引用就会悬垂 (dangle)。\n假设我们有一个全局的过滤器(函数)容器，一个函数 addDivisorFilter 用于向其中添加一个过滤器。\nusing FilterContainer = std::vector&lt;std::function&lt;bool(int)&gt;&gt;; // 函数包装器可以存储任何可调用对象FilterContainer filters;void addDivisorFilter() {    auto divisor = computeDivisor(); // divisor 是一个局部变量        // 危险！[&amp;] 捕获了对局部变量 divisor 的引用    filters.emplace_back(        [&amp;](int value) { return value % divisor == 0; }    );} // divisor 在这里被销毁\n当 addDivisorFilter 函数返回时，其局部变量 divisor 会被销毁。然而，被添加到全局容器 filters 中的 lambda 闭包仍然存在，并且它内部包含一个指向已被销毁的 divisor 内存地址的引用。任何后续对这个过滤器的调用都将导致未定义行为。在此时, 显式写出 [&amp;divisor] 比 [&amp;] 更安全。因为它清晰地表明了这个 lambda 的生存依赖于 divisor 的生命周期，迫使开发者去思考和确认这个依赖是安全的。而 [&amp;] 则会隐藏这种依赖关系。\n按值默认捕获 ([=]) 的风险按值默认捕获 [=] 看起来似乎可以解决悬垂引用的问题，并让 lambda 变得“自洽”，但这种想法是具有误导性的，并隐藏着两个主要的陷阱。\n陷阱一：悬垂指针（this 指针陷阱）按值捕获一个指针，只是复制了指针本身，而不是它所指向的对象。如果指针所指向的对象被销毁，闭包中持有的指针副本同样会变成悬垂指针。\n这个问题在类的成员函数中尤其隐蔽，因为 [=] 会隐式地捕获 this 指针。\nclass Widget {public:    void addFilter() const;private:    int divisor;};void Widget::addFilter() const {    // [=] 看起来是按值捕获，但实际上是按值捕获了 this 指针    filters.emplace_back(        [=](int value) { return value % divisor == 0; }    );}void doSomeWork() {    auto pw = std::make_unique&lt;Widget&gt;();    pw-&gt;addFilter(); // 添加了一个依赖 *pw 的过滤器} // pw 在这里被销毁, 但这个指针的值 (即指向 Widget 对象的指针) 已经被复制到了 lambda 闭包中\n在 addFilter 中，divisor 是一个成员变量，它无法被直接捕获。为了在 lambda 内部访问 divisor（实际上是 this-&gt;divisor），[=] 捕获的是this 指针的副本。\n而当doSomeWork 函数返回时，pw 所指向的 Widget 对象被销毁。但 filters 容器中的 lambda 闭包仍然存在，并且它内部持有一个指向已被销毁的 Widget 对象的 this 指针。这同样导致了悬垂指针和未定义行为。\n陷阱二：“自洽”的假象[=] 模式给人的感觉是，闭包复制了它所需的一切，因此是完全独立、自洽的。这是错误的。\n[=] 不会捕获静态存储期的变量。如果 lambda 使用了全局变量、static 局部变量或 static 成员变量，它只是直接引用这些变量，而不会在闭包中创建其副本。\nvoid addDivisorFilter() {    static auto divisor = computeDivisor(); // divisor 是静态局部变量        filters.emplace_back(        [=](int value) { return value % divisor == 0; }    );        ++divisor; // 修改静态变量}\n这里的 [=] 实际上没有捕获任何东西，因为 divisor 是 static 的。lambda 内部的 divisor 直接引用了那个唯一的静态变量。\n每次调用 addDivisorFilter，divisor 的值都会增加。这意味着每次添加到 filters 中的 lambda 的行为都会因 divisor 的改变而改变，这与 [=] 所暗示的“按值复制、行为固定”的直觉完全相反。\n鉴于上述的默认捕获行为的危险性, 最安全的做法是避免使用默认捕获模式，转而显式捕获 lambda 所需的所有变量。这使得代码的依赖关系清晰可见，迫使开发者思考变量的生命周期，从而写出更健壮、更安全的代码。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款33：对 auto&& 型别的形参使用 decltype, 以 std forward 之","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE33%20-%20%E5%AF%B9%20auto&&%20%E5%9E%8B%E5%88%AB%E7%9A%84%E5%BD%A2%E5%8F%82%E4%BD%BF%E7%94%A8%20decltype,%20%E4%BB%A5%20std%20forward%20%E4%B9%8B/","content":"该条款的核心是解决一个在 C++14 泛型 lambda 中进行完美转发时遇到的具体语法问题。\n泛型lambda简单来说，泛型 Lambda (Generic Lambda) 是一种可以使用 auto 关键字作为参数类型的 Lambda 表达式。这使得该 Lambda 能够接受任意类型的参数，其行为类似于一个函数模板。\n\n在 C++14 之前，如果你想让一个 Lambda 接受不同类型的参数，你需要为每种类型写一个 Lambda，或者使用更复杂的模板技巧（比如定义一个带模板化 operator() 的函数对象）。C++14 通过允许在 Lambda 参数中使用 auto，极大地简化了这一过程。\n\n正如我们前面所说, lambda的本质是闭包类, 因此泛型 Lambda 的本质也是闭包类, 只是这个闭包类的 operator() 是一个模板函数, 可以接受任意类型的参数。\nauto my_lambda = [](auto x) { /* ... */ };// 可以理解为下列代码class __compiler_generated_functor_name {public:    template&lt;typename T&gt;    auto operator()(T x) const {        /* ... */    }};auto my_lambda = __compiler_generated_functor_name{};\n也就是说, 泛型 Lambda 本质上是一个拥有模板化的函数调用运算符 (operator()) 的函数对象的语法糖。这使得每一次用不同类型的参数调用该 Lambda 时，编译器都能为其生成一个特定的函数实例。\n泛型 Lambda 与完美转发而在许多情况下(例如工厂函数), 我们需要在泛型 Lambda 中进行完美转发, 即保留参数的左值/右值属性, 为此我们需要将 lambda 的形参声明为万能引用 auto&amp;&amp;，并在内部使用 std::forward. 此时会出现一个问题\n// auto&amp;&amp; x 是万能引用auto f = [](auto&amp;&amp; x) {    // ??? 应该是什么类型？    return func(normalize(std::forward&lt;???&gt;(x)));};\n在常规的函数模板中，我们会写 std::forward(x)，这里的 T 是模板参数。但在 lambda 表达式中，我们无法直接访问到编译器在背后为我们生成的那个模板参数 T。那么，??? 处应该填什么呢？\n条款33给出的解决方案是使用 decltype 来获取 lambda 形参的类型，并将其作为 std::forward 的模板参数, 也就是:\nauto f = [](auto&amp;&amp; param) {    return func(normalize(std::forward&lt;decltype(param)&gt;(param)));};\n\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款34：优先选用 lambda 式，而非 std bind","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE34%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20lambda%20%E5%BC%8F%EF%BC%8C%E8%80%8C%E9%9D%9E%20std%20bind/","content":"在 C++11 中，lambda 表达式几乎总是比 std::bind 更好的选择；到了 C++14，std::bind 基本上已无用武之地。std::bind 是一个源自 C++98 时代函数式编程思想的工具，虽然在 C++11 标准库中被正式引入，但其设计与现代 C++ 的 lambda 表达式相比，在多个方面都相形见绌。\nstd::bindstd::bind 是 C++11 在  头文件中提供的一个非常有用的函数模板。它就像一个函数适配器，可以接受一个可调用对象（callable object），并将其部分或全部参数绑定到特定的值或占位符上，最终生成一个新的、可直接调用的对象（通常称为函数对象 function object）。\n简而言之，std::bind 的核心作用是延迟调用和参数定制。\nstd::bind 的基本语法如下：\nauto new_callable = std::bind(callable_object, arg1, arg2, ...);\n\ncallable_object: 任何可以被调用的对象，例如普通函数指针, 类的成员函数指针, Lambda 表达式, 其他函数对象（如 std::function）等\narg1, arg2, …: 要传递给 callable_object 的参数列表。这些参数可以是具体的值(如 10, “hello”, 3.14), 这些参数会被复制或移动并存储在生成的新函数对象中; 也可以是占位符 (Placeholders): 如 _1, _2, _3, …。它们定义在命名空间 std::placeholders 中。占位符表示新生成的可调用对象的参数位置。例如，_1 表示新对象的第一个参数，_2 表示第二个参数，以此类推(注意：使用占位符时，通常需要 using namespace std::placeholders; 或显式指定 std::placeholders::_1)\n\n主要用途与代码示例下面我们通过几个核心场景来理解 std::bind 的具体用法。\n\n绑定普通函数参数这是最常见的用法，用于将一个函数的某些参数固定下来，生成一个参数更少的新函数。假设有一个函数需要三个参数，但我们想创建一个只需要一个参数的简化版本。\n\n#include &lt;iostream&gt;#include &lt;functional&gt;// 原始函数，接受三个参数void print_info(const std::string&amp; name, int age, const std::string&amp; city) {    std::cout &lt;&lt; name &lt;&lt; \" is \" &lt;&lt; age &lt;&lt; \" years old and lives in \" &lt;&lt; city &lt;&lt; \".\" &lt;&lt; std::endl;}int main() {    // 使用占位符命名空间    using namespace std::placeholders;    // 1. 绑定部分参数    // 将 print_info 的第一个和第三个参数固定为 \"Alice\" 和 \"New York\"    // _1 是一个占位符，代表新函数 call_alice 的第一个参数    // 第二个参数被设置为占位符 _1，这意味着 call_alice 的第一个参数将会被传递到 print_info 的第二个位置。    auto call_alice = std::bind(print_info, \"Alice\", _1, \"New York\");    // 调用新生成的函数对象，只需要提供年龄    std::cout &lt;&lt; \"--- Calling with partial binding ---\" &lt;&lt; std::endl;    call_alice(30); // 输出: Alice is 30 years old and lives in New York.    call_alice(25); // 输出: Alice is 25 years old and lives in New York.    // 2. 绑定所有参数    // 将所有参数都固定下来    auto call_bob = std::bind(print_info, \"Bob\", 42, \"London\");    // 调用时不再需要任何参数    std::cout &lt;&lt; \"\\n--- Calling with full binding ---\" &lt;&lt; std::endl;    call_bob(); // 输出: Bob is 42 years old and lives in London.    return 0;}\n\n调整参数顺序: std::bind 还可以通过占位符灵活地调整参数的传递顺序。假如有一个减法函数，我们想创建一个新函数来实现参数顺序颠倒的减法\n\n#include &lt;iostream&gt;#include &lt;functional&gt;double subtract(double a, double b) {    return a - b;}int main() {    using namespace std::placeholders;    // 原始调用    std::cout &lt;&lt; \"subtract(10, 3) = \" &lt;&lt; subtract(10, 3) &lt;&lt; std::endl; // 输出: 7    // 使用 bind 交换参数顺序    // _1 对应新函数的第一个参数，_2 对应第二个    // bind(subtract, _2, _1) 的意思是：    // 调用时，将新函数的第二个参数传给 subtract 的第一个参数    // 将新函数的第一个参数传给 subtract 的第二个参数    auto reversed_subtract = std::bind(subtract, _2, _1);    std::cout &lt;&lt; \"reversed_subtract(10, 3) = \" &lt;&lt; reversed_subtract(10, 3) &lt;&lt; std::endl; // 输出: -7    // 上述调用等效于 subtract(3, 10)        return 0;}\n\n绑定类的成员函数: 这是 std::bind 一个非常重要的应用场景，尤其是在回调函数中。绑定成员函数时，必须提供一个类的实例（或指针、引用）作为 std::bind 的第一个参数(在函数参数之后)。也就是说, 绑定成员函数时，第一个参数必须是成员函数指针，第二个参数必须是对象实例（或指针）\n\n#include &lt;iostream&gt;#include &lt;functional&gt;#include &lt;string&gt;class Greeter {public:    void say_hello(const std::string&amp; name) {        std::cout &lt;&lt; \"Hello, \" &lt;&lt; name &lt;&lt; \"!\" &lt;&lt; std::endl;    }};int main() {    using namespace std::placeholders;    Greeter greeter_instance;    // 绑定成员函数    // 第一个参数是成员函数指针：&amp;Greeter::say_hello    // 第二个参数是对象实例的地址：&amp;greeter_instance    // 第三个参数 _1 是占位符，对应 say_hello 的 name 参数    auto greet_func = std::bind(&amp;Greeter::say_hello, &amp;greeter_instance, _1);    greet_func(\"World\");   // 输出: Hello, World!    greet_func(\"C++\");    // 输出: Hello, C++!    // 如果传递对象实例本身，会发生拷贝    auto greet_func_copy = std::bind(&amp;Greeter::say_hello, greeter_instance, _1);    greet_func_copy(\"Copied\"); // 输出: Hello, Copied!    return 0;}\n\n&amp;greeter_instance：这是调用该成员函数的对象实例的指针。this 指针被隐式地绑定到了 greeter_instance。你也可以直接传递 greeter_instance，此时会拷贝一份对象。\n\nstd::bind 与 Lambda 表达式的对比在现代 C++ (C++14 及以后) 中，Lambda 表达式通常是比 std::bind 更好的选择。因为 Lambda 通常更具可读性、更灵活，并且可能产生更高效的代码。让我们用 Lambda 重写上面的第一个例子：\n#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;functional&gt;void print_info(const std::string&amp; name, int age, const std::string&amp; city) {    std::cout &lt;&lt; name &lt;&lt; \" is \" &lt;&lt; age &lt;&lt; \" years old and lives in \" &lt;&lt; city &lt;&lt; \".\" &lt;&lt; std::endl;}int main() {    // ---- std::bind 版本 ----    using namespace std::placeholders;    auto call_alice_bind = std::bind(print_info, \"Alice\", _1, \"New York\");    call_alice_bind(30);    // ---- Lambda 版本 ----    // 捕获 name 和 city 变量，age 作为参数传入    std::string name = \"Alice\";    std::string city = \"New York\";    auto call_alice_lambda = [name, city](int age) {        print_info(name, age, city);    };    call_alice_lambda(30);    return 0;}\nLambda 的优势：\n\n可读性更强：[name, city](int age){…} 的意图非常清晰：捕获 name 和 city，并接受一个 age 参数。而 std::bind(…, “Alice”, _1, …) 的 _1 语法相对晦涩。\n更灵活：Lambda 内部可以包含更复杂的逻辑，定义局部变量等，而 std::bind 只是单纯的函数调用包装。\n性能可能更好：编译器通常能更好地内联和优化 Lambda 表达式，因为 Lambda 的类型是唯一的、在编译期确定的。而 std::bind 产生的函数对象类型较为复杂，可能给优化带来挑战。\n无需占位符：Lambda 自然地处理参数，不需要引入 std::placeholders 命名空间和 _1, _2 等符号。\n\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款42 ：考虑置入而非插入","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%BE%AE%E8%B0%83/%E6%9D%A1%E6%AC%BE42%20-%20%E8%80%83%E8%99%91%E7%BD%AE%E5%85%A5%E8%80%8C%E9%9D%9E%E6%8F%92%E5%85%A5/","content":"该条款的核心是介绍 C++11 引入的“置入函数”（如 emplace_back, emplace 等），并将其与传统的“插入函数”（如 push_back, insert 等）进行比较。在许多情况下，置入函数比插入函数更高效。这是因为置入函数避免了不必要的复制或移动操作，直接在容器中构造对象，而插入函数则需要先构造对象，然后再将其复制或移动到容器中。\n插入函数和置入函数的根本区别在于它们接受的参数类型：\n\n插入函数 (如 push_back, insert)：接受一个对象（容器所存储类型的对象）作为参数。\n置入函数 (如 emplace_back, emplace)：接受用于在容器中构造一个对象的构造函数实参。它使用完美转发将这些参数直接传递给对象的构造函数。\n\n因此, 置入函数的主要性能优势在于，它可以避免创建和销毁临时对象。\nstd::vector&lt;std::string&gt; vs;// 插入操作vs.push_back(\"xyzzy\");// 置入操作, 这里由于是字符串因此构造函数实参和对象一致vs.emplace_back(\"xyzzy\");\npush_back 的过程：\n\n编译器首先从字符串字面量 “xyzzy” 创建一个临时的 std::string 对象。\n然后，这个临时的 std::string 对象（一个右值）被移动构造到 vector 的内存空间中。\n最后，这个临时的 std::string 对象被析构。\n整个过程涉及一次临时对象的构造、一次移动构造和一次析构。\n\nemplace_back 的过程：\n\nemplace_back 将其参数 (“xyzzy”) 完美转发到 std::string 的构造函数。\nstd::string 对象直接在 vector 的内存空间中被构造出来。\n这个过程完全避免了创建和销毁临时对象，因此效率更高。\n\n理论上，置入函数应该永远不比插入函数慢。在实践中，当以下三个条件都成立时，置入几乎肯定会比插入更高效：\n\n值是以构造而非赋值方式加入容器：这对于所有基于节点的容器（如 std::list, std::map）和在序列容器（如 std::vector）尾部 emplace_back 都成立。\n传递的实参类型与容器持有之物的类型不同：性能优势主要来自于避免创建临时对象。如果传递的实参类型与容器内元素的类型不同（如传递 const char* 给 std::vectorstd::string），置入就能避免创建临时的 std::string。\n容器不太可能因为存在重复值而拒绝新值：对于 std::set 或 std::map 等不允许重复键的容器，emplace 的实现通常会先创建一个新节点，再将其与容器内现有节点比较。如果此时发现值已存在，这个新创建的节点就会被销毁，其构造和析构的开销就被浪费了。\n\n置入的注意事项与陷阱尽管置入很高效，但在使用时也存在两个重要的陷阱。\n陷阱一：资源管理与异常安全当容器持有资源管理类对象（如智能指针）时，使用置入函数可能会破坏异常安全。\nstd::list&lt;std::shared_ptr&lt;Widget&gt;&gt; ptrs;// push_back 版本（异常安全）ptrs.push_back(std::shared_ptr&lt;Widget&gt;(new Widget, killWidget));// emplace_back 版本（危险！）ptrs.emplace_back(new Widget, killWidget);\npush_back 的情况：std::shared_ptr 的临时对象在 push_back 函数被调用前就已经创建了，它安全地接管了 new Widget 返回的裸指针。如果后续 push_back 在分配内存时抛出异常，这个临时 shared_ptr 的析构函数会确保 Widget 被正确删除，不会发生资源泄漏。\nemplace_back 的情况：new Widget 的结果（一个裸指针）被直接转发到 emplace_back 内部。如果在 emplace_back 内部、在为 std::shared_ptr 分配内存之前，发生了另一次内存分配失败（例如为 list 的节点分配内存），那么 new Widget 返回的裸指针就会丢失，导致资源泄漏。\n陷阱二：与 explicit 构造函数的交互置入函数使用直接初始化，而插入函数使用复制初始化。这意味着置入函数可以调用 explicit 的构造函数，而插入函数不能。因为 emplace_back 的内部行为相当于直接调用构造函数，这遵循的是直接初始化 (Direct-Initialization) 的规则\nstd::vector&lt;std::regex&gt; regexes;// 已知std::regex 的构造函数 std::regex(const char*) 是 explicit 的。// 编译失败：push_back 使用复制初始化，不能调用 explicit 构造函数regexes.push_back(nullptr);// 编译成功！emplace_back 使用直接初始化，可以调用 explicit 构造函数regexes.emplace_back(nullptr);\n这里虽然 emplace_back(nullptr) 能通过编译，但将一个空指针传递给 std::regex 的构造函数会在运行时导致未定义行为。\n因此, 置入函数可能会调用那些会被插入函数拒绝的 explicit 构造函数，这可能会“隐藏”一些潜在的 bug，让本应在编译期发现的问题延迟到运行时。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款41 ：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%BE%AE%E8%B0%83/%E6%9D%A1%E6%AC%BE41%20-%20%E9%92%88%E5%AF%B9%E5%8F%AF%E5%A4%8D%E5%88%B6%E7%9A%84%E5%BD%A2%E5%8F%82%EF%BC%8C%E5%9C%A8%E7%A7%BB%E5%8A%A8%E6%88%90%E6%9C%AC%E4%BD%8E%E5%B9%B6%E4%B8%94%E4%B8%80%E5%AE%9A%E4%BC%9A%E8%A2%AB%E5%A4%8D%E5%88%B6%E7%9A%84%E5%89%8D%E6%8F%90%E4%B8%8B%EF%BC%8C%E8%80%83%E8%99%91%E5%B0%86%E5%85%B6%E6%8C%89%E5%80%BC%E4%BC%A0%E9%80%92/","content":"该条款探讨了一种在特定情况下，可以替代“为左值和右值分别重载”这一常规做法的编码技巧。C++98 的一条重要准则是“避免按值传递用户定义类型”，而该条款则解释了在C++11的移动语义下，这条准则何时可以被“打破”。\n当一个函数需要持有其参数的一个副本时（例如，将其存入一个数据成员），在 C++11 中最常见的做法是提供两个重载版本：\n\n一个版本接受 const T&amp;（左值），并在函数体内复制它。\n另一个版本接受 T&amp;&amp;（右值），并在函数体内移动它。\n\nclass Widget {public:    // 方案一：为左值和右值分别重载    void addName(const std::string&amp; newName) { names.push_back(newName); }       // 复制左值    void addName(std::string&amp;&amp; newName)      { names.push_back(std::move(newName)); } // 移动右值private:    std::vector&lt;std::string&gt; names;};\n这种做法虽然正确且高效，但缺点是需要编写和维护两份几乎相同的代码。\n按值传递的替代方案条款41提出的替代方案是，编写一个单一的、按值传递的函数，并在函数体内 std::move 这个参数副本。\nclass Widget {public:    // 方案二：按值传递    void addName(std::string newName) { // newName 是一个副本        names.push_back(std::move(newName)); // 将副本移动到容器中    }private:    std::vector&lt;std::string&gt; names;};\n这个方案的精妙之处在于它如何利用移动语义来处理不同类型的实参。\n当传入一个左值时（例如 std::string name; w.addName(name);）：\n\n重载方案：const std::string&amp; 版本被调用。成本是 1 次复制（在 push_back 内部）。\n按值传递方案：形参 newName 通过复制构造函数从 name 创建。 (1 次复制); 在 push_back 内部，newName 被移动到 vector 中。(1 次移动). 总成本：1 次复制 + 1 次移动。\n\n当传入一个右值时（例如 w.addName(“hello”);）：\n\n重载方案：std::string&amp;&amp; 版本被调用。成本是 1 次移动（在 push_back 内部）。\n按值传递方案：形参 newName 通过移动构造函数从右值实参创建。(1 次移动); 在 push_back 内部，newName 被移动到 vector 中。(1 次移动). 总成本：2 次移动。\n\n因此, 与重载方案相比，按值传递方案在处理左值时多了一次移动，处理右值时也多了一次移动。\n按值传递的适用条件既然按值传递会带来额外的移动开销，那么只有在满足一系列严格条件时，它才是一个值得考虑的选项。这些条件都体现在条款的标题中：\n形参是可复制的 (Copyable)：如果参数是只移类型（如 std::unique_ptr），那么重载方案只需要写一个 T&amp;&amp; 版本即可（成本1次移动），而按值传递方案则需要2次移动，成本翻倍，因此不适用。\n移动成本低廉 (Cheap to Move)：按值传递方案的额外成本是一次移动。只有当这个移动操作非常廉价时（例如，对于 std::string 或 std::vector 等大多数标准容器），这笔额外开销才是可以接受的。\n形参一定会被复制 (Always Copied)：函数必须在所有代码路径上都确实需要这个参数的副本。如果函数中存在某个分支（例如一个检查失败的 if 语句）会提前返回而不使用该副本，那么按值传递方案中提前创建副本的开销就被浪费了。\n必须避免切片问题 (Slicing Problem)：按值传递不适用于多态场景。如果你按值传递一个基类对象，那么当调用者传入一个派生类对象时，其派生类特有的部分将被“切掉”，这通常会导致非预期的行为。\n总之, 按值传递并非要颠覆 C++98 中“避免按值传递”的传统智慧。然而，在现代 C++ 中，对于那些可复制、移动成本低、总是需要被复制且不涉及多态的参数，按值传递提供了一种简洁的替代方案。它用一次额外的廉价移动操作，换取了更少的代码量和更简单的维护，避免了函数重载或模板带来的复杂性。\n","categories":["language"],"tags":["language","CPP"]},{"title":"std::call_once 解决多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/4.%20std%20call_once/","content":"在多线程环境中，我们经常会遇到一个需求：确保某段代码（通常是初始化代码）在整个程序的生命周期中，无论有多少个线程并发调用它，都只被执行一次。一个经典的例子就是线程安全的懒汉式单例模式 (Lazy-Initialized Singleton)。\n#include &lt;iostream&gt;class Singleton {public:    static Singleton* getInstance() {        if (instance == nullptr) { // &lt;-- 竞争条件点 1            instance = new Singleton(); // &lt;-- 竞争条件点 2        }        return instance;    }private:    Singleton() { std::cout &lt;&lt; \"Singleton constructed.\\n\"; }    static Singleton* instance;};Singleton* Singleton::instance = nullptr;\n这段代码看起来似乎可以实现线程安全的懒汉式单例模式，但是在多线程环境下，它会立即崩溃。这段代码在多线程环境下会立即崩溃, 其原因是：\n\n假设线程 A 和线程 B 同时调用了 getInstance() 方法，且 instance 为 nullptr。\n线程 A 先进入 if 语句，发现 instance 为 nullptr，于是它开始创建 Singleton 的实例。\n线程 B 也进入 if 语句，发现 instance 为 nullptr，于是它也开始创建 Singleton 的实例。\n由于线程 A 和线程 B 都在创建 Singleton 的实例，所以就会发生竞态条件，导致 instance 被创建了两次。\n当线程 A 或线程 B 尝试访问 instance 时，就会发生访问冲突，导致程序崩溃。最终的结果是单例模式被破坏（创建了多个实例），并且造成了内存泄漏（第一个实例的指针被覆盖丢失）。\n\n虽然可以使用 std::mutex 来解决这个问题（这种模式被称为“双重检查锁定”，Double-Checked Locking），但手动实现起来复杂且容易出错。为了以一种更简单、更高效、更安全的方式解决这类问题，C++11 提供了 std::call_once。\nstd::call_oncestd::call_once 是一个函数模板，它配合一个 std::once_flag 对象，能够保证一个函数或可调用对象在多线程环境下只被成功调用一次。其核心部分如下：\n\nstd::once_flag:这是一个特殊的标记对象, 你可以把它想象成一个一次性的门锁或一次性的门票。它用于 std::call_once 来同步各个线程，并记录目标函数是否已经被调用过。std::once_flag 对象不可复制，也不可移动，通常被定义为 static、全局或类的成员变量，以便在多个线程调用点之间共享。\n\n**std::call_once(std::once_flag&amp; flag, Callable&amp;&amp; f, Args&amp;&amp;… args):这是执行调用的函数。\n\nflag：上面定义的 once_flag 对象的引用。\nf：你希望只被执行一次的可调用对象（如函数指针、Lambda表达式、函数对象等）。\nargs…：传递给可调用对象 f 的参数。\n\n\n\n另外注意的是, std::call_once 和 std::once_flag 都定义在头文件  中。\n使用 std::call_once 解决懒汉式单例模式的代码如下:\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt; // 需要包含 &lt;mutex&gt; 头文件#include &lt;vector&gt;class Singleton {public:    static Singleton* getInstance() {        // 所有线程都会尝试调用，但只有第一个线程能执行 Lambda 表达式        std::call_once(flag, []() {            instance = new Singleton();        });        return instance;    }private:    Singleton() { std::cout &lt;&lt; \"Singleton constructed.\\n\"; }        // 必须是 static，以便在所有调用中共享    static Singleton* instance;    static std::once_flag flag; };// 静态成员变量的定义Singleton* Singleton::instance = nullptr;std::once_flag Singleton::flag;// --- 测试代码 ---void create_instance() {    Singleton* s = Singleton::getInstance();    std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" got instance at \" &lt;&lt; s &lt;&lt; std::endl;}int main() {    std::vector&lt;std::thread&gt; threads;    for (int i = 0; i &lt; 10; ++i) {        threads.emplace_back(create_instance);    }    for (auto&amp; th : threads) {        th.join();    }    // 尽管有10个线程调用，\"Singleton constructed.\" 也只会被打印一次    return 0;}\n当第一个调用 getInstance() 的线程到达 std::call_once时, 它发现 flag 尚未被“标记”。因此这个线程会独占性地执行传入的 Lambda 表达式（即 instance = new Singleton();）。\n在此期间，如果其他线程也调用了 getInstance() 并到达 std::call_once，它们会阻塞等待，直到第一个线程的 Lambda 表达式执行完毕。\n当第一个线程成功执行完 Lambda 后，std::call_once 会将 flag 永久地标记为“已完成”。所有之前阻塞等待的线程会被唤醒，并从 std::call_once 返回。它们不会再次执行 Lambda。\n此后任何线程再调用 std::call_once 并传入同一个 flag 对象，都会发现 flag 已被标记，于是会立即返回，不做任何事。\n它的优势是线程安全：由标准库保证其实现的线程安全性，无需手动加锁; 高效：相比于每次调用都加锁的互斥量方案，std::call_once 在初始化完成后，后续的调用开销极低（通常只是一次无锁的内存读取）, 且代码简洁，意图明确：清晰地表达了“此代码只执行一次”的意图。\n主要应用于上述提到的线程安全的懒汉式单例模式和一次性全局初始化(程序中某些模块或资源只需要被初始化一次。例如首次使用时才加载配置文件, 首次需要时才初始化日志系统, 首次访问时才建立一个全局的数据库连接池等)\n\n下面也提到了, 单例模式的实现可以通过 Magic statics来实现, 但是如果你有更通用的、不局限于静态变量初始化的“执行一次”的需求，std::call_once 依然是那个最合适的、强大的工具。\n\n单例模式（Singleton Pattern）单例模式（Singleton Pattern）是一种在软件设计中被广泛使用的创建型设计模式, 核心思想是确保一个类在任何情况下只有一个实例，并为该实例提供一个全局唯一的访问点。\n想象一下，系统中有一些组件是“全局唯一”的，比如：\n\n配置管理器：整个应用程序共享同一份配置信息。\n日志记录器：所有模块都应该将日志写入同一个日志文件。\n数据库连接池：管理一组数据库连接，避免频繁创建和销毁连接的开销。\n线程池：统一管理和调度一组工作线程。\n\n在这些场景下，如果创建多个实例，可能会导致程序行为异常（如配置不一致）、资源过度使用（如过多的数据库连接）或结果不可预测。单例模式正是为了解决这类问题而生的。\n单例模式的实现要点要实现一个标准的单例模式，通常需要满足以下几个关键条件：\n私有化构造函数 (Private Constructor): \n\n为了防止外部代码通过 new 关键字随意创建类的实例。这是保证类实例唯一性的基础。\n如果构造函数是 public 的，那么任何地方都可以自由地创建该类的对象，就无法实现“单例”的目标。\n\n私有静态实例变量 (Private Static Instance)\n\n在类的内部持有那个唯一的实例。\n使用 static 关键字可以确保这个实例变量属于类本身，而不是类的某个对象，因此它在内存中只有一份。将其设为 private 是为了防止外部直接访问和修改它。\n\n公有静态访问方法 (Public Static Access Method)\n\n提供一个全局唯一的、可供外部访问该实例的入口。这个方法通常被命名为 getInstance() 或类似名称。\n这是外部世界获取单例实例的唯一途径。该方法会检查实例是否已经被创建：如果尚未创建，则创建它；如果已经存在，则直接返回。\n\n单例模式主要有两种经典的实现方式：饿汉式（Eager Initialization） 和 懒汉式（Lazy Initialization）。\n饿汉式（Eager Initialization）饿汉式在类加载的时候就立即创建实例，因此它是线程安全的。\n优点是实现简单; 且在类加载时就完成了实例化，避免了多线程同步问题，是天然线程安全的。\n缺点是如果这个实例从未使用过，会造成内存浪费。因为它不是在需要时才创建，而是一开始就创建了。\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;// 饿汉式单例class SingletonEager {public:    // 提供全局访问点, 返回单例对象的指针    static SingletonEager* getInstance() {        return instance;    }    // 禁止外部复制或赋值    SingletonEager(const SingletonEager&amp;) = delete;    SingletonEager&amp; operator=(const SingletonEager&amp;) = delete;    void showMessage() const {        std::cout &lt;&lt; \"Eager Singleton instance address: \" &lt;&lt; this &lt;&lt; std::endl;    }private:    // 1. 私有化构造函数    SingletonEager() {        std::cout &lt;&lt; \"Eager Singleton instance created.\" &lt;&lt; std::endl;    }    // 2. 静态成员变量声明    static SingletonEager* instance;    // 可以在内部定义一个垃圾回收类来自动释放内存    class GarbageCollector {    public:        ~GarbageCollector() {            if (SingletonEager::instance != nullptr) {                std::cout &lt;&lt; \"Eager Singleton instance destroyed.\" &lt;&lt; std::endl;                delete SingletonEager::instance;                SingletonEager::instance = nullptr;            }        }    };    // 静态成员，程序结束时会自动调用其析构函数    // 这是一个巧妙的技巧，用于自动释放 new 出来的单例内存。gc 是一个静态成员对象，它的生命周期是整个程序。当程序结束时，gc 对象会被销毁，此时它的析构函数 ~GarbageCollector() 会被自动调用，从而 delete 掉我们创建的 instance，避免了内存泄漏。    static GarbageCollector gc;};// 3. 在类外初始化静态成员变量，这是饿汉式的关键// 这行代码会在 main 函数执行前被调用, 创建实例, 并将其地址赋给 instance 指针。无论 getInstance() 被调用多少次，都返回这个早已创建好的实例。 SingletonEager* SingletonEager::instance = new SingletonEager();SingletonEager::GarbageCollector SingletonEager::gc;\n\n懒汉式单例懒汉式在第一次被调用 getInstance() 方法时才创建实例。这种方式延迟了对象的创建时间。\n优点是实现了延迟加载（Lazy Loading），只有在实际需要时才创建实例，节约了资源。\n缺点是在多线程环境下，如果不进行同步处理，可能会创建出多个实例，从而破坏单例模式。因此，必须处理线程安全问题。\n我们当然可以像上述代码一样使用std::call_once来实现单例模式, 然而在 C++11 及以后，最推荐的懒汉式实现是使用静态局部变量（Meyers’ Singleton），因为它既简洁又线程安全, 并且避免了手动管理裸指针。编译器和标准库在底层为你实现了与 std::call_once 类似的安全保障。\n\n\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;// 懒汉式单例 (C++11 推荐的 Meyers' Singleton 写法)class SingletonLazy {public:    static SingletonLazy&amp; getInstance() {        // C++11 标准保证，静态局部变量的初始化是线程安全的，并且只会发生一次        static SingletonLazy instance;        return instance;    }    // 禁止外部复制或赋值    SingletonLazy(const SingletonLazy&amp;) = delete;    SingletonLazy&amp; operator=(const SingletonLazy&amp;) = delete;    void showMessage() const {        std::cout &lt;&lt; \"Lazy Singleton (Meyers') instance address: \" &lt;&lt; this &lt;&lt; std::endl;    }private:    // 1. 私有化构造函数    SingletonLazy() {        std::cout &lt;&lt; \"Lazy Singleton instance created.\" &lt;&lt; std::endl;    }    // 2. 析构函数    ~SingletonLazy() {        std::cout &lt;&lt; \"Lazy Singleton instance destroyed.\" &lt;&lt; std::endl;    }};\n\nstatic SingletonLazy instance;：这是懒汉式实现的核心。instance 位于 getInstance() 函数内部，是一个静态局部变量。只有当 getInstance() 函数第一次被调用时，instance 才会在这里被初始化。如果函数从未被调用，实例就永远不会被创建。\n\n线程安全：C++11 标准明确规定，这种静态局部变量的初始化过程必须是原子性的，即线程安全的。编译器和运行时库会处理好多线程同时首次调用 getInstance() 的同步问题。\n\n自动内存管理：instance 的生命周期与程序相同，程序结束时它会自动被销毁，无需像饿汉式那样手动管理内存。\n\n\n显然, 如果实例的创建成本不高，且在程序启动后肯定会被用到，饿汉式是更简单、更可靠的选择; 如果实例的创建非常耗时或占用大量资源，并且不确定是否会用到它，懒汉式（特别是双重检查锁定版本）是更好的选择。\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"条款32：使用初始化捕获将对象移入闭包","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE32%20-%20%E4%BD%BF%E7%94%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8D%95%E8%8E%B7%E5%B0%86%E5%AF%B9%E8%B1%A1%E7%A7%BB%E5%85%A5%E9%97%AD%E5%8C%85/","content":"在 C++11 中，lambda 的捕获列表 [] 只能捕获在 lambda 所在作用域内可见的变量，捕获方式只有两种：按值复制或按引用。这导致了一个问题：C++11 无法直接将对象“移动”到闭包中。\n这个局限对两类对象影响很大：\n\n只移类型 (Move-only Types)：像 std::unique_ptr、std::future 或 std::thread 这样的类型，它们是不能被复制的。因此，在 C++11 中，你无法将它们捕获到 lambda 闭包中。\n\n复制成本高昂的类型：像 std::vector 或 std::string 这样的大多数标准库容器，复制它们的成本可能很高，但移动它们的成本却很低。在 C++11 中，如果你想在闭包中拥有一份容器的副本，你只能付出高昂的复制代价。\n\n\n这个问题就是下面介绍的初始化捕获所要解决的\nC++14 解决方案：初始化捕获 (Init Capture)C++14 引入了一种全新的、更强大的捕获机制，被称为初始化捕获，也叫广义 lambda 捕获 (generalized lambda capture)。它彻底解决了 C++11 的局限。\n初始化捕获允许你做两件事：在 lambda 生成的闭包类中，指定一个新成员变量的名字; 提供一个表达式，用于初始化该成员变量。\n语法为：[新变量名 = 初始化表达式]\n下面是利用初始化捕获实现移动捕获的一个例子：\nauto pw = std::make_unique&lt;Widget&gt;();// C++14: 使用初始化捕获，将 pw 移动到闭包的新成员 pw 中auto func = [pw = std::move(pw)] {     return pw-&gt;isValidated() &amp;&amp; pw-&gt;isArchived(); };\npw = std::move(pw) 的含义是：在闭包中创建一个名为 pw 的新成员，并用 std::move(pw) 的结果来初始化它。等号左侧的 pw 是闭包的成员，而右侧的 pw 是外部作用域的局部变量。\n此外, 初始化捕获甚至能“捕获”一个表达式的结果，这是 C++11 捕获完全做不到的：\n// C++14: 直接用表达式的结果初始化闭包成员auto func = [pw = std::make_unique&lt;Widget&gt;()] {    return pw-&gt;isValidated() &amp;&amp; pw-&gt;isArchived();};\n\n\nC++11 的变通方案：使用 std::bind 模拟","categories":["language"],"tags":["language","CPP"]},{"title":"条款35 ：优先选用基于任务而非基于线程的程序设计","url":"/2025/09/22/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE35%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E5%9F%BA%E4%BA%8E%E4%BB%BB%E5%8A%A1%E8%80%8C%E9%9D%9E%E5%9F%BA%E4%BA%8E%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/","content":"该条款的核心观点是，当需要异步运行一个函数时，使用 std::async 的基于任务 (task-based) 的方法，通常优于直接使用 std::thread 的基于线程 (thread-based) 的方法。\n基于线程 (Thread-based) 与 std::threadstd::thread 是 C++ 标准库中对操作系统线程 (Thread) 的直接封装。线程可以看作是 CPU 上一个独立的执行流。\nstd::asyncstd::async 是一个函数模板，用于以异步方式（可能在一个单独的线程中）启动一个任务。相比于直接使用 std::thread，std::async 提供了一种更高层次、更方便的抽象，特别适用于那些需要从异步任务中获取返回值的场景。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款39 ：考虑针对一次性事件通信使用以 void 为模板型别实参的期值","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE39%20-%20%E8%80%83%E8%99%91%E9%92%88%E5%AF%B9%E4%B8%80%E6%AC%A1%E6%80%A7%E4%BA%8B%E4%BB%B6%E9%80%9A%E4%BF%A1%E4%BD%BF%E7%94%A8%E4%BB%A5%20void%20%E4%B8%BA%E6%A8%A1%E6%9D%BF%E5%9E%8B%E5%88%AB%E5%AE%9E%E5%8F%82%E7%9A%84%E6%9C%9F%E5%80%BC/","content":"","categories":["language"],"tags":["language","CPP"]},{"title":"条款40 ：对并发使用 std atomic，对特种内存使用 volatile","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE40%20-%20%E5%AF%B9%E5%B9%B6%E5%8F%91%E4%BD%BF%E7%94%A8%20std%20atomic%EF%BC%8C%E5%AF%B9%E7%89%B9%E7%A7%8D%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%20volatile/","content":"","categories":["language"],"tags":["language","CPP"]},{"title":"条款37 ：使 std::thread 型别对象在所有路径皆不可联结","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE37%20-%20%E4%BD%BF%20std%20thread%20%E5%9E%8B%E5%88%AB%E5%AF%B9%E8%B1%A1%E5%9C%A8%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84%E7%9A%86%E4%B8%8D%E5%8F%AF%E8%81%94%E7%BB%93/","content":"该条款的核心论点是，由于销毁一个可联结（joinable）的 std::thread 对象会导致程序终止，因此开发者必须确保在 std::thread 对象被销毁前，在代码的所有可能路径上都将其变为不可联结状态(设定join()或detach())。\nstd::thread 的可联结性 (Joinability)一个 std::thread 对象存在两种状态：\n\n可联结 (Joinable)：该 std::thread 对象对应于一个底层的、正在运行或已完成运行的系统线程。\n不可联结 (Unjoinable)：该 std::thread 对象不对应任何正在运行的线程。这包括：\n默认构造的 std::thread（还未关联任何线程）。\n已被移动的 std::thread（所有权已转移）。\n已被 join 的 std::thread（已等待其完成）。\n已被 detach 的 std::thread（已与其底层线程分离）。\n\n\n\n最关键的规则：当一个可联结的 std::thread 对象的析构函数被调用时(此时还不应该结束)，程序的执行会立即终止。\n制定这条严格规则的原因是，另外两种看似合理的备选方案————隐式 join() 和隐式 detach()会带来更严重的问题。\n\n隐式 Join (Implicit Join) 指的是一个管理线程生命周期的对象（例如一个线程包装类）在其析构函数中自动调用 join() 方法的行为。这意味着当该对象离开其作用域（scope）并被销毁时，程序会自动地、无需显式代码指示地阻塞，直到它所管理的线程执行完毕。这是一种设计选择，而不是 C++ std::thread 的标准行为。std::thread 本身不会进行隐式 join。\n\n\n隐式 Join 的缺陷：性能陷阱。它可能在开发者不经意间引入长时间的阻塞，使程序的性能变得不可预测和难以调试。一个看似简单的函数返回或对象销毁，背后可能隐藏着一个漫长的等待。\n隐式 Detach 的缺陷：未定义行为。如果析构函数自动 detach()，线程可能会继续访问已经销毁的局部变量（通过引用或指针捕获），导致内存崩溃。这是比性能问题更严重的安全问题。\n\n由于隐式 join 和隐式 detach 都存在严重缺陷，标准委员会选择了最安全、最明确的策略：直接终止程序，迫使开发者必须显式地处理线程的生命周期。\n解决方案：使用 RAII 对象确保线程被处理确保在代码的所有退出路径（包括正常返回、break、continue 和异常）上都执行某个操作的最佳 C++ 实践是RAII (Resource Acquisition Is Initialization)。即创建一个局部对象，并在其析构函数中执行所需的操作。\n标准库没有为 std::thread 提供现成的 RAII 类，但我们可以自己轻松实现一个。\n\n你可能疑惑, 上面的隐式 join() 不也是通过 RAII 封装线程类实现的吗? 为什么上面的不可以, 而下面的可以? 问题的根源不在于使用 RAII 本身，而在于那个“坏”的 RAII 对象实现了一个糟糕的、隐晦的策略（比如总是 join 或总是 detach）; 而解决方案中的“好”的 RAII 对象，则实现了一个优秀的、明确的策略, 程序员通过将解决策略显式地指出, 确保我们预先设定的、明确的策略（通常是 join）在任何情况下都能被严格执行。\n\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;stdexcept&gt;class thread_guard {public:    // 构造函数获取线程的引用    explicit thread_guard(std::thread&amp; t) : t_(t) {}    // 析构函数：如果线程还 joinable，就 join 它    ~thread_guard() {        if (t_.joinable()) {            t_.join();        }    }    // 删除拷贝构造和赋值操作，防止所有权混乱    thread_guard(const thread_guard&amp;) = delete;    thread_guard&amp; operator=(const thread_guard&amp;) = delete;private:    std::thread&amp; t_;};void do_something_in_background() {    std::cout &lt;&lt; \"后台任务运行中...\\n\";    // 模拟抛出异常    throw std::runtime_error(\"后台任务发生错误!\");    std::cout &lt;&lt; \"后台任务完成。\\n\";}void process() {    std::cout &lt;&lt; \"process 函数开始。\\n\";    std::thread t(do_something_in_background);        // *** 关键在这里 ***    // 我们显式地创建了一个 guard 对象，其意图非常明确：    // “我希望在这个作用域的任何出口处，都对线程 t 执行 join 操作”    thread_guard g(t);    std::cout &lt;&lt; \"process 函数即将结束（或因异常退出）。\\n\";    // 当 process 因为异常而退出时，g 的析构函数会被调用    // g 的析构函数会安全地 join 线程 t}int main() {    try {        process();    } catch (const std::exception&amp; e) {        std::cout &lt;&lt; \"main 捕获到异常: \" &lt;&lt; e.what() &lt;&lt; std::endl;    }    return 0;}\n线程的创建 (std::thread t(…)) 和“生命周期管理策略” (thread_guard g(t)) 是分离的、显式的。程序员通过创建 thread_guard 对象，清晰地表达了“我要在这个作用域结束时 join 这个线程”的意图。这不再是隐式的行为，而是一种明确的声明。即使函数因为异常而提前退出，这个声明依然有效，保证了程序的健壮性。\nC++20 的终极解决方案：std::jthreadC++20 标准直接引入了 std::jthread，它本质上就是一个官方实现的、更加完善的 thread_guard。它的析构函数总是会 join，但这是它公开的、众所周知的、作为其核心设计的行为。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款36 ：如果异步是必要的，则指定 std::launch::async","url":"/2025/09/22/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE36%20-%20%E5%A6%82%E6%9E%9C%E5%BC%82%E6%AD%A5%E6%98%AF%E5%BF%85%E8%A6%81%E7%9A%84%EF%BC%8C%E5%88%99%E6%8C%87%E5%AE%9A%20std%20launch%20async/","content":"该条款的核心论点是，std::async 的默认启动策略虽然为标准库调度器提供了有用的灵活性，但也给程序员带来了不确定性，可能导致难以发现的bug。因此，当你确实需要函数必须异步执行时，就应该明确指定这一点。\nstd::async 的启动策略std::async 可以接受一个启动策略参数，来控制任务的执行方式：\n\nstd::launch::async：此策略保证任务会在一个不同的线程上异步执行 。\nstd::launch::deferred：此策略意味着任务会被延迟执行。它只会在返回的 std::future 对象上调用 get() 或 wait() 时，才同步地（即阻塞地）在调用 get() 或 wait() 的那个线程上执行。如果 get() 或 wait() 一直未被调用，任务将永远不会执行 。\n默认启动策略：如果你不指定任何策略，std::async 会使用 std::launch::async | std::launch::deferred 的组合策略 。\n\n默认的组合策略赋予了标准库调度器极大的灵活性，让它可以根据系统当前的线程负载情况来决定任务的执行方式，这有助于避免线程耗尽和超订问题（如条款35所述）。然而，这种灵活性也给程序员带来了几个严重的不确定性：\n\n无法预知任务是否并发运行：你无法保证任务 f 会与调用 std::async 的线程 t 并发执行 。\n无法预知任务运行在哪一个线程上：你无法确定任务 f 是运行在一个新线程上，还是运行在对 future 调用 get() 或 wait() 的那个线程上 。这对 thread_local 变量的使用会产生影响 。\n无法保证任务一定会被执行：如果 std::async 返回的 future 在程序的任何路径上都未被调用 get() 或 wait()，那么被延迟执行的任务可能永远不会启动。\n\n核心陷阱：基于超时的 wait 与无限循环默认策略最危险的陷阱在于它与基于超时的等待函数（如 wait_for）的交互\nusing namespace std::literals;void f() {    std::this_thread::sleep_for(1s);}auto fut = std::async(f); // 采用默认启动策略// 意图是每 100ms 检查一次任务是否完成while (fut.wait_for(100ms) != std::future_status::ready) {    // ... 这个循环可能永远不会结束！}\n如果调度器因为系统负载过高等原因，为任务 f 选择了 std::launch::deferred 策略，那么 fut.wait_for(…) 的返回值将永远是 std::future_status::deferred。这也就意味着, fut.wait_for(…) 的结果永远不等于 std::future_status::ready，导致 while 循环成为一个无限循环。这个bug非常隐蔽，因为它可能只在高负载的生产环境中才会出现。\n解决方案：显式指定启动策略该条款给出的结论非常明确：如果你需要确保任务必须异步执行，从而避免上述所有不确定性和陷阱，你就必须在调用 std::async 时显式指定 std::launch::async 启动策略。\nauto fut = std::async(std::launch::async, f); // 保证 f 会异步执行\n这样做之后，f 一定会在一个不同的线程上运行，你可以安全地使用基于超时的 wait，并且不必担心任务会因为未调用 get 或 wait 而不被执行。\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款38 ：对变化多端的线程句柄析构函数行为保持关注","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE38%20-%20%E5%AF%B9%E5%8F%98%E5%8C%96%E5%A4%9A%E7%AB%AF%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%8F%A5%E6%9F%84%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%E8%A1%8C%E4%B8%BA%E4%BF%9D%E6%8C%81%E5%85%B3%E6%B3%A8/","content":"该条款的核心论点是，std::thread 和期值（std::future / std::shared_future）虽然都可以看作是系统线程的句柄，但它们的析构函数行为却截然不同，这种差异对于编写健壮的并发代码至关重要。\n对于std::thread, 正如前面所说, 其析构函数的行为非常严格和明确：如果 std::thread 对象是可联结的 (joinable)，其析构函数的调用将导致程序终止 \n与 std::thread 不同，期值(std::future)析构函数的行为要复杂得多。为了理解它，首先需要了解共享状态 (shared state) 的概念: 共享状态是期值通信机制的核心。它通常是在堆上分配的一个对象，用于存储由异步任务（被调方）计算出的结果或抛出的异常，并将其传递给期值（调用方） 。\n期值析构函数的行为完全取决于其所引用的共享状态。具体来说，有两种截然不同的行为模式。\n常规行为：仅析构期值对象\n对于绝大多数期值，其析构函数只会做一件事：销毁期值对象本身。这意味着它不会 join，也不会 detach，不会阻塞，也不会运行任何东西。它仅仅是销毁期值的成员变量，并递减共享状态的引用计数。这种常规行为适用于所有通过 std::promise 或 std::packaged_task 创建的期值。\n特殊行为：阻塞并等待\n存在一个非常重要的例外情况。当且仅当一个期值同时满足以下所有条件时，其析构函数会阻塞，直到异步任务完成（效果等同于隐式的 join）：该期值所引用的共享状态是由 std::async 的调用所创建的。该任务的启动策略是 std::launch::async （无论是显式指定还是由默认策略选择的）。该期值是最后一个引用该共享状态的期值。\n// 析构函数可能会阻塞std::vector&lt;std::future&lt;void&gt;&gt; futs; class Widget {private:    // Widget 对象的析构函数可能会阻塞    std::shared_future&lt;double&gt; fut;};\n如果这些容器或对象中持有的期值恰好是最后一个引用由 std::async 启动的异步任务的期值，那么在容器或对象析构时，程序就会在此处阻塞，直到任务完成。\n特殊行为的成因与后果\n成因：标准委员会为了避免隐式 detach 可能导致的未定义行为（参见条款37），但又不希望像 std::thread 那样直接终止程序，最终妥协设计了这种针对 std::async 任务的隐式 join 行为。\n后果：开发者无法仅通过期值的类型来判断其析构函数是否会阻塞。这可能会在不经意间引入性能问题，尤其是在关键路径上或GUI线程中，意外的阻塞可能是致命的。\n因此，在处理期值时，了解其来源至关重要。如果一个期值来自 std::async，你就必须警惕其析构函数可能导致的阻塞行为。\n","categories":["language"],"tags":["language","CPP"]},{"title":"缓存替换策略","url":"/2025/09/28/algorithms/%E7%BC%93%E5%AD%98%E6%9B%BF%E6%8D%A2%E7%AD%96%E7%95%A5/","content":"自适应替换缓存（Adaptive Replacement Cache, ARC）"},{"title":"动态规划(Dynamic Programming)","url":"/2025/09/02/algorithms/DynamicProgramming/DynamicProgramming/","content":"动态规划（Dynamic Programming, DP） 是一种通过将复杂问题分解为更小的、重叠的子问题来求解的算法思想。它与分治法（Divide and Conquer）有些相似，但不同之处在于，动态规划适用于子问题重叠的场景，即不同的子问题会共享更小的子子问题。\nDP的核心思想是 “记忆化” 或 “表格法”，即计算过一次的子问题的解，就将其存储起来，避免重复计算。这是一种典型的 “空间换时间” 的策略，通过使用额外的内存来存储中间结果，从而显著降低计算的时间复杂度。\n适用条件一个问题能否使用动态规划来解决，通常取决于它是否满足以下三个核心特征：\n最优子结构 (Optimal Substructure)\n\n问题的最优解包含其子问题的最优解。换句话说，我们可以通过组合子问题的最优解来构造出原问题的最优解。\n\n例如：在最短路径问题中，从A到C的最短路径，如果经过B点，那么这条路径中从A到B的部分也必然是A到B的最短路径。\n\n\n重叠子问题 (Overlapping Subproblems)\n\n在问题的求解过程中，许多子问题会被反复计算。DP的威力正体现在此，它通过存储已解决的子问题的答案来避免这种不必要的重复计算。\n\n例如：在计算斐波那契数列时，F(5) 依赖 F(4) 和 F(3)，而 F(4) 依赖 F(3) 和 F(2)。F(3) 就是一个被重复计算的重叠子问题。\n\n\n无后效性 (No Aftereffect)\n\n一旦某个阶段的状态确定，它就不会再被后续的决策所改变。当前状态只与之前的状态有关，而与之后的状态无关。我们做的每一个决策都是基于当前已有的信息，而不用担心未来的决策会反过来影响当前决策的正确性。\n\n解题步骤解决一个动态规划问题，通常可以遵循以下四个步骤，这是一个系统性的思考框架。\n第一步：定义状态\n这是动态规划中最关键，也往往是最困难的一步。状态定义需要清晰、无歧义，并且能够涵盖解决问题所需的所有信息。\n一个常见且可行的操作是创建一个数组（通常称为 dp 数组），并明确 dp[i] 或 dp[i][j] 代表什么。\n\n例如：在计算斐波那契数列时，dp[i] 可能代表“第i个斐波那契数”。\n例如：在爬楼梯问题中，dp[i] 可能代表“爬到第i级台阶的方法数”。\n例如：在背包问题中，dp[i][j] 可能代表“前i个物品在容量为j的背包中的最大价值”。\n\n状态的定义必须能够帮助我们推导出最终的答案。一个好的状态定义是成功的一半。\n第二步：确定状态转移方程\n状态转移方程是动态规划的核心，它描述了不同状态之间是如何关联和演进的。\n具体而言, 我们需要找出 dp[i] 与 dp[i-1], dp[i-2], … 等之前状态的关系。\n这个方程是问题的数学模型。它告诉我们如何利用已知的子问题的解来计算出当前问题的解。例如，爬楼梯问题中，爬到第 i 级台阶的方法数等于爬到第 i-1 级和第 i-2 级的方法数之和，其状态转移方程就是 。\n第三步：初始化\n任何递推关系都需要一个或多个起点，这就是初始状态。\n我们需要根据状态定义，为 dp 数组中的基础情况（base case）赋初值。\n例如，在斐波那契数列中， 就是初始状态。如果初始化错误，后续的所有计算都会是错误的。\n第四步：确定遍历顺序\n根据状态转移方程，我们需要确定计算 dp 数组的顺序, 也就是决定循环是从前向后还是从后向前，或者对于二维数组是逐行还是逐列。\n遍历顺序必须保证，在计算 dp[i] 时，所有它所依赖的状态（如 dp[i-1]）都已经计算出来了。这通常意味着从小规模的问题向大规模问题进行迭代。\n两种模式动态规划 (Dynamic Programming, DP) 的核心是将一个大问题分解成若干个子问题，并存储子问题的解以避免重复计算。它主要有两种实现方式：\n\n自顶向下 (Top-Down) DP：通常通过 递归 + 记忆化 来实现。\n\n自底向上 (Bottom-Up) DP：通常通过 迭代 + 表格 来实现。\n\n\n\n自顶向下 (Top-Down) 动态规划 — 记忆化搜索\n\n这种方法也称为 记忆化搜索 (Memoization)。核心思想是从我们最终要求解的大问题出发，通过递归函数去解决它。如果在这个过程中遇到了一个子问题，我们先检查是否已经计算过这个子问题（即“记忆”里有没有）。\n如果计算过，直接从“记忆”中取出答案; 如果没有计算过，就递归地去解决这个子问题，并将计算出的结果存入“记忆”中，以备后用。\n这个过程就像是从树的顶部（根节点，即原始问题）开始，向下探索到树的底部（叶子节点，即最小的子问题）。\n\n自底向上 (Bottom-Up) 动态规划 — 表格法\n\n这种方法也称为 表格法 (Tabulation)。核心思想完全反过来，我们不从大问题开始，而是从能够直接求解的、最小的子问题开始。然后利用这些小问题的解，像搭积木一样，一步步地构建出更大问题的解，直到最终解决了我们想要的那个大问题。\n这个过程通常用一个数组或矩阵（我们称之为 dp 表）来完成，通过迭代（for循环）的方式，按照从小到大的顺序填充表格。\n\n\n\n特征 (Feature)\n自顶向下 (Top-Down)\n自底向上 (Bottom-Up)\n\n\n\n实现方式\n递归 + 记忆化 (Memoization)\n迭代 + 表格法 (Tabulation)\n\n\n思路方向\n从 大问题 分解到 小问题\n从 小问题 构建到 大问题\n\n\n子问题计算\n按需计算：只计算解决最终问题所必需的子问题。\n计算所有：通常会计算出所有可能的子问题的解。\n\n\n代码直观性\n通常更符合人类的直觉，因为其逻辑直接遵循问题的递归定义。\n可能需要更仔细地设计循环和状态转移的顺序。\n\n\n性能\n可能会因递归深度过大导致栈溢出。函数调用有一定开销。\n没有递归开销，通常性能略好一些。\n\n\n二维降一维在动态规划中，很多问题的状态可以用二维数组来表示，例如 dp[i][j] 代表某个子问题的解。然而，二维数组往往会占用较多的空间，有时我们可以通过观察状态转移方程，发现某些情况下，当前状态只依赖于前一行或前一列的状态，从而将二维数组优化为一维数组(节省了空间, 但是循环仍旧是二维的)。\n例如, 在某道题的二维 DP 中，状态转移方程是：\n\n这个公式告诉我们，要计算当前单元格 (i, j) 的路径数，我们只需要它正上方的单元格 (i-1, j) 和它正左方的单元格 (i, j-1) 的路径数。\n这意味着，当我们在计算第 i 行的数据时，我们实际上只用到了第 i-1 行（上一行）和当前行但是前一个的数据。更早的行（如第 i-2 行、第 i-3 行）的数据已经不再需要了。\n因此，我们没有必要存储整个 m×n 的二维表格，这造成了空间浪费。我们可以用一个一维数组来“滚动”计算，从而将空间复杂度从 O(m×n) 优化到 O(n)。这个一维数组在每次迭代中，都保存着“上一行”的计算结果。\n原代码：\nclass Solution {public:    int uniquePaths(int m, int n) {        vector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n));        dp[0][0] = 1;        int i,j;        for(i=1;i&lt;n;i++){            dp[0][i] = 1;        }        for(i=1;i&lt;m;i++){            dp[i][0] = 1;        }        for(i=1;i&lt;m;i++){            for(j=1;j&lt;n;j++){                dp[i][j] = dp[i-1][j] + dp[i][j-1];            }        }        return dp[m-1][n-1];    }};\n优化后：\nclass Solution {public:    int uniquePaths(int m, int n) {        // 1. 初始化        vector&lt;int&gt; dp(n, 1);        // 2. 遍历行        for (int j = 1; j &lt; m; j++) {            // 3. 遍历列            for (int i = 1; i &lt; n; i++) {                // 4. 状态转移                dp[i] += dp[i - 1];            }        }                // 5. 返回结果        return dp[n - 1];    }};\n第一步是创建一个大小为 n (网格的列数) 的一维数组 dp，并将其所有元素初始化为 1。\n这步操作相当于计算了二维网格中第一行 的所有路径数。对于第一行的任何一个单元格 (0, j)，都只有一条路径可以到达，那就是从起点 (0, 0) 一直向右走。所以 dp[0][j] 恒为 1。\ndp 数组此时的状态是 {1, 1, 1, …, 1}，代表了第一行 m=0 时每个位置的路径数。\n接着每一次外层循环的开始，dp 数组里存储的都是 上一行 (j-1) 的计算结果。我们的目标是在这次循环中，利用这些结果计算出 当前行 (j) 的结果，并更新 dp 数组。\n这一步是核心: dp[i] += dp[i - 1];\n在执行 dp[i] += dp[i-1] 这行代码时：\n\n= 左边的 dp[i]：它里面存储的还是 上一行 的值，因为它在本次内层循环中还没有被更新。这正好对应二维公式中的 dp [j−1][i] (来自上方的路径)。\n\n= 右边的 dp[i-1]：它在本次内层循环的上一步 (i 的值还是 i-1 时) 已经被更新了。所以它存储的是 当前行左边单元格的值。这正好对应二维公式中的 dp [j][i−1] (来自左方的路径)。\n\n\n因此，dp[i] += dp[i-1] 就等价于：$$dp[i]{\\text{新}} = dp[i]{\\text{旧}} + dp[i-1]_{\\text{新}}$$\n这完美地实现了二维状态转移方程的功能，但只用了一个一维数组。\n例题例题1: 最长递增子序列给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n示例 1：\n\n输入：nums = [10,9,2,5,3,7,101,18]\n输出：4, 因为最长递增子序列是 [2,3,7,101]，因此长度为 4 。\n\n示例 2：\n\n输入：nums = [0,1,0,3,2,3]\n输出：4, 因为最长递增子序列是 [0,1,2,3]，因此长度为 4 。\n\n示例 3：\n\n输入：nums = [7,7,7,7,7,7,7]\n输出：1, 因为最长递增子序列是 [7]，因此长度为 1 。\n\n\n    答案及分析 \n    \n      这个问题的关键在于准确定义状态dp[i]的含义, 如果按照一般的dp[i] = 到 i 的子数组（即 nums[0…i]）中最长递增子序列的长度, 那么在从 i 推进到 i+1 的过程中丢失了至关重要的信息！这个信息就是：“构成 LIS 的那个子序列，它的结尾元素是谁？也就是说, 我们假如只知道dp[i]=x, 是无法推出dp[i+1]的, 因为我们并不知道结尾元素是哪个, 只有知道了结尾元素, 才能判断是否能构成递增子序列.\n因此我们定义dp[i] = 以 nums[i] 这个元素结尾的最长递增子序列的长度, 实现将“结尾元素”这个约束条件直接融入状态定义中\n假如我们还是坚持定义 dp_naive[i] = nums[0…i] 中的 LIS 长度呢? 我们的目标是推导出 dp_naive[i] 和 dp_naive[i-1] 之间的关系。\n此时dp_naive[i] 的值有两种可能性：\n\nLIS 不包含 nums[i]：这种情况下，nums[0…i] 的 LIS 和 nums[0…i-1] 的 LIS 是完全一样的。所以，dp_naive[i] = dp_naive[i-1]。\n\nLIS 包含 nums[i]：: 这种情况就复杂了。如果 LIS 包含 nums[i]，那么 nums[i] 必然是这个 LIS 的最后一个元素。这个 LIS 的形式就是 […, a, b, nums[i]]。这意味着，我们需要在 nums[0…i-1] 中，找到一个以某个小于 nums[i] 的数字结尾的、最长的递增子序列，然后把 nums[i] 接在它后面。这个新的长度就是 (那个子序列的长度) + 1。\n\n\n我们把这两种可能性结合起来：dp_naive[i] = max( dp_naive[i-1], (在 nums[0…i-1] 中以 &lt; nums[i] 的数结尾的 LIS 长度) + 1 )\n而后者, “在 nums[0…i-1] 中以 &lt; nums[i] 的数结尾的 LIS 长度”, 这个东西，我们能从 dp_naive[i-1] 这个单一的数字里得到吗？完全不能！所以为了计算这个值，我们别无选择，只能在计算 dp_naive[i] 的时候，重新遍历 j 从 0 到 i-1，对于每一个 j，我们都去计算“以 nums[j] 结尾的 LIS 长度”\n而为了计算 dp_naive[i]，被迫要去计算所有 j &lt; i 的**“以 nums[j] 结尾的 LIS 长度”**, 这不正是我们之前讨论的那个“最优”定义吗?\n所以，下次再遇到 DP 问题想不出状态定义时，可以问自己一个问题：“为了从 dp[i] 推导出 dp[i+1]，我需要哪些额外信息？我能不能把这些额外信息变成状态定义的一部分？”\nclass Solution {public:    int lengthOfLIS(vector&lt;int&gt;&amp; nums) {        int n = nums.size();        int i,j;        vector&lt;int&gt; dp(n);        dp[0] = 1;        int maxdp = 1;        for(i=1;i&lt;n;i++){            // dp[i]            vector&lt;int&gt; ddp(dp);            int maxddp = 1;            for(j=0;j&lt;i;j++){                if(nums[i]&gt;nums[j]) ddp[j]++;                else ddp[j] = 1;                if(ddp[j]&gt;maxddp) maxddp = ddp[j];            }            dp[i] = maxddp;            if(dp[i]&gt;maxdp) maxdp = dp[i];        }        return maxdp;    }};\n也可以简化dp[i]的计算\n// 尝试用更直接的方式计算 dp[i]dp[i] = 1; // 先假设 nums[i] 自己构成一个长度为 1 的子序列for (j = 0; j &lt; i; j++) {    // 检查是否可以接在 nums[j] 后面    if (nums[i] &gt; nums[j]) {        // 如果可以，dp[i] 就有可能是 dp[j] + 1        // 我们要取所有可能性中的最大值        dp[i] = max(dp[i], dp[j] + 1);    }}\n\n    \n  \n\n例题2: 单词拆分给你一个字符串 s 和一个字符串列表 wordDict 作为字典。如果可以利用字典中出现的一个或多个单词拼接出 s 则返回 true。注意：不要求字典中出现的单词全部都使用，并且字典中的单词可以重复使用。\n示例 1：输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true解释: 返回 true 因为 “leetcode” 可以由 “leet” 和 “code” 拼接成。\n示例 2：输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以由 “apple” “pen” “apple” 拼接成。\n示例 3：输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false\n\n    思路 1 \n    \n      采取动态规划的思路, 要解决s能否被组合, 我们得考虑比s更小的子问题, 即s的子串是否能被组合.基于此, 一个思路便产生了: dp[i][j]代表s[i:j]是否能被组合, 此时要求的就是dp[0][n-1], 递推式是dp[i][j] = 存在k使得 dp[i][k]&amp;&amp;dp[k+1][j], i&lt;=k&lt;j 或者 s[i:j]在wordDict中, 后者同样很重要最后, 我们要填的表相当于一个n*n的二维数组的上半部分基本代码如下:\nclass Solution {public:    bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) {        size_t n = s.length();        int max=0, min=INT_MAX;        for(auto it = wordDict.begin(); it!=wordDict.end();it++){            if(it-&gt;length()&gt; max) max = it-&gt;length();            if(it-&gt;length()&lt; min) min = it-&gt;length();        }        // 1.定义dp        vector&lt;vector&lt;bool&gt;&gt; dp{n, vector&lt;bool&gt;(n, false)};        // 2. 决定关系式: 求dp[0][n-1], dp[i][j] = 存在k使得 dp[i][k]&amp;&amp;dp[k+1][j], i&lt;=k&lt;j        int i,j;        // 3. 初始化初值        for(i=0;i&lt;n;i++){            string ss(1,s[i]);            auto it = std::find(wordDict.begin(), wordDict.end(), ss);            if(it!=wordDict.end()) dp[i][i] = true;        }        // 4. 构建递推        for(i=n-2;i&gt;=0;i--){            for(j=i+1;j&lt;n;j++){                for(int k=i;k&lt;j;k++){                    if(dp[i][k]&amp;&amp;dp[k+1][j]) dp[i][j] = true;                }                if(!dp[i][j]&amp;&amp;(j-i+1)&gt;=min&amp;&amp;(j-i+1)&lt;=max){                    auto it = std::find(wordDict.begin(), wordDict.end(), s.substr(i,j-i+1));                    if(it!=wordDict.end()) dp[i][j] = true;                }            }        }        return dp[0][n-1];    }};\n    \n  \n\n\n    思路 2 \n    \n      上一个思路如果考虑完备的话是没有问题, 但是二维的dp表需要填充的内容很多, 我们真的需要这么多信息吗? 答案是不需要, 我们只需要知道s[i:j]是否能被组合, 而不关心s[i:j]的具体组合方式. 那我们是不是可以将dp表简化为一维, 即dp[i]代表s[0:i]是否能被组合?\n再细细回想, 为了知道dp[i][j], 我们考虑了所有分段dp的信息, 其中显然有冗余. 在上面的例子2中, applepenapple能够被有效拆分为applepen:apple和apple:penapple,这两种都是有效的组合, 但其实只知道前者就足够了, 因为后者可以由前者和wordDict中的pen拼接得到.\n因此, 我们可以定义一个一维的数组dp[i]表示字符串 s 中，长度为 i 的前缀（即子串 s[0…i-1]）是否可以被字典中的单词拼接而成, 而dp[i]拆分为的两部分不必都是dp数组(从而造成冗余),如果满足以下两个条件，那么 dp[i] 就可以是 true：\n\ndp[j] 是 true：这说明从字符串开头到 j 点的这一段前缀 s[0…j-1] 已经被成功拼接了。\n从 j 到 i 的这一段子串 s.substr(j, i-j) 本身就是字典里的一个单词。\n\n相当于我们的状态转移方程右边有一项外界参数, 通过引入它可以不必重复计算dp数组, 状态转移方程为: dp[i] = OR { dp[j] &amp;&amp; (s.substr(j, i-j) is in wordDict) } for all 0 &lt;= j &lt; i.\nclass Solution {public:    bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) {        int n = s.length();        // 1. 将字典转为哈希集合，提高查询效率        // std::find 在 vector 上是 O(N)，在 unordered_set 上是 O(1)        unordered_set&lt;string&gt; wordSet(wordDict.begin(), wordDict.end());        // 2. 定义 dp 数组，大小为 n+1        // dp[i] 表示 s 的前 i 个字符能否被拼接        vector&lt;bool&gt; dp(n + 1, false);        // 3. 初始化初值        // dp[0] 表示空字符串，是合法的起点        dp[0] = true;        // 4. 构建递推        // 外层循环遍历所有前缀长度 i，从 1 到 n        for (int i = 1; i &lt;= n; ++i) {            // 内层循环遍历所有可能的分割点 j            for (int j = 0; j &lt; i; ++j) {                // 如果 dp[j] 为 true，并且 s[j...i-1] 是一个字典词                if (dp[j] &amp;&amp; wordSet.count(s.substr(j, i - j))) {                    dp[i] = true;                    break; // 找到了一个可行方案，无需再检查其他分割点 j                }            }        }        return dp[n];    }};\n    \n  \n\n\n例题3: 0-1背包问题\n背包问题指的是对于有 n 件物品和一个容量为 V 的背包。每件物品 i 有一个重量 w[i] 和一个价值 v[i]。求解在不超过背包容量的前提下，能够装入背包的物品的最大总价值。\n\n而根据每件物品的数量和是否可以重复选择，背包问题可以分为以下几种类型：\n现阶段我们主要考虑的是0-1背包和完全背包, 完全背包又是由0-1背包演化而来, 因此0-1背包是重点\n\n状态定义: 0-1背包问题的状态定义为: dp[i][j] 代表前 i 件物品可选的情况下, 放入容量为 j 的背包可以获得的最大价值\n\n初始化: dp[i][0] = 0, dp[0][j] = j&gt;w[0]?value[0]:0\n\n状态转移方程:\n\n\n以上过程，抽象化如下：对于第 i 件物品和容量为 j 的背包，最大价值有两种选择可以到达：\n\n不放物品i：背包容量为j，里面不放物品i的最大价值是dp[i - 1][j]。\n放物品i：背包空出物品i的容量后，背包容量为j - weight[i]，dp[i - 1][j - weight[i]] 为背包容量为j - weight[i]且不放物品i的最大价值，那么dp[i - 1][j - weight[i]] + value[i] （物品i的价值），就是背包放物品i得到的最大价值\n\n\n遍历顺序: i从1到n-1, j从0到V\n\nfor (int i = 1; i &lt;= n; ++i) {    for (int j = 0; j &lt;= V; ++j) {        // 状态转移        if (j &gt;= weight[i]) {            dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i]);        } else {            dp[i][j] = dp[i-1][j];        }    }}\n\n举个例子, 假如背包最大重量为4。物品为：\n       重量\t价值物品0\t1\t 15物品1\t3\t 20物品2\t4\t 30\n\n求背包能背的物品最大价值是多少？\n更新完毕后的示意图如下:\n二维降一维在0-1背包问题中，二维数组 dp[i][j] 代表前 i 件物品可选的情况下, 放入容量为 j 的背包可以获得的最大价值。我们注意到，计算 dp[i][j] 时，只依赖于上一行 dp[i-1][…] 的值。因此，我们可以将二维数组降为一维数组。\n\n需要满足的条件是上一层可以重复利用，直接拷贝到当前层。\n\nvector&lt;int&gt; dp(V + 1, 0);for (int i = 1; i &lt;= n; ++i) {    for (int j = V; j &gt;= weight[i]; --j) {        dp[j] = max(dp[j], dp[j - weight[i]] + value[i]);    }}\n\ndp定义: 在一维dp数组中，dp[j]表示：容量为j的背包，所背的物品价值可以最大为dp[j]。\n\n其实dp[j]隐含了一个条件：在计算dp[j]时，物品i是可选的, 只不过我们没有显式地表示i.在循环的过程中, dp[j]的值会随着i的变化而变化, 直到最后一个i, 此时的dp[j]才是最终结果\n\n\n初始化: \n\n状态转移方程:\n\n遍历顺序: i从1到n-1, j从V到weight[i]\n\n\n这里的关键在于内层循环的遍历顺序。我们必须从后向前遍历 j（从 V 到 weight[i]），以确保在计算 dp[j] 时，dp[j - weight[i]] 仍然是上一行的值（即不包含当前物品 i 的情况）。\n假如还是正序遍历, 此时计算 dp[j], 我们需要用到 dp[j−weight[i]] 的值。而根据正序遍历的规则，当程序执行到 j 时，所有小于 j 的索引（包括 j - weight[i]）都已经在本轮（即针对物品 i 的循环中）被更新过了。此时我们用到的 dp[j−weight[i]] 已经不是 dp[i−1][j−weight[i]]（上一轮的状态），而是 dp[i][j−weight[i]]（本轮更新后的状态）。\n这意味着在计算 dp[i][j] 时，我们参考了已经放入过物品 i 的状态 dp[i][j−weight[i]]。这相当于物品 i 在一轮决策中被重复放入了多次(变成了完全背包), 这就违背了 0-1 背包问题中每件物品只能放入一次的原则。\n而在二维动态规划中，我们在计算第 i 行（dp[i]）的任何一个值时，所依赖的 全部是 第 i-1 行（dp[i-1]）的数据。无论内层循环（遍历背包容量 j）是正序还是倒序，dp[i][j] 始终从上一行 dp[i-1] 获取数据。本行的更新（例如先计算了 dp[i][j-1]）不会“污染”到计算 dp[i][j] 时所需要的数据源\n上述示例的一维示意图:\n","categories":["algorithms"],"tags":["algorithms","动态规划"]},{"title":"初识 Wireshark","url":"/2025/09/16/web/Wireshark/Wireshark/","content":"捕获过滤器“捕获过滤器”是在你开始捕获之前设置的一个规则。它的作用是告诉 Wireshark：“请你只记录符合这个规则的数据包，其他所有的包都直接丢弃，不要保存。”\n\n捕获过滤器 (Capture Filter)：捕获前设置，只保存匹配的包（数据量小）。\n显示过滤器 (Display Filter)：捕获后设置，捕获所有包，但根据选择只显示匹配的包（数据量大，但分析灵活）。\n\n捕获过滤器的语法示例如下图:\n\nEthernet address 00:00:5e:00:53:00: ether host 00:00:5e:00:53:00\n\n作用：只捕获数据链路层（以太网）的源 MAC 地址 或 目标 MAC 地址等于 00:00:5e:00:53:00 的数据包。\n\nEthernet type 0x0806 (ARP): ether proto 0x0806\n\n作用：只捕获以太网帧类型字段为 0x0806 的数据包。由于 0x0806 是 ARP 协议的类型编号，所以这条规则等同于“只捕获 ARP 包”。\n\nNo Broadcast and no Multicast: not broadcast and not multicast\n\n作用：不捕获任何广播包和多播（组播）包，只保留单播包。\n\nNo ARP: not arp\n\n作用：不捕获任何 ARP 协议的包。\n\nIPv4 only: ip\n\n作用：只捕获所有 IPv4 协议的数据包。\n\nIPv4 address 192.0.2.1: host 192.0.2.1\n\n作用：只捕获源 IP 地址 或 目标 IP 地址等于 192.0.2.1 的 IPv4 数据包。\n\nIPv6 only: ip6\n\n作用：只捕获所有 IPv6 协议的数据包。\n\nTCP only: tcp\n\n作用：只捕获 TCP 协议的数据包（会排除 UDP, ICMP 等）。\n\nUDP only: udp\n\n作用：只捕获 UDP 协议的数据包。\n\nNon-DNS: not port 53\n\n作用：不捕获源端口 或 目标端口是 53 的数据包。DNS（域名解析）服务通常使用 53 端口，所以这条规则是“排除所有 DNS 流量”。\n\nTCP or UDP port 80 (HTTP): port 80（最后一行被部分截断，但通常是这个）\n\n作用：只捕获源端口 或 目标端口是 80 的数据包。HTTP（网页）服务通常使用 80 端口。\n","categories":["web"],"tags":["web","computer network"]},{"title":"Coding技巧","url":"/2025/10/09/algorithms/Coding%E6%8A%80%E5%B7%A7/Coding%E6%8A%80%E5%B7%A7/","content":"递归这里帮助大家确定下来递归算法的三个要素。每次写递归，都按照这三要素来写，可以保证大家写出正确的递归算法！\n确定递归函数的参数和返回值： 确定哪些参数是递归的过程中需要处理的，那么就在递归函数里加上这个参数， 并且还要明确每次递归的返回值是什么进而确定递归函数的返回类型。\n确定终止条件： 写完了递归算法, 运行的时候，经常会遇到栈溢出的错误，就是没写终止条件或者终止条件写的不对，操作系统也是用一个栈的结构来保存每一层递归的信息，如果递归没有终止，操作系统的内存栈必然就会溢出。\n确定单层递归的逻辑： 确定每一层递归需要处理的信息。在这里也就会重复调用自己来实现递归的过程。\n递归的实现就是：每一次递归调用都会把函数的局部变量、参数值和返回地址等压入调用栈中，然后递归返回的时候，从栈顶弹出上一次递归的各项参数，所以这就是递归为什么可以返回上一层位置的原因。\n另一种算法, 回溯, 其实是递归的副产品，只要有递归就会有回溯。\n","categories":["algorithms"],"tags":["algorithms"]},{"title":"尾递归 (Tail Recursion) 与尾调用优化 (TCO)","url":"/2025/09/29/misc/%E5%B0%BE%E9%80%92%E5%BD%92%20(Tail%20Recursion)%20%E4%B8%8E%E5%B0%BE%E8%B0%83%E7%94%A8%E4%BC%98%E5%8C%96%20(TCO)/","content":"要理解尾递归和尾递归优化，首先必须理解程序是如何执行函数调用的。\n函数调用与调用栈 (Call Stack)当一个函数被调用时，计算机会在内存中一个称为 “调用栈” (Call Stack) 的特殊区域创建一个“栈帧” (Stack Frame)。它可以看作是函数的一次执行实例的“工作区”。它存储了函数的：\n\n参数 (Arguments)：传递给函数的数值。\n局部变量 (Local Variables)：函数内部定义的变量。\n返回地址 (Return Address)：函数执行完毕后，程序应该回到哪里继续执行。\n\n而函数调用的过程就像是往一摞盘子上放盘子：\n\nmain 函数开始执行，main 的栈帧被压入栈底。\nmain 调用函数 A，A 的栈帧被压入栈顶。\n函数 A 调用函数 B，B 的栈帧被再次压入栈顶。\n函数 B 执行完毕，它的栈帧被弹出，程序根据返回地址回到 A 中继续执行。\n函数 A 执行完毕，它的栈帧被弹出，程序回到 main。\n\n这个调用栈的大小是有限的。如果函数调用链条太长，栈会耗尽空间，导致 栈溢出 (Stack Overflow) 错误，程序崩溃。\n普通递归及其问题让我们以一个经典的阶乘函数为例来说明普通递归\ndef factorial(n):    if n == 1:        return 1    else:        # 注意：递归调用后，还有一个乘法操作        return n * factorial(n - 1)\n当我们计算 factorial(4) 时，调用栈的变化过程如下：\n\nfactorial(4) 被调用。它需要计算 factorial(3) 的结果才能完成 4 * … 的计算。factorial(4) 的栈帧入栈。\n调用栈(前面代表栈底或者说高地址, 后部代表栈顶或者低地址): [factorial(4)]\n\n\nfactorial(3) 被调用。它需要 factorial(2) 的结果。factorial(3) 的栈帧入栈。\n调用栈: [factorial(4), factorial(3)]\n\n\nfactorial(2) 被调用。它需要 factorial(1) 的结果。factorial(2) 的栈帧入栈。\n调用栈: [factorial(4), factorial(3), factorial(2)]\n\n\nfactorial(1) 被调用。它直接返回 1。factorial(1) 的栈帧入栈，然后立即出栈。\n调用栈: [factorial(4), factorial(3), factorial(2), factorial(1)] -&gt; [factorial(4), factorial(3), factorial(2)]\n\n\nfactorial(2) 拿到返回值 1，计算 2 * 1，返回 2。factorial(2) 的栈帧出栈。\n调用栈: [factorial(4), factorial(3)]\n\n\nfactorial(3) 拿到返回值 2，计算 3 * 2，返回 6。factorial(3) 的栈帧出栈。\n调用栈: [factorial(4)]\n\n\nfactorial(4) 拿到返回值 6，计算 4 * 6，返回 24。factorial(4) 的栈帧出栈。\n\n问题所在：在普通递归中，每一次递归调用都需要保留当前的栈帧，因为需要用它的信息（比如变量 n）来完成后续的计算。如果递归深度非常大（例如 factorial(10000)），就会创建成千上万个栈帧，最终导致栈溢出。这种空间复杂度是 O(n)。\n尾递归 (Tail Recursion)尾调用 (Tail Call) 指的是一个函数中最后一步, 操作是调用另一个函数。\n尾递归 (Tail Recursion) 是尾调用的一种特殊情况，即这个调用是调用函数自身。\n关键点在于，递归调用是整个函数的最后一个动作，其返回值被直接返回，不再参与任何其他计算。\n我们可以将上面的阶乘函数改写为尾递归形式，通常需要一个额外的“累加器”参数：\ndef factorial_tail(n, accumulator):    if n == 1:        return accumulator    else:        # 最后的动作就是调用自身，没有其他操作        return factorial_tail(n - 1, n * accumulator)# 初始调用# factorial(4) is equivalent to factorial_tail(4, 1)\n观察 return factorial_tail(n - 1, n * accumulator)，乘法 n * accumulator 在递归调用之前就计算好了。当 factorial_tail(n-1, …) 被调用时，当前的函数 factorial_tail(n, …) 已经完成了它所有的工作, 这个结果在原函数中直接返回而不需要再进入原函数参与计算。\n尾递归优化 (Tail-Call Optimization, TCO)尾递归优化 (Tail-Call Optimization, TCO) 是编译器或解释器的一种优化技术。它的目标是消除尾递归调用所带来的额外栈空间开销。\n对于支持 TCO 的语言（编译器或解释器），当它检测到一个尾调用时，它会意识到当前的栈帧已经不再需要了。因此，它不会创建一个新的栈帧，而是复用当前的栈帧。\n因此, 对于 factorial_tail(4, 1) 的调用过程：\n\n调用 factorial_tail(4, 1)。栈帧包含 n=4, accumulator=1。\n检测到尾调用 factorial_tail(3, 4 * 1)。编译器不会创建新栈帧，而是直接用新参数 n=3, accumulator=4 更新（覆盖）当前的栈帧，然后像 goto 一样跳转到函数开头重新执行。\n调用栈: [frame(n=4, acc=1)] -&gt; 复用 -&gt; [frame(n=3, acc=4)]\n再次检测到尾调用 factorial_tail(2, 3 * 4)。再次更新当前栈帧。\n调用栈: [frame(n=2, acc=12)]\n\n以此类推，直到 n=1，直接返回 accumulator 的最终值。\n优化的效果：整个递归过程只占用了一个栈帧的空间。它的空间复杂度从 O(n) 降到了 O(1)，等效于一个循环。这样，即使递归一亿次，也不会发生栈溢出。\n为什么大多数编程语言不做这个优化尽管尾递归优化有显著的优势，但许多主流编程语言（如 Python、Java、JavaScript）并不支持 TCO，主要有以下几个原因：\n\n调试困难 (Debugging Difficulty), 破坏了调用栈：TCO 的本质是销毁（复用）栈帧。如果程序在深层递归中出错，你看不到完整的函数调用链条，因为中间的栈帧信息都丢失了。这对于调试来说是一个巨大的障碍，你无法追溯函数是如何一步步调用到当前状态的。\n\n实现复杂性和语言规范\n\n对语言设计者是负担：强制要求 TCO 会让语言的规范和编译器的实现变得更加复杂。设计者需要精确定义什么是“尾位置”，并确保所有实现都遵循。\n与某些语言特性冲突：在像 C++ 或 Java 这样的语言中，栈上的对象可能有关联的析构函数（或 finally 块）。如果 TCO 优化掉了栈帧，这些清理代码可能不会被正确执行，导致资源泄露。\n\n\n文化和哲学原因\n\nPython 的理念：Python 的创造者 Guido van Rossum 多次表示反对 TCO。他认为 Python 程序员更倾向于使用明确的循环 (for, while)，这比递归更直观、易读。强制 TCO 会鼓励一种不符合 Python 风格的编程范式，并且他认为调试信息的价值高于 TCO 带来的性能优势。\nJava 的情况：Java 虚拟机（JVM）的设计使得 TCO 难以实现，因为它需要修改字节码的验证和安全模型。虽然有一些实验性的支持，但它不是标准特性。\n\n\n不认为是必要功能: 在很多面向对象和命令式编程场景下，深度递归并不是一个常见的模式。大多数问题都可以用迭代（循环）清晰地解决。因此，实现 TCO 的投入产出比被认为不高。\n\n\n不过, 仍然有部分语言是支持TCO的, 例如: \n\n某些函数式编程语言：这类语言通常将递归作为核心的循环和控制流结构，因此 TCO 是 必须 的。例如 Scheme（语言规范强制要求 TCO）、Lisp、F#、Scala 等。\n\nC/C++：某些编译器（如 GCC, Clang）在开启较高优化等级（如 -O2 或 -O3）时，可能会进行 TCO，但这不是语言标准所保证的。\n\nJavaScript：ES6 规范中引入了对尾调用优化的支持，但实际实现依赖于具体的 JavaScript 引擎（如 V8, SpiderMonkey）。然而，许多主流引擎并未完全实现这一特性。\n\n\n"},{"title":"libc","url":"/2024/06/30/system/Old_OS/Libc/","content":"","categories":["system"],"tags":["system"]},{"title":"智能体范式","url":"/2025/09/29/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/Agent%E5%85%A5%E9%97%A8/%E6%99%BA%E8%83%BD%E4%BD%93%E8%8C%83%E5%BC%8F/","content":"ReActReAct (Reason + Act) 核心思想是模仿人类解决问题的方式，将推理 (Reasoning) 与行动 (Acting) 显式地结合起来，形成一个“思考-行动-观察”的循环。\n在ReAct诞生之前，主流的方法可以分为两类：一类是“纯思考”型，如思维链 (Chain-of-Thought)，它能引导模型进行复杂的逻辑推理，但无法与外部世界交互，容易产生事实幻觉；另一类是“纯行动”型，模型直接输出要执行的动作，但缺乏规划和纠错能力。\nReAct的巧妙之处在于，它认识到思考与行动是相辅相成的。思考指导行动，而行动的结果又反过来修正思考。为此，ReAct范式通过一种特殊的提示工程来引导模型，使其每一步的输出都遵循一个固定的轨迹：\n\nThought (思考): 这是智能体的“内心独白”。它会分析当前情况、分解任务、制定下一步计划，或者反思上一步的结果。\nAction (行动): 这是智能体决定采取的具体动作，通常是调用一个外部工具，例如 Search[‘华为最新款手机’]。\nObservation (观察): 这是执行Action后从外部工具返回的结果，例如搜索结果的摘要或API的返回值。\n\n智能体将不断重复这个 Thought -&gt; Action -&gt; Observation 的循环，将新的观察结果追加到历史记录中，形成一个不断增长的上下文，直到它在Thought中认为已经找到了最终答案，然后输出结果。这个过程形成了一个强大的协同效应：推理使得行动更具目的性，而行动则为推理提供了事实依据。\n"},{"title":"操作系统对象","url":"/2024/08/20/system/Old_OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%B9%E8%B1%A1/","content":"文件描述符在 Linux/Unix 操作系统中，文件描述符是进行所有输入/输出（I/O）操作的基础。它是一个非负整数，作为程序与内核之间进行文件操作的“凭证”。理解文件描述符的关键在于掌握其背后的三层内核数据结构：进程文件描述符表、系统级打开文件表和 i-node 表。\n回到定义, 文件描述符 (File Descriptor, fd) 本质上是一个索引，指向一个进程内核区域中的特定数据结构。它的形式是一个非负整数（0, 1, 2, 3, …）。当进程成功打开一个文件或创建一个管道/套接字时，内核会返回一个文件描述符。此后，程序所有对该文件的读、写、关闭等操作，都通过这个整数来标识，而无需再使用文件名。\n\n回忆“一切皆文件”：在 Unix 哲学中，设备（如键盘、显示器）、网络连接（套接字）等都被抽象为文件，因此也都可以通过文件描述符来访问。\n\n需要注意的是, 当一个进程启动时，默认会拥有三个标准的文件描述符：\n\n0\t: 标准输入 (stdin) - 键盘\n1\t: 标准输出 (stdout) - 屏幕\n2\t: 标准错误 (stderr) - 屏幕\n\n因此，程序中第一次成功 open() 一个新文件，通常返回的文件描述符是 3。\n三层核心结构要彻底理解文件描述符的行为，必须了解其背后的三层内核结构。这三层结构清晰地分离了“哪个进程”、“哪次打开”和“哪个文件”的概念。\n\n第一层：进程文件描述符表 (Per-Process File Descriptor Table)\n\n\n归属：每个进程独立拥有一张。\n\n功能：它是一个简单的数组，索引就是文件描述符的整数值。数组的每个元素是一个指针，指向第二层中的一个“文件表项”。这张表将一个简单的整数（文件描述符）与一个具体的“文件打开实例”（文件表项）关联起来。它只告诉进程：“你的文件描述符 3 对应的是那个文件打开实例”。\n\n\n\n第二层：系统级打开文件表 (System-wide Open File Table)\n\n\n归属：整个操作系统内核共享一张。\n\n功能：表中的每一个条目被称为 文件表项 (File Table Entry)，它代表了一次独立的文件打开操作。这是整个机制的核心，包含了：\n\n文件状态标志：文件是如何被打开的（如 O_RDONLY 只读, O_APPEND 追加模式等）。\n当前文件偏移量 (offset)：这是最重要的属性。它记录了下一次读/写操作在文件中的位置，即读写指针。\n引用计数：记录了有多少个来自第一层的指针指向此表项。\n指向 i-node 的指针：指向第三层，关联到文件的具体物理信息。\n\n\n这张表抽象了“打开的文件”这个概念。offset 存放在这里，意味着 offset 是跟“某次文件打开”这个行为绑定的，而不是跟进程或者文件本身绑定。\n\n\n\n第三层：i-node 表 (i-node Table)\n\n\n归属：系统内核级，代表物理存储上的文件。\n\n功能：每个文件或目录在文件系统中都有一个唯一的 i-node。它存储了文件的元数据 (metadata)，如文件大小、所有者、权限、创建时间以及数据在磁盘上的实际位置。i-node 是文件的静态描述。无论一个文件被打开多少次，它在磁盘上都只有一个 i-node。\n\n\n\nfork() 和 dup() 对于offset的影响fork() 的情况: \n\n父进程打开一个文件，我们假设它得到 fd = 3。此时，三层结构是：\n\n\n父进程的 fd 表：fd[3] -&gt; 指向一个文件表项 A\n\n系统文件表：文件表项 A (offset = 0, 引用计数 = 1) -&gt; 指向 i-node X\n\ni-node 表：i-node X (代表实际文件)\n\n\n\n父进程调用 fork() 创建子进程。\n\n\n子进程复制了父进程的文件描述符表。这意味着：\n\n子进程的 fd 表：fd[3] -&gt; 也指向同一个文件表项 A\n\n\n此时，文件表项 A 的状态变为：文件表项 A (offset = 0, 引用计数 = 2) -&gt; 指向 i-node X\n\n\n结论：因为父子进程的 fd=3 都指向了同一个文件表项 A，所以它们共享该表项中的所有信息，其中最重要的就是共享同一个 offset。任何一方读取文件导致 offset 变化，另一方都会受到影响。\ndup() 的情况: \n\n进程打开一个文件，得到 fd = 3。\n\n\n进程 fd 表：fd[3] -&gt; 指向文件表项 A\n\n系统文件表：文件表项 A (offset = 0, 引用计数 = 1)\n\n\n\n进程调用 dup(3)，假设返回了新的文件描述符 fd = 4。\n\ndup() 的作用是在进程的 fd 表中创建一个新条目，让它指向与原 fd 相同的那个文件表项。\n进程 fd 表：fd[3] -&gt; 指向文件表项 A； fd[4] -&gt; 也指向文件表项 A\n结论：同样地，因为 fd=3 和 fd=4 指向了同一个文件表项 A，所以它们也共享同一个 offset。\nmount (挂载)mount 是一个将独立的“文件系统”集成到主文件系统树中的过程。简单来说，就是将一个存储设备（如硬盘分区、U盘）的内容，附加到主文件系统的一个目录下，让我们可以像访问普通目录一样访问该设备里的文件。\n例如, 执行 mount /dev/sdb1 /mnt/data 之后, 便可以通过访问/mnt/data来直接访问挂载的存储文件系统的物理或虚拟设备，如 /dev/sda1 (第一个硬盘的第一个分区)。\numount (卸载): 与 mount 相对，umount 命令（注意没有 ‘n’）则是将这个挂载文件系统从主文件系统树中移除。在拔掉 U 盘等设备前，执行卸载是非常重要的安全操作。\npipe (管道)管道是 Unix 系统中历史最悠久也最强大的进程间通信 (Inter-Process Communication, IPC) 机制之一。它的作用是在两个进程之间建立一个单向的数据流。\n可以将管道想象成一条单向的传送带：\n\n一个进程（Write方）在传送带的一端放上物品（数据）。\n\n另一个进程（Read方）在传送带的另一端取走物品。\n\n传送带本身有容量限制，如果放满了，Write方就必须等待。\n\n如果传送带空了，Read方就必须等待。\n\n物品遵循“先进先出”(First-In, First-Out, FIFO) 的原则。\n\n\n管道的内部工作机制首先, 管道不是普通的磁盘文件，它存在于内核内存中的缓冲区 (Buffer), 而且需要通过文件描述符访问. \n当一个进程调用 pipe() 系统调用时：\nint fd[2];pipe(fd);\n\n内核会执行以下操作：\n\n在内核中创建一个管道对象，这个对象包含一个内存缓冲区和相关的管理信息。\n\n在系统级打开文件表(第二级)中创建一个文件表项，这个表项指向新创建的管道对象。\n\n在调用进程的文件描述符表(第一级)中，分配两个连续的文件描述符，并让它们都指向同一个文件表项。\n\nfd[0] 被设置为只读端。\n\nfd[1] 被设置为只写端。\n\n\n\n\n管道的经典使用模式管道本身在一个进程中没有意义（自己写自己读），它的威力体现在与 fork() 结合，用于父子进程间的通信。经典四步法如下：\n\n父进程创建管道：父进程调用 pipe(fd)，获得一个读描述符 fd[0] 和一个写描述符 fd[1]。\n\n父进程创建子进程：父进程调用 fork()。现在，子进程继承了父进程的文件描述符表，因此子进程也拥有了这对指向同一个管道的 fd[0] 和 fd[1]。\n\n关闭不用的描述符：这是至关重要的一步，为了建立单向数据流。假设我们想让父进程写，子进程读：\n\n\n\n父进程：它只负责写，所以应该在父进程中使用下列指令关闭它的读端：close(fd[0]);\n\n子进程：它只负责读，所以应该在子进程中使用下列指令关闭它的写端：close(fd[1]);\n\n\n关闭不需要的一端不仅使得功能清晰, 而且也明确了结束信号 (EOF)：读操作在管道为空时会阻塞。只有当所有指向管道写端的描述符都关闭后，读端再次读取时才会收到 EOF (End-Of-File，返回值 0)，从而知道数据已经全部发送完毕。如果子进程不关闭写端 fd[1]，那么它在读完所有数据后会永远阻塞，因为它自己还持有一个“可能写入”的端口。\n\n通信：\n\n\n父进程通过 write(fd[1], …) 写入数据。\n\n子进程通过 read(fd[0], …) 读取数据。\n\n\n这个模型正是 Shell 中 | 操作符的实现原理。例如 ls -l | grep .txt，ls 进程的标准输出被重定向到管道的写端，grep 进程的标准输入被重定向到管道的读端。\n管道的类型匿名管道 (Anonymous Pipe)：由 pipe() 系统调用创建。\n\n特点：没有文件名，只能用于有亲缘关系（通常是父子）的进程间通信。它们随着进程的结束而消失。\n\n应用：Shell 中的 |。\n\n\n命名管道 (Named Pipe / FIFO)：由 mkfifo() 函数创建。\n\n特点：在文件系统中拥有一个可见的、特殊的文件名。这使得任何两个不相关的进程都可以通过打开这个特殊文件来进行通信。\n\n应用：用于一些需要在不同服务程序之间稳定交换数据的场景。\n\n\n终端和Shell终端和伪终端在计算机早期（上世纪 60-70 年代），计算机主机非常昂贵且巨大，通常锁在专门的机房里。人们不是一人一台电脑，而是通过一种硬件设备来连接和使用主机。这种设备就是终端 (Terminal)。\n它的本质就是一个纯粹的输入/输出设备, 通常就是一个键盘和一个屏幕（早期甚至是类似打字机的纸张打印输出设备）。它本身几乎没有计算能力。它的唯一工作就是把你从键盘敲入的字符，通过一根串行电缆发送给计算机主机; 同时接收从主机返回的字符，然后把它们显示在屏幕上。\n你可以把它想象成一个纯粹的“传话筒”和“显示板”。它不理解你输入的 ls 是什么意思，它只负责把这两个字母传过去，再把主机返回的文件名列表显示出来。这种硬件设备也被称为 TTY (Teletypewriter, 电传打字机) 的衍生品。\n随着技术发展，个人计算机普及了，我们不再需要一个独立的物理终端硬件。我们现在用的是功能强大的个人电脑，有图形用户界面 (GUI)。因此当需要与计算机系统交互时, 我们通常会使用一个终端模拟器 (Terminal Emulator)或者说伪终端(Pseudo-Terminal, PTY), 也就是双击打开的黑色命令行窗口。它的工作就是用软件来模拟过去那种硬件的行为。\n所以，“伪”就伪在：\n\n它不是硬件，而是软件。\n\n它在软件层面模拟了一个物理终端的行为和接口。\n\n\n从 Shell的角度看，它感觉自己连接的从设备 (/dev/pts/N) 和过去连接一个物理终端设备 (/dev/ttyS0) 没什么两样。正是这种成功的“伪装”，让所有为传统终端设计的命令行程序（几乎是所有）都能在新时代的图形化窗口中无缝运行。\nShell而Shell, 字面意思是“外壳”。这个名字非常形象，因为它就是包裹在内核这个核心之外的一层，为用户提供了一个与内核交互的界面。\n更详细一点, Shell 是一个运行在用户空间的、作为命令解释器的应用程序。它是用户通过命令行与操作系统内核进行交互的主要接口。它接收你的文本命令，将其翻译成内核可以理解的请求（系统调用），然后将内核返回的结果显示给你。它既是强大的交互工具，也是一个功能完备的脚本编程环境。\n\n类比python(.py), 是一门解释性语言, 通过python.exe这个解释器来解释执行;同样, shell(.sh)也是一门解释性语言, 通过shell解释器(例如bash, fish等)来解释执行, 将文本命令翻译为系统调用\n\n作为编程语言的定位与特点虽然 Shell 是一种编程语言，但它的设计哲学和应用领域与 C++、Java 或 Python 等通用编程语言（General-Purpose Language）有很大不同。\n\n领域特定语言（Domain-Specific Language）: Shell 的主要设计目标是自动化系统管理任务和与操作系统交互。它的“领域”就是操作系统的命令行环境。\n\n胶水语言（Glue Language）: Shell 最强大的能力是作为“胶水”，将操作系统中成百上千个小而专的命令行工具（如 ls, grep, awk, sed, curl）粘合起来，通过**管道（|）和重定向（&gt;）**组合成强大的工作流。它的编程模型不是从零开始构建所有逻辑，而是编排和调度其他程序。\n\n解释型语言（Interpreted Language）: Shell 脚本由解释器（如 bash, zsh）逐行读取并执行，无需预先编译。这使得开发和测试周期非常快，非常适合快速编写自动化脚本。\n\n\n不过, 其显著缺点则是数据结构有限和不擅长计算. 原生POSIX标准仅支持字符串和一维数组，处理复杂的数据结构（如哈希表、树、对象）非常笨拙。且对于数学运算，尤其是浮点数运算，支持非常薄弱，通常需要借助 bc 或 awk 等外部工具。\n区别cmd, pwsh与bash正如前面所说, Shell 是一个核心概念，它指代命令行解释器（Command Line Interpreter），即为用户提供与操作系统交互接口的程序。基于这一理念，业界诞生了多种具体的 Shell 实现。CMD (Command Prompt)是 Windows 的早期命令解释器, 只是一个简单的、基于文本行的命令接口, 现在已经被更现代化的命令行框架PowerShell替代。bash 则是 GNU 项目的一部分，当下被广泛应用于Unix系统。\nBash (Bourne Again Shell)\n\n定位：类 Unix 系统（Linux, macOS）的事实标准 Shell, 是 Unix-like 世界的通用语言。\n\n哲学：一切皆文件，一切皆文本流。Bash 的核心优势在于处理纯文本。它通过管道（|）将一个个小而专的命令行工具（grep, awk, sed 等）组合起来，形成强大的文本处理工作流。它是典型的“胶水语言”，用于粘合不同的程序。\n\n\nPowerShell\n\n定位：Windows 的现代化、面向对象的自动化框架。(目前已实现Windows, Linux 和 macOS 的跨平台)\n\n哲学：一切皆对象（Object）。这是 PowerShell 与前两者最根本的区别。PowerShell 不在命令之间传递无格式的文本流，而是传递结构化的 .NET 对象。这使得它在进行复杂的系统管理和数据操作时，无需进行繁琐的文本解析，可以直接访问对象的属性和方法，更为精准和强大。\n\n其简单的语法习惯等兼容Unix/Linux Shell\n\n\n可执行文件可执行文件（Executable File）是计算机中的一种特殊文件，它包含了一系列可以直接被操作系统加载并由CPU执行的机器指令。简单来说，它是程序的最终形态，可以独立运行，不需要其他辅助工具（如编译器或解释器）的帮助。\n\n可执行文件是一个描述状态机初始状态的数据结构 (字节序列)\n\n例如，在 Windows 系统上，你双击打开一个 .exe 文件，在 Linux 系统上，你在终端输入 ls 或 ./a.out，你所操作的这些文件都是可执行文件。\n生成过程一个可执行文件是从人类可读的源代码到机器可读的二进制指令的复杂转换过程的终点。这个过程通常包括以下几个关键步骤：\n\n编写源代码：程序员用 C、C++、Java 等高级语言编写程序代码。\n\n编译（Compilation）：编译器将源代码文件（如 .c 文件）翻译成目标文件（Object File），通常是二进制格式。这个阶段会进行语法检查，并将高级代码转换为汇编代码，再转换为机器指令，但此时的指令地址还不是最终地址，且无法独立运行。\n\n链接（Linking）：链接器将一个或多个目标文件，以及程序所需的库文件（如标准库），组合成一个完整的可执行文件。\n\n\n","categories":["system"],"tags":["system"]},{"title":"函数","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%87%BD%E6%95%B0/","content":"函数的参数(Parameters)在 Python 中，函数的参数可以分为以下几种类型：必选参数、默认参数、可变参数 (*args)、命名关键字参数和关键字参数 (**kwargs)。并且在定义函数时, 必须按照这样的顺序来排列参数.\ndef complex_function(pos1, pos2, default_arg='default', *args, kw_only1, kw_only2='default', **kwargs):    # 函数体    pass\n\n必选参数 (Positional or Required Arguments)这是最基本的参数类型。在调用函数时，必须为这些参数传递值，并且传递的顺序要与函数定义中的顺序一致(或者也可以指定名称传递, 这样就不需要按顺序来)。因为它们没有默认值，所以是“必选的”。\ndef describe_person(name, age):    \"\"\"显示一个人的姓名和年龄。\"\"\"    print(f\"Name: {name}, Age: {age}\")  # f-string 格式化字符串# 正确调用describe_person(\"Alice\", 30)describe_person(age=30, name=\"Alice\")  # 使用关键字参数, 不需要按顺序# 错误调用 - 缺少参数# describe_person(\"Alice\")  # TypeError: describe_person() missing 1 required positional argument: 'age'\n\n默认参数 (Default Arguments)在定义函数时，可以为一个或多个参数提供默认值。如果在调用函数时没有为这些参数提供值，Python 将使用预设的默认值(可选提供，若不提供则使用默认值)\n定义时在参数名后使用 = 赋值, 并且要注意: 默认参数必须定义在所有必选参数之后。\ndef send_greeting(name, message=\"Hello\"):    \"\"\"发送问候语。\"\"\"    print(f\"{message}, {name}!\")# 使用默认参数send_greeting(\"Bob\")  # 输出: Hello, Bob!# 覆盖默认参数send_greeting(\"Charlie\", \"Good morning\")  # 输出: Good morning, Charlie!\n\n默认参数必须指向不变对象一个常见的错误是使用可变对象（如列表或字典）作为默认参数。这会导致意想不到的行为，因为默认参数在函数定义时只被计算一次，而不是每次调用函数时都重新计算。\n默认参数的值在函数定义时就被计算和存储了。如果默认参数是一个可变对象（如列表或字典），并且在函数调用中被修改，那么这个修改会影响到后续的函数调用。\ndef append_to_list(value, my_list=[]):    \"\"\"将值添加到列表中。\"\"\"    my_list.append(value)    return my_listprint(append_to_list(1))  # 输出: [1]print(append_to_list(2))  # 输出: [1, 2] -- 这里的 my_list 不是一个新的列表，而是上次调用时的列表\n正确的做法是使用 None 作为默认值，然后在函数体内创建一个新的列表：\ndef append_to_list(value, my_list=None):    \"\"\"将值添加到列表中。\"\"\"    if my_list is None:        my_list = []    my_list.append(value)    return my_listprint(append_to_list(1))  # 输出: [1]print(append_to_list(2))  # 输出: [2] -- 每次调用 都是一个新的列表\n\n为什么要设计str、None这样的不变对象呢？因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。\n可变参数 (*args)当你希望函数能够处理任意数量的位置参数时，可以使用可变参数。Python 会将所有传入的多余位置参数收集到一个元组 (tuple) 中。\n实现方法是, 在参数名前加一个星号 *。按照惯例，我们通常将其命名为 args, 用于接收任意多个位置参数。\ndef calculate_sum(*numbers):    \"\"\"计算所有输入数字的和。\"\"\"    total = 0    print(f\"Received numbers: {numbers}\") # numbers 是一个元组    for number in numbers:        total += number    return totalprint(calculate_sum(1, 2, 3))         # 输出: Received numbers: (1, 2, 3) -&gt; 6print(calculate_sum(10, 20, 30, 40))  # 输出: Received numbers: (10, 20, 30, 40) -&gt; 100\n如果已经有一个列表或元组, 想把它当作可变参数传入函数, 可以使用 * 号来解包:\nnums = [1, 2, 3, 4]print(calculate_sum(*nums))  # 输出: Received numbers: (1, 2, 3, 4) -&gt; 10\n\n关键字参数 (**kwargs)当你希望函数能处理任意数量的关键字参数时，可以使用这种类型。Python 会将这些参数收集到一个字典 (dict) 中。\n\n可变参数处理的是位置参数，而关键字参数处理的是命名参数, 也就是说, 可变参数只能接收没有名称的参数, 而关键字参数接收的是有名称的参数.\n\n实现方式是在**参数名前加两个星号 ****。按照惯例，我们通常将其命名为 kwargs。\ndef create_user_profile(**user_info):    \"\"\"创建一个用户信息的字典。\"\"\"    print(f\"Received info: {user_info}\") # user_info 是一个字典    for key, value in user_info.items():        print(f\"{key.title()}: {value}\")create_user_profile(name=\"Eve\", age=28, city=\"New York\")  # 需要输入 key=value 形式的参数# 输出:# Received info: {'name': 'Eve', 'age': 28, 'city': 'New York'}# Name: Eve# Age: 28# City: New York\n\n同样, 如果已经有一个字典, 想把它当作关键字参数传入函数, 可以使用 ** 号来解包:\nuser_data = {'name': 'Frank', 'age': 35, 'city': 'Los Angeles'}create_user_profile(**user_data)# 输出:# Received info: {'name': 'Frank', 'age': 35, 'city': 'Los Angeles'}# Name: Frank   # Age: 35# City: Los Angeles\n注意user_info获得的dict是user_data的一份拷贝，对user_info的改动不会影响到函数外的user_data。\n命名关键字参数 (Named-Keyword Arguments)对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。有时候，我们希望函数能够接受一些特定的关键字参数，而不是任意的关键字参数。这时，可以使用命名关键字参数。\n这种参数用于强制调用者必须使用制定关键字的形式来传递参数值，而不是通过位置。这可以提高代码的可读性，明确参数的意图。\n也就是说, 必须以 key=value 的形式提供，不能通过位置传递。\n\n如果前面有 *args，则直接在 *args 后面定义。\n如果没有 *args，则需要一个单独的星号 * 作为分隔符。\n\ndef process_data(initial_value, *data, status, is_valid):    \"\"\"处理数据，status 和 is_valid 必须用关键字指定。\"\"\"    print(f\"Initial Value: {initial_value}\")    print(f\"Data tuple: {data}\")    print(f\"Status: {status}\")    print(f\"Is Valid: {is_valid}\")# 正确调用process_data(100, 1, 2, 3, status=\"active\", is_valid=True)# 错误调用 - 未使用关键字# process_data(100, 1, 2, 3, \"active\", True) # TypeError: process_data() takes 1 positional argument but 4 were given\ndef set_config(*, theme, font_size, show_toolbar):    \"\"\"配置设置，所有参数必须用关键字指定。\"\"\"    print(f\"Theme: {theme}\")    print(f\"Font Size: {font_size}\")    print(f\"Show Toolbar: {show_toolbar}\")# 正确调用set_config(theme=\"dark\", font_size=14, show_toolbar=False)# 错误调用 - 尝试使用位置参数# set_config(\"dark\", 14, False) # TypeError: set_config() takes 0 positional arguments but 3 were given\n\n类型注解 (Type Annotations)Python 允许在函数定义中使用类型注解来指定参数和返回值的预期类型。这有助于提高代码的可读性，并且可以被静态类型检查工具（如 mypy）使用来检测类型错误。\n使用类型注解的语法是在参数名后使用冒号 :，然后跟上类型名称(如果参数有默认值, 则默认值放在类型名称后面, 用=连接):\n对于返回值，可以在参数列表后使用箭头 -&gt; 来指定返回类型。\ndef greet(name: str, age: int = 20) -&gt; str:    \"\"\"返回一个问候语字符串。\"\"\"    return f\"Hello, {name}. You are {age} years old.\"print(greet(\"Alice\", 30))  # 输出: Hello, Alice. You are 30 years old.\n类型注解并不会影响函数的运行时行为，它们只是提供了额外的信息，帮助开发者理解代码的意图。\n同时, 类型注解也可以用于变量声明:\nage: int = 25self.records: List[Dict[str, Any]] = [] # 表示 records 是一个包含字典的列表\n\n高阶函数 (Higher-order Function)要理解高阶函数，首先必须接受 Python 中的一个核心设计哲学：函数是“一等公民” (First-class Citizen)。\n\n所谓“一等公民”，是指在 Python 中，函数可以像其他数据类型（如整数、字符串、列表等）一样被赋值给变量、作为参数传递给其他函数、作为函数的返回值返回。\n\n一个函数如果满足以下两个条件中的至少一个，它就是高阶函数：\n\n接受一个或多个函数作为参数。\n将函数作为返回值。\n\n简单来说：一个操作其他函数的函数，就是高阶函数。\n接受函数作为参数这是高阶函数最常见的形式。它允许我们将行为“注入”到一个函数中，使这个函数变得更加灵活和通用。\n# 这是一个普通的函数def say_hello(name):    return f\"Hello, {name}\"def say_goodbye(name):    return f\"Goodbye, {name}\"# 这就是一个高阶函数，因为它接受一个函数(fn)作为参数def be_polite(fn):    # 在内部，它调用了传入的函数 fn    greeting = fn(\"John\")    # 并在其基础上增加了一些行为    return greeting + \", have a nice day!\"# --- 使用高阶函数 ---# 1. 把 say_hello 函数作为“值”传入 be_politepolite_hello = be_polite(say_hello)print(polite_hello)  # 输出: Hello, John, have a nice day!# 2. 把 say_goodbye 函数作为“值”传入 be_politepolite_goodbye = be_polite(say_goodbye)print(polite_goodbye) # 输出: Goodbye, John, have a nice day!\n\n同时, Python 提供了很多非常有用的内置高阶函数，最典型的就是 map(), filter() 和 sorted()。\n\nmap(function, iterable): 对 iterable 中的每个元素执行 function 操作, 并把结果作为新的 Iterator 返回。\n\ndef f(x):     return x * xr = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])list(r)   # 输出: [1, 4, 9, 16, 25, 36, 49, 64, 81]\n这里 map() 返回的不是一个“现成的列表”，而是一个惰性计算的迭代器 (Iterator), 也就是说结果不会一次性全部算出来，而是按需计算. 当你对 r 进行迭代（比如 for x in r: 或 list(r)）时，它才会逐个调用 f(x)，生成结果。\n\nfilter(function, iterable): 使用 function 过滤 iterable 中的元素，只保留使 function 返回 True 的元素。\n\ndef is_odd(n):    return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15]\n\nsorted(iterable, key=function): sorted 的 key 参数就是一个函数，它定义了排序的规则。\n\nsorted([36, 5, -12, 9, -21], key=abs)# 输出: [5, 9, -12, -21, 36]\n\n将函数作为返回值高阶函数也可以动态地“创建”并返回一个新的函数。这通常与闭包 (Closure) 的概念紧密相关。\n假设我们想创建一些功能专一的函数，比如“乘以2的函数”、“乘以3的函数”等\n# 这就是一个高阶函数，因为它返回一个函数def create_multiplier(n):    # 这个内部函数 \"multiplier\" 就是将要被返回的    def multiplier(x):        return x * n  # 注意：这里引用了外部函数的变量 n        return multiplier # 返回的是函数本身，不是调用的结果# --- 使用高阶函数 ---# 调用 create_multiplier(2) 并不执行乘法，而是创建了一个新的函数# 这个新函数“记住”了 n=2double = create_multiplier(2) # 调用 create_multiplier(3) 创建了另一个新函数# 这个新函数“记住”了 n=3triple = create_multiplier(3)# 现在我们可以使用这些新创建的函数了print(f\"double(10) is {double(10)}\") # 输出: double(10) is 20print(f\"triple(10) is {triple(10)}\") # 输出: triple(10) is 30print(f\"double(5) is {double(5)}\")   # 输出: double(5) is 10\n在这个例子中，create_multiplier 是一个“函数工厂”。你给它一个参数 n，它就为你生产出一个“乘以n”的定制函数。返回的函数 multiplier 捕获并持有了外部环境中的变量 n，这就是一个闭包。\n装饰器 (Decorators)理解了高阶函数后，你就能理解 Python 中最强大的特性之一, 装饰器。\n装饰器本质上就是一个高阶函数，它接受一个函数作为参数，并返回一个被“装饰”过的、功能更强的新函数。\nimport time# a_decorator 本质上就是一个高阶函数def a_decorator(func):    def wrapper(*args, **kwargs):        print(f\"Calling function '{func.__name__}'...\")        start_time = time.time()                result = func(*args, **kwargs) # 调用原始函数                end_time = time.time()        print(f\"Function '{func.__name__}' took {end_time - start_time:.4f} seconds.\")        return result    return wrapper# @a_decorator 是 Python 的语法糖# 它等价于: slow_function = a_decorator(slow_function)@a_decoratordef slow_function():    time.sleep(1)    print(\"Function finished.\")slow_function()","categories":["python"],"tags":["language","python"]},{"title":"列表与元组","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%88%97%E8%A1%A8/","content":"列表 (List)列表是一个有序的、可变的集合，可以包含任意类型的对象，例如数字、字符串、甚至其他列表。 列表使用方括号 [] 来定义，元素之间用逗号分隔。\n\n有序性 (Ordered)：列表中的元素按照它们被添加的顺序进行存储。每个元素都有一个唯一的索引（位置编号），从 0 开始。\n可变性 (Mutable)：你可以在列表创建后，随时添加、删除或修改其中的元素。\n异构性 (Heterogeneous)：列表中可以包含不同数据类型的元素，比如整数、字符串和另一个列表同时存在。\n动态性 (Dynamic)：列表的长度是动态变化的，可以根据需要增长或缩减。\n\n创建列表直接使用方括号 []:\n# 创建一个空列表empty_list = []# 创建一个包含整数的列表numbers = [1, 2, 3, 4, 5]# 创建一个包含字符串的列表fruits = [\"apple\", \"banana\", \"cherry\"]# 创建一个混合类型的列表mixed_list = [1, \"hello\", 3.14, True, [\"a\", \"b\"]]print(numbers)      # 输出: [1, 2, 3, 4, 5]print(mixed_list)   # 输出: [1, 'hello', 3.14, True, ['a', 'b']]\n也可以使用 list() 函数从其他可迭代对象（如字符串、元组或范围）创建列表：\n# 从字符串创建列表char_list = list(\"Python\")print(char_list)    # 输出: ['P', 'y', 't', 'h', 'o', 'n']# 从元组创建列表tuple_example = (10, 20, 30)tuple_to_list = list(tuple_example)print(tuple_to_list) # 输出: [10, 20, 30]\n\n访问列表元素（索引）可以通过索引来访问列表中的单个元素, 正向索引从 0 开始, 反向索引从 -1 开始。\nfruits = [\"apple\", \"banana\", \"cherry\", \"date\"]# 正向索引 (从 0 开始)print(fruits[0])  # 输出: 'apple'print(fruits[2])  # 输出: 'cherry'print(fruits[4])  # 报错: IndexError: list index out of range (索引超出范围)# 反向索引 (从 -1 开始)print(fruits[-1]) # 输出: 'date' (最后一个元素)print(fruits[-2]) # 输出: 'cherry' (倒数第二个元素)print(fruits[-5]) # 报错: IndexError: list index out of range (索引超出范围)\n\n列表切片 (Slicing)切片允许你提取列表的一个子集，通过指定起始和结束索引来实现。切片的语法是 list[start:end:step]，左闭右开, 其中：\n\nstart：切片的起始索引（包含该索引对应的元素）, 如果省略，默认为 0。\nend：切片的结束索引（不包含该索引对应的元素）, 如果省略，默认为列表末尾, 包含末尾元素。\nstep：步长，表示每隔多少个元素取一个，默认为 1; 如果是负数, 则表示逆序取元素。\n\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]# 获取索引 2 到 4 的元素 (索引 5 不包含)print(numbers[2:5])   # 输出: [2, 3, 4]# 获取从开头到索引 3 的元素print(numbers[:4])    # 输出: [0, 1, 2, 3]# 获取从索引 5 到末尾的元素print(numbers[5:])    # 输出: [5, 6, 7, 8, 9]# 获取整个列表的副本print(numbers[:])     # 输出: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]# 每隔一个元素取一个print(numbers[::2])   # 输出: [0, 2, 4, 6, 8]# 倒着取元素print(numbers[-2:-1:]) # 输出: [8]  # 注意: -1 是结束索引, 不包含print(numbers[-1:-2:]) # 输出: []  # 步长为正，起始索引在结束索引之后，结果为空列表 print(numbers[-1:-2:-1]) # 输出: [9] # 步长为负，起始索引在结束索引之后，可以取到元素# 逆序列表print(numbers[::-1])  # 输出: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\n修改、添加和删除元素由于列表是可变的，我们可以很方便地操作其内容。\n修改元素: 直接通过索引赋值即可。\ncolors = [\"red\", \"green\", \"blue\"]colors[1] = \"yellow\"print(colors) # 输出: ['red', 'yellow', 'blue']\n\n添加元素: \n\nappend()：在列表末尾添加一个元素, 函数原型为 list.append(element)。\ninsert()：在指定索引位置插入一个元素, 函数原型为 list.insert(index, element)。\nextend()：用另一个可迭代对象（如列表、元组、字符串等）扩展当前列表，将其中的所有元素添加到末尾。函数原型为 list.extend(iterable)，这里参数不是专门限定为列表，而是任何可迭代对象，因此更灵活。\n\ncolors.append(\"purple\")print(colors) # 输出: ['red', 'yellow', 'blue', 'purple']colors.insert(1, \"orange\") # 在索引 1 处插入 'orange'print(colors) # 输出: ['red', 'orange', 'yellow', 'blue', 'purple']more_colors = [\"cyan\", \"magenta\"]colors.extend(more_colors)print(colors) # 输出: ['red', 'orange', 'yellow', 'blue', 'purple', 'cyan', 'magenta']colors.extend(\"pink\") # 也可以传入字符串, 会把每个字符作为单独元素添加colors.extend((1, 2, 3)) # 也可以传入元组\n\n删除元素: \n\ndel 语句：根据索引删除元素, 语法为 del list[index], 注意 del 不是列表的方法, 而是 Python 的一个关键字。\nremove() 方法：根据值删除第一个匹配的元素, 语法为 list.remove(value)。\npop() 方法：删除并返回指定索引的元素, 可以用一个变量接受返回值. 如果不指定索引, 默认删除并返回最后一个元素, 语法为 list.pop([index])。\n\ndel colors[1] # 删除索引为 1 的 'orange'print(colors) # 输出: ['red', 'yellow', 'blue', 'purple', 'cyan', 'magenta', 'p', 'i', 'n', 'k', 1, 2, 3]colors.remove(\"yellow\") # 删除值 'yellow'print(colors) # 输出: ['red', 'blue', 'purple', 'cyan', 'magenta', 'p', 'i', 'n', 'k', 1, 2, 3]last_color = colors.pop() # 删除并返回 'magenta'print(f\"Removed color: {last_color}\")print(colors) # 输出: ['red', 'blue', 'purple', 'cyan', 'p', 'i', 'n', 'k', 1, 2]\n\n常用的列表方法除了上面提到的，列表还有许多非常有用的内置方法。\nsort()：对列表进行原地排序（会修改原列表）。\nsorted() 函数：返回一个排序后的新列表，不修改原列表。\nreverse()：将列表中的元素原地反转。\nlen() 函数：返回列表的长度（元素个数）。\ncount()：返回指定元素在列表中出现的次数。\nindex()：返回指定元素在列表中首次出现的索引。\ncopy()：返回列表的一个浅拷贝。\n列表推导式 (List Comprehensions)/列表生成式列表生成式是一种优雅且高效的创建列表的方式。它允许你用一行代码代替多行的 for 循环，使代码更具可读性和 Pythonic 风格。\n它的基本结构如下：\nnew_list = [expression for item in iterable if condition]\n我们可以将这个结构拆解成四个部分来理解：\n\nexpression (表达式)：基于 item 计算得出的新列表中的元素。\nfor item in iterable (循环)：遍历一个可迭代对象，将每个元素赋值给 item。这是必须的部分。\nif condition (条件判断)：一个可选的过滤器。只有当 condition 为 True 时，expression 的结果才会被添加到新列表中, 不过不能加 else。\n[] (方括号)：表示我们正在创建一个列表。\n\n为了更好地理解，我们来看几个从传统 for 循环演变到列表生成式的例子\n# 传统的 for 循环方式squares = []for x in range(10):    squares.append(x**2)print(squares)  # 输出: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]# 使用列表生成式squares = [x**2 for x in range(10)]print(squares)  # 输出: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n还可以在表达式中使用条件判断(if … else):\n# 注意：if-else 结构在表达式部分，而不是在末尾number_types = ['even' if x % 2 == 0 else 'odd' for x in range(10)]print(number_types)# 输出: ['even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd']\n可见，在一个列表生成式中，for前面的if … else是表达式，而for后面的if是过滤条件，不能带else。\n列表生成式的优点:\n\n代码简洁：将多行代码浓缩为一行，减少了代码的冗余。\n可读性强：对于熟悉其语法的开发者来说，列表生成式能够更清晰地表达代码的意图。\n性能更高：列表生成式通常比等效的 for 循环和 append 操作要快。这是因为 Python 解释器可以为其进行专门的优化，避免了在循环中重复调用 append 方法的开销。\n\n\n除了列表生成式，Python 还提供了类似的字典生成式和集合生成式，它们的语法结构非常相似：{key_expr: val_expr for item in iterable} (字典生成式){expr for item in iterable} (集合生成式)\n\n元组 (Tuple)元组是一个有序的、不可变的集合，可以包含任意类型的对象。元组使用圆括号 () 来定义，元素之间用逗号分隔。\n","categories":["python"],"tags":["language","python"]},{"title":"链接和加载","url":"/2025/08/22/system/Old_OS/%E9%93%BE%E6%8E%A5%E5%92%8C%E5%8A%A0%E8%BD%BD/","content":"静态链接静态链接（Static Linking）是一种在程序编译后的链接阶段，将所有必需的库代码从静态库（Static Library）文件中复制到最终可执行文件中的过程。\n其核心思想是“一次性打包”。链接器在生成可执行文件时，会解析程序中所有对外部函数的调用（比如 printf()），然后从静态库文件中找到对应的函数代码，并将其直接嵌入到可执行文件内部。\n这个过程通常发生在编译的最后一步，由链接器（如 ld）完成：\n\n输入：链接器接收一个或多个由编译器生成的目标文件（Object Files，如 .o 文件），以及程序所依赖的静态库文件（在 Linux 上通常是 .a 格式，在 Windows 上是 .lib 格式）。\n静态库文件（在 Linux 上通常是 .a 格式，a 代表 archive，意为“档案”或“归档”）本质上就是一系列目标文件（Object Files，.o 文件）的归档文件, 保存了多个由编译器生成的 .o 文件，每个 .o 文件都包含了某个函数或一组相关函数的机器码和数据。\n\n\n符号解析和代码嵌入：链接器会扫描所有目标文件，并解析其中对外部函数和变量的引用（即“符号”）。对于每一个被引用的外部符号，链接器会从静态库中找到对应的代码和数据，并将它们精确地复制到最终的可执行文件中。\n生成输出：链接器将所有目标文件中的代码、被引用的库代码以及其他必要的运行时信息（如文件头、数据段等）组合在一起，生成一个完整的、自包含的可执行文件。这个可执行文件在运行时不再需要外部库文件，因为它已经包含了所有必要的代码。\n\n静态链接的优缺点优点: \n\n高度可移植性：由于静态链接后的可执行文件在运行时不再需要外部库文件，你可以轻松地将它复制到任何兼容的系统上运行，而不用担心动态链接时目标系统是否安装了特定的库版本。这解决了“依赖地狱”（Dependency Hell）问题。\n\n运行时独立性：程序在运行时不需要额外的链接步骤，加载器只需要将整个文件加载到内存即可，这可能带来更快的程序启动速度。\n\n版本锁定：程序使用的库代码版本是固定的，不会因为系统库的更新而出现兼容性问题。这对于需要稳定运行环境的应用程序非常重要。\n\n\n缺点: \n\n体积庞大：由于每个可执行文件都包含了所有必需的库代码，最终生成的文件会非常大。如果多个程序都使用了同一个静态库，那么每个程序都会有一份独立的库代码副本。\n\n内存浪费：在多进程环境中，如果多个静态链接的程序同时运行，它们会各自在内存中加载同一份库代码，造成内存资源的重复占用。\n\n更新不便：如果使用的某个静态库被发现有安全漏洞或 Bug，那么所有使用了这个库的程序都必须重新编译并重新分发，才能获得更新。这对于广泛部署的软件来说是一个巨大的维护负担。\n\n\n动态链接动态链接（Dynamic Linking）是一种将程序依赖的库代码的链接工作，推迟到程序运行时才进行的链接方式。\n其核心思想是“按需加载，共享使用”。程序在编译时并不会把库代码复制进来，而是在可执行文件中只保留对外部库函数的一个引用。当程序启动时，操作系统中的动态加载器（Dynamic Loader）会负责找到这些外部库文件，将它们加载到内存中，并完成最终的链接工作。\n动态链接的流程如下：\n\n编译器生成目标文件，其中对库函数的调用只是一个符号引用（例如，printf）。\n\n链接器生成最终的可执行文件，但它并不会将库代码嵌入进来。它只会在可执行文件的特定区域（例如，Windows 的 IAT 或 Linux 的 GOT/PLT）记录下程序所依赖的库名称和函数名。此时，可执行文件体积很小，因为它只包含自己的代码和对外部库的“占位符”。\n\n用户启动程序，操作系统将可执行文件加载到内存。此时操作系统的动态加载器接管控制权。它会读取可执行文件中的依赖列表，找到所需的动态库文件（例如，Windows 的 .dll 或 Linux 的 .so）并将这些动态库加载到内存的某个位置。\n\n地址解析：加载器会“修补”可执行文件中的“占位符”，将对库函数的符号引用替换为这些库函数在内存中的实际地址。一旦所有依赖都成功加载和解析，加载器将控制权转交给程序，程序开始正式执行。\n\n\n优缺点优点: \n\n节省磁盘空间：多个程序可以共享同一个动态库文件。磁盘上只需要存储一份库代码，大大减少了存储空间的占用。\n\n节省内存：在内存中，动态库的代码段通常只被加载一次。如果有多个程序同时使用同一个动态库，它们会共享这块内存区域，从而显著提高了内存利用率。\n\n便于程序升级与维护：当库文件被修复了 Bug 或进行了安全更新后，开发者只需要替换旧的库文件即可。所有依赖这个库的程序在下次运行时都会自动使用新版本，而不需要重新编译或分发。这解决了“DLL Hell”或“共享库地狱”的部分问题。\n\n模块化开发：大型程序可以被分解为多个动态库，每个库可以由不同的团队独立开发和更新。\n\n\n缺点: \n\n依赖性问题：程序在运行时必须依赖于目标系统上存在特定版本的动态库。如果库文件缺失、版本不兼容或被意外删除，程序将无法启动。\n\n启动时性能开销：程序启动时，操作系统需要额外花费时间来定位、加载和链接动态库，这会比静态链接的程序有略微的启动延迟。\n\n版本冲突：当一个程序依赖于一个库的旧版本，而另一个程序依赖于这个库的新版本时，可能会发生冲突。\n\n\n","categories":["system"],"tags":["system"]},{"title":"RISC-V 的调用约定","url":"/2025/10/08/system/computer-architecture/RISC-V%20%E7%9A%84%E8%B0%83%E7%94%A8%E7%BA%A6%E5%AE%9A/","content":"什么是调用约定首先，我们需要理解什么是调用约定（Calling Convention）。它是一套规则，用于规定函数在调用时如何进行交互。这套规则确保了由不同程序员编写、甚至由不同编译器编译的函数能够正确地相互调用。\n调用约定通常定义了以下内容：\n\n参数传递：如何将参数传递给函数（使用寄存器还是栈）。\n\n返回值：函数如何将返回值传回给调用者。\n\n寄存器使用：调用者（Caller）和被调用者（Callee）如何划分和使用寄存器。\n\n栈管理：如何分配和释放栈帧（Stack Frame）。\n\n\nRISC-V 标准调用约定 (LP64)RISC-V 的标准调用约定非常清晰和高效，主要依赖寄存器来传递参数。下面是其核心内容的总结，以标准的 64 位架构（RV64I）为例。\n\n参数传递 (Argument Passing)\n\n\n整型/指针参数：前 8 个整型或指针参数通过寄存器 a0 到 a7 (x10 - x17) 传递。\n\n浮点参数：前 8 个浮点参数通过浮点寄存器 fa0 到 fa7 传递。\n\n更多参数：如果参数超过 8 个，多余的参数将从右到左依次压入**栈（Stack）**中进行传递。\n\n\n\n返回值 (Return Values)\n\n\n整型/指针返回值：返回值通常放在 a0 (x10) 中。如果返回值需要 128 位（例如一个大的结构体），则高 64 位放在 a1 (x11) 中，低 64 位放在 a0 中。\n\n浮点返回值：同样，浮点返回值使用 fa0 和 fa1。\n\n\n\n寄存器用途表RISC-V 共有 32 个通用整型寄存器 (x0 - x31)，它们在调用约定中扮演着不同的角色。使用 ABI (Application Binary Interface) 名称可以更容易地记住它们的用途。\n\n\n\n\n寄存器 (ABI 名称)\n寄存器编号\n角色\n保存策略\n描述\n\n\n\nzero\nx0\n硬编码零\n-\n始终为 0，不可修改。\n\n\nra\nx1\n返回地址\nCaller-Saved\n保存函数调用后的返回地址。由 jal 和 jalr 指令隐式修改。\n\n\nsp\nx2\n栈指针\nCallee-Saved\n指向当前栈帧的顶部。\n\n\ngp\nx3\n全局指针\n-\n指向全局数据区，由链接器设定。\n\n\ntp\nx4\n线程指针\n-\n指向当前线程的私有数据区。\n\n\nt0-t2\nx5-x7\n临时寄存器\nCaller-Saved\n用于存放临时数据，函数可以随意使用。\n\n\ns0/fp\nx8\n保存寄存器/帧指针\nCallee-Saved\ns0 是被调用者保存寄存器，也可作为帧指针（Frame Pointer）。\n\n\ns1\nx9\n保存寄存器\nCallee-Saved\n被调用者保存寄存器。\n\n\na0-a1\nx10-x11\n函数参数/返回值\nCaller-Saved\n用于传递前两个参数和返回值。\n\n\na2-a7\nx12-x17\n函数参数\nCaller-Saved\n用于传递第 3 到第 8 个参数。\n\n\ns2-s11\nx18-x27\n保存寄存器\nCallee-Saved\n被调用者保存寄存器。\n\n\nt3-t6\nx28-x31\n临时寄存器\nCaller-Saved\n用于存放临时数据。\n\n\nCaller-Saved 与 Callee-Saved 寄存器的区别这是调用约定中关于寄存器管理的核心。这个策略旨在最小化内存访问（保存/恢复寄存器到栈），从而提高性能。\n\n调用者保存寄存器 (Caller-Saved Registers)\n\n也称为临时寄存器（Temporary Registers）或易变寄存器（Volatile Registers）。这些寄存器可以被**被调用函数（Callee）**自由地、无条件地修改。\n工作流程：\n\n调用前：如果一个调用者函数（例如 main）在一个 Caller-Saved 寄存器（例如 t0）中存放了一个重要的值，并且希望在被调用函数（例如 funcA）返回后继续使用这个值。\n\n保存：那么 main 函数必须在执行 call funcA 指令之前，自己负责将 t0 的值保存到栈上。\n\n调用后：funcA 返回后，main 函数再从栈上恢复 t0 的值。\n\n\n为什么这么设计？funcA 可以无所顾忌地使用这些寄存器进行计算，而不需要执行任何保存/恢复操作，这使得那些简短的、不需要太多寄存器的叶子函数（leaf function）执行得非常快。例如RISC-V 中的ra, t0-t6, a0-a7等\n\n被调用者保存寄存器 (Callee-Saved Registers)\n\n也称为保存寄存器（Saved Registers）或非易变寄存器（Non-Volatile Registers）。这些寄存器的值在函数调用前后必须保持不变。\n工作流程：\n\n调用前：调用者函数（main）可以放心地将一个长期有效的值（例如一个循环计数器）存放在一个 Callee-Saved 寄存器（例如 s0）中，然后去调用 funcA。\n\n被调用者内部：如果 funcA 需要使用 s0 寄存器，它必须在函数的开头（prologue）先把 s0 的原始值保存到自己的栈帧中。\n\n返回前：在 funcA 返回之前（epilogue），它必须从栈中恢复 s0 的原始值。\n\n调用后：这样，当 funcA 返回到 main 时，main 可以确信 s0 里的值和调用前一模一样。\n\n\n为什么这么设计？调用者可以放心地使用这些寄存器来存储重要的局部变量，而不用在每次函数调用时都去保存和恢复它们，这减少了不必要的内存操作。在RISC-V 中的例子有sp, s0-s11。\n","categories":["system"],"tags":["system"]},{"title":"操作系统概论","url":"/2024/05/01/system/Old_OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/","content":"操作系统的角色和功能所谓操作系统, 就是软硬件之间的桥梁, 通过调度硬件资源更好地运行软件\n\n向上（对软件）：它为应用程序（如微信、Word、游戏等）提供了一个一致的运行平台和接口。\n\n步骤说明：应用程序不需要知道具体硬件（比如某款特定声卡）的复杂细节，只需要向操作系统发出“播放声音”的请求，操作系统会负责将这个请求翻译给具体的硬件来执行。这极大地简化了软件开发的难度。\n\n\n向下（对硬件）：它直接控制和驱动所有硬件设备，如处理器（CPU）、内存、硬盘、键盘、鼠标等。\n\n步骤说明：操作系统将硬件的复杂物理特性抽象成简单的逻辑功能，例如，它将硬盘上复杂的磁道和扇区抽象成我们易于理解的“文件”和“文件夹”。\n\n\n\n我们可以将操作系统（Operating System, OS） 理解为现代数字计算机的灵魂和总指挥。它是在计算机硬件（如CPU、内存、硬盘）之上运行的最基础、最核心的系统软件。没有操作系统，我们的电脑就是一堆无法有效工作的金属和塑料。\n操作系统核心任务：管理资源与提供服务资源管理器 (Resource Manager)计算机的资源是有限的，比如只有一个 CPU（或者有限的核心）、固定大小的内存。当多个程序同时运行时，操作系统必须扮演一个公平且高效的“管家”。\n\n管理CPU：决定在某个瞬间，哪个程序可以使用处理器。\n\n目的：通过快速切换，实现宏观上的“多任务同时运行”，避免单个程序独占系统。\n\n\n管理内存：为每个程序分配所需的内存空间，并在程序关闭后回收它们，确保程序之间互不干扰。\n\n管理I/O设备：管理键盘输入、屏幕输出、磁盘读写等所有输入/输出操作。\n\n\n服务提供者 (Service Provider)操作系统通过提供一系列基础服务，让用户和应用程序能够方便地使用计算机。\n\n文件系统管理：提供创建、读取、更新和删除文件（CRUD）的功能。\n\n用户接口：提供与用户交互的方式，可以是图形用户界面（GUI），如 Windows 的桌面和窗口；也可以是命令行界面（CLI）\n\n程序执行：负责将程序加载到内存中并开始运行。\n\n\n操作系统上的程序操作系统是连接软件和硬件的桥梁。因此想要理解操作系统，我们首先需要对操作系统的服务对象 (应用程序) 有更精确和深刻的理解\n程序 = 状态机任何一个C程序，其从开始运行到结束的整个过程，都可以被严格地描述为一个状态机。\n\n状态机是拥有严格数学定义的对象。这意味着我们可以用一种精确的、无歧义的方式来描述和分析程序的行为，这种方法也称为形式化方法（Formal Methods）。\n\n什么是程序的状态 (State)程序在任何一个瞬间的“快照”就是它的状态。这个快照必须包含所有能决定程序未来行为的信息, 即状态 = [StackFrame, StackFrame, …] + 全局变量\n\n栈帧（Stack Frame）：每当一个函数被调用时，系统就会为它在调用栈上创建一个栈帧。这个栈帧里包含了该函数的所有信息，例如：\n\n函数的参数（Arguments）。\n\n函数内部定义的局部变量（Local Variables）。\n\n程序计数器（Program Counter, PC）：它指向当前函数中，下一条将要被执行的语句的地址。\n\n返回地址（Return Address）：当函数执行完毕后，应该返回到哪里继续执行。\n\n\n\n全局变量（Global Variables）：它们不属于任何一个函数，在程序的整个生命周期中都存在，因此是状态的一个独立组成部分。\n\n\n一个程序在任一时刻的精确状态，由“当前所有全局变量的值”和“整个调用栈（及其所有栈帧）的内容”共同唯一确定。\n什么是程序的初始状态 (Initial State)程序的执行必须有一个明确的起点。这个起点就是初始状态。在程序语言的层面, 可以理解为初始状态 = main 的第一条语句\n\n全局变量全部为初始值：\n\n所有全局变量和静态变量都被赋予它们的初始值（如果代码中指定了），或者被默认初始化为零。\n\n\n仅有一个 StackFrame(main, argc, argv, PC=0)：\n\n程序开始执行时，操作系统会调用 main 函数。\n\n此时，调用栈上只有一个为 main 函数创建的栈帧。\n\n这个栈帧里包含了传递给 main 的命令行参数 argc 和 argv。\n\nPC=0 （这里的 0 是一个相对位置）意味着程序计数器指向 main 函数内部的第一条可执行语句。\n\n\n\n\n总的来说, 程序的初始状态是：所有全局变量初始化完毕，且调用栈上仅有 main 函数的栈帧，执行点位于 main 的开头。\n什么是状态迁移 (State Transition)状态机模型的核心在于状态如何从一个变为另一个，这就是状态迁移。\n总的来说, 状态迁移 = 执行 frames[-1].PC 处的简单语句 , 这里的 frames[-1] 指的是调用栈顶部的那个栈帧（也就是当前正在执行的函数）。.PC 则是该函数内的程序计数器。\n状态迁移由执行一条最基本的、不可再分的指令触发。 每执行这样一条指令，程序的状态就会发生一次微小的、确定的变化。例如：\n\n赋值操作：x = 10; 这条语句会改变变量 x 的值，导致程序状态发生变化。\n\n函数调用：foo(); 这会导致一个新的栈帧（为 foo 函数）被压入调用栈的顶部，PC会跳转到 foo 函数的起始位置。这显然是一个状态迁移。\n\n函数返回：return; 这会导致顶部的栈帧被弹出，PC恢复到调用该函数之前的位置。这也是一个状态迁移。\n\n控制流：if-else 或循环语句会根据条件改变 PC 的值，从而改变下一条要执行的指令，引发状态迁移。\n\n\n程序通过一条条地执行简单指令，不断地从一个状态转移到下一个状态。整个程序的执行过程，就是一条从“初始状态”出发，经过一系列“状态迁移”而形成的轨迹。\n\n这个模型是调试器（Debugger）、编译器优化（Compiler Optimization）和程序形式化验证（Formal Verification）等技术的理论基础。调试器之所以能让你“单步执行”或“设置断点”，本质上就是因为它能暂停程序的状态迁移，并让你检查当前的状态（变量值、调用栈等）。\n\n如何改变外部状态我们之前讨论过，一个C程序可以被看作一个严谨的状态机。这个模型的“状态”由变量值和调用栈构成，而“状态迁移”由执行一条条简单的语句驱动。\n使用这个状态机模型，我们可以实现任何纯粹的计算（Pure Computation）。\n\n    什么是纯粹的计算 \n    \n      它指的是所有操作都局限在程序内部状态中的计算。它读取程序内存中的数据，处理后，再写回程序内存中。整个过程是自包含的，与外界隔离。例如：\n\nstrlen(s)：读取内存中字符串 s 的数据，计算其长度，返回一个数字。整个过程只涉及内存读取。\n\nmemcpy(dest, src, n)：从内存地址 src 复制 n 个字节到内存地址 dest。整个过程只是在程序自己的内存空间里移动数据。\n\nsprintf(buf, “%d”, 123)：将数字 123 格式化成字符串，然后写入到程序提供的内存缓冲区 buf 中。\n\n\n这些函数的所有行为，都可以用我们之前讨论的状态机模型完美描述。它们的执行只会改变程序内部的变量和内存，不会对计算机的其他部分产生任何直接影响。\n \n\n    \n  \n\n然而, 仅靠程序无法实现的是改变“程序外的状态”, 例如: \n\n显示器上显示的内容\n硬盘上的文件。\n网络连接的状态。\n键盘、鼠标的输入。\n程序自身的生与死（由操作系统管理）。\n\n当你在程序中输入putchar(‘A’), 这个函数的目的不是在内存里写入字符 ‘A’，而是要让 ‘A’ 这个字符出现在屏幕上。屏幕是程序外部的物理设备，它的显示内容就是一种“程序外的状态”。\n同理, 当我们键入exit(0)时, 这个函数要终止程序自身的运行。一个程序如何“杀死”自己？这涉及到操作系统对进程的管理，这同样是“程序外的状态”。\n系统调用 (System Call)为什么程序不能直接操作外部世界？因为这是极其危险的。如果任何程序都能随意写硬盘、控制屏幕，整个系统将陷入混乱且毫无安全可言。\n因此，操作系统在程序（用户空间 User Space）和系统资源/硬件（内核空间 Kernel Space）之间建立了一道不可逾越的屏障。程序运行在受限的“用户模式”下，而操作系统内核运行在拥有最高权限的“内核模式”下。\n当一个程序需要执行像“在屏幕上显示字符”这样超出“纯粹计算”范畴的操作时，它不能直接去做，而是必须向操作系统请求服务。这个请求服务的机制，就是系统调用。其基本过程如下：\n\n调用库函数：当我们在C代码调用 putchar(‘A’)。这实际上是调用了C标准库（libc）中的一个函数。\n\n准备系统调用：putchar 这个库函数会将要执行的操作（例如，在Linux上是 write 系统调用）的编号和参数（要写入的字符’A’、目标是标准输出等）准备好，存放在CPU的特定寄存器中。\n\n触发陷阱（Trap）：库函数执行一条特殊的机器指令（例如在 x86-64 上是 syscall，在 RISC-V 上是 ecall）。这条指令会使CPU产生一个“陷阱”，中断当前程序的执行。\n\n切换到内核模式：CPU响应陷阱，立即将运行模式从用户模式切换到内核模式，并将控制权交给操作系统预先设定的一个“系统调用处理程序”。\n\n内核执行操作：操作系统内核根据程序放在寄存器里的请求编号和参数，得知程序想要“在标准输出写入字符’A’”。内核会验证这个请求的合法性，然后代替程序去执行这个操作，例如调用显卡驱动程序，最终将字符’A’显示在屏幕上。这是真正改变“程序外状态”的一步。\n\n返回用户模式：内核完成操作后，会将结果（如果有的话）放回寄存器，并将CPU切换回用户模式，控制权交还给程序中触发 syscall 指令之后的位置。程序继续执行，就好像什么都没发生一样，但屏幕上已经多了一个’A’。\n\n\n\n像 putchar, exit, fopen, read, write 这些看似普通的标准库函数，其内部都封装了复杂的系统调用过程，它们是程序向操作系统请求服务的用户友好接口。\n\nstrace (system call trace)strace (system call trace)，即系统调用跟踪。它能够跟踪一个进程执行时所进行的所有系统调用（system calls）以及这些调用的参数、返回值和执行时间。\n使用示例strace 的基本用法非常简单，你可以在想要追踪的命令前加上 strace。例如对下列的C程序代码:\n// test_write.c#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;int main() {    int fd;    const char *data = \"Hello, strace!\\n\";    // 打开文件    fd = open(\"output.txt\", O_CREAT | O_WRONLY | O_TRUNC, 0644);    if (fd == -1) {        perror(\"open\");        return 1;    }    // 写入数据    if (write(fd, data, strlen(data)) == -1) {        perror(\"write\");        close(fd);        return 1;    }    // 关闭文件    if (close(fd) == -1) {        perror(\"close\");        return 1;    }    printf(\"Data written to output.txt\\n\");    return 0;}\n\n采取下列命令编译并执行\ngcc test_write.c -o test_writestrace ./test_write\n\n终端的输出结果如下\n...openat(AT_FDCWD, \"output.txt\", O_WRONLY|O_CREAT|O_TRUNC, 0644) = 3fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0write(3, \"Hello, strace!\\n\", 15) = 15close(3) = 0...\n\n\nopenat(…) = 3：程序调用 openat 系统调用打开名为 output.txt 的文件。参数 O_WRONLY|O_CREAT|O_TRUNC 表示以只写、创建（如果不存在则创建）和截断（如果文件已存在则清空其内容）模式打开。返回值 3 是文件描述符。\n\nwrite(3, “Hello, strace!\\n”, 15) = 15：程序调用 write 系统调用向文件描述符 3（即 output.txt）写入 Hello, strace!\\n 这段数据，共 15 个字节。返回 15 表示成功写入了 15 个字节。\n\nclose(3) = 0：程序调用 close 系统调用关闭文件描述符 3。返回 0 表示成功关闭。\n\n\n通过这些输出，我们可以清晰地看到程序如何与文件系统进行交互，从而验证它的行为是否符合预期。\n\n    观测程序运行的常用手段 \n    \n      调试器 (Debugger)：通常用于单步执行程序，设置断点，检查变量值，并修改程序执行流程。\n\n提供微观、精确的控制和观测，适合深入分析特定代码段的逻辑错误或运行时行为。它关注的是“程序在某个点上，状态是什么样的？”。\n\nTrace (跟踪工具，例如 strace)：记录程序执行过程中的特定事件或交互，如系统调用、函数调用、消息传递等。\n\n提供宏观、连续的执行流视图，帮助我们理解程序的行为序列。strace特别关注程序与操作系统之间的交互，揭示了“程序做了什么系统操作？”以及“这些操作的顺序和结果如何？”。\n\nProfiler (剖析器/性能分析器)：测量程序的性能指标，如函数执行时间、CPU使用率、内存占用、缓存命中率等。\n\n提供性能优化所需的洞察。它关注的是“程序在哪里消耗了最多的资源？”或“哪个部分是性能瓶颈？”。\n\n\n    \n  \n\n理解操作系统上的应用程序作为用户, 我们是感受不到操作系统的, 我们只能感受到操作系统上运行的程序(进程)\n但是总的来看, 应用程序 = 计算 + 操作系统 API. 应用程序的魔法在于，它将操作系统提供的简单、原始的API，通过大量的计算和逻辑，组合、封装、抽象成了我们所见的复杂功能。\n下面是一个程序的生命周期 :\n\n诞生：由 execve 设置初始状态\n\n程序不会凭空开始运行。它总是由一个已存在的进程（例如，你正在使用的命令行 shell 或者桌面环境的图标点击处理器）通过执行 execve 这个系统调用来加载和启动。\n\nexecve 是一个核心的系统调用，它会加载新的程序代码到内存中，清空旧的进程数据，并设置好新程序的初始状态（例如，初始化CPU寄存器，设置程序计数器PC指向入口点），准备开始执行。\n\n\n\n运行：计算 + 系统调用 (Syscalls)\n\n一旦开始，程序的整个生命就是一部状态机执行的历史。这个过程只由两类活动构成：\n\n计算 (Computation)：在程序内部进行的数据处理、逻辑判断等，这部分只会改变程序内部的状态。\n\n系统调用 (Syscalls)：当程序需要与外部世界交互时，它必须通过系统调用向操作系统请求服务。\n\n\n\n\n\n\n\n常见的系统调用如下:进程管理: fork (创建新进程), execve (执行新程序), exit (终止进程)。文件/设备管理: open, close, read, write (对文件或设备进行读写，在Linux中“一切皆文件”，屏幕、键盘等设备也是通过这些API操作的)。存储管理: mmap (内存映射，一种高效的文件I/O和进程间共享内存的方式), brk (调整程序数据段的大小以分配/释放内存)。\n\n\n终结：调用 _exit 退出\n\n程序的生命最终会通过调用 _exit (在Linux中通常是 exit_group 这个系统调用) 来结束。这个调用会通知操作系统回收该程序占用的所有资源（内存、文件句柄等）。\n\n\n\n程序与操作系统的分层生态系统层次一：能直接看到的程序 (Applications)这类程序是我们作为用户最熟悉的，它们是我们为了完成特定任务而主动打开并直接与之交互的软件。\n它们是操作系统“提供舒适抽象API”的最终消费者, 可以全面地利用操作系统提供的各种API（系统调用）来实现丰富的功能，将底层的复杂性转换成用户友好的图形界面或功能。\n例如开发工具Vscode, 作为集成开发环境，它需要频繁地进行文件操作（open, read, write 来读写代码文件）、进程管理（调用 gcc 或 clang 等编译器，需要 fork 和 execve）、以及网络功能（下载插件和更新，需要 socket API）。\n再比如日用软件Chrome浏览器是功能集大成者。它既是网络客户端（大量网络API），又是文件管理器（下载/上传），还是一个多媒体播放器（音频/视频API），甚至是一个程序平台（运行JavaScript和WebAssembly），其背后是成千上万次的系统调用。\n层次二：能直接看到的(幕后)程序 (Utilities)这类程序通常没有华丽的图形界面，它们是开发者和系统管理员用来管理和操作系统的工具。普通用户可能不常接触，但它们是系统的基石。\n如果说Applications是OS服务的消费者，那么Utilities更像是直接操作OS所提供抽象的“钳子和扳手”。它们的功能与系统调用往往有更直接的对应关系。\nCore Utilities(coreutils) 例如GNU Coreutils, busybox和toybox等, 它们提供了最基础的命令如 ls, cp, rm。ls 的核心是调用 readdir 来读取目录内容；cp 的核心是 read 一个文件再 write 到另一个文件。它们是系统调用的“浅层封装”。\n系统/工具程序如Shell(bash) 是命令行的“心脏”。它的核心循环就是：读取用户输入，然后通过 fork 创建一个子进程，再通过 execve 在子进程中执行用户指定的命令（如 ls 或 chrome）。它是操作系统的进程管理器的最直接用户界面。\n层次三：不能直接看到的后台程序 (Daemons)这类程序在系统启动时就会自动运行，它们没有用户界面，默默地在后台工作，为整个系统提供关键服务。它们被称为守护进程 (Daemon)。\n守护进程是操作系统功能的延伸和实现者。它们本身也是运行在用户空间的进程，但它们负责管理系统资源，并为上层的Applications和Utilities提供服务，是操作系统内核与用户应用程序之间的重要中间层。\n“守护进程” systemd: 在现代Linux系统中，systemd 是1号进程，是所有用户空间进程的“始祖”。它负责启动和管理所有其他的守护进程，是系统服务的大管家。\n系统管理 (cron, udisksd): cron 是定时任务守护进程，它使用定时器相关的系统调用来在特定时间唤醒并执行任务。udisksd 监控硬件事件，当你插入U盘时，它会收到内核通知，并自动执行 mount 等系统调用来挂载U盘。\n各类服务 (httpd, sshd): httpd (Apache) 和 sshd (SSH服务) 是网络服务的提供者。它们在后台监听特定的网络端口 (bind, listen)，等待客户端连接 (accept)，为连接进来的用户提供Web或远程登录服务。\n总结：一个分层的生态系统这三类程序与操作系统的关系构成了一个清晰的层次结构：\n操作系统内核 (Kernel)：提供最核心、最底层的服务和抽象（进程、文件、网络、内存管理等），通过系统调用作为API。\n守护进程 (Daemons)：作为内核的延伸，在后台运行，管理系统资源，并为上层提供更高级、更方便的服务（如窗口管理、音频管理、定时任务）。\n实用工具 (Utilities)：作为专业的“工具箱”，让高级用户和开发者能够直接、高效地操作和管理系统。\n应用程序 (Applications)：作为生态系统的顶层，消费下面所有层提供的服务和抽象，专注于为用户提供完成特定任务的功能和体验。\n从本质上讲，它们全都是操作系统眼中的“进程”，都遵循着计算 + 系统调用的模型。它们的区别在于其设计目的、运行方式以及在整个生态系统中所扮演的角色。\n操作系统上的最小程序 minimal.Sminimal.S 指的是一个最小化的汇编语言程序（.S 是汇编文件的常见扩展名）。它的目标是剥离所有C语言、标准库等上层封装，只保留一个程序能够运行所需的最核心、最基本的元素，从而让我们能清晰地看到程序是如何启动、执行和退出的。\n认识 minimal.S在C语言中，我们写的第一个函数通常是 main。但 main 并非程序的真正入口。在 main 函数执行前，C运行时库（C Runtime Library）已经做了大量的准备工作，比如设置堆栈、初始化全局变量等。\n为了获得最彻底的控制权，我们需要直接从操作系统交给我们的那个最原始的入口点, 即一个名为 _start 的函数开始。\n然而，如果我们天真地写一个C函数 void _start() { … } 并试图编译链接，程序很可能会因为 段错误（Segmentation Fault） 而崩溃。这是因为C函数会默认自己拥有一个合法的、设置好的堆栈（Stack），但在这个最原始的入口点，堆栈环境可能并未完全准备好满足C语言的需求。\n因此，要编写这个最小的程序，我们必须使用比C更底层的汇编语言，这样才能完全、精确地控制每一条指令和每一个寄存器。这就是 minimal.S 的由来。\nminimal.S 如何工作：一个二进制状态机\n初始状态 (Initial State)\n\n由ABI规定：当操作系统通过 execve 加载我们的程序后，在跳转到 _start 之前，它会为我们的程序准备好一个“初始状态”。这个状态必须遵循应用二进制接口（Application Binary Interface, ABI） 的规范。\n\n关键初始状态：最重要的就是操作系统必须提供一个合法的、指向可用内存的栈指针寄存器 sp。没有这个，几乎任何函数调用都会失败。\n\n\n\n入口点与状态迁移 (Entry Point &amp; State Transition)\n\n我们的 minimal.S 的代码就从 _start 这个标签开始。我们要做的最简单、但又能证明程序成功运行的事，就是“正常退出”。\n\n然而, 根据上面介绍的程序知识, 程序自己是不能“停下来”的, CPU指令集中没有“停止”或“退出”指令。程序必须向操作系统发出请求，让操作系统来终结自己。这个请求就是通过系统调用（syscall, 在RISC-V中为ecall） 来完成的。\n\n\n\nsyscall: 终极状态交接\n\n当程序执行 syscall 指令时，它就完全放弃了控制权。CPU会立即陷入内核模式，程序的执行被暂停，操作系统的代码开始运行。\n\n操作系统接管：操作系统内核会检查 a7 寄存器的值，发现是 93，就知道程序请求 exit。然后它会检查 a0 的值，知道退出码是 0。\n\n最终操作：操作系统收到请求后，执行所有清理工作（回收内存、关闭文件等），然后将这个进程彻底销毁。我们的程序，这个“状态机”，就此终结。\n\n\n\n\n一个在RISC-V Linux下的 minimal.S 文件内容如下：\nvoid _start() {    __asm__(        \"li a7, 93\\n\\t\"   // syscall/ecall: exit         \"li a0, 0\\n\\t\"    // status: 0        \"ecall\"    );}// 编译命令: // gcc -nostdlib -Os -o minimal minimal.c\n\n在 GCC 和 Clang 等常见的 C 编译器中，使用 asm 或 asm 关键字来告诉编译器：“接下来的内容不是 C 代码，请直接将其作为汇编指令处理”。这是一种在 C 语言代码中直接嵌入汇编代码的语法，称为 内联汇编 (Inline Assembly)。\n\n硬件视角下的操作系统CPU = 状态机对 CPU 而言，它只是一个忠实而无情的状态机，其毕生的使命就是不断重复一个简单的循环：根据程序计数器（PC, Program Counter）寄存器的地址，从内存中取出一条指令，然后执行它。\n\n状态 (State)\n\n\n计算机在任何一个瞬间的“快照”就是它的状态。这个状态由所有存储单元中的数值共同定义，最核心的就是内存和 CPU 内部所有寄存器的值。\n\n改变任何一个寄存器或内存单元的值，计算机的状态就发生了改变。\n\n\n\n初始状态 (Initial State)\n\n\n系统必须有一个确定的起点。这个起点由系统设计者规定，通常是通过 CPU Reset（复位） 实现的。\n\n当你按下电脑的电源键或重启按钮时，硬件电路会将 CPU 的所有寄存器（包括程序计数器 PC）设置为一个预先规定好的初始值。\n\n\n\n状态迁移 (State Transition)\n\n\n计算机的状态变化由执行指令、响应中断和输入输出三种方式实现\n\n执行指令：CPU 根据 PC 寄存器的指向，从内存中取出指令并执行。执行这条指令的过程，就会改变寄存器或内存的值，从而完成一次状态迁移，进入下一个状态。\n\n在单处理器系统中，状态迁移是线性、串行的。CPU 严格按照程序计数器（PC）的指引，一条一条地执行指令。\n在多处理器系统中, 操作系统内核（作为运行在内核模式下的特权程序）负责调度，它决定在哪个时间点，在哪个处理器核心上，运行哪个进程（或线程）的哪部分指令。而对于多核的单个处理器, ，它的工作模式并没有改变，依然是那个“无情的指令执行机”。\n\n\n响应中断 (Responding to Interrupts)：强制的控制权转移, 可以理解为if (intr) goto vec;\n\nif (intr)：这部分代表硬件在每执行完一条指令后，都会去检查一个名为 intr (interrupt) 的物理信号线。如果某个硬件设备（如定时器、硬盘、网卡）完成了任务或需要关注，它就会在这条线上发出一个信号。\n\ngoto vec;：如果硬件检测到了中断信号，它会立即打断当前正常的执行流程（即不再去执行 PC 指向的下一条指令），转而执行一个特殊的跳转。vec 指的是中断向量表 (Interrupt Vector Table)。硬件会根据中断信号的类型，从这个表的特定位置取出一个地址，然后强制将这个地址加载到 PC 寄存器中。\n\n最终的实现效果是, 无论当前正在运行什么程序，只要中断发生，CPU 的控制权必然、强制性地被硬件移交给操作系统。\n\n\n\n输入输出 (Input/Output)：与外部世界的交互. I/O 是计算机与外部世界（如用户、网络、存储设备）交换数据的过程，也是触发中断和系统调用的主要原因。\n\n应用程序想要读一个文件（访问“外部”的硬盘）, 但是它不能直接向硬盘控制器发命令，于是执行一条 syscall（系统调用）指令，陷入（Trap）到内核。\n\n硬件检测到这是一条特权指令，于是像响应中断一样，将控制权移交给操作系统。\n\n操作系统在内核模式下，向硬盘控制器发出“读数据”的命令，然后可能会让该应用程序暂停（等待），并调度另一个程序运行。\n\n当硬盘准备好数据后，它会通过硬件发出一个中断信号。\n\n硬件再次捕获这个中断，将控制权交给操作系统的中断处理程序。\n\n操作系统从硬盘控制器读取数据，然后将数据交给等待的应用程序，并将其重新置为就绪状态，等待下一次被调度运行。\n\n\n\n\n操作系统：一个掌握特权的“普通程序”既然 CPU 对所有指令一视同仁，那么操作系统是如何实现管理的呢？为什么它能凌驾于普通应用程序之上？\n答案是：操作系统本身就是一个普通的（二进制）程序，但它通过巧妙地利用硬件提供的特权机制和中断机制，实现了对整个系统的管理。\n理解特权现代 CPU 硬件通常包含至少两种操作模式（或称特权级）：\n\n内核模式 (Kernel Mode)：拥有最高权限，可以执行所有指令，访问所有内存和硬件设备。\n\n用户模式 (User Mode)：权限受限，不能执行某些特权指令（如直接操作 I/O 设备、修改页表等），只能访问分配给它的部分内存。\n\n\n操作系统内核的代码运行在内核模式下，而普通的应用程序运行在用户模式下。这道由硬件划分的鸿沟，是系统安全和稳定的基石。\n中断与陷阱：夺取控制权的关键这是整个机制中最核心、最巧妙的部分。操作系统通过“接管”中断，实现了对所有关键事件的控制。\n当一个事件发生时——无论是硬件发出的信号（如磁盘读写完成、网络包到达，这叫中断），还是应用程序请求服务（如读文件、创建进程，这需要执行一条特殊的“陷阱”指令 syscall，也叫陷阱或软中断）——CPU 会硬件级别地、自动地停下当前的工作。\n此时CPU 会自动保存当前程序的执行上下文（比如 PC 寄存器和一些关键寄存器的值），然后跳转到一个预先设定好的内存地址去执行新的指令。这个预设的地址表被称为中断向量表 (Interrupt Vector Table)。\n\n操作系统在启动时，就会去修改这个中断向量表，把里面所有的地址都设置为指向它自己的代码——即各种中断处理程序。\n\n因此可以认为, 一旦启动后，操作系统就变成了一个中断处理程序。\n当应用程序需要访问 I/O 设备时，它不能直接访问（因为处于用户模式，没有权限），只能通过 syscall 指令请求操作系统。这个指令会触发一次陷阱，CPU 自动跳转到操作系统的代码。操作系统在内核模式下代为完成 I/O 操作，完成后再把控制权交还给应用程序。\n当中断发生时（比如用户敲击键盘），CPU 也会立刻跳转到操作系统的中断处理程序，让操作系统决定如何响应。\n操作系统 = 状态机的管理者如果每个进程都是一个状态机，那么操作系统的角色就是这些状态机的管理者 (Manager) 或调度器 (Scheduler)。它负责以下核心任务：\n\n状态机的创建与销毁 (Creation &amp; Destruction)\n\n创建 (spawn 或 fork): 当一个进程请求创建另一个新进程时，操作系统负责为这个新的状态机分配资源（如内存空间、进程控制块PCB），并将其设置到一个可运行的初始状态。\n\n销毁 (exit): 当一个进程执行完毕或被终止时，操作系统负责回收它占用的所有资源，彻底移除这个状态机。\n\n\n\n状态机的调度 (Scheduling)\n\n这是管理的核心。现代操作系统可以同时“容纳”多个程序状态机（即多任务）。但通常情况下，一个CPU核心在同一时刻只能执行一个状态机的一步。\n\n“选一个程序执行一步”: 操作系统的调度器 (Scheduler) 的核心职责就是从所有处于“就绪”状态的状态机中，选择一个，让它在CPU上运行一小段时间（称为“时间片”）。\n\n上下文切换 (Context Switch): 当一个进程的时间片用完，或者它因等待I/O而需要暂停时，操作系统会介入：\n\n保存现场：将当前进程的完整状态（PC、寄存器、内存状态等）保存下来。\n\n恢复现场：选择下一个要运行的进程，并将其之前保存的状态加载到CPU和内存中。\n\n继续执行：让新的进程从它上次暂停的地方继续执行。\n\n\n\n这个“保存-恢复”的过程就是上下文切换，它使得多个状态机看起来像是在同时运行，即并发 (Concurrency)。\n\n\n\n响应状态迁移的请求 (Handling System Calls)\n\n当一个状态机（进程）执行系统调用时，它实际上是在向管理者（操作系统）发出一个请求。操作系统会接管控制权，执行相应的服务。\n\n例如，当进程调用 read():\n\n进程的状态从“运行”迁移到“阻塞”（等待I/O）。\n\n操作系统执行实际的硬件读取操作。\n\n当数据准备好后，操作系统将数据交给进程，并将其状态从“阻塞”改回“就绪”，等待下一次被调度器选中。\n\n\n\n\n\n资源分配与隔离 (Resource Allocation &amp; Isolation)\n\n作为管理者，操作系统必须确保各个状态机之间不会相互干扰，防止一个行为不当的进程搞垮整个系统。\n\n内存隔离：通过虚拟内存技术，操作系统为每个进程提供一个独立的、私有的地址空间。一个进程无法直接访问另一个进程的内存。\n\n权限控制：操作系统控制着对文件、设备等所有共享资源的访问权限。\n\n\n固件: 硬件和操作系统之间的桥梁在我们之前的讨论中，我们已经明确：\n\nCPU 是一个只会从内存指定地址（由 PC 寄存器指向）取指令并执行的“无情机器”。\n\n操作系统是一个特殊的程序，它通过中断和特权级管理整个系统。\n\n\n这里就引出了一个关键的“鸡生蛋还是蛋生鸡”的问题：当计算机刚通电，CPU 复位（Reset）后，它的 PC 寄存器指向的那个初始地址，里面的代码究竟是什么？是谁在一切开始之前就把代码放在了那里？答案就是固件 (Firmware)。\n什么是固件固件，顾名思义，就是被“固化”在硬件里的软件。它是系统厂商“固定”在计算机系统里的代码。它不存储在易失性的主内存（RAM）中，也不是存储在硬盘上，而是存在于主板上的一个特殊的非易失性存储芯片里。\n早期固件通常被烧录在 ROM (Read-Only Memory) 芯片里。这意味着一旦出厂就无法更改。想要升级唯一的办法就是物理更换芯片。\n而现在普遍使用 Flash Memory（闪存）。这使得我们可以通过软件更新的方式来升级固件（例如，刷新主板的 BIOS/UEFI），大大增加了灵活性。\n硬件电路的设计保证了，当 CPU 加电复位时，其 PC 寄存器会被强制设置为一个固定的内存地址，而这个地址正好被内存映射 (memory-map) 到存放固件的那个芯片上。\n因此，CPU 执行的第一条指令必然来自固件。这就意味着，固件“‘出生’就有机器完整的控制权”，它是计算机世界里第一个“发号施令”的角色。\n固件的核心功能固件是连接纯硬件和操作系统的桥梁，它的使命主要分为两个阶段：\n\n硬件初始化与自检 (POST)\n\n\n在操作系统这个庞大的软件开始运行之前，必须确保硬件本身处于一个健康、可用的状态。这正是固件的首要任务。这个过程通常被称为 POST (Power-On Self-Test)，即开机自检。\n\n具体工作：检查 CPU 类型和速度; 检测内存条大小、频率并进行测试; 配置 CPU 电压、内存时序等关键参数; 检测并初始化显卡、硬盘、键盘等外围设备; 根据用户在 BIOS/UEFI 设置界面中的配置，打开或关闭某些接口等。\n\n我们平常打开计算机进入的蓝色的 BIOS(Basic I/O System)或者更先进的UEFI (Unified Extensible Firmware Interface) 设置界面，就是固件提供给我们的一个用户交互接口。\n\n\n\n引导加载操作系统 (Bootstrapping)\n\n\n当硬件检查和配置完毕后，固件的下一个任务，就是找到并启动操作系统。具体流程如下: \n\n固件根据用户设定的启动顺序（如：USB -&gt; SSD -&gt; HDD）去扫描这些存储设备。\n\n它会在设备的特定位置（如硬盘的 MBR 或 GPT 分区的 EFI 文件）寻找一个非常小的程序，这个程序叫做引导加载程序 (Bootloader)。\n\n固件将这个 Bootloader 加载到内存（RAM）中，然后将 CPU 的控制权移交给它。\n\n至此，固件的使命就完成了。接下来，由 Bootloader 负责找到完整的操作系统内核（例如 Windows 的 ntoskrnl.exe 或 Linux 的 vmlinuz），将其加载到内存，最后再把控制权交给操作系统内核。\n\n\n\n\n","categories":["system"],"tags":["system"]},{"title":"程序和进程","url":"/2024/06/30/system/Old_OS/%E7%A8%8B%E5%BA%8F%E5%92%8C%E8%BF%9B%E7%A8%8B/","content":"fork(): 创建新进程的“克隆”技术fork() 是一个在类-UNIX 操作系统（如 Linux, macOS）中使用的系统调用，其唯一的功能就是创建一个新的进程。\n这个新创建的进程被称为“子进程”（Child Process），而调用 fork() 的那个进程则被称为“父进程”（Parent Process）。\n整个过程类似细胞分裂, 当调用 fork() 时，操作系统会拿父进程作为“模板”，几乎原封不动地“克隆”出一个一模一样的副本，这个副本就是子进程。\nfork() 的工作机制当 fork() 被调用时，子进程会获得父进程在调用那一刻的几乎所有资源的副本。\n\n内存空间：子进程会得到父进程整个虚拟地址空间的精确副本，包括代码段、数据段、堆和栈。这意味着父进程中的所有变量和数据，在 fork() 的瞬间，子进程也有一份一模一样的。\n\n程序计数器（Program Counter）：子进程的程序计数器被设置为与父进程相同的值。它意味着子进程和父进程一样将从 fork() 调用返回之后的那条指令开始执行，而不是从程序的开头。\n\n文件描述符：父进程打开的所有文件描述符都会被复制到子进程中。如果父进程打开了一个文件，那么子进程也同样“持有”这个打开的文件。它们共享同一个文件表项，这意味着它们对文件的读写指针是同步的。\n\n其他资源：还包括用户和组ID、环境变量、工作目录、I/O 缓冲区等。\n\n\n尽管是克隆，但父子进程并非100%相同，它们有各自独立的属性：\n\n进程ID (PID)：每个进程在系统中都有一个唯一的ID。子进程会获得一个新的、不同于父进程的PID。\n\n父进程ID (PPID)：子进程的PPID被设置为其父进程的PID。\n\n资源利用信息：如CPU使用时间等统计信息，子进程会从零开始计算。\n\nfork() 的返回值：这是区分父子进程的最关键机制\n\n\nfork() 返回值: 一次调用，两次返回fork() 最独特的地方在于它被调用一次，却在两个进程（父进程和子进程）中各返回一次。并且，这两次的返回值是不同的，这使得我们的程序能够根据返回值来区分当前代码是在父进程中运行还是在子进程中运行。\n\n在父进程中：fork() 返回新创建的子进程的PID（一个正整数）。\n\n原因：父进程需要知道它创建的子进程的ID，以便后续可以管理它（例如，等待它结束）。\n\n\n在子进程中：fork() 返回 0。\n\n原因：子进程可以通过 getppid() 函数轻易地获取其父进程的ID，所以 fork() 返回0就足以让它知道自己是一个子进程。\n\n\n如果出错：fork() 会在父进程中返回 -1，并且不会创建子进程。\n\n原因：通常是因为系统资源不足（如内存耗尽或进程数量达到上限）。\n\n\n\n下面是一个示例\n#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; // 包含 fork(), getpid(), getppid() 的头文件#include &lt;sys/types.h&gt; // 包含 pid_t 类型的头文件int main() {    pid_t pid; // pid_t 是专门用来存储进程ID的数据类型    printf(\"程序开始：我是父进程，我的PID是 %d\\n\", getpid());    // 关键步骤：调用 fork() 创建新进程    pid = fork();    // fork() 之后，这里的代码会被父子两个进程同时执行    // 我们需要通过 pid 的值来区分它们    if (pid &lt; 0) {        // 步骤1：检查 fork 是否失败        // 解释：如果返回值小于0，说明进程创建失败，需要进行错误处理。        fprintf(stderr, \"Fork 失败\\n\");        return 1;    } else if (pid == 0) {        // 步骤2：判断是否为子进程        // 解释：如果返回值为0，那么当前代码在子进程中运行。        printf(\"--- 我是子进程 ---\\n\");        printf(\"我的PID是 %d, 我的父进程PID是 %d\\n\", getpid(), getppid());        // 子进程可以执行独立的任务，例如在这里休眠几秒钟        sleep(2);        printf(\"--- 子进程执行完毕 ---\\n\");    } else {        // 步骤3：判断是否为父进程        // 解释：如果返回值大于0，那么当前代码在父进程中运行，        // 且 pid 变量的值就是刚刚创建的子进程的ID。        printf(\"+++ 我是父进程 +++\\n\");        printf(\"我创建的子进程PID是 %d\\n\", pid);        printf(\"+++ 父进程继续执行任务... +++\\n\");    }    // 这行代码父子进程都会执行，但执行时间点不同    printf(\"fork() 调用之后，我是PID为 %d 的进程\\n\", getpid());    return 0;}\n编译并运行后输出如下:\n程序开始：我是父进程，我的PID是 54321+++ 我是父进程 +++我创建的子进程PID是 54322+++ 父进程继续执行任务... +++fork() 调用之后，我是PID为 54321 的进程--- 我是子进程 ---我的PID是 54322, 我的父进程PID是 54321fork() 调用之后，我是PID为 54322 的进程--- 子进程执行完毕 ---\n\n(注意：由于操作系统调度的不确定性，父子进程的输出顺序可能会交错)\n\nfork() 经典示例下面是一个非常经典的 fork() 习题，它巧妙地结合了进程创建和I/O缓冲区的知识。\n#include &lt;stdio.h&gt;#include &lt;unistd.hh&gt;int main() {    for (int i = 0; i &lt; 2; i++) {        fork();        printf(\"Hello\\n\");    }    return 0;}\n这个程序的运行结果取决于它的输出是如何被处理的，这直接影响到 printf 的缓冲策略。\n\n    当直接在终端执行 (./a.out) 时 \n    \n      \n循环开始前: 只有一个进程 (P0)。\n\ni = 0:\n\nP0 调用 fork()，创建了子进程 P1。现在有 2 个进程 (P0, P1)。\n\nP0 执行 printf(“Hello\\n”)，打印一次。\n\nP1 执行 printf(“Hello\\n”)，打印一次。\n\n此轮循环结束时，共打印了 2 次 “Hello”。\n\n\n\ni = 1:\n\n此时，P0 和 P1 两个进程都进入了第二次循环。\n\nP0 调用 fork()，创建了子进程 P2。\n\nP1 调用 fork()，创建了子进程 P3。\n\n现在总共有 4 个进程 (P0, P1, P2, P3)。\n\n这 4 个进程各自执行 printf(“Hello\\n”)，每个打印一次。\n\n此轮循环结束时，又打印了 4 次 “Hello”。\n\n\n\n总计: 2 + 4 = 6 次 “Hello”。\n\n\n\n    \n  \n\n\n    如果通过管道执行 (./a.out | cat)时 \n    \n      \n循环开始前: 1 个进程 (P0), 且P0 的输出缓冲区是空的。\n\ni = 0:\n\nP0 调用 fork()，创建子进程 P1。\n\n缓冲区状态: P0 和 P1 的缓冲区都是空的。\n\nP0 执行 printf，”Hello\\n” 被放入 P0 的缓冲区。\n\nP1 执行 printf，”Hello\\n” 被放入 P1 的缓冲区。\n\n此时没有任何内容被打印到屏幕上，它们都在各自进程的内存缓冲区里。\n\n\n\ni = 1:\n\nP0 继续执行: 它调用 fork()，创建子进程 P2。\n\n关键: P2 被创建时，它完整地复制了 P0 的内存，因此 P2 的缓冲区初始内容就是 “Hello\\n”。\n\n\nP1 继续执行: 它调用 fork()，创建子进程 P3。同样，P3 被创建时，复制了 P1 的内存，P3 的缓冲区初始内容也是 “Hello\\n”。\n\n现在我们有 4 个进程：P0, P1, P2, P3。缓冲区初始状态为:\n\nP0: “Hello\\n”\n\nP1: “Hello\\n”\n\nP2: “Hello\\n” (继承自 P0)\n\nP3: “Hello\\n” (继承自 P1)\n\n\n\n接下来，这 4 个进程各自执行 printf(“Hello\\n”)。执行后，缓冲区最终状态:\n\nP0 缓冲区: “Hello\\nHello\\n”\n\nP1 缓冲区: “Hello\\nHello\\n”\n\nP2 缓冲区: “Hello\\nHello\\n”\n\nP3 缓冲区: “Hello\\nHello\\n”\n\n\n\n\n\n程序结束:\n\n所有 4 个进程执行完毕，它们在退出前会冲刷各自的 stdout 缓冲区。\n\n每个进程都将打印出其缓冲区中的两个 “Hello\\n”。\n\n总计: 4 个进程 × 每个进程打印 2 次 = 8 次 “Hello”。\n\n\n\n\n\n    \n  \n\n要理解结果的差异，必须先理解 printf 函数的标准输出流 (stdout) 缓冲机制。\n\n行缓冲 (Line-Buffered): 当输出设备是交互式终端时（即我们直接在命令行运行 ./a.out），stdout 默认为行缓冲。\n\nprintf 的内容会先暂存到一块内存缓冲区里。当遇到换行符 \\n，或者缓冲区满了，或者程序结束时，缓冲区的内容才会被真正“冲刷”（flush）到屏幕上。\n\n对于本题：printf(“Hello\\n”) 中的 \\n 会立即触发冲刷，所以每次调用 printf 都会立刻看到输出。\n\n\n\n全缓冲 (Fully-Buffered): 当输出被重定向到文件或管道时（如 ./a.out | cat），stdout 会变为全缓冲。\n\n在这种模式下，只有当缓冲区被写满，或者程序正常结束时，内容才会被冲刷。\\n 不再能触发立即冲刷。\n\n对于本题：printf 的内容会一直留在内存缓冲区中，直到进程结束时才被一次性打印出来。这是导致两种结果不同的根本原因。\n\n\n\n\n这个问题深刻地揭示了 fork() 的一个核心特性：它创建的是父进程在调用那一刻的“快照”。这个快照不仅包括代码和数据，还包括像 I/O 缓冲区这样的用户态资源。\nfork() 的主要用途execve() : 一个复位状态机在操作系统中，我们经常将 fork() 和 execve() 放在一起讨论。\n\nfork() 是新生：它像细胞分裂一样，从一个父进程完整地克隆出一个新的子进程。这个子进程拥有全新的进程ID（PID），但继承了父进程的全部内存状态。\n\nexecve() 是重生：它不会创建新进程。相反，它会将调用它的那个进程彻底“变身”，用一个全新的程序来完全替换当前进程的内存空间。进程的ID（PID）保持不变，但它内部运行的程序已经焕然一新。\n\n\n或者从状态机的视角来看, execve 是一个复位状态机 (Reset State Machine)。它按下了一个“重置按钮”，将当前进程的“状态”——主要是内存中的内容——重置为目标可执行文件所描述的初始状态。\n","categories":["system"],"tags":["system"]},{"title":"生成器","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E7%94%9F%E6%88%90%E5%99%A8/","content":"生成器是一种特殊的迭代器，它不需要你手动去实现迭代器协议（即 iter() 和 next() 方法）。它允许你用一种更简单、更像普通函数的方式来生成一个值的序列。\n生成器的核心思想是 “懒加载” (Lazy Evaluation) 或 “延迟计算”。它不会一次性在内存中创建并存储所有元素，而是在你请求下一个元素时才实时生成它。\n为什么要使用生成器？生成器最主要的优点是内存效率极高。想象一下，你需要处理一个包含一百万个元素的序列。\n\n使用列表：会立即在内存中创建并存储这一百万个元素，占用大量内存。\n使用生成器：它只在你需要时才逐一生成元素。在任何时刻，内存中只有一个元素存在，极大地节约了内存资源。\n\n这使得生成器非常适合处理：\n\n大规模数据集：如大型日志文件、数据库查询结果等。\n无限序列：例如，生成一个永不停止的斐波那契数列。\n数据流处理：在数据处理管道中，数据可以像水流一样通过各个生成器节点，而无需将整个数据集加载到内存中。\n\n创建生成器主要有两种方式可以创建生成器：\n\n生成器函数 (Generator Functions)这是最常见的方式。一个普通的函数，只要包含了 yield 关键字，它就变成了一个生成器函数。\n\nyield 关键字：这是生成器的魔法所在。yield 的作用类似于 return，但它并不会终止函数。相反，它会“暂停”函数的执行，并将其当前状态（包括局部变量）保存下来，然后将 yield 后面的值返回给调用者。当下次请求值时（例如通过 next() 或 for 循环），函数会从上次暂停的地方继续执行。\ndef countdown(n):    print(\"开始倒计时！\")    while n &gt; 0:        yield n  # 暂停并返回 n 的值        n -= 1    print(\"倒计时结束！\")# 1. 调用生成器函数，返回一个生成器对象，此时函数内的代码还未执行c = countdown(3)print(type(c)) # &lt;class 'generator'&gt;# 2. 第一次调用 next()，函数开始执行，直到遇到第一个 yieldprint(next(c)) # 输出 \"开始倒计时！\" 和 3# 3. 第二次调用 next()，函数从上次暂停处继续执行print(next(c)) # 输出 2# 4. 第三次调用 next()print(next(c)) # 输出 1# 5. 第四次调用 next()，循环结束，函数执行完毕#    由于没有更多的 yield，函数会隐式地抛出 StopIteration 异常try:    next(c) # 输出 \"倒计时结束！\" 然后抛出异常except StopIteration:    print(\"生成器已耗尽。\")\n\n注意, 调用generator函数会创建一个generator对象，多次调用generator函数会创建多个相互独立的generator。假如在上面的代码中这样做:\nprint(next(countdown(3))) # 每次调用都会创建一个新的生成器对象, 所以每次都是输出 3print(next(countdown(3))) # 每次调用都会创建一个新的生成器对象, 所以每次都是输出 3\n正确的写法是创建一个generator对象，然后不断对这一个generator对象调用next()或者使用for循环.\n\n生成器表达式 (Generator Expressions)生成器表达式是列表生成式的近亲，语法上非常相似，但它返回的是一个生成器对象，而不是一个列表。\n\n语法：将列表生成式的 [] 替换为 () 即可\n# 列表生成式my_list = [x * x for x in range(5)]print(my_list) # 输出: [0, 1, 4, 9, 16]# 生成器表达式my_generator = (x * x for x in range(5))print(my_generator) # 输出: &lt;generator object &lt;genexpr&gt; at 0x...&gt;# 像使用其他迭代器一样使用它for num in my_generator:    print(num, end=' ') # 输出: 0 1 4 9 16","categories":["python"],"tags":["language","python"]},{"title":"array","url":"/2025/09/30/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/array/","content":"std::array 是在 C++11 中引入的一个容器模板，它封装了一个固定大小的数组。它结合了C风格数组的性能优势（静态分配、无额外开销）和STL容器的便利性与安全性。\n#include &lt;array&gt;std::array&lt;T, N&gt; array_name;\n\nT: 存储的元素类型 (例如 int, double, std::string)。\nN: 数组的大小，必须是一个编译时常量。\n\n主要特性\n空间固定且内存连续：一旦声明之后大小就不能改变。这与 std::vector 不同，后者是动态大小的。并且, std::array&lt;T, N&gt; 的内存布局与 T[N] 完全相同。它不包含任何额外的元数据，比如虚函数表指针、大小变量等。它在内存中就是一块连续的、大小为 N * sizeof(T) 的空间。\n\n栈上分配：和C风格数组一样，如果作为局部变量声明，它通常在栈上分配内存，速度非常快。\n\n完整的容器接口：它表现得像一个标准的STL容器，提供了许多方便的成员函数：\n\nat(pos): 访问指定位置的元素，会进行边界检查。如果越界，会抛出 std::out_of_range 异常。\n\noperator[]: 访问指定位置的元素，不进行边界检查（为了性能，与C风格数组行为一致）。\n\nfront() / back(): 访问第一个/最后一个元素。\n\nsize() / max_size(): 返回数组的大小。\n\nempty(): 检查数组是否为空 (对于 std::array 来说，如果 N &gt; 0 则永远不为空)。\n\nfill(value): 用一个指定的值填充整个数组。\n\nbegin() / end(): 提供迭代器支持，可以轻松与STL算法（如 std::sort）配合使用。\n\n\n\n\n底层实现std::array 的底层实现非常简单，它在内部只包含一个公开的、C风格的普通数组作为其唯一的非静态数据成员。标准库围绕这个内置数组提供了一系列成员函数（如 size(), at(), begin() 等），以赋予它现代容器的行为和安全性。\n这个设计的关键在于，所有这些“包装”工作都在编译时完成，几乎不会产生任何运行时的性能开销。\n以下是一个简化的示例：\n#include &lt;cstddef&gt; // for size_t#include &lt;stdexcept&gt; // for std::out_of_range#include &lt;algorithm&gt; // for std::filltemplate&lt;typename T, std::size_t N&gt;struct MyArray {    // 核心：内部就是一个公开的C风格数组    // 命名为 _data 以避免与用户代码冲突（标准库实现有自己的命名规则）    T _data[N];    // --- 成员函数实现 ---    // size()：返回大小。因为N是编译时常量，所以这个函数可以标记为 constexpr    constexpr std::size_t size() const noexcept {        return N;    }    // operator[]：直接访问内部数组，不进行边界检查    T&amp; operator[](std::size_t index) noexcept {        return _data[index];    }    const T&amp; operator[](std::size_t index) const noexcept {        return _data[index];    }    // at()：访问内部数组，但带有边界检查    T&amp; at(std::size_t index) {        if (index &gt;= N) {            throw std::out_of_range(\"MyArray::at() index out of range\");        }        return _data[index];    }    const T&amp; at(std::size_t index) const {        if (index &gt;= N) {            throw std::out_of_range(\"MyArray::at() index out of range\");        }        return _data[index];    }        // begin() 和 end()：返回指向内部数组的指针，实现迭代器支持    T* begin() noexcept {        return _data; // 或者 &amp;_data[0]    }    const T* begin() const noexcept {        return _data;    }        T* end() noexcept {        return _data + N; // 指向数组末尾的后一个位置    }    const T* end() const noexcept {        return _data + N;    }    // fill()：填充数组    void fill(const T&amp; value) {        std::fill(begin(), end(), value);    }};// ------------------- 使用示例 -------------------#include &lt;iostream&gt;int main() {    MyArray&lt;int, 5&gt; arr = {1, 2, 3, 4, 5};    std::cout &lt;&lt; \"Size: \" &lt;&lt; arr.size() &lt;&lt; std::endl;    arr[0] = 100;        for(int val : arr) { // 可以使用范围for循环，因为有 begin() 和 end()        std::cout &lt;&lt; val &lt;&lt; \" \";    }    std::cout &lt;&lt; std::endl;}\n\n聚合类型 (Aggregate Type) 与初始化std::array 被设计成一个聚合类型。在C++中，聚合类型大致是指没有用户定义的构造函数、没有私有或保护的非静态数据成员、没有基类、没有虚函数的类或结构体。\n因为 std::array 内部只有一个公开的C风格数组 T _data[N];，它符合聚合类型的定义。\n这使得我们可以使用大括号 {} 进行聚合初始化，就像初始化一个普通的C风格数组一样，非常直观。\nstd::array&lt;int, 3&gt; arr = {10, 20, 30}; // 直接初始化内部的C风格数组\n\n零成本抽象 (Zero-Cost Abstraction)这是 std::array 最重要的特性。这意味着你获得了更高的安全性（at()）、便利性（size()、迭代器）和类型安全，在开启编译器优化后，其性能与手写的C风格数组代码完全相同。\n如何实现？下面是几个关键点：\n\nsize(): size() 函数返回的是模板参数 N，它是一个编译时常量。编译器在编译时就可以直接将 arr.size() 替换为具体数字（例如 5）。这个函数调用在最终的机器码中不存在(也就是说根本不存在这样一个size变量或者函数调用)\n\noperator[], begin(), end(): 这些函数非常简单，通常只有一条返回语句。编译器可以轻易地进行内联 (inlining)，即把函数调用替换为函数体本身。最终生成的汇编代码与直接操作C风格数组的指针或索引完全一样(没有额外的函数调用开销)。\n\n范围for循环: for (auto&amp; element : arr)之所以能工作，是因为编译器会将其转换为基于迭代器的代码 for (auto it = arr.begin(); it != arr.end(); ++it)。由于 begin() 和 end() 会被内联，最终的循环代码与操作C风格数组的指针循环效率相同。\n\n\n类型系统与模板元编程td::array 的强大之处在于它将数组的大小 N 融入了类型系统。std::array&lt;int, 5&gt; 和 std::array&lt;int, 10&gt; 是完全不同的、不兼容的类型, 因为 N 是一个非类型模板参数 (non-type template parameter)。\n\n非类型模板参数是指模板参数不是一个类型，而是一个值（如整数、枚举值、指针等）。在 std::array 中，N 是一个 std::size_t 类型的非类型模板参数，表示数组的大小。\n\n这使得我们可以在编译时捕获许多错误。例如，试图将一个 std::array&lt;int, 5&gt; 赋值给 std::array&lt;int, 10&gt; 会导致编译错误，而不是运行时错误。\n同时, 还可以防止数组退化：当把 std::array 传递给函数时，传递的是一个完整的对象，函数签名中包含了确切的大小信息。编译器可以检查类型匹配，不会再出现数组退化为指针、丢失大小信息的问题。\n","categories":["language"],"tags":["language","cpp"]},{"title":"List","url":"/2025/09/28/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/List/","content":"std::list 是一个序列容器，它的底层实现是双向链表（Doubly-Linked List）。理解了“双向链表”这个数据结构，就理解了 std::list 的所有优缺点和行为特性。\nstd::list 的核心特性与 std::vector（动态数组）的连续内存布局截然不同，std::list 的元素在内存中是非连续存储的。每个元素（节点）都包含三部分信息：\n\n存储的数据本身。\n一个指向前一个元素节点的指针 (prev)。\n一个指向后一个元素节点的指针 (next)。\n\n这种结构赋予了 std::list 一系列独特的特性：\n\n快速的插入和删除: 这是 std::list 最主要的优点。在链表的任何位置（开头、中间、结尾）插入或删除一个元素，时间复杂度都是常数时间 O(1)（前提是你已经有了指向该位置的迭代器）。\n\n原因：插入/删除操作只需要修改相邻节点的 next 和 prev 指针，将新节点“链接”进去或将旧节点“断开链接”，而不需要像 std::vector 那样移动大量后续元素。\n\n\n慢速的随机访问: 这是 std::list 最主要的缺点。它不支持快速的随机访问。\n\n由于内存不连续，你无法像数组那样通过计算偏移量来直接定位到第 n 个元素。要访问第 n 个元素，必须从头节点（或尾节点）开始，沿着指针逐个遍历 n 次。因此，访问操作的时间复杂度是线性时间 O(n)。    \n正因如此，std::list 没有提供 operator[] 访问符。\n\n\n迭代器稳定性: 这是一个非常重要的优点。向 std::list 中插入或删除元素，不会导致指向其他元素的迭代器失效。\n\n插入或删除只影响被操作节点及其邻居的指针，其他节点在内存中的位置和它们之间的链接关系保持不变。而在 std::vector 中，一次插入或删除就可能导致所有或部分迭代器失效。\n\n\n更高的内存开销: 相比 std::vector，std::list 的每个元素都需要额外的空间来存储前向和后向指针，因此总的内存占用会更大。\n\n\n常用操作使用 std::list 需要包含头文件 。\n添加元素std::list 提供了在头部和尾部快速添加元素的方法。\n#include &lt;list&gt;#include &lt;iostream&gt;std::list&lt;int&gt; myList;// 在尾部添加元素myList.push_back(10); // {10}myList.push_back(20); // {10, 20}// 在头部添加元素 (vector 没有这个方法)myList.push_front(5); // {5, 10, 20}\n\n删除元素同样，std::list 也能在头部和尾部快速删除元素\nmyList.pop_back();  // 删除尾部元素 {5, 10}myList.pop_front(); // 删除头部元素 {10}\n\n遍历遍历 std::list 通常使用迭代器或范围 for 循环。\nstd::list&lt;int&gt; numbers = {1, 2, 3, 4, 5};for (int num : numbers) {    std::cout &lt;&lt; num &lt;&lt; \" \"; // 输出: 1 2 3 4 5}\n\n在中间插入和删除使用 insert() 和 erase() 方法，需要一个指向特定位置的迭代器。\nauto it = numbers.begin(); // it 指向 1++it; // it 指向 2// 在 it 指向的位置(2)之前插入 99numbers.insert(it, 99); // {1, 99, 2, 3, 4, 5}// 删除 it 指向的元素(2)// erase 会返回指向被删除元素下一个元素的迭代器it = numbers.erase(it); // {1, 99, 3, 4, 5}\n同样, erase()成功后迭代器会自动前进一位, 需要额外考虑\nstd::list 特有的高效操作std::list 提供了一些 std::vector 所没有的高效成员函数，这些函数充分利用了其链表结构的优势，通过直接操纵节点指针来完成，避免了元素的拷贝。\n\nsplice()：将一个 list 的全部或部分元素“剪切”并“粘贴”到另一个 list 中。这是一个 O(1) 的操作，非常高效。\nmerge()：将一个已排序的 list 合并到另一个已排序的 list 中，并保持排序。\nsort()：std::list 拥有自己的 sort() 成员函数。不能使用全局的 std::sort()，因为 std::sort 要求随机访问迭代器，而 list 的迭代器是双向的。\nreverse()：反转链表中元素的顺序。\nunique()：移除连续的重复元素。\n\n什么时候应该使用 std::list根据以上对比，我们可以得出结论, 你应该在以下情况考虑使用 std::list：\n\n需要频繁地在序列的任意位置（尤其是中间）进行插入和删除操作。\n对迭代器的稳定性有很高的要求，不希望因为插入/删除操作而需要频繁更新迭代器。\n不需要进行频繁的随机访问操作。\n\n现代 C++ 的观点和建议是, 尽管 std::list 在特定场景下有其理论上的优势，但在现代 C++ 编程中，std::vector 仍然是绝大多数场景下的首选默认容器。\n原因是现代计算机的 CPU 拥有多级缓存（Cache）。std::vector 的连续内存布局具有极佳的缓存友好性，CPU 可以预取数据，从而大大加快遍历速度。而 std::list 的节点分散在内存各处，遍历时会导致频繁的缓存未命中（Cache Miss），这带来的性能损失往往会抵消其 O(1) 插入/删除的理论优势。\n除非你的程序经过性能分析（Profiling），明确显示出瓶颈在于 std::vector 的中间插入/删除，否则请优先使用 std::vector。\n"},{"title":"哈希 Hash","url":"/2025/09/03/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C/","content":"哈希函数对象 (Hash Functor) – std::hashstd::hash 是 C++ 标准库中定义的一个类模板，位于  头文件中。它的主要作用是作为一个函数对象（Functor），为给定的数据类型计算一个唯一的、稳定的哈希值。\n从本质上讲，std::hash 是一个提供了标准哈希计算接口的工具或者说算法(算子)。\n// 主模板, 用于传入自定义类实现哈希函数template&lt;class Key&gt; struct hash;// 为int类型特化template&lt;&gt;struct hash&lt;int&gt; {    size_t operator()(int value) const noexcept {        // 对于整数，最简单的哈希就是其本身的值, 或者其他哈希算法。        return static_cast&lt;size_t&gt;(value);    }};// --- 为指针类型特化 ---template&lt;typename T&gt;struct hash&lt;T*&gt; {    size_t operator()(T* ptr) const noexcept {        // 指针的哈希值就是其内存地址的整数表示。        return reinterpret_cast&lt;size_t&gt;(ptr);    }};// --- 为字符串类型特化 ---template&lt;&gt;struct hash&lt;std::string&gt; {    size_t operator()(const std::string&amp; str) const noexcept {        // 使用一个简单且经典的 djb2 字符串哈希算法。        // 核心思想：遍历字符串，将每个字符融入一个不断变化的哈希值中。        size_t hash_value = 5381;        for (char c : str) {            // hash = (hash * 33) + character_value            hash_value = ((hash_value &lt;&lt; 5) + hash_value) + c;        }        return hash_value;    }};\n它的形式如上, 我们可以为不同的数据类型实例化它, 从而实现传入某个类型的数据, 返回计算得到的哈希值(size_t). 它也重载了 operator()并返回一个 size_t 类型的哈希值，使其可以像函数一样被调用。例如，std::hashstd::string()(“hello”) 会返回字符串 “hello” 的哈希值。\n\nstd::hashstd::string()(“hello”)是创建一个临时哈希对象并调用它的operator()函数, 等价于 auto hasher = std::hash&lt;std::string&gt;{}; size_t value = hasher(\"hello\");\n\n如何使用 std::hashstd::hash 的使用分为两种情况：对标准库内置支持的类型使用，以及对自定义类型使用。\n对内置支持的类型使用标准库已经为所有基本数据类型（如 int, char, float, double, bool）、指针、以及一些常用库类型（如 std::string, std::thread::id, std::shared_ptr 等）提供了 std::hash 的特化版本。因此可以直接使用它们，\n#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;functional&gt; // 包含 std::hashint main() {    std::string s = \"Hello, World!\";    int i = 12345;    double d = 3.14159;    // 创建不同类型的 hash 对象    std::hash&lt;std::string&gt; string_hasher;    std::hash&lt;int&gt; int_hasher;    std::hash&lt;double&gt; double_hasher;    // 调用 operator() 计算哈希值    size_t string_hash = string_hasher(s);    size_t int_hash = int_hasher(i);    size_t double_hash = double_hasher(d);    std::cout &lt;&lt; \"Hash of \\\"\" &lt;&lt; s &lt;&lt; \"\\\" is \" &lt;&lt; string_hash &lt;&lt; std::endl;    std::cout &lt;&lt; \"Hash of \" &lt;&lt; i &lt;&lt; \" is \" &lt;&lt; int_hash &lt;&lt; std::endl;    std::cout &lt;&lt; \"Hash of \" &lt;&lt; d &lt;&lt; \" is \" &lt;&lt; double_hash &lt;&lt; std::endl;    return 0;}\n\n对自定义类型使用如果你想将自定义的类或结构体作为 std::unordered_map 的键或者哈希算子的参数，编译器默认是不知道如何计算其哈希值的。这时，你需要为你的自定义类型 特化（Specialize） std::hash 模板。\n特化步骤主要是：\n\n定义你的自定义类型（例如 struct Student）。\n在 std 命名空间内，为你的类型提供一个 std::hash 的模板特化版本。\n在这个特化版本中，实现 operator()，它接受一个你的自定义类型的常量引用，并返回一个 size_t 类型的哈希值。\n在实现 operator() 时，你需要设计一种算法，将对象的各个成员的哈希值组合成一个总的哈希值。\n\n可以看出, 获得自定义对象的哈希值比较麻烦, 还需使用者来设计哈希算法.\n// 一个自定义类型，用于展示如何为其提供哈希支持struct Student {    int id;    std::string name;    // 注意: 哈希容器还需要 operator== 来处理哈希冲突, 因此在自定义类中也要实现    bool operator==(const Student&amp; other) const {        return id == other.id &amp;&amp; name == other.name;    }};namespace std{    template&lt;&gt;    struct hash&lt;Student&gt; {        size_t operator()(const Student&amp; s) const noexcept {            // 核心思想：分别计算每个成员的哈希值，然后将它们组合起来。                        // 计算 id 的哈希值 (复用了上面的 hash&lt;int&gt;)            size_t id_hash = SimpleHash::hash&lt;int&gt;{}(s.id);                        // 计算 name 的哈希值 (复用了上面的 hash&lt;std::string&gt;)            size_t name_hash = SimpleHash::hash&lt;std::string&gt;{}(s.name);            // 通过位运算将两个哈希值组合成一个，这是常用技巧。            return id_hash ^ (name_hash &lt;&lt; 1);        }    };}\n\n哈希表（Hash Table） 容器对于哈希, 我们在平时使用更多的反而是根据哈希函数对象创建的哈希表容器. 这些容器包括：\n\nstd::unordered_map\nstd::unordered_set\nstd::unordered_multimap\nstd::unordered_multiset\n\n主要使用的是前两者.\nunordered_setstd::unordered_set 是一个基于哈希表实现的用于存储唯一元素的关联容器。它的主要设计目标是提供平均时间复杂度为 O(1) 的元素查找、插入和删除操作。\n可以把它想象成一个数学上的集合：一个无序的、包含唯一元素的集合, 具有下列特性:\n\n底层数据结构：与 unordered_map 一样，是哈希表。\n元素：只包含一个元素, 即键 Key。所有元素都是唯一的，不允许重复。\n顺序：元素在容器中是无序的，迭代遍历时的顺序不固定。\n时间复杂度：\n平均情况：查找、插入、删除都是 O(1)。\n最坏情况：当发生严重的哈希冲突时，退化为 O(N)，其中 N 是容器中的元素数量。\n\n\n对存储元素即键的要求：作为键的类型必须是可哈希的 (Hashable) 和可判等的 (Equality Comparable)。即，必须支持 std::hash 和 operator==。\n\n一般来说, 无序集这个数据结构适用于快速且频繁地判断元素是否存在, 这是其最核心的用途。例如，在处理一个巨大的单词列表时，快速判断一个新单词是否已经出现过。\n也可以用于去除重复元素：将一个包含重复元素的列表（如 std::vector）转换为 std::unordered_set，可以快速得到一个不含重复元素的集合。\n\n\n\n函数/操作\n功能描述\n常用场景\n\n\n\n构造函数\nunordered_set&lt;T&gt; s(v.begin(), v.end());\n一键去重：用一个容器（如 vector）的迭代器范围来构造集合，瞬间完成去重。\n\n\ninsert(key)\n插入一个元素。返回 pair&lt;iterator, bool&gt;，其中 bool 值表示是否插入成功（若元素已存在则失败）。\n判断新元素：利用返回的 bool 值，可以边插入边判断当前元素是否是第一次出现。\n\n\nfind(key)\n查找元素。如果找到，返回指向该元素的迭代器；否则，返回 s.end()。\n判断存在性（经典）：if (s.find(key) != s.end()) { … } 是最经典的判断方式。\n\n\ncontains(key) (C++20)\n直接判断元素是否存在，返回 bool 值。\n判断存在性（现代）：代码更简洁易读。if (s.contains(key)) { … }。\n\n\ncount(key)\n返回等于 key 的元素个数。因为元素唯一，所以结果只能是 0 或 1。\n判断存在性（另一种方式）：if (s.count(key)) { … } 效果等同于 contains，但 contains 的语义更清晰。\n\n\nerase(key)\n删除指定值的元素, 注意是所有匹配的元素。\n从集合中移除一个元素，例如在滑动窗口等算法中。\n\n\nsize()\n返回集合中元素的数量。\n获取不同元素的总个数。\n\n\nempty()\n判断集合是否为空。\n用于循环的终止条件或边界情况判断。\n\n\nunordered_map","categories":["language"],"tags":["language","cpp"]},{"title":"排序算法","url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"C++ STL (Standard Template Library) 提供了非常强大、通用且高效的排序算法。这些算法都在  头文件中。它们的核心优势在于：\n\n通用性：通过迭代器 (Iterators) 对任何标准容器（如 std::vector, std::deque, std::list 等）甚至普通 C++ 数组进行操作。\n高效性：底层实现经过高度优化，通常采用多种排序算法结合的策略（如内省排序）。\n灵活性：支持使用自定义的比较函数，可以对任意复杂的数据结构进行排序。\n\nstd::sort：最常用的排序算法这是最常使用的排序算法\n\n特点：速度极快，但不保证稳定性。\n底层实现：通常是内省排序 (Introsort)，一种混合排序算法。它首先使用快速排序，当递归深度过深时转为堆排序以防止最坏情况，最后对小分区使用插入排序进行优化。\n时间复杂度：平均为 O(NlogN)。\n\n它的函数签名如下:\ntemplate&lt; class RandomIt &gt;void sort( RandomIt first, RandomIt last );  // RandomIt 必须是随机访问迭代器, 参数是迭代器的范围 [first, last)template&lt; class RandomIt, class Compare &gt;void sort( RandomIt first, RandomIt last, Compare comp );  // 使用自定义比较函数 comp, 可以是函数指针或函数对象","categories":["language"],"tags":["language","cpp"]},{"title":"栈和队列","url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/","content":"“栈和队列是以底层容器完成其所有的工作，对外提供统一的接口，底层容器是可插拔的”\n这句话描述的是一种经典的设计模式————适配器模式 (Adapter Pattern)。在 C++ 标准库中，std::stack 和 std::queue 正是这种模式的绝佳范例，它们并不是底层容器, 而被称为“容器适配器 (Container Adapters)”。\n适配器模式 (Adapter Pattern)\n适配器模式是一种结构型设计模式，它允许将一个类的接口转换成客户端所期望的另一个接口。通过这种方式，原本由于接口不兼容而无法一起工作的类可以协同工作。\n\n回到标题, std::stack 和 std::queue 类本身并不真正存储数据。它们内部包含了一个底层容器的对象（比如一个 std::deque 对象），并将所有的数据操作委托（Delegate）给这个内部对象来完成。\n\n当你对一个 std::stack 执行 push() 操作时，std::stack 内部实际上调用的是其底层容器的 push_back() 方法。\n当你执行 pop() 操作时，它内部调用的是底层容器的 pop_back() 方法。\n当你执行 top() 操作时，它内部调用的是底层容器的 back() 方法来获取最后一个元素的引用。\n\n因此, stack 类的实现就像一个“中间人”或“代理”: \n// 概念伪代码template&lt;class T, class Container&gt;class stack {protected:    Container c; // 内部包含一个底层容器对象 c, 可以是 std::vector, std::deque 等public:    void push(const T&amp; val) {        c.push_back(val); // 将 push 操作委托给底层容器的 push_back    }    void pop() {        c.pop_back(); // 将 pop 操作委托给底层容器的 pop_back    }    T&amp; top() {        return c.back(); // 将 top 操作委托给底层容器的 back    }    // ... 其他接口如 empty(), size() 也都委托给 c};\n\n当然, 底层容器（如 std::vector）的功能非常强大，它提供了在任意位置插入 (insert())、删除 (erase())、随机访问 (operator[]) 等多种操作。但是，一个“栈”的逻辑是严格的后进先出 (Last-In, First-Out, LIFO)。你不应该能在栈的中间插入或删除元素。\n因此，std::stack 适配器屏蔽了底层容器的大部分接口，只暴露出符合栈逻辑的几个关键接口(限制和简化接口):\n\npush(): 在栈顶添加元素。\npop(): 从栈顶移除元素。\ntop(): 查看栈顶元素。\nempty(): 判断栈是否为空。\nsize(): 获取栈中元素的数量。\n\n通过这种方式，std::stack 强制保证了其 LIFO 的行为特性，使得代码更安全、逻辑更清晰。你无法意外地对一个栈执行不符合其数据结构逻辑的操作。std::queue（先进先出, First-In, First-Out, FIFO）也是同理。\n与此同时, 底层容器是可插拔的. 这体现了设计的灵活性和复用性。C++ 通过模板 (Templates) 机制实现了这一点。std::stack 和 std::queue 的定义如下：\ntemplate&lt;    class T,    class Container = std::deque&lt;T&gt;&gt; class stack;template&lt;    class T,    class Container = std::deque&lt;T&gt;&gt; class queue;\n可以看出, T是存储元素的类型; Container是选择的底层容器类型。它有一个默认值 std::deque, 我们可以显式指定为 std::vector 或 std::list。\n#include &lt;stack&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;deque&gt; // 默认使用它std::stack&lt;int&gt; s1; // 底层是 std::deque&lt;int&gt;// 显式指定 std::vector&lt;int&gt; 作为底层容器std::stack&lt;int, std::vector&lt;int&gt;&gt; s2;// 显式指定 std::list&lt;int&gt; 作为底层容器std::stack&lt;int, std::list&lt;int&gt;&gt; s3;\n\n\n不是任何容器都可以作为 stack 的底层容器。它必须满足一定的接口要求，比如必须提供 back(), push_back(), pop_back() 这几个函数。\n\n栈 (Stack)栈是一种严格遵循“后进先出”（Last-In, First-Out）原则的数据结构。\n头文件: 要使用 std::stack，你需要包含以下头文件:\n#include &lt;stack&gt;\n\n定义和初始化: std::stack 是一个模板类，你需要指定存储的元素类型。你也可以选择性地指定底层容器。\n#include &lt;iostream&gt;#include &lt;stack&gt;#include &lt;vector&gt;#include &lt;list&gt;#include&lt;string&gt;// 1. 使用默认的底层容器 std::dequestd::stack&lt;int&gt; s1;// 2. 显式指定 std::vector 作为底层容器std::stack&lt;std::string, std::vector&lt;std::string&gt;&gt; s2;// 3. 显式指定 std::list 作为底层容器std::stack&lt;double, std::list&lt;double&gt;&gt; s3;\n\n核心成员函数: std::stack 的接口非常简洁，主要包含以下几个核心操作：\n\npush(const T&amp; value): 将元素压入栈顶。\npop(): 移除栈顶元素。注意：这个函数没有返回值，它只负责移除。\ntop(): 返回对栈顶元素的引用。你可以通过它读取或修改栈顶元素。\n如果栈为空，调用 top() 会导致未定义行为 (Undefined Behavior)。\n\n\nempty(): 检查栈是否为空。如果为空，返回 true；否则返回 false。\nsize(): 返回栈中元素的数量。\n\n#include &lt;iostream&gt;#include &lt;stack&gt;int main() {    // 创建一个存储 int 类型的栈，底层使用默认的 std::deque    std::stack&lt;int&gt; my_stack;    // --- 压入元素 ---    std::cout &lt;&lt; \"Pushing 10, 20, 30 onto the stack...\" &lt;&lt; std::endl;    my_stack.push(10); // 栈: [10]    my_stack.push(20); // 栈: [10, 20]    my_stack.push(30); // 栈: [10, 20, 30] &lt;- 30 是栈顶    // --- 访问和检查 ---    std::cout &lt;&lt; \"Stack size is: \" &lt;&lt; my_stack.size() &lt;&lt; std::endl; // 输出: 3    if (!my_stack.empty()) {        std::cout &lt;&lt; \"Top element is: \" &lt;&lt; my_stack.top() &lt;&lt; std::endl; // 输出: 30    }    // --- 弹出元素 ---    std::cout &lt;&lt; \"\\nPopping elements from the stack:\" &lt;&lt; std::endl;    while (!my_stack.empty()) {        // 步骤1：访问栈顶元素        int top_element = my_stack.top();        std::cout &lt;&lt; \"Popping: \" &lt;&lt; top_element &lt;&lt; std::endl;                // 步骤2：移除栈顶元素        my_stack.pop();    }    // 循环结束后，栈为空    // --- 检查栈是否为空 ---    if (my_stack.empty()) {        std::cout &lt;&lt; \"\\nThe stack is now empty.\" &lt;&lt; std::endl;    }    return 0;}\n\n队列 (Queue)std::queue 是 C++ 标准模板库（STL）中的一个容器适配器（Container Adapter）。它提供了一种先进先出（First-In, First-Out, FIFO）的数据结构。默认情况下，std::queue 使用 std::deque（双端队列）作为其底层容器。\nstd::queue 的接口非常简洁，主要包含以下几个核心操作：\npush(const T&amp; value): 在队列的尾部添加一个元素。这被称为“入队”（enqueue）。\npop(): 移除队列头部的元素。这被称为“出队”（dequeue）。\n\n此函数不返回任何值 (void)。如果想获取头部元素的值，必须在调用 pop() 之前先调用 front()。\n\nfront(): 返回对队列头部的第一个元素的引用。你可以通过它读取或修改头部元素，但不会将其从队列中移除。\nback(): 返回对队列尾部的最后一个元素的引用。\nempty(): 检查队列是否为空。如果队列中没有任何元素，返回 true；否则返回 false。\nsize(): 返回队列中元素的数量。\n","categories":["language"],"tags":["language","cpp"]},{"title":"可迭代对象和迭代器","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1/","content":"可迭代对象 (Iterable) 是指那些能够逐一返回其内部成员的对象(返回迭代器)。换句话说，任何你可以用 for 循环进行遍历的对象，都是可迭代对象。\n常见的可迭代对象常见的可迭代对象包括：\n\n序列 (Sequence)：如列表 (list)、元组 (tuple)、字符串 (str)。\n集合 (Set)：如 set、frozenset。\n映射 (Mapping)：如字典 (dict)。\n文件对象。\n通过 yield 关键字创建的生成器 (Generator)。\n\n# 列表是可迭代的my_list = [1, 2, 3]for item in my_list:    print(item)# 字符串是可迭代的my_string = \"hello\"for char in my_string:    print(char)# 字典是可迭代的（默认遍历键）my_dict = {'a': 1, 'b': 2}for key in my_dict:    print(key)# 如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。for value in my_dict.values():    print(value)for k, v in my_dict.items():    print(k, v)\n\n如何判断一个对象是可迭代对象你可以使用 collections.abc.Iterable 和isinstance来检查一个对象是否是可迭代的：\nfrom collections.abc import Iterableprint(isinstance([1, 2, 3], Iterable))  # True，列表是可迭代的print(isinstance(\"hello\", Iterable))    # True，字符串是可迭代的print(isinstance(42, Iterable))         # False，整数不是可迭代的\n\n迭代器协议 (Iterator Protocol)一个对象之所以“可迭代”，是因为它遵守了 Python 的迭代器协议。这个协议规定了对象如何支持迭代。我们可以从两个角度来理解这个协议：\n\n可迭代对象 (Iterable)\n\n定义：一个对象如果实现了 iter() 方法，那么它就是可迭代对象。\n作用：iter() 方法的职责是返回一个迭代器 (Iterator) 对象。\nList、Tuple、String、Dict、Set 等内置类型都实现了 iter() 方法，因此它们都是可迭代对象。\n\n\n迭代器 (Iterator)\n\n定义：一个对象如果同时实现了 iter() 和 next() 方法，那么它就是迭代器。\niter() 的作用：对于迭代器本身，其 iter() 方法通常只是返回它自己 (self)。\nnext() 的作用：这是迭代器的核心。每次调用该方法时，它会返回序列中的下一个元素。当所有元素都返回完毕后，再次调用 next() 会抛出 StopIteration 异常，以告知外部调用者迭代已经结束。\nGenerator 对象就是一种特殊的迭代器，它们是通过生成器函数创建的。\n\n\n\n需要注意的是, List、Tuple、String、Dict、Set等内置类型不是迭代器，因为它们没有实现 next() 方法, 也就意味着他们不能通过next()逐个访问下一元素(因为他们本身就是有限的集合, 没有必要逐个生成逐个next()访问).\n可以使用isinstance()判断一个对象是否是Iterator对象：\n&gt;&gt;&gt; from collections.abc import Iterator&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True&gt;&gt;&gt; isinstance([], Iterator)False&gt;&gt;&gt; isinstance({}, Iterator)False&gt;&gt;&gt; isinstance('abc', Iterator)False\n\nfor 循环的幕后工作原理当我们使用 for 循环时，Python 解释器在背后实际上执行了以下步骤：\n\n获取迭代器：调用可迭代对象的 iter() 方法来获取一个迭代器。\n\n循环取值：在一个循环中，不断地调用迭代器的 next() 方法来获取下一个元素。\n\n处理异常：当 next() 方法抛出 StopIteration 异常时，for 循环会捕获这个异常并优雅地结束循环。\n\n\nmy_list = [10, 20, 30]# 1. 获取迭代器#    这相当于调用了 my_list.__iter__()my_iterator = iter(my_list)# 2. 循环取值和处理异常while True:    try:        # 相当于调用了 my_iterator.__next__()        item = next(my_iterator)        print(item)    except StopIteration:        # 3. 迭代结束，跳出循环        break","categories":["python"],"tags":["language","python"]},{"title":"介质访问控制(Media Access Control, MAC)","url":"/2025/09/26/web/Computer%20Network/%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/5.%20%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/","content":"我们之前讨论的可靠传输、流量控制等，大多是针对点对点 (Point-to-Point) 链路的，即链路上只有两个节点。但在很多网络中，多个节点需要共享同一条通信信道，这种信道被称为广播信道 (Broadcast Channel)。\n例如早期的总线型以太网（所有计算机共享一根同轴电缆），现在的无线局域网 Wi-Fi（所有设备共享同一频段的空口）。\n在广播信道上，如果两个或两个以上的节点同时发送数据，它们的信号就会在信道中混合、相互干扰，导致所有数据都变得无法识别，这种现象称为冲突 (Collision)。\n介质访问控制 (MAC) 的任务就是制定一套规则，来协调各个节点对共享介质的访问，决定“下一个谁可以发送数据”，从而尽可能地避免或解决冲突问题。MAC协议通常被认为是数据链路层的一个子层（MAC子层）。\nMAC协议主要分为三大类：信道划分、随机访问和轮询访问。其中前者是静态分配，后两者是动态分配。\n信道划分介质访问控制 (Channel Partitioning)这类协议的核心思想是“资源预留”。它将共享的信道资源（如时间、频率）从物理上分割成多个互不干扰的子信道，然后为每个节点分配一个专用的子信道。\n优点：一旦分配，节点就可以在自己的子信道上自由通信，绝不会发生冲突。网络负载高时，性能稳定且有保障。\n缺点：效率低下，资源浪费。如果一个节点被分配了子信道，但它大部分时间都没有数据要发送，那么这个子信道的容量就被白白浪费了。这对于流量具有突发性的计算机网络来说，尤其不划算。\n其主要是通过复用技术来实现的，所谓复用，就是将多个信号合并在一起传输，然后在接收端再将它们分离开来。\n\n频分多路复用 (FDMA - Frequency Division Multiple Access)核心思想是按频率划分信道。类似于不同的广播电台使用不同的频率播出节目，互不干扰。\n\n如图所示，频分多路复用将总带宽划分为多个频段 (Channel)，每个节点被分配到一个独立的频段进行通信。同一时刻不同节点使用不同的频段，因此不会发生冲突。\n时分多路复用 (TDMA - Time Division Multiple Access)时分多路复用按时间划分信道。将时间划分为一个个时隙，每个节点被分配到固定的时隙才能发送数据，这样的时隙称作 TDM 帧。如图，每个用户在自己的时隙内发送数据，不同用户的时隙互不重叠，因此不会发生冲突。\n\n波分多路复用 (WDM - Wavelength Division Multiplexing)波分多路复用实际上就是光纤网络中的频分复用，按光的波长来划分信道。\n码分多路复用 (CDMA - Code Division Multiple Access)码分多路复用按码片序列划分信道。每个节点被分配一个唯一且相互正交的码片序列 (Chipping Sequence)，用来对数据进行编码。\n所有节点可以在同一时间、同一频率发送数据，但由于使用了不同的码片序列，因此不会发生冲突。接收方利用相同的码片序列，可以从混合的信号中分离出自己想要的数据。\n\nCDMA 的技术基石是正交性 (Orthogonality)：  \n\n任何码片序列  与其自身的规格化内积结果为 ；  \n两个不同用户的码片序列  和 ，其规格化内积结果为 ；  \n任何码片序列  与其反码的规格化内积结果为 。\n\n\n例如，A 节点被分配了码片序列 ，这里的  和  分别表示二进制的  和 。\n这意味着，A 节点如果发送比特  就是发送该用户原始的码片序列 ；发送比特  就是发送该用户码片序列的反码（所有  变 ， 变 ）。\nB 节点也要传输信息，分配码片 （此码片与  正交）。\n假设 A 发送比特 ，B 发送比特 ，则它们同时在信道中发送的信号为：，接收端 C 节点接收到了这个混合信号 。\nC 节点现在可以利用码片序列从混合信号中分离出它想听的信号：\n解码 A 站的信号：C 站用 A 站的码片  与混合信号进行内积运算。\n解码结果：\n根据规则：，而 。\n解码结果：\n结论：结果为正，代表站点 A 发送了比特 。\n解码 B 站的信号：C 站用 B 站的码片  与同一个混合信号进行内积运算。\n解码结果：\n根据规则：，而 。\n解码结果：\n结论：结果为负，代表站点 B 发送了比特 。\n\n如果结果为零，说明该站点没有发送任何数据。\n\n这种技术实际上就是扩频通信 (Spread Spectrum Communication) 的基础。它通过将原始信号扩展到一个更宽的频带上进行传输，从而提高抗干扰能力和安全性。\n甚至即使码片序列中的少数几位因为干扰而出错，经过整个序列的“民主投票”（内积运算），最终的结果仍然能非常可靠地判断出原始比特是1还是0\n随机访问介质访问控制 (Random Access)这类协议的核心思想是“先到先得”。节点在任何时候，只要有数据要发送，就可以立即尝试在信道上发送数据。如果发生冲突，节点会通过某种机制来检测到冲突，并在稍后重新尝试发送, 因此, 协议的核心是如何处理不可避免的冲突 (Collision) 问题。\nALOHA 协议ALOHA 协议是最早的随机访问协议，思想极其简单，也因此效率很低。它是后续更复杂协议的思想源头。\n纯 ALOHA (Pure ALOHA): “想发就发，完全随性”, 任何节点只要有数据要发送，就可以立即发送。\n发送后，节点会监听信道，等待一个确认 (ACK)。如果在规定时间内没有收到ACK，就认为发生了冲突。发生冲突后，节点会等待一个随机的时间，然后重新发送。\n假设发送一帧需要时间 。如果 A 站在  时刻开始发送，那么任何其他站只要在区间  内开始发送数据，都会与 A 站发生冲突。也就是说，冲突窗口的长度为 ，范围非常大，因此纯 ALOHA 的信道利用率较低。\n分隙 ALOHA (Slotted ALOHA): “统一行动，只在整点发”, 将时间划分为一个个等长的时隙 (Slot)，每个时隙的长度刚好够发送一帧。\n节点不再是随时可以发送，而是必须等到下一个时隙的开始时刻才能发送。如果多个节点在同一个时隙内发送，仍然会发生冲突。\n此时冲突只可能发生在多个节点选择同一个时隙发送的情况下。冲突窗口从  缩小到 ，信道利用率有所提升。\nCSMA 协议 (载波侦听多路访问)CSMA 协议是对ALOHA协议的重大改进，引入了载波侦听 (Carrier Sense) 的机制。核心思想: “先听再说 (Listen Before Talk)”. \n一个节点在发送数据之前，会先侦听信道，检查信道是否空闲。如果信道空闲，则发送数据; 如果信道正忙，节点会等待，直到信道变为空闲。\n尽管这样, 冲突仍然可能发生, 因为信号在信道上传播需要时间（传播时延 ）。可能A站在侦听到信道空闲后立即发送，但其信号还没传播到B站，此时B站也可能侦听到信道空闲并开始发送，从而导致冲突。\n根据“监听到信道忙后怎么办”，CSMA又分为三种：\n\n1-坚持 CSMA: 监听到信道忙，就持续监听，一旦空闲立即发送。缺点是如果多个节点都在等待，信道一空闲它们会同时发送，导致冲突概率大。\n\n非坚持 CSMA: 监听到信道忙，就放弃监听，等待一个随机时间后再回来重新尝试。缺点是可能导致信道空闲了也没人立即使用，利用率降低。\n\np-坚持 CSMA: 只适用于时分复用信道. 监听到信道空闲，以概率 p 发送，以概率 1−p 推迟到下一个时隙。这是前两者的折中。若监听到信道忙，则持续监听(监听到下一个信道)。\n\n\nCSMA/CD 协议 (载波侦听多路访问/冲突检测)CSMA/CD 协议是在 CSMA 的基础上，增加了冲突检测 (Collision Detection) 的机制。核心思想: “边说边听，冲突即停 (Talk and Listen Simultaneously, Stop on Collision)”. 这是有线以太网 (Ethernet) 采用的经典协议.\n它继承了CSMA的“先听再说”。最重要的改进是，节点在发送数据的同时，会持续不断地监听信道。如果在发送过程中，节点监听到信道上的信号与自己发送的信号不一致，就说明发生了冲突。\n当冲突发生时, 立即停止发送数据(等待一段时间后重新发送), 并发送一个简短的冲突增强信号 (Jam Signal)，以确保网络上所有节点都知道发生了冲突，并丢弃已收到的不完整数据。接着执行二进制指数退避算法 (Binary Exponential Backoff)：\n\n定义 k 为当前帧的重传次数。第一次冲突后，准备进行第1次重传，此时 k=1。如果再次冲突，准备进行第2次重传，此时 k=2，以此类推。\n在进行第 k 次重传时，从整数集合 [0, 1, …, 2^k - 1] 中随机选择一个数，记为 r。同时, 为了防止等待时间的上限变得过长，算法对 k 的值进行了限制, 一般 k=min(重传次数,10)。这意味着当重传次数小于等于10时，k 就等于重传次数; 当重传次数超过10次后，k 的值不再增长，始终保持为10。因此，随机数的最大选择范围就是 [0, 1023]。\n等待 r 个争用期 (Contention Period) 后，重新尝试发送数据。(也就是说所有的退避等待时间都是争用期的整数倍)。\n如果重传次数超过了一个预设的最大值 (通常是16次)，就放弃发送该帧，并向上层报告一个错误。\n\n优点: 能在冲突发生的第一时间就检测到并停止发送，极大地减少了因冲突而浪费的信道时间和带宽。同时确保冲突的站点在不同的时间点重新尝试发送,避免再次冲突。\n争用期 (Contention Period)CSMA/CD协议中的冲突检测不是瞬时的。根本原因在于电磁波的传播速率是有限的。\n\n上图展示了两个节点发送信息时出现冲突的情况:\n\nt = 0: 站点A（最左端）侦听信道空闲，开始发送数据。\nt = τ - δ: A的信号即将到达最右端的站点B。就在这一瞬间，B也侦听到信道空闲并决定发送数据。（τ 是信号从A到B的单程最大传播时延，δ 是一个极小的时间）。这是可能发生冲突的最晚时刻。\nt = τ - δ/2: 冲突发生, B发出的信号与A发出的信号在B站附近立刻相撞。\nt = τ: A的信号传播了整整一个 τ 的时间，终于到达了B, 同一时刻, B检测到了冲突，并立即停止发送。\nt = 2τ - δ: 冲突的信号从B站附近一路传回，最终在 t = 2τ - δ (2倍的冲突发生时间)时刻到达A站。此时，A站才终于检测到自己之前发送的数据发生了冲突。\n\n因此, 取极限δ-&gt;0, 从A开始发送，到A能确信自己的发送是否成功（即是否检测到冲突），最多需要经过两倍的端到端传播时延 (2τ)。而争用期 (Contention Period)，也称为冲突窗口或碰撞窗口，就是指这个最长时间 2τ。\n它的物理意义是：在以太网中，一个站点发送数据后，最多经过时间 2τ，就可以确定自己是否成功“占领”了信道。\n如果在争用期（2τ）内没有检测到冲突，那么之后就绝不可能再发生冲突了（因为此时第一个比特已经传播到了网络中的所有角落，所有其他站点都已经能侦听到信道为“忙碌”状态）。\n例如, 在10Mb/s的以太网标准中，经过精确计算和一定的工程冗余，这个争用期被规定为 51.2μs\n最短帧长 (Minimum Frame Length)现在，一个关键问题出现了：站点A必须确保在 t = 2τ 这个最晚的冲突信号返回之前，自己仍然在发送数据。否则，如果它已经发送完毕并“认为”传输成功，它就永远不会知道其实自己的帧已经在半路被毁了(认为传输成功后就不再监听信号)。\n这就引出了一个必须满足的不等式：帧的发送时延 () ≥ 争用期 (2τ)\n我们将这个不等式展开：\n最短帧长数据传输速率即, 最短帧长≥争用期×数据传输速率\n根据上述公式, 计算以太网规定最短帧长得到了64字节 (512 bits):\n这个长度确保了即使发生最极端的“末端碰撞”，发送方也能在发送完成前及时检测到冲突，从而执行退避算法进行重传。\n同时, 任何小于64字节的帧都被认为是无效帧，也称为“冲突碎片” (Runt Frame)。网络设备（如交换机、网卡）收到这种帧会直接将其丢弃，因为它们知道这必然是冲突后异常中止发送的残留物。\n\n如果上层（如IP层）交下来的数据包本身很小，不足以构成一个64字节的帧（例如，只有一个ACK确认信息），那么数据链路层必须在数据字段后面填充一些额外的字节，以凑够64字节的最小长度，然后才能发送。\n\nCSMA/CA 协议 (载波侦听多路访问/冲突避免)CSMA/CA 协议是在 CSMA 的基础上，增加了冲突避免 (Collision Avoidance) 的机制。核心思想: “先听再说，冲突前预防 (Listen Before Talk, Prevent Collision)”. 这是无线局域网 (Wi-Fi) 采用的经典协议.\n\n无法实现冲突检测主要是因为无线信号的传播特性。无线信号在空气中传播时，信号强度会随着距离的增加而迅速衰减, 同时无线设备通常功率较低。因此, 无线设备在发送数据时难以监听到信道上的其他信号, 也就无法检测到冲突。当然, 还有下面要介绍的隐藏站问题。\n\n这套机制主要由以下几个部分组成：\n核心策略一：确认与重传 (ARQ)\n由于无线信道的通信质量远不如有线信道，数据帧更容易丢失或损坏。为了保证可靠传输，802.11标准规定，所有单播的数据帧都必须得到接收方的确认 (ACK)。\n\n802.11标准，也就是我们常说的 Wi-Fi 协议族，是由 IEEE（电气电子工程师学会）在 1997 年制定的无线局域网通信协议标准\n\n因此发送方每发送一个数据帧，就会启动一个计时器并等待接收方回复ACK帧。如果在规定时间内收到了ACK，说明传输成功。如果超时仍未收到ACK，发送方就认为该帧已丢失或损坏（即发生了冲突），并会立即进行重传。这是一种停止-等待式的可靠传输机制。\n核心策略二：帧间间隔 (IFS) - 协调信道访问优先级\n为了避免多个站点在信道刚一空闲时就“蜂拥而上”导致冲突，CSMA/CA规定，所有站点在发送前都必须先侦听信道。当侦听到信道从忙碌变为空闲后，不能立即发送，而是必须再等待一段被称为帧间间隔 (InterFrame Space, IFS) 的时间。\nIFS的长短决定了访问的优先级。等待时间越短，优先级越高。主要有三种IFS：\n\nSIFS (短帧间间隔 - Short IFS): 时间最短，优先级最高。用于处理需要立即响应的、最高优先级的操作，例如发送 ACK 确认帧, 回复 CTS (清除发送) 帧, 响应接入点(AP)的轮询等。这保证了像ACK这样的重要控制帧不会因为要和其他数据帧竞争而被延迟。\nPIFS (点协调功能帧间间隔 - PCF IFS): 时间中等，优先级较高。在PCF（点协调功能，一种集中控制模式）下，供AP（无线路由器）优先抢占信道使用。\nDIFS (分布式协调功能帧间间隔 - DCF IFS): 时间最长，优先级最低。这是最常用的一种间隔。任何一个站点如果想要发送一个新的数据帧或管理帧，当它检测到信道空闲后，必须至少等待一个DIFS的时长\n\n核心策略三：退避倒计时\n这是CSMA/CA避免冲突的精髓所在。当一个站点有数据要发送，并且已经等待了一个DIFS后，它并不能立刻发送，而是要进入一个随机退避阶段(除非是第一个发送帧且信道空闲)。\n启动时机：\n\n在发送一个新的数据帧之前（在DIFS后）检测到信道忙。\n在每一次重传之前。\n在每一次成功发送后，准备发送下一个新帧之前。\n\n退避时间计算：\n类似CSMA/CD协议, 但不同的是, 站点在进行第 k 次重传时，从整数集合 [0, 1, …, 2^{k+2} - 1] 的范围内随机选择一个数，作为自己的退避计时器的值, 这样做扩大了随机选择的范围, 从而进一步降低冲突概率。不过, k的最大值被限制在了6, 因此最大范围是 [0, 255]。\n退避倒计时过程：\n\n站点选择了随机的退避值后，开始倒计时。\n倒计时器只在信道保持空闲时才会递减。\n如果在倒计时过程中，信道被其他站点占用变为忙碌，则计时器暂停, 直到信道再次变为空闲，并经过一个DIFS后，计时器才继续从暂停处开始倒数。\n当且仅当计时器倒数到0时，站点才能真正发送它的数据帧。\n\n这个“暂停-继续”的机制极大地降低了冲突概率。即使多个站点在同一个DIFS后启动了退避，它们大概率会选择不同的随机值，因此倒计时到0的时刻也不同，从而实现了“错峰出行”。\n总之, CSMA/CA 算法的过程如下：1）若站点最初有数据要发送（而非发送不成功后再进行重传），且检测到信道空闲，那么在等待时间 DIFS 后，就发送整个数据帧。2）否则，站点执行 CSMA/CA 退避算法。选取一个随机退避时间。一旦检测到信道空闲，退避计时器就保持不变。只要信道空闲，退避计时器就继续倒计时。3）退避计时器减为 0 后（即等待时间已被足够的时间），站点就发送整个数据帧。4）若接收方正确接收到该数据帧（即帧的校验和正确），则发送一个确认帧 ACK。否则，发送方在超时时间后重传该数据帧。5）若发送方没有接收到 ACK，就认为该数据帧丢失，进入重传过程。重传过程包括退避算法（即 CSMA/CA 退避算法）。重传过程重复一定次数。若连续多次发送失败，则 CSMA 协议中断该数据帧的发送，改经过上层协议的其他方式来发送。\n隐藏站问题 (Hidden Terminal Problem)隐藏站问题描述的是这样一种情况: 三个站点分布为A–B–C, 显然A和C都能和B通信，但A和C距离较远, 之间互相听不到。如果A和C在某时刻检测到信道空闲而同时向B发送数据，就会在B处发生冲突, 这里假如A是发送站, B是接收站, 那C对于A来说就是隐藏站. \n为了解决“隐藏站”问题，802.11标准提出了信道预约机制和虚拟载波监听机制。\n发送方在发送数据前(已经监听信道空闲并等待了DIFS)，先向目的站发送一个 RTS (请求发送 - Request to Send) 帧，告诉接收方自己有数据要发送，并请求许可。接收方收到RTS后，如果信道空闲且准备好接收，在等待SIFS后就广播回复一个 CTS (清除发送 - Clear to Send) 帧，表示允许发送。\nCTS帧中包含了一个持续时间字段，指示发送方和其他所有听到CTS的站点，自己将占用信道多长时间。这样, 其他站点(包括隐藏站)在听到CTS后, 都会知道信道即将被占用, 并且知道要等待多长时间才可以再次尝试发送, 从而避免了冲突。\nA站在收到CTS后, 等待SIFS后就发送数据帧。B站在正确接收到数据帧后, 也等待SIFS后发送ACK确认帧, 从而成功完成了一次可靠的数据传输。\n而在RTS和CTS帧中(甚至传输的数据帧也可以携带), 都附带了本次通信所要占据信道的时间, 所谓虚拟载波监听指的就是其他节点虽然不一定是这些帧的目的站, 但是可以监听并解析这些帧(MAC帧头中的 Duration 字段)，这些帧中包含了本次通信预计要持续的时间。节点于是根据这个时间设置一个“网络分配向量(NAV)”，在NAV计时器归零前，即使物理信道空闲，节点也会认为信道是“虚拟”忙碌的，从而保持静默。\n轮询访问 (Polling Access)轮询访问是一种受控的访问方式，其核心思想可以概括为**“依次点名，授权发言”**。\n在这种机制下，网络中的节点不能随心所欲地发送数据。它们必须等待“授权”。这个授权的过程，就是由一个主节点或一种特殊规则，按照一定的顺序（通常是循环的）去“轮询”或“询问”每一个节点是否需要发送数据。\n这种方式完全避免了随机访问中可能发生的冲突，因为在任何时刻，只有一个节点被授权使用信道。它比信道划分更灵活，因为信道是按需分配，而不是永久预留。\n轮询可以由一个中心站来完成。但更常见的一种分布式是令牌传递协议，它通过传递“令牌”这个“发言权”信令，来模拟一个去中心化的轮询过程, 基本步骤如下:\n\n步骤 A - 等待令牌: 一个节点（例如A）如果有数据要发送，它必须进入监听状态，等待从其上游节点传来的令牌。\n步骤 B - 捕获令牌与发送数据: 当A接收到“空闲”令牌后，它会：\n将令牌的状态从“空闲”改为“忙碌”。\n将自己的数据帧附加在“忙碌”令牌之后，发送到环路中。\n\n\n步骤 C - 沿环传递与接收: 载有数据的帧沿着环路向下游传递。环路上的每个节点都会接收并检查该帧的目的地址。\n如果不是发给自己的，就简单地将该帧转发给下游节点。\n如果目的地址是自己（例如节点C），C就会复制一份数据帧的内容。\n\n\n步骤 D - 释放令牌: 数据帧会继续传递，直到它绕环一周后，返回到最初的发送方A。\nA接收到自己发出的帧后，确认它已被成功环回（可以检查帧中的状态位了解接收情况）。\nA将该数据帧从环路中移除, 并重新生成一个新的“空闲”令牌，并将其发送给自己的下游节点。\n\n\n\n\n如果一个节点收到“空闲”令牌，但它自己没有数据要发送，它会立即将这个“空闲”令牌转发给下游节点。\n\n","categories":["web"],"tags":["web","computer network"]},{"title":"OOP","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/OOP/","content":"类和实例基础Python 允许在运行时动态地为某个实例添加、修改或删除属性。\nclass Dog:    def __init__(self, name):        self.name = namedog1 = Dog(\"Buddy\")print(dog1.name)  # 输出: Buddy# 动态添加属性dog1.age = 3print(dog1.age)   # 输出: 3# 动态修改属性dog1.name = \"Max\"print(dog1.name)  # 输出: Max# 动态删除属性del dog1.ageprint(hasattr(dog1, 'age'))  # 输出: False\n\n在Python中，实例的变量名如果以**__开头**，就变成了一个私有变量（private），只有内部可以访问，外部不能访问\nclass Cat:    def __init__(self, name):        self.__name = name  # 私有变量    def get_name(self):        return self.__name  # 通过方法访问私有变量cat1 = Cat(\"Whiskers\")print(cat1.get_name())  # 输出: Whiskersprint(cat1.__name)  # 报错: AttributeError: 'Cat' object has no attribute '__name'\n\n注意：Python 并没有真正的私有变量机制，这只是通过名称重整（name mangling）来实现的。实际上，私有变量可以通过 _ClassName__varname 的方式访问，但这不推荐这样做，因为它违反了封装的原则。例如上面的例子中，其实可以通过 cat1._Cat__name 来访问私有变量 __name。\n\n实例属性和类属性正如我们前面所说, 由于Python是动态语言，根据类创建的实例可以任意绑定属性。给实例绑定属性的方法是通过实例变量动态绑定，或者通过self变量(在__init__函数中)：\nclass Dog:    def __init__(self, name, age):        self.name = name  # 实例属性        self.age = age    # 实例属性dog1 = Dog(\"Buddy\", 3)dog1.breed = \"Golden Retriever\"  # 动态绑定属性\n\n在Python中，实例属性是属于某个具体实例的属性，而类属性是属于类本身的属性，所有实例共享同一个类属性。\nclass Dog:    species = \"Canis familiaris\"  # 类属性    def __init__(self, name, age):        self.name = name  # 实例属性        self.age = age    # 实例属性dog1 = Dog(\"Buddy\", 3)dog2 = Dog(\"Max\", 5)print(dog1.name)  # 输出: Buddyprint(dog2.name)  # 输出: Maxprint(dog1.species)  # 输出: Canis familiarisprint(dog2.species)  # 输出: Canis familiarisprint(Dog.species)   # 输出: Canis familiaris\n\n如果你在实例中创建了和类属性同名的属性，那么实例属性会覆盖类属性. 因此, 在编写程序的时候，千万不要对实例属性和类属性使用相同的名字.\ndog1.species = \"Canis lupus\"print(dog1.species)  # 输出: Canis lupusprint(dog2.species)  # 输出: Canis familiaris\n\n获取对象信息Python 提供了内置函数 type() 来获取对象的类型，isinstance() 来检查对象是否是某个类的实例(其实也是检查类型)，dir() 来列出对象的所有属性和方法。\nclass Animal:    def speak(self):        return \"Animal sound\"class Dog(Animal):    def speak(self):        return \"Woof!\"dog1 = Dog()print(type(dog1))  # 输出: &lt;class '__main__.Dog'&gt;print(isinstance(dog1, Dog))  # 输出: Trueprint(isinstance(dog1, Animal))  # 输出: Trueprint(dir(dog1))  # 输出: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'speak']\n注意这里的 dir() 函数返回的是一个列表，包含了对象的所有属性和方法，包括内置的和自定义的, 其中 __ 开头和结尾的方法是 Python 的魔法方法，用于实现特定的行为, 而没有 __ 的是普通方法, 例如speak() 方法。\n比如__len__方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法，所以，下面的代码是等价的：\nclass MyList:    def __init__(self, items):        self.items = items    def __len__(self):        return len(self.items)my_list = MyList([1, 2, 3, 4, 5])print(len(my_list))  # 输出: 5print(my_list.__len__())  # 输出: 5\n仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态：\n\ngetattr(obj, 'attr')：获取对象 obj 的属性 attr 的值。\nsetattr(obj, 'attr', value)：设置对象 obj 的属性 attr 的值为 value。\nhasattr(obj, 'attr')：检查对象 obj 是否有属性 attr，返回布尔值。\n\nclass Person:    def __init__(self, name):        self.name = nameperson1 = Person(\"Alice\")print(getattr(person1, 'name'))  # 输出: Alicesetattr(person1, 'age', 30)print(getattr(person1, 'age'))  # 输出: 30print(hasattr(person1, 'name'))  # 输出: Trueprint(hasattr(person1, 'address'))  # 输出: False\n\n鸭子类型在Python中，鸭子类型（Duck Typing）是一种动态类型系统的概念，它强调的是**对象的行为（方法和属性）**而不是对象的实际类型。\n换句话说，如果一个对象看起来像鸭子、叫起来像鸭子，那么它就可以被当作鸭子来对待。也就是说，只要一个对象实现了某个方法或属性，就可以被视为具有该行为，而不需要显式地继承某个类或实现某个接口。\nclass Duck:    def quack(self):        return \"Quack!\"class Dog:    def quack(self):        return \"Woof!\"def make_it_quack(animal):    print(animal.quack())duck = Duck()dog = Dog()make_it_quack(duck)  # 输出: Quack!make_it_quack(dog)   # 输出: Woof!\n这里的 make_it_quack 函数接受任何对象，只要该对象有 quack 方法，就可以调用它，而不关心该对象的实际类型, 这就是鸭子类型的体现。\n多继承和MixIn与C++一样，Python也支持多继承，但它通过一种非常明确且可预测的方式——MRO（方法解析顺序）——解决了多继承中的二义性问题，尤其是菱形继承问题。\nPython的多继承在Python中，一个类可以同时从多个父类继承，从而获得所有父类的属性和方法。\nclass Bird:    def fly(self):        print(\"I am flying!\")class Mammal:    def walk(self):        print(\"I am walking!\")# Bat 同时继承 Bird 和 Mammalclass Bat(Bird, Mammal):    pass# 创建实例b = Bat()b.fly()  # 输出: I am flying! (继承自 Bird)b.walk() # 输出: I am walking! (继承自 Mammal)\n\n而当遇到菱形继承时，Python并不会像C++那样需要开发者使用virtual关键字来解决。相反，Python使用 C3线性化算法 来计算出一个确定的方法解析顺序（Method Resolution Order, MRO）。\nMRO是一个列表，它定义了当调用一个方法时，Python解释器查找该方法的顺序。你可以通过类的 mro 属性或 mro() 方法来查看它。\nclass A:    def who_am_i(self):        print(\"I am an A\")class B(A):    def who_am_i(self):        print(\"I am a B\")class C(A):    def who_am_i(self):        print(\"I am a C\")class D(B, C):    passd = D()d.who_am_i() # 输出会是什么？\n在这个例子中，D的对象调用 who_am_i() 时，Python会遵循MRO来查找。我们可以打印出D类的MRO来理解其查找顺序。\nprint(D.mro())# 或者 print(D.__mro__)# 输出: [&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;]\n这里MRO列表的顺序是 [D, B, C, A, object]。当调用 d.who_am_i() 时，Python首先在 D 类中查找。D 中没有定义，于是继续。接着在 B 类中查找。B 中定义了该方法，于是调用 B.who_am_i()。因此，最终输出是 I am a B。查找在找到第一个匹配项后就停止了，不会再继续查找 C 或 A。\nMRO保证了无论继承结构多复杂，方法的查找路径都是唯一且确定的，从而优雅地解决了二义性问题。\nMixIn 设计模式虽然多继承很强大，但如果滥用，会使类的层次结构变得混乱且难以维护。为了以一种更可控、更清晰的方式利用多继承，Python社区广泛采用 MixIn 设计模式。\nMixIn (或 Mix-in) 是一个类，它包含了一组特定的、可重用的功能，旨在通过多继承的方式“混入”到其他类中，为这些类添加某些功能，而不是为了建立 “is-a” (是一个) 的父子关系。我们可以把MixIn看作是一个功能插件。\nMixIn类通常有以下特点：\n\n功能单一、职责明确：一个MixIn类通常只提供一种特定的功能，例如日志记录、序列化、对象表示等。\n不用于实例化：MixIn类通常不应该被直接实例化。它存在的意义就是被其他类继承。\n通常无 init 构造函数：为了避免与主类的构造函数发生冲突，MixIn通常不定义自己的__init__方法。如果需要初始化，也应确保它能与super()链良好协作。\n命名约定：为了清晰起见，MixIn类的命名通常以后缀 Mixin 结尾，例如 LoggingMixin、JSONMixin。\n\n假设我们有几个不同的类，我们都希望它们能方便地将自身属性转换为字典或JSON格式。我们可以为此创建一个 SerializationMixin。\nimport json# 1. 定义一个 MixIn 类class SerializationMixin:    \"\"\"一个将对象属性序列化为字典和JSON的MixIn。\"\"\"    def to_dict(self):        # vars(self) 返回对象 __dict__ 属性，即其所有实例变量        return vars(self)    def to_json(self):        return json.dumps(self.to_dict(), indent=2)# 2. 定义一些业务类class Book:    def __init__(self, title, author):        self.title = title        self.author = authorclass Course:    def __init__(self, name, teacher, duration):        self.name = name        self.teacher = teacher        self.duration = duration# 3. 将 MixIn “混入”到业务类中class SerializableBook(SerializationMixin, Book):    passclass SerializableCourse(SerializationMixin, Course):    pass# 4. 使用“混入”的功能book = SerializableBook(\"The Lord of the Rings\", \"J.R.R. Tolkien\")course = SerializableCourse(\"Computer Networking\", \"Dr. Smith\", \"16 weeks\")print(\"--- Book Object ---\")print(book.to_dict())print(book.to_json())print(\"\\n--- Course Object ---\")print(course.to_dict())print(course.to_json())\n\n这里 SerializationMixin 提供了 to_dict() 和 to_json() 两个方法。它本身不关心操作的是什么对象，只负责通用的序列化逻辑。\nSerializableBook 通过继承 SerializationMixin 和 Book，既拥有了Book的属性和逻辑，又“免费获得”了序列化的能力。\n\n注意继承顺序很重要：我们将 SerializationMixin 放在前面。根据MRO，如果Book中也有一个to_dict方法，那么SerializationMixin中的版本会优先被调用。\n\n","categories":["python"],"tags":["language","python"]},{"url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/Set/","content":""},{"url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/Map/","content":""},{"title":"物理层","url":"/2025/09/25/web/Computer%20Network/%E7%89%A9%E7%90%86%E5%B1%82/3.%20%E7%89%A9%E7%90%86%E5%B1%82/","content":"通信基础要理解物理层的工作原理，我们首先需要掌握一些通信领域的基础理论。\n基本概念数据：是我们想要传送的信息，是信息的载体。可以是数字的（如文本文件）或模拟的（如语音）。\n信号：是数据在物理介质上的电气或电磁表现形式。信号是传输数据的方式。\n\n数字信号 (Digital Signal)：信号的状态是离散、不连续的，例如只有高、低两种电平。\n模拟信号 (Analog Signal)：信号的幅值是连续变化的，例如正弦波。\n\n信道 (Channel): 信道是信号传输的物理路径。它可以是有形的（如双绞线、光纤）或无形的（如无线电波传播的空间）。\n速率相关的概念: \n\n码元 (Symbol)：在数字通信中，一个固定时长的、具有明确定义的波形（如某个电压、频率或相位）被称为一个码元。码元是承载信息的基本信号单位。\n\n波特率 (Baud Rate)：也称为码元速率，指每秒钟传输的码元个数。单位是波特（Baud）。它描述的是信号变化的速率。\n\n比特率 (Bit Rate)：也称为信息速率，指每秒钟传输的二进制比特（bit）数。单位是比特/秒（bit/s 或 bps）。它描述的是信息传输的速率。\n\n\n需要注意, 一个码元可以携带多个比特的信息。如果一个码元有 V 种不同的状态（例如，4种不同的电压等级），那么每个码元就可以表示  个比特。\n从通信双方的信息交互方式来看, 可以有三种模式:\n\n单工 (Simplex): 通信是单向的，信息只能从发送方传输到接收方，接收方不能向发送方反馈信息。例如，电视广播就是单工通信。\n半双工 (Half-Duplex): 通信是双向的，但在同一时间内只能有一方发送信息，另一方必须等待。例如，对讲机就是半双工通信。\n全双工 (Full-Duplex): 通信是双向的，双方可以同时发送和接收信息。例如，电话就是全双工通信。\n\n信道的极限容量任何信道能够传输数据的速率都不是无限的，它受到物理规律的限制。有两个重要的理论描述了信道的极限容量。\n奈奎斯特定理 (Nyquist’s Theorem)奈氏准则研究的是一个理想的、无噪声的、带宽有限的信道\n在信道中，发送过快的信号码元（代表数据的基本信号单元）会在时间上“展宽”，导致前后码元的波形发生重叠，相互“模糊”，使得接收端无法清晰地分辨出每一个码元。这种现象就是码间串扰。\n奈氏准则的首要目标，就是确定为了避免码间串扰，码元发送速率的上限是多少\n极限码元传输速率:对于一个带宽为 W (单位为Hz) 的信道，其极限码元传输速率为 2W 波特 (Baud)。\n码元速率上限\n极限比特传输速率:\n数据传输速率不仅取决于每秒能发多少个码元，还取决于每个码元能携带多少比特的信息。\n如果一个码元有  种不同的离散状态（例如 4 种不同的电压等级），那么每个码元就可以表示  个比特。\n因此，理想信道的极限数据传输速率（比特率）  为：\n单位：\n\n带宽是瓶颈：信道的带宽 W 直接限制了码元的发送速度。\n提升速率靠编码: 在带宽 W 固定的情况下，要想提高数据传输速率 C，唯一的办法就是让每个码元携带更多的比特，即增加 V 的值。这需要更复杂的调制解调技术。\n过于理想化: 奈氏准则是在一个没有噪声的完美世界里得出的。它告诉我们，只要技术足够好，理论上可以通过无限增加 V 来无限提升数据速率。但这在现实中是不可能的，因为噪声的存在会限制我们分辨不同码元状态的能力。\n\n香农定理 (Shannon’s Theorem)香农定理则将随机噪声这个现实因素考虑进来，给出了一个有噪声、带宽有限的信道的绝对极限数据传输速率。\n这里有一个信噪比的概念：信噪比 (S/N - Signal-to-Noise Ratio) 是衡量信号与噪声相对强弱的关键指标。S/N 越高，信号越清晰，信道质量越好。\n香农定理指出，对于一个带宽为 W，信噪比为 S/N 的信道，其极限数据传输速率C为：\n单位：\n注意：公式中的  是信号功率与噪声功率的比值，是一个无单位的数值。\n在实际应用中，信噪比常以分贝 (dB) 为单位，换算关系为：\n\n\n进行香农公式计算时，必须将 dB 单位的信噪比换算回无单位的  值。例如，信噪比为 30dB，意味着 ，解得 。\n\n\n速率存在硬上限: 香农定理给出的 C 是一个理论上的极限值。无论采用多么先进的技术（无论奈氏准则中的 V 取多大），只要数据传输速率超过这个 C 值，就不可能实现无差错的传输。\n\n提升速率靠“开源节流”: 要想提高极限数据速率 C，只有两种途径：\n\n增加带宽 W (“开源”)。\n提高信噪比 S/N (“节流”，即增大信号功率或降低噪声干扰)。\n\n\n理论上的可能性: 香农定理也给出了一个积极的结论：只要信息传输速率低于信道极限 C，就一定存在某种先进的编码和调制技术，能够实现无差错的传输。\n\n\n两者的比较奈奎斯特定理和香农定理分别从不同的角度描述了信道的极限容量。前者假设无噪声，强调码元速率和编码复杂度；后者考虑噪声，强调带宽和信噪比。\n在实际应用中, 我们需要综合考虑这两个方面, 假如按照已知条件计算发现奈奎斯特定理的极限比特率低于香农定理的极限比特率, 那么奈奎斯特定理的结果才是实际可达到的上限, 反之亦然(因为他们本身描述的极限条件不同)。\n编码与调制编码和调制是将原始的数字数据（比特流）转换为适合在信道中传输的信号的过程。\n编码 (Encoding)：数字数据 -&gt; 数字信号\n目的：主要用于基带传输，即信号的频谱从零频附近开始。例如，以太网内部的传输。编码的主要目标是解决时钟同步、直流分量等问题。\n常见编码方式：\n不归零编码 (NRZ)：用高电平表示1，低电平表示0。实现简单，但如果出现连续的1或0，会导致接收方时钟漂移，难以同步。\n曼彻斯特编码 (Manchester Encoding)：将每个比特周期分为两半，从高到低跳变表示1，从低到高跳变表示0（反之亦可）。这种编码自带时钟信号，解决了同步问题，但它需要的带宽是NRZ的两倍。\n差分曼彻斯特编码：位中间的跳变只用于同步，而位开始处的跳变与否用于表示0或1。\n调制 (Modulation)：数字数据 -&gt; 模拟信号\n目的：主要用于通带传输(Carrier)，即信号需要被搬移到较高的频率范围进行传输。例如，Wi-Fi、无线电广播和电话线上的调制解调器（Modem）。\n\n而基带传输则是直接在低频段（从0Hz开始）传输数字信号。\n\n基本调制技术：通过修改载波信号的属性来表示数字数据。\n\n幅移键控 (ASK - Amplitude Shift Keying)：用载波的不同振幅来表示0和1。\n频移键控 (FSK - Frequency Shift Keying)：用载波的不同频率来表示0和1。\n相移键控 (PSK - Phase Shift Keying)：用载波的不同相位来表示0和1。\n\n混合调制技术：主要是正交幅度调制QAM\n正交幅度调制 (QAM - Quadrature Amplitude Modulation)：这是一种更高级的调制技术，它同时结合了幅移键控 (ASK) 和 相移键控 (PSK)。通过组合多个振幅和多个相位，可以使一个码元代表更多的比特（即增大奈奎斯特定理中的 V 值），从而在有限的带宽内实现极高的数据传输速率。例如，16-QAM 使用16种不同的组合状态，每个码元可以传输  个比特。\n此时, 该 QAM 的数据传输速率 R 为 R = W log₂(mn) (单位为 b/s)，其中 W 是带宽，m 是振幅状态数，n 是相位状态数, mn 就是总的状态数(QAM-X中的X)。\n传输介质传输介质，也称为传输媒体或信道，是网络中发送方和接收方之间的物理路径。它决定了网络通信的带宽、距离、成本和可靠性。传输介质可以分为两大类：导向型传输介质和非导向型传输介质。\n导向型与非导向型传输介质在导向型传输介质中，电磁波被限制并沿着一个固态的物理媒介（如金属线或玻璃纤维）传播。\n双绞线 (Twisted Pair): 由两根相互绝缘的铜导线，按一定规则绞合而成。将导线绞合是其最重要的特性。这样做的目的是为了尽可能减少来自外界的电磁干扰（EMI）以及相邻线对之间的串扰（Crosstalk）。两根导线中的电流方向相反，它们产生的磁场可以相互抵消，从而增强了信号的抗干扰能力。\n\n非屏蔽双绞线 (UTP - Unshielded Twisted Pair)：无金属屏蔽层，是目前局域网（LAN）中最常见的传输介质\n屏蔽双绞线 (STP - Shielded Twisted Pair)：在线对外部包裹有金属屏蔽层，抗干扰能力更强，但成本更高，安装也更复杂。\n\n同轴电缆 (Coaxial Cable): 由内到外依次是：中心铜质导体、塑料绝缘层、网状编织的金属屏蔽层和外部保护胶皮曾广泛用于有线电视（CATV）和早期的以太网（如10BASE-5），但现在在局域网中已基本被双绞线取代。\n光纤 (Optical Fiber): 由一个非常细的玻璃或塑料纤芯 (Core) 和一层折射率较低的玻璃包层 (Cladding) 组成。它传输的不是电信号，而是光脉冲。光信号在纤芯中以全内反射 (Total Internal Reflection) 的方式向前传播。\n\n多模光纤 (Multi-mode Fiber)：纤芯较粗，允许多束不同角度的光线同时传播。成本较低，适用于短距离通信（如建筑物内部）。\n单模光纤 (Single-mode Fiber)：纤芯极细，只允许一束光线沿直线传播。成本高，但衰减小、带宽高，适用于长距离、大容量的通信（如跨洋海底光缆）。\n\n非导向型传输介质就是我们常说的无线传输，它不限制电磁波的传播方向，信号在自由空间中传播。\n无线电波 (Radio Waves)：具有很强的穿透能力，可向所有方向传播。适用于移动通信、调频广播、Wi-Fi和蓝牙等。\n微波 (Microwaves)：沿直线传播，频率比无线电波高。主要用于地面点对点通信（如手机基站之间）和卫星通信。\n红外线 (Infrared)：沿直线传播，不能穿透墙壁。常用于短距离通信，如电视遥控器\n物理层接口的特性物理层的主要功能之一就是定义了设备与传输介质之间的接口标准。这些标准通常由以下四个特性来规定:\n\n机械特性 (Mechanical Characteristics): 指明接口的物理属性，如连接器的形状、尺寸、引脚数量和排列方式等。\n\n例如我们日常使用的USB接口和RJ45网线接口的物理形状和尺寸都是标准化的，确保不同厂商的设备可以物理连接。\n\n电气特性 (Electrical Characteristics): 规定了在线路上传输的信号的电气参数，如电压的范围、阻抗匹配、传输速率和距离限制等。\n\n例如规定用-5V到+5V的电压表示比特“1”，用0V表示比特“0”。同时规定了驱动器和接收器的电气参数。\n\n功能特性 (Functional Characteristics): 指明接口的各个引脚（或线路）的功能和用途。\n\n示例：在一个串行通信接口中，会明确规定哪个引脚是用于发送数据（TxD），哪个引脚是用于接收数据（RxD），哪个是地线（GND）等。\n\n过程特性(Procedural Characteristics): 也称为规程特性，它规定了利用接口线路实现比特流传输的一系列操作事件的顺序。\n\n示例：规定了设备间建立连接的“握手”过程。例如，A设备要向B设备发送数据，A首先要激活“请求发送”（RTS）引脚，等待B激活“清除发送”（CTS）引脚作为响应后，A才能开始发送数据。\n物理层设备物理层设备，也称为Layer 1设备，是网络中最简单的连接设备。它们的共同特点是，它们在OSI模型的第一层（物理层）上工作，只处理电信号（比特流），而不识别更高层次的数据结构，如MAC地址（数据链路层）或IP地址（网络层）。\n这些设备的主要作用是信号的再生和分发，以克服物理介质在传输过程中的信号衰减和距离限制。\n中继器 (Repeater)中继器是一种连接两个相同网络段的设备，通常只有两个端口。\n其核心功能是信号再生 (Signal Regeneration): 当电信号在电缆中长距离传输时，会发生衰减（信号变弱）和失真。中继器接收到这种衰弱的信号后，并不是简单地将其放大（Amplification）。简单的放大器会同时放大信号和累积的噪声。相反，中继器会解析出原始的比特流（0和1），然后生成一个全新的、标准的、无失真的强信号再发送出去。这个“再生”过程是其关键所在。\n主要用途：延长网络的物理距离。例如，以太网标准规定双绞线的最大传输距离为100米。如果需要连接两个相距150米的设备，就可以在中间放置一个中继器来延长通信距离。\n局限性:\n\n无法连接不同类型的网络：它只能连接物理层协议和速率都相同的网络段，例如连接两个以太网段。\n扩大冲突域：中继器会将其连接的所有网段合并成一个更大的冲突域 (Collision Domain)。这意味着，如果任何一端的设备发送数据时发生碰撞，这个碰撞信号会被中继器转发，从而影响到另一端的网络。\n\n\n冲突域是指在同一时间内，只允许一台设备发送数据的网络范围\n\n集线器 (Hub)集线器本质上是一个多端口的中继器 (Multi-port Repeater)。它是一个中心连接设备，用于将多个计算机或其他网络设备连接在一起，形成一个星型拓扑结构。\n当集线器从其任何一个端口接收到数据信号时，它会对信号进行再生，然后将该信号广播到所有其他端口。这意味着连接到集线器的所有设备都会收到这份数据，无论这份数据是不是发给它的。接收到的设备需要在其网络接口卡（网卡）层面判断这份数据是否是自己的，如果不是则丢弃。集线器本身完全不关心数据的目的地。\n核心特点与缺点：\n\n单一冲突域 (Single Collision Domain)：这是集线器最主要的特征。所有连接到集线器的设备都处于同一个冲突域中。如果两台设备同时发送数据，就会发生碰撞，并且这个碰撞会影响到网络中的所有设备，导致通信失败和重传。\n共享带宽 (Shared Bandwidth)：集线器上所有端口共享总带宽。例如，一个100Mbps的8口集线器，如果8台设备都在通信，那么它们必须共享这100Mbps的带宽，每台设备实际可用的带宽会远低于100Mbps。\n半双工 (Half-duplex)模式：由于工作在单一冲突域中，设备不能同时发送和接收数据，只能进行半双工通信。\n\n因此, 由于上述严重的性能瓶颈，集线器目前已基本被淘汰，在现代网络中几乎看不到。它的位置已经被数据链路层的交换机 (Switch) 所取代。\n","categories":["web"],"tags":["web","computer network"]},{"title":"数据链路层","url":"/2025/09/16/web/Computer%20Network/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/4.%20%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/","content":"数据链路层的主要功能是让帧在物理介质上可靠地传输。它位于物理层之上，网络层之下，负责将网络层传下来的数据包封装成帧，并处理帧的传输、差错检测和流量控制等问题。\n它使用的通信信道主要有两种:\n\n点对点信道 (Point-to-Point Channel)：通信双方通过专用的物理链路直接连接，数据在两点之间一对一传输。例如，串行通信、PPP协议等。\n广播信道 (Broadcast Channel)：多个设备共享同一物理链路，数据可以被所有连接到该链路的设备接收。例如，以太网(采用CSMA/CD协议)、Wi-Fi(采用CSMA/CA协议)等。\n\n数据链路层的主要功能数据链路层所处的地位数据链路层位于OSI模型的第二层，介于物理层和网络层之间。\n对下：它接收物理层提供的原始比特流服务，并需要处理这些比特流中可能出现的传输错误。\n对上：它向网络层提供服务，其主要作用是将源自网络层的数据包（Packet）可靠地传输到相邻节点的目标网络层。它对网络层隐藏了物理传输中的各种复杂细节和错误。\n链路管理 (Link Management)指的是在两个节点之间建立、维持和释放数据链路的过程。这主要用于点对点的连接。\n\n链路建立：通信双方通过“握手”确认彼此的状态，准备好进行数据传输。\n数据传输：在已建立的链路上交换数据。\n链路释放：通信结束后，有序地断开连接，释放资源。\n\n在像以太网这样的广播网络中，链路管理通常是自动且隐含的，但在广域网协议中，这是一个非常明确的步骤。\n封装成帧与透明传输物理层传输的是一长串没有明显边界的比特流。为了让接收方能够区分数据的起点和终点，数据链路层必须将网络层传下来的数据包添加首部（Header）和尾部（Trailer），将它们封装成一个独立的、可识别的数据单元，这个单元就是帧 (Frame)。\n接收方可以通过帧的头部和尾部来准确地确定一帧的开始和结束, 帧头通常包含源和目标的物理地址（MAC地址）等控制信息；帧尾通常包含用于差错校验的字段。\n而现在还有一个问题: 如果在帧的数据部分（即网络层的数据包）中，恰好出现了与帧尾定界符完全相同的比特组合，接收方就会错误地认为帧已经结束，导致数据解析错误。\n透明传输指的是，无论上层交付什么样的数据，数据链路层都有办法将其封装并成功传输，即使数据中包含了与控制信息（如帧定界符）相同的比特模式。\n上述问题的解决方法是, 通过字符填充 (Character Stuffing) 或 比特填充 (Bit Stuffing) 技术来实现。\n例如, 以比特填充为例, 假设使用 01111110 作为帧的起始和结束标志。\n发送方：在发送数据时，会扫描整个数据部分。一旦发现有连续的5个“1”，就立即在其后填充一个“0”。\n接收方：在接收数据时，同样扫描数据。一旦发现连续的5个“1”，就检查其后的比特。\n\n如果第6个比特是“0”，就将其删除，恢复原始数据。\n如果第6个比特是“1”（即组成了01111110），则判断这是一个帧定界符。\n\n\n通过这种方式，确保了数据内部永远不会出现与帧定界符相同的模式，实现了透明传输。\n流量控制 (Flow Control)指的是协调发送方和接收方的速率，防止发送速率过快而导致接收方来不及处理，造成数据丢失。\n流量控制是一种点对点的控制，确保发送方只在接收方确认有能力接收时才发送数据。\n\n拥塞控制: 关注的是整个网络宏观上的负载，防止网络因数据过多而瘫痪，这通常是传输层（如TCP）的职责。\n\n常见的方法有：停止-等待协议、滑动窗口协议（如后退N帧协议、选择重传协议）\n差错检测 (Error Detection)物理链路并非绝对可靠，信号在传输过程中可能会因为噪声等因素产生差错（比特翻转，即0变1或1变0）。差错检测就是让接收方有能力发现收到的数据帧是否在传输中出现了错误。\n核心思想是：在发送数据时，根据原始数据计算出一个校验码 (Check Code)，并将其附加在帧的尾部一起发送。接收方收到后，用同样的方法对数据部分进行计算，比较计算结果和收到的校验码是否一致。\n目前使用最广泛的差错检测方法是循环冗余校验 (CRC, Cyclic Redundancy Check)。\n组帧(Framing)组帧是数据链路层的基本任务之一。其核心目标是在一连串的比特流中，准确地标识出“帧”的开始和结束，以便接收方能够完整地提取出每一个数据单元。这个过程也称为帧同步。以下是四种经典的组帧方法。\n字符计数法 (Character Count)这是一种概念上最简单的方法。它在帧的头部设置一个计数字段，用以标明该帧总共包含的字符（或字节）数。\n\n发送方：在帧首部的计数字段填入该帧的长度（例如，长度为5）。\n接收方：首先读取计数字段的值（读到5），然后向后数出对应数量（5个）的字符，这就构成了一个完整的帧。读取完毕后，它就知道下一字节将是下一个新帧的计数字段。\n\n| 5 | A | B | C | D | E | 7 | F | G | H | I | J | K |  ↑ 计数字段               ↑ 计数字段\n致命缺点：可靠性极差。如果在传输过程中，计数字段的某一位发生了错误（例如，5（二进制00000101）因为噪声变成了7（00000111）），接收方就会错误地读取7个字符。这将导致接收方对后续所有帧的边界判断都发生错误，造成灾难性的失步，且难以恢复。因此，这种方法如今已基本不被使用。\n字节填充法 (Byte Stuffing)使用特定的字符（字节）作为帧的起始和结束定界符，通常称为标志字节 (Flag Byte)。例如，在PPP协议中，标志字节是 01111110（十六进制为 0x7E）。\n这种方法容易出现的是透明传输问题：如果帧的数据部分恰好也出现了与标志字节相同的内容，就会造成混淆。解决方法同样是填充：\n\n发送方：在发送前扫描整个数据部分。\n如果数据中出现标志字节 (0x7E)，就在其前面插入一个转义字节 (0x7D)。\n如果数据中出现转义字节 (0x7D)，同样在其前面再插入一个转义字节。\n接收方：在接收时进行反向操作。当读到转义字节时，就删除这个转义字节，并将其后面的字节当作普通数据接收（无论它是什么）。当读到非转义字节的标志字节时，就认为是帧的边界。\n\n示例：原始数据: A | 0x7D | 0x7E | B\n填充后发送: FLAG | A | 0x7D | 0x7D | 0x7D | 0x7E | B | FLAG\n优点：比字符计数法可靠得多，解决了透明传输问题。\n缺点：依赖于以8位字节为单位的数据，不适用于非字符编码的数据流。\n零比特填充法 (Zero-Bit Stuffing)这是目前应用最广泛的组帧方法，它同样使用一个特定的比特模式作为帧定界符，即标志字段 01111110。只不过透明传输解决方法有所不同：\n\n发送方：在硬件层面扫描整个数据比特流（除标志字段外）。只要发现连续的5个“1”，就立即在后面强制插入一个“0”。\n接收方：同样在硬件层面扫描。只要发现连续的5个“1”，就检查其后的第6个比特。\n如果第6个比特是“0”，则说明这是一个填充位，必须将其删除以还原原始数据。\n如果第6个比特是“1”，则说明这是一个标志字段（结合其后的“0”，构成了 …1111110），表示帧的边界。\n\n\n\n示例：\n\n原始数据: …01111110…\n填充后发送: …011111010…\n\n优点：\n高效：由硬件执行，速度非常快。\n通用：完全不依赖于数据是否为8位字节的整数倍，可以处理任意长度的比特流。\n应用：被广泛用于HDLC、SDLC、USB等多种协议中。\n违规编码法 (Physical Layer Coding Violations)这是一种巧妙利用物理层编码冗余性的方法。在某些物理层编码方案中，并非所有信号模式都对应有效的数据。这些“无效”或“违规”的信号模式就可以被借用来定义帧的边界。\n示例（以曼彻斯特编码为例）：\n\n有效编码：在曼彻斯特编码中，每个比特的中间时刻都必须有一次电平跳变（高→低 或 低→高）。\n违规编码：我们可以定义“连续高电平”和“连续低电平”这种没有中间跳变的信号模式作为帧的起始（Start）和结束（End）定界符。\n\n当接收方检测到这种“违规”信号时，就知道这是一个帧边界，而不是数据。\n优点：不需要任何填充，不增加数据载荷，实现了带外（out-of-band）的信令，效率很高, 但是不通用。\n应用：常用于令牌环网和一些局域网技术中。\n差错控制 (Error Control)差错控制是数据链路层的核心职责之一。它不仅包括我们之前提到的差错检测，还包括检测到错误后应采取的纠正措施。一个完整的差错控制机制，就是一套发现并解决数据传输错误的方法论。\n通常，差错控制的实现策略主要有两种：\n自动重传请求 (ARQ - Automatic Repeat reQuest)\n策略：接收方检测到错误后，直接丢弃这个错误的帧，然后通过一个反馈机制（如发送一个否认信息NAK，或不发送确认信息ACK）通知发送方，要求其重新发送该帧。\n特点：这种策略实现相对简单，额外开销小。它依赖于检错编码来发现错误。这是目前有线网络（如以太网）中最主流的策略。\n前向纠错 (FEC - Forward Error Correction)\n策略：接收方不仅能检测到错误，还能根据编码中包含的冗余信息，直接确定错误的位置并加以纠正，无需发送方重传。\n特点：这种策略实现复杂，冗余信息开销大。它依赖于纠错编码。常用于实时性要求高或单向通信（如广播）以及信道质量差、重传代价高的场景（如无线通信、卫星通信）。\n检错编码 (Error-Detecting Codes)检错编码的目标是让接收方有能力判断收到的数据是否在传输过程中发生了改变，但不能确定错误的位置。\n核心思想：在原始数据 k 位的后面，附加 r 位的冗余信息（校验码），构成一个 n=k+r 位的码字进行传输。这 r 位的冗余信息是根据 k 位的数据通过某种算法计算得出的。\n奇偶校验码 (Parity Code)是最简单的检错码。通过增加1位校验位，使得整个码字中“1”的个数为奇数或偶数。它只能检测出奇数个比特的错误，对于偶数个比特的错误则无能为力。\n奇检验码: 加入一位校验位，使得整个码字中“1”的个数为奇数。偶检验码: 加入一位校验位，使得整个码字中“1”的个数为偶数。\n循环冗余码 (CRC - Cyclic Redundancy Check)这是目前应用最广泛的检错码。它利用生成多项式和模2除法，可以生成检错能力极强的校验码，尤其擅长检测计算机网络中常见的突发错误（即连续多个比特出错）。\n其核心思想可以概括为：在 k 位的原始数据后面，附加 r 位的校验码（也称为 帧检验序列 FCS, Frame Check Sequence），构成一个总长为 n=k+r 位的帧。这个构造过程有一个精巧的数学保证：最终生成的这个 n 位帧，作为一个二进制数，一定能被一个预先选定的、长度为 r+1 位的特定二进制数“整除”。\n接收方收到帧后，只需用这个约定的“除数”去除以收到的帧。如果余数为零，则认为数据正确；如果余数不为零，则说明数据在传输中已损坏。\n下面以一个具体的例子来说明CRC的编码和检验过程：假设数据 M = 101001, 生成多项式(除数)G = 1101, 此时 r = 3 (G的位数-1)\n\n编码过程\n\n\n在数据 M 后面添加 r 个0，得到 M’ = 101001000\n用 M’ 除以 G，得到余数 R (这里的除法是模2除法，即不考虑进位的二进制除法, 也可以看作是按位异或操作, 只要位数够就一直做异或)\n\n          1101001101 ) 101001000       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             001 (余数, 要保留r位, 因此还要考虑前面的0)\n\n\n附加校验码\n\n\n将余数 R = 001 附加在 M 的后面，得到最终的码字 C = 101001001\n\n\n检验过程\n\n\n接收方收到码字 C’ = 101001001 后，用 G 除以 C’，如果余数为0，则数据正确；否则数据有误。\n\n          1101001101 ) 101001001       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             000 (余数为0, 数据正确)\n假如在传输过程中, 第3位(从左向右)发生了错误, 接收方收到的码字变为 C’ = 101101001, 此时再用 G 除以 C’:\n          1101001101 ) 101101001       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             101 (余数不为0, 数据有误)\n\n纠错编码 (Error-Correcting Codes)纠错编码不仅能发现错误，还能定位错误并自动修复。\n核心思想是：通过增加更多的冗余位，使得码字中任意两个有效码字之间存在足够的“差异”。即使某个码字在传输中发生了少量错误，它在“形态”上依然离原始的正确码字“最近”，而离其他的有效码字“很远”，从而让接收方可以推断出原始的正确码字。\n在介绍具体的纠错码之前，我们需要了解一个重要概念：海明距离 (Hamming Distance)或者码距(Distance)。\n它的定义是指两个等长码字之间，对应位置上比特不同的位数。例如，10101 和 10011 之间的海明距离是2（第三位和第四位不同）, 这可以通过异或操作实现。在一个编码集中, 编码级的海明距离是指该编码方案中，任意两个有效码字之间海明距离的最小值。\n根据纠错理论, 海明距离的大小直接决定了该编码的检错和纠错能力：\n\n编码方案的纠错能力(c), 检错能力(d)和码距(l)的关系: l = d + c + 1, 其中 d&gt;=c (能纠错必然能检错)\n若要检测 d 个比特的错误，则编码的海明距离(l)至少需要为 d+1。(c=0的边界情况)\n若要纠正 t 个比特的错误，则编码的海明距离(l)至少需要为 2t+1。(d=t的边界情况)\n\n\n例如, 当海明距离为 2t+1 时，如果一个码字发生了 t 位错误，它会变成一个无效码字。但这个无效码字与原始正确码字的海明距离为 t，而与其他任何一个正确码字的海明距离都至少为 t+1。因此，接收方可以通过“选择最近的有效码字”的原则，成功纠正错误。\n\n一个典型的例子是海明码 (Hamming Code), 它是设计最精巧的纠错编码之一，它不仅能发现错误，还能精确定位单个比特的错误位置。通过设置多个校验位，并且让每个校验位都对一组不同的数据位进行校验。这样，当某个数据位出错时，会同时导致多个校验位的值发生变化。通过观察是哪些校验位“不匹配”，就可以像查字典一样反推出是哪一位数据出错了。\n编码过程示例（以数据1010为例）：\n\n确定海明码的位数若信息位有k位, 设需要r位校验位, r位校验位可以表示种状态, 且总位数为k+r, 单个比特位出错的情况有k+r种, 再加上一种正确状态, 则需满足  &gt;= k + r + 1, 代入k=4, 可得r=3, 则总位数n=7则海明码的位数为7位, 其中4位是数据位, 3位是校验位.\n\n\n数据位: d4 d3 d2 d1\n校验位: p3 p2 p1\n海明码: h7 h6 h5 h4 h3 h2 h1\n\n\n确定校验位的位置规定校验位  必须放在2的幂次位置  上, 因此p1放在h1, p2放在h2, p3放在h4此时, 海明码的位数为:| h7 | h6 | h5 | h4 | h3 | h2 | h1 || d4 | p3 | d2 | p3 | d1 | p2 | p1 |\n\n分组以形成校验关系每个校验位负责校验一组特定位置的数据位, 具体规则如下:具体来说, 校验位根据其二进制位置的1所处位置位来决定它负责校验哪些数据位:\n\n\n\np1 (h1) 负责校验位置 1, 3, 5, 7 (二进制位中第1位为1的位置), 也就是这里的 h1, h3, h5, h7\np2 (h2) 负责校验位置 2, 3, 6, 7 (二进制位中第2位为1的位置), 也就是这里的 h2, h3, h6, h7\np3 (h4) 负责校验位置 4, 5, 6, 7 (二进制位中第3位为1的位置), 也就是这里的 h4, h5, h6, h7\n\n\n计算校验位的值校验位的值通过对其负责校验的数据位进行异或操作来确定:\n\n\np1 = d1 ⊕ d2 ⊕ d4 = 0 ⊕ 1 ⊕ 1 = 0\np2 = d1 ⊕ d3 ⊕ d4 = 0 ⊕ 0 ⊕ 1 = 1\np3 = d2 ⊕ d3 ⊕ d4 = 1 ⊕ 0 ⊕ 1 = 0因此, 最终的海明码为: 1010010\n\n\n错误检测与纠正每个检验组分别利用检验位和参与检验的数据位进行异或运算, 构成r个检验方程. 如果结果全部为0, 则表示数据无误; 如果某一组方程结果为1, 则表示该组数据有误.\n\n假设在传输过程中, 第3位发生了错误, 接收方收到的码字变为: 1010110, 此时在接收方不知道的情况下, 接收方重新计算校验位:\n\np1’ = h1 ⊕ h3 ⊕ h5 ⊕ h7 = 0 ⊕ 1 ⊕ 1 ⊕ 1 = 1\np2’ = h2 ⊕ h3 ⊕ h6 ⊕ h7 = 1 ⊕ 1 ⊕ 0 ⊕ 1 = 1\np3’ = h4 ⊕ h5 ⊕ h6 ⊕ h7 = 0 ⊕ 1 ⊕ 0 ⊕ 1 = 0将校验结果组合成一个二进制数, p3’p2’p1’ = 011, 并非全部是0, 说明出现了错误. 转换为十进制为3, 表示第3位出错, 接收方直接将第3位从1改回0, 成功纠正了错误.\n\n\n即使是校验位本身出错, 也能通过同样的方法定位并纠正. 校验子（Syndrome）的计算和解码过程，对所有比特一视同仁。无论是数据位还是校验位出错，都会破坏其所在校验组的平衡，从而产生一个精确指向其位置的、独一无二的校验子，使得接收方能够完美地完成定位和纠正。\n\n流量控制与可靠传输在数据链路层，我们的目标是将物理层提供的原始、可能出错的比特流，转变为一条对网络层来说高效、无差错的链路。要实现这个目标，必须解决两个核心问题：\n流量控制 (Flow Control)：如何防止速度快的发送方用数据“淹没”速度慢的接收方？这关乎效率和协调。\n可靠传输 (Reliable Transmission)：如何确保发送的数据帧最终能被接收方准确无误地收到，即使在传输过程中发生了丢失或损坏？这关乎正确性和完整性。\n这两个问题通常使用同一套协议框架来解决，其中最核心的就是滑动窗口机制。\n流量控制与滑动窗口机制如果发送方发送数据的速率，超过了接收方处理数据的速率，接收方的缓冲区（缓存）就会被填满。此时，后续到达的数据帧将因为无处存放而被丢弃，从而造成数据丢失和网络资源的浪费。\n而我们的目标是在发送方和接收方之间建立一种协调机制，让发送方根据接收方的实际接收能力来调整自己的发送速率。\n一个简单的起点：停止-等待协议 (Stop-and-Wait)这是最简单的流量控制协议。工作方式是发送方每发送一帧后，就必须停止发送，并等待接收方返回对该帧的确认（ACK）。只有收到确认后，才能发送下一帧。\n优点：机制简单，天然地实现了流量控制和可靠传输（因为接收方不确认，发送方就不会发送）。\n缺点：信道利用率极低。在发送方等待确认信号返回的漫长时间里，整个信道都处于空闲状态，造成了巨大的浪费，尤其是在卫星通信这种高延迟的场景下。\n高效的解决方案：滑动窗口协议 (Sliding Window)为了克服停止-等待协议的低效，滑动窗口协议应运而生。其核心思想是允许发送方在收到确认之前，连续发送多个数据帧。\n窗口 (Window)：\n\n发送窗口：在发送方，维持一个允许连续发送的帧的序号范围，称为“发送窗口”。窗口内所有帧都可以被发送出去，而无需等待确认。\n接收窗口：在接收方，维持一个允许接收的帧的序号范围，称为“接收窗口”。\n\n滑动 (Sliding)：\n当发送方收到一个确认帧（例如，确认了窗口内的第一个帧）时，它就知道该帧已被成功接收，于是发送窗口就可以向前“滑动”，从而可以发送新的数据帧。\n当接收方成功接收并向上层交付数据后，接收窗口也会向前“滑动”，准备接收后续的数据帧。\n流量控制的关键在于接收窗口的大小。接收方可以通过确认帧（ACK）告诉发送方自己当前还能接收多少数据帧（即接收窗口的大小）。如果接收方缓冲区已满，它可以将接收窗口大小设为0，发送方收到这个信息后就会暂停发送，直到接收方处理完数据，重新开放窗口。这是一种非常灵活且高效的流量控制方式。\n\n可靠传输机制可靠传输机制必须确保数据不丢失、不重复、无差错、按顺序地交付给上层。这通常通过以下技术组合实现：\n\n帧编号 (Sequence Numbers)：为每个帧分配一个唯一的序号，接收方可以据此判断是否有帧丢失或失序。\n确认 (Acknowledgements, ACKs)：接收方通过发送ACK来告知发送方哪些帧已成功收到。\n超时重传 (Timeout Retransmission)：发送方在发送一个帧后会启动一个计时器。如果在规定时间内没有收到对该帧的确认，就认为该帧（或其ACK）在途中丢失，并重新发送该帧。\n\n基于滑动窗口，最主流的两种可靠传输协议是回退N帧协议和选择重传协议。他们都属于ARQ(自动重传请求)协议的范畴。\n此外, 前面提到的停止-等待协议也可以看作是滑动窗口协议的一种特殊情况, 其发送窗口和接收窗口大小均为1. 这意味着发送方在发送一帧后必须等待确认, 直到收到确认后才能发送下一帧. 在这样的情况下, 帧的编号只需要1位(0或1)即可, 因为在任何时刻, 发送方和接收方都只需要区分当前帧和下一帧. \n回退N帧协议 (Go-Back-N, GBN)\n工作方式：\n\n发送方可以连续发送多个帧（发送窗口大小 &gt; 1）。\n接收方只按顺序接收数据帧（接收窗口大小 = 1）。如果它期望收到第 n 帧，但却收到了第 n+1 帧，它会直接丢弃第 n+1 帧以及后续所有到达的帧，并反复发送对第 n−1 帧的确认。当发送方发现第 n 帧超时后，它会从第 n 帧开始，重新发送它后面所有已发送过的帧（即“回退N帧”）。\n\n优缺点：接收方逻辑简单，无需缓存失序的帧。但效率较低，因为一次超时可能会导致大量本已正确到达的帧被重传。\n\n需要注意的是, 回退N帧协议要求发送窗口的大小  &lt;=  (k为帧序号位数), 以避免序号混淆. 例如, 如果序号位数为3位, 则序号范围为0~7, 发送窗口大小最大只能为7. 这是因为, 如果发送窗口大小等于8, 则在发送方发送完8个帧后, 第一个帧的序号将再次变为0, 此时接收方无法区分这是第一个帧还是第二轮发送的第一个帧, 导致序号混淆.\n选择重传协议 (Selective Repeat, SR)\n工作方式：\n\n发送方可以连续发送多个帧（发送窗口大小 &gt; 1）。\n接收方可以接收并缓存失序的帧（接收窗口大小 &gt; 1）。如果它期望收到第 n 帧，但却收到了第 n+1 帧，它会先将 n+1 帧缓存起来，并发送一个对第 n−1 帧的确认（或专门的否定确认NAK），等待第 n 帧的到来。当发送方发现第 n 帧超时后，它只重新发送第 n 帧，而不会重传那些已经被确认或已经发送过的后续帧。\n\n优缺点：信道效率极高，因为它最大限度地避免了不必要的重传。但实现起来更复杂，要求接收方有足够的缓存空间和更复杂的逻辑来处理失序的帧。\n\n如上, 这里的选择重传协议还使用了NAK(否定确认)机制, 即接收方在发现某个帧有误或丢失时, 会立即发送一个NAK给发送方, 要求其重传该帧. 这样可以更快地触发重传, 提高传输效率.\n不同的是, SR协议对接受窗口和发送窗口的大小都有要求. 具体来说, 发送窗口大小  和接受窗口大小  加起来必须满足  +  &lt;=  (k为帧序号位数), 否则, 当确认（ACK）信息丢失时，新旧窗口的序号发生重叠，从而导致接收方无法区分一个收到的帧究竟是“旧帧的重传”还是“新发送的帧”。\n一般来说, 因为接受窗口必然&lt;=发送窗口, 因此通常会设置  =  = ., 这样可以最大化窗口利用率, 同时避免序号混淆的问题.\n\n    假如违反这种规则 \n    \n      我们设定一个最简单的场景：帧序号用 k=2 位来表示。那么序号空间就是 2^k = 4，也就是说，序号范围为 0, 1, 2, 3，然后循环回 0。\n我们设定发送窗口 W_T=3，接收窗口 W_R=3。这样 W_T+W_R=6 &gt; 4。让我们一步步来看会发生什么：\n第一步：初始状态\n\n发送方的发送窗口是 {0, 1, 2}。\n接收方的接收窗口也是 {0, 1, 2}。\n\n第二步：发送与接收\n\n发送方将窗口内的帧 0, 1, 2 全部发送出去。\n接收方成功收到了这三个帧。因为它期望的就是 {0, 1, 2}，所以它将这三个帧的数据交付给上层。\n\n第三步：接收方滑动窗口并发回确认\n\n接收方成功接收了 0, 1, 2，于是它的接收窗口向前滑动3个位置。\n新的接收窗口变成了 {3, 0, 1}。它现在准备接收新一轮的帧了。\n同时，接收方为 0, 1, 2 这三个帧都发回了确认信息 ACK(0), ACK(1), ACK(2)。\n\n第四步：灾难发生——所有ACK全部丢失\n\n假设网络出现问题，接收方发出的三个ACK信号在传输过程中全部丢失了。\n\n第五步：发送方超时重传\n\n发送方苦苦等待，但始终没有收到对帧 0, 1, 2 的任何确认。\n最终，帧 0 的计时器超时。\n发送方认为帧 0 在传输过程中丢失了，于是它重新发送帧 0。\n\n第六步：接收方收到重传的帧 0\n\n接收方此刻的接收窗口是 {3, 0, 1} (如第三步所示)。\n它收到了一个序号为 0 的帧 (来自第五步发送方的重传)。\n从接收方的视角看，序号 0 正好在它的接收窗口 {3, 0, 1} 内。它完全有理由认为，这是一个全新的、属于下一轮传输的帧 0，而不是对上一轮旧帧 0 的重传。它无法分辨这两种情况！最终导致了数据重复，协议的可靠性被彻底打破。\n\n\n    \n  \n\n信道利用率 (Channel Utilization)信道利用率是衡量数据链路层协议效率的一个重要指标。它表示在一个发送周期(从发送方开始发送分组到收到第一个确认分组的时间)内，实际用于传输有用数据的时间占总时间的比例。\n停止-等待协议的信道利用率这是最简单的协议，但也是效率最低的。\n停止-等待协议的一个完整“发送周期”包含以下几个部分：\n\n（数据帧发送时延）：发送方发送一个数据分组（帧）所需的时间。\n（往返传播时延）：信号在信道中往返一次所需的时间，包括数据分组从发送方到接收方的传播时间，以及确认帧（ACK）从接收方回到发送方的传播时间。\n（确认帧发送时延）：接收方发送一个确认帧所需的时间。\n\n在一个周期内，发送方只有在最初的  时间内是在发送有效数据，其余的  时间里，信道都在空闲等待。因此，其总周期为 。\n将上述分析代入利用率的定义，我们得到停止-等待协议的信道利用率公式：\n\n通常情况下，确认帧  很短，可以忽略不计，公式可简化为：\n\n从公式可以看出, 对于停止-等待协议，当往返时延 RTT 远大于数据帧发送时延 ​时，信道利用率会非常低。\n连续ARQ协议（滑动窗口）的信道利用率为了解决停止-等待协议的效率问题，引入了连续ARQ协议，它采用流水线传输 (Pipelining) 的方式，允许发送方在收到确认前连续发送多个分组。\n设发送窗口大小为 n（即一次最多可以连续发送 n 个分组）。根据 n 是否能“填满”信道，分为两种情况。\n一个完整的发送周期（从发送第1个分组到收到它的确认）总时长仍然是 。我们需要看在这个周期内，发送方究竟发送了多少数据。\n情况一：（窗口较小，无法填满信道）\n此时发送方把窗口内的  个分组全部发完后，第一个分组的 ACK 还没有回来，因此发送方必须停下来等待，造成信道空闲。\n利用率计算：在一个发送周期内，发送方有效发送数据的时间是 。\n\n\n情况二：（窗口足够大，可以填满信道）\n条件解读：当第一个分组的 ACK 返回时，发送方还没发完窗口内的  个分组，因此它可以继续不间断地发送新的分组，信道始终处于忙碌状态。\n利用率计算：由于信道没有空闲，发送方一直在发送有效数据。\n\n\n结论：连续 ARQ 协议通过流水线技术，极大地提高了信道利用率。只要发送窗口  足够大（满足 ），在不考虑差错的情况下，理论上可以达到 100% 的信道利用率，完全克服了停止-等待协议的效率瓶颈。\n局域网 (Local Area Network, LAN)局域网 (LAN) 是指在一个较小的地理范围内（如一栋建筑、一个校园或一个办公室），将各种计算机、服务器、打印机等设备互联起来组成的私有网络。\n其特点是覆盖范围小, 但是通常具有高传输速率、低时延、低误码率\n局域网的技术标准主要集中在OSI参考模型的最低两层：物理层和数据链路层。IEEE 802系列标准为了适应不同的局域网技术，将数据链路层进一步划分为两个子层：\n逻辑链路控制 (LLC - Logical Link Control) 子层: 负责向上层（网络层）提供一个统一的接口，隐藏了不同MAC协议的差异。它也负责处理一些确认、流量控制等逻辑功能。\n介质访问控制 (MAC - Medium Access Control) 子层: 这是局域网技术的核心。它负责数据帧的封装、物理地址（MAC地址）的寻址，以及最重要的——如何协调对共享物理介质的访问（即我们前面讨论的CSMA/CD、CSMA/CA等协议）。\n他们之间的结构关系为: 网络层 (L3) &lt;–&gt; LLC子层 (L2上) &lt;–&gt; MAC子层 (L2下) &lt;–&gt; 物理层 (L1)\n局域网的三个决定性要素是拓扑结构、传输介质和介质访问控制方式，其中介质访问控制方式最为重要 。\n以太网与 IEEE 802.3以太网 (Ethernet) 是当今应用最广泛的有线局域网技术，其技术标准由 IEEE 802.3 规范定义。\nMAC地址（或称物理地址）是一个48位（6字节）的全球唯一地址，固化在网卡的ROM中。它通常用12个十六进制数表示，如 02-60-8c-e4-b1-21 。前24位是厂商代码，后24位是厂商分配的序列号。\n网卡通过硬件检查收到的MAC帧，如果目的地址是本机地址（单播）、广播地址（全1）或本机所在的多播组地址，则接收该帧，否则丢弃。\nIEEE 802.11 无线局域网VLAN 基本概念与基本原理虚拟局域网 (VLAN) 是一种将一个大型物理局域网分割成多个逻辑上独立的虚拟网络的技术 。VLAN的作用主要有以下几个方面：\n\n隔离广播域：一个大型局域网是一个广播域，大量的广播帧（如ARP）会严重影响网络性能 。VLAN将网络分割成多个小的广播域，广播帧被限制在各自的VLAN内部 。\n\n增强安全性和管理：可以将不同部门或用户组划分到不同的VLAN中，即使他们物理上连接在同一台交换机，也无法直接通信，从而提高安全性 。\n\n\n广域网(Wide Area Network, WAN)广域网的基本概念点对点协议数据链路层设备网桥以太网交换机","categories":["web"],"tags":["web","computer network"]},{"title":"网络层","url":"/2025/09/30/web/Computer%20Network/%E7%BD%91%E7%BB%9C%E5%B1%82/%E7%BD%91%E7%BB%9C%E5%B1%82/","content":"网络层的功能IPv4IPv6","categories":["web"],"tags":["web","computer network"]},{"title":"计算机网络体系结构","url":"/2025/09/16/web/Computer%20Network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/1.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","content":"电路交换, 报文交换和分组交换\n在计算机网络中，数据交换技术是指在网络节点之间传输数据时所采用的方式。根据数据传输的组织形式，主要分为三种基本类型：电路交换 (Circuit Switching)、报文交换 (Message Switching) 和 分组交换 (Packet Switching), 三种方式的比较如上图\n电路交换电路交换 是一种在通信双方之间建立一条专用物理连接（电路）的技术。在整个通信过程中，这条电路被双方独占，直到通信结束才被释放。电路交换的通信过程严格分为三个阶段：\n\n建立连接 (Circuit Establishment): 在数据传输开始之前，源节点（如打电话的人）向网络发出连接请求。网络通过一系列交换机（节点）为通信双方分配并建立一条专用的物理路径。\n\n此步骤的目的是预留通信所需的所有资源（如信道带宽、交换机端口等），以确保后续数据传输的服务质量 (QoS)，如固定的速率和时延。\n\n数据传输 (Data Transfer): 连接建立后，源节点开始沿着这条专用电路向目的节点发送数据。数据以恒定的速率传输，中间节点（交换机）不对数据进行存储，而是直接进行转发。\n\n由于电路是专用的，数据传输几乎没有时延（仅有传播时延和节点处理时延），且时延是固定的，非常适合实时通信。\n\n释放连接 (Circuit Release): 通信结束后，任何一方（通常是发起方）发出拆除连接的信令。网络收回为该连接分配的所有资源。\n\n释放资源是为了让其他用户可以使用这些空闲的信道和端口，提高网络资源的整体利用率。\n优点：\n\n实时性强： 一旦连接建立，数据传输时延极小且固定，非常适用于对时延敏感的实时业务（如语音、视频通话）。\n服务质量保证： 通信双方独占带宽，数据传输速率恒定，不会出现网络拥塞导致的速率波动。\n\n缺点：\n\n线路利用率低： 无论双方是否在传输数据（例如通话中的沉默时段），电路都会被占用，导致资源浪费，尤其不适合突发性（bursty）的数据通信。\n建立连接时延： 在数据传输前，必须花费额外的时间来建立连接。\n难以实现差错控制: 中间节点不具备存储和检验数据的能力, 无法识别和纠正差错\n\n报文交换 (Message Switching)报文交换 是一种无需预先建立专用路径的数据交换技术。它以报文 (Message)（即一个完整的数据单元，如一封电子邮件）为单位进行传输，并采用“存储-转发” (Store-and-Forward) 机制。工作原理如下: \n\n发送报文： 源节点将要发送的数据（报文）附加上目标地址等控制信息，然后将整个报文发送给相邻的第一个交换节点。\n\n存储和转发：交换节点收到完整的报文后，先将其存储在本地缓存（如硬盘）中, 节点需要接收完整的报文并保存，一方面是为了进行差错校验，另一方面是等待输出链路可用。当输出链路空闲时，节点再将该报文转发给下一个节点。这种方式允许多个不同来源的报文共享同一条链路，提高了链路的利用率。\n\n中继传输： 报文在网络中逐个节点地“存储-转发”，直到最终到达目的节点。\n\n\n优点在于: \n\n线路利用率高： 交换节点可以动态分配链路资源，只有在传输报文时才占用链路，提高了信道利用率。\n无需建立连接： 省去了电路交换中建立连接所需的时间。\n\n缺点：\n\n时延大且不固定： 每个节点都需要完整接收并存储报文，导致较大的“存储转发时延”。时延会随着网络负载的增加而显著增加。\n节点缓存要求高： 交换节点必须有足够大的缓存空间（通常是磁盘）来存储可能很长的整个报文。\n不适合实时通信： 较大的时延使其无法满足实时交互的需求。\n\n分组交换 (Packet Switching)分组交换 是目前互联网 (Internet) 使用的核心技术。它结合了报文交换的优点（高效的链路共享），并克服了其缺点（时延大、缓存要求高）。互联网 (Internet)、局域网 (LAN)、广域网 (WAN) 等几乎所有现代数据网络都使用这种方式。\n它同样采用“存储-转发”机制，但其传输的基本单位是分组 (Packet)——即将一个完整的报文拆分成多个较小的数据块。工作原理为: \n\n报文分组 (Segmentation): 在源节点，一个完整的报文（如一个网页、一封邮件）被分割成多个固定或可变长度的分组。每个分组都会被添加一个头部 (Header)，包含源地址、目的地址、分组序号等控制信息。这里的将大报文拆分成小单元（分组），有几个关键好处：\n\n减少时延： 交换节点只需接收一个很小的分组即可开始转发，而无需等待整个报文。这使得网络可以实现“流水线” (Pipelining) 传输(边接受边传输)，大大降低了端到端时延。\n\n减少缓存需求： 节点缓存中只需存储较小的分组，而非完整的大报文。\n\n提高可靠性： 如果传输中出现错误，只需重传错误的分组，而不是整个报文。\n\n\n\n存储和转发 (Store-and-Forward): 每个分组在网络中被独立地进行“存储-转发”。交换节点（路由器）接收一个分组，将其暂存在内存（速度远快于报文交换的磁盘）中，检查其头部，然后根据路由表选择最佳路径转发给下一个节点。这种方式非常灵活，分组可以动态地选择路径，适应网络拥塞或链路故障。\n\n路径选择 (Routing): 不同的分组可能会沿着不同的路径传输到目的地。（这主要取决于使用的是数据报方式还是虚电路方式, 数据报方式具有无连接性, 每个分组独立路由; 而虚电路(Virtual Circuit, VC)则在数据传输前先建立一条逻辑连接（虚电路）, 所有分组都沿着这条逻辑路径按顺序传输）。\n\n\n重组 (Reassembly): 分组到达目的节点后，目的主机根据分组头部中的序号信息，将这些可能乱序到达的分组重新排序，组装成原始的报文(由于分组独立路由，它们到达目的地的顺序可能与发送顺序不同，必须重组才能恢复原始数据)\n\n\n这种方式的优点在于：\n\n线路利用率极高：动态共享链路，资源利用率在三种方式中最高。\n灵活高效： 传输单位小，时延相对较低（虽然不固定）。\n鲁棒性强 (Robust)： 节点或链路故障时，分组可以动态选择其他路径绕过故障点。\n\n缺点则是：\n\n时延不固定 (Jitter)： 每个分组的存储转发时延和排队时延是变化的，会导致“时延抖动”，对实时业务（如高质量视频会议）有一定挑战。\n额外开销：每个分组都需要附加包头信息，这会产生一定的传输开销。\n\n计算机网络的分类计算机网络可以从多个不同的维度进行分类:\n按分布范围分类这是最常用的一种分类方式，它根据网络所覆盖的地理区域大小来划分：\n\n广域网 (WAN - Wide Area Network): 覆盖范围非常大，通常直径为几十到几千公里，可以覆盖一个国家、一个大洲甚至全球。它的任务是提供长距离通信，连接不同地区的主机或局域网。它通常使用高速链路和交换机（如路由器）进行数据传输。互联网 (Internet) 的核心部分就是一个全球最大的广域网。\n\n城域网 (MAN - Metropolitan Area Network): 覆盖范围介于WAN和LAN之间，通常覆盖一个城市（直径约 5 km 到 50 km）。它可以被视为一个大型的局域网，通常采用以太网等技术，用于连接城市内的多个局域网。\n\n局域网 (LAN - Local Area Network): 覆盖范围较小，通常是直径为几米到几千米的区域，例如一栋办公楼、一个校园或一个家庭。局域网通常具有较高的传输速率和较低的误码率。传统上，局域网多采用广播技术（如早期的以太网），而广域网多采用点对点交换技术。\n\n个人区域网 (PAN - Personal Area Network): 覆盖范围最小，通常在个人工作区域（约几米内）。用于在个人设备之间（如智能手机、平板电脑、笔记本电脑、蓝牙耳机）进行短距离通信。当它使用无线技术时，也称为 无线个人区域网 (WPAN)。\n\n\n按传输技术分类\n广播式网络 (Broadcast Networks): 网络中所有联网的计算机共享一个公共通信信道。当一台计算机发送一个分组时，信道上的所有其他计算机都会“收听”到这个分组。每台计算机通过检查分组中的目的地址来判断这个分组是否是发送给自己的，从而决定是否接收它。\n\n传统的局域网（如总线型以太网）基本都采用广播式通信。此外，无线网络和卫星通信网络也属于广播式网络。\n\n点对点网络 (Point-to-Point Networks): 网络由多条独立的物理线路组成，每条线路连接一对计算机（节点）。如果两台主机没有被一条线路直接连接，它们之间的通信就需要通过中间节点的中继。\n\n这通常需要“存储-转发” (Store-and-Forward) 机制，即中间节点（如路由器）接收整个分组，将其存储下来，然后查找路由表，最后转发给下一个节点。广域网大多采用点对点技术。\n按拓扑结构分类拓扑结构是指网络中节点（如主机、路由器）与通信线路之间的几何关系，它主要定义了网络的物理布局。\n\n总线形 (Bus Topology): 所有计算机都连接到一根单根传输线（称为“总线”）上。\n\n其优点是建网容易，增/减节点方便，节省线路成本; 缺点则在于通信效率在重负载时不高（容易冲突）, 且总线是网络的命脉，任意一处故障都可能导致整个网络瘫痪。\n\n星形 (Star Topology): 网络中有一个中央设备（如交换机、集线器或路由器），每个终端或计算机都通过单独的线路与该中央设备相连。\n\n其优点是便于集中控制和管理, 单个节点的故障不会影响其他节点; 缺点则是线路成本较高, 中央设备是网络的“瓶颈”，一旦中央设备发生故障，整个网络都会瘫痪。\n现代的局域网（如以太网交换机）基本都采用星形结构。\n\n环形 (Ring Topology): 所有计算机接口设备被连接成一个闭合的环，信号在环中沿着一个方向单向传输。典型的例子是令牌环 (Token Ring) 局域网。\n\n网状 (Mesh Topology): 每个节点至少有两条路径与其他节点相连，存在高度的冗余连接。\n\n\n一个显著优点在于可靠性极高。某条链路或某个节点出现故障时，数据可以自动选择其他路径进行传输。\n缺点也很显而易见： 控制非常复杂（需要动态路由算法），线路成本极高。因此多用于广域网的核心层和互联网的骨干网，以确保通信的鲁棒性。\n按传输介质分类\n有线网络 (Wired Networks): 使用物理线缆作为传输介质的网络。包括双绞线网络（如以太网）、同轴电缆网络（如早期的有线电视网）、光纤网络等。\n\n无线网络 (Wireless Networks): 使用电磁波在空间中进行数据传输，无需物理线缆。包括 Wi-Fi、蓝牙 (Bluetooth)、微波通信、蜂窝移动网络 (4G/5G) 等。\n\n\n计算机网络的性能指标速率 (Rate): 也常称为数据率(Data Rate)或比特率(Bit Rate), 是指连接到计算机网络上的节点在数字信道上传送数据的速率, 基本单位是 b/s (比特/秒，即 bps)。\n\nkb/s (千比特/秒) = 10³ b/s \nMb/s (兆比特/秒) = 10⁶ b/s  \nGb/s (吉比特/秒) = 10⁹ b/s \nTb/s (太比特/秒) = 10¹² b/s\n\n带宽 (Bandwidth): 在计算机网络中，带宽通常是“最高数据传输速率”的同义词, 因此单位也是 b/s (比特/秒)。我们常说的“我家拉了100兆的宽带”，指的就是这条线路的理论最高速率为 100 Mb/s。它代表了链路传输数据的最大能力。\n\n在信息论中，带宽 (Bandwidth) 指的是信号频率范围，单位为赫兹 (Hz)。例如，一个信道的带宽为 3000 Hz，表示它可以传输从某一频率到该频率加3000 Hz范围内的信号。\n\n吞吐量 (Throughput): 是指在单位时间内，通过某个网络（或信道、接口）的实际数据量。其单位为 b/s, Mb/s, Gb/s 等. 实际的吞吐量会受到网络拥塞、设备处理能力、协议开销、时延等多种因素的限制。因此，吞吐量总是小于或等于带宽。\n信道利用率 (Channel Utilization): 指某条信道在特定时间段内，有数据通过的时间所占的百分比。这是衡量信道繁忙程度或效率的指标。不过实际上并非信道利用率越高越好。根据排队理论，当信道利用率过高（例如接近100%）时，会导致分组在路由器队列中等待的时间（即排队时延）急剧增加，网络性能（总时延）会严重恶化，甚至导致大量丢包。\n时延带宽积 (Delay-Bandwidth Product): 这是一个表示容量的复合指标，它等于传播时延与信道带宽的乘积计算公式：时延带宽积 (bit) = 传播时延 (s)× 带宽 (b/s)\n我们可以将链路想象成一个圆柱形管道：\n\n管道的长度 = 传播时延（数据通过管道所需的时间）\n管道的横截面积 = 带宽（单位时间能塞入多少数据）\n时延带宽积 = 管道的容积（这条链路最多能容纳多少比特）\n\n往返时延 (Round-Trip Time, RTT): RTT 是指从发送端发送一个短分组开始，到发送端接收到来自接收端的确认分组为止，所经历的总时间, 它是衡量网络响应速度和进行交互式应用（如网页浏览、在线游戏）时非常重要的指标\n需要注意的是, 它并不仅仅*是“传播时延的两倍”。一个完整的RTT至少包括：去程的传播时延 + 接收端的处理时延（用于生成确认）+ 确认分组的发送时延（通常很短）+ 回程的传播时延. 在实际的互联网中，RTT还包含了数据分组和确认分组在所有中间路由器上所经历的处理时延和排队时延。因此，RTT通常是一个动态变化的值。\n时延在计算机网络中，时延 (Delay) 是一个核心的性能指标。它指的是一个数据单元（例如一个报文或一个分组）从网络（或链路）的一端传输到另一端所需要的总时间。这个总时延 (T总) 并不是单一因素决定的，而是由以下四个主要部分构成的：\nT总 = T发送 + T传播 + T处理 + T排队\n发送时延 (Transmission Delay)定义：发送时延，也常被称为传输时延，是指网络节点（如主机或路由器）将一个分组的所有比特”推送”到通信链路（如光纤、网线）上所花费的时间，从第一个Bit开始发送，到最后一个Bit发送完成。\n计算公式：\nT发送 = 分组长度 (bit) / 发送速率 (bit/s)\n这个时延取决于分组的大小和链路的发送速率（也称为带宽）。\n传播时延 (Propagation Delay)定义：传播时延是指电磁波（或光信号）在信道（传输介质）中传播一定距离所花费的时间。通俗地说，就是一个比特从链路的始端传播到末端所需的时间。\n计算公式：\nT传播 = 信道长度 (m) / 电磁波在信道上的传播速率 (m/s)\n从公式中可以看出，这个时间与分组有多大、发送速率有多快无关。\n处理时延 (Processing Delay)定义：指分组到达交换节点（如路由器）时，节点为进行存储转发而进行一系列必要处理所花费的时间。\n路由器不是一个简单的”直通”管道。它必须对收到的每个分组进行分析才能决定下一步做什么。处理内容包括：\n\n检查分组首部：分析目标地址、协议类型等信息\n差错校验：检查分组在传输过程中是否出现损坏\n查找路由：根据目标地址查询本地路由表，确定将分组转发到哪一个输出端口\n\n在现代高速路由器中，处理时延通常非常短（在微秒或更低的级别）。\n排队时延 (Queuing Delay)定义：指分组在路由器的输入队列或输出队列中排队等待所花费的时间。\n因为当多个分组同时到达，而路由器无法立即处理它们时（例如，多个输入链路的分组都要转发到同一个正忙的输出链路），这些分组就必须排队等待。\n其特点是：\n\n排队时延是四个时延中唯一一个高度可变的\n它完全取决于网络的拥塞状况\n如果网络非常空闲，排队时延可能接近于0\n如果网络非常拥塞，排队时延可能会变得非常大，成为总时延中最主要的部分，甚至导致路由器缓存溢出而发生丢包 (Packet Loss)\n\n计算机网络分层结构计算机网络的分层结构是一种将复杂的网络通信任务划分为多个独立层次的设计方法。每一层都负责特定的功能，并通过定义良好的接口与相邻层进行交互。\n其基本原则是: \n\n分层：每一层都执行一组明确定义的功能。\n服务提供：每一层都为其紧邻的上一层提供服务，同时隐藏了实现该服务的具体细节。\n对等通信：不同计算机上的同一层（称为对等层）之间似乎在直接通信。实际上，这种通信是通过下层提供的服务来实现的，并由该层的协议来规范。\n\n这里有几个概念需要区分: \n服务 (Service): 是下层通过层间接口向上层提供的功能。它描述了某一层能为它的上一层做什么。服务的核心在于功能抽象。上层不需要关心下层是如何实现这些功能的，只需要知道如何使用这些功能即可。\n例如, 传输层为应用层提供“可靠的数据传输服务”。应用层（如网页浏览器）只需要请求传输层发送数据，并相信数据会准确无误地到达目的地，而不需要关心传输层是如何通过确认、重传等机制来保证可靠性的。\n接口 (Interface): 接口是同一台计算机上相邻两个层次之间的交互点。它定义了上层如何访问下层所提供的服务。它规定了一套操作和参数，用于在层与层之间传递控制信息和数据。\n可以将其看作是一个软件函数库的API（应用程序编程接口）。传输层会提供像 send() 和 receive() 这样的函数调用作为接口，供应用层来使用它的数据传输服务。\n协议 (Protocol): 协议是控制不同计算机上对等实体（Peer Entities，即不同机器上的同一层）之间通信的一组规则。它规定了通信双方需要共同遵守的格式、顺序和操作，确保它们能够正确地理解对方发送的信息。协议是水平的，服务和接口是垂直的。\n协议三要素：\n\n语法 (Syntax)：数据与控制信息的结构或格式。例如，HTTP协议规定一个HTTP请求报文必须包含请求行、请求头和请求体。\n语义 (Semantics)：需要发出何种控制信息，完成何种动作以及做出何种应答。例如，规定收到一个特定的状态码（如404）代表“未找到资源”。\n时序 (Timing)：事件实现的顺序。例如，规定发送方发送数据后，必须在多长时间内收到接收方的确认。\n\n计算机网络的两种参考模型\n","categories":["web"],"tags":["web","computer network"]},{"title":"Process","url":"/2025/09/30/system/OS/Process/Process/","content":"进程的基本概念 (Process Concept)什么是进程 (Process)一个进程是 “一个正在执行中的程序” 。它不仅仅是代码，还包含了程序当前的活动状态 。\n一个进程在内存中通常包含以下几个部分 ：\n\n文本段 (Text Section)：存放程序代码 。\n数据段 (Data Section)：存放全局变量 。\n堆 (Heap)：用于动态分配的内存 。\n栈 (Stack)：存放函数参数、局部变量和返回地址 。\n程序计数器 (Program Counter)：指示下一条要执行的指令地址 。\n进程状态 (Process State)\n\n\n进程状态 (Process State)一个进程在其生命周期中会经历多种状态的转换 ：\n\n新建 (New)：进程正在被创建 。\n就绪 (Ready)：进程已准备好，等待被分配给CPU运行 。\n运行 (Running)：进程的指令正在被处理器执行 。\n等待 (Waiting/Blocked)：进程正在等待某个事件的发生，如 I/O 操作完成 。\n终止 (Terminated)：进程已完成执行 。\n\n\n进程控制块 (Process Control Block, PCB)进程控制块 (Process Control Block, PCB)：是操作系统进行进程切换和管理的基础, 操作系统为每一个进程都维护一个 PCB，它包含了与该进程相关的所有重要信息 ，例如：\n\n进程状态 。\n程序计数器和 CPU 寄存器的值 。\nCPU 调度信息（如优先级） 。\n内存管理信息（如页表） 。\nI/O 状态信息（如已分配的设备） 。\n\n进程调度 (Process Scheduling)进程调度是操作系统管理多个进程以有效利用 CPU 的机制 。\n调度队列调度队列 (Scheduling Queues)：操作系统使用队列来组织进程 。\n\n作业队列 (Job Queue)：系统中所有进程的集合 。\n就绪队列/CPU队列 (Ready Queue/CPU Queue)：所有在主内存中、准备好执行的进程的集合 。\n设备队列 (Device Queues)：等待某个 I/O 设备的进程集合 。\n\n\n上图展示了操作系统中用于管理进程的两种主要类型的队列：就绪队列 (Ready Queue) 和 I/O 设备队列 (I/O Device Queues)。\n每个矩形框（如 PCB7, PCB2）代表一个进程控制块 (Process Control Block, PCB)，它是操作系统用来存储一个进程所有信息的数据结构。\n位于图顶部的“ready queue”就是就绪队列，也被称为 CPU 队列 (The CPU queue)。它包含所有已经准备就绪、可以立即在 CPU 上运行的进程。这些进程正在等待操作系统调度程序（Scheduler）为它们分配 CPU 时间。\n\nqueue header（队列头部）包含 head 和 tail 两个指针，分别指向队列的第一个和最后一个进程的 PCB。\n在这个例子中，PCB7 和 PCB2 正在就绪队列中排队，等待被 CPU 执行。PCB7 在 PCB2 的前面。\n\n而当一个进程需要执行 I/O 操作时（例如从磁盘读取数据），它会进入等待状态，并被放入相应 I/O 设备的等待队列中，直到 I/O 操作完成。\n图中也展示了多个独立的 I/O 设备队列，每个设备都有自己的队列。\n\n磁盘单元0 (disk unit 0)：它的队列中有三个进程 PCB3、PCB14 和 PCB6，说明这三个进程都在等待从该磁盘设备完成 I/O 操作。\n终端单元0 (terminal unit 0)：PCB5 正在等待该终端设备的 I/O 操作。\n磁带单元0和1 (mag tape unit 0/1)：这两个设备的队列是空的，表示当前没有进程在等待它们。\n\n\n上图则是一个 “排队图” (A queueing-diagram)，它详细描绘了一个进程在操作系统中的生命周期和状态转换路径。\n矩形框（灰色）代表队列或导致状态变化的事件; 圆形/椭圆形框（蓝色）代表系统资源（如 CPU, I/O）或事件的结果; 箭头表示进程在不同状态和队列之间的流转方向。\n具体来看, 一个进程从进入系统到最终退出的完整流程，以及在此期间可能发生的各种情况有：\n\n进入就绪队列 (Ready Queue)\n 一个新创建的或者从等待状态恢复的进程首先会进入就绪队列。这里的进程已经准备好了一切，只等待被分配 CPU。\n\n分配 CPU 并运行\n 操作系统的调度程序会从就绪队列中选择一个进程，并将其调度到 CPU 上运行。\n\n从 CPU 离开的几种可能情况\n\n情况一：发起 I/O 请求 (I/O request)\n\n如果正在运行的进程需要进行读写文件、访问网络等 I/O 操作，它会发起一个 I/O 请求。\n\n随后，该进程会从 CPU 释放，并进入相应的 I/O 队列 (I/O queue) 进行等待。\n\n当 I/O 操作完成后，进程会重新回到就绪队列的末尾，等待下一次 CPU 调度。\n\n\n\n情况二：时间片用完 (Time slice expired)\n\n在分时操作系统中，每个进程只能在 CPU 上运行一个固定的时间段，即“时间片”。\n\n当时间片用完后，操作系统会通过一个中断来剥夺该进程的 CPU 使用权。\n\n该进程会直接回到就绪队列的末尾，等待下一轮调度。\n\n\n\n情况三：创建子进程 (Fork a child)\n\n进程在运行时可以调用 fork 之类的系统调用来创建一个新的子进程。\n\n创建子进程后，父进程可能会等待子进程执行完毕，或者继续并发执行。图中箭头指向父进程回到就绪队列。\n\n\n\n情况四：等待中断 (Wait for an interrupt)\n\n进程可能需要主动等待某个特定的事件发生，例如等待另一个进程发来的信号。\n\n在这种情况下，进程会进入等待状态，直到所等待的中断发生 (interrupt occurs)。\n\n中断发生后，该进程会被唤醒并移回到就绪队列中。\n\n\n\n情况五：正常结束\n\n进程执行完所有任务后会正常终止，然后退出系统。图中从 CPU 指向右侧外部的箭头就代表了这一路径。\n\n\n\n\n\n调度程序 (Schedulers)\n从概念上来看, 操作系统中的调度程序负责管理进程的执行, 可以有两种类型的调度程序：\n短期调度程序 (Short-term Scheduler): 也称为 CPU 调度程序 (CPU scheduler) 。\n它的主要任务是从就绪队列 (ready queue)中选择一个进程，并为它分配 CPU 。它决定了就绪队列中的哪个进程可以“上CPU”运行。\n它的执行频率非常高，通常是毫秒级别，因为每次 CPU 需要切换进程时都可能调用它 。\n由于执行得非常频繁，短期调度程序本身必须运行得非常快，否则会占用大量本该用于执行用户进程的时间 。\n长期调度程序 (Long-term Scheduler): 也称为 作业调度程序 (job scheduler) 。\n它的任务是从一个更大的进程池（例如硬盘上的所有待处理的“作业”）中，选择哪些进程应该被加载到内存中，并放入就绪队列 。\n它控制着系统中的多道程序设计度 (degree of multiprogramming)，即同时存在于内存中的进程数量 。\n一般来说, 它的执行频率非常低，可能几秒钟甚至几分钟才执行一次 。由于不经常执行，它的速度也相对较慢 。\n值得注意的是，许多现代操作系统（如 UNIX 和 Windows）实际上并不使用长期调度程序 。\n\n此外, 有些系统还引入了中期调度程序 (Medium-term Scheduler)，当内存不足或系统需要调整内存中的进程组合时，中期调度程序会选择一个进程（通常是处于等待状态或优先级较低的进程），将其从内存中暂时移除，并保存到硬盘等二级存储中。\n在未来的某个时刻，当内存条件允许或该进程被需要时，中期调度程序会将被换出的进程重新加载回内存的就绪队列中，使其可以继续执行 \n\n在内存中, 进程大致可以分为计算密集型（CPU-bound）和I/O密集型（I/O-bound）进程, 前者主要进行大量CPU计算, 而后者则频繁进行I/O操作。\n操作系统的调度程序通常会优先选择 I/O 密集型进程，因为它们在等待 I/O 操作完成时，CPU 可以被其他进程使用，从而提高整体系统的吞吐量和响应时间 。\n\n上下文切换 (Context Switch)\n当 CPU 从一个进程切换到另一个进程时，系统必须保存当前进程的状态（上下文）到其 PCB 中，并加载新进程的上下文 。\n这个过程是纯粹的开销 (overhead)，因为在切换期间系统没有执行任何有用的工作 。\n进程操作 (Operations on Processes)这部分描述了进程的创建和终止过程。\n进程创建 (Process Creation)：一个进程（父进程）可以创建新的进程（子进程），从而形成一个进程树 。\n\n在 UNIX/Linux 系统中: \n\nfork() 系统调用用于创建一个新的子进程，该子进程是父进程的一个副本 。\n\n在创建后, 父进程和子进程会从 fork() 调用返回, 但返回值不同: 父进程收到子进程的 PID, 而子进程收到0 。\n子进程继承了父进程的大部分属性（如环境变量、打开的文件描述符等），但有自己的独立地址空间 。\n\n\nexec() 系统调用通常在 fork() 之后被子进程调用，用于将新的程序加载到自己的内存空间中，以替代从父进程复制来的内容 。\n\n父进程可以通过 wait() 系统调用来阻塞等待子进程的完成\n\n\n进程终止 (Process Termination)当一个进程完成其最后一个语句的执行后，它会调用 exit() 系统调用来请求操作系统删除它 。其所有占用的资源（内存、文件等）都会被操作系统回收 。\n父进程也可以终止其子进程（例如，当子进程超出了资源限制时）。\n如果父进程终止，其子进程可能会被级联终止 (cascading termination) ，或者在某些系统中成为孤儿进程 (orphaned)，并被 init 进程（PID 为 1）所收养。\n进程间通信 (Interprocess Communication, IPC)这部分探讨了进程之间如何协作和交换信息。\n协作进程 (Cooperating Processes)：能够影响或被其他进程影响的进程称为协作进程 。\n协作的优势包括信息共享、加快计算速度、模块化和便利性 。\n生产者-消费者问题 (Producer-Consumer Problem)生产者-消费者模型 描述了两个或多个并发实体（线程/进程）通过共享缓冲区（bounded buffer）协作完成任务的过程。\n\n生产者（Producer）：负责生产数据（例如消息、任务、商品）并放入缓冲区。\n消费者（Consumer）：从缓冲区取出数据进行处理或消费。\n缓冲区（Buffer）：是一个共享的、有界的存储空间，用来暂存生产者产生但消费者尚未取走的数据。\n\n这个模型有两个关键挑战：\n\n同步（Synchronization）问题: 消费者不能在缓冲区为空时取数据, 生产者也不能在缓冲区满时放数据。因此需要一种方式让它们“有序等待、协调运行”。\n\n互斥（Mutual Exclusion）问题: 生产者和消费者不能同时访问缓冲区（否则会出现数据竞争）。因此需要互斥锁或信号量来保护共享资源。\n\n\nIPC 的两种模型\n共享内存 (Shared Memory)：多个进程共享一块内存区域。进程通过直接读写这块共享内存来交换信息。\n消息传递 (Message Passing)：进程通过发送和接收消息进行通信，而无需共享变量 。这种通信通常由内核提供的 send() 和 receive() 操作来完成 。\n消息传递的实现直接通信 (Direct Communication)：进程必须明确地命名对方来进行通信，通信双方必须明确知道对方的身份（进程名或PID），通信链路由操作系统自动建立。\n\nsend(P, message)   → 向进程 P 发送消息  \nreceive(Q, message) → 从进程 Q 接收消息\n\n间接通信 (Indirect Communication)：消息被发送到 邮箱 (mailbox) 或 端口 (port)，进程通过共享同一个邮箱来进行通信 。\n同步与异步 (Synchronization)：通信可以是 阻塞的 (blocking/synchronous)，即发送方会等待消息被接收；也可以是 非阻塞的 (non-blocking/asynchronous)，即发送方发送消息后立即继续执行 。\n客户端-服务器系统中的通信这部分介绍了在网络环境中实现进程通信的几种常用技术。\n套接字 (Sockets)：\n套接字是通信的一个端点，它由一个 IP 地址和一个端口号组合而成 。两个进程间的网络通信就是通过一对套接字进行的 。\n远程过程调用 (Remote Procedure Calls, RPC)：\nRPC 是一种允许一个进程调用网络中另一台计算机上进程的过程（或函数）的机制，使得分布式编程看起来像本地调用一样简单 。\n远程方法调用 (Remote Method Invocation, RMI)：\nRMI 是 Java 中类似 RPC 的机制，它允许一个 Java 程序调用远程机器上另一个 Java 对象的\n方法 。\n","categories":["system","OS"],"tags":["system"]},{"title":"OSI model","url":"/2025/09/01/web/Computer%20Network/OSI/2.%20OSI/","content":"OSI 模型（Open Systems Interconnection model，开放式系统互联模型）是一个由国际标准化组织（ISO）提出的概念模型，旨在为不同计算机网络之间的通信提供一个标准的参考框架。它将复杂的通信过程划分为七个独立的、功能明确的层次（Layer）。\n这个模型的核心思想是 “分层”。每一层都负责特定的网络功能，并为其上一层提供服务，同时使用其下一层提供的服务。这种分层结构使得网络协议的设计和排错变得更加简单和模块化。\nOSI 模型从上到下分为七个层次，每一层都有其独特的功能。数据在发送端从顶层（应用层）向下逐层封装，在接收端则从底层（物理层）向上逐层解封装。\n第一层：物理层 (Physical Layer)物理层是 OSI 模型的最底层，它负责传输原始的比特流（Bits）。\n这一层处理的是最基础的物理媒介。它规定了网线、光纤、无线电波等传输介质的电气和物理特性, 如电压、接口类型、线缆规范、传输速率等。它的任务就是将上层传递下来的数字信号（0 和 1）转换成电信号、光信号或无线电信号，并在物理介质上传输。\n更详细来说, 物理层的目的是在物理传输介质上，实现原始比特流（raw bit stream）的透明传输\n\n“物理”的含义：这一层关注的是构成网络的实体部分，例如线缆、连接器、电压、光信号等，这些都是看得见、摸得着的物理设备和标准。\n“比特流”的含义：物理层不关心数据的内容、格式或意义。在它看来，所有数据都是一串由 0 和 1 组成的二进制序列。它的工作就是确保发送方发送的 0101 序列，接收方接收到的也是 0101 序列。\n“透明传输”的含义：这意味着物理层对上层（数据链路层）屏蔽了所有物理细节。数据链路层不需要关心数据是通过光纤、铜缆还是无线电波传输的，也不需要关心电压是多少、接口是什么形状。物理层为上层提供了一个统一、透明的比特流传输通道。\n\n物理层的四大核心功能物理层的功能主要围绕着如何可靠地传输比特流来展开，具体可以分为以下四个方面：\n\n定义电气和物理特性\n\n这是物理层最基础的职责，它定义了所有与传输介质和接口相关的物理和电气规范。\n机械特性：定义了网络接口（如网线接口）的物理形状、尺寸、引脚数量和排列方式。\n\n这一步是为了确保不同制造商生产的设备可以物理上相互连接。例如，我们常见的 RJ45 网线接口就是一个标准化的机械特性，保证任何一根标准的网线都能插入任何一个标准的网络端口。\n\n电气特性：定义了在线缆的各个引脚上传输信号时的电压范围、阻抗匹配、传输速率等。\n\n规定信号的标准，以确保接收方能正确解读。例如，规定 +5V 代表比特 1，0V 代表比特 0。如果电压标准不统一，就会导致信号的误判。\n\n功能特性：指明接口的各条信号线（引脚）的功能。\n\n这就像定义插座上哪个孔是火线，哪个是零线。例如，在网线中，规定哪几根线用于发送数据（TX），哪几根用于接收数据（RX）。\n\n规程特性：定义了利用信号线进行比特流传输的一系列操作流程和时序关系。\n\n这是对信号传输过程的规定，确保数据传输的同步和协调。例如，规定了建立连接、传输数据、断开连接时，信号变化的先后顺序。\n\n\n比特流的编码与表示\n\n计算机内部的数据是二进制的 0 和 1，物理层需要将这些抽象的比特转换成可以在物理介质上传输的物理信号（如电信号或光信号）, 这个过程称为编码 (Encoding)。\n直接用高低电平代表 1 和 0 的方式（称为不归零编码 NRZ）在长距离传输时容易出现时钟同步问题。因此，物理层采用更复杂的编码方式，如曼彻斯特编码 (Manchester Encoding)。\n\n数据传输速率（比特率）\n\n物理层规定了数据在信道上的传输速率，即每秒可以传输多少个比特（bits per second, bps）。\n传输速率受到物理介质、编码方式和信道带宽等多种因素的限制。物理层标准会明确定义一个网络所能支持的速率，例如 10 Mbps、100 Mbps、1 Gbps。\n物理层还必须确保发送方和接收方以相同的速率工作，这称为比特同步 (Bit Synchronization)。如果发送方以 100 Mbps 的速率发送，而接收方以 10 Mbps 的速率接收，数据就会丢失或出错。\n\n传输模式\n\n物理层定义了数据在两个设备之间传输的方向。\n\n单工 (Simplex)：数据只能在一个方向上传输。例如无线电广播、电视广播。你只能接收信号，不能发送信号给电视台。\n\n半双工 (Half-Duplex)：数据可以在两个方向上传输，但在同一时刻只能有一个方向在进行。例如对讲机。一方说话时，另一方只能听，不能同时说话。\n\n全双工 (Full-Duplex)：数据可以同时在两个方向上传输。例如电话通话。通话双方可以同时说话和倾听。\n\n\n物理层的常见设备和介质物理层是唯一一层涉及具体物理设备的层次。常见的传输介质有同轴电缆 (Coaxial Cable), 光纤 (Fiber Optic Cable)以及无线电波 (Radio Waves, 用于 Wi-Fi)等\n常见的物理层设备有中继器 (Repeater):对衰减的信号进行再生和放大，然后转发出去，从而延长网络的传输距离; 集线器 (Hub)：它将从一个端口接收到的信号放大后，广播到所有其他端口等\n第二层：数据链路层 (Data Link Layer)数据链路层位于物理层之上、网络层之下，扮演着一个至关重要的“承上启下”的角色。如果说物理层负责在一段物理介质上透明地传输比特流，那么数据链路层的核心任务就是：在同一个物理网络（即一个局域网或广播域）内的相邻节点之间，提供可靠的数据传输。\n\n从“比特”到“帧”：数据链路层接收来自网络层的数据包（Packet），并将其封装成一种称为“帧” (Frame) 的结构化数据单元。帧是数据链路层传输的基本单位。这个过程好比将一堆零散的货物（比特流）打包成一个个贴好标签、有明确边界的箱子（帧），便于管理和运输。\n\n节点到节点 (Node-to-Node)：它负责的是点对点或相邻节点之间的通信。例如，从你的电脑到你的路由器，或者从你的路由器到互联网服务提供商（ISP）的下一个设备。它不关心数据的最终目的地，只关心如何将数据可靠地送到链路上的下一个节点。\n\n提供服务给网络层：它向其上层（网络层）隐藏了物理层的复杂细节。网络层只需要将数据包交给数据链路层，并指定下一个节点的地址(MAC)，数据链路层就会负责将其变成帧，并通过物理层可靠地发送出去。\n\n\nMACMAC 地址（Media Access Control Address），中文全称为“媒体访问控制地址”，也被称为物理地址（Physical Address）或硬件地址（Hardware Address）。\n可以把它想象成网络设备的“身份证号码”。理论上，每一块出厂的网络接口卡（NIC，无论是你的电脑网卡、手机 Wi-Fi 芯片，还是路由器的端口）都有一个全球唯一的 MAC 地址。这个地址在设备生产时就被固化（烧录）在硬件中。\nMAC 地址具有全球唯一性，一个标准的 MAC 地址长度为 48 位（6 个字节）。用 12 个十六进制数 来表示，例如：00:1A:2B:3C:4D:5E。\n一个 MAC 地址由两部分组成：前 24 位称作组织唯一标识符（OUI, Organizationally Unique Identifier）。这是由 IEEE 分配给硬件制造商的。通过查询 OUI，你可以知道这个网络设备是由哪家公司生产的。例如，00:1A:2B 可能就代表苹果公司（Apple Inc.）。\n而后 24 位是网络接口标识符（NIC Specific）。这部分由制造商自行分配，确保其生产的每一个设备都有一个独一无二的编号。\nMAC 地址工作在 OSI 模型的第二层——数据链路层 (Data Link Layer)。它的核心功能是在同一个局域网（LAN）内部进行设备寻址和数据传输。\n五大核心功能为了实现节点间的可靠传输，数据链路层需要执行以下几个关键功能: \n\n封装成帧 (Framing)\n\n这是数据链路层的首要任务。它将来自网络层的 IP 数据包，在前后分别添加头部 (Header) 和尾部 (Trailer)，构成一个完整的帧。\n\n添加头部：头部通常包含源 MAC 地址和目的 MAC 地址，以及一些控制信息。这就像在包裹上贴上寄件人和收件人的本地地址。\n\n添加尾部：尾部通常包含差错校验码 (Frame Check Sequence, FCS)，例如循环冗余校验（CRC）码。\n\n帧定界 (Frame Delimiting)：为了让接收方知道一个帧从哪里开始、到哪里结束，数据链路层会使用特殊的比特模式作为帧的起始和结束标记。\n\n\n\n物理寻址 (Physical Addressing)\n\n数据链路层使用 MAC 地址来标识网络中的每一个设备（如网卡）。当一个设备要向同一局域网内的另一个设备发送数据时，它会在帧的头部填入自己的源 MAC 地址和对方的目的 MAC 地址。网络中的设备（如交换机）会根据这个目的 MAC 地址来决定将帧转发到哪个端口。这好比邮递员根据门牌号（MAC 地址）来投递信件。\n\n流量控制 (Flow Control)\n\n流量控制是为了防止发送速度过快的发送方淹没接收速度较慢的接收方，导致数据丢失。\n如果接收方的缓冲区已满，无法再处理更多的数据，它会通过数据链路层协议向发送方发送一个“暂停”信号。发送方收到信号后会暂停发送，直到接收方通知它可以继续发送。这确保了数据的平稳传输，避免了因接收方处理能力不足而造成的“数据溢出”。\n\n差错控制 (Error Control)\n\n由于物理线路上的噪声或其他干扰，比特流在传输过程中可能会出错（例如 1 变成 0）。差错控制就是为了检测并可能纠正这些错误。\n一般的步骤如下：\n\n差错检测 (Error Detection)：发送方在生成帧时，会根据帧的数据内容计算出一个校验码 (FCS/CRC) 并附加在帧的尾部。\n\n接收方收到帧后，会用同样的算法对接收到的数据进行计算，得出一个新的校验码。\n\n校验码比较：接收方将新计算的校验码与帧中包含的校验码进行比较。\n\n错误检测：如果两个校验码一致，说明数据在传输过程中没有出错，接收方就接受该帧。\n\n差错纠正 (Error Correction)：一些更高级的数据链路层协议（如在无线通信中）不仅能检测错误，还能通过重传机制来纠正错误。例如，如果接收方检测到错误，它可以请求发送方重新发送损坏的帧。\n\n\n\n介质访问控制 (Media Access Control)\n\n介质访问控制决定了在同一时刻哪个设备可以使用这个共享介质来发送数据, 这是为了解决“信道争用”和“冲突”的问题。如果两个设备同时在共享介质上发送数据，它们的信号会相互干扰，导致数据损坏，这就是冲突 (Collision)。\n常见的控制方式是CSMA/CD (Carrier Sense Multiple Access with Collision Detection), 即载波侦听多路访问/冲突检测，主要用于有线以太网。其主要策略有三点:\n\n先听后发：发送前先侦听信道是否空闲。\n\n边发边听：发送数据的同时继续侦听，以检测是否发生冲突。\n\n冲突后退：一旦检测到冲突，立即停止发送，并等待一个随机时间后重试。\n\n\n数据链路层的常见设备数据链路层最重要的设备就是交换机 (Switch), 称得上是现代局域网的核心设备。\n我们可以把交换机看做升级版的Hub. 它内部维护着一张 MAC 地址表，记录了每个 MAC 地址所连接的端口。\n当交换机从一个端口收到一个帧时，它会检查帧头部的目的 MAC 地址。然后，它会在 MAC 地址表中查找这个地址，并只将该帧从对应的端口精确地转发出去，而不是像集线器那样广播到所有端口。\n因此, 交换机能够隔离冲突域，每个端口都是一个独立的冲突域，从而极大地提高了网络效率和性能。\n第三层：网络层 (Network Layer)网络层位于数据链路层之上、传输层之下。如果说数据链路层负责的是局域网内部相邻节点之间的通信，那么网络层的核心任务就是：实现数据在不同网络之间的路由和转发，为数据从源主机到目的主机提供一条端到端的路径。\n\n全局视野：网络层是第一个具有全局网络视野的层次。它不再局限于单个局域网，而是要负责数据在整个互联网（由无数个局域网组成）中的传输路径。\n\n从“帧”到“包”：网络层处理的基本数据单元是“包” (Packet) 或“数据报” (Datagram)。它接收来自上层（传输层）的数据段（Segment），并为其添加一个网络层头部（Header），其中包含了关键的逻辑地址信息，从而构成了数据包。\n\n逻辑寻址 (Logical Addressing)：网络层引入了一套与物理地址（MAC 地址）完全不同的地址体系——逻辑地址，最典型的就是我们熟知的 IP 地址 (Internet Protocol Address)。IP 地址为网络中的每台主机提供了一个全局唯一的、分等级的地址。\n\n路由 (Routing)：这是网络层的核心功能。它负责根据目的主机的 IP 地址，通过特定的算法（路由协议）计算出一条从源到目的地的最佳路径，并指示数据包如何穿越一系列相互连接的网络。\n\n\n四大核心功能\n逻辑寻址 (Logical Addressing)\n\n为了在庞大的互联网中唯一地标识每一台主机，网络层定义了逻辑地址, 即IP地址。\n目前主要使用 IPv4 (32位地址，如 192.168.1.1) 和 IPv6 (128位地址)。IP 地址由两部分组成：\n\n网络部分 (Network ID)：标识主机所在的特定网络。\n\n\n因此，在不连接任何网络时，设备没有一个可以用来与外部通信的有效 IP 地址。\n\n\n主机部分 (Host ID)：标识该网络中的特定主机。\n\n当一台主机要向另一台主机发送数据时，它必须知道对方的 IP 地址。网络层会在数据包的头部封装上源 IP 地址和目的 IP 地址。这个目的 IP 地址就是数据包在整个旅程中的最终导航目标。\n\nMAC 地址是设备的固有属性，而一个能让设备与外界通信的 IP 地址，则是设备加入网络后获得的临时身份\n\n\n路由 (Routing)\n\n路由是网络层最复杂也最重要的功能，即为数据包选择最佳的传输路径。\n路由器 (Router)：执行路由功能的关键设备。路由器连接着两个或多个不同的网络，其内部维护着一张路由表 (Routing Table)。\n路由表：这张表记录了“要去往某个目的网络，应该从哪个接口出去，并将数据包交给下一个路由器”。路由表可以由管理员静态配置 (Static Routing)，也可以通过路由协议动态学习 (Dynamic Routing)。\n步骤说明（数据包的旅程）：\n\n源主机创建一个数据包，包含源/目的 IP 地址。\n\n数据包被发送到本地网络的默认网关（通常是一个路由器）。\n\n路由器收到数据包后，会查看其头部的目的 IP 地址。\n\n路由器在其路由表中查找与该目的 IP 地址最匹配的条目。\n\n根据路由表中的指示，路由器将数据包从正确的接口转发给下一个路由器。\n\n\n这个过程（查找路由表 -&gt; 转发）在路径上的每一个路由器上重复进行，直到数据包最终到达包含目的主机的那个局域网。这个过程被称为“逐跳转发” (Hop-by-Hop Forwarding)。\n\n数据包转发与分片 (Forwarding &amp; Fragmentation)\n\n转发 (Forwarding)：这是路由器根据路由表做出的具体动作，即将数据包从输入端口移送到正确的输出端口。\n分片 (Fragmentation)：数据链路层对可传输的帧大小有一个上限，称为最大传输单元 (Maximum Transmission Unit, MTU)。例如，以太网的 MTU 通常是 1500 字节。如果要传输的网络层数据包大于 MTU，网络层就需要将这个大数据包分片 (Fragment) 成多个较小的数据包，以便它们能够装入数据链路层的帧中。\n步骤说明：\n\n当路由器准备转发一个数据包时，它会检查出口网络的 MTU。\n\n如果数据包的大小超过了 MTU，路由器就会将其分割成多个更小的分片。\n\n每个分片都会被加上自己的网络层头部，并被独立地进行路由和转发。\n\n这些分片最终会在目的主机的网络层被重新组装成原始的数据包。\n\n\n\n拥塞控制与服务质量 (Congestion Control &amp; QoS)\n\n\n拥塞控制 (Congestion Control)：当网络中的数据包数量过多，超出路由器处理能力时，就会发生网络拥塞。网络层协议可以包含一些机制来检测和缓解拥塞，例如通知源主机降低发送速率。\n\n服务质量 (Quality of Service, QoS)：网络层可以为不同类型的数据包提供不同的服务优先级。例如，可以优先处理对延迟敏感的实时视频流数据，而不是普通的网页浏览数据。\n\n\n关键协议和设备路由器 (Router)：网络层的标志性设备。它的主要工作是连接不同的网络（如连接你的家庭局域网和互联网），并根据 IP 地址执行路由和转发。路由器能够隔离广播域，即一个网络中的广播消息不会被路由器转发到另一个网络，这对于大型网络的性能和安全至关重要。\nIP (Internet Protocol)：网际协议，是网络层的基石。它定义了数据包的格式（IP 头部）和地址方案，是目前互联网上使用最广泛的协议。它是一个无连接 (Connectionless) 的、不可靠 (Unreliable) 的协议，即它只负责尽力而为地转发数据包，不保证数据包一定能到达，也不保证按序到达。可靠性由上层（传输层）的 TCP 协议来保证。\nARP (Address Resolution Protocol)：地址解析协议。它负责将一个已知的 IP 地址解析为对应的 MAC 地址。虽然 ARP 协议在功能上连接了网络层和数据链路层，但通常被认为是网络层协议。\n路由协议 (Routing Protocols)：用于在路由器之间交换路由信息，动态地构建和维护路由表。常见的有 RIP, OSPF, BGP 等。\n第四层：传输层 (Transport Layer)传输层位于网络层之上、会话层之下，是网络协议栈中承上启下的关键一层。它在面向通信的底层（网络层及以下）和面向应用的上层之间架起了一座关键的桥梁。如果说网络层提供了主机到主机 (Host-to-Host) 的通信，那么传输层的核心任务就是：为运行在不同主机上的应用程序之间，提供端到端 (End-to-End) 的逻辑通信服务。\n\n端到端 (End-to-End)：这是传输层与网络层的根本区别。网络层只关心如何将数据包送到正确的主机IP地址，但它并不知道这个数据包具体应该由这台主机上的哪个应用程序（例如浏览器、QQ还是邮件客户端）来处理。传输层则负责将数据准确地送达到指定应用程序的“门口”。\n\n进程到进程 (Process-to-Process)：传输层的通信是应用程序进程之间的通信。它确保了源主机上一个应用程序发送的数据，能够被目的主机上正确的应用程序接收。\n\n逻辑通信 (Logical Communication)：传输层为应用程序之间建立了一条“逻辑”上的连接通道。应用程序可以认为它们之间有一条直接的、专用的通道在通信，而无需关心底层复杂的路由、转发等网络细节。\n\n\n五大核心功能\n端口寻址 (Port Addressing)\n\n为了区分一台主机上同时运行的多个网络应用程序，传输层引入了端口号 (Port Number) 的概念。这是一个 16 位的数字（范围从 0 到 65535），用于标识一个特定的应用程序进程。其主要分为下面三类:\n\n知名端口 (Well-known Ports)：0 - 1023，分配给特定的、标准的服务。例如，HTTP 服务的端口是 80，HTTPS 是 443，FTP 是 21。\n\n注册端口 (Registered Ports)：1024 - 49151。这是 IANA (Internet Assigned Numbers Authority) 分配的端口号，用于注册非标准服务。\n\n动态/私有端口 (Dynamic/Private Ports)：49152 - 65535，客户端程序通常会随机使用这个范围的端口。\n\n\n当传输层接收到来自上层应用的数据时，会为其封装上源端口号和目的端口号。目的主机上的传输层在收到数据后，会根据目的端口号，将数据递交给绑定在该端口上的应用程序。这个 (IP地址, 端口号) 的组合，称为套接字 (Socket)，它唯一地标识了网络中的一个通信端点(如162.105.146.10:80)。\n\n分段与重组 (Segmentation and Reassembly)\n\n来自上层应用的数据通常很大，不适合一次性在网络中传输。传输层负责将这些大数据块分割成更小的、易于管理和传输的数据段 (Segment)。\n\n分段 (Segmentation)：在发送端，传输层将应用层数据流切割成大小合适的数据段，并为每个数据段添加传输层头部（包含端口号、序列号等信息）。\n\n重组 (Reassembly)：在接收端，传输层根据数据段头部的序列号 (Sequence Number)，将接收到的多个数据段按照正确的顺序重新组合起来，恢复成原始的应用层数据流，再递交给上层应用。\n\n\n\n连接控制 (Connection Control)\n\n传输层可以提供两种不同模式的连接服务：面向连接和无连接。\n面向连接 (Connection-Oriented)：在数据传输之前，必须先在发送方和接收方之间建立一个专用的逻辑连接。传输结束后，再将连接释放。这种方式可靠性高。代表协议为TCP (Transmission Control Protocol)。\n而建立连接的过程, 最著名的就是 TCP 的三次握手 (Three-Way Handshake)。具体为: \n\nSYN：客户端向服务器发送一个 SYN (Synchronize) 包，请求建立连接。\n\nSYN-ACK：服务器收到请求后，回复一个 SYN-ACK (Synchronize-Acknowledge) 包，表示同意建立连接。\n\nACK：客户端收到服务器的同意后，再发送一个 ACK (Acknowledge) 包进行确认。至此，连接建立成功。\n\n\n无连接 (Connectionless)：发送数据之前不需要建立连接。发送方直接将数据段发送出去，每个数据段都是独立传输的，相互之间没有关联。这种方式简单、高效，但不可靠。代表协议为UDP (User Datagram Protocol)。\n\n流量控制 (Flow Control)\n\n与数据链路层类似，传输层也提供流量控制，但它是一个端到端的流量控制。目的是防止发送方发送数据的速度过快，导致接收方的缓冲区溢出。\n步骤说明 (以 TCP 为例)：TCP 使用滑动窗口 (Sliding Window) 机制来实现流量控制。接收端在确认报文中会告诉发送端自己当前还有多少可用的缓冲区空间（即接收窗口大小）; 发送方根据接收端反馈的窗口大小，来动态调整自己的发送速率。如果接收窗口为 0，发送方就会暂停发送，直到窗口更新。\n\n差错控制 (Error Control)\n\n网络层的 IP 协议是不可靠的，数据包在传输中可能丢失、损坏或失序。传输层（特指 TCP）负责提供端到端的差错控制，以确保数据的可靠性。\n其机制主要通过序列号 (Sequence Number)、确认号 (Acknowledgment Number) 和校验和 (Checksum) 来实现。步骤说明如下：\n\n差错检测：发送方和接收方都会计算数据段的校验和，以检测数据在传输过程中是否损坏。\n\n确认与重传：发送方为每个发出的数据段启动一个计时器; 接收方每收到一个正确的数据段，就会发送一个确认 (ACK) 消息; 如果发送方在计时器超时之前收到了 ACK，就知道该数据段已成功送达; 如果计时器超时仍未收到 ACK（可能数据段丢失或 ACK 丢失），发送方会重新发送 (Retransmit) 该数据段。\n\n确保有序：通过序列号，接收端可以检测出失序的数据段，并对其进行重新排序，保证交给应用层的数据是正确的顺序。\n\n\n第五层：会话层 (Session Layer)会话层位于传输层之上、表示层之下。它的核心任务是：负责建立、管理和终止不同主机上应用程序之间的会-话（Session），并提供对话控制和同步功能。\n\n超越连接，关注“会话”：传输层（如 TCP）负责建立和维护一条可靠的连接 (Connection)，但它不关心这条连接上进行的是什么样的交互。会话层则更进一步，它管理的是两个应用程序之间一次完整的交互过程，这个过程就被称为“会-话”。会话层就像一个会议主持人或对话管理者。它确保通信双方能够有序地进行对话，决定何时开始、谁先发言、如何交替、以及何时结束\n\n在现代的 TCP/IP 模型中，会话层的功能往往被简化，并直接整合到了应用层协议（如 HTTP）中。因此，它是一个在理论上很重要，但在实践中不那么独立的层次。\n三大核心功能\n会话管理 (Session Management)\n\n这是会话层最基本的功能，即负责在两个应用程序进程之间建立、维护和终止会话。\n\n建立会话 (Establishment)：当一个应用程序想要与另一个远程应用程序开始一次交互时，会话层会负责建立起一个会话通道。这不仅仅是建立一个传输连接，还可能包括用户认证、权限检查、协商交互参数等步骤。例如，在进行远程登录时，会话层会启动这个过程，验证用户名和密码，成功后才正式建立一个可供交互的会话。\n\n维护会话 (Maintenance)：在会话期间，会话层负责保持通信的稳定。即使底层的传输连接（如 TCP 连接）因网络问题瞬时中断，会话层也可以尝试自动重新连接，从而对上层应用保持会话的连续性，做到对底层问题透明。\n\n终止会话 (Termination)：当交互完成后，会话层负责“优雅地”关闭会话。它会确保所有正在进行的操作都已完成，数据都已同步，然后才释放相关资源。这避免了因突然中断连接而导致的数据不一致问题。\n\n\n\n对话控制 (Dialog Control)\n\n对话控制决定了两个应用程序之间的数据交换方式，即由哪一方在何时发送数据。\n会话层通过引入“令牌” (Token)的概念来管理对话。只有持有令牌的一方才能执行某个关键操作（如发送数据）。\n三种对话模式：\n\n单工 (Simplex)：数据只能从一方流向另一方，类似于广播。\n半双工 (Half-Duplex)：双方都可以发送数据，但不能同时进行。一方发送时，另一方必须接收。会话层通过令牌传递来控制发言权。\n全双工 (Full-Duplex)：双方可以随时同时发送和接收数据。在这种模式下，对话控制的作用较小。\n\n\n同步 (Synchronization)\n\n同步是会话层一个非常重要的功能，尤其是在传输大量数据时。它允许在数据流中插入“同步点” (Synchronization Points)或“检查点” (Checkpoints)。\n如果在数据传输过程中发生错误或中断（例如，一个包含 1000 页的文档在传输到第 800 页时网络中断了），同步功能可以使通信恢复到最后一个已确认的同步点，而无需从头开始重新传输所有数据。\n步骤说明：\n\n发送方在数据流中设置同步点（例如，每传输 100 页设置一个）。\n\n接收方每成功接收到一个同步点的数据，就会向发送方发送一个确认。\n\n如果传输中断，双方会协商从最后一个被成功确认的同步点开始，继续传输剩余的数据（从第 701 页开始，而不是第 1 页）。\n\n\n这对于大型文件传输、数据库事务等长时间的交互至关重要，极大地提高了传输效率和可靠性。\n\n我们之前经历的 SQL Session 便属于会话：当你连接到一个数据库时，你就建立了一个 SQL 会话。在这个会话中，你可以执行多个查询和事务。数据库系统会管理这个会话的状态、权限和事务的完整性，这正是会话层功能的体现。\n\n第六层：表示层 (Presentation Layer)表示层位于会话层之上、应用层之下，是处理数据“表示”问题的一个特殊层次。它的核心任务是：确保一个系统的应用层所发送的信息可以被另一个系统的应用层识别和理解。\n\n网络的“通用翻译官”：表示层的主要作用是解决不同系统之间数据表示方式的差异问题。因为不同的计算机体系结构、操作系统和编程语言可能会使用不同的内部数据格式。表示层负责将数据从发送方的“本地格式”转换为一种标准的、与平台无关的“网络通用格式”，然后在接收端再将这种通用格式转换回接收方的“本地格式”。\n\n关注数据的语法和语义：与下层只关心如何传输数据不同，表示层开始关心数据本身的语法（格式）和语义（含义）。它确保数据在传输过程中不会因为格式问题而导致意义的扭曲。\n\n服务提供者：它为上层（应用层）提供服务，使得应用层开发者可以专注于应用程序的逻辑，而不用担心数据的编码、加密或压缩等底层细节。\n\n\n在现代的 TCP/IP 模型中，表示层的功能通常也和会话层一样，被整合到了应用层协议中。例如，HTTP 协议自身会定义内容类型（Content-Type），浏览器则根据这个类型来决定如何解析和显示数据（如 HTML、JSON、JPEG 等），这实际上就是表示层在发挥作用。\n三大核心功能\n数据格式化与转换 (Data Formatting and Translation)\n\n这是表示层最核心的功能。它负责在不同系统的数据格式之间进行转换，确保通信双方对数据有相同的理解。其基本步骤如下:\n\n发送端：表示层获取来自应用层的数据（通常是发送方的内部格式），并将其转换（编码）成一种标准的、通用的网络数据格式（如 ASN.1 - Abstract Syntax Notation One）。\n\n传输：这些标准格式的数据通过网络传输到接收端。\n\n接收端：表示层接收到标准格式的数据，并将其转换（解码）成接收端应用层能够理解的内部格式。\n\n\n通过这个“编码-传输-解码”的过程，表示层屏蔽了不同系统间的格式差异，实现了异构系统之间的透明通信。\n\n数据加密与解密 (Data Encryption and Decryption)\n\n为了保证通信的安全性，表示层还负责对数据进行加密和解密，以防止数据在传输过程中被窃听或篡改。步骤说明：\n\n发送端：在数据发送到网络之前，表示层使用一个加密算法和一个密钥 (Key) 将原始的、可读的数据（明文）转换成不可读的密文。\n\n接收端：接收到密文后，表示层使用一个解密算法和相应的密钥将密文恢复成原始的明文数据，然后再递交给应用层。\n\n\n常见协议：SSL (Secure Sockets Layer) 或其后继者 TLS (Transport Layer Security) 协议通常被认为跨越了表示层和会话层。当你通过 HTTPS 访问网站时，你的浏览器和服务器之间的数据就是由 TLS 协议进行加密的，这正是表示层功能的体现。\n\n数据压缩与解压缩 (Data Compression and Decompression)\n\n为了减少网络传输的数据量，提高传输效率和节省带宽，表示层可以对数据进行压缩。步骤说明：\n\n发送端：表示层使用一种压缩算法（如 Lempel-Ziv 算法）来减少数据的比特数。\n\n接收端：在将数据交给应用层之前，表示层使用相应的解压缩算法将数据恢复到其原始形式。\n\n\n这对于传输大型文件、图片、视频等多媒体数据尤其有效。常见的压缩格式如 GZIP, JPEG, MPEG 等都体现了这一功能。\n第七层：应用层 (Application Layer)应用层是 OSI 模型的最顶层，也是距离最终用户最近的一层。它的核心任务是：直接为用户的应用程序提供网络通信服务，并作为用户与网络之间的接口。\n\n用户的网络门户：当你使用任何需要联网的软件时，无论是浏览器、电子邮件客户端、游戏还是文件共享程序，你都是在与应用层进行直接交互。应用层负责将你的操作（如点击一个链接、发送一封邮件）转换成网络协议可以理解的请求，并发起通信过程。\n\n协议的集合：应用层本身并不是一个单一的程序，而是一个包含了众多协议的集合。每个协议都是为了实现某种特定的应用功能而设计的。例如，浏览网页用 HTTP 协议，收发邮件用 SMTP 和 POP3 协议。\n\n封装的终点与起点：在发送数据时，应用层是数据封装过程的起点。应用程序产生的数据在这里被首次处理，并加上应用层协议的控制信息，然后向下传递给表示层。在接收数据时，应用层是数据解封装过程的终点。从下层传递上来的数据在这里被最终解析，并呈现给用户或应用程序。\n\n\n主要功能与常见协议与下层处理具体的数据传输细节不同，应用层的功能更加抽象和多样化，主要围绕着为应用程序提供服务展开。\n也就是说, 提供用户接口与服务是应用层最根本的功能。它定义了应用程序如何访问网络以及如何使用网络服务。\n应用层协议规定了请求和响应的格式、命令和参数。例如，HTTP 协议定义了 GET、POST 等请求方法，以及 200 OK、404 Not Found 等状态码。应用程序（如浏览器）必须按照这些规定来创建请求和解析响应。\n同时, 应用层包含了我们日常使用互联网时接触到的大部分协议：\n\nHTTP (Hypertext Transfer Protocol) / HTTPS (HTTP Secure)\n\n超文本传输协议，是构建万维网（World Wide Web）的基础。用于从 Web 服务器请求网页和数据，并在浏览器上显示。HTTPS 是其加密版本，提供了更安全的连接。\n\n端口：80 (HTTP), 443 (HTTPS)。\n\n\n\nFTP (File Transfer Protocol)\n\n文件传输协议，用于在客户端和服务器之间上传和下载文件。\n\n端口：20 (数据), 21 (控制)。\n\n\n\nDNS (Domain Name System)\n\n域名系统，是互联网的“电话簿”。负责将人类易于记忆的域名（如 www.google.com）解析成机器能够识别的 IP 地址（如 142.251.1.101）。\n\n端口：53。\n\n\n\nTelnet / SSH (Secure Shell)\n\n用于远程登录和管理服务器。Telnet 以明文传输数据，非常不安全。SSH 是其加密的替代品，提供了安全的远程命令行访问。\n\n端口：23 (Telnet), 22 (SSH)。\n\n\n\nDHCP (Dynamic Host Configuration Protocol)\n\n动态主机配置协议，用于网络中的设备自动获取 IP 地址、子网掩码、默认网关等网络配置信息。\n\n\n\n总的来说, 应用层是整个 OSI 模型的最终目的，它将底层的、复杂的数据传输能力，转化为丰富多彩、功能各异的应用程序和服务，直接呈现给最终用户。\n","categories":["web"],"tags":["web","computer network"]},{"title":"多进程并发和多线程并发","url":"/2025/10/02/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91/","content":"\n并发是指在单个CPU核心上，通过快速切换任务，使得多个任务看起来像在同时进行。并行是指在多个CPU核心上，多个任务真正在物理上同时进行。\n\n这两种都是经典的并发服务器设计模式，它们的核心目标相同：同时处理多个客户端请求, 实现并发处理, 提高服务器的吞吐量和响应速度。\n\n\n\n特性维度\n多进程模型 (Fork)\n多线程模型 (Pthread)\n\n\n\n基本单元\n进程 (Process)\n线程 (Thread)\n\n\n资源开销\n高。创建进程是重型操作，内存和CPU开销大，切换慢。\n低。创建线程是轻型操作，资源占用少，切换快。\n\n\n数据共享与通信\n困难。进程地址空间独立，通信需借助IPC（管道、共享内存等）。\n简单。所有线程共享同一地址空间（全局变量、堆、静态变量等）。\n\n\n稳定性与隔离性\n高。一个子进程崩溃不会影响父进程或其他子进程。\n低。任何一个线程的非法操作都可能导致整个进程崩溃。\n\n\n文件描述符\n独立。fork后父子进程各有独立的文件描述符表。\n共享。所有线程共享同一张文件描述符表，一个线程关闭会影响所有线程。\n\n\n编程模型与挑战\n编程相对简单，主要挑战在于进程间通信（IPC）的实现。\n编程更复杂，主要挑战在于处理线程安全和数据同步（如互斥锁）。\n\n\n并发能力\n受限于系统进程数上限，通常只能支持几百个并发连接。\n理论上可支持成千上万个并发连接，是高并发服务器的主流选择。\n\n\n多进程并发多进程并发服务器模型通过创建多个子进程来处理客户端请求。每当有新的客户端连接时，服务器会调用 fork() 系统调用创建一个新的子进程，这个子进程专门负责与该客户端进行通信和处理请求。父进程继续监听新的连接请求。\n基本流程如下：\n\n服务器启动，创建一个监听套接字 (listening socket)，绑定到指定端口，并开始监听连接请求。\n当有新的客户端连接时，服务器调用 fork() 创建一个新的子进程\n子进程继承父进程的资源（如文件描述符），并专门处理该客户端的请求。\n父进程继续监听新的连接请求，重复上述过程。\n子进程处理完客户端请求后，关闭连接并退出。\n父进程通过 wait() 或 waitpid() 回收子进程资源，防止僵尸进程(这里可以使用信号处理 SIGCHLD 来自动回收)。\n\n示例代码:\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/wait.h&gt;#include &lt;signal.h&gt;#include &lt;errno.h&gt;#define PORT 8888#define BUFFER_SIZE 1024/* * 信号捕捉函数，用于回收子进程 * 这是处理 SIGCHLD 信号的回调函数 */void recycle_child(int signum) {    // 使用 while 循环和 waitpid 是为了处理多个子进程在短时间内同时结束的情况    // WNOHANG 选项表示非阻塞，如果没有已退出的子进程，则立即返回，不会卡住    while (waitpid(-1, NULL, WNOHANG) &gt; 0) {        printf(\"A child process has been recycled.\\n\");    }}int main() {    int lfd, cfd; // lfd: 监听文件描述符; cfd: 连接文件描述符    struct sockaddr_in serv_addr, cli_addr;    socklen_t cli_addr_len;    pid_t pid;    char buf[BUFFER_SIZE];    int n;    // 1. 创建监听套接字    lfd = socket(AF_INET, SOCK_STREAM, 0);    if (lfd == -1) {        perror(\"socket error\");        exit(1);    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(lfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定IP地址和端口    // bzero(&amp;serv_addr, sizeof(serv_addr)); // bzero 已不推荐使用，改用 memset    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(PORT);    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 监听本机所有IP地址    if (bind(lfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) == -1) {        perror(\"bind error\");        exit(1);    }    // 3. 设置监听上限    if (listen(lfd, 128) == -1) {        perror(\"listen error\");        exit(1);    }    // 4. 注册 SIGCHLD 信号捕捉函数，用于回收子进程    struct sigaction sa;    sa.sa_handler = recycle_child;    sigemptyset(&amp;sa.sa_mask);    sa.sa_flags = SA_RESTART; // 自动重启被信号中断的系统调用    if (sigaction(SIGCHLD, &amp;sa, NULL) == -1) {        perror(\"sigaction error\");        exit(1);    }        printf(\"Server is running on port %d, waiting for connections...\\n\", PORT);    // 5. 主循环，接收客户端连接    while (1) {        cli_addr_len = sizeof(cli_addr);        cfd = accept(lfd, (struct sockaddr *)&amp;cli_addr, &amp;cli_addr_len);        if (cfd == -1) {            // 如果是被信号中断，则继续 accept，否则报错退出            if (errno == EINTR) {                continue;            } else {                perror(\"accept error\");                exit(1);            }        }                // 打印客户端连接信息        char client_ip[16];        inet_ntop(AF_INET, &amp;cli_addr.sin_addr.s_addr, client_ip, sizeof(client_ip));        printf(\"Received connection from %s at port %d\\n\", client_ip, ntohs(cli_addr.sin_port));        // 6. 创建子进程        pid = fork();        if (pid &lt; 0) {            perror(\"fork error\");            exit(1);        }                 // 7. 子进程的工作        else if (pid == 0) {             // 子进程不需要监听，关闭监听文件描述符            close(lfd);                         while ((n = read(cfd, buf, sizeof(buf))) &gt; 0) {                // 将接收到的数据转换为大写                for (int i = 0; i &lt; n; i++) {                    buf[i] = toupper(buf[i]);                }                // 将处理后的数据写回客户端                write(cfd, buf, n);            }            if (n == 0) {                printf(\"Client %s closed the connection.\\n\", client_ip);            } else if (n &lt; 0) {                perror(\"read error\");            }                        // 关闭连接描述符，并退出子进程            close(cfd);            exit(0);         }                 // 8. 父进程的工作        else {            // 父进程不需要与客户端通信，关闭连接文件描述符            close(cfd);             // 继续循环，等待下一个客户端连接            // 子进程的回收由信号处理函数完成, 无需在这里调用 wait()        }    }        // 关闭监听描述符（实际上主循环是死循环，代码不会执行到这里）    close(lfd);    return 0;}\n\n多线程并发多线程并发服务器模型通过创建多个线程来处理客户端请求。每当有新的客户端连接时，服务器会创建一个新的线程，这个线程专门负责与该客户端进行通信和处理请求。主线程继续监听新的连接请求。\n基本流程如下：\n\n服务器启动，创建一个监听套接字 (listening socket)，绑定到指定端口，并开始监听连接请求。\n当有新的客户端连接时，服务器创建一个新的线程，这个线程专门处理该客户端的请求\n主线程继续监听新的连接请求，重复上述过程。\n\n#include &lt;stdio.h&gt;  #include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;pthread.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;errno.h&gt;#define PORT 8888#define BUFFER_SIZE 1024// 线程处理函数void* handle_client(void* arg) {    int cfd = *(int*)arg; // 获取连接文件描述符    free(arg); // 释放动态分配的内存    char buf[BUFFER_SIZE];    int n;    while ((n = read(cfd, buf, sizeof(buf))) &gt; 0) {        // 将接收到的数据转换为大写        for (int i = 0; i &lt; n; i++) {            buf[i] = toupper(buf[i]);        }        // 将处理后的数据写回客户端        write(cfd, buf, n);    }    if (n == 0) {        printf(\"Client closed the connection.\\n\");    } else if (n &lt; 0) {        perror(\"read error\");    }    close(cfd); // 关闭连接描述符    return NULL; // 线程退出}int main() {    int lfd, cfd; // lfd: 监听文件描述符; cfd: 连接文件描述符    struct sockaddr_in serv_addr, cli_addr;    socklen_t cli_addr_len;    pthread_t tid;    // 1. 创建监听套接字    lfd = socket(AF_INET, SOCK_STREAM, 0);    if (lfd == -1) {        perror(\"socket error\");        exit(1);    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(lfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定IP地址和端口    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(PORT);    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 监听本机所有IP地址    if (bind(lfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) == -1) {        perror(\"bind error\");        exit(1);    }    // 3. 设置监听上限    if (listen(lfd, 128) == -1) {        perror(\"listen error\");        exit(1);    }    printf(\"Server is running on port %d, waiting for connections...\\n\", PORT);    // 4. 主循环，接收客户端连接    while (1) {        cli_addr_len = sizeof(cli_addr);        cfd = accept(lfd, (struct sockaddr *)&amp;cli_addr, &amp;cli_addr_len);        if (cfd == -1) {            // 如果是被信号中断，则继续 accept，否则报错退出            if (errno == EINTR) {                continue;            } else {                perror(\"accept error\");                exit(1);            }        }        // 打印客户端连接信息        char client_ip[16];        inet_ntop(AF_INET, &amp;cli_addr.sin_addr.s_addr, client_ip, sizeof(client_ip));        printf(\"Received connection from %s at port %d\\n\", client_ip, ntohs(cli_addr.sin_port));        // 动态分配内存保存连接文件描述符，传递给线程函数        int* p_cfd = malloc(sizeof(int));        *p_cfd = cfd;        // 创建线程处理客户端请求        if (pthread_create(&amp;tid, NULL, handle_client, p_cfd) !=            0) {            perror(\"pthread_create error\");            close(cfd);            free(p_cfd);            continue;        }        // 分离线程，避免僵尸线程        pthread_detach(tid);        // 主线程继续监听新的连接请求    }    // 关闭监听描述符（实际上主循环是死循环，代码不会执行到这里）    close(lfd);    return 0;}","categories":["web","language","C++"],"tags":["web","C++"]},{"title":"函数参数反序入栈","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%87%BD%E6%95%B0/%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E5%8F%8D%E5%BA%8F%E5%85%A5%E6%A0%88/","content":"函数参数反序入栈，也称为从右至左参数压栈，指的是在调用一个函数时，传递给该函数的参数不是按照代码中从左到右的顺序，而是从右到左的顺序依次被推入（push）到程序的调用栈（Call Stack）中。\n这是一种由**调用约定（Calling Convention）**规定的行为。最常见的采用这种方式的调用约定是 cdecl，它是 C 和 C++ 程序的默认调用约定。\n为什么需要反序入栈？你可能会觉得从左到右的顺序更符合直觉，为什么大多数语言（如C/C++）会选择这种看起来“奇怪”的反序方式呢？最核心的原因是为了支持可变参数函数（Variadic Functions）。\n可变参数函数是指那些可以接受不定数量参数的函数，最典型的例子就是 C 语言中的 printf 和 scanf 函数。\n让我们来看一个 printf 的调用：\nprintf(\"Name: %s, Age: %d, Score: %.2f\\n\", \"Alice\", 20, 95.5);\n\n这个 printf 函数调用了4个参数。但 printf 函数本身在被编译时，并不知道它未来会被多少个参数调用。它唯一能确定的就是第一个参数，即格式化字符串 (“Name: %s, Age: %d, Score: %.2f\\n”)。\n函数需要通过解析这个格式化字符串来确定后面还有多少个、以及分别是什么类型的参数。\n如果采用顺序（从左到右）入栈：\n\n栈底(高位)\npush “Name: %s, Age: %d, Score: %.2f\\n”\npush “Alice”\npush 20\npush 95.5 (栈顶(低位))\n\n在这种情况下，当 printf 函数开始执行时，它能直接访问到的栈顶元素是 95.5。它无法直接定位到最重要的格式化字符串，因为格式化字符串被压在栈的深处，其具体位置依赖于后面参数的数量，而这个数量本身又是未知的, 这使得函数无法确定读取参数读到哪里停止。\n如果采用反序（从右到左）入栈（实际情况）：\n\npush 95.5\npush 20\npush “Alice”\npush “Name: %s, Age: %d, Score: %.2f\\n”\n\n在这种情况下，当 printf 函数开始执行时，无论后面有多少个参数，格式化字符串始终位于栈的固定、可预测的位置（紧邻着函数返回地址的上方）。函数可以轻松地访问到这个字符串，通过解析它（发现 %s, %d, %.2f），就能准确地知道接下来需要从栈上读取一个字符串指针、一个整数和一个浮点数。\n因此，反序入栈确保了函数的第一个（或固定）参数的位置是确定的，这为实现可变参数函数提供了基础。\n"},{"title":"线程池","url":"/2025/09/25/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"","categories":["web","system"],"tags":["web"]},{"title":"内存分区","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%88%86%E5%8C%BA/","content":"程序的内存布局 (Process Memory Layout)一个程序运行起来后，操作系统会为其分配一块虚拟内存空间。这块空间在逻辑上通常分为以下几个部分：\n\n栈 (Stack)：\n\n用途：用于存储函数的局部变量（也叫临时变量）、函数参数、返回地址等。\n\n特点：由编译器自动分配和释放。内存区域通常较小，且向下增长（即从高地址向低地址扩展）。每个线程都有自己独立的栈。\n\n\n\n堆 (Heap)：\n\n用途：用于程序运行时动态分配的内存，例如通过 new (C++) 或 malloc (C) 创建的对象。\n\n特点：由程序员手动分配和释放（delete/free）。空间较大，向上增长。\n\n\n\n静态/全局存储区 (Static/Global Storage Area)：\n\n这块区域用于存储全局变量和静态变量，生命周期与整个程序相同。它内部又细分为两个子区域：\n\n.data 段 (Initialized Data Segment)：存储已初始化且初始值不为0的全局变量和静态变量。\n\n.bss 段 (Uninitialized Data Segment)：存储未初始化或初始化为0的全局变量和静态变量。\n\n\n\n\n这部分内存在程序加载到内存时就已经分配好了，并且在程序的整个生命周期内都不会改变位置。因此，无论你何时访问一个全局变量，它的内存地址都是同一个。\n\n\n\n常量存储区 (Constant Storage Area / .rodata)：\n\n用途：存储字符串字面量和被 const 修饰的常量。\n\n特点：只读（Read-Only）。\n\n\n\n代码段 (Code Segment / .text)：\n\n用途：存储程序的可执行二进制指令。\n\n特点：只读且可共享。\n\n\n\n\n变量在内存中的分布全局/静态变量 vs. 临时变量: 全局变量和静态变量的内存地址是固定的，但临时变量的内存地址，往往不是固定的。”\n为什么全局/静态变量地址固定: 因为它们被存储在静态/全局存储区（.data 或 .bss 段）。这部分内存在程序加载到内存时就已经分配好了，并且在程序的整个生命周期内都不会改变位置。因此，无论你何时访问一个全局变量，它的内存地址都是同一个。\n为什么临时变量（局部变量）地址不固定: 因为它们被存储在**栈 (Stack)**上。当一个函数被调用时，系统会在栈顶为这个函数创建一个“栈帧”（Stack Frame），用来存放它的局部变量。当函数执行完毕返回时，这个栈帧就会被销毁。\n如果你在一个循环中多次调用同一个函数，那么每次调用时，该函数内的局部变量都会在一个新的栈帧中被创建，其内存地址也因此会不一样。如果函数发生递归调用，同样会创建多个栈帧，局部变量的地址也各不相同。\n静态变量与全局变量的相似性和差异性: 静态变量，除了作用域跟全局变量有所差异外，其存储原则、生命周期跟全局变量类似。”\n\n相似点：存储原则和生命周期\n\n存储位置：它们都存储在静态/全局存储区（.data 或 .bss）。\n\n生命周期：它们的生命周期都是整个程序的运行期间。从程序开始执行时被创建，到程序结束时才被销毁。即使是定义在函数内部的静态局部变量（static local variable），它也只会被初始化一次，并且在函数调用结束后其值会一直保留，不会被销毁。\n\n\n\n差异点：作用域 (Scope)\n\n全局变量 (Global Variable)：作用域是整个程序，可以被多个源文件通过 extern 关键字访问（除非被 static 修饰成文件作用域）。\n\n静态变量 (Static Variable)：\n\n静态全局变量（在函数外定义）：作用域被限制在定义它的单个源文件内，其他文件无法访问。\n\n静态局部变量（在函数内定义）：作用域被限制在定义它的函数或代码块内，但其生命周期依然是整个程序。\n\n\n\n\n\n\n未初始化/零初始化变量与 .bss 段: 无论是全局变量还是静态变量，如果它们没有被初始化，或者被初始化为 0，都会被安置在未初始化数据段(.bss)，一定程度上可以节省二进制文件 a.out 的存储空间。\n这是一个非常巧妙的编译器和加载器优化。对于 .data 段中的变量（例如 int global_var = 100;），值 100 必须被实际地保存在可执行文件（如 a.out）中，因为它是一个非零的特定值。这会占用文件的体积。\n但对于 .bss 段，可执行文件只需要记录这个段的总大小，而不需要存储所有这些0。当操作系统加载程序时，它会读取 .bss 段的大小，然后在内存中分配相应大小的区域，并自动将其全部填充为零。\n因此，一个拥有大量未初始化或零初始化全局/静态变量的程序，其可执行文件的大小可以显著减小，因为这些“零”并没有被实际存储在文件中，而是由加载器在运行时“创造”出来的。\n"},{"title":"shared_ptr与weak_ptr","url":"/2025/09/27/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/shared_ptr%E4%B8%8Eweak_ptr/","content":"std::shared_ptr：共享所有权的管理者std::shared_ptr 是一种拥有共享所有权的智能指针。这意味着多个 shared_ptr 实例可以共同拥有和管理同一个动态分配的对象。当最后一个指向该对象的 shared_ptr 被销毁或重置时，该对象会被自动释放。\n核心理念：引用计数shared_ptr 的核心机制是引用计数（Reference Counting）。它通过一个“控制块”来实现这一机制。\n控制块（Control Block）是一个与被管理对象分离的内存块, 存储在堆上。当第一个 shared_ptr 创建时，控制块也随之被创建。它包含以下关键信息：\n\n强引用计数（Strong Reference Count）：记录有多少个 shared_ptr 正指向同一个对象。\n弱引用计数（Weak Reference Count）：记录有多少个 weak_ptr 正在“观察”这个对象。\n指向被管理对象的指针。\n（可选）自定义删除器的指针。\n\n一般来说, 引用计数和控制块的工作流程如下：\n\n当一个新的 shared_ptr 创建或通过拷贝构造或拷贝赋值指向一个已有对象时，强引用计数 +1。\n当一个 shared_ptr 被销毁（例如离开作用域）、被重置（reset()）或指向其他对象时，强引用计数 -1。\n当强引用计数变为 0 时，shared_ptr 会自动调用删除器（默认为 delete）来释放被管理的对象。\n当弱引用计数和强引用计数都变为 0 时，控制块本身才会被释放。\n\n这种引用计数的加减还是线程安全的：shared_ptr 的引用计数增减操作是原子的，这意味着在多线程环境下，仅对 shared_ptr 对象本身进行拷贝、赋值和销毁是线程安全的，不会导致引用计数出错。但它并不保护被管理对象本身，如果多线程要修改对象内容，仍需手动加锁。\n创建 shared_ptr函数模板 std::make_shared 的函数原型如下:\nnamespace std {    template &lt;typename T, typename... Args&gt;    std::shared_ptr&lt;T&gt; make_shared(Args&amp;&amp;... args);}\nT是要指向的对象的类型, args是传给T这个类构造函数的参数（如果有的话）。\n#include &lt;memory&gt;    // 存放智能指针相关#include &lt;iostream&gt;class MyClass {public:    MyClass() { std::cout &lt;&lt; \"MyClass 构造\" &lt;&lt; std::endl; }    ~MyClass() { std::cout &lt;&lt; \"MyClass 析构\" &lt;&lt; std::endl; }    void greet() { std::cout &lt;&lt; \"Hello!\" &lt;&lt; std::endl; }};int main() {    // 推荐方式：使用 std::make_shared    // 优点：1. 更高效（对象和控制块一次性分配内存） 2. 异常安全    std::shared_ptr&lt;MyClass&gt; sp1 = std::make_shared&lt;MyClass&gt;();        // 不太推荐的方式：使用 new, 虽然最终也能通过shared_ptr安全管理, 但是会分两次（一次 new T()，一次为控制块）分配内存    std::shared_ptr&lt;MyClass&gt; sp2(new MyClass());     auto sp3 = sp1; // 直接拷贝构造    // 创建完毕后, 这两个指针指向的对象都在堆上, 控制块也在堆上}\n对于std::shared_ptr, 还有一些需要了解但是不太常用的接口: \n\n通过 get() 方法来获取原始指针，适用于和旧版C语言库等只接受原始指针的接口交互\n通过 reset() 来减少一个强引用计数， 适用于提前终止对资源的管理\n通过use_count()来查看一个对象的引用计数。\n\n共享所有权// 创建一个 shared_ptrstd::shared_ptr&lt;MyClass&gt; sp1 = std::make_shared&lt;MyClass&gt;();std::cout &lt;&lt; \"sp1 创建后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 1{    // sp2 通过拷贝 sp1 创建    std::shared_ptr&lt;MyClass&gt; sp2 = sp1;    std::cout &lt;&lt; \"sp2 创建后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 2        sp2-&gt;greet(); // 可以像普通指针一样使用} // sp2 在这里离开作用域并被销毁std::cout &lt;&lt; \"sp2 销毁后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 1// sp1 在 main 函数结束时销毁，引用计数变为0，MyClass 对象被析构\n\n优点：\n\n自动管理内存，有效防止内存泄漏。\n易于使用，可以像普通指针一样操作。\n明确了资源的“共享所有权”语义。\n\n但是, 如果只使用std::shared_ptr, 会存在一个难以察觉的陷阱: 循环引用（Circular Reference）, 这是 shared_ptr 最大的问题，也是 weak_ptr 存在的原因。\n循环引用（Circular Reference）如下是一个双向链表的实现代码\n#include &lt;iostream&gt;#include &lt;memory&gt;struct Node {    int value;    // 错误的方式：前后指针都使用 shared_ptr    std::shared_ptr&lt;Node&gt; next;    std::shared_ptr&lt;Node&gt; prev;    Node(int v) : value(v) {        std::cout &lt;&lt; \"构造函数: Node(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }    ~Node() {        std::cout &lt;&lt; \"析构函数: ~Node(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }};void create_leaky_list() {    std::cout &lt;&lt; \"--- 进入 create_leaky_list 函数 ---\" &lt;&lt; std::endl;        // 创建两个节点    auto node1 = std::make_shared&lt;Node&gt;(10); // Node(10) 的强引用计数为 1    auto node2 = std::make_shared&lt;Node&gt;(20); // Node(20) 的强引用计数为 1    // 将它们互相连接，形成双向链表    node1-&gt;next = node2; // Node(20) 的强引用计数变为 2 (来自 node2 和 node1-&gt;next)    node2-&gt;prev = node1; // Node(10) 的强引用计数变为 2 (来自 node1 和 node2-&gt;prev)        std::cout &lt;&lt; \"连接后, Node(10) 的引用计数: \" &lt;&lt; node1.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"连接后, Node(20) 的引用计数: \" &lt;&lt; node2.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"--- 准备离开 create_leaky_list 函数 ---\" &lt;&lt; std::endl;}int main() {    create_leaky_list();    std::cout &lt;&lt; \"\\n--- create_leaky_list 函数已结束 ---\" &lt;&lt; std::endl;    std::cout &lt;&lt; \"程序即将退出，检查是否有析构函数被调用...\" &lt;&lt; std::endl;    return 0;}\n当 create_leaky_list 函数结束时，栈上的 node1 和 node2 两个 shared_ptr 指针变量被销毁(指向的堆上的对象并没有)。node1 销毁，导致 Node(10) 的强引用计数从 2 降为 1。但不为 0，因为 Node(20)-&gt;prev 仍然指向它; node2 销毁，导致 Node(20) 的强引用计数从 2 降为 1。但不为 0，因为 Node(10)-&gt;next 仍然指向它。\n最终结果是, 由于两个节点(对象)的强引用计数都无法归零，它们的析构函数永远不会被调用，导致它们所占用的内存无法被释放。\nstd::weak_ptr：打破循环引用的观察者std::weak_ptr 是一种非拥有型的智能指针。它像一个“观察者”，可以指向一个由 shared_ptr 管理的对象，但不会增加对象的强引用计数。\n也就是说, 这种指针是一种弱引用:\n\nweak_ptr 的存在不会影响对象的生命周期。它只是监视对象是否存在。\n它指向与 shared_ptr 相同的控制块，并通过创建和销毁来增减控制块中的弱引用计数。\n你不能直接通过 weak_ptr 访问对象（没有 * 或 -&gt; 操作符），因为对象可能随时被销毁。\n\n创建 weak_ptr 和访问对象（核心操作：lock()）weak_ptr 只能从 shared_ptr 或另一个 weak_ptr 构造, 而不能构造一个来指向某个新对象\nstd::shared_ptr&lt;int&gt; sp = std::make_shared&lt;int&gt;(10);std::weak_ptr&lt;int&gt; wp = sp; // 从 shared_ptr 创建\n\nweak_ptr 最重要的函数是 lock()。它会安全地检查被观察对象是否存在：\n\n如果对象仍然存在，lock() 会返回一个指向该对象的有效的 shared_ptr，并使对象的强引用计数 +1。\n如果对象已被销毁，lock() 会返回一个空的 shared_ptr。\n\n这种“检查并获取”的模式是原子操作，保证了线程安全。\nstd::weak_ptr&lt;MyClass&gt; weak_p;{    std::shared_ptr&lt;MyClass&gt; shared_p = std::make_shared&lt;MyClass&gt;();    weak_p = shared_p; // weak_p 观察 shared_p 管理的对象    // 尝试从 weak_p 获取一个 shared_ptr    if (auto sp_temp = weak_p.lock()) { // 看是否能够成功获取        std::cout &lt;&lt; \"对象仍然存在, 可以安全访问。\" &lt;&lt; std::endl;        sp_temp-&gt;greet();    }} // shared_p 在此销毁, MyClass 对象也被析构// MyClass 对象已被析构, weak_p无指向, 再次尝试 lock会失败if (auto sp_temp = weak_p.lock()) {    // 这段代码不会执行} else {    std::cout &lt;&lt; \"对象已被销毁, 无法访问。\" &lt;&lt; std::endl;}\n\n还有个常用的函数: std::weak_ptr::expired(), 用于判断当前 weak_ptr 是否已经失效，也就是它所观察的对象是否已经被销毁。如果返回 true, 表示对象已经被销毁，weak_ptr 不再指向有效资源; 返回 false则表示对象仍然存在，可以尝试通过 lock() 获取一个有效的 shared_ptr。\n结合起来上面的代码还可以修改为:\nif (!weak_ptr.expired()) {    weak_ptr.lock()-&gt;greet();} else {    std::cout &lt;&lt; \"对象已被销毁, 无法访问。\" &lt;&lt; std::endl;}\n\n解决循环引用只需将循环引用链中的任意一环从 shared_ptr 改为 weak_ptr 即可。通常，我们会选择从属关系中的“子”指向“父”的指针(在双向链表中通常是 prev 指针)改为 weak_ptr。\n#include &lt;iostream&gt;#include &lt;memory&gt;struct CorrectNode {    int value;    std::shared_ptr&lt;CorrectNode&gt; next;    // 解决方案：将 prev 指针改为 weak_ptr    std::weak_ptr&lt;CorrectNode&gt; prev;    CorrectNode(int v) : value(v) {        std::cout &lt;&lt; \"构造函数: CorrectNode(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }    ~CorrectNode() {        std::cout &lt;&lt; \"析构函数: ~CorrectNode(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }};void create_correct_list() {    std::cout &lt;&lt; \"--- 进入 create_correct_list 函数 ---\" &lt;&lt; std::endl;    auto node1 = std::make_shared&lt;CorrectNode&gt;(10); // Node(10) 强引用 = 1    auto node2 = std::make_shared&lt;CorrectNode&gt;(20); // Node(20) 强引用 = 1    node1-&gt;next = node2; // Node(20) 强引用 = 2    node2-&gt;prev = node1; // Node(10) 强引用不变，仍为 1 (因为 prev 是 weak_ptr)    std::cout &lt;&lt; \"连接后, Node(10) 的引用计数: \" &lt;&lt; node1.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"连接后, Node(20) 的引用计数: \" &lt;&lt; node2.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"--- 准备离开 create_correct_list 函数 ---\" &lt;&lt; std::endl;}int main() {    create_correct_list();    std::cout &lt;&lt; \"\\n--- create_correct_list 函数已结束 ---\" &lt;&lt; std::endl;    std::cout &lt;&lt; \"程序即将退出，检查是否有析构函数被调用...\" &lt;&lt; std::endl;    return 0;}\n当 create_correct_list 函数结束时，栈上的 node1 和 node2 被销毁。因为 node1 销毁，Node(10) 的强引用计数从 1 降为 0。Node(10) 对象被析构, 导致其成员 next（一个指向 Node(20) 的 shared_ptr）被销毁。这导致 Node(20) 的强引用计数从 2 降为 1。\n随后，node2 销毁，Node(20) 的强引用计数从 1 降为 0。Node(20) 对象被析构。最终结果是, 所有节点都被正确地、依次地销毁。\n总结对比\n\n\n特性\nstd::shared_ptr\nstd::weak_ptr\n\n\n\n所有权\n拥有（共享所有权）\n不拥有（观察者）\n\n\n引用计数\n创建/销毁/拷贝会改变强引用计数\n创建/销毁/拷贝会改变弱引用计数\n\n\n生命周期\n它的存在会延长对象的生命周期\n不影响对象的生命周期\n\n\n直接访问\n可以，通过 * 和 -&gt; 操作符\n不可以\n\n\n安全访问方式\n直接使用\n必须调用 lock() 获取一个临时的 shared_ptr\n\n\n主要用途\n管理具有共享所有权的动态资源\n1. 打破 shared_ptr 的循环引用2. 实现缓存系统3. 观察者模式\n\n\n如何创建\nstd::make_shared 或从原始指针构造\n从 shared_ptr 或其他 weak_ptr 构造\n\n\n智能指针这种技术并不新奇，在很多语言中都是一种常见的技术，现代 C++ 将这项技术引进，在一定程度上消除了 new/delete 的滥用，是一种更加成熟的编程范式。\n"},{"title":"unique_ptr与auto_ptr","url":"/2025/09/28/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/unique_ptr%E4%B8%8Eauto_ptr/","content":"std::unique_ptr 同样是 C++11 中引入的，用于表示对动态分配对象的独占所有权（Exclusive Ownership）。\nstd::unique_ptr：独占所有权的轻量级管理者与 shared_ptr 的“共享”理念完全相反，unique_ptr 遵循“独裁”模式：在任何时刻，只能有一个 unique_ptr 指向并拥有一个给定的对象。当这个 unique_ptr 被销毁或重置时，它所拥有的对象也会被立即销毁。\n独占所有权 (Exclusive Ownership): 一个资源（内存、文件句柄等）的生命周期由唯一的 unique_ptr 控制。这从根本上杜绝了“谁该删除指针”的混乱问题，所有权模型非常清晰。\n轻量级与高性能 (Lightweight &amp; High-Performance): unique_ptr 是一个零成本抽象（Zero-cost Abstraction）。它内部没有引用计数，也没有控制块。在大多数情况下，一个 unique_ptr 的大小与一个原始指针完全相同。且它的操作（如访问成员）与操作原始指针一样快，没有任何额外的性能开销。\n不可拷贝，但可移动 (Non-copyable, but Movable): 为了保证所有权的“独占性”，unique_ptr 删除了拷贝构造函数和拷贝赋值运算符。你不能像 shared_ptr 那样简单地复制它。\nstd::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();// std::unique_ptr&lt;MyClass&gt; ptr2 = ptr1; // 紧张拷贝构造, 编译错误！\n不过它拥有移动构造函数和移动赋值运算符。这意味着所有权可以被转移（Transfer）。一旦所有权被转移，原来的 unique_ptr 将变为空指针 (nullptr)。\nstd::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();std::unique_ptr&lt;MyClass&gt; ptr2 = std::move(ptr1); // 正确，所有权从 ptr1 转移到 ptr2// 此后，ptr1 等于 nullptr，ptr2 拥有对象\n\n如何使用首先是创建 unique_ptr (推荐使用 std::make_unique, C++14 中引入)\n#include &lt;memory&gt;class MyClass { /* ... */ };// 推荐方式 (C++14 及以后)// 优点：代码简洁、异常安全std::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();// C++11 的方式std::unique_ptr&lt;MyClass&gt; ptr2(new MyClass());\n\n所有权的转移是 unique_ptr 的核心操作模式，最常见的场景是从函数返回。\nstd::unique_ptr&lt;MyClass&gt; create_widget() {    // 在函数内部创建对象, 对象在堆上    // ...    // 直接返回 unique_ptr，所有权被自动“移动”给调用者    return std::make_unique&lt;MyClass&gt;(); }void process_widget(std::unique_ptr&lt;MyClass&gt; widget) {    // 这个函数通过移动接收了 widget 的所有权    // ...} // 函数结束，widget 在此被销毁，其管理的对象也被销毁int main() {    std::unique_ptr&lt;MyClass&gt; my_widget = create_widget(); // 从工厂函数接收所有权, 因为unique_ptr不可拷贝且移动更高效, 所以直接移动给了my_widget        my_widget-&gt;do_something();        process_widget(std::move(my_widget)); // 将所有权转移给 process_widget 函数        // 此后，main 函数中的 my_widget 变为 nullptr    // if (my_widget == nullptr) { /* ... */ } }\n这里在create_widget()函数中, return 语句返回一个临时创建的对象（在例子中是 std::make_unique 的结果）时，这个临时对象被视为一个右值（rvalue）。当用一个右值来初始化一个新的对象时（例如 my_widget = create_widget()），编译器会优先选择使用移动构造函数，而不是拷贝构造函数。\n通过返回值和 std::move，unique_ptr 实现了清晰、安全的所有权在不同作用域之间的传递\n\n现代 C++ 编译器通常会做得更极致。它们会使用一种叫做“返回值优化”的技术。在这种情况下，编译器会发现 create_widget 内部创建的指针最终会进入 main 函数的 my_widget 中，于是它会省略掉中间的“移动”步骤，直接在 my_widget 的内存位置上构造那个 unique_ptr。从外部看，就好像 create_widget 函数直接把对象变到了 main 函数里一样。\n\n此外, 还有一些其他函数:\n\n访问：像普通指针一样使用 * 和 -&gt;。\n获取原始指针：使用 get() 方法，规则和风险与 shared_ptr 的 get() 类似。\n释放所有权：调用 release() 方法。它会放弃所有权并返回原始指针，但不会删除对象。调用者需要手动管理返回的指针。\n重置：调用 reset() 方法。它会销毁当前拥有的对象，并可以选择性地接管一个新的对象。\n\n高级特性unique_ptr 比看起来更灵活，它支持两个强大的高级特性: \n自定义删除器 (Custom Deleters)\n与 shared_ptr 不同，unique_ptr 的删除器类型是其自身类型的一部分。这使得它仍然是零开销的，但不同删除器类型的 unique_ptr 是不同的类型。这使得 unique_ptr 非常适合用于管理任何需要配对操作的资源，完美实践 RAII（资源获取即初始化）。\n管理C风格的文件句柄#include &lt;cstdio&gt;// 自定义删除器结构体, 也可以是其他可调用对象如函数, lambda表达式, 封装的std::functionstruct FileCloser {    void operator()(FILE* file) const {        if (file) {            fclose(file);            std::cout &lt;&lt; \"文件已关闭。\" &lt;&lt; std::endl;        }    }};// 使用 using 让类型名更简洁using UniqueFilePtr = std::unique_ptr&lt;FILE, FileCloser&gt;;   // 将删除器这个可调用对象也传入int main() {    // fopen 返回 FILE*，我们立即将其所有权交给 unique_ptr    UniqueFilePtr file_ptr(fopen(\"test.txt\", \"w\"));    if (file_ptr) {        fputs(\"Hello, unique_ptr!\", file_ptr.get());    }    } // main 结束，file_ptr 被销毁，它的自定义删除器 FileCloser::operator() 会被自动调用，fclose(file) 得以执行\n\n数组支持\nunique_ptr 对动态分配的数组有特殊的重载版本，使用时需要加上 []。\n\n创建：std::make_unique&lt;T[]&gt;(size)\n析构：它会自动调用 delete[] 而不是 delete，这是正确的数组内存释放方式。\n访问：它重载了 operator[] 来访问数组元素，但没有 * 和 -&gt;。\n\n// 创建一个包含 10 个整数的动态数组std::unique_ptr&lt;int[]&gt; arr_ptr = std::make_unique&lt;int[]&gt;(10);// 通过 operator[] 访问元素for (int i = 0; i &lt; 10; ++i) {    arr_ptr[i] = i * i;}// arr_ptr 离开作用域时，会自动调用 delete[] arr_ptr.get();\n\n黄金法则：默认使用 std::unique_ptr。在现代 C++ 中，当你需要动态分配内存时，unique_ptr 应该是你的第一选择。它的所有权模型清晰，性能无损，完全符合 RAII 思想。何时使用 unique_ptr？\n\n当你需要一个指向动态对象的指针，并且该对象的生命周期应该与这个指针的作用域绑定时。\n作为工厂函数的返回值，安全地将新创建对象的所有权转移出去。\n在类中作为成员，管理一个只属于该类实例的资源（例如，PIMPL 模式的实现）。\n\n只有当你明确需要共享一个资源的所有权，即多个独立的观察者都需要延长该资源的生命周期时，才应该“升级”到使用 std::shared_ptr。\nstd::auto_ptr什么是auto_ptr? 真不熟\n\nstd::auto_ptr 是 std::unique_ptr 的祖先, 它在 C++11 中被不推荐使用（deprecated），并在 C++17 中被彻底移除, 完全被std::unique_ptr代替。\n\n"},{"title":"面向对象","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":""},{"title":"模板","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E6%A8%A1%E6%9D%BF/","content":"模板的哲学在于将一切能够在编译期处理的问题丢到编译期进行处理，仅在运行时处理那些最核心的动态服务，进而大幅优化运行期的性能。\n外部模板外部模板（extern template） 是一种向编译器发出的指令，用于阻止编译器在当前翻译单元（也就是当前的 .cpp 文件）中隐式地实例化一个模板。它告诉编译器：“不必在此处生成这个模板的完整代码，我向你保证，它的代码会在其他某个地方被生成，链接器（Linker）最终会找到它。”\n它的主要，也是唯一的目标，就是减少编译时间和避免代码冗余。\nC++ 模板的默认工作方式要理解 extern template 的用处，首先必须了解 C++ 模板的默认工作方式，以及它带来的问题\n当你在代码中使用一个模板时，比如 std::vector，编译器会自动为你生成 std::vector 模板针对 int 类型特化的所有代码。这个过程叫做隐式实例化。\n问题在于，如果你的项目中有多个 .cpp 文件都包含了  头文件，并且都使用了 std::vector，那么编译器会在每一个使用它的 .cpp 文件中都生成一份完整的 std::vector 的代码。\n\na.cpp 使用了 std::vector -&gt; 编译器在 a.o 中生成一份 std::vector 的代码。\nb.cpp 使用了 std::vector -&gt; 编译器在 b.o 中也生成一份 std::vector 的代码。\nc.cpp 使用了 std::vector -&gt; 编译器在 c.o 中又生成一份 std::vector 的代码。\n……\n\n显然, 这样重复生成同样的代码，不仅浪费了编译时间，还会导致生成的目标文件（.o 文件）体积膨胀，链接器最终只会选择一个模板而丢弃多余的模板.o文件, 最终影响链接时间和可执行文件的大小。\n解决方案：extern template 与 显式实例化 组合拳为了解决上述问题，C++11 提供了 extern template 关键字，允许你显式地告诉编译器在哪个翻译单元中实例化模板，而在其他翻译单元中则不进行实例化。\n\n选择一个地方进行显式实例化: 我们创建一个专门的 .cpp 文件（例如 templates.cpp），或者在某个主要的 .cpp 文件中，来统一管理模板的实例化。\n\n// templates.cpp#include &lt;vector&gt;#include &lt;string&gt;// 显式实例化定义：强制编译器在此处生成代码template class std::vector&lt;int&gt;;template class std::vector&lt;std::string&gt;;\n\n在其他地方使用 extern template: 在所有其他需要使用这些模板的 .cpp 文件中，使用 extern template 来告诉编译器不要在这些文件中实例化模板。\n\n// a.cpp#include &lt;vector&gt;extern template class std::vector&lt;int&gt;; // 告诉编译器不要在这里实例化void foo() {    std::vector&lt;int&gt; vec; // 使用 std::vector&lt;int&gt;，但不实例化}\n\n变长模板参数在 C++11 之前，无论是类模板还是函数模板，都只能按其指定的样子， 接受一组固定数量的模板参数；而 C++11 加入了新的表示方法， 允许任意个数、任意类别的模板参数，同时也不需要在定义时将参数的个数固定。\n核心语法变长模板的核心是一个名为 “参数包” (Parameter Pack) 的概念，其语法中使用了省略号 …\n\n模板参数包 (Template Parameter Pack): 用于声明一个可以接收零个或多个模板参数的包。\n\ntemplate &lt;typename... Args&gt; // Args 就是一个模板参数包class MyTuple {};\n\n\n函数参数包 (Function Parameter Pack): 用于声明一个可以接收零个或多个函数参数的包。\n\ntemplate &lt;typename... Args&gt;void my_printf(const char* format, Args... args) { // args 就是一个函数参数包    // ...}\n\n\n包展开 (Pack Expansion): 这是使用参数包的关键。你不能像遍历数组一样直接访问包中的每一个参数，而是需要通过“展开”的方式来一次性地处理它们, 通过在参数包后面加上省略号 …，可以将参数包展开成多个独立的参数。\n\ntemplate &lt;typename... Args&gt;void my_printf(const char* format, Args... args) {    printf(format, args...); // 展开 args 包, args...将变为&lt;arg1, arg2, arg3, ...&gt;    // 这会被展开成 printf(format, arg1, arg2, arg3, ...);}\n\n\n获取包的大小: 可以使用 sizeof…(PackName) 运算符来获取参数包中的参数数量\n\ntemplate &lt;typename... Args&gt;void print_num_args(Args... args) {    std::cout &lt;&lt; \"Number of arguments: \" &lt;&lt; sizeof...(args) &lt;&lt; std::endl;}\n\n如何使用参数包（包展开技巧）既然不能直接迭代，我们该如何处理包里的每一个参数呢？主要有以下几种方法，从经典到现代。\n方法一：递归函数（经典方式）\n这是C++11中最常用、最基础的展开方式。它包含两个部分：\n\n一个处理包中第一个元素，并用剩余元素递归调用自身的递归函数。\n一个用于终止递归的同名基本函数（当参数包为空时调用）。\n\n#include &lt;iostream&gt;// 3. 当参数包为空时，调用这个基本版本，终止递归void print() {    std::cout &lt;&lt; std::endl;}// 1. 递归模板函数template&lt;typename T, typename... Args&gt;  // 这里为了使得参数至少有一个, 显式指定了第一个参数 Tvoid print(T first, Args... rest) {    // 2. 处理包中的第一个参数    std::cout &lt;&lt; first &lt;&lt; \" \";    // 递归调用 print，传入剩余的参数包    print(rest...); // rest... 在这里被展开}int main() {    print(1, 2.3, \"hello\", 'c'); // 输出: 1 2.3 hello c}// 编译器的展开过程大致如下：// print(1, 2.3, \"hello\", 'c');// -&gt; std::cout &lt;&lt; 1 &lt;&lt; \" \"; print(2.3, \"hello\", 'c');// -&gt; std::cout &lt;&lt; 2.3 &lt;&lt; \" \"; print(\"hello\", 'c');// -&gt; std::cout &lt;&lt; \"hello\" &lt;&lt; \" \"; print('c');// -&gt; std::cout &lt;&lt; 'c' &lt;&lt; \" \"; print(); // 调用基本版本，递归结束\n\n方法二：使用 if constexpr 简化递归（C++17）\nC++17 的 if constexpr 可以在编译期进行判断，使得我们可以将递归函数和基本函数合二为一，代码更简洁。\n#include &lt;iostream&gt;template&lt;typename T, typename... Args&gt;void print_cpp17(T first, Args... rest) {    std::cout &lt;&lt; first &lt;&lt; \" \";    // 如果 rest 包中还有参数 (sizeof...(rest) &gt; 0)    if constexpr (sizeof...(rest) &gt; 0) {        print_cpp17(rest...); // 递归调用    } else {        std::cout &lt;&lt; std::endl; // 所有参数处理完毕，打印换行    }}int main() {    print_cpp17(1, 2.3, \"hello\", 'c');}\n\n方法三：折叠表达式（C++17，最现代、最推荐）\n对于很多常见的操作（如求和、打印），C++17 提供了折叠表达式 (Fold Expressions)，这是一种极其简洁的包展开语法。\n#include &lt;iostream&gt;#include &lt;string&gt;// 使用折叠表达式求和template&lt;typename... Args&gt;auto sum(Args... args) {    return (args + ...); // 对所有参数执行 operator+}// 使用折叠表达式打印，利用逗号运算符template&lt;typename... Args&gt;void print_fold(Args... args) {    // ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...); 的展开过程大致是：    // (std::cout &lt;&lt; arg1 &lt;&lt; \" \"), (std::cout &lt;&lt; arg2 &lt;&lt; \" \"), ...    // 逗号运算符会依次执行每个表达式    ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...);    std::cout &lt;&lt; std::endl;}int main() {    std::cout &lt;&lt; sum(1, 2, 3, 4, 5) &lt;&lt; std::endl; // 输出 15    print_fold(1, 2.3, \"hello\", 'c');             // 输出 1 2.3 hello c }\n\n折叠表达式(Fold Expressions)折叠表达式的本质，是提供一种极其简洁的语法，来将一个二元操作符 (binary operator)，例如 +, *, &amp;&amp;, ||, , 等，重复地应用于参数包中的所有元素。\n想象一下你想对一包数字 1, 2, 3, 4 求和，你实际上想计算的是 1 + 2 + 3 + 4。折叠表达式就是让你能够直接表达这个意图的工具。\n折叠表达式一共有四种形式，它们在结合性（从左到右还是从右到左计算）和是否提供初始值方面有所不同。\n假设我们有一个参数包 pack，包含元素 E1, E2, E3, … En，以及一个二元操作符 op。\n\n\n\n形式\n语法\n展开形式\n结合性\n\n\n\n一元右折叠\n(pack op ...)\nE1 op (E2 op (E3 op E4))\n右结合\n\n\n一元左折叠\n(... op pack)\n(((E1 op E2) op E3) op E4)\n左结合\n\n\n二元右折叠\n(pack op ... op init)\nE1 op (E2 op (E3 op (E4 op init)))\n右结合\n\n\n二元左折叠\n(init op ... op pack)\n((((init op E1) op E2) op E3) op E4)\n左结合\n\n\n\n一元折叠 (Unary Folds)：不提供显式的初始值。\n\n二元折叠 (Binary Folds)：提供一个显式的初始值 init。\n\n… 与 pack 的位置决定了展开的顺序（结合性）, … 在 pack 右边是右折叠，在 pack 左边是左折叠。\n\n\n实例深度解析\n求和\n\ntemplate&lt;typename... Args&gt;auto sum(Args... args) {    // return (args + ...); // 一元左折叠。如果调用 sum()，编译会失败。    return (args + ... + 0); // 二元右折叠，更安全！    // 或者 return (0 + ... + args); // 二元左折叠，效果相同}// sum(1, 2, 3, 4, 5) 展开为:// 二元右折叠: (1 + (2 + (3 + (4 + (5 + 0)))))// 二元左折叠: (((((0 + 1) + 2) + 3) + 4) + 5)\n\n\n打印\n\ntemplate&lt;typename... Args&gt;void print_fold(Args... args) {    ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...);  // 一元左折叠}\n\n操作符 op：这里是逗号操作符 ,。\n表达式：std::cout &lt;&lt; args &lt;&lt; “ “ 是应用到参数包 args 中每个元素 arg 上的表达式。\n形式：这是一元右折叠 (pack op …)。\n展开过程：假设调用 print_fold(1, “hi”, 3.0)，它会展开成：((std::cout &lt;&lt; 1 &lt;&lt; “ “), (std::cout &lt;&lt; “hi” &lt;&lt; “ “), (std::cout &lt;&lt; 3.0 &lt;&lt; “ “))\n\n逗号操作符的特性是“计算左边的表达式，丢弃其结果，然后计算右边的表达式，并返回其结果”。由于C++保证逗号操作符的求值顺序是从左到右的，尽管是右折叠, 依旧完美地实现了按顺序打印每一个元素\n\n完美转发与函数调用折叠表达式可以极大地简化对参数包中每个元素执行同一操作的场景，例如将所有参数完美转发给另一个函数。\n\n#include &lt;vector&gt;#include &lt;utility&gt;// 一个将所有参数 push_back 到 vector 的函数template&lt;typename T, typename... Args&gt;void push_all(std::vector&lt;T&gt;&amp; vec, Args&amp;&amp;... args) {    // 对每个参数，调用 vec.push_back，并用逗号操作符连接    (vec.push_back(std::forward&lt;Args&gt;(args)), ...);}int main() {    std::vector&lt;int&gt; v;    push_all(v, 1, 2, 3, 4, 5); // v 中现在是 {1, 2, 3, 4, 5}}"},{"title":"PIMPL","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/PIMPL/","content":"PIMPL (Pointer to Implementation) - 指向实现的指针, 也被称为“编译防火墙 (Compilation Firewall)”或“不透明指针 (Opaque Pointer)”。它的核心思想是将类的私有成员和私有方法从头文件中完全移除，放到一个独立的、只在 .cpp 文件中定义的实现类（Impl）中。头文件里只保留一个指向该实现类的指针。\n通过将类的接口与其实现细节分离，可以解决以下问题：\n\n降低编译依赖，大幅加快编译速度：这是 PIMPL 最主要的目的。通常，如果一个类的头文件包含了其他头文件（例如 , ），那么任何包含了这个类头文件的 .cpp 文件，都会间接地依赖那些头文件。当你修改类的私有成员时（比如把 std::vector 换成 std::list），所有包含了该类头文件的文件都必须重新编译。在大型项目中，这可能意味着几分钟甚至几十分钟的编译时间。使用 PIMPL 后，所有实现细节和依赖的头文件都转移到了 .cpp 文件中。你修改私有实现时，只需要重新编译这个类自己的 .cpp 文件，链接器会处理好剩下的事情，从而极大地提升了编译效率。\n\n隐藏实现细节：头文件只暴露公有接口，所有内部数据结构、使用的第三方库等都被完全隐藏。这对于发布二进制库（SDK）的开发者来说非常有用。\n\n提供稳定的ABI (Application Binary Interface)：只要公有接口不变，你就可以在不破坏ABI兼容性的前提下，随意修改 Impl 类的内部实现（增删私有成员）。这意味着用户无需重新编译他们的代码，就可以直接使用新版本的动态库/静态库。\n\n\n假设我们有一个 Widget 类, 没有使用 PIMPL的情况如下：\n// Widget.h#pragma once#include &lt;string&gt; // 编译依赖#include &lt;vector&gt; // 编译依赖class Widget {public:    Widget();    void do_something();private:    std::string m_name;    std::vector&lt;int&gt; m_data;    // 任何包含 Widget.h 的文件都会被迫包含 &lt;string&gt; 和 &lt;vector&gt;    // 修改任何私有成员，所有包含者都需重编};\n使用 PIMPL 的版本 (After):\n// Widget.h#pragma once#include &lt;memory&gt; // 只需要包含智能指针class Widget {public:    Widget();    ~Widget(); // 关键：必须在头文件中声明析构函数    // 移动构造和移动赋值（可选，但推荐）    Widget(Widget&amp;&amp;);    Widget&amp; operator=(Widget&amp;&amp;);        // 拷贝构造和拷贝赋值（如果需要）    Widget(const Widget&amp;);    Widget&amp; operator=(const Widget&amp;);    void do_something();private:    class Impl; // 关键：前向声明实现类，不需要知道它的细节    std::unique_ptr&lt;Impl&gt; m_pimpl; // 关键：一个指向实现的指针};\n\n// Widget.cpp#include \"Widget.h\"#include &lt;string&gt;   // 实现所依赖的头文件只在这里包含#include &lt;vector&gt;   // 不会暴露给外部#include &lt;iostream&gt;// 关键：在这里完整定义实现类 Implclass Widget::Impl {public:    void do_something_impl() {        std::cout &lt;&lt; \"Doing something with \" &lt;&lt; m_name &lt;&lt; std::endl;        m_data.push_back(1);    }private:    std::string m_name;    std::vector&lt;int&gt; m_data;};// 关键：构造函数和析构函数必须在 Impl 类完全定义之后再定义Widget::Widget() : m_pimpl(std::make_unique&lt;Widget::Impl&gt;()) {}// 关键：析构函数必须在这里定义，否则 std::unique_ptr 会因为 Impl 类型不完整而出错Widget::~Widget() = default; // 其他成员函数只是简单地将调用转发给 Impl 对象void Widget::do_something() {    m_pimpl-&gt;do_something_impl();}// 移动和拷贝构造/赋值也需要在这里实现Widget::Widget(Widget&amp;&amp;) = default;Widget&amp; Widget::operator=(Widget&amp;&amp;) = default;// 拷贝构造需要深拷贝Widget::Widget(const Widget&amp; other)     : m_pimpl(std::make_unique&lt;Impl&gt;(*other.m_pimpl)) {} Widget&amp; Widget::operator=(const Widget&amp; other) {    if (this != &amp;other) {        *m_pimpl = *other.m_pimpl;    }    return *this;}\n从中我们可以看到，Widget 类的头文件中不再包含任何实现细节和依赖的头文件。所有私有成员都被移到了 Impl 类中，并且 Impl 类只在 Widget.cpp 中定义。 这样，当我们修改 Impl 类的私有成员时，只有 Widget.cpp 需要重新编译，其他包含 Widget.h 的文件不受影响，从而大大提升了编译效率\n总之, PIMPL 是一种设计模式，它利用 RAII 技术来管理其实现对象的生命周期。在我们的 PIMPL 示例中，std::unique_ptr m_pimpl; 就是这种关系的体现。std::unique_ptr 是一个 RAII 包装器, 它包装的资源是堆上分配的 Impl 对象。当 Widget 对象被销毁时，它的成员 m_pimpl 也会被销毁。m_pimpl 的析构函数会自动 delete 它所拥有的 Impl 对象，完美地实现了资源的自动管理。\n"},{"title":"Structures","url":"/2025/09/28/system/OS/Structures/Structures/","content":"操作系统服务与接口这部分主要介绍了操作系统（OS）为用户和系统本身提供的核心功能，以及用户与操作系统交互的方式。\n操作系统服务 (Operating System Services)操作系统提供的服务可以从两个角度来看：为用户提供便利和确保系统高效运行。\n面向用户的服务：\n\n用户界面 (User Interface)：几乎所有操作系统都提供用户界面，主要包括命令行界面（CLI）、图形用户界面（GUI）和批处理界面（Batch） 。\n\n程序执行 (Program Execution)：系统必须能够将程序加载到内存中并运行，以及正常或异常地终止程序 。\n\nI/O 操作 (I/O Operations)：运行中的程序可能需要与文件或 I/O 设备进行交互 。\n\n文件系统操作 (File-system Manipulation)：程序需要创建、删除、读写文件和目录，并管理其权限 。\n\n通信 (Communications)：允许进程之间交换信息，无论是在同一台计算机上（通过共享内存）还是跨网络（通过消息传递） 。\n\n错误检测 (Error Detection)：操作系统需要持续监控硬件和软件中可能发生的错误，并采取适当措施确保系统稳定 。\n\n\n面向系统的服务 ：\n\n资源分配 (Resource Allocation)：当多个用户或任务同时运行时，必须为它们分配 CPU 时间、内存、文件存储等资源 。\n\n记录 (Accounting)：跟踪记录用户使用的资源类型和数量 。\n\n保护与安全 (Protection and Security)：保护是确保所有对系统资源的访问都受控制 ；安全则是通过用户身份验证等手段，防止外部非法访问 。\n\n\n用户操作系统接口 (User Operating System Interface)用户主要通过以下两种方式与操作系统交互：\n\n命令行界面 (CLI)：允许用户直接输入命令来执行操作 。它的实现有时在内核中，有时由一个名为 “shell” 的系统程序提供 。\n\n图形用户界面 (GUI)：提供了一个用户友好的桌面环境，用户通过鼠标、键盘与图标、窗口等图形元素交互 。GUI 的概念最早由施乐帕克研究中心（Xerox PARC）发明 。\n\n\n许多现代操作系统（如 Windows, macOS）同时提供这两种接口 。\n系统调用 (System Calls)系统调用是操作系统提供给程序的编程接口。它们允许用户级程序请求内核执行特权操作，如文件操作、进程控制和设备管理 。\n程序通常不直接使用系统调用，而是通过高级语言的应用程序编程接口 (API)，如 Windows 的 Win32 API 或类 UNIX 系统的 POSIX API 。API 库函数（如 C 语言的 printf）在内部会调用相应的系统调用（如 write）来完成任务 。\n实现机制：每个系统调用都有一个唯一的编号。当程序调用一个 API 时，该 API 会将对应的系统调用编号和参数传递给操作系统。操作系统通过一个表来查找并执行内核中相应的代码 。这个过程对程序员是透明的 。\n参数传递：将参数从用户程序传递给内核有三种主要方法 ：\n通过 \n寄存器 传递（最简单，但数量有限） 。\n将参数存在内存的 \n块或表 中，然后将该块的地址通过寄存器传递（Linux 和 Solaris 采用此法） 。\n将参数压入 \n栈 中，由操作系统从栈中弹出 。\n系统调用类型：系统调用根据功能可分为几大类，如进程控制、文件管理、设备管理、信息维护、通信和保护 。\n操作系统设计与结构这部分探讨了操作系统设计的核心原则和几种主流的内部结构模型。\n设计与实现原则 (Design and Implementation)设计目标：需要平衡用户目标（易用、可靠、快速）和系统目标（易于设计、实现和维护） 。\n策略与机制分离 (Separation of Policy and Mechanism)：这是一个非常重要的设计原则 。\n机制 (Mechanism)：定义 如何 去做某件事（例如，提供一个定时器来限制 CPU 使用） 。\n策略 (Policy)：决定 要做什么（例如，决定一个进程可以使用 CPU 多长时间） 。\n将两者分离可以使系统更加灵活，因为改变策略（如访问权限）时无需修改底层机制（如门禁卡系统） 。\n操作系统结构 (Operating System Structure)简单结构 (Simple Structure)：如 MS-DOS，功能模块之间没有明确的划分，接口和功能层次不清晰，目标是在最小的空间内提供最多的功能 。\n分层方法 (Layered Approach)：将操作系统划分为多个层次，每一层都建立在更低层次之上 。最底层是硬件（第0层），最高层是用户界面（第N层） 。\nUNIX 结构：被认为是 宏内核 (Monolithic) 结构 。其内核包含了文件系统、CPU 调度、内存管理等几乎所有的核心功能 。\n微内核 (Microkernel)：将尽可能多的功能从内核态移到用户态 。内核只保留最基本的功能，如进程间通信、内存管理和 CPU 调度。\n优点：更可靠、更安全、易于扩展和移植 。\n缺点：用户态和内核态之间的通信会带来性能开销 。\n模块化 (Modules)：大多数现代操作系统采用此方法 。它使用面向对象的方法，将内核划分为多个独立的核心组件，这些组件通过明确的接口相互通信，并且可以根据需要在内核中动态加载 。这种结构比分层方法更灵活 。\n其他结构：\nExokernel：一种极简内核，只负责安全地分配硬件资源，将所有硬件抽象都交给用户空间的库来管理 。性能高但开发难度大 。\nUnikernel：将应用程序与所需的操作系统库静态链接，形成一个单一、专门的启动镜像 。非常适合云服务，启动速度极快 。\n高级概念与系统启动这部分介绍了虚拟化技术以及操作系统的生成与启动过程。\n虚拟机 (Virtual Machines)虚拟机是分层方法的一种逻辑延伸，它将硬件和操作系统内核视为一个整体，并在此之上模拟出多个独立的、与底层硬件接口完全相同的虚拟计算机 。\n优点：\n完全隔离：每个虚拟机都与其他虚拟机隔离，提供了极高的系统资源保护 。\n开发与研究：是操作系统研究和开发的理想平台，因为可以在虚拟机上进行开发而不影响物理主机的正常运行 。\n实现：通过一个名为 虚拟机监视器 (Hypervisor) 的软件层来共享物理计算机的资源，为每个虚拟机创建出独立的处理器和内存的假象 。\n操作系统生成与启动 (OS Generation and System Boot)系统生成 (SYSGEN)：操作系统通常被设计为可以在一类机器上运行，因此需要通过一个名为 SYSGEN 的程序来配置系统，以适应特定计算机的硬件配置 。\n系统引导 (System Boot)：\n定义：指通过加载内核来启动计算机的过程 。\n引导程序 (Bootstrap Program)：一段存储在只读存储器（ROM）或固件中的小程序 。\n过程：当计算机通电时，硬件会从一个固定的内存地址开始执行引导程序。该程序负责定位操作系统内核，将其加载到内存中，然后开始执行内核，从而完成系统的启动 。\n","categories":["system","OS"],"tags":["system"]},{"title":"类型转换","url":"/2025/09/30/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/","content":"C++ 的类型转换分为两大类：隐式类型转换和显式类型转换\n隐式类型转换 (Implicit Type Conversion)隐式类型转换是由编译器自动进行的，无需程序员显式指定。这通常发生在以下几种情况：\n\n算术转换 (Arithmetic Conversion)：在混合类型的算术表达式中，较小的类型会被提升（promote）为较大的类型以保证精度。\n\n// 例如：int 和 double 运算时，int 会被自动转换为 double。int i = 5;double d = 3.14;double result = i + d; // i 被隐式转换为 double 5.0，然后与 3.14 相加\n\n\n赋值转换 (Assignment Conversion)：将一个类型的值赋给另一个类型的变量时。\n\n// 在此处，double 类型转换为 int 类型，会丢失精度，这是一种潜在的数据丢失风险。int i;double d = 9.8;i = d; // d 的值被截断，小数部分丢失，i 的值为 9\n\n\n指针转换 (Pointer Conversion)：派生类的指针或引用可以被隐式转换为基类的指针或引用。这是支持多态性的基础。\n\nclass Base {};class Derived : public Base {};Derived* p_derived = new Derived();Base* p_base = p_derived; // 派生类指针隐式转换为基类指针Base* p_base2 = new Derived(); // 更多时候，直接 new 一个派生类对象赋给基类指针\n\n显式类型转换 (Explicit Type Conversion)显式类型转换，也称为强制类型转换（Casting），是程序员明确要求的转换。C++ 从 C 语言继承了强制转换的语法，并增加了四个功能更明确、更安全的转换操作符。\nC 风格强制转换 (C-Style Cast)这是从 C 语言继承来的语法，有两种形式：\n\n(new_type)expression\nnew_type(expression)\n\nint a = 10;int b = 4;double result = (double)a / b; // 将 a 转换为 double，结果为 2.5\nC 风格转换的缺点在于它过于强大和不安全，可能会执行多种不同类型的转换（如 static_cast、const_cast、reinterpret_cast），这使得代码难以理解和维护。\n\n过于粗暴：C 风格的转换符像一把“万能钥匙”，它会依次尝试 static_cast、const_cast、reinterpret_cast，直到找到一个可以工作的。这使得它的行为难以预测，可能会执行一些非常危险的转换。\n\n意图不明：当你在代码中看到一个 C 风格转换时，你很难一眼看出程序员的真实意图。他是想进行一个安全的数值转换，还是想进行一个危险的指针类型重解释？\n\n难以搜索：在大型项目中，想要找出所有的类型转换是非常困难的，因为 () 符号在代码中太常见了。而 C++ 的 *_cast 关键字则非常容易搜索。\n\n\nC++ 风格转换操作符C++ 引入了四个新的转换操作符，它们的功能更具体，意图更明确，也更安全。\nstatic_cast(expression): 用于“良性”或“合理”的转换，其正确性在编译时检查就可以确定。它是最常用的转换操作符。\n\n相关类型之间的转换：如数值类型之间的转换（int 到 double）、void* 指针与其他类型指针之间的转换。\n\n类层次结构中的转换：\n\n上行转换（安全）：将派生类的指针或引用转换为基类的指针或引用（与隐式转换相同）。\n下行转换（不安全）：将基类的指针或引用转换为派生类的指针或引用, 由于这属于多态, 而static_cast不进行运行时检查, 因此这需要程序员自己保证转换是安全的，即基类指针确实指向一个派生类对象。\n\n\n\n// 1. 基本类型转换double d = 3.14;int i = static_cast&lt;int&gt;(d); // i 的值为 3// 2. 类层次结构转换 (下行转换)class Base { public: virtual ~Base() {} };class Derived : public Base {};Base* p_base = new Derived();// 程序员确信 p_base 指向的是一个 Derived 对象，可以进行下行转换Derived* p_derived = static_cast&lt;Derived*&gt;(p_base);\n\n这里的 static_cast 进行了下行转换。但它不会在运行时进行检查。如果 p_base 实际上指向的不是 Derived 对象，这个操作将导致未定义行为。\ndynamic_cast(expression): dynamic_cast专门用于处理多态类型，在运行时进行类型检查，以确保下行转换的安全性。\n主要用于安全的类层次结构下行转换：在多态（基类必须有虚函数）的类继承体系中，将基类指针/引用安全地转换为派生类指针/引用。\n\n运行时检查：它会检查转换是否有效。\n对指针操作：如果转换成功，返回指向派生类对象的指针；如果转换失败（即基类指针并非指向目标派生类对象），返回 nullptr。\n对引用操作：如果转换成功，返回派生类的引用；如果转换失败，会抛出 std::bad_cast 异常。\n\n\n前提：必须用于至少包含一个虚函数（virtual function）的基类，因为它依赖于运行时类型信息（RTTI）。\n\n#include &lt;iostream&gt;class Base { public: virtual void who() { std::cout &lt;&lt; \"I am Base\\n\"; } };class Derived : public Base { public: void who() override { std::cout &lt;&lt; \"I am Derived\\n\"; } };class Other : public Base { public: void who() override { std::cout &lt;&lt; \"I am Other\\n\"; } };void check_type(Base* p) {    // 尝试将 Base* 转换为 Derived*, 这里 dynamic_cast 是创建一个新的指针变量，而不是改变原来指针的类型, 因此 p 本身的类型仍然是 Base*    Derived* p_derived = dynamic_cast&lt;Derived*&gt;(p);        if (p_derived != nullptr) {        std::cout &lt;&lt; \"Cast to Derived successful.\\n\";        p_derived-&gt;who();    } else {        std::cout &lt;&lt; \"Cast to Derived failed (p is not pointing to a Derived object).\\n\";    }}int main() {    Base* b1 = new Derived();    Base* b2 = new Other();        check_type(b1); // 输出: Cast to Derived successful. I am Derived    check_type(b2); // 输出: Cast to Derived failed (p is not pointing to a Derived object).    delete b1;    delete b2;    return 0;}\n\nconst_cast(expression): 是唯一能修改 const 或 volatile 属性的转换操作符, 用于去除对象的常量性。它只能添加或移除 const/volatile 属性，不能改变对象的实际类型。\n\n移除 const 属性：将一个 const 指针/引用转换为非 const 指针/引用。\n增加 const 属性：将一个非 const 指针/引用转换为 const 指针/引用（这通常是安全的，可以隐式完成，但也可以显式使用 const_cast）。\n\n\n使用 const_cast 移除 const 属性后，如果试图修改一个本身被定义为 const 的对象，其行为是未定义的。它主要用于这样的场景：你有一个 const 指针/引用，但你知道它指向的对象本身不是 const 的，你需要调用一个不接受 const 参数的函数。\n\nvoid legacy_function(int* p) { // 一个老旧的、不接受 const 指针的函数    *p = 20;}int main() {    const int val = 10;    // legacy_function(&amp;val); // 错误：无法将 const int* 转换为 int*        // 警告：对原始的 const 变量进行修改是未定义行为！    // const_cast&lt;int*&gt;(&amp;val) 虽然可以通过编译，但运行时行为未定义！val完全可能存储在只读内存中。    // legacy_function(const_cast&lt;int*&gt;(&amp;val));     int non_const_val = 15;    const int* p_const = &amp;non_const_val;    // 这种情况是安全的，因为 p_const 指向的对象 non_const_val 本身不是 const    legacy_function(const_cast&lt;int*&gt;(p_const));     // 现在 non_const_val 的值是 20}\n\nreinterpret_cast(expression): 用于低级别的重新解释类型，仅仅是重新解释给定的位模式，非常不安全。它通常用于与硬件打交道或进行底层编程。\n\n不同类型的指针之间转换：如将 int* 转换为 char*。\n指针与整数之间的转换：将指针转换为一个足以容纳它的整数类型，反之亦然。\n\n\n这是最危险的转换操作符。它不进行任何类型检查，只是简单地告诉编译器“把这些二进制位当成另一种类型来看待”。它几乎总是不可移植的，应仅在绝对必要时（如与硬件交互的底层代码）使用。\n\n#include &lt;iostream&gt;int main() {    int value = 0x41424344; // 在小端系统中代表 'D', 'C', 'B', 'A'    int* p_int = &amp;value;    // 将 int* 重新解释为 char*    char* p_char = reinterpret_cast&lt;char*&gt;(p_int);    // 逐字节打印整数的内存表示    for (int i = 0; i &lt; sizeof(int); ++i) {        std::cout &lt;&lt; *(p_char + i);    }    std::cout &lt;&lt; std::endl; // 在小端系统上输出：DCBA    return 0;}\n\n最佳实践：\n\n优先使用 C++ 风格转换：它们更安全、意图更明确、更易于搜索和维护。\n\n尽量避免转换：如果你的代码中充斥着大量的类型转换，这通常是设计不良的信号。考虑使用多态、模板或更好的设计模式来避免转换。\n\n选择最合适的转换符：\n\n当你需要在相关类型之间进行转换时，static_cast 是首选。\n当你需要在多态类体系中安全地进行下行转换时，使用 dynamic_cast。\n当你需要处理 const 或 volatile 属性时（通常是为了兼容旧代码），只能使用 const_cast，并要格外小心。\n只有在进行非常底层的、与硬件相关的、并且你完全清楚自己在做什么时，才使用 reinterpret_cast。\n\n\n\n"},{"title":"Volatile 和编译器优化","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/Volatile%E5%92%8C%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96/","content":"编译器优化的核心目标是在不改变程序原始逻辑（即可观察行为）的前提下，对生成的机器码进行修改，以提升程序的运行效率或减小其体积。这些改进通常体现在两个方面：\n\n执行速度：减少程序运行所需的总时钟周期。\n代码体积：减小程序编译后生成的可执行文件的大小。\n\nGCC 提供了一系列丰富的优化选项，让开发者可以根据具体需求在编译时间、调试便利性、运行速度和代码大小之间做出权衡。\n具体操作是通过 -O 系列标志（Flag）来控制。你可以直接在编译命令中加入这些标志。例如：gcc -O2 -o main main.c\nGCC 的主要优化级别GCC 将大量的具体优化选项组合成了几个预设的优化级别。级别越高，启用的优化项越多，编译所需的时间也越长。\n\n-O0: 不进行任何优化。这是默认的优化级别（如果你不指定任何 -O 选项）。\n\n目的：确保编译速度最快，并产生最直接、未经修改的机器码，与源代码的对应关系最强。\n\n适用场景：主要用于开发和调试阶段。因为没有优化，变量的值不会被意外优化掉，代码执行顺序也和源码完全一致，使得 GDB 等调试工具可以准确地跟踪程序的每一步。\n\n\n\n-O1: 基础级别的优化。编译器会尝试在不花费太多编译时间的情况下，执行一些基本的优化。\n\n目的：在不过分增加编译时间的前提下，提升程序性能。\n\n包含的优化：例如死代码消除（Dead Code Elimination）、常量传播（Constant Propagation）等。\n\n\n\n\n-O2: 推荐的通用优化级别。它开启了几乎所有不涉及“空间换时间”或“时间换空间”权衡的优化选项。\n- 目的：在编译时间和生成代码的性能之间取得最佳平衡。\n\n- 适用场景：软件的正式发布版本（Release Build）。这是最常用、最稳定的优化级别。\n\n\n-O3: 最高级别的优化。在 -O2 的基础上，开启了更多、更激进的优化，例如函数内联（Inlining）和循环展开（Loop Unrolling）等。\n\n目的：追求极致的运行速度。\n\n潜在问题：编译时间显著增加; 代码体积可能变大，因为一些优化（如循环展开）会用更多的代码来换取更快的速度。在极少数情况下，激进的优化可能会导致代码缓存（Instruction Cache）命中率下降，反而使程序性能降低。\n\n\n\n-Os：优化代码大小（Size）。它会开启 -O2 中所有不会增加代码体积的优化项，并执行一些专门为减小代码体积设计的优化。\n\n目的：生成尽可能小的可执行文件。\n\n适用场景：嵌入式系统、移动设备或其他存储空间受限的环境。\n\n\n\n-Ofast: 极限但可能不安全的优化。它包含了 -O3 的所有优化，并额外开启了一些可能会违反严格语言标准的优化。\n\n目的：压榨出最高的性能，不惜牺牲部分标准的符合性。\n\n重要警告：这个级别最显著的特点是会启用 -ffast-math 选项，这会影响浮点数的计算精度，可能不符合 IEEE 754 标准。除非你完全理解其后果，否则不应在对浮点数精度有要求的科学计算或金融应用中使用。\n\n\n\n-Og: 为调试而优化的级别（Optimize for Debugging）。\n\n目的：在不严重干扰调试体验的前提下，提供一个合理的性能。它会启用一些不会影响变量跟踪和断点设置的优化。\n\n适用场景：当你希望在调试时也能获得较好的程序性能，但又不想像 -O0 那样完全放弃优化时，这是一个很好的选择。\n\n\n\n\n具体的优化技术示例下面是一些在上述优化级别中常见的具体优化技术，以帮助理解编译器在幕后做了什么。\n常量折叠与常量传播 (Constant Folding &amp; Propagation): 在编译期间直接计算出结果为常量的表达式，并用结果替换该表达式。\n这里编译器发现 3.14 * 10 * 10 是一个常量表达式，于是在编译时直接计算出结果 314.0。\nint radius = 10;double area = 3.14 * radius * radius;// 优化后，编译器会将 area 直接替换为 314.0double area = 314.0;\n\n死代码消除 (Dead Code Elimination): 移除那些永远不会被执行到的代码。\n这里编译器发现 debug 是一个编译时常量 0，因此 if 条件永远为假，其中的代码永远不会执行。\nint debug = 0;if (debug) {    printf(\"This is a debug message.\\n\");}// 优化后，编译器会移除整个 if 语句块\n\n函数内联 (Function Inlining): 将一个函数的调用替换为该函数体的实际代码，以消除函数调用的开销（如堆栈操作、参数传递等）。这通常在 -O2 和 -O3 中启用。\nint square(int x) {    return x * x;}int main() {    int y = square(5);    return y;}// 优化后，编译器会将函数调用替换为函数体int main() {    int y = 5 * 5; // 直接展开函数体    return y;}\n\n\n尾递归优化也属于函数内联的一种特殊形式，编译器会将尾递归调用转换为循环，从而避免函数调用的开销和栈溢出风险。\n\n循环展开 (Loop Unrolling): 减少循环的迭代次数，但在每次迭代中执行更多的工作。这可以减少循环判断和分支的开销，并为其他优化（如指令级并行）创造机会。这通常在 -O3 中启用。\nfor (int i = 0; i &lt; 16; ++i) {    process(data[i]);}// 优化后，编译器可能会将循环展开为for(int i = 0; i &lt; 16; i += 4) {    process(data[i]);    process(data[i + 1]);    process(data[i + 2]);    process(data[i + 3]);}\n\n代价和权衡虽然优化能带来巨大好处，但也存在一些需要注意的代价和风险：\n\n编译时间增加：优化级别越高，编译器需要做的分析和转换就越多，导致编译时间变长。\n\n调试难度加大：优化会重排代码、消除变量、内联函数，这使得源码和最终执行的机器码之间的对应关系变得复杂。在 -O2 或 -O3 下调试时，你可能会发现单步执行时代码跳转不符合预期和无法打印某个变量的值等，因为它可能被优化到寄存器中，或者完全被消除了。\n\n可能暴露未定义行为 (Undefined Behavior)：C/C++ 标准中一些行为是未定义的（如访问数组越界、有符号整数溢出）。在 -O0 下，这些行为可能恰好能“正常”工作，但在优化后，编译器可能会基于“这种行为永远不会发生”的假设进行优化，从而导致程序崩溃或产生非预期结果。\n\n代码体积问题：-O3 等高级别优化为了速度可能会显著增加代码体积，这在某些场景下是不可接受的。\n\n\nvolatile 关键字volatile 是 C/C++ 语言中的一个类型限定符（type qualifier），与 const 类似。它的核心作用是告知编译器，被它修饰的变量的值随时都可能被程序本身之外的因素改变。\n这个“外部因素”可以是硬件（例如，一个内存映射的状态寄存器）, 操作系统, 另一个线程或者一个信号处理函数。\n因此，volatile 的主要目的是抑制编译器的优化，确保对该变量的每一次访问都是直接从内存中读取或写入，而不是使用寄存器中的缓存值。\n下面是一个简单的例子，展示了 volatile 的典型用法：\n// 假设 0x12345678 是一个硬件状态寄存器的地址unsigned int *status_reg = (unsigned int *)0x12345678;// 等待设备就绪while (*status_reg != 0) {    // 忙等待 (busy-wait)}// 设备已就绪，继续执行...\n编译器的优化思路 (-O2 或更高)：\n\n分析循环：编译器看到 while 循环的条件是 *status_reg != 0。\n发现问题：在循环体内，没有任何代码会修改 *status_reg 指向的内存地址的值。\n做出假设：因此，编译器假设 *status_reg 的值永远不会改变。\n进行优化：它会在循环开始前，*只读取一次 *status_reg 的值**并存入一个寄存器*（例如 eax）。然后，while 循环就变成了 while (eax != 0)。\n\n如果第一次读取的值不为 0，这将变成一个无限循环 (while(true))，即使硬件在稍后将状态寄存器的值更新为 0，程序也永远无法感知到这个变化，因为它一直在检查寄存器里的旧值。\n最后优化后的效果：\nRISCV    LDR R0, [0x12345678]  ; 只读取一次状态寄存器.L1:    CMP R0, #0            ; 比较寄存器中的值    BNE .L1               ; 如果不为 0，继续循环\n\n现在，我们把 volatile 加上。\n// 使用 volatile 告诉编译器，这个地址的值随时可能改变volatile unsigned int *status_reg = (volatile unsigned int *)0x12345678;// 等待设备就绪while (*status_reg != 0) {    // 忙等待}// 设备已就绪，继续执行...\n现在, 编译器看到 status_reg 指向一个 volatile 变量后会抑制优化：volatile 关键字像一个指令，告诉编译器：“不要对这个变量做任何假设！它的值随时可能从外部改变。”\n因此，编译器会在每一次循环中都生成从内存地址 0x12345678 重新读取值的指令。它不会将这个值缓存到寄存器中。\n最终生成的汇编代码可能类似于：\nRISCV.L1:    LDR R0, [0x12345678]  ; 每次循环都重新读取状态寄存器    CMP R0, #0            ; 比较寄存器中的值    BNE .L1               ; 如果不为 0，继续循环\n这样，当硬件更新了状态寄存器的值后，下一次循环的 mov 指令就能读取到新的值，程序就能正确地跳出循环。\n值得注意的是, 一个变量可以同时被 const 和 volatile 修饰，这看似矛盾，但实际上有明确的含义。\nvolatile const unsigned int *device_timer = (volatile const unsigned int *)0x87654321;\n\n这里的 const 表示程序不能通过这个指针修改 device_timer 指向的内存内容（即程序不能写入这个寄存器），而 volatile 则表示该寄存器的值可能随时被外部硬件改变，所以每次访问都必须从内存中重新读取。\n这个组合的完美用例是一个只读的硬件寄存器，比如一个硬件计时器或状态寄存器。我们的程序只能读取它的值，但这个值本身会由硬件自动更新。\nconst不能保证不被修改, volatile真能保证不被优化const 关键字在 C/C++ 中表示“只读”，即通过该指针或引用不能修改它所指向的数据。然而，const 并不意味着数据本身是不可变的。数据可能会被其他途径修改，例如：\n\n通过非 const 指针或引用。\n通过硬件寄存器（如内存映射 I/O）。\n通过多线程中的其他线程。\n通过类型转换（cast）绕过 const 限定符。\n\nint main() {    const int a = 10;    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; // Output may still be 10    cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl; // Output: 20    return 0;}\n在这个例子中，我们通过类型转换（cast）绕过了 const 限定符，直接修改了 a 的值。虽然这种做法在技术上是可行的，但它违反了 const 的语义\n然而值得注意的是 a 的值在输出时仍然是 10，因为声明const int a = 10;这种做法太直接了, 即使在-o0的情况下, 编译器也会将 a 的值直接内联到代码中, 导致修改 a 的值实际上并没有影响到程序的行为。\n不过, 通过指针可以看到, 原先 a 的内存地址上的值确实被改成了 20。\n第二种情况是, 假如变量a被定义在了全局中:\nconst int a = 10;int main() {    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl;     cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl;     return 0;}\n此时, 再执行会发现在运行时直接报错退出, 这是因为 a 是const的全局变量, 被放在了 .rodata 的只读数据段 (Read-Only Data Segment) 中, 试图修改它会导致访问冲突 (Access Violation) 或 段错误 (Segmentation Fault)。\n现在, 如果我们把第一种情况的 const 换成 volatile const：\nint main() {    volatile const int a = 10;    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; // Output will be 20    cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl; // Output: 20    return 0;}\n在这个例子中，a 被声明为 volatile const，这告诉编译器 a 的值可能会被外部因素改变（例如硬件或其他线程）。因此，编译器不会对 a 进行优化，每次访问 a 时都会从内存中重新读取它的值。\n因此当我们通过指针修改了 a 的值后，下一次访问 a 时，编译器会重新从内存中读取它的值，这次读取到的值是 20。\n总结来说, const只是一种编译时的约束, 它并不能真正保证数据不被修改(像情况2那样真正的约束在于底层硬件中MMU的保护机制)。而 volatile 则是一种运行时的约束, 它确保每次访问变量时都直接从内存中读取最新的值, 从而防止编译器对其进行优化。\n"},{"title":"Volatile 和编译器优化","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/%E4%B8%89-%E4%BA%94-%E9%9B%B6%E6%B3%95%E5%88%99/","content":"这个法则是关于如何正确管理类中的资源（尤其是动态分配的内存），避免内存泄漏和悬挂指针等问题的指导方针。它们是C++语言演化过程中逐步形成的三个阶段性法则。\n法则一：三法则 (The Rule of Three) - C++98/03时代核心思想：如果一个类需要程序员显式地定义析构函数、拷贝构造函数或拷贝赋值运算符 中的任意一个，那么它极有可能也需要定义所有这三个。\n\n析构函数 (~MyClass())：释放类所拥有的资源。\n\n拷贝构造函数 (MyClass(const MyClass&amp; other))：用一个已存在的对象来创建一个新对象。\n\n拷贝赋值运算符 (MyClass&amp; operator=(const MyClass&amp; other))：将一个已存在对象的值赋给另一个已存在的对象。\n\n\n这个法则的根源在于手动资源管理。通常，你需要自定义这三个函数的唯一原因，就是你的类通过裸指针管理着动态分配的内存或其他资源（如文件句柄、网络连接等）。\n如果你需要 析构函数 -&gt; 说明你需要在对象销毁时释放资源（例如 delete ptr;）。\n既然你需要释放资源，那么编译器自动生成的 拷贝构造函数（它只会进行浅拷贝，即直接复制指针地址）就是错误的。因为它会导致两个对象指向同一块内存，造成重复释放。所以，你必须自己写一个深拷贝的版本。\n同理，编译器自动生成的 拷贝赋值运算符也是浅拷贝，同样是错误的。它不仅会造成重复释放，还会导致内存泄漏（赋值前没有释放自己原有的内存）。所以，你也必须自己实现它。\n#include &lt;cstring&gt;#include &lt;iostream&gt;class String {public:    // 构造函数    String(const char* s = \"\") {        std::cout &lt;&lt; \"构造函数\\n\";        m_data = new char[strlen(s) + 1];        strcpy(m_data, s);    }    // 1. 析构函数 (触发三法则)    ~String() {        std::cout &lt;&lt; \"析构函数\\n\";        delete[] m_data;    }    // 2. 拷贝构造函数 (必须提供，否则会重复释放)    String(const String&amp; other) {        std::cout &lt;&lt; \"拷贝构造函数\\n\";        m_data = new char[strlen(other.m_data) + 1];        strcpy(m_data, other.m_data);    }    // 3. 拷贝赋值运算符 (必须提供，否则会内存泄漏+重复释放)    String&amp; operator=(const String&amp; other) {        std::cout &lt;&lt; \"拷贝赋值运算符\\n\";        if (this == &amp;other) { // 1. 检查自赋值            return *this;        }        delete[] m_data; // 2. 释放旧资源        m_data = new char[strlen(other.m_data) + 1]; // 3. 分配新资源        strcpy(m_data, other.m_data); // 4. 复制数据        return *this;    }private:    char* m_data;};\n\n法则二：五法则 (The Rule of Five) - C++11及以后由于C++11引入了移动语义 (Move Semantics)，三法则扩展为了五法则。如果一个类定义了五个特殊成员函数中的任何一个，它应该把它们全部定义（或 =delete 掉）。\n新增的两个特殊成员函数：\n\n移动构造函数 (MyClass(MyClass&amp;&amp; other) noexcept)：用一个将要被销毁的临时对象（右值）来创建新对象，通过“窃取”其资源来避免昂贵的拷贝。\n\n移动赋值运算符 (MyClass&amp; operator=(MyClass&amp;&amp; other) noexcept)：从一个临时对象（右值）“窃取”资源。\n\n\n移动语义是C++11的重大性能提升。如果你的类管理着资源，你不仅要告诉编译器如何拷贝它，还应该告诉编译器如何移动它。因为移动操作（只是交换指针和设置nullptr）远比深拷贝（分配内存 + 复制数据）要快得多。\n如果你手动定义了拷贝操作（拷贝构造/拷贝赋值）或析构函数，编译器通常不会再自动为你生成移动操作。这会导致在需要移动的场合（例如从函数返回临时对象）被迫降级去执行昂贵的拷贝操作，从而丧失性能。\n// ... 在上面的 String 类中增加 ...// 4. 移动构造函数 (高效的资源“窃取”)String(String&amp;&amp; other) noexcept {    std::cout &lt;&lt; \"移动构造函数\\n\";    m_data = other.m_data;   // 1. 直接拿走资源    other.m_data = nullptr; // 2. 将源对象置为空，防止它析构时释放资源}// 5. 移动赋值运算符, 设置 noexcept 表示这个函数不会抛异常String&amp; operator=(String&amp;&amp; other) noexcept {    std::cout &lt;&lt; \"移动赋值运算符\\n\";    if (this == &amp;other) { // 1. 检查自赋值        return *this;    }    delete[] m_data;         // 2. 释放自己的旧资源    m_data = other.m_data;   // 3. 拿走对方的资源    other.m_data = nullptr; // 4. 将源对象置为空    return *this;}\n\n法则三：零法则 (The Rule of Zero) - 现代C++最佳实践应该优先设计一个类，它不需要程序员编写任何自定义的析构函数、拷贝/移动构造函数或赋值运算符。\n因为手动编写这五个函数非常繁琐且极易出错（例如忘记检查自赋值、忘记处理异常安全等）。现代C++提倡将资源管理交给专门的类去做。\n具体实现方法, 可以通过使用C++标准库提供的RAII (Resource Acquisition Is Initialization) 容器和智能指针来管理资源。\n\n用 std::string 代替 char* 来管理字符串。\n用 std::vector 代替裸数组。\n用 std::unique_ptr 或 std::shared_ptr 代替裸指针来管理动态分配的对象。\n\n这些标准库组件本身已经完美地实现了五法则。你的类只需要包含它们作为成员，编译器自动生成的特殊成员函数就会正确地调用这些成员的对应函数。\n例如, 之前的 String 类可以简化为：\n#include &lt;string&gt;#include &lt;iostream&gt;class String {public:    String(const std::string&amp; s = \"\") : m_data(s) {        std::cout &lt;&lt; \"构造函数\\n\";    }    // ... 其他成员函数 ...    // 不需要写析构函数    // 不需要写拷贝构造函数    // 不需要写拷贝赋值运算符    // 不需要写移动构造函数    // 不需要写移动赋值运算符    // 编译器会为我们自动生成所有这些，并且它们都是正确的！private:    std::string m_data; // 使用 std::string 来管理资源};\n\n通过遵循零法则，你的类会变得更简单、更安全、更易维护，同时也能享受到现代C++的强大功能。\n总结| 法则\t| 何时应用\t| 核心内容\t| 目标 |三法则\t(遗留代码/C++98) 类中直接用裸指针管理资源。\t如果定义了 析构、拷贝构造、拷贝赋值 之一，就要定义全部三个，以实现深拷贝。\t避免浅拷贝导致的内存错误。五法则\t(C++11及以后) 类中直接用裸指针管理资源，且需要高性能。\t在三法则基础上，增加 移动构造 和 移动赋值，以利用移动语义提升性能。\t在安全的基础上，提供更高的性能。零法则\t(现代C++最佳实践) 设计新类时。\t不要用裸指针管理资源。使用 std::string, std::vector, std::unique_ptr 等RAII工具，从而让编译器自动生成所有正确的特殊函数。\t让代码更简洁、更安全、更易维护，避免重复造轮子。\n"},{"title":"多路IO转接/IO Multiplexing（I/O 多路复用）","url":"/2025/10/02/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5/%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5/","content":"在我们之前创建的最基础的 Client-Server 模型中，服务器是迭代式的：它一次只能处理一个客户端。当 HandleRequest 函数正在为一个客户端服务时，其他所有新的客户端都必须在 accept 的队列中等待。这在实际应用中是完全不可接受的。\n而进一步为了解决并发问题，我们实现了两种朴素的思路：\n\n多进程模型：主进程负责 accept 连接，每当有新连接到来时，就 fork() 一个新的子进程去专门处理这个连接。\n\n缺点：fork() 的开销非常大，每个进程都有独立的内存空间，进程间通信复杂，系统能创建的进程数量有限。\n\n\n多线程模型：主线程负责 accept 连接，每当有新连接到来时，就创建一个新的线程去处理。\n\n缺点：虽然比进程轻量，但线程仍然需要消耗系统资源（如栈内存）。当连接数达到成千上万时，创建同样数量的线程会消耗巨大内存，并且 CPU 需要花费大量时间在这些线程之间进行上下文切换，导致性能下降。\n\n\n\n这两种模型的共同问题是：一个执行流（进程/线程）绑定一个连接（Socket）。当连接数非常多时，这种模型的资源开销是无法承受的。\n而多路 I/O 转接（也常被称为“事件驱动 I/O”）从根本上改变了这种模式。它的核心思想是：用一个进程（或线程）同时监视多个文件描述符（Socket），一旦其中一个或多个描述符的 I/O 条件就绪（例如，数据可读或可写），就能够得到通知，然后进行相应的处理。\n多路 I/O 转接的实现机制多路 I/O 转接的实现依赖于操作系统提供的特定机制，常见的有以下几种:\n\nselect：最早的多路 I/O 转接机制，支持监视多个文件描述符的读写状态。它使用一个位图来表示文件描述符集合，但有文件描述符数量的限制（通常是 1024）。\npoll：类似于 select，但没有文件描述符数量的限制，使用一个数组来表示文件描述符集合，性能更好一些。\nepoll（Linux 特有）：是对 poll 的改进，支持更高效的事件通知机制，适合处理大量并发连接。epoll 使用事件驱动模型，只有在文件描述符状态发生变化时才进行通知，避免了轮询所有文件描述符的开销。\n\n使用 select 实现多路 I/O 转接select 的核心功能是：允许程序同时监视多个文件描述符，等待一个或多个描述符进入“就绪”状态。\n核心数据结构：fd_set要使用 select，首先必须学会操作它的核心数据结构 fd_set，即“文件描述符集合”。你可以把它理解为一个比特位图 (bitmap)，其中每一位对应一个文件描述符的编号。\n操作系统提供了一组标准的宏来安全地操作 fd_set：\n\n**void FD_ZERO(fd_set *set)**; 清空/置零整个集合。在每次使用前，这通常是第一步。\n**void FD_SET(int fd, fd_set *set)**: 将一个文件描述符 fd 添加到集合 set 中。\n**void FD_CLR(int fd, fd_set *set)**: 将一个文件描述符 fd 从集合 set 中移除。\n**int FD_ISSET(int fd, fd_set *set)**: 检查文件描述符 fd 是否仍然在集合 set 中。这在 select 函数返回后使用，用于判断某个 fd 是否是“就绪”的。\n\nselect 函数原型#include &lt;sys/select.h&gt;int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);\n\n\nint nfds: 这是一个非常容易误解的参数。它不是你要监视的文件描述符的总数，而是所有被监视的文件描述符中最大值加 1。例如，如果你要监视的 fd 是 3, 5, 8，那么 nfds 的值就应该是 8 + 1 = 9。\n\n原因：内核是以位图方式检查 fd_set 的，这个参数告诉内核它需要检查到哪一位就可以了，以提高效率。\n\n\nfd_set *readfds: 指向一个 fd_set 结构的指针，包含了所有你关心其“可读”事件的文件描述符。例如可以监听套接字看是否有新的连接请求到来; 监听已连接套接字检查是否有数据从客户端发来。如果不关心任何“可读”事件，可以设为 NULL。\n\nfd_set *writefds: 指向一个 fd_set 结构的指针，包含了所有你关心其“可写”事件的文件描述符。一个套接字“可写”通常意味着它的 TCP 发送缓冲区有足够的空间来接收新的数据。如果不关心，可以设为 NULL。\n\nfd_set *exceptfds: 指向一个 fd_set 结构的指针，用于监视异常条件。这在 TCP 中用得较少，例如接收到带外数据。如果不关心，可以设为 NULL。\n\n\n重要的是, readfds, writefds, exceptfds 这三个参数是传入传出参数。传入时, 你告诉内核你关心哪些 fd ; 传出时（select返回后）, 内核会修改这些 fd_set，把其中没有就绪的 fd 全部清除，只留下那些已经就绪的 fd。这意味着，每次在循环中调用 select 之前，你都必须重新设置这些 fd_set。\n\nstruct timeval *timeout: 用于设置 select 的超时时间。struct timeval 结构包含秒和微秒。\n\n设为 NULL：永久阻塞，直到至少有一个 fd 就绪。\ntimeout 值为 0：完全不阻塞，立即返回。这相当于进行一次非阻塞的轮询。\ntimeout 值大于 0：在指定的时间内阻塞等待。如果超时，select 会返回 0。\n\n\n返回值: 如果 &gt; 0 表示就绪的文件描述符的总数就是返回值; 返回0表示超时，没有任何文件描述符就绪; 返回-1表示发生错误，需要检查 errno。\n\n\n使用 select 的典型流程\n初始化 fd_set 集合，使用 FD_ZERO 清空集合，然后使用 FD_SET 将所有需要监视的文件描述符添加进去。\n调用 select 函数，传入 nfds 和 fd_set 集合。\nselect 返回后，检查返回值:\n如果返回值 &gt; 0，表示有文件描述符就绪。使用 FD_ISSET 检查每个文件描述符，找出哪些是就绪的，并进行相应的读写操作。\n如果返回值 == 0，表示超时，没有任何文件描述符就绪。\n如果返回值 == -1，表示发生错误，检查 errno 以确定错误类型。\n\n\n重复上述过程，通常在一个循环中不断调用 select 以持续监视文件描述符。\n\n#include &lt;vector&gt;#include &lt;algorithm&gt; // For std::max// ... (socket, bind, listen a listen_sockfd) ...fd_set master_fds; // 用于保存所有需要监视的 fdFD_ZERO(&amp;master_fds);FD_SET(listen_sockfd, &amp;master_fds); // 将监听 socket 加入集合int max_fd = listen_sockfd; // nfds 参数需要while (true) {    // 1. 准备工作：select会修改集合，所以每次都需要从 master 复制一份    fd_set read_fds = master_fds;    // fd_set write_fds = ... (if needed)    // 2. 调用 select，阻塞等待事件    int ready_count = select(max_fd + 1, &amp;read_fds, NULL, NULL, NULL);    if (ready_count &lt; 0) {        perror(\"select\");        break;    }    // 3. 遍历所有可能的 fd，检查是哪个就绪了    for (int i = 0; i &lt;= max_fd; ++i) {        if (FD_ISSET(i, &amp;read_fds)) { // 检查 fd i 是否在返回的就绪集合中                        if (i == listen_sockfd) {                // 3a. 如果是监听 socket 就绪，表示有新连接                struct sockaddr_in client_addr;                socklen_t len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);                if (client_sockfd &lt; 0) { /* error */ }                // 将新的客户端 socket 添加到 master 集合中                FD_SET(client_sockfd, &amp;master_fds);                // 更新 max_fd                if (client_sockfd &gt; max_fd) {                    max_fd = client_sockfd;                }            } else {                // 3b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = i;                char buffer[1024];                ssize_t n = read(client_sockfd, buffer, sizeof(buffer));                                if (n &lt;= 0) {                    // 客户端断开连接或出错                    close(client_sockfd);                    // 将其从 master 集合中移除                    FD_CLR(client_sockfd, &amp;master_fds);                } else {                    // 处理数据...                    // write(client_sockfd, ...);                }            }        }    }}\n\nselect 的缺点尽管 select 非常通用，但它的设计存在几个固有缺陷，导致其不适合大规模高并发场景：\n\n连接数限制：fd_set 的大小由 FD_SETSIZE 宏定义，通常是 1024(因为单个进程文件描述符最大就是1024)，这硬性限制了服务器能处理的最大并发连接数。\n\n性能开销：\n\n重复拷贝：每次调用 select，都需要将包含所有 fd 的 fd_set 从用户空间拷贝到内核空间(因为select是系统调用), 这在 fd 数量很大时开销显著。\n无法直接定位触发事件的文件描述符, 需要线性扫描：内核需要遍历所有传入的 fd 来检查状态；select 返回后，用户程序也需要从 0 到 max_fd 遍历一次，才能找出哪些 fd 真正就绪。这两个扫描的开销都与 max_fd 的大小成正比。\n\n\n\n但优点是可以跨平台使用, 具有良好的兼容性。\n正是由于这些缺点，Linux 平台才引入了性能更优越的 epoll。但 select 的编程模型——即将所有描述符放入一个集合，等待事件，然后处理就绪的描述符——是所有 I/O 多路转接技术的基础。\n使用 poll 实现多路 I/O 转接poll 的核心功能与 select 完全相同：允许程序在一个地方阻塞，同时监视多个文件描述符的 I/O 事件。\n核心数据结构：struct pollfdpoll 不再使用繁琐的 fd_set 和宏，而是引入了一个更直观的结构体 struct pollfd。你需要为每一个你关心的文件描述符创建一个这样的结构体。\n#include &lt;poll.h&gt;struct pollfd {    int   fd;         /* file descriptor: 你要监视的文件描述符 */    short events;     /* requested events: 你关心的事件 (输入参数) */    short revents;    /* returned events:  实际发生的事件 (输出参数) */};\n\nint fd: 你要监视的文件描述符的编号。如果你想让 poll 忽略这个 pollfd 元素，可以将 fd 设置为 -1。\nshort events: 这是一个输入参数，由你来设置。它是一个位掩码，用来告诉内核你对这个 fd 关心哪些事件。常用事件包括：\nPOLLIN: 普通或优先级数据可读。\nPOLLOUT: 普通数据可写。\nPOLLERR: 发生错误。\n\n\nshort revents: 这是一个输出参数，由内核来设置。当 poll 函数返回后，内核会修改这个成员，用一个位掩码来表明该 fd 上实际发生了哪些事件。你可以通过位运算来检查 revents 中是否包含你关心的事件，例如 if (pfd.revents &amp; POLLIN)。\n\npoll 函数原型及示例int poll(struct pollfd *fds, nfds_t nfds, int timeout);\n\nstruct pollfd *fds: 一个指向 pollfd 结构体数组的第一个元素的指针。这个数组包含了所有你希望监视的文件描述符及其事件。\n\nnfds_t nfds: fds 数组中元素的总数量。这个参数比 select 的 nfds 直观得多。\n\nint timeout: poll 函数的超时时间，单位是毫秒 (milliseconds)。\n\n-1: 永久阻塞，直到有事件发生。\n0: 完全不阻塞，立即返回。\n某个数 &gt; 0: 在指定的毫秒数内阻塞等待。\n\n\n返回值: &gt;0 表示 fds 数组中 revents 成员不为 0 的元素个数，即已就绪的文件描述符的数量; 0 表示超时，没有任何文件描述符就绪; -1 表示发生错误，需要检查 errno。\n\n\n使用 poll 的服务器逻辑比 select 更清晰，特别是当需要动态增删文件描述符时。使用 std::vector 来管理 pollfd 数组非常方便。\n#include &lt;vector&gt;#include &lt;poll.h&gt;// ... (socket, bind, listen a listen_sockfd) ...std::vector&lt;struct pollfd&gt; poll_fds;// 将监听 socket 加入监视struct pollfd listen_pfd;listen_pfd.fd = listen_sockfd;listen_pfd.events = POLLIN; // 关心可读事件 (新连接)poll_fds.push_back(listen_pfd);while (true) {    // 1. 调用 poll，阻塞等待事件    // poll_fds.data() 获取指向 vector 内部数组的指针    int ready_count = poll(poll_fds.data(), poll_fds.size(), -1); // 永久阻塞    if (ready_count &lt; 0) {        perror(\"poll\");        break;    }    // 2. 遍历所有被监视的 fd，检查是哪个就绪了    for (size_t i = 0; i &lt; poll_fds.size(); ++i) {        if (poll_fds[i].revents &amp; POLLIN) { // 检查 revents 字段            if (poll_fds[i].fd == listen_sockfd) {                // 2a. 如果是监听 socket 就绪，表示有新连接                struct sockaddr_in client_addr;                socklen_t len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);                if (client_sockfd &lt; 0) { /* error */ }                // 将新的客户端 socket 添加到监视列表                struct pollfd client_pfd;                client_pfd.fd = client_sockfd;                client_pfd.events = POLLIN;                poll_fds.push_back(client_pfd);            } else {                // 2b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = poll_fds[i].fd;                char buffer[1024];                ssize_t n = read(client_sockfd, buffer, sizeof(buffer));                if (n &lt;= 0) {                    // 客户端断开连接或出错                    close(client_sockfd);                    // 将其从监视列表中移除 (简单起见，这里设置为-1，实践中可能需要更高效的移除方式)                    poll_fds[i].fd = -1;                 } else {                    // 处理数据...                    // write(client_sockfd, ...);                }            }        }    }    // (实践中，可以在循环后清理所有 fd 为 -1 的元素)}\n\npoll 相对于 select 的优缺点优点: \n解决了连接数限制：poll 使用 pollfd 数组，而不是 fd_set 位图，因此它监视的文件描述符数量只受限于系统资源（如内存大小、进程最大文件描述符数），没有了 select 的 1024 个硬性限制。\n数据结构更清晰：pollfd 结构体将 fd、关心的 events 和发生的 revents 整合在一起，比 select 分离的三个 fd_set 更易于管理。\n无需每次重置：poll 的 events 字段是输入参数，revents 是输出参数，两者是分开的。内核不会修改 events 字段，因此在循环中你不需要像 select 那样每次都重置你关心的事件列表（除非你的确想动态改变它）。\n依然存在的缺点: \npoll 和 select 在本质上是同一种工作模式，因此它们有共同的性能瓶颈, 主要是性能开销例如重复拷贝, 每次调用 poll，都需要将整个 pollfd 数组从用户空间完整地拷贝到内核空间; 还有线性扫描. 当连接数非常多时（例如上万个），内核为了找出就绪的 fd，仍然需要遍历整个数组。poll 返回后，用户程序也需要遍历整个数组来检查 revents 字段。这个 O(n) 的开销在大并发场景下是致命的。\n总之, poll 是 select 的一个直接且有效的改进版，主要解决了连接数限制的问题。但它并没有解决核心的性能问题，而 epoll 则通过完全不同的事件通知机制，从根本上解决了这两个性能瓶颈。\n使用 epoll 实现多路 I/O 转接epoll 的出现，标志着 I/O 事件通知从“轮询模式”向“通知模式”的根本性转变。\n\nselect/poll 的模式：“你好，内核。请帮我看看我这一大堆 Socket 里，有没有人准备好了？我在这里等着你检查完告诉我。” (应用进程主动轮询)\nepoll 的模式：“你好，内核。这是我关心的所有 Socket 列表，你先记一下。以后哪个 Socket 准备好了，你再主动通知我。我先去忙别的了。” (内核主动通知)\n\nepoll 之所以高效，主要得益于两个核心机制，完美解决了 select/poll 的两大性能瓶颈。\n\n解决“内存拷贝”：内核与用户空间共享内存 (mmap)当你调用 epoll_create 创建 epoll 实例时，内核不仅会创建一个事件表，还会开辟一块特殊的内核缓冲区，并通过内存映射 (mmap) 技术与用户空间共享。这个区域专门用来存放“已就绪”的文件描述符列表。当 epoll_wait 返回时，它不需要从内核空间向用户空间拷贝整个庞大的列表，而是直接让用户空间可以访问这块共享内存，大大提高了效率。\n\n解决“线性扫描”：基于回调的事件通知机制当你使用 epoll_ctl 将一个 Socket fd 注册到 epoll 实例时，内核会将这个 fd 与 epoll 实例关联，并在这个 Socket 的内部等待队列上注册一个“回调函数”。当这个 Socket 接收到数据时，会触发一个中断，内核在处理这个中断时，会执行这个回调函数。这个回调函数的任务很简单：将这个就绪的 Socket fd 添加到 epoll 实例的“就绪列表”中（就是上面提到的那块共享内存区域）。因此，epoll_wait 函数的工作就变得极其简单：它只需要检查一下“就绪列表”是否为空。如果不为空，就将列表返回给用户程序并唤醒进程。这个过程的时间复杂度是 O(1)，与你监视的连接总数完全无关！\n\n\nepoll 的三大核心函数epoll 的所有操作都围绕这三个函数展开。\nint epoll_create(int size):\n\n功能：在内核中创建一个 epoll 实例，并返回一个指向该实例的文件描述符（epoll fd）。\nsize 参数在早期版本的 Linux 内核中用于提示内核事件表的大小，但在现代内核中此参数已被忽略，只要是一个正数即可。\n这个返回的 epfd 是后续所有 epoll 操作的句柄。\n\n**int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)**:\n\n功能：epoll 的控制接口，用于向 epfd 指向的 epoll 实例中添加、修改或删除被监视的文件描述符。\nepfd: epoll_create 返回的句柄。\nop: 操作类型，主要有三种：\nEPOLL_CTL_ADD: 添加一个新的 fd 到 epoll 实例中。\nEPOLL_CTL_MOD: 修改一个已经存在的 fd 的监听事件。\nEPOLL_CTL_DEL: 从 epoll 实例中删除一个 fd。\n\n\nfd: 所要监视的目标文件描述符（如 listen_sockfd 或 client_sockfd）。\nstruct epoll_event *event: 指向一个结构体，描述了你对 fd 关心的事件类型。  struct epoll_event {    uint32_t     events;      /* Epoll events (bit mask) */    epoll_data_t data;        /* User data variable */};union epoll_data {    void        *ptr;    int          fd;    uint32_t     u32;    uint64_t     u64;};\n\nevents: 事件的位掩码，如 EPOLLIN (可读), EPOLLOUT (可写), EPOLLET (边缘触发)等。\ndata: 一个联合体，这是 epoll 的一大亮点。你可以将自定义数据（如 fd 本身、一个指向对象/结构体的指针等）与事件关联起来。当 epoll_wait 返回这个事件时，你也能拿到这个数据，极大地简化了编程。\n\n\n\n**int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)**:\n\n功能：等待 epfd 上的 I/O 事件。这是服务器主循环中唯一需要阻塞的地方。\nepfd: epoll_create 返回的句柄。\nstruct epoll_event *events:  一个由用户程序分配的 epoll_event 数组。当函数成功返回时，内核会将所有就绪的事件拷贝到这个数组中。\n注意它不是像上面的 epoll_ctl那样传入一个单独的 event 结构体指针，而是传入一个数组，允许一次返回多个就绪事件。\n\n\nmaxevents: events 数组的大小，告诉内核最多可以返回多少个事件。\ntimeout: 超时时间（毫秒），与 poll 类似\n\n红黑树和就绪链表epoll 内部使用了两种非常高效的数据结构来管理文件描述符：\n\n红黑树 (Red-Black Tree): 用于存储所有被监视的文件描述符及其相关信息。红黑树是一种自平衡的二叉搜索树，能够在 O(log n) 时间内完成插入、删除和查找操作。当你调用 epoll_ctl 添加、修改或删除一个 fd 时，内核会在这棵红黑树上进行相应的操作。\n我们调用 epoll_create 创建 epoll 实例时，内核会初始化这棵红黑树, 返回的 epoll fd 就是这棵树的根节点。\n\n\n就绪链表 (Ready List): 用于存储所有当前就绪的文件描述符。当某个 fd 的 I/O 条件满足时（例如数据可读），内核会将这个 fd 添加到就绪链表中。epoll_wait 只需要检查这个链表，而不需要遍历所有被监视的 fd。\n\nepoll 使用示例/* * 程序名：epoll_server.cpp, 一个基于 Epoll 的高并发 TCP 服务器。 * 功能：接收客户端的连接，并将客户端发来的消息原封不动地返回（Echo）。 * 特点：非阻塞 I/O + I/O 多路复用 (epoll)。 */#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt; // for fcntl#define MAX_EVENTS 1024 // epoll_wait 返回的最大事件数// 设置文件描述符为非阻塞模式void setnonblocking(int sockfd) {    fcntl(sockfd, F_SETFL, fcntl(sockfd, F_GETFL, 0) | O_NONBLOCK);}int main(int argc, char *argv[]) {    if (argc != 2) {        std::cout &lt;&lt; \"Usage: ./epoll_server port\\n\";        return -1;    }    // 1. 创建监听 socket    int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_sockfd &lt; 0) {        perror(\"socket\");        return -1;    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(listen_sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定地址和端口    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);    serv_addr.sin_port = htons(atoi(argv[1]));    if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {        perror(\"bind\");        close(listen_sockfd);        return -1;    }    // 3. 开始监听    if (listen(listen_sockfd, SOMAXCONN) &lt; 0) {        perror(\"listen\");        close(listen_sockfd);        return -1;    }    std::cout &lt;&lt; \"Epoll Server is listening on port \" &lt;&lt; argv[1] &lt;&lt; \"...\" &lt;&lt; std::endl;    // 4. 创建 epoll 实例, 从这里开始使用 epoll    int epoll_fd = epoll_create1(0);    if (epoll_fd &lt; 0) {        perror(\"epoll_create1\");        close(listen_sockfd);        return -1;    }    // 这里的epoll_create1是epoll_create的增强版, 参数为0即可设定默认模式, 不需要像epoll_create那样传入size    struct epoll_event ev;    ev.events = EPOLLIN; // 监听可读事件    ev.data.fd = listen_sockfd;    // 这里的data的其余成员暂时不使用, 直接用fd即可    // 5. 将监听 socket 添加到 epoll 实例中    if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, listen_sockfd, &amp;ev) &lt; 0) {        perror(\"epoll_ctl: listen_sockfd\");        close(listen_sockfd);        close(epoll_fd);        return -1;    }    // 用于接收就绪事件的数组    std::vector&lt;struct epoll_event&gt; events(MAX_EVENTS);    // 6. 主事件循环    while (true) {        int num_events = epoll_wait(epoll_fd, events.data(), MAX_EVENTS, -1); // 永久阻塞        if (num_events &lt; 0) {            perror(\"epoll_wait\");            continue;        }        for (int i = 0; i &lt; num_events; ++i) {            if (events[i].data.fd == listen_sockfd) {                // 6a. 如果是监听 socket 就绪，表示有新客户端连接                struct sockaddr_in client_addr;                socklen_t client_len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;client_len);                                if (client_sockfd &lt; 0) {                    perror(\"accept\");                    continue;                }                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr) &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                // 将新的客户端 socket 设置为非阻塞, 这是使用 epoll 的推荐做法                setnonblocking(client_sockfd);                // 将新的客户端 socket 添加到 epoll 实例中                // 注意：对于ET模式，这里需要加上 EPOLLET                ev.events = EPOLLIN; // | EPOLLET;                ev.data.fd = client_sockfd;                if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, client_sockfd, &amp;ev) &lt; 0) {                    perror(\"epoll_ctl: client_sockfd\");                    close(client_sockfd);                }            } else {                // 6b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = events[i].data.fd;                char buffer[1024];                memset(buffer, 0, sizeof(buffer));                // 注意：如果是ET模式，这里需要循环读取，直到返回EAGAIN                ssize_t bytes_received = read(client_sockfd, buffer, sizeof(buffer));                if (bytes_received &lt;= 0) {                    // 如果 read 返回 0 或 -1，表示客户端断开或出错                    if (bytes_received == 0) {                        std::cout &lt;&lt; \"Client \" &lt;&lt; client_sockfd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;                    } else {                        perror(\"read\");                    }                    // 从 epoll 实例中移除并关闭 socket                    epoll_ctl(epoll_fd, EPOLL_CTL_DEL, client_sockfd, NULL);                    close(client_sockfd);                } else {                    // 原封不动地将数据写回客户端（Echo）                    if (write(client_sockfd, buffer, bytes_received) != bytes_received) {                        perror(\"write\");                    }                }            }        }    }    close(listen_sockfd);    close(epoll_fd);    return 0;}\n/* * 程序名：client.cpp，一个简单的TCP客户端。(用于测试epoll服务器) */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char *argv[]){    if (argc != 3)    {        std::cout &lt;&lt; \"Using: ./client ip port\\nExample: ./client 127.0.0.1 5005\\n\\n\";        return -1;    }    int sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (sockfd == -1) { perror(\"socket\"); return -1; }    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(atoi(argv[2]));    if (inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr) &lt;= 0) {        perror(\"inet_pton\"); close(sockfd); return -1;    }    if (connect(sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0) {        perror(\"connect\"); close(sockfd); return -1;    }    std::cout &lt;&lt; \"Connected to server \" &lt;&lt; argv[1] &lt;&lt; \":\" &lt;&lt; argv[2] &lt;&lt; std::endl;    char buffer[1024];    std::string input;        std::cout &lt;&lt; \"Enter a message (or 'exit' to quit): \";    while (getline(std::cin, input) &amp;&amp; input != \"exit\")    {        std::string message_to_send = input + \"\\n\";        if (write(sockfd, message_to_send.c_str(), message_to_send.length()) &lt;= 0) {            perror(\"write\"); break;        }        memset(buffer, 0, sizeof(buffer));        ssize_t bytes_received = read(sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0) {            std::cout &lt;&lt; \"Server echo: \" &lt;&lt; buffer; // buffer中自带换行        } else {            std::cout &lt;&lt; \"Server disconnected or error.\" &lt;&lt; std::endl; break;        }        std::cout &lt;&lt; \"\\nEnter a message (or 'exit' to quit): \";    }    close(sockfd);    std::cout &lt;&lt; \"Connection closed.\" &lt;&lt; std::endl;    return 0;}\n\nepoll 的两种工作模式：水平触发 (LT) 与边缘触发 (ET)这是 epoll 的一个高级但非常重要的特性。\n\n水平触发 (Level Triggered, LT) - 默认模式\n\n行为：只要文件描述符的缓冲区中还有数据可读，epoll_wait 每次被调用都会返回这个事件。\n\n特点：编程更简单、更安全，与 poll 的行为类似。即使你这次没有把数据全部读完，下次循环调用 epoll_wait 时内核还会“提醒”你。\n\n\n\n边缘触发 (Edge Triggered, ET) - 高性能模式\n\n行为：只有当文件描述符的状态发生变化（例如，数据从无到有）时，epoll_wait 才会通知一次。\n\n特点：效率更高，因为它避免了对同一事件的重复通知。但编程要求也更高：你必须在收到通知后，在一个循环中一次性将缓冲区的数据全部读取完毕（直到 read 返回 EAGAIN 错误），否则剩下的数据可能再也得不到处理机会了。Nginx 等高性能服务器都工作在 ET 模式下。\n\n\n\n\n在接口的使用上，ET 模式只需要在注册事件时，将 EPOLLET 标志加上即可：\nev.events = EPOLLIN | EPOLLET; // 监听可读事件，使用边缘触发模式\n而LT模式则不需要额外设置，默认就是LT。\nev.events = EPOLLIN; // 监听可读事件，使用默认的水平触发模式\nfcntlfcntl 是 “file control” 的缩写，意为文件控制。它是 POSIX 标准中定义的一个系统调用，功能非常强大，可以用一个函数来对文件描述符 (file descriptor) 执行各种各样的控制操作。\n在 Unix/Linux “一切皆文件” 的哲学中，socket 也是通过文件描述符来表示的，因此 fcntl 自然也可以用来控制 socket 的属性和行为。\n它的主要作用是在程序运行时，动态地获取或修改一个已打开文件描述符的属性。\nfcntl 函数的声明在头文件 &lt;fcntl.h&gt; 中。它的原型比较特殊，是一个可变参数函数：\n#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* arg */ );\n\nint fd: 目标文件描述符，即你想要控制的那个文件或 socket 的句柄。\n\nint cmd: 命令 (command)，这是 fcntl 的核心。你通过这个参数告诉 fcntl 你具体想做什么操作。cmd 的值是一系列预定义的宏。\n\n… /* arg */: 一个可选的、可变的第三个参数。这个参数的类型和含义完全取决于 cmd 的值。有些命令需要这个参数，有些则不需要。\n\n\nfcntl 的常用命令 (cmd)fcntl 的功能非常多，我们重点介绍在网络和系统编程中最常用的几个命令。\nF_GETFL 和 F_SETFL：获取和设置文件状态标志. 这是 fcntl 在网络编程中最重要、最常用的功能，主要用于设置文件描述符的 I/O 模式，例如非阻塞 I/O。\n\nF_GETFL (Get File Status Flags):\n\n功能：获取 fd 当前的文件状态标志。\n用法：int flags = fcntl(fd, F_GETFL, 0);\n解释：这个调用会返回一个整数，其中包含了描述 fd 状态的多个标志位（例如 O_RDONLY, O_APPEND 等）。\n\n\nF_SETFL (Set File Status Flags):\n\n功能：设置 fd 的文件状态标志。\n用法：fcntl(fd, F_SETFL, new_flags);\n\n\n\nF_DUPFD：复制一个现有的文件描述符 fd，返回一个新的文件描述符。新描述符是大于或等于第三个参数 arg 的最小可用编号。\n用法：newfd = fcntl(fd, F_DUPFD, start_fd);\n应用：常用于 shell 的重定向功能。\nF_GETLK, F_SETLK, F_SETLKW：文件锁, 用于对文件的某个区域进行加锁或解锁，以协调多个进程对同一文件的访问。\n\nF_GETLK: 测试锁。\nF_SETLK: 设置锁（非阻塞）。\nF_SETLKW: 设置锁（阻塞）。\n\n应用：在多进程数据库、日志系统等需要精确文件访问控制的场景中使用。对于网络编程，通常使用其他同步机制。\nET和非阻塞IO现在我们回到最初的场景。为什么在高性能 epoll 服务器(ET模式)中，将 listen_sockfd 和 client_sockfd 设置为非阻塞是如此重要？\n对于 listen_sockfd：在 epoll 的 ET (边缘触发) 模式下，如果多个客户端连接请求同时到达，内核只会通知你一次。你必须在一个循环中持续调用 accept()，直到它返回 -1 并且 errno 为 EAGAIN 或 EWOULDBLOCK，这表示所有已到达的连接都已被处理完毕。\n如果 listen_sockfd 是阻塞的，那么当你处理完所有排队的连接后，最后一次 accept() 调用就会永远阻塞在那里，导致你的整个事件循环被卡住，服务器彻底失去响应。\n对于 client_sockfd：同样，在 ET 模式下，当 epoll_wait 通知你某个客户端 socket 可读时，你必须在一个循环中持续调用 read()，直到把内核缓冲区中的数据全部读完。\n如果 client_sockfd 是阻塞的，那么当你读完所有数据后，最后一次 read() 调用就会永远阻塞，等待该客户端的下一批数据，同样会卡死事件循环。\nwrite() 操作同理，当发送缓冲区满时，阻塞的 write() 会卡住整个服务器。\n因此, 在上述的ET模式下, 我们使用了setnonblocking函数将 socket 设置为非阻塞模式：\n#include &lt;fcntl.h&gt;void setnonblocking(int sockfd) {    // 1. 读取当前的状态标志    int flags = fcntl(sockfd, F_GETFL, 0);    if (flags &lt; 0) {        perror(\"fcntl(F_GETFL)\");        return;    }    // 2. 添加 O_NONBLOCK 标志    flags |= O_NONBLOCK;    // 3. 将新的标志设置回去    if (fcntl(sockfd, F_SETFL, flags) &lt; 0) {        perror(\"fcntl(F_SETFL)\");    }}\n\n注意, 如果你想把一个 socket 设置为非阻塞模式，绝对不能直接用 fcntl(fd, F_SETFL, O_NONBLOCK). 因为这样做会覆盖掉 fd原有的所有其他状态标志。\n正确的做法是采用“读取-修改-写入”三部曲：\n\n读取：先用 F_GETFL 获取当前所有的标志位。\n修改：在获取到的标志位基础上，使用位或 | 运算来添加 O_NONBLOCK 标志。\n写入：最后用 F_SETFL 将这个新的、包含了所有标志位的整数值设置回去。\n\nepoll 相对于 select/poll 的优缺点优点:\n\n高并发处理能力：epoll 可以轻松处理成千上万个并发连接，而不会像 select/poll 那样因为线性扫描而导致性能瓶颈。\n低延迟：由于内核与用户空间共享内存，减少了内存拷贝的开销，epoll_wait 的响应速度更快。\n灵活的事件通知机制：支持 LT 和 ET 两种模式，开发者可以根据应用需求选择合适的模式。\n更好的资源利用率：epoll 采用了事件驱动的方式，避免了无效的轮询，能够更高效地利用系统资源。\n简化的编程模型：与传统的 select/poll 相比，epoll 提供了更简单的编程接口，减少了复杂的状态管理。\n\n缺点:\n\nLinux 专有：epoll 是 Linux 特有的接口，无法跨平台使用。如果需要在不同操作系统上运行，必须使用 select 或 poll。\n编程复杂度：尤其是在 ET 模式下，要求开发者必须非常小心地处理 I/O 操作，否则容易出现数据丢失或服务器卡死的情况。\n\n基于 epoll 的 Reactor 模式Epoll Reactor 模式，简单来说，就是使用 epoll 作为 I/O 多路转接机制来实现 Reactor 设计模式。它是一个在单线程（或少量线程）中通过事件循环来高效处理大量并发网络连接的架构。\n\nReactor 模式是一种典型的事件驱动（Event-Driven）编程模型，广泛用于高并发网络编程中。核心思想是将事件分离为：事件检测（I/O多路复用） + 事件分发（分派给处理器）。\n\n一个典型的 Reactor 模式实现包含以下几个关键角色：\n\nReactor (反应器/调度器): 整个事件处理的中心。它内部持有一个 epoll 实例，负责运行事件循环 (Event Loop)。它的核心工作就是调用 epoll_wait() 等待事件，然后根据事件的类型，将事件分发 (Dispatch) 给对应的处理器。它本身不处理任何业务逻辑。\n\nHandler (事件处理器): 处理特定类型的事件。这是一个抽象的角色，通常会定义一个接口或基类，包含 handle_event() 这样的方法。它与一个文件描述符（fd）绑定。\n\nConcrete Handler (具体事件处理器): 实现 Handler 接口，执行具体的业务逻辑。在我们的服务器中，至少有两种具体处理器：\n\nAcceptor (接收器)：一种特殊的 Handler，它只与监听套接字 (listen_sockfd) 绑定。它的唯一职责就是处理“新连接”事件，即调用 accept()，然后创建一个新的 Connection Handler 来处理这个新连接。\nConnection Handler (连接处理器)：与客户端套接字 (client_sockfd) 绑定。它负责处理这个连接上的所有读写事件：解析请求、执行业务逻辑、准备并发送响应。\n\n\n\nEpoll Reactor 的工作流程下面是这个模型运作的详细步骤：\n\n初始化阶段：\n\n服务器程序启动，创建一个 Reactor 对象。Reactor 内部调用 epoll_create() 创建一个 epoll 实例。\n\n服务器创建一个监听套接字 listen_sockfd，并完成 bind() 和 listen()。\n\n服务器创建一个 Acceptor 对象，并将 listen_sockfd 交给它管理。\n\n服务器调用 Reactor 的 register_handler() 方法，将 Acceptor 注册进去。Reactor 内部会调用 epoll_ctl(EPOLL_CTL_ADD, listen_sockfd, …)，开始监听新连接事件 (EPOLLIN)。\n\n\n\n事件循环阶段：\n\n服务器启动 Reactor 的主事件循环 event_loop()。这是一个 while(true) 循环。Reactor 在循环中调用 epoll_wait()，阻塞等待事件的发生。\n\n事件分发与处理：epoll_wait() 返回，带来一个或多个就绪的事件。Reactor 遍历这些事件。\n\n情况A：如果是 listen_sockfd 上的 EPOLLIN 事件\n\nReactor 知道这个 fd 对应的是 Acceptor。\nReactor 调用 Acceptor 的 handle_event() 方法。\nAcceptor 的 handle_event() 内部调用 accept() 接受新的客户端连接，得到一个新的 client_sockfd。\nAcceptor 为这个新的 client_sockfd 创建一个全新的 Connection Handler 对象。\nAcceptor 请求 Reactor 将这个新的 Connection Handler 注册进来。Reactor 随即调用 epoll_ctl 将 client_sockfd 也加入到 epoll 的监听队列中，关注其 EPOLLIN 事件。\n\n\n情况B：如果是某个 client_sockfd 上的 EPOLLIN 事件\n\nReactor 知道这个 fd 对应的是一个 Connection Handler。\nReactor 调用这个 Connection Handler 的 handle_event() 方法。\nConnection Handler 在其方法内部执行 read() 读取数据，进行业务逻辑处理（例如，像我们之前一样，转换成大写）\n接着修改事件为 EPOLLOUT，请求 Reactor 更新 epoll_ctl，将这个 client_sockfd 的事件改为 EPOLLOUT。\n当 epoll_wait 再次返回时，如果这个 client_sockfd 上有 EPOLLOUT 事件，Reactor 会再次调用这个 Connection Handler 的 handle_event() 方法。\nConnection Handler 这次执行 write() 将处理结果发送回客户端。\n如果 read() 发现客户端已断开，Connection Handler 就会请求 Reactor 将自己注销。Reactor 会调用 epoll_ctl(EPOLL_CTL_DEL, …) 并销毁这个 Connection Handler 对象。\n\n\n\n\n\n\n\n\n示例/* * 程序名：reactor_server.cpp * 功能：一个完整的、基于 Epoll ET模式 + 非阻塞IO 的 Reactor 模型服务器。 * 业务：一个 Echo 服务器，将客户端发来的消息转为大写后返回。 */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt;#include &lt;cerrno&gt;#include &lt;cctype&gt;// 前向声明 Reactor 类，因为 EventHandler 中会用到它class Reactor;// 抽象事件处理器基类 (Handler)// 提供统一的接口，让不同类型的事件（监听 socket、客户端 socket）都能被 Reactor 调度。// 所有具体的事件处理器（Acceptor, ConnectionHandler）都继承自它。class EventHandler {public:    virtual ~EventHandler() {}    // 纯虚函数，由子类实现，用于处理具体的事件    virtual void handle_event(uint32_t events) = 0;    // 纯虚函数，由子类实现，用于获取该处理器关联的文件描述符    virtual int get_fd() const = 0;};// Reactor 核心类 (反应器/调度器)// 负责管理 epoll 实例，运行事件循环，并将事件分发给对应的 EventHandler。class Reactor {private:    int epoll_fd; // epoll 实例的文件描述符    // 使用哈希表存储 fd 到其对应 EventHandler 指针的映射    std::unordered_map&lt;int, EventHandler*&gt; handlers;public:    // 构造函数：创建 epoll 实例    Reactor() {        epoll_fd = epoll_create1(0);        if (epoll_fd &lt; 0) {            perror(\"epoll_create1\");            exit(EXIT_FAILURE);        }    }    // 析构函数：关闭 epoll 文件描述符    ~Reactor() {        close(epoll_fd);    }    // 注册事件处理器    void register_handler(EventHandler* handler, uint32_t events) {        int fd = handler-&gt;get_fd();        struct epoll_event ev;  // 作用是描述要监听的事件, epoll_event的结构是:         // struct epoll_event {        //     uint32_t     events;      /* Epoll events (bit mask) */        //     epoll_data_t data;        /* User data variable */        // };            ev.events = events;        ev.data.ptr = handler; // 核心：将 handler 指针存入 data.ptr，实现 fd 和 handler 的绑定        if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &amp;ev) &lt; 0) {  // Epoll得以监听该 fd, 关心可读事件 (EPOLLIN)和边缘触发 (EPOLLET)            perror(\"epoll_ctl: add\");            return;        }        handlers[fd] = handler; // 将 fd 和 handler 的映射关系存入哈希表    }    // 修改事件处理器监听的事件    void modify_handler(EventHandler* handler, uint32_t events) {        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler;        if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &amp;ev) &lt; 0) {            perror(\"epoll_ctl: mod\");        }    }    // 移除事件处理器    void remove_handler(EventHandler* handler) {        int fd = handler-&gt;get_fd();        if (epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL) &lt; 0) {            perror(\"epoll_ctl: del\");        }        handlers.erase(fd); // 从哈希表中移除映射关系        // 注意：这里由调用者负责 delete handler 对象，Reactor 本身不管理其生命周期    }    // 事件循环 (Event Loop)    void event_loop() {        std::vector&lt;struct epoll_event&gt; ready_events(1024);  // 用于存储就绪事件的数组        while (true) {            // 阻塞等待事件发生            int n = epoll_wait(epoll_fd, ready_events.data(), ready_events.size(), -1);            if (n &lt; 0) {                if (errno == EINTR) continue; // 被信号中断，继续等待                perror(\"epoll_wait\");                break;            }            // 遍历所有就绪的事件            for (int i = 0; i &lt; n; ++i) {                // 从 data.ptr 中取回 handler 指针，并进行类型转换                EventHandler* handler = static_cast&lt;EventHandler*&gt;(ready_events[i].data.ptr);                // 调用 handler 的方法处理事件                handler-&gt;handle_event(ready_events[i].events);            }        }    }};// 工具函数：设置文件描述符为非阻塞模式bool set_nonblocking(int fd) {    int flags = fcntl(fd, F_GETFL, 0);    if (flags == -1) {        perror(\"fcntl: F_GETFL\");        return false;    }    if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) {        perror(\"fcntl: F_SETFL\");        return false;    }    return true;}// 具体事件处理器：处理已连接客户端的读写事件 (Connection Handler)class ConnectionHandler : public EventHandler {private:    int fd;             // 客户端 socket fd    Reactor* reactor;   // 指向 Reactor 的指针，用于修改或移除自身    std::string read_buffer;  // 读缓冲区    std::string write_buffer; // 写缓冲区public:    ConnectionHandler(int cfd, Reactor* r) : fd(cfd), reactor(r) {}    ~ConnectionHandler() {        close(fd);    }    int get_fd() const override { return fd; }    // 事件处理入口    void handle_event(uint32_t events) override {        if (events &amp; (EPOLLHUP | EPOLLERR)) { // 发生挂起或错误            handle_close();            return;        }        if (events &amp; EPOLLIN) { // 可读事件            handle_read();        }        if (events &amp; EPOLLOUT) { // 可写事件            handle_write();        }    }private:    // 处理读事件    void handle_read() {        char buf[1024];        ssize_t n;        // ET 模式，必须循环读取直到返回 EAGAIN        while ((n = read(fd, buf, sizeof(buf))) &gt; 0) {            read_buffer.append(buf, n);        }        if (n == 0) { // 客户端关闭连接            handle_close();        } else if (n &lt; 0) {            if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 真正的错误                perror(\"read\");                handle_close();            }        }        // 收到数据后，进行业务处理并准备发送        if (!read_buffer.empty()) {            // 业务逻辑：将接收到的字符转为大写            for (char &amp;c : read_buffer) {                c = toupper(c);            }            write_buffer += read_buffer; // 将处理后的数据放入写缓冲区            read_buffer.clear();            // 数据已准备好，注册写事件，以便在 socket 可写时发送            reactor-&gt;modify_handler(this, EPOLLIN | EPOLLOUT | EPOLLET);        }    }    // 处理写事件    void handle_write() {        ssize_t n;        // 循环写入，直到写缓冲区为空或 socket 发送缓冲区满        while (!write_buffer.empty()) {            n = write(fd, write_buffer.c_str(), write_buffer.length());            if (n &gt; 0) {                write_buffer.erase(0, n); // 从写缓冲区中移除已发送的数据            } else if (n &lt; 0) {                if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 真正的错误                    perror(\"write\");                    handle_close();                }                break; // 发送缓冲区满了，等待下一次 EPOLLOUT 通知            }        }        // 如果数据都写完了，就不再关心写事件，避免 epoll_wait 忙轮询        if (write_buffer.empty()) {            reactor-&gt;modify_handler(this, EPOLLIN | EPOLLET);        }    }        // 处理关闭连接    void handle_close() {        std::cout &lt;&lt; \"Client \" &lt;&lt; fd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;        reactor-&gt;remove_handler(this); // 从 Reactor 中移除自己        delete this; // 自我销毁，释放资源    }};// 具体事件处理器：处理新连接的接收事件 (Acceptor)class Acceptor : public EventHandler {private:    int listen_fd;    // 监听 socket fd    Reactor* reactor; // 指向 Reactor 的指针public:    Acceptor(int lfd, Reactor* r) : listen_fd(lfd), reactor(r) {}    int get_fd() const override { return listen_fd; }    // 处理新连接事件    void handle_event(uint32_t events) override {        if (events &amp; EPOLLIN) {            struct sockaddr_in client_addr;            socklen_t len = sizeof(client_addr);            int client_fd;            // ET 模式，必须循环 accept 直到返回 EAGAIN            while ((client_fd = accept(listen_fd, (struct sockaddr*)&amp;client_addr, &amp;len)) &gt; 0) {                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr)                           &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                                set_nonblocking(client_fd); // 将新连接设置为非阻塞                                // 为新连接创建一个 ConnectionHandler 并注册到 Reactor                ConnectionHandler* handler = new ConnectionHandler(client_fd, reactor);                reactor-&gt;register_handler(handler, EPOLLIN | EPOLLET); // 初始只关心读事件            }            if (client_fd == -1 &amp;&amp; (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK)) {                perror(\"accept\");            }        }    }};// 主函数int main(int argc, char* argv[]) {    if (argc != 2) {        std::cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" &lt;port&gt;\\n\";        return 1;    }    // 1. 创建、绑定、监听 socket    int port = atoi(argv[1]);    int listen_fd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_fd &lt; 0) { perror(\"socket\"); return 1; }    int opt = 1;    setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);    serv_addr.sin_port = htons(port);    if (bind(listen_fd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {        perror(\"bind\"); return 1;    }    if (listen(listen_fd, SOMAXCONN) &lt; 0) {        perror(\"listen\"); return 1;    }        // 2. 将监听 socket 设置为非阻塞，配合 ET 模式    set_nonblocking(listen_fd);    // -------------3. 初始化 Reactor 和 Acceptor--------------    Reactor reactor;    Acceptor acceptor(listen_fd, &amp;reactor);        // 4. 将 Acceptor 注册到 Reactor，监听新连接事件    reactor.register_handler(&amp;acceptor, EPOLLIN | EPOLLET);    // 5. 启动服务器    std::cout &lt;&lt; \"Reactor Server is running on port \" &lt;&lt; port &lt;&lt; \"...\" &lt;&lt; std::endl;    reactor.event_loop(); // 进入事件循环    close(listen_fd);    return 0;}\n总结总之, 多路 I/O 转接是解决 C10K（单机同时处理上万连接）问题的关键技术。它通过一个线程管理大量连接的方式，将服务器从繁重的线程/进程创建和调度中解放出来，将 CPU 的精力集中在实际的 I/O 数据处理上。像 Nginx、Redis、Node.js 等著名的高性能软件，其底层都无一例外地使用了 epoll 或类似的 I/O 转接技术。\n","categories":["web","language","C++"],"tags":["web","C++"]}]