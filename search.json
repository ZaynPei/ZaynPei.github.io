[{"title":"缓存替换策略","url":"/2025/09/28/algorithms/%E7%BC%93%E5%AD%98%E6%9B%BF%E6%8D%A2%E7%AD%96%E7%95%A5/","content":"自适应替换缓存（Adaptive\r\nReplacement Cache, ARC）\r\n"},{"title":"双指针","url":"/2025/07/31/algorithms/TwoPointers/","content":"什么是双指针法？(What\r\nis the Two-Pointers Technique?)\r\n双指针（Two\r\nPointers）是一种算法设计思想，它通过在数据结构（通常是数组或链表）上维护两个指针，并让它们以一定的规则移动，从而协同完成任务。\r\n\r\n这里的“指针”并非 C/C++ 中的内存地址指针，而更多是指索引 (index)\r\n或迭代器 (iterator)，用来标记数据序列中的位置。\r\n\r\n核心目标：双指针法的主要目标通常是将一些需要嵌套循环（时间复杂度为\r\nO(n²)）才能解决的问题，优化为只需一次遍历（时间复杂度为\r\nO(n)）即可解决。它通过巧妙的指针移动，减少了不必要的计算和比较。\r\n通俗比喻：\r\n想象一下在一条长长的跑道上，有两个运动员。我们可以让他们：\r\n\r\n一个跑得快，一个跑得慢（快慢指针）。\r\n从跑道的两端同时出发，相向而行（左右指针）。\r\n都从起点出发，但保持一定距离，像一个“窗口”一样前进（滑动窗口）。\r\n\r\n通过观察这两个运动员的位置关系和他们所在位置的“风景”（数据），我们就能高效地解决问题。\r\n\r\n双指针法的三种主要模式\r\n双指针主要有以下三种经典的模式\r\n1. 快慢指针 (Fast &amp; Slow\r\nPointers)\r\n这种模式下，两个指针从同一端点出发，但移动速度不同。快指针 fast\r\n负责在前面探索，慢指针 slow 负责处理“已确认”的部分。\r\n典型应用1：移动零\r\n问题：将所有 0\r\n移动到数组末尾，保持非零元素相对顺序。\r\n思想：\r\n\r\nslow 指针：指向下一个非零元素应该被放置的位置。\r\nfast 指针：遍历整个数组，寻找非零元素。\r\n\r\n过程：\r\n\r\nfast 向前移动，如果 nums[fast] 不是\r\n0，就说明找到了一个需要保留的元素。\r\n将这个非零元素放到 slow 指针的位置\r\nnums[slow] = nums[fast]。\r\nslow 指针前进一步，为下一个非零元素腾出位置。\r\nfast 无论如何都前进一步。\r\n\r\n优势：通过一次遍历就完成了元素的“去芜存菁”和重新排列。\r\n典型应用2：判断链表是否有环\r\n问题：给定一个链表，判断其中是否存在环。\r\n思想：\r\n\r\nslow 指针：每次移动一步。\r\nfast 指针：每次移动两步。\r\n\r\n过程：\r\n\r\n两个指针从链表头同时出发。\r\n如果在某个时刻，fast 指针追上了 slow\r\n指针（即 fast == slow），说明链表中存在环。\r\n如果 fast 指针到达了链表的末尾（即\r\nfast == nullptr 或\r\nfast-&gt;next == nullptr），说明没有环。\r\n\r\n\r\n2. 左右指针 (Left &amp; Right\r\nPointers)\r\n也称为“对撞指针”或“首尾指针”。两个指针分别位于数据序列的两端，然后根据特定条件向中间移动。这种模式通常适用于已经排好序的数组。\r\n典型应用：两数之和 II -\r\n输入有序数组\r\n问题：在一个升序数组中，找到两个数，使它们的和等于目标值\r\ntarget。\r\n思想：\r\n\r\nleft 指针：指向数组开头，即最小值。\r\nright 指针：指向数组末尾，即最大值。\r\n\r\n过程：\r\n\r\n计算 sum = nums[left] + nums[right]。\r\n如果 sum == target，恭喜，找到了！\r\n如果\r\nsum &lt; target，说明当前的和太小了，需要增大总和，所以让\r\nleft 指针向右移动一位（left++）。\r\n如果\r\nsum &gt; target，说明当前的和太大了，需要减小总和，所以让\r\nright 指针向左移动一位（right--）。\r\n循环直到 left 和 right 相遇。\r\n\r\n优势：通过在两端逼近，每次迭代都能排除一个不可能的选项，将\r\nO(n²) 的暴力搜索优化为 O(n)。\r\n示例:三数之和\r\n给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j],\r\nnums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] +\r\nnums[k] == 0 。请你返回所有和为 0 且不重复的三元组。\r\nclass Solution {public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) {        vector&lt;vector&lt;int&gt;&gt; sum;        if(nums.size()&lt;3) return sum;        sort(nums.begin(),nums.end());        int n = nums.size();        for(int i= 0;i&lt;n-2;i++){            if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue;   // 去重逻辑1: 对于连着的同一个i只看一次            int j=i+1, k=n-1;   // 去重逻辑2: j的起点是i+1, 因为更小的j已经被当做i遍历过            while(j&lt;k){                // 方法1                // if(nums[j]+nums[k] == -nums[i]){                //     vector&lt;int&gt; temp = {nums[i],nums[j],nums[k]};                //     if(find(sum.begin(),sum.end(),temp) == sum.end())                //         sum.push_back({nums[i],nums[j],nums[k]});                // }  直接遍历去重会部分超时                // if(nums[j]+nums[k] &gt; -nums[i]) k--;                // else j++;                // 方法2                if(nums[j]+nums[k] == -nums[i]){                    sum.push_back({nums[i],nums[j],nums[k]});                    // 去重逻辑 3: 跳过所有与当前 j 相同的元素, 因为i不变，当j取的数的值与前一个相同时不用在计算                    while (j&lt;k &amp;&amp; nums[j] == nums[j + 1]) {                        j++;                    }                    // 去重逻辑 3: 跳过所有与当前 k 相同的元素                    while (j&lt;k &amp;&amp; nums[k] == nums[k - 1]) {                        k--;                    }                    j++;                    k--;                }                else if(nums[j]+nums[k] &gt; -nums[i]) k--;                else j++;                        }        }        return sum;    }};\r\n3. 滑动窗口 (Sliding Window)\r\n这可以看作是快慢指针的一种特例，两个指针 start 和\r\nend 构成一个“窗口”。窗口通常会先扩大（移动 end\r\n指针），然后在满足一定条件后缩小（移动 start\r\n指针），整个过程就像一个窗口在数据上滑动。\r\n典型应用：长度最小的子数组\r\n问题：给定一个正整数数组和一个目标值\r\ns，找出该数组中满足其和 ≥ s 的长度最小的连续子数组。\r\n思想：\r\n\r\nstart 指针：窗口的左边界。\r\nend 指针：窗口的右边界。\r\n维护一个变量 window_sum 记录窗口内元素的和。\r\n\r\n过程：\r\n\r\n扩大窗口：end 指针不断向右移动，并将新元素加入\r\nwindow_sum。\r\n判断与收缩窗口：一旦\r\nwindow_sum ≥ s，就说明找到了一个满足条件的窗口。\r\n记录下当前窗口的长度\r\nend - start + 1，并与已记录的最小长度比较。\r\n尝试缩小窗口：从 window_sum 中减去\r\nnums[start] 的值，并将 start\r\n指针向右移动。\r\n持续缩小，直到\r\nwindow_sum &lt; s，然后再去扩大窗口。\r\n重复此过程，直到 end 到达数组末尾。\r\n\r\n优势：巧妙地避免了对所有可能的子数组进行求和的暴力计算。每个元素最多被访问两次（一次被\r\nend 指针扫过，一次被 start 指针扫过），时间复杂度为 O(n)。\r\n\r\n总结：何时考虑使用双指针？\r\n当遇到一个问题，特别是涉及数组或链表时，如果发现有以下特征，可以优先考虑双指针法：\r\n\r\n需要进行原地操作：要求空间复杂度为\r\nO(1)，直接在原数组上修改，如“移动零”。\r\n涉及有序数组的配对问题：需要在有序数组中寻找满足特定和、差、积的数对，如“两数之和\r\nII”。\r\n寻找连续子数组/子串的极值问题：要求满足某个条件的“最长”、“最短”、“最大”、“最小”的连续子数组，如“长度最小的子数组”、“无重复字符的最长子串”。\r\n链表问题：判断环、寻找中点、合并两个有序链表等。\r\n\r\n总之,\r\n双指针法是一种“降维”思想，它将二维的搜索空间（嵌套循环）压缩到一维（线性扫描），是提升算法效率的强大工具。\r\n","categories":["algorithms"],"tags":["algorithms","Pointer"]},{"title":"About Shell","url":"/2025/07/07/misc/Shell/","content":"什么是 Shell\r\nShell\r\n是一个命令行解释器，它为用户提供了一个向操作系统内核发送请求以便运行程序的界面系统级程序。\r\n什么是 Shell 脚本/.sh 文件\r\n.sh 文件，全称为 Shell 脚本文件 (Shell Script File)，是一种为 Shell\r\n编写的脚本程序。它的核心作用是将一系列需要执行的 Shell\r\n命令按照顺序预先写在一个文件里，然后让 Shell\r\n像执行剧本一样，从上到下自动地、依次地执行这些命令，从而实现任务的自动化。\r\n下面是一个简单的文件备份脚本：\r\n#!/bin/bash# 这是一个简单的文件备份脚本# --- 1. 定义变量 ---# 设置要备份的源目录和存放备份的目标目录SOURCE_DIR=\"/home/user/documents\"BACKUP_DIR=\"/mnt/backups/documents\"# 创建一个基于当前日期和时间的时间戳TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\")# 最终的备份路径FINAL_BACKUP_PATH=\"${BACKUP_DIR}/backup_${TIMESTAMP}\"# --- 2. 执行命令 ---# 在屏幕上打印信息，告知用户操作开始echo \"开始备份 ${SOURCE_DIR} 到 ${FINAL_BACKUP_PATH} ...\"# 创建一个带时间戳的新目录用于存放本次备份mkdir -p \"${FINAL_BACKUP_PATH}\"# 使用 rsync 命令（一个强大的文件复制工具）来执行备份# -a: 归档模式，保留所有文件属性# -v: 详细模式，显示过程# -h: 人性化显示大小rsync -avh \"${SOURCE_DIR}/\" \"${FINAL_BACKUP_PATH}/\"# --- 3. 结束 ---# 再次打印信息，告知用户操作完成echo \"备份完成！\"\r\n","categories":["misc"],"tags":["misc"]},{"title":"About GNU/Linux","url":"/2025/06/28/misc/GNU-LINUX/","content":"GNU 项目 (GNU Project)\r\nGNU 项目（发音为 /ɡnuː/，类似 “g-noo”），由理查德·斯托曼 (Richard\r\nStallman) 于 1983 年发起，其核心目标是创建一个完全由自由软件 (Free\r\nSoftware) 组成的、与 Unix 兼容的完整操作系统。这个操作系统被命名为\r\nGNU。\r\n“GNU” 这个名字本身就是一个典型的黑客式幽默，它是一个递归缩写，全称为\r\n“GNU’s Not Unix!”（GNU 不是 Unix!）。这个名字巧妙地表明了 GNU\r\n的目标：它在技术上兼容 Unix，能够运行为 Unix\r\n编写的软件，但在哲学上，它与当时商业化、封闭的 Unix 截然不同。\r\n核心理念：自由软件 (Free\r\nSoftware)\r\n要理解 GNU 项目，就必须理解其基石——“自由软件”的理念。这里的“自由”\r\n(Free) 指的是自由的权利 (Freedom)，而非“免费” (Free of charge)。\r\n理查德·斯托曼认为，软件用户应该拥有控制自己所使用软件的权利。他将这种权利具体化为四项基本自由：\r\n\r\n自由\r\n0：无论出于任何目的，用户都有运行程序的自由。\r\n自由\r\n1：用户有学习和修改程序源代码的自由，从而让程序真正为自己服务。(访问源代码是这项自由的前提。)\r\n自由\r\n2：用户有重新分发软件副本的自由，从而可以帮助他人。\r\n自由\r\n3：用户有将自己修改后的版本分发给他人的自由，从而让整个社区有机会从你的改进中受益。\r\n\r\n一个软件，只有当其用户享有全部这四项自由时，才能被称为“自由软件”。GNU\r\n项目的所有产出都遵循这一原则。\r\nGNU 项目的主要组成部分\r\n为了构建一个完整的操作系统，GNU\r\n项目开发了大量的核心软件组件。这些组件如今已成为几乎所有 Linux\r\n发行版和许多其他开源系统的基石。\r\n\r\nGNU 工具链 (GNU Toolchain) 这是 GNU\r\n项目最核心、影响最深远的贡献之一，是软件开发的“基础设施”。\r\n\r\n\r\nGCC (GNU Compiler Collection)：GNU\r\n编译器套装。最初是 C 语言编译器，现已支持\r\nC++、Objective-C、Fortran、Go、Rust\r\n等多种语言。它是世界上最重要、使用最广泛的编译器之一。\r\nGDB (GNU\r\nDebugger)：一款功能强大且应用广泛的编译型语言命令行调试工具。GDB\r\n允许您“进入”另一个正在运行或崩溃的程序内部，查看其内部状态，并控制其执行流程。它主要用于\r\nC、C++、Go、Rust、Ada 等编译型语言，是 Linux 和 Unix-like\r\n系统下进行软件开发不可或缺的工具。\r\nMake：一个自动化构建工具，可以根据文件依赖关系自动执行编译链接等任务。\r\n\r\n\r\n核心应用程序与工具 (Core Applications &amp; Utilities)\r\n\r\n\r\nBash (Bourne-Again SHell)：GNU\r\n的命令行外壳（Shell），是今天绝大多数 Linux\r\n系统默认的交互界面。\r\nCoreutils (Core\r\nUtilities)：一套包含所有基础命令行工具的软件包，如 ls, cd, cp, mv, rm,\r\ncat 等。\r\n\r\n\r\nGNU 通用公共许可证 (GPL)\r\n\r\n\r\n为了在法律上保障软件的“自由”，斯托曼设计了 GPL (GNU General Public\r\nLicense)。这是一个具有“传染性”的许可证，它要求任何修改或分发受 GPL\r\n保护的软件的人，也必须以 GPL 的形式分享其修改后的版本。\r\n这确保了自由软件的衍生品同样保持自由，防止其被商业公司闭源。\r\n\r\nGNU 与 Linux\r\n：一个历史性的结合\r\n到了 90 年代初，GNU\r\n项目已经基本完成了构建一个完整操作系统所需的所有组件——除了最核心的部分：内核\r\n(Kernel)。\r\n\r\n内核是操作系统的“心脏”，负责管理硬件资源（CPU、内存、硬盘等），并为上层软件提供服务。\r\nGNU 项目自己的内核，名为 GNU\r\nHurd，由于设计过于宏大复杂，开发进度一直非常缓慢。\r\n\r\n就在此时，1991年，一位名叫林纳斯·托瓦兹 (Linus Torvalds)\r\n的芬兰大学生，出于个人兴趣编写了一个与 Unix 兼容的内核，并将其命名为\r\nLinux。他将 Linux 内核以 GPL 许可证发布。\r\n这个行为带来了历史性的结合：\r\nLinux 内核 + GNU 项目的系统软件和工具 = 一个完整、可用的自由操作系统。\r\n这就是我们今天所熟知的“Linux”操作系统。或者说,\r\n这个操作系统更准确的名称应该是 GNU/Linux，因为 GNU\r\n贡献了除了内核之外的绝大部分组件，并且是整个自由软件理念的源头。\r\n","categories":["misc"],"tags":["misc"]},{"title":"内容分发网络（CDN）","url":"/2025/08/27/web/cdn/","content":"内容分发网络（Content Delivery Network,\r\nCDN）是一种构建在现有互联网基础之上的智能虚拟网络。它由分布在全球各地的大量边缘服务器（Edge\r\nServer）组成，旨在通过将网站内容缓存到离用户更近的服务器上，来更快速、更可靠地向用户交付内容。\r\n简单来说，CDN\r\n就像一个遍布全球的“快递网络”。当您访问一个网站时，如果没有\r\nCDN，您的请求需要直接发送到网站的“中心仓库”（即源服务器 Origin\r\nServer），无论这个仓库有多远，都可能导致访问延迟。而有了\r\nCDN，您的请求会被智能地导向离您最近的“快递站点”（即边缘服务器），直接从这个站点获取内容，从而大大缩短了等待时间。\r\n\r\nCDN 的工作原理\r\nCDN\r\n的核心目标是缩短数据传输的物理距离，从而减少延迟。其工作流程通常涉及以下几个关键步骤：\r\n1. 用户发起请求\r\n当用户在浏览器中输入网址并发起访问请求时，这个请求首先会由本地的\r\nDNS（域名系统）服务器处理。\r\n2. 智能 DNS 解析\r\n配置了 CDN 服务的网站，其 DNS 解析过程会被 CDN\r\n的全局负载均衡（GSLB）系统接管。该系统会根据用户的地理位置、网络状况以及各个边缘节点的负载情况，智能地选择一个最优化的边缘服务器，并将其\r\nIP 地址返回给用户。\r\n\r\n这一步是实现“就近访问”的关键。通过智能调度，确保用户的请求被发送到响应速度最快的节点，而非地理位置绝对最近但可能拥堵的节点。\r\n\r\n3. 内容交付\r\n用户的浏览器在获取到最优边缘服务器的 IP\r\n地址后，会直接向该服务器发起请求。\r\n\r\n缓存命中（Cache\r\nHit）：如果该边缘服务器上已经缓存了用户请求的内容（例如图片、CSS\r\n文件或视频），并且缓存尚未过期，服务器会立即将内容响应给用户。这是最理想、最快速的情况。\r\n缓存未命中（Cache\r\nMiss）：如果边缘服务器上没有缓存所需内容，或者缓存已过期，它会向源服务器发起请求，获取最新的内容。\r\n\r\n\r\n这个过程被称为“回源”。边缘服务器从源服务器获取内容后，会将其缓存在本地，以备后续相同请求使用，然后才将内容发送给用户。这样，下一个访问该内容的附近用户就能直接从缓存中获取，实现加速。\r\n\r\n\r\nCDN 的主要优势\r\n使用 CDN 可以为网站和应用带来多方面的显著优势：\r\n1. 提升网站性能和用户体验\r\n\r\n降低延迟：通过从离用户最近的边缘服务器提供内容，显著减少了数据传输时间，加快了页面加载速度。研究表明，网站加载速度的提升能有效降低跳出率，提升用户留存和转化率。\r\n\r\n2. 提高可用性和可靠性\r\n\r\n负载均衡：CDN\r\n将访问流量分散到多个边缘服务器，避免了单一源服务器因流量过大而崩溃的风险。\r\n冗余备份：当某个边缘节点或服务器发生故障时，CDN\r\n的智能调度系统会自动将流量切换到其他健康的节点，保障服务的连续性，实现高可用性。\r\n\r\n3. 增强网站安全性\r\n\r\nDDoS 攻击缓解：CDN\r\n的分布式架构天然能够分散和吸收大规模的分布式拒绝服务（DDoS）攻击流量，保护源服务器不被直接攻击而瘫痪。许多\r\nCDN 服务商还提供 Web 应用程序防火墙（WAF）等增值安全服务。\r\n隐藏源站 IP：由于所有流量都经过 CDN\r\n节点，攻击者无法轻易获取源服务器的真实 IP\r\n地址，从而增加了攻击难度。\r\n\r\n4. 降低带宽成本\r\n\r\n减少源站负载：大部分用户请求由 CDN\r\n的边缘服务器处理，大大减少了回源的次数和数据量。这意味着源服务器所需的带宽显著降低，从而为网站所有者节省了大量的带宽成本。\r\n\r\n\r\nCDN 的关键技术\r\nCDN 的高效运作依赖于多种核心技术：\r\n1. 内容路由技术（负载均衡）\r\n这是 CDN\r\n的大脑。它通过全局负载均衡（GSLB）和本地负载均衡（SLB）技术，实时监测全网的流量和节点状态，将用户请求精准地导向最佳服务节点。\r\n2. 内容分发与存储技术\r\n\r\n拉取模式（Pull）：由用户请求驱动，当边缘节点未命中缓存时主动回源拉取内容。这种模式部署简单，适用于内容更新不频繁的场景。\r\n推送模式（Push）：由网站管理员主动将内容从源站推送到所有边缘节点。这种模式适用于需要提前分发的大文件或热门内容，确保用户首次访问即可命中缓存。\r\n\r\n3. 缓存技术（Caching）\r\nCDN 的核心功能。通过复杂的缓存策略（如设置缓存过期时间 TTL - Time To\r\nLive），决定哪些内容被缓存、缓存多久，以在加速效果和内容新鲜度之间取得平衡。\r\n\r\n镜像站点与 CDN 的区别\r\n在一些游戏的官方网站上，您可能会看到类似这样的选项：\r\n\r\n下载点 1（亚洲服务器）\r\n下载点 2（欧洲服务器）\r\n下载点 3（北美服务器）\r\n\r\n这种方式被称为“镜像站点（Mirror Site）”。它确实是 CDN\r\n的一种早期或简化形式，但与现代 CDN 存在关键区别。\r\n核心区别：手动选择 vs\r\n自动智能调度\r\nCDN 和传统的下载镜像站，最核心的区别在于智能化和自动化程度。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\n下载镜像（Mirror Site）\r\n内容分发网络（CDN）\r\n\r\n\r\n\r\n\r\n工作模式\r\n手动\r\n自动\r\n\r\n\r\n用户操作\r\n用户需要手动选择一个认为最快的下载链接。\r\n用户只需点击一个下载按钮，无需做任何选择。\r\n\r\n\r\n路由方式\r\n静态。链接固定指向某个服务器。\r\n动态、智能。CDN\r\n系统会实时根据用户的地理位置、网络延迟、节点负载等因素，自动将用户请求路由到最优的边缘服务器。\r\n\r\n\r\n可靠性\r\n如果用户选择的某个镜像服务器宕机或拥堵，下载就会失败或变得很慢。\r\n高可靠性。如果某个节点出现问题，系统会自动切换到其他健康的节点，用户几乎无感知。\r\n\r\n\r\n效率\r\n依赖用户的个人判断，不一定能选到最优节点。\r\n通过全局负载均衡（GSLB）确保用户总是连接到当前最理想的服务器，效率最大化。\r\n\r\n\r\n\r\n","categories":["web"],"tags":["web"]},{"title":"尾递归 (Tail Recursion) 与尾调用优化 (TCO)","url":"/2025/09/29/misc/%E5%B0%BE%E9%80%92%E5%BD%92%20(Tail%20Recursion)%20%E4%B8%8E%E5%B0%BE%E8%B0%83%E7%94%A8%E4%BC%98%E5%8C%96%20(TCO)/","content":"要理解尾递归和尾递归优化，首先必须理解程序是如何执行函数调用的。\r\n函数调用与调用栈 (Call Stack)\r\n当一个函数被调用时，计算机会在内存中一个称为\r\n“调用栈” (Call Stack)\r\n的特殊区域创建一个“栈帧” (Stack\r\nFrame)。它可以看作是函数的一次执行实例的“工作区”。它存储了函数的：\r\n\r\n参数 (Arguments)：传递给函数的数值。\r\n局部变量 (Local\r\nVariables)：函数内部定义的变量。\r\n返回地址 (Return\r\nAddress)：函数执行完毕后，程序应该回到哪里继续执行。\r\n\r\n而函数调用的过程就像是往一摞盘子上放盘子：\r\n\r\nmain 函数开始执行，main 的栈帧被压入栈底。\r\nmain 调用函数 A，A 的栈帧被压入栈顶。\r\n函数 A 调用函数 B，B 的栈帧被再次压入栈顶。\r\n函数 B 执行完毕，它的栈帧被弹出，程序根据返回地址回到 A\r\n中继续执行。\r\n函数 A 执行完毕，它的栈帧被弹出，程序回到 main。\r\n\r\n这个调用栈的大小是有限的。如果函数调用链条太长，栈会耗尽空间，导致\r\n栈溢出 (Stack Overflow) 错误，程序崩溃。\r\n普通递归及其问题\r\n让我们以一个经典的阶乘函数为例来说明普通递归 def factorial(n):    if n == 1:        return 1    else:        # 注意：递归调用后，还有一个乘法操作        return n * factorial(n - 1) 当我们计算\r\nfactorial(4) 时，调用栈的变化过程如下：\r\n\r\nfactorial(4) 被调用。它需要计算 factorial(3) 的结果才能完成 4 * …\r\n的计算。factorial(4) 的栈帧入栈。\r\n\r\n调用栈(前面代表栈底或者说高地址, 后部代表栈顶或者低地址):\r\n[factorial(4)]\r\n\r\nfactorial(3) 被调用。它需要 factorial(2) 的结果。factorial(3)\r\n的栈帧入栈。\r\n\r\n调用栈: [factorial(4), factorial(3)]\r\n\r\nfactorial(2) 被调用。它需要 factorial(1) 的结果。factorial(2)\r\n的栈帧入栈。\r\n\r\n调用栈: [factorial(4), factorial(3), factorial(2)]\r\n\r\nfactorial(1) 被调用。它直接返回 1。factorial(1)\r\n的栈帧入栈，然后立即出栈。\r\n\r\n调用栈: [factorial(4), factorial(3), factorial(2), factorial(1)]\r\n-&gt; [factorial(4), factorial(3), factorial(2)]\r\n\r\nfactorial(2) 拿到返回值 1，计算 2 * 1，返回 2。factorial(2)\r\n的栈帧出栈。\r\n\r\n调用栈: [factorial(4), factorial(3)]\r\n\r\nfactorial(3) 拿到返回值 2，计算 3 * 2，返回 6。factorial(3)\r\n的栈帧出栈。\r\n\r\n调用栈: [factorial(4)]\r\n\r\nfactorial(4) 拿到返回值 6，计算 4 * 6，返回 24。factorial(4)\r\n的栈帧出栈。\r\n\r\n问题所在：在普通递归中，每一次递归调用都需要保留当前的栈帧，因为需要用它的信息（比如变量\r\nn）来完成后续的计算。如果递归深度非常大（例如\r\nfactorial(10000)），就会创建成千上万个栈帧，最终导致栈溢出。这种空间复杂度是\r\nO(n)。\r\n尾递归 (Tail Recursion)\r\n尾调用 (Tail Call) 指的是一个函数中最后一步,\r\n操作是调用另一个函数。\r\n尾递归 (Tail Recursion)\r\n是尾调用的一种特殊情况，即这个调用是调用函数自身。\r\n关键点在于，递归调用是整个函数的最后一个动作，其返回值被直接返回，不再参与任何其他计算。\r\n我们可以将上面的阶乘函数改写为尾递归形式，通常需要一个额外的“累加器”参数：\r\ndef factorial_tail(n, accumulator):    if n == 1:        return accumulator    else:        # 最后的动作就是调用自身，没有其他操作        return factorial_tail(n - 1, n * accumulator)# 初始调用# factorial(4) is equivalent to factorial_tail(4, 1) 观察\r\nreturn factorial_tail(n - 1, n * accumulator)，乘法 n *\r\naccumulator 在递归调用之前就计算好了。当 factorial_tail(n-1, …)\r\n被调用时，当前的函数 factorial_tail(n, …) 已经完成了它所有的工作,\r\n这个结果在原函数中直接返回而不需要再进入原函数参与计算。\r\n尾递归优化 (Tail-Call\r\nOptimization, TCO)\r\n尾递归优化 (Tail-Call Optimization, TCO)\r\n是编译器或解释器的一种优化技术。它的目标是消除尾递归调用所带来的额外栈空间开销。\r\n对于支持 TCO\r\n的语言（编译器或解释器），当它检测到一个尾调用时，它会意识到当前的栈帧已经不再需要了。因此，它不会创建一个新的栈帧，而是复用当前的栈帧。\r\n因此, 对于 factorial_tail(4, 1) 的调用过程： - 调用 factorial_tail(4,\r\n1)。栈帧包含 n=4, accumulator=1。 - 检测到尾调用\r\nfactorial_tail(3, 4 * 1)。编译器不会创建新栈帧，而是直接用新参数\r\nn=3, accumulator=4 更新（覆盖）当前的栈帧，然后像 goto\r\n一样跳转到函数开头重新执行。 - 调用栈: [frame(n=4, acc=1)] -&gt; 复用\r\n-&gt; [frame(n=3, acc=4)] - 再次检测到尾调用 factorial_tail(2, 3 *\r\n4)。再次更新当前栈帧。 - 调用栈: [frame(n=2, acc=12)]\r\n以此类推，直到 n=1，直接返回 accumulator 的最终值。\r\n优化的效果：整个递归过程只占用了一个栈帧的空间。它的空间复杂度从\r\nO(n) 降到了\r\nO(1)，等效于一个循环。这样，即使递归一亿次，也不会发生栈溢出。\r\n为什么大多数编程语言不做这个优化\r\n尽管尾递归优化有显著的优势，但许多主流编程语言（如\r\nPython、Java、JavaScript）并不支持 TCO，主要有以下几个原因：\r\n\r\n调试困难 (Debugging Difficulty), 破坏了调用栈：TCO\r\n的本质是销毁（复用）栈帧。如果程序在深层递归中出错，你看不到完整的函数调用链条，因为中间的栈帧信息都丢失了。这对于调试来说是一个巨大的障碍，你无法追溯函数是如何一步步调用到当前状态的。\r\n实现复杂性和语言规范\r\n\r\n对语言设计者是负担：强制要求 TCO\r\n会让语言的规范和编译器的实现变得更加复杂。设计者需要精确定义什么是“尾位置”，并确保所有实现都遵循。\r\n与某些语言特性冲突：在像 C++ 或 Java\r\n这样的语言中，栈上的对象可能有关联的析构函数（或\r\nfinally 块）。如果 TCO\r\n优化掉了栈帧，这些清理代码可能不会被正确执行，导致资源泄露。\r\n\r\n文化和哲学原因\r\n\r\nPython 的理念：Python 的创造者 Guido van Rossum 多次表示反对\r\nTCO。他认为 Python 程序员更倾向于使用明确的循环 (for,\r\nwhile)，这比递归更直观、易读。强制 TCO 会鼓励一种不符合 Python\r\n风格的编程范式，并且他认为调试信息的价值高于 TCO\r\n带来的性能优势。\r\nJava 的情况：Java 虚拟机（JVM）的设计使得 TCO\r\n难以实现，因为它需要修改字节码的验证和安全模型。虽然有一些实验性的支持，但它不是标准特性。\r\n\r\n不认为是必要功能:\r\n在很多面向对象和命令式编程场景下，深度递归并不是一个常见的模式。大多数问题都可以用迭代（循环）清晰地解决。因此，实现\r\nTCO 的投入产出比被认为不高。\r\n\r\n不过, 仍然有部分语言是支持TCO的, 例如:\r\n\r\n某些函数式编程语言：这类语言通常将递归作为核心的循环和控制流结构，因此\r\nTCO 是 必须 的。例如 Scheme（语言规范强制要求 TCO）、Lisp、F#、Scala\r\n等。\r\nC/C++：某些编译器（如 GCC,\r\nClang）在开启较高优化等级（如 -O2 或\r\n-O3）时，可能会进行 TCO，但这不是语言标准所保证的。\r\nJavaScript：ES6\r\n规范中引入了对尾调用优化的支持，但实际实现依赖于具体的 JavaScript\r\n引擎（如 V8,\r\nSpiderMonkey）。然而，许多主流引擎并未完全实现这一特性。\r\n\r\n"},{"title":"域名解析(DNS)","url":"/2025/08/27/web/dns/","content":"什么是 DNS？—— 互联网的“电话簿”\r\nDNS（Domain Name\r\nSystem，域名系统）是互联网一项核心的服务。它最基本的功能，就是将人类易于记忆的域名（例如\r\nwww.google.com）翻译成计算机能够理解和处理的 IP 地址（例如\r\n142.251.42.196）。\r\n这个过程就如同查一本巨大的电话簿：\r\n\r\n姓名（域名）：www.google.com\r\n电话号码（IP 地址）：142.251.42.196\r\n\r\n我们人类习惯于记住有意义的名字，而计算机在网络中通信则依赖于数字地址。DNS\r\n就是连接这两者之间的桥梁，没有它，我们访问每个网站都需要输入一长串无规律的数字，互联网将变得极难使用。\r\n\r\nDNS 解析的核心参与者\r\n在一次完整的域名解析过程中，通常有四类服务器协同工作，像一个分工明确的团队：\r\n1. 递归解析器 (Recursive\r\nResolver)\r\n也常被称为本地 DNS 服务器 (Local\r\nDNS)。它通常由您的网络服务提供商（ISP，例如中国电信）或公共服务商（如\r\nGoogle 的 8.8.8.8、Cloudflare 的 1.1.1.1）提供。\r\n\r\n职责：它不直接拥有域名信息，而是作为用户的“代理”，负责接收用户的查询请求，并通过一系列查询，最终为用户找到并返回一个确切的\r\nIP 地址。它会缓存查询结果，以加速后续的相同请求。\r\n\r\n2. 根域名服务器 (Root Server)\r\n位于 DNS 查询链的顶端，是整个域名系统的起点。全球只有 13\r\n组根服务器（从 A 到 M 命名），但每组都在全球部署了大量镜像。\r\n\r\n职责：它不直接解析域名，而是告诉递归解析器下一步应该去哪里查询，即提供顶级域名服务器的地址。\r\n\r\n3. 顶级域名 (TLD)\r\n服务器 (Top-Level Domain Server)\r\n负责管理特定类型的域名后缀，例如\r\n.com、.org、.net，以及国家/地区代码如.cn（中国大陆）、.jp（日本）等。\r\n\r\n职责：当收到查询请求后（例如查询\r\ngoogle.com），它会指明负责管理这个具体域名的权威域名服务器的地址。\r\n\r\n4. 权威域名服务器\r\n(Authoritative Server)\r\n这是查询链的最后一站。它真正存储着特定域名与其 IP 地址的对应关系（即\r\nDNS 记录）。\r\n\r\n职责：当收到关于它所管辖域名（如\r\nwww.google.com）的查询时，它会给出最终的、权威的答案——目标的 IP\r\n地址。\r\n\r\n\r\nDNS 解析的详细步骤（查询之旅）\r\n下面以您在浏览器中访问 www.google.com 为例，走一遍完整的 DNS\r\n解析流程。这个过程融合了递归查询和迭代查询两种模式。\r\n\r\n背景：您的电脑向它的本地\r\nDNS（递归解析器）发起的是一个“递归查询”，意思是“请你务必帮我找到答案”。而本地\r\nDNS\r\n向其他服务器发起的则是“迭代查询”，意思是“如果你不知道，请告诉我下一步该问谁”。\r\n\r\n\r\n1. 检查本地缓存\r\n\r\n操作：您的电脑在发起网络请求前，会首先检查自身的浏览器缓存和操作系统缓存（包括\r\nHosts 文件），看之前是否访问过 www.google.com 并留下了记录。\r\n原因：这是最快的响应方式。如果本地有记录且未过期，解析过程直接结束，电脑立即使用该\r\nIP 地址发起访问。\r\n\r\n2. 发起递归查询\r\n\r\n操作：如果在本地缓存中未找到记录，您的电脑会将查询请求发送给预先配置好的本地\r\nDNS 服务器（递归解析器）。\r\n原因：电脑将繁琐的查询任务“外包”给了专业的 DNS\r\n服务器。\r\n\r\n3. 递归解析器的迭代查询之旅\r\n本地 DNS 服务器收到请求后，会开启一连串的迭代查询：\r\n\r\n(3a) 查询根域名服务器：本地 DNS\r\n服务器向其中一个根域名服务器发出请求：“你好，请问谁知道 .com\r\n域名的信息？” 根服务器回答：“我不知道 www.google.com 的\r\nIP，但你可以去问负责 .com 的 TLD 服务器，它的地址是 XXX。”\r\n(3b) 查询顶级域名 (TLD) 服务器：本地 DNS 服务器转向\r\n.com 的 TLD 服务器发出请求：“你好，请问谁知道 google.com 的信息？” TLD\r\n服务器回答：“我不知道 www.google.com，但你可以去问 google.com\r\n的权威域名服务器，它的地址是 YYY。”\r\n(3c) 查询权威域名服务器：本地 DNS 服务器最后向\r\ngoogle.com 的权威域名服务器发出请求：“你好，请问 www.google.com 的 IP\r\n地址是什么？”\r\n\r\n4. 获得最终答案\r\n\r\n操作：权威域名服务器查询自己的记录，找到 www\r\n这条主机记录对应的 IP 地址 142.251.42.196，并将其返回给本地 DNS\r\n服务器。\r\n原因：权威服务器拥有最终解释权，它提供的答案是本次查询的终点。\r\n\r\n5. 返回结果并缓存\r\n\r\n操作：本地 DNS 服务器拿到了 IP\r\n地址，它会先将这个对应关系缓存起来（以便下次有其他用户查询时能直接响应），然后将这个\r\nIP 地址返回给您的电脑。\r\n原因：缓存是提升 DNS\r\n解析效率的关键，可以避免对同一个域名进行重复的、从根开始的完整查询。\r\n\r\n6. 浏览器发起连接\r\n\r\n操作：您的电脑收到了 IP 地址\r\n142.251.42.196，您的浏览器就可以利用这个地址向 Google 的服务器发起 TCP\r\n连接，请求网页内容了。\r\n\r\n至此，一次完整的 DNS 域名解析过程就结束了。\r\n","categories":["web"],"tags":["web"]},{"title":"分类算法","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/","content":"分类算法的目标是构建一个模型，用于将新的、未见过的数据点分配到预定义的类别中。\r\n逻辑回归 (Logistic\r\nRegression)\r\n\r\n尽管它的名字中带有”回归”二字，但逻辑回归实际上是一种用于分类的监督学习算法，尤其在处理二分类问题时表现出色。\r\n\r\n逻辑回归是一种预测分析，它通过分析现有数据（自变量），来预测一个离散的、分类型的结果（因变量）。最常见的应用是二分类问题，例如预测一封邮件是否为垃圾邮件（是/否）、一个用户是否会点击广告（点击/不点击）、一个肿瘤是恶性的还是良性的（恶性/良性）。\r\n它的核心思想是：将输入的特征（features）进行线性组合，然后通过一个特殊的非线性函数——Sigmoid函数，将结果映射到\r\n(0,1) 的区间内，这个结果可以被解释为”属于某个类别的概率”。\r\n核心原理\r\n逻辑回归的实现主要包含两个关键部分：预测函数和决策边界。\r\n预测函数：从线性回归到逻辑回归\r\n线性回归模型通常表示为：\r\ny = θ0 + θ1x1 + θ2x2 + ⋯ + θnxn = θTx\r\n这里，y\r\n的输出是连续的，可以是任何数值。但对于分类问题，我们需要一个介于0和1之间的概率值。\r\n为了解决这个问题，逻辑回归引入了 Sigmoid 函数（也称为 Logistic\r\n函数）。\r\n\r\n操作：将线性回归的输出 z = θTx\r\n作为 Sigmoid 函数的输入。\r\n目的：Sigmoid 函数能将任何实数输入”压缩”到 (0,1)\r\n的范围内，这个输出值在逻辑回归中被赋予了概率的意义。\r\n\r\nSigmoid 函数的公式如下：\r\n\r\n将 z = θTx\r\n代入，我们就得到了逻辑回归的预测函数（假设函数） hθ(x)：\r\n\r\n这个 hθ(x)\r\n的输出值，就代表了给定输入 x\r\n时，预测结果为正类（Positive Class, 通常记为 1） 的概率。例如，hθ(x) = 0.7\r\n意味着模型预测该样本有70%的概率属于类别1。\r\n\r\n逻辑回归和线性回归的根本区别就是,\r\n逻辑回归在线性回归的基础上，通过一个 Sigmoid\r\n函数的”包装”，巧妙地将一个回归问题转化为了一个分类问题。\r\n\r\n决策边界 (Decision Boundary)\r\n有了概率之后，我们如何做出最终的分类决策呢？这就需要一个决策边界来建立一个明确的规则，将模型输出的概率值转化为最终的分类结果。\r\n通常我们设定一个阈值（Threshold），最常用的阈值是 0.5。\r\n\r\n如果 hθ(x) ≥ 0.5，则预测类别为\r\n1 (正类)。\r\n如果 hθ(x) &lt; 0.5，则预测类别为\r\n0 (负类)。\r\n\r\n观察 Sigmoid 函数 g(z) 的图像可以发现：\r\n\r\n当 z ≥ 0 时，g(z) ≥ 0.5。\r\n当 z &lt; 0 时，g(z) &lt; 0.5。\r\n\r\n因此，决策边界实际上是由 z = 0 这条线决定的，也就是由 θTx = 0\r\n决定的。\r\nθTx = 0\r\n这个方程定义了一个超平面（在二维空间中是一条直线，三维中是一个平面），它将特征空间一分为二，一边是预测为1的区域，另一边是预测为0的区域。这个超平面就是模型的决策边界。\r\n\r\n重要提示：决策边界是模型属性（由参数 θ\r\n决定），而不是数据集的属性。模型训练的过程，本质上就是在寻找最佳的参数\r\nθ\r\n来确定这个决策边界的位置和方向。\r\n\r\n如何训练模型：代价函数与梯度下降\r\n找到了模型的表达形式，接下来的问题是：如何确定最佳的参数 θ 呢？答案是通过最小化一个代价函数\r\n(Cost Function) 来学习。\r\n代价函数 (Cost Function)\r\n对于逻辑回归，我们不能使用线性回归中的均方误差（MSE）作为代价函数，因为当它与\r\nSigmoid\r\n函数结合时，会形成一个非凸函数，存在很多局部最优解，不利于优化。\r\n因此，逻辑回归采用对数损失函数 (Log\r\nLoss)，也称为二元交叉熵 (Binary\r\nCross-Entropy)。\r\n对于单个训练样本 (x, y)，其代价定义如下：\r\n\r\n这个分段函数可以优雅地合并成一个表达式：\r\nCost(hθ(x), y) = −ylog (hθ(x)) − (1 − y)log (1 − hθ(x))\r\n这个代价函数具有良好的数学特性。\r\n\r\n当真实标签 y = 1\r\n时，如果模型预测的概率 hθ(x)\r\n越接近1，代价就越接近0；如果预测越接近0，代价就趋于无穷大，从而对模型进行”惩罚”。\r\n当真实标签 y = 0\r\n时，逻辑正好相反。\r\n\r\n这样的设计确保了代价函数是一个凸函数，只有一个全局最优解。\r\n对于整个训练集（m个样本），总的代价函数 J(θ)\r\n是所有样本代价的平均值：\r\n\r\n优化算法：梯度下降 (Gradient\r\nDescent)\r\n我们的目标是找到使 J(θ) 最小的参数 θ。梯度下降是最常用的优化算法之一。\r\n我们会从一个随机的 θ\r\n值开始，迭代地更新 θ\r\n的值，每次都沿着代价函数梯度的反方向（即下降最快的方向）移动一小步。通过迭代，逐步逼近代价函数的最小值点，从而找到最优的参数\r\nθ。\r\nθ 的更新规则如下：\r\n\r\n其中：\r\n\r\nα 是学习率 (Learning\r\nRate)，控制每一步更新的步长。\r\n 是代价函数对参数 θj\r\n的偏导数（梯度）。\r\n\r\n经过数学推导，逻辑回归代价函数的梯度可以被简化为：\r\n\r\n所以，梯度下降的最终更新规则是：\r\n\r\n这个过程会一直重复，直到 θ\r\n的值收敛，即代价函数不再显著下降。\r\n逻辑回归的优劣势\r\n优势 (Pros)\r\n\r\n模型简单，速度快：实现简单，计算开销小，训练速度快，易于并行化。\r\n可解释性强：参数 θ\r\n的大小可以直观地反映不同特征对最终结果的影响程度，方便解释。\r\n输出结果是概率：不仅能给出分类结果，还能得到属于该类的概率，这在很多场景下非常有用（如风险评估）。\r\n对数据要求低：不需要满足严格的统计假设，如正态分布等。\r\n\r\n劣势 (Cons)\r\n\r\n容易欠拟合：模型形式相对简单，处理复杂非线性关系的能力有限，可能导致欠拟合。\r\n对特征工程要求高：需要手动进行特征组合和筛选，对数据中的非线性关系需要进行转换。\r\n假设特征间线性关系：它假设数据在”对数几率”（log-odds）上是线性的，如果这个假设不成立，模型表现会很差。\r\n对多重共线性敏感：如果特征之间高度相关，模型的稳定性和解释性会受到影响。\r\n\r\nK-近邻 (K-Nearest Neighbors,\r\nKNN)\r\nKNN\r\n是一种监督学习算法，既可以用于分类任务，也可以用于回归任务。它的核心思想可以用一句非常朴素的话来概括：“近朱者赤，近墨者黑”。一个样本的类别，由它在特征空间中最邻近的\r\nK 个邻居来决定。\r\n同时, KNN 是一种基于实例的学习 (Instance-based\r\nLearning)，也常被称为”懒惰学习” (Lazy Learning)\r\n算法。\r\n\r\n“基于实例”的含义：算法不会从训练数据中学习一个明确的判别函数（像逻辑回归那样得到一个参数化的模型\r\nhθ(x)）。相反，它只是简单地将整个训练数据集存储起来。\r\n“懒惰学习”的含义：它在训练阶段 (Training Phase)\r\n不做任何计算，没有任何”学习”过程。所有的计算都推迟到预测阶段\r\n(Prediction Phase)，即当一个新数据点需要被预测时，算法才开始工作。\r\n\r\n这与逻辑回归、线性回归等”积极学习” (Eager Learning)\r\n算法形成鲜明对比，后者在训练阶段会努力学习出一个模型参数。\r\n\r\n\r\n核心工作原理\r\nKNN 的工作流程非常直观，可以分解为以下三个核心要素：距离度量、K\r\n值的选择、以及决策规则。\r\n距离度量 (Distance Metric)\r\n为了找到新数据点的”邻居”，我们首先需要一种方法来衡量样本之间的”距离”或”相似度”。\r\n\r\n操作：当一个未标记的新数据点出现时，算法会计算它与训练集中每一个数据点之间的距离。\r\n目的：量化样本在特征空间中的远近关系。距离越小，代表两个样本越相似。\r\n\r\n最常用的距离度量是欧几里得距离 (Euclidean\r\nDistance)，也就是我们在二维或三维空间中熟悉的直线距离。对于两个样本点\r\nx = (x1, x2, …, xn)\r\n和 y = (y1, y2, …, yn)，它们之间的欧几里得距离为：\r\n\r\n除了欧氏距离，还有其他距离度量方法，如曼哈顿距离 (Manhattan\r\nDistance)、闵可夫斯基距离 (Minkowski Distance)\r\n等，可以根据数据的特性来选择。\r\n\r\n重要提示：由于距离计算对数据的尺度非常敏感（例如，一个以”米”为单位的特征会比一个以”厘米”为单位的特征在数值上小很多），因此在使用\r\nKNN 之前，对数据进行归一化 (Normalization) 或标准化\r\n(Standardization) 通常是一个至关重要的预处理步骤。\r\n\r\nK 值的选择\r\nK\r\n值代表我们要选择新数据点周围邻居的数量。这是一个需要我们手动指定的超参数。\r\n\r\n操作：在计算完新数据点与所有训练样本的距离后，我们对这些距离进行排序，并选出距离最近的\r\nK 个样本，作为它的”邻居”。\r\n目的：K\r\n值的选择直接决定了模型的复杂度和预测结果，对模型的性能有重大影响。\r\n较小的 K\r\n值：模型会变得非常复杂，容易受到噪声数据的影响。例如，如果\r\nK=1，新样本的类别将完全由距离它最近的一个点决定，这可能导致过拟合\r\n(Overfitting)。\r\n较大的 K 值：模型会变得相对简单。如果 K\r\n值过大（例如等于训练样本总数），模型可能会忽略数据中局部的、有意义的模式，导致欠拟合\r\n(Underfitting)。\r\n\r\n选择最佳 K 值通常需要通过交叉验证等方法来评估不同 K\r\n值下的模型性能。\r\n决策规则 (Decision Rule)\r\n找到了 K\r\n个最近的邻居之后，我们如何利用它们来对新数据点进行预测呢？这取决于任务是分类还是回归。\r\n用于分类任务 (KNN Classification):\r\n\r\n决策规则：采用“少数服从多数”的投票原则。\r\n过程：查看这 K\r\n个邻居分别属于哪个类别，然后选择其中出现次数最多的那个类别作为新数据点的预测类别。例如，如果\r\nK=5，其中有 3 个邻居是”A类”，2\r\n个邻居是”B类”，那么新数据点就被预测为”A类”。\r\n\r\n用于回归任务 (KNN Regression):\r\n\r\n决策规则：采用“取平均值”的方法。\r\n过程：将这 K\r\n个邻居的数值（因变量的值）取平均值（或中位数），将这个平均值作为新数据点的预测值。例如，如果\r\nK=5，这 5 个邻居的房价分别是 100万, 102万, 98万, 105万,\r\n99万，那么新数据点的预测房价就是这五个数的平均值，即 100.8万。\r\n\r\nKNN算法的优劣势\r\n优势 (Pros)\r\n\r\n模型简单，易于理解和实现：算法的直觉性非常强，没有复杂的数学理论。\r\n无需训练：作为一种”懒惰学习”算法，它不需要耗时的训练过程。\r\n对数据分布没有假设：作为非参数模型，它不对数据的底层分布做任何假设，因此能适用于各种形状的决策边界。\r\n可以处理多分类问题：天然支持多分类任务，无需像某些算法一样做特殊处理。\r\n对异常值不敏感：在投票或取平均值的机制下，少数异常邻居点对最终结果的影响有限。\r\n\r\n劣势 (Cons)\r\n\r\n计算成本高，预测慢：在预测阶段，需要计算新样本与所有训练样本的距离，当数据集很大时，这会非常耗时。\r\n对内存需求大：需要存储整个训练数据集，对内存占用较大。\r\n对 K 值的选择敏感：K\r\n值的选择对结果影响巨大，需要仔细调试。\r\n对不平衡样本敏感：如果某些类别的样本数量远多于其他类别，投票时会占据优势，导致预测偏向多数类。\r\n对特征尺度和无关特征敏感：距离计算会受到特征尺度的巨大影响，且高维空间中”距离”的定义可能会变得不那么有意义（维度灾难）。\r\n\r\n支持向量机 (Support\r\nVector Machine, SVM)\r\n支持向量机 (Support Vector Machine,\r\nSVM)是一种经典的有监督学习算法，尤其在处理分类和回归问题上表现出色。它的核心思想非常直观且优雅：在数据点中寻找一个能够将不同类别分得最开、最完美的决策边界。\r\n核心思想：最大化”间隔” (Margin)\r\n想象一下，你有一些黑白两种颜色的豆子散落在桌面上，你需要画一条直线将它们分开。通常，你可能可以画出很多条线都能完成这个任务。但哪一条是最好的呢？\r\nSVM\r\n的回答是：那条距离两边最近的豆子都最远的线是最好的。换句话说，这条线为两个类别创造了尽可能宽的”缓冲地带”或”街道”。这个”缓冲地带”的宽度，在SVM的术语里被称为间隔\r\n(Margin)。\r\nSVM\r\n的目标就是找到这个间隔最大的决策边界。这个决策边界在二维空间里是一条直线，在三维空间里是一个平面，在更高维的空间中则被称为超平面\r\n(Hyperplane)。\r\n\r\n一个更大的间隔意味着我们对分类结果有更高的置信度。这个决策边界对于新的、未知的数据点具有更强的泛化能力，不容易因为数据的轻微扰动而产生误分类。\r\n\r\n关键概念：支持向量 (Support\r\nVectors)\r\n在定义这个最大间隔时，你会发现，Margin的边界正好是由距离决策边界最近的那些数据点”支撑”起来的。这些位于间隔边界上的关键数据点，就被称为支持向量\r\n(Support Vectors)。\r\n支持向量的独特之处在于：\r\n\r\n决定性作用：整个SVM模型只由支持向量决定。决策边界的位置完全取决于这些支持向量，而与其他数据点无关。\r\n高效性：即使训练数据集中有成千上万个点，真正对模型起作用的可能只有一小部分,\r\n即支持向量。这使得SVM在存储和计算上都非常高效。\r\n\r\n你可以想象，只要这些”支撑”边界的点不移动，无论你增加或移动多少其他远离边界的点，决策边界都不会发生任何改变。\r\n核函数 (Kernel Function)\r\n\r\n到目前为止，我们讨论的都是数据点可以用一条直线（或一个平面）完美分开的情况，这被称为线性可分。但如果数据是类似一三象限和二四象限的点，我们便无法用一条直线将两者分开。这就是非线性数据。\r\n\r\nSVM 通过一个非常巧妙的”核技巧 (Kernel Trick)“来解决这个问题。\r\n\r\n核心思想：如果我们无法在当前维度上分割数据，那么我们可以将数据映射到一个更高的维度空间，在那里它们可能就变得线性可分了。\r\n一个直观的例子：想象一下在一张纸上（二维空间）有一些无法用直线分开的红点和蓝点。现在，你突然把这张纸向上弯曲，变成一个三维的曲面。从上往下看，这些点可能就神奇地可以用一个平面分开了。\r\n\r\n核函数是SVM中用于将低维数据映射到高维空间的一种数学工具。它允许SVM处理非线性边界的问题，通过将数据点从低维空间映射到高维空间，从而在新的空间中找到一个线性决策边界。\r\n常见的核函数 (Kernel Functions)：\r\n\r\n线性核 (Linear\r\nKernel)：实际上就是不进行映射，用于处理本身就线性可分的数据。\r\n多项式核 (Polynomial\r\nKernel)：将数据映射到多项式空间。\r\n高斯径向基函数核 (Radial Basis Function, RBF\r\nKernel)：这是最常用、最强大的核函数之一。它能将数据映射到无限维空间，可以处理非常复杂的非线性边界。\r\n\r\n代码实现\r\n# 导入必要的库, svc 是 Support Vector Classifier的缩写from sklearn.svm import SVC# 创建SVM分类器svm_classifier = SVC(kernel='linear')# 训练模型svm_classifier.fit(X_train, y_train)# 预测y_pred = svm_classifier.predict(X_test)\r\nSVM 的优缺点\r\n优点\r\n\r\n在高维空间中非常有效：尤其当特征维度数量大于样本数量时。\r\n模型高效：由于只依赖于支持向量，模型占用的内存较少。\r\n泛化能力强：最大化间隔的原则使其不容易过拟合，对未知数据的预测能力强。\r\n通用性强：通过使用不同的核函数，可以灵活地解决各种线性和非线性问题。\r\n\r\n缺点\r\n\r\n对大规模训练样本效率不高：当训练样本数量巨大时（例如几十万甚至上百万），其计算复杂度会急剧增加。\r\n对参数和核函数的选择敏感：SVM的表现很大程度上依赖于核函数的选择以及一些超参数（如正则化参数C）的设定，需要通过交叉验证等方式进行仔细的调优。\r\n对缺失数据敏感：需要预先对数据进行完整的预处理。\r\n输出不直接包含概率：SVM的原始输出是类别的硬划分，而不是一个点属于某个类别的概率。虽然有方法可以进行扩展，但不是其原生功能。\r\n\r\n决策树 (Decision Tree)\r\n决策树是一种监督学习算法，同样可以用于分类和回归任务。它的模型结构非常直观，就像一个倒立的树，或者说是一个流程图。\r\n它的核心思想是通过一系列的“问题”或“决策”来对数据进行划分，最终导向一个结论。整个模型呈树形结构，包含以下几个关键部分：\r\n\r\n根节点 (Root Node)：代表整个数据集，是树的起点。\r\n内部节点 (Internal\r\nNode)：代表一个特征或属性上的判断。每个内部节点都会引出两个或多个分支。\r\n分支 (Branch)：代表基于内部节点判断的输出结果。 叶节点 (Leaf\r\nNode)：代表最终的决策结果（在分类任务中是类别，在回归任务中是数值）。\r\n\r\n从根节点到任何一个叶节点的路径，都构成了一条决策规则。\r\n想象一下你决定“今天是否出门打篮球”的过程，这本身就是一个决策树：\r\n\r\n根节点：开始决策。\r\n第一个内部节点（问题）：“今天下雨吗？”\r\n\r\n分支 (是)：如果下雨，导向叶节点 -&gt; “不打球”。\r\n分支 (否)：如果不下雨，进入下一个内部节点。\r\n\r\n第二个内部节点（问题）：“有朋友一起吗？”\r\n\r\n分支 (是)：如果有，导向叶节点 -&gt; “去打球”。\r\n分支 (否)：如果没有，导向叶节点 -&gt; “不打球”。\r\n\r\n\r\n这个简单的流程就构成了一个决策树。机器学习中的决策树构建过程，就是让算法自动地、基于数据去学习出这样一个最优的决策流程。\r\n随机森林 (Random Forest)\r\n\r\n随机森林是决策树的“进化版”。它通过一种巧妙的集成思想，克服了单个决策树容易过拟合的缺点，从而在各种任务中都表现出极高的准确性和稳定性。\r\n\r\n随机森林是一种集成学习 (Ensemble Learning)\r\n方法。集成学习的核心思想是“三个臭皮匠，顶个诸葛亮”——即通过构建并结合多个学习器（或模型）来完成学习任务，以获得比单一学习器更好的性能。\r\n它构建了多棵决策树，并将它们集成为一个“森林”。在进行预测时，森林中的每一棵树都会独立地给出一个预测结果，最后算法会综合所有树的预测来得出最终结论。\r\n\r\n对于分类任务：采用投票法，选择得票最多的类别作为最终结果。\r\n对于回归任务：采用平均法，将所有树的预测值取平均作为最终结果。\r\n\r\n这个“森林”不是由一堆相同的树组成的，而是由许多各不相同、具有多样性的决策树构成的。正是这种多样性，使得随机森林具有强大的泛化能力和鲁棒性。\r\n","categories":["ML"]},{"title":"评估指标","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/","content":"KL散度\r\nKL散度（Kullback-Leibler\r\nDivergence），也常被称为相对熵（Relative\r\nEntropy），是信息论和数理统计中一种重要的度量方式。它用于衡量两个概率分布之间的差异性。\r\n通俗地讲，KL散度可以告诉我们：当我们用一个近似的概率分布 Q(x)\r\n来模拟一个真实的概率分布 P(x)\r\n时，会产生多少信息的损失。换句话说，它衡量的是用分布 Q 来代替分布 P 所付出的“代价”。\r\n\r\nKL散度的值越小，表示两个分布越接近；当两个分布完全相同时，KL散度为0。\r\n\r\n数学定义与公式\r\nKL散度在离散型和连续型随机变量上有不同的数学表达形式，但其核心思想是一致的。\r\n1. 离散型概率分布\r\n对于两个离散的概率分布 P(x) 和 Q(x)，从 Q 到 P 的KL散度定义为：\r\n\r\n其中： - 𝒳 是随机变量 x 所有可能取值的集合。 - P(x) 是事件 x 的真实概率。 - Q(x) 是事件 x 的近似概率或模型预测概率。\r\n步骤说明： 1. 计算比值 ：对于每一个可能的事件\r\nx，计算其真实概率与近似概率的比值。这个比值反映了近似分布\r\nQ 相对于真实分布 P 的“偏差程度”。 2.\r\n取对数：对该比值取对数。如果 P(x) &gt; Q(x)，对数值为正；如果\r\nP(x) &lt; Q(x)，对数值为负。\r\n3. 加权求和 P(x)log (…)：用真实分布\r\nP(x)\r\n对上述对数值进行加权。这意味着，我们更关心那些在真实世界中频繁发生（即\r\nP(x)\r\n较大）的事件上，近似分布 Q(x)\r\n表现得如何。如果一个高频事件被 Q\r\n赋予了很低的概率，那么它对总的KL散度贡献就很大，意味着信息损失严重。\r\nKL散度的重要特性\r\n\r\n非负性（Non-negativity）\r\n\r\nKL散度总是大于或等于0。 DKL(P∥∥Q) ≥ 0\r\n只有当两个分布完全相同时，即对于所有的 x 都有 P(x) = Q(x)，KL散度才等于0。这个特性使得它可以被用作衡量“差异”或“距离”的指标。\r\n\r\n不对称性（Asymmetry）\r\n\r\nKL散度一个非常关键的特性是不对称性，也就是说，从 Q 到 P 的KL散度通常不等于从 P 到 Q 的KL散度。 DKL(P∥∥Q) ≠ DKL(Q∥∥P)\r\n正因为如此，KL散度并不是一个真正意义上的“距离”（因为距离度量通常需要满足对称性，例如欧氏距离中A到B的距离等于B到A的距离）。它是一种有方向的度量。\r\n\r\n\r\n\r\n直观理解不对称性：\r\n\r\nDKL(P∥∥Q)：衡量的是用\r\nQ 来近似 P\r\n的信息损失。它会着重惩罚这样一种情况：P(x) 很大，而 Q(x)\r\n很小。也就是说，“真实世界中经常发生，但你的模型却认为它几乎不发生”，这是一种严重的错误，会导致\r\nDKL(P∥∥Q)\r\n的值急剧增大。\r\nDKL(Q∥∥P)：衡量的是用\r\nP 来近似 Q\r\n的信息损失。它会着重惩罚另一种情况：Q(x) 很大，而 P(x)\r\n很小。也就是说，“你的模型认为某事经常发生，但实际上它从不发生”。\r\n\r\n\r\nKL散度的应用\r\nKL散度在机器学习和数据科学领域有着广泛的应用，尤其是在处理概率模型时。\r\n\r\n变分自编码器（Variational Autoencoders, VAE）\r\n\r\n在VAE中，损失函数的一部分就是KL散度。它被用来衡量编码器产生的潜在空间分布（通常是一个高斯分布）与一个标准正态分布（先验分布）之间的差异。通过最小化KL散度，VAE能够学习到一个结构良好、易于采样的潜在空间，从而提升生成新样本的质量。\r\n\r\n评估生成模型\r\n\r\n在训练生成对抗网络（GANs）或其他生成模型时，有时会使用KL散度来评估生成的数据分布与真实数据分布的相似度。\r\n\r\n强化学习\r\n\r\n在一些高级的强化学习算法中（如TRPO、PPO），KL散度被用作一个约束条件，确保策略网络在每次更新时不会与旧策略偏离太远，从而保证训练过程的稳定性。\r\n\r\n信息检索\r\n\r\n在某些信息检索模型中，KL散度可以用来衡量一个文档与用户查询的相关性。将文档和查询都看作是词语的概率分布，KL散度可以度量它们之间的“距离”。\r\n\r\n\r\n","categories":["ML"]},{"title":"CVXOPT","url":"/2025/07/04/lang/python/CVXOPT/","content":"CVXOPT 是一个用于凸优化问题的 Python\r\n库。它提供了一系列用于求解凸优化问题的函数，包括线性规划、二次规划、二次约束等。CVXOPT\r\n的 API 设计得非常直观，使得用户可以方便地定义和求解各种凸优化问题。\r\n二次规划 (QP)\r\n二次规划 (Quadratic Programming, QP)\r\n是一种常见的凸优化问题，其目标函数为二次函数，约束条件为线性不等式。在\r\nCVXOPT 中提供了 QP solver 来求解 QP 问题。\r\n\r\n在金融领域，二次规划常用于资产组合优化。\r\n\r\n下面我们来拆解一下这个词：\r\n\r\nQ - Quadratic (二次的)\r\n\r\n“二次”指的是问题的核心目标像一个”碗”或者”山谷”。它的数学表达式里包含变量的平方，比如\r\nx2。\r\n为什么”碗”这个形状很重要？因为它只有一个最低点。求解器的任务就是精准地找到这个碗底。如果是个平面，那就没有最低点了；如果坑坑洼洼，就会有很多个局部最低点，难以抉择。二次问题（QP）保证了我们能找到那个唯一的、全局的最低点。\r\n\r\nP - Programming (规划)\r\n\r\n这里的”规划”不是指我们平时说的写代码（Programming）。它是一个历史悠久的数学术语，意思是”做计划”或者”寻找最优方案”。\r\n所以，“二次规划”指的就是为二次型问题寻找最优解决方案的计划。\r\n\r\nSolver (求解器)\r\n\r\n这个最好理解，它就是执行这个计划的工具或引擎。你把问题描述给它，它内部有一套非常高效的算法，能自动、快速地帮你找到答案。\r\n\r\n\r\n总结: 一个 QP 求解器 (QP\r\nSolver)，就是一个专门用来寻找”碗状”问题最低点的自动化数学工具。你需要做的就是告诉它你的”碗”长什么样（目标），以及你必须遵守的”规则边界”（约束），然后它就能帮你找到在这些边界内的最低点在哪里。\r\nQP solver流程示例\r\n问题描述\r\n求解以下 QP 问题。\r\n目标函数 (Minimize)： 2x12 + x22 + x1x2 + x1 + x2\r\n约束条件 (Subject to)： - x1 ≥ 0 - x2 ≥ 0 - x1 + x2 = 1\r\n“碗”就是目标函数: 2x12 + x22 + x1x2 + x1 + x2\r\n“规则边界”就是约束条件: x1 ≥ 0, x2 ≥ 0, 和 x1 + x2 = 1\r\nCVXOPT 里的 solvers.qp\r\n就是那个能解决这个问题的求解器。\r\n我们把使用这个库想象成 “给一个很厉害但一板一眼的厨师下订单”\r\n的过程。这位厨师（CVXOPT）厨艺高超，但你必须用他唯一能看懂的、格式固定的订单（矩阵）来告诉他你要什么。\r\n整个过程分为三步：\r\n第 1\r\n步：用大白话描述你的”目标”和”规则”\r\n这一步是给自己看的，先理清思路。\r\n\r\n我的目标是什么？(Objective)\r\n我想要一个”菜”（由原料 x1 和 x2\r\n组成），它的”成本”由公式 2x12 + x22 + x1x2 + x1 + x2\r\n决定。我的目标是让这个成本最低。\r\n我有什么规则？(Constraints)\r\n\r\n规则1：原料 x1\r\n的用量不能是负数 (x1 ≥ 0)。\r\n规则2：原料 x2\r\n的用量也不能是负数 (x2 ≥ 0)。\r\n规则3：两种原料的总用量必须正好是 1 (x1 + x2 = 1)。\r\n\r\n\r\n第 2\r\n步：把”目标”和”规则”翻译成”厨师的订单格式”（矩阵）\r\n这是最关键的一步。这位厨师（CVXOPT）不认识我们的大白话，他只认识一张叫\r\nP, q, G, h, A, b 的标准订单。我们必须把信息填进去。\r\n\r\n填写 P 和 q (描述你的”目标”)\r\n厨师通过 P 和 q 来理解你想要的那个”成本函数”（那个”碗”）。\r\n\r\nP\r\n矩阵描述成本函数里二次项（带平方的项）的部分，它决定了”碗”的形状。\r\nq\r\n矩阵描述成本函数里一次项（不带平方的项）的部分，它决定了”碗”的位置。\r\n\r\n怎么填: 根据数学规则(后面介绍)，我们计算出 \r\n填写 G 和 h (描述你的”不严格”规则)\r\n厨师通过 G 和 h 来理解所有”小于等于”或”大于等于”的规则。\r\n我们的规则是 x1 ≥ 0 和 x2 ≥ 0。订单格式要求写成”小于等于”，所以我们改写成\r\n−x1 ≤ 0 和 −x2 ≤ 0。\r\n怎么填: 我们把这个信息填入订单，得到 \r\n填写 A 和 b (描述你的”死规定”)\r\n厨师通过 A 和 b 来理解所有”必须正好等于”的死规定。\r\n我们的死规定是 x1 + x2 = 1。\r\n怎么填: 我们把这个信息填入订单，得到 \r\n\r\n现在，我们的订单填好了！我们已经成功把我们的想法，翻译成了计算机能懂的语言。\r\n第 3 步：用 Python\r\n代码把”订单”交给”厨师”\r\n这一步就是写代码，把我们刚刚整理好的矩阵告诉 CVXOPT。\r\nfrom cvxopt import matrix, solvers# --- 把我们翻译好的订单内容写下来 ---# 这是告诉厨师，我们目标\"碗\"的形状和位置P = matrix([[4.0, 1.0], [1.0, 2.0]])q = matrix([1.0, 1.0])# 这是我们设定的\"不能超过\"的规则G = matrix([[-1.0, 0.0], [0.0, -1.0]])h = matrix([0.0, 0.0])# 这是我们设定的\"必须等于\"的死规定A = matrix([[1.0, 1.0]])b = matrix(1.0)# --- 把这张\"订单\"正式交给\"厨师\"（求解器），让他开始工作 ---sol = solvers.qp(P, q, G, h, A, b)# --- 查看\"厨师\"给出的最终配方（最优解） ---# sol['x'] 里就是我们想要的 x1 和 x2 的最佳用量print(\"找到了能让成本最低的原料配比：\")print(sol['x'])\r\n数学规则\r\n目标函数\r\n要理解这些矩阵的含义，首先需要了解 cvxopt.solvers.qp\r\n所求解的二次规划问题的标准数学形式。其目标是找到一个向量 x，使得：\r\n\r\n最小化 (Minimize)： \r\n约束条件 (Subject to)：  其中 ≼\r\n表示逐元素小于等于。\r\n\r\n下面我们来逐一解释每个矩阵和向量的含义。\r\n矩阵和向量的含义\r\n\r\nP 和 q：定义目标函数\r\n这两个参数共同构成了你需要最小化的目标函数，它是一个二次函数。\r\n\r\nP (Matrix, 矩阵)：\r\n\r\n这是一个 n × n\r\n的半正定矩阵（positive semi-definite），其中 n 是你要求解的变量 x 的维度。\r\n矩阵 P\r\n描述了目标函数中所有变量的二次关系。在数学上，P 是目标函数 f(x) 的海森矩阵\r\n(Hessian\r\nMatrix)，即由目标函数的二阶偏导数组成的方阵，描述了函数的局部曲率。\r\n格式：在 cvxopt 中，P\r\n必须是 cvxopt.matrix 类型。\r\n计算方法：\r\n\r\n写出目标函数 f(x) = 2x12 + x22 + x1x2 + x1 + x2。\r\n计算 f(x)\r\n对所有变量的一阶偏导（梯度 ∇f(x)）： \r\n计算二阶偏导，构成海森矩阵 H： \r\n\r\n\r\n\r\n\r\n\n    为什么有  \n    \n      数学上，在目标函数中加入 \r\n是一个惯例。这样做可以使得求导后的形式变得简洁（例如，），但它不影响最优点的位置。cvxopt\r\n的标准形式包含了这个 ，所以在定义 P 时，你不需要自己再乘以2。\r\n\n    \n  \r\n\r\nq (Vector, 向量)：\r\n\r\n这是一个 n × 1 的向量。\r\n向量 q\r\n描述了目标函数中所有变量的线性关系。它是在剥离了二次项和常数项后，与\r\nx\r\n线性组合的系数向量。它影响了目标函数曲面的位置。\r\n格式：q 也必须是\r\ncvxopt.matrix 类型。\r\n计算方法：\r\n\r\n审视目标函数 f(x) = 2x12 + x22 + x1x2 + x1 + x2。\r\n找出所有只与变量一次幂相乘的项：x1 + x2。\r\n将这部分写成向量内积的形式 qTx：\r\n\r\n对比系数可得 q1 = 1, q2 = 1。\r\n\r\n结果： \r\n\r\n\r\n\r\nG 和 h：定义不等式约束\r\n这两个参数共同定义了问题中的不等式约束。标准形式 Gx ≼ h\r\n要求所有不等式都是”小于等于”的形式，并且每一行代表一个独立的约束。≼ 符号代表逐元素比较。\r\n\r\nG (Matrix, 矩阵)：\r\n\r\n这是一个 m × n\r\n的矩阵，其中 m\r\n是不等式约束的数量。\r\nG\r\n的每一行定义了一个线性不等式。例如，G 的第一行和 h 的第一个元素共同定义了第一个约束：\r\nG1, 1x1 + G1, 2x2 + ⋯ + G1, nxn ≤ h1\r\n格式：cvxopt.matrix 类型。\r\n\r\nh (Vector, 向量)：\r\n\r\n这是一个 m × 1\r\n的向量。\r\n作用：h 包含了 m 个不等式约束的右侧边界值。\r\n格式：cvxopt.matrix 类型。\r\n\r\n计算方法：\r\n\r\n逐一标准化：将每一个不等式约束都转换为 [...] ≤ [...] 的形式。\r\n\r\n\r\n约束1：x1 ≥ 0 ⟹ −x1 ≤ 0\r\n约束2：x2 ≥ 0 ⟹ −x2 ≤ 0\r\n\r\n\r\n提取系数行向量(每个约束中x的系数)：\r\n\r\n\r\n对于 −x1 ≤ 0，系数行向量是\r\n，右侧常数是 0。\r\n对于 −x2 ≤ 0，系数行向量是\r\n，右侧常数是 0。\r\n\r\n\r\n堆叠成矩阵：将所有系数行向量按顺序堆叠，形成矩阵 G，右侧常数堆叠成向量 h。\r\n\r\n\r\n结果： \r\n\r\n\r\nA 和 b：定义等式约束\r\n这两个参数共同定义了问题中的等式约束（Ax = b）。\r\n\r\nA (Matrix, 矩阵)：\r\n\r\n这是一个 p × n\r\n的矩阵，其中 p\r\n是等式约束的数量。\r\n作用：A\r\n的每一行定义了一个线性等式约束。\r\n格式：cvxopt.matrix 类型。\r\n\r\nb (Vector, 向量)：\r\n\r\n这是一个 p × 1\r\n的向量。\r\n作用：b 包含了 p 个等式约束右侧的目标值。\r\n格式：cvxopt.matrix 类型。\r\n\r\n计算方法 (与G,h类似)：\r\n\r\n审视等式：本例只有一个等式约束 x1 + x2 = 1。\r\n提取系数行向量：，右侧常数为 1。\r\n堆叠成矩阵：本例只有一行。\r\n\r\n\r\n结果： \r\n\r\n\r\n\r\n总结：\r\n\r\nP, q：描述了你想最小化的”成本”函数。\r\nG, h：设定了变量\r\nx 的活动范围（例如 x1 ≥ 0 可以写成 −x1 ≤ 0）。\r\nA, b：设定了变量\r\nx 必须满足的精确关系（例如\r\nx1 + x2 = 1）。\r\n\r\n","categories":["language"],"tags":["language","python"]},{"title":"yield","url":"/2025/06/28/lang/python/yield/","content":"yield 是 Python\r\n中一个功能强大的关键字，它主要用于创建生成器 (Generator)。理解 yield\r\n的关键在于理解生成器是如何工作的。简而言之，当一个函数包含 yield\r\n关键字时，它就不再是一个普通的函数，而是一个生成器函数。\r\n\n    生成器是一种特殊的迭代器 \n    \n      与一次性计算并返回所有结果的普通函数不同，生成器函数会返回一个生成器对象。这个对象可以按需、逐个地“生成”结果，而不是一次性将所有结果都存储在内存中,\r\n它是一种惰性求值的迭代器。\r\n\r\n普通函数 (return): 执行 -&gt; 计算所有结果 -&gt; 返回结果 -&gt;\r\n结束。\r\n生成器函数 (yield): 调用 -&gt; 返回一个生成器对象 (不执行代码)\r\n-&gt; 迭代时, 当执行到 yield才“产出”一个值并暂停 -&gt; 等待下一次迭代\r\n-&gt; 从暂停处继续执行。\r\n\r\n\n    \n  \r\nyield示例\r\n下面的simple_generator函数内部包含了\r\nyield，所以它现在是一个生成器函数。\r\ndef simple_generator():    print(\"生成器开始执行...\")    yield 1        print(\"生成器继续执行...\")    yield 2        print(\"生成器最后一次执行...\")    yield 3        print(\"生成器执行结束。\")# 调用生成器函数，返回一个生成器对象my_gen = simple_generator()print(type(my_gen))print(my_gen)\r\n当执行上述代码时,\r\n输出并不会包含\"生成器开始执行...\"等内部代码.\r\n因为yield的存在,\r\n它只是创建并返回了一个生成器对象，这个对象处于“待命”状态。 &lt;class 'generator'&gt;&lt;generator object simple_generator at 0x...&gt;\r\n而当采用next()函数或者for循环时,\r\n才能来驱动生成器执行并获取其产出的值。 # 重新创建一个生成器对象for value in simple_generator():    print(f\"For 循环获取到的值: {value}\") 输出结果如下:\r\n生成器开始执行...For 循环获取到的值: 1生成器继续执行...For 循环获取到的值: 2生成器最后一次执行...For 循环获取到的值: 3生成器执行结束。\r\nyield优势\r\n\r\n极高的内存效率: 这是 yield\r\n最突出的优点。生成器按需生成值，在任何时刻只有一个值存在于内存中。对于处理大规模数据集、文件流或无穷序列，这是至关重要的。\r\n能够处理无限序列\r\n由于其“懒加载”的特性，你可以轻松定义一个无限序列的生成器，这是列表或元组无法做到的。\r\n代码逻辑更清晰、简洁\r\n对于需要维护内部状态的复杂迭代逻辑（例如，遍历一个树状结构），使用生成器函数通常比自己实现一个迭代器类（包含\r\n__iter__ 和 __next__\r\n方法）要简单得多，代码也更具可读性。\r\n\r\n","categories":["language"],"tags":["language","python"]},{"title":"Coding技巧","url":"/2025/10/09/algorithms/Coding%E6%8A%80%E5%B7%A7/Coding%E6%8A%80%E5%B7%A7/","content":"二分查找\r\n二分查找 (Binary Search)\r\n是一种高效的查找算法，适用于在有序数组或列表中查找特定元素。它通过不断将搜索范围减半来快速定位目标元素，从而大大减少了查找的时间复杂度。\r\n代码实现如下: int binarySearch(const vector&lt;int&gt;&amp; nums, int target) {    int left = 0;    int right = nums.size() - 1;    while (left &lt;= right) {        int mid = left + (right - left) / 2;  // 防止溢出        if (nums[mid] == target) {            return mid;  // 找到目标元素，返回其索引        } else if (nums[mid] &lt; target) {            left = mid + 1;  // 目标在右半部分        } else {            right = mid - 1;  // 目标在左半部分        }    }    return -1;  // 未找到目标元素    // return left;  // 如果需要返回插入位置, 可以返回 left} &gt; 最后的 left 指向第一个大于等于\r\ntarget 的位置, 也就是插入位置.\r\n滑动窗口\r\n滑动窗口是一种用于处理数组或字符串中子序列问题的高效算法技巧。它通过维护一个动态调整的窗口来遍历数据结构，从而避免了重复计算，提高了算法的效率。\r\n固定长度与可变长度滑动窗口\r\n按照窗口的长度是否固定，滑动窗口可以分为两种类型：\r\n\r\n固定长度滑动窗口 (Fixed-size Sliding\r\nWindow)：窗口的大小在整个过程中保持不变。适用于寻找满足某种条件的固定长度子序列的问题。例如，寻找数组中所有长度为k的子数组的最大和。\r\n可变长度滑动窗口 (Variable-size Sliding\r\nWindow)：窗口的大小可以根据需要动态调整。适用于寻找满足某种条件的任意长度子序列的问题。例如，寻找字符串中包含所有目标字符的最短子串。\r\n\r\n固定长度滑动窗口\r\n固定长度滑动窗口的基本思想是维护一个固定大小的窗口，并通过移动窗口来遍历数组或字符串。\r\n-\r\n初始化时，窗口覆盖数据结构的前k个元素，计算初始窗口的相关信息（如和、最大值等）。\r\n- 循环遍历,\r\n逐步向右移动窗口，每次移动一位，通过加入新元素并移除旧元素来更新窗口的信息。\r\n例如, 寻找数组中所有长度为k的子数组的最大和: int maxSumSubarray(const vector&lt;int&gt;&amp; nums, int k) {    int n = nums.size();    if (n &lt; k) return -1;  // 不合法的输入    int maxSum = 0;  // 记录最大和    int cur = 0;  // 记录当前窗口和    // 初始化窗口    for (int i = 0; i &lt; k; i++) {        cur += nums[i];    }    maxSum = cur;    // 循环移动窗口    for (int i = 1; i &lt;= n-k; i++) {        cur += nums[i+k-1] - nums[i-1];  // 更新窗口和        maxSum = max(maxSum, cur);    }    return maxSum;}\r\n对于其他问题, 只要窗口大小固定, 都可以使用类似的方法进行处理,\r\n基本套路都是两步走: 初始化窗口 -&gt; 移动窗口并更新结果.\r\n示例\r\n有这样一道题(leetcode239): 给你一个整数数组 nums，有一个大小为 k\r\n的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k\r\n个数字。滑动窗口每次只向右移动一位。返回滑动窗口中的最大值。\r\n看起来是固定长度滑动窗口问题,\r\n但是如果直接用上面的固定长度滑动窗口方法, 每次移动窗口都需要遍历窗口内的\r\nk 个元素来找最大值, 时间复杂度是 O(n*k), 会超时.\r\n为什么呢? 因为上面的其他固定长度滑动窗口问题, 每次移动窗口时,\r\n只需要加上新元素, 减去旧元素, 窗口内的信息更新是 O(1)\r\n的, 但是求最大值就不行了, 每次移动窗口时,\r\n上一次的最大值可能被移出了窗口, 而我们又没有记录其他元素的信息,\r\n只能遍历窗口内的 k 个元素来找最大值, 这样时间复杂度就是 O(n*k) 了.\r\n为了解决这个问题,\r\n我们需要使用一种特殊的数据结构——单调队列，来维护窗口内的元素顺序,\r\n使得我们可以在 O(1) 时间内获取窗口的最大值.\r\n具体代码可以参考队列部分的笔记.\r\n可变长度滑动窗口\r\n可变长度滑动窗口的核心思想是通过调整窗口的左右边界来满足特定条件。通常使用两个指针/索引（left\r\n和 right）来表示窗口的边界。 - 初始化时，left 和 right\r\n指针都指向数据结构的起始位置。 - 循环遍历,\r\n通过移动 right\r\n指针来扩展窗口，直到窗口满足某种条件（如包含所有目标字符）。\r\n- 然后通过移动 left\r\n指针来收缩窗口，直到窗口不再满足条件。在这个过程中，记录满足条件的窗口信息（如最短长度、最大长度等）。\r\n- 重复上述过程，直到 right 指针遍历完整个数据结构。\r\n\r\n注意:\r\n可变长度滑动窗口通常需要一个辅助数据结构（如哈希表）来记录窗口内的元素信息，以便快速判断窗口是否满足条件。\r\n\r\n一般可变长度滑动窗口的题型有三种: 1.\r\n找出满足某种条件的最小子数组/子字符串。 2.\r\n找出满足某种条件的最大子数组/子字符串。 3.\r\n计算满足某种条件的子数组/子字符串的数量。\r\n例如, 给定一个含有 n 个正整数的数组和一个正整数 target ,\r\n找出该数组中满足其和 ≥ target\r\n的长度最小的连续子数组的长度: (最小长度子数组问题)\r\nint minSubArrayLen(int target, vector&lt;int&gt;&amp; nums) {    int n = nums.size();    if(target&gt;accumulate(nums.begin(),nums.end(),0)) return 0;  // 特殊情况处理    int left=0, right=0;    int minlen = INT_MAX;    int cur = 0;    for(right=0;right&lt;n;right++){  // 扩展窗口        cur += nums[right];  // 增加当前窗口和        while(cur&gt;=target){  // 收缩窗口            minlen = min(right-left+1, minlen);            cur -= nums[left];  // 一定注意先减去left位置的元素, 再left++!!!!!            left++;        }    }    return minlen;}\r\n又例如, 给定一个字符串 s ,\r\n求每个字符最多出现两次的最长子字符串的长度:\r\n(最大长度子字符串问题) int lengthOfLongestSubstringTwoDistinct(string s) {    int n = s.size();    if (n &lt; 3) return n;  // 特殊情况处理    int left = 0, right = 0;    int maxLen = 2;    unordered_map&lt;char, int&gt; charCount;  // 记录窗口内字符的出现次数    for (right = 0; right &lt; n; right++) {  // 扩展窗口        charCount[s[right]]++;        while (charCount.size() &gt; 2) {  // 收缩窗口, 直到左边界到达和右边界相同字符的位置            charCount[s[left]]--;            left++;        }        maxLen = max(maxLen, right - left + 1);  // 更新最大长度    }    return maxLen;} &gt; 其实, 之所以可以滑动窗口解决,\r\n一个必不可少的条件就是连续性,\r\n也就是说问题本质上是求一个连续子数组或者连续子字符串的问题,\r\n这样才能用滑动窗口来解决.\r\n下一个示例则是求子数组个数的问题: 给你一个整数数组 nums 和一个 正整数\r\nk , 请你统计有多少满足 「 nums 中的最大 元素」至少出现 k\r\n次(越多越行)的子数组，并返回满足这一条件的子数组的数目。\r\nclass Solution {public:    long long countSubarrays(vector&lt;int&gt;&amp; nums, int k) {        long long n = nums.size();        int left=0, right=0;        long long sum=0;        int max_num=0;          long long max_sum=0;        for(int i=0;i&lt;n;i++){            max_num = max(nums[i], max_num);  // 找到数组中的最大值        }        for(right=0;right&lt;n;right++){            if(nums[right]==max_num) max_sum++;  // 记录当前窗口内最大值的个数            while(max_sum&gt;=k){  // 收缩窗口, 不过是满足条件时                sum+=n-right;   // 因为要求子数组个数, 所以每次符合条件进入收缩窗口时, 这个数组右边界到数组末尾的所有子数组都是符合条件的                if(nums[left]==max_num) max_sum--;  // 先减去left位置的元素对最大值个数的影响                left++;  // 再移动左指针            }        }        return sum;    }};\r\n还有一个经典问题:\r\n给一个数组的分数定义为数组之和乘以数组的长度。比方说，[1, 2, 3, 4, 5]\r\n的分数为 (1 + 2 + 3 + 4 + 5) * 5 = 75 。给你一个正整数数组 nums\r\n和一个整数 k ，请你返回 nums 中分数 严格小于 k 的\r\n非空整数子数组数目。(越小越行)\r\nclass Solution {public:    long long countSubarrays(vector&lt;int&gt;&amp; nums, long long k) {        long long n = nums.size();        long long sum = 0;        long long left = 0, right = 0;        long long cur_sum = 0;        for(right=0;right&lt;n;right++){            cur_sum += nums[right];  // 增加当前窗口和            while(cur_sum*(right-left+1)&gt;=k){  // 收缩窗口, 如果不满足条件时                cur_sum -= nums[left];  // 先减去left位置的元素对窗口和的影响                left++;  // 再移动左指针            }            sum += (right-left+1);  // 增加符合条件的子数组个数, 这里因为求的是小于k的子数组个数, 所以所有以right结尾的子数组都是符合条件的        }        return sum;    }};\r\n回顾上面两道题, 可以发现, 求子数组个数的问题, 每次满足条件时,\r\n以right结尾的所有子数组, 或者是以left开头的所有子数组, 都是符合条件的,\r\n这样就可以快速统计子数组个数. 也就是当窗口 [left, right]\r\n满足某个条件时，其内部的某些子数组（或外部的某些超数组）也必然满足条件。我们利用这个性质来批量计数。\r\n而且还可以发现,\r\n第一题收缩窗口时是满足条件时收缩窗口,\r\n第二题则是不满足条件时收缩窗口,\r\n这取决于你要统计的子数组是“以 left\r\n开头”还是“以 right 结尾”。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n策略\r\n策略一：满足时收缩\r\n策略二：不满足时收缩\r\n\r\n\r\n\r\n\r\n条件类型\r\n“至少”型 (如 sum ≥ k)\r\n“至多”型 (如 sum &lt;= k)\r\n\r\n\r\n统计对象\r\n所有以 left 为起点的达标数组\r\n所有以 right 为终点的达标数组\r\n\r\n\r\nwhile 循环条件\r\nwhile (条件满足)\r\nwhile (条件不满足)\r\n\r\n\r\n收缩 left 的目的\r\n统计完 left 后，移动到下一个起点\r\n修复窗口，使其重新满足条件\r\n\r\n\r\n计数公式\r\ntotal += n - right; (在 while 内部)\r\ntotal += right - left + 1; (在 for 循环内, while\r\n外部)\r\n\r\n\r\n\r\n除此之外, 还有一种是”恰好”型的问题, 例如求恰好包含 k\r\n个不同字符的最长子字符串,\r\n这种问题可以转化为”至多”型问题来解决, 即: 恰好包含 k\r\n个不同字符的最长子字符串 = 包含 至多 k 个不同字符的最长子字符串 - 包含\r\n至多 (k-1) 个不同字符的最长子字符串.\r\n或者也可以转换w为”至少”型问题来解决, 即: 恰好包含 k\r\n个不同字符的最长子字符串 = 包含 至少 k 个不同字符的最长子字符串 - 包含\r\n至少 (k+1) 个不同字符的最长子字符串.\r\n例如给你一个二元数组 nums ，和一个整数 goal\r\n，请你统计并返回有多少个和为 goal 的 非空 子数组。 class Solution {public:    int mostk(vector&lt;int&gt;&amp; nums, int goal){        int n = nums.size();        int left=0, right=0;        int sum=0;        int level=0;        for(right=0;right&lt;n;right++){            level+=nums[right];            while(level&gt;=goal&amp;&amp;left&lt;=right){  // 符合条件时收缩                sum+=n-right;                level-=nums[left];                left++;            }        }        return sum;    }    int numSubarraysWithSum(vector&lt;int&gt;&amp; nums, int goal) {        return mostk(nums, goal)-mostk(nums, goal+1);  // 转换为\"至少\"型问题, 包含 至少 k 个不同字符的最长子字符串 - 包含 至少 (k+1) 个不同字符的最长子字符串    }};\r\n枚举技巧\r\n侧重于解决问题的通用思维方式，特别是如何优化循环和遍历。\r\n\r\n枚举右，维护左：一种将 O(n2)\r\n复杂度（双变量）问题优化到 O(n)（单变量）的常用技巧，通常与哈希表结合使用。-\r\n枚举中间：处理三元组或四元组问题（如 i &lt; j &lt; k）的有效策略，通过固定中间变量\r\nj，将问题分解为两个独立的子问题（处理\r\ni 和 k）。\r\n遍历对角线：针对矩阵问题的特定遍历方式。\r\n\r\n序列与区间处理\r\n(Sequence &amp; Range Processing)\r\n这种方法用于将一个“朴素”的 O(n2) 解法优化到\r\nO(n)。\r\n在我们的算法题中, 可能会遇到两类问题： - 区间查询\r\n(Range Query)：频繁地询问“数组 i 到 j\r\n之间的和/积/异或值是多少？” - 区间更新\r\n(Range Update)：频繁地操作“把数组 i 到 j 之间的所有数都加上 k。”\r\n如果你对每一次“查询”或“更新”都老老实实地跑一个 for\r\n循环，那么每次操作都是 O(n)， q 次操作就是 O(nq)，这通常会超时。\r\n下面是两种常见且互逆的优化技巧：\r\n前缀和\r\n前缀和 (Prefix Sum)一般用于快速区间查询。 -\r\n原理：花费 O(n)\r\n时间预处理一个prefixSum数组。 -\r\n效果：之后每一次区间查询都降为 O(1) 时间。\r\n例如, 给定一个数组 nums，假如题目要求你频繁地计算子数组\r\nnums[i…j]（闭区间）的和或者相关信息, 此时不急着直接入手,\r\n我们可以构建一个前缀和数组 prefixSum 来预处理，其中\r\nprefixSum[i] 存储 nums[0…i-1]（从第0个到第 i − 1 个元素）的总和。\r\n那么，nums[i…j]（闭区间）的和 sum(i, j)\r\n是多少？ - sum(i, j) = (前\r\nj 个元素的和) − (前 i − 1 个元素的和) - sum(i, j) = prefixSum[j + 1] − prefixSum[i]\r\n这样，我们用 O(n)\r\n预处理，换来了 O(1)\r\n的查询。\r\n再比如, 问题变为“和为 K\r\n的子数组有多少个？” 这个问题等价于：找到多少对 (i, j) 使得 sum(i, j) = K。\r\n用前缀和公式代入：prefixSum[j + 1] − prefixSum[i] = K。\r\n变换一下：prefixSum[i] = prefixSum[j + 1] − K。\r\n这成为了一个“两数之和”问题！这就是“枚举右，维护左”的完美应用： -\r\n枚举右 (j)：我们遍历数组，计算出当前的 prefixSum[j+1]（记为\r\ncurrent_sum）。 - 提问：我们需要在 j 的左边找到一个 i，使得 prefixSum[i] = current_sum -\r\nK。 - 维护左：我们使用一个哈希表 memo 来存储所有历史上的 prefixSum\r\n值及其出现的次数。\r\n例题: 给定一个整数数组 nums 和一个整数 K，请你统计并返回该数组中和为 K 的子数组的个数。(LC 560 和为 K\r\n的子数组个数)\r\nint subarraySum(std::vector&lt;int&gt;&amp; nums, int k) {    // 步骤 1: 初始化哈希表    // 键(Key): 某个前缀和    // 值(Value): 该前缀和出现的次数    std::unordered_map&lt;int, int&gt; memo;    // 步骤 2: 关键初始化    // 放入 (0, 1) 来处理从索引 0 开始的子数组    // 解释: 如果 nums[0...j] 的和恰好为 k,    // 那么 current_sum = k, needed = k - k = 0。    // 我们需要 memo.count(0) 为 true。    memo[0] = 1;    int current_sum = 0;    int total_count = 0;    // 步骤 3 &amp; 4: 一次循环 - 提问、查找、维护    for (int num : nums) {        // a. 更新状态: (枚举右)        current_sum += num;        // b. 提问: 我们需要找的左侧前缀和是什么？        int needed = current_sum - k;        // c. 查找: 左侧存在吗？        // 我们在 map 中查找是否存在键(key)为 needed        if (memo.count(needed)) {            // 如果存在，说明找到了一个或多个以 num 结尾的            // 且和为 k 的子数组。            total_count += memo[needed];        }        // d. 维护: (维护左)        // 把当前的前缀和存入 map，供后续的元素查找        memo[current_sum]++;    }    return total_count;}\r\n如果更一般的, 我们会两次遍历 (Two-pass)，提前预处理 - 第一次遍历\r\n(预处理)：创建一个 std::vector prefixSum，prefixSum[i] 存储\r\nnums[0…i-1] 的和。 - 第二次遍历 (求解)： - 创建一个\r\nstd::unordered_map&lt;int, int&gt; memo。 - 遍历这个\r\nprefixSum 数组（从 prefixSum[0] 到 prefixSum[n]）。 - 在 memo 中查找\r\nprefixSum[j] - k，累加答案。 - 将 prefixSum[j] 存入 memo。 例如:\r\nint subarraySum(std::vector&lt;int&gt;&amp; nums, int k) {    int n = nums.size();    // 步骤 1: 预处理前缀和数组    std::vector&lt;int&gt; prefixSum(n + 1, 0);    for (int i = 1; i &lt;= n; ++i) {        prefixSum[i] = prefixSum[i - 1] + nums[i - 1];    }    // 步骤 2: 初始化哈希表    std::unordered_map&lt;int, int&gt; memo;    memo[0] = 1;  // 处理从索引 0 开始的子数组    int total_count = 0;    // 步骤 3: 遍历前缀和数组    for (int j = 1; j &lt;= n; ++j) {        int needed = prefixSum[j] - k;        // 查找左侧存在吗？        if (memo.count(needed)) {            total_count += memo[needed];        }        // 维护哈希表        memo[prefixSum[j]]++;    }    return total_count;}\r\n常见题型包括: - 基础（一维）与二维前缀和 - 前缀和 +\r\n哈希表：解决特定和（如和为 k）的子数组问题的经典组合。 -\r\n距离和（绝对值问题） - 状态压缩前缀和（处理位运算或小状态集）\r\n树上的前缀和\r\n在树结构中，前缀和的概念可以通过路径和来实现。路径和是指从树的根节点到当前节点的所有节点值的累加和。例如LC\r\n437. 路径总和 III.\r\n题目: 给定一个二叉树的根节点 root 和一个整数目标和 targetSum\r\n，求该树中 路径和等于目标和 的路径数量。路径\r\n不需要从根节点开始，也不需要在叶子节点结束，但路径方向必须是向下的（只能从父节点到子节点）。\r\n// 1. \"前缀和账本\" (哈希表)// 存储 {前缀和 -&gt; 该和出现的次数}std::unordered_map&lt;long long, int&gt; prefixSumCount;// 2. 最终答案int totalPaths = 0;// 3. 目标值int target;/** * @brief 深度优先搜索 (DFS) 辅助函数 * @param node 当前节点 * @param currentPathSum 从根节点到 *当前节点* 的路径总和 */void dfs(TreeNode* node, long long currentPathSum) {    // Base Case: 节点为空，结束递归    if (node == nullptr) {        return;    }    // --- 1. 处理当前节点 ---    // 更新当前路径的前缀和    currentPathSum += node-&gt;val;    // 查找 \"补数\" (currentPathSum - target)    // 看看在祖先中，是否存在一个前缀和 `complement`    long long complement = currentPathSum - target;        // 如果 `complement` 存在于 \"账本\" 中，说明找到了路径    if (prefixSumCount.count(complement)) {        totalPaths += prefixSumCount[complement];    }    // --- 2. 更新状态并进入子树 ---    // 将当前节点的前缀和加入 \"账本\"，供其子节点使用    prefixSumCount[currentPathSum]++;    // 递归处理左右子树    dfs(node-&gt;left, currentPathSum);    dfs(node-&gt;right, currentPathSum);    // --- 3. 恢复现场 (回溯) ---    // 离开当前节点，返回父节点时，必须将当前节点的前缀和从 \"账本\" 中移除    // 这是为了防止干扰 \"兄弟\" 节点的计算    prefixSumCount[currentPathSum]--;}int pathSum(TreeNode* root, int targetSum) {    // 初始化目标值    target = targetSum;        // 初始化哈希表 \"账本\"    // 放入 {0, 1} 是为了正确计算 \"从根节点开始\" 的路径    prefixSumCount[0] = 1;        // 启动 DFS，初始前缀和为 0    dfs(root, 0);        // 返回最终统计的路径总数    return totalPaths;}\r\n差分数组\r\n差分数组 (Difference Array) 一般用于高效区间更新。 -\r\n原理：通过维护一个差分数组\r\ndiff，使得每次区间更新操作都降为 O(1) 时间。 -\r\n效果：之后可以通过一次前缀和计算，得到最终的数组状态。\r\n给你一个数组 nums，我们定义它的差分数组 diff 如下： - diff[0] =\r\nnums[0] - diff[i] = nums[i] - nums[i-1] (对于 i &gt; 0) - 惊人的特性：从 diff\r\n数组还原 nums 数组，只需要对 diff 求前缀和即可。 - \r\n关键操作：如果我们要对 nums 的区间 [i,\r\nj]（闭区间）上的所有元素都加上 val： - nums[i] 增加了\r\nval，而 nums[i-1] 不变，所以 diff[i]（即 nums[i] - nums[i-1]）增加了\r\nval。 - nums[i+1] 到 nums[j] 这一段，由于 nums[k] 和 nums[k-1] 都增加了\r\nval，它们的差 diff[k] 不变 - nums[j] 增加了 val，而 nums[j+1] 不变，所以\r\ndiff[j+1]（即 nums[j+1] - nums[j]）减少了 val。\r\n结论：一次 O(n)\r\n的区间更新 [i, j] 被转化为了两次 O(1) 的单点更新！ -\r\ndiff[i] += val; if (j + 1 &lt; n) { diff[j + 1] -= val; }\r\n例题: LC 1109. 航班预订统计. 有 n 个航班，编号从 1 到 n。有一个预订表\r\nbookings，其中 bookings[i] = [first, last, seats] 表示从 first 到 last\r\n的航班都预订了 seats 个座位。请返回一个长度为 n 的数组 answer，其中\r\nanswer[i] 是第 i 个航班的总预订座位数。\r\nstd::vector&lt;int&gt; corpFlightBookings(std::vector&lt;std::vector&lt;int&gt;&gt;&amp; bookings, int n) {        // 步骤 1: 初始化差分数组    // 我们使用 n 个元素，对应 0 到 n-1 下标    // diff[i] 对应第 i+1 号航班    std::vector&lt;int&gt; diff(n, 0);    // 步骤 2: 处理所有更新 (O(1) / query)    for (const auto&amp; booking : bookings) {        // 题目编号从 1 开始，数组下标从 0 开始        int first = booking[0];        int last = booking[1];        int seats = booking[2];                // 转换为 0-based 下标        int i = first - 1;         int j = last - 1;        // 应用差分        // 1. 在区间的起始点 i 加上 val        diff[i] += seats;        // 2. 在区间的结束点 j 的下一个位置 j+1 减去 val        // 注意检查边界        if (j + 1 &lt; n) {            diff[j + 1] -= seats;        }    }    // 步骤 3: 还原结果 (O(n))    // 通过对差分数组求前缀和，来还原出最终的航班座位数    // 还原后的数组可以直接用 diff 自身来存储    for (int i = 1; i &lt; n; ++i) {        // 第 i 个航班的座位 = 第 i-1 个航班的座位 + 第 i 个航班的“变化量”        diff[i] += diff[i - 1];    }    // 步骤 4: 返回    // 此时 diff 数组已经变成了我们想要的 answer 数组    return diff;}\r\n常见题型包括: -\r\n一维差分：用于高效处理区间更新、单点查询的问题，常与扫描线思想结合。 -\r\n二维差分：用于处理子矩阵的批量更新。\r\n栈\r\n栈是一种后进先出（LIFO）的数据结构，支持基本操作：入栈（push）、出栈（pop）和查看栈顶元素（top）。栈的应用场景包括表达式求值、括号匹配、深度优先搜索等。\r\n邻项消除 &amp; 合法括号字符串\r\n这两个是栈的最经典应用，因为它们的思想完全一致。\r\n核心思想：\r\n\r\n遍历你的输入（如一个字符串）。\r\n使用一个栈来维护一个“尚未被消除/匹配”的元素序列。\r\n当你遇到一个新元素 current 时，你去看它和“栈顶”元素\r\nstack.top()（即最近一个尚未被消除的元素）是否能“配对”。\r\n\r\n如果能配对：说明 current 和 stack.top() 互相消除了。你执行\r\nstack.pop()，并且不将 current 入栈。\r\n如果不能配对：说明 current 暂时无法被消除，你将它\r\nstack.push()，等待它未来的“配对者”出现\r\n\r\n遍历结束后，栈内剩下的元素就是“无法被消除/匹配”的元素。\r\n\r\n对于邻项消除问题，栈内剩下的元素就是最终结果。\r\n对于括号匹配问题，栈内剩下的元素数量就是无法被匹配的括号数量。\r\n\r\n\r\n单调栈\r\n单调栈是一种特殊的栈数据结构，它在入栈和出栈操作时保持栈内元素的单调性（从栈底到栈顶递增或递减）。其核心思想，是在\r\nO(n)\r\n的一次遍历中，为数组中的每一个元素，快速找到它左侧或右侧(取决于遍历方向)的第一个比它“大”（或“小”）的元素。\r\n它是如何工作的？ 以“单调递增栈”（栈底到栈顶）为例，当一个新元素 x\r\n准备入栈时：\r\n\r\n比较：x 会和栈顶 st.top() 比较。\r\n“清洗”：\r\n\r\n如果 x &lt; st.top()，说明栈顶元素 st.top()\r\n“没用了”。为什么？因为它比 x 大，而且比 x 旧（在 x\r\n左侧）。如果将来有一个元素 y（在 x\r\n右侧）在寻找它“左侧第一个更小的元素”，y 会先看到 x，而永远不会看到\r\nst.top()。\r\n因此，我们弹出 (pop) st.top()，然后 x 继续和新的栈顶比较。\r\n这个过程会一直持续，直到 st.top() &lt;= x。\r\n\r\n入栈：x 入栈。\r\n\r\n通过这个“清洗”过程，栈内始终维护了一个单调递增的序列，这个序列里的元素都是“有潜力”的（它们都还在等待右侧第一个比自己小的元素）。\r\n单调栈目前主要有四大应用场景:\r\n1.\r\n基础：寻找下一个更大/更小元素 (NGE/NSE)\r\n问题：为数组中每个 nums[i]，找到它右侧第一个比它大的元素\r\nnums[j]（j &gt; i, nums[j] &gt; nums[i]）。\r\n解法：使用一个单调递减的栈（栈内存放下标）。 - 遍历数组 i 从左到右。 -\r\nwhile (!st.empty() &amp;&amp; nums[i] &gt; nums[st.top()])： -\r\n这说明，nums[i] 是 st.top()\r\n所代表的那个元素的“右侧第一个更大元素”。 -\r\n找到了！ans[st.top()] = nums[i] (或 j - i，根据题目要求)。 - st.pop()。\r\n- st.push(i)：nums[i] 入栈，等待它“右侧第一个更大元素”的出现。\r\n例如每日温度: 给定一个整数数组 temperatures\r\n，表示每天的温度，返回一个数组 answer ，其中 answer[i] 是指对于第 i\r\n天，下一个更高温度出现在几天后。如果不存在更高温度，答案为 0 。(LC\r\n739)\r\nclass Solution {public:    vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) {        int n = temperatures.size();        stack&lt;int&gt; indexes;        vector&lt;int&gt; ans(n,0);        for(int i=0;i&lt;n;i++){            int cur = temperatures[i];            while(!indexes.empty()&amp;&amp; temperatures[indexes.top()]&lt;cur){                int index = indexes.top();                ans[index] = i-index;                indexes.pop();            }            indexes.push(i);        }        return ans;    }};\r\n2. 进阶：柱状图中的最大矩形面积\r\n这是单调栈最经典的应用。问题描述: 给定 n\r\n个非负整数表示每个柱子的高度图，宽度均为\r\n1，计算在该柱状图中，能够勾勒出来的矩形的最大面积(LC 84)。\r\n解法：\r\n\r\n遍历每一个柱子 h[i]，并假设它就是矩形的最终高度。\r\n我们需要找到这个矩形能向左和向右延伸的最大宽度。\r\n向左：找到 h[i] 左侧第一个小于 h[i] 的柱子\r\nh[l]。\r\n向右：找到 h[i] 右侧第一个小于 h[i] 的柱子\r\nh[r]。\r\n这个 h[i] 的矩形面积就是 h[i] * (r - l - 1)。\r\n\r\n这就是“寻找下一个更小元素”(NSE)\r\n问题。你可以通过两次遍历（一次找左侧，一次找右侧）来解决。\r\nclass Solution {public:    int largestRectangleArea(vector&lt;int&gt;&amp; heights) {        int n = heights.size();        stack&lt;int&gt; left_s;        vector&lt;int&gt; left_vec(n,-1);        stack&lt;int&gt; right_s;        vector&lt;int&gt; right_vec(n,n);        int max_aera = 0;        for(int i=0;i&lt;n;i++){            int cur = heights[i];            while(!right_s.empty()&amp;&amp; cur&lt;heights[right_s.top()]){                right_vec[right_s.top()] = i;                right_s.pop();            }            right_s.push(i);        }        for(int i=n-1;i&gt;=0;i--){            int cur = heights[i];            while(!left_s.empty()&amp;&amp; cur&lt;heights[left_s.top()]){                left_vec[left_s.top()] = i;                left_s.pop();            }            left_s.push(i);        }        for(int i=0;i&lt;n;i++){                int cur_aera = heights[i]*(right_vec[i]-left_vec[i]-1);                max_aera = max(max_aera, cur_aera);        }        return max_aera;    }};\r\n贡献法：子数组的最小值之和\r\n这是单调栈最精妙的应用。问题描述: 给定一个整数数组 nums\r\n，返回所有非空子数组的最小值之和。(由于答案可能很大，因此返回答案对 10^9\r\n+ 7 取余后的结果)(LC 907)\r\n核心思想（贡献法）：我们不遍历子数组，我们遍历每一个元素\r\nnums[i]。 - 我们问：nums[i]\r\n作为最小值，在多少个子数组中出现过？ - 同样，我们需要找到 nums[i]\r\n的左侧第一个更小元素 (下标 l) 和右侧第一个更小元素 (下标 r)。 - 这说明\r\nnums[i] 是开区间 (l, r) 内的唯一最小值。任何一个起点在\r\n(l, i] 之间（共 i - l 种选择）且终点在\r\n[i, r) 之间（共 r - i\r\n种选择）组成的子数组，其最小值都是 nums[i]。 - nums[i] 的总贡献 =\r\nnums[i] * (i - l) * (r - i)。 - 用单调栈求出所有 l 和 r，然后 O(n) 累加总贡献。\r\nclass Solution {public:    int sumSubarrayMins(vector&lt;int&gt;&amp; arr) {        int n = arr.size();                // 1. 计算左边界 left[i]        // left[i] = l, 其中 l 是 arr[i] 左侧第一个“严格小于” arr[i] 的元素下标        // 我们使用一个单调递增栈        std::vector&lt;int&gt; left(n);        std::stack&lt;int&gt; st_left;        for (int i = 0; i &lt; n; ++i) {            // 解释: 栈顶元素如果 &gt;= 当前元素，说明它不是 arr[i] 的左边界            // (我们在找严格小于的)            // 并且它也不是它右侧任何元素的左边界了，弹出            while (!st_left.empty() &amp;&amp; arr[st_left.top()] &gt;= arr[i]) {                st_left.pop();            }            // 解释: 栈为空，说明左侧没有更小元素；否则，栈顶就是左边界            left[i] = st_left.empty() ? -1 : st_left.top();            st_left.push(i);        }        // 2. 计算右边界 right[i]        // right[i] = r, 其中 r 是 arr[i] 右侧第一个“小于或等于” arr[i] 的元素下标        // 我们也使用一个单调递增栈 (但从右往左遍历)        std::vector&lt;int&gt; right(n);        std::stack&lt;int&gt; st_right;        for (int i = n - 1; i &gt;= 0; --i) {            // 解释: 栈顶元素如果 &gt; 当前元素，说明它不是 arr[i] 的右边界            // (我们在找小于或等于的)            while (!st_right.empty() &amp;&amp; arr[st_right.top()] &gt; arr[i]) {   // 注意这里是严格大于, 因为要避免两个栈都是大于等于导致重复计算                st_right.pop();            }            // 解释: 栈为空，说明右侧没有更小或相等元素；否则，栈顶就是右边界            right[i] = st_right.empty() ? n : st_right.top();            st_right.push(i);        }        // 3. 累加贡献        long long total_sum = 0;        int MOD = 1e9 + 7;        for (int i = 0; i &lt; n; ++i) {            // 解释: l = left[i], r = right[i]            // 左侧的起点选择数: i - l            // (j 可以在 (l, i] 范围内, 即 l+1, l+2, ..., i)            long long left_span = i - left[i];            // 解释: 右侧的终点选择数: r - i            // (k 可以在 [i, r) 范围内, 即 i, i+1, ..., r-1)            long long right_span = right[i] - i;            // 贡献 = arr[i] * (左侧选择数) * (右侧选择数)            long long contribution = (arr[i] * left_span * right_span);                        total_sum = (total_sum + contribution) % MOD;        }        return (int)total_sum;    }};\r\n最小字典序：移掉 K 位数字\r\n这是单调栈结合贪心思想的应用。问题描述:\r\n给你一个以字符串表示的非负整数 num ，移除这个数中的 k\r\n位数字，使得剩下的数字最小。返回移除 k\r\n位数字后得到的最小整数，以字符串形式表示。(LC 402)\r\n核心思想：\r\n\r\n为了让数字尽可能小，我们希望高位（左侧）的数字尽可能小。\r\n\r\n因为高位数字权重更大，假如有两个数字 a 和 b，如果 a &lt; b，那么把 a\r\n放在高位比把 b 放在高位更能减小整体数值。\r\n\r\n我们使用一个单调递增的栈来维护我们“保留”的数字。\r\n遍历数字字符串，for (char c : num)：\r\n\r\nwhile (!st.empty() &amp;&amp; k &gt; 0 &amp;&amp; c &lt; st.top())：\r\n\r\n解释：新来的 c\r\n比栈顶元素（已保留的数字）更小，并且我们还有删除的名额 (k &gt; 0)。\r\n贪心：我们应该“扔掉”栈顶那个更大的数字，换成 c。\r\nst.pop(); k–;\r\n\r\nst.push(c);\r\n\r\n最终，栈中就保留了最小的序列。\r\n\r\n队列\r\n队列是一种先进先出（FIFO）的数据结构，支持基本操作：入队（enqueue）、出队（dequeue）和查看队首元素（front）。队列的应用场景包括广度优先搜索、任务调度等。\r\n我们可以使用容器适配器 std::queue 来实现队列, 也可以使用\r\nstd::deque 来实现双端队列。\r\n对于 queue, 主要用到的接口有: push(), pop(), front(),\r\nback(), empty(), size(). 并且需要注意的是, queue 没有迭代器,\r\n不能使用范围for循环来遍历queue中的元素, 只能通过不断 pop\r\n出队列的方式来访问每个元素.\r\n而对于 deque,\r\n由于它是双端队列，可以分别操作两端，因此在入队和出队时要加以说明,\r\n主要用到的接口有: push_back(), push_front(), pop_back(), pop_front(),\r\nfront(), back(), empty(), size().\r\n单调队列\r\n单调队列是一种特殊的队列数据结构，它在入队和出队操作时保持队列内元素的单调性（从队头到队尾递增或递减）。其核心思想，是在\r\nO(n)\r\n的一次遍历中，为数组中的每一个元素，快速找到它左侧或右侧(取决于遍历方向)的第一个比它“大”（或“小”）的元素。\r\n单调队列的应用场景包括滑动窗口问题、最大值/最小值查询等。\r\n堆\r\n当你需要在一个动态的集合中（元素不断在增加或减少）快速地查找并（或）移除“最值”（最大值或最小值）时，堆就是你的不二之选。\r\nTop-K 问题 / 第 K 小/大\r\n这是堆最基础、最直接的应用。核心思想是：维护一个大小固定为\r\nK 的堆。这个堆里存储了你到目前为止见过的 “Top K” 个元素。\r\n问题模型： - 静态数组：在 N\r\n个元素中找到第 K 大的元素 (LC\r\n215)。 - 数据流：在不断加入的数据流中，始终保持对第 K 大元素的快速访问 (LC 703)。\r\n解题思路 (以“第 K\r\n大”为例)：你需要一个最小堆（Min-Heap）。为什么？\r\n最小堆的堆顶 min_pq.top()\r\n永远是堆中最小的元素。如果我们的堆里有 K 个元素，那么堆顶就是这\r\nK 个元素中的第 K 大的那个。 -\r\n初始化：创建一个大小为 K\r\n的最小堆 min_pq。 - 遍历数据：for (int num : nums) -\r\n入堆：min_pq.push(num); - 维护大小：if (min_pq.size() &gt;\r\nk)：min_pq.pop(); - (将堆中最小的元素——即“第 K+1 大”的元素——扔掉) -\r\n获取答案：当所有数据都处理完毕后，堆中剩下的 K 个元素就是最大的 K 个，而 min_pq.top()\r\n就是我们想要的第 K 大元素。\r\n对顶堆（动态中位数）\r\n一个极其精妙的技巧,\r\n使用两个堆来将一个动态数据流“从中间劈开”，从而\r\nO(1) 访问中位数。\r\n数据结构配置： - small\r\n(最大堆)：存储数据流中较小的一半元素。small.top() 是“小半”中的最大值。 -\r\nlarge (最小堆)：存储数据流中较大的一半元素。large.top()\r\n是“大半”中的最小值。\r\n核心规则（不变式）： - small.size() 永远等于\r\nlarge.size()（当总数为偶） - 或 small.size() 等于 large.size() +\r\n1（当总数为奇）中位数：如果总数为奇，\r\n中位数就是 small.top()。如果总数为偶，中位数就是 (small.top() +\r\nlarge.top()) / 2。\r\n重排元素（贪心）\r\n反悔堆（反悔贪心）\r\n链表\r\n链表是一种线性数据结构，由一系列节点组成，每个节点包含数据和指向下一个节点的指针。链表的主要类型包括单向链表、双向链表和循环链表。链表适合频繁的插入和删除操作，因为这些操作不需要移动其他元素。\r\n两个黄金问题\r\n对于链表, 有两个黄金问题, 贯穿了绝大多数链表题目的解法思路.\r\n什么时候用哨兵节点 (Dummy Node)？\r\n\r\n答案：任何时候可能会修改（删除或插入）链表的头节点\r\n(head)时，都应该使用哨兵节点。\r\n为什么？\r\n\r\n统一逻辑：常规操作中，删除一个节点 curr\r\n需要操作它的前一个节点 prev（即 prev-&gt;next =\r\ncurr-&gt;next）。\r\n痛点：但如果你要删除的是头节点 head 呢？head 没有 prev！\r\n常规解法：你需要写一个 if (curr == head)\r\n的特殊判断，这非常繁琐且容易出错。\r\n哨兵解法：创建一个ListNode* dummy = new ListNode(0);，并让\r\ndummy-&gt;next = head;\r\n\r\n现在，原 head 节点也有了一个“前驱”节点 dummy。\r\n你所有的操作都可以从 dummy 节点开始，如果要删除 prev-&gt;next\r\n所指向的元素, 所有的删除逻辑都统一成了\r\nprev-&gt;next = prev-&gt;next-&gt;next。\r\n最后返回：dummy-&gt;next（这可能是原来的 head，也可能是新的\r\nhead）。\r\n\r\n\r\n典型案例：\r\n\r\n删除节点 (如 203. 移除链表元素, 82. 删除排序链表中的重复元素\r\nII)\r\n合并链表 (如 21. 合并两个有序链表) - dummy\r\n用来作为新链表的“假头”。\r\n\r\n\r\nwhile (node != nullptr) vs while (node-&gt;next !=\r\nnullptr)？\r\n\r\n这是一个关于循环终止条件的精髓问题，决定了你的指针最后“停在”哪里。\r\nwhile (node != nullptr)\r\n\r\n含义：我会处理 node，直到 node 变为 nullptr 为止。\r\n循环体：在循环内部，node 是 你要处理的当前节点。\r\n终止时：node 的值是\r\nnullptr。你已经走过了（处理过了）最后一个节点。\r\n用途：\r\n\r\n遍历并访问所有节点的值（例如：打印链表、二进制求和）。\r\n反转链表（你需要处理最后一个节点）。\r\n示例：while (curr != nullptr) { … curr = curr-&gt;next; }\r\n\r\n\r\nwhile (node-&gt;next != nullptr)\r\n\r\n含义：我会检查 node\r\n的下一个节点，直到 node 的下一个是\r\nnullptr 为止。\r\n循环体：在循环内部，node 是\r\n你要处理的当前节点的前一个节点, 而 node-&gt;next 是\r\n你要处理的当前节点。\r\n终止时：node 的值是 链表的最后一个节点\r\n(node-&gt;next 是 nullptr)。\r\n用途：\r\n\r\n删除节点（你需要访问被删除节点的前一个节点）。\r\n寻找链表的尾节点（例如：在尾部添加新节点）。\r\n快慢指针中 fast 指针的检查（while (fast != nullptr &amp;&amp;\r\nfast-&gt;next != nullptr)，因为你要访问 fast-&gt;next-&gt;next）。\r\n当你的操作涉及 node 和 node-&gt;next 两个节点时（例如：83.\r\n删除排序链表中的重复元素）。\r\n\r\n\r\n\r\n例如, 给你一个链表的头节点 head 和一个整数 val\r\n，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。(LC\r\n203)\r\nListNode* removeElements(ListNode* head, int val) {    ListNode* dummy = new ListNode(0);    dummy-&gt;next = head;   // 考虑到删除头节点的情况, 使用哨兵节点    ListNode* prev = dummy;  // 因为删除节点需要访问前一个节点, 因此使用 while(prev-&gt;next!=nullptr)    while(prev-&gt;next!=nullptr){  // 实际上是遍历 prev-&gt;next 节点        if(val==prev-&gt;next-&gt;val){            prev-&gt;next = prev-&gt;next-&gt;next;  // 注意如果删除后, prev 不变, 继续检查新的 prev-&gt;next. 否则会跳过新的 prev-&gt;next 节点        }else{            prev = prev-&gt;next;        }    }    return dummy-&gt;next;}\r\n遍历链表\r\n给你两个链表 list1 和 list2 , 请你将 list1 中下标从 a 到 b\r\n的全部节点都删除，并将list2 接在被删除节点的位置。(LC 1669)\r\nListNode* mergeInBetween(ListNode* list1, int a, int b, ListNode* list2) {        // 步骤 1：找到 list2 的尾节点 (tail2)    // 应用「while (node-&gt;next != nullptr)」原则    // 目标：循环结束后，tail2 停在 list2 的最后一个节点上。    ListNode* tail2 = list2;    while (tail2-&gt;next != nullptr) {        tail2 = tail2-&gt;next;    }    // 步骤 2：找到 list1 中第 a-1 个节点 (node_a_prev)    //     // 我们需要一个指针从 head (索引 0) 开始，走 a-1 步。    // for 循环是执行“固定步数”的最清晰的工具。    ListNode* node_a_prev = list1;    for (int i = 0; i &lt; a - 1; ++i) {        // i=0 时, cur 移动到索引 1        // ...        // i=a-2 时, cur 移动到索引 a-1        node_a_prev = node_a_prev-&gt;next;    }    // 步骤 3：找到 list1 中第 b+1 个节点 (node_b_next)    //     // 我们可以从 node_a_prev (索引 a-1) 继续出发。    // 我们需要找到 b+1。    // b+1 与 a-1 之间的步数差是：(b+1) - (a-1) = b - a + 2    //    // 我们让 node_b_next 从 node_a_prev 开始，    // 再走 (b - a + 2) 步，它就会停在 b+1 节点上。    ListNode* node_b_next = node_a_prev;    for (int i = 0; i &lt; (b - a + 2); ++i) {        // i=0 时, cur 移动到索引 a        // i=1 时, cur 移动到索引 a+1        // ...        // i=(b-a+1) 时, cur 移动到索引 b+1 (总共 b-a+2 步)        node_b_next = node_b_next-&gt;next;    }        // 步骤 4：执行“链表手术”    //     // 此时我们手上有三个关键节点：    // 1. node_a_prev: list1 的第 a-1 个节点    // 2. node_b_next: list1 的第 b+1 个节点    // 3. tail2:       list2 的最后一个节点    //    // 我们只需要执行两次链接：        // 1. 将 (a-1) 节点的 next 指向 list2 的头部    node_a_prev-&gt;next = list2;        // 2. 将 list2 的尾部 (tail2) 的 next 指向 (b+1) 节点    tail2-&gt;next = node_b_next;    // (可选：在非 LeetCode 环境下，这里应该释放 [a, b] 之间的节点)    // 步骤 5：返回 list1    // 因为头节点 (list1) 始终未变    return list1;}\r\n反转链表\r\n这是链表操作的“Hello World”，是所有复杂操作（如 K\r\n个一组反转）的基础。你必须能徒手、快速、无误地写出它。\r\n核心思想：你需要三个指针在遍历过程中协同工作。 -\r\nListNode* prev：指向已反转部分的头，初始为 nullptr。 - ListNode*\r\ncurr：指向正在处理的当前节点，初始为 head。 - ListNode*\r\nnext_temp：临时保存 curr\r\n的下一个节点，防止链表“断开”后丢失。\r\n“穿针引线”四步法（循环体内）： - next_temp = curr-&gt;next; // 1.\r\n暂存：保存好“下一个” - curr-&gt;next = prev; // 2.\r\n反转：当前节点指向“前一个” - prev = curr; // 3. 步进：prev 移动到“当前”\r\n- curr = next_temp; // 4. 步进：curr 移动到“下一个”\r\nListNode* reverseList(ListNode* head) {    // 步骤 1: 初始化三个指针    ListNode* prev = nullptr;    ListNode* curr = head;    ListNode* next_temp = nullptr;    // 步骤 2: 循环遍历    // 使用 while (curr != nullptr) 因为我们要处理到最后一个节点    while (curr != nullptr) {        // 步骤 3: 穿针引线四步法        next_temp = curr-&gt;next; // 1. 暂存        curr-&gt;next = prev;      // 2. 反转        prev = curr;            // 3. 步进 prev        curr = next_temp;       // 4. 步进 curr    }    // 步骤 4: 返回    // 循环结束时，curr 是 nullptr, prev 正好是原链表的尾，    // 即新链表的头    return prev;}\r\nLC 25: K 个一组反转链表. 给你一个链表，每 k\r\n个节点一组进行翻转，请你返回翻转后的链表。\r\n一个比较容易理解的解法是: 先反转每一组节点,\r\n然后再把这些反转后的节点组连接起来. ListNode* reverseList(ListNode* head, ListNode* tail) {    ListNode* prev = tail-&gt;next;  // 反转后 tail 的下一个节点, 用于保持链表的连通性    ListNode* curr = head;    ListNode* next_temp = nullptr;    ListNode* tail_next = tail-&gt;next; // 额外保存循环停止条件, 因为 tail 可能会变化    while (curr != tail_next) {        next_temp = curr-&gt;next;        curr-&gt;next = prev;        prev = curr;        curr = next_temp;    }    return prev;  // 返回反转后的头节点}ListNode* reverseKGroup(ListNode* head, int k) {    if(k &lt;= 1 || !head) return head;  // 如果 k &lt;= 1 或链表为空, 不需要反转    ListNode* dummy = new ListNode(0, head);  // 使用哨兵节点简化边界情况, 作为新链表的头节点    vector&lt;ListNode*&gt; Head; // 存储每组的起始节点    vector&lt;ListNode*&gt; Tail; // 存储每组的结束节点    int cnt = 0;  // 计数节点    ListNode* curr = head;    while (curr != nullptr) {   // 循环中处理的是 curr 节点        cnt++;                if (cnt % k == 1) {         // 这里如果k==1会导致无法记录节点, 因此在函数开头处理k&lt;=1的情况                                    // 或者采取(cnt - 1) % k == 0 也可以处理            Head.push_back(curr);  // 记录每组的起始节点        }        if (cnt % k == 0) {            Tail.push_back(curr);  // 记录每组的结束节点        }        curr = curr-&gt;next;    }    int full_groups = cnt / k;  // 计算完整的 k 组数量    ListNode* prevTail = dummy;  // 上一组的尾节点, 初始为哨兵节点    for (int i = 0; i &lt; full_groups; i++) {        ListNode* currHead = Head[i];        ListNode* currTail = Tail[i];        ListNode* newHead = reverseList(currHead, currTail); // 反转当前组        // 这里 reverseList 函数会返回反转后的头节点(即之前的尾节点), 同时会将反转后的尾节点指向下一组的头节点, 从而保持链表的连通性        prevTail-&gt;next = newHead;  // 连接上一组和当前组, 这是核心步骤, 将上一组的尾节点指向当前组反转后的头节点        prevTail = currHead;       // 更新 prevTail 为当前组的尾节点    }    ListNode* newHead = dummy-&gt;next;;    delete dummy;  // 释放哨兵节点    return newHead;}\r\n这个解法的时间复杂度是 O(N), 空间复杂度是 O(N/k) 用于存储每组的头尾节点.\r\n如果想优化空间复杂度, 可以在遍历链表时, 每当遇到一组完整的 k\r\n个节点时, 立即反转该组节点,\r\n并连接到结果链表中,\r\n这样就不需要额外存储每组的头尾节点了, 从而将空间复杂度优化到 O(1).\r\nListNode* reverseList(ListNode* head, ListNode* tail){    ListNode* prev = tail-&gt;next;    ListNode* curr = head;    ListNode* next_temp = nullptr;    ListNode* tail_next = tail-&gt;next;     while(curr != tail_next){        next_temp = curr-&gt;next;        curr-&gt;next = prev;        prev = curr;        curr = next_temp;    }    return prev;}ListNode* reverseKGroup(ListNode* head, int k) {    // 使用一个哨兵节点    ListNode* dummy = new ListNode(0, head);        // prevGroupTail 指向上一组的尾部, 初始时，它指向哨兵节点    ListNode* prevGroupTail = dummy;        // currGroupHead 指向当前组的头部    ListNode* currGroupHead = head;    while (currGroupHead != nullptr) {                // 步骤 1：找到当前组的尾节点 (currGroupTail)        ListNode* currGroupTail = currGroupHead;        int count = 1;        // 向前走 k-1 步        while (count &lt; k &amp;&amp; currGroupTail != nullptr) {            currGroupTail = currGroupTail-&gt;next;            count++;        }        // 步骤 2：检查是否凑足了 k 个        // 如果 currGroupTail 是 nullptr，说明剩余节点不足 k 个        if (currGroupTail == nullptr) {            break; // 循环终止，剩余部分保持原样        }        // 步骤 3：保存下一组的头节点，以便后续连接        ListNode* nextGroupHead = currGroupTail-&gt;next;        // 步骤 4：翻转当前组 [currGroupHead, currGroupTail]        // 你的 reverseList 函数会返回翻转后的新头 (即 currGroupTail)        // 并且自动将翻转后的新尾 (即 currGroupHead) 指向 nextGroupHead        ListNode* newHead = reverseList(currGroupHead, currGroupTail);        // 步骤 5：将上一组的尾部连接到当前组的新头部        prevGroupTail-&gt;next = newHead; // 或者写 prevGroupTail-&gt;next = currGroupTail;        // 步骤 6：推进指针，为下一次循环做准备        // 翻转后，currGroupHead 变成了当前组的尾巴        prevGroupTail = currGroupHead;         // 移动到下一组的头部        currGroupHead = nextGroupHead;    }    // 释放哨兵节点并返回    ListNode* newHead = dummy-&gt;next;    delete dummy;    return newHead;} ### 快慢指针及前后指针\r\n快慢指针是一种常用的链表技巧，使用两个指针以不同速度遍历链表，从而解决诸如寻找中间节点、检测环、寻找环的入口等问题。\r\n- ListNode* slow：每次走 1 步。 - ListNode* fast：每次走 2 步 (fast =\r\nfast-&gt;next-&gt;next)。\r\n循环条件：while (fast != nullptr &amp;&amp; fast-&gt;next != nullptr)\r\n- （必须同时检查两者，使得fast和它的下一个节点都非空, 因为你要访问\r\nfast-&gt;next-&gt;next）\r\n找中点 (876. 链表的中间结点)： - 当 fast\r\n走到终点（nullptr）时，slow 恰好在中点。 - （如果偶数个节点，slow\r\n在后一个中点，符合题目要求）。\r\n判环 (141. 环形链表)： - fast 走得快，slow 走得慢。\r\n- 如果链表有环，fast 迟早会从“后面”追上 slow（fast == slow）。\r\n倒数第 N 个 (19. 删除链表的倒数第 N 个结点)： -\r\n这是“快慢”的变体，也叫前后指针。 - fast 先走 N\r\n步。 - 然后 slow 和 fast 一起走（每次各走 1\r\n步）。 - 当 fast 走到尾节点（fast-&gt;next == nullptr）时，slow\r\n就停在倒数第 N+1 个节点上，即要删除节点的前驱。(这里配合 dummy\r\n节点食用更佳)。 ListNode* removeNthFromEnd(ListNode* head, int n) {    ListNode* dummy = new ListNode(0, head); // 使用哨兵节点简化边界情况    ListNode* fast = dummy;    ListNode* slow = dummy;    // 让 fast 先走 n 步    for (int i = 0; i &lt; n; ++i) {        fast = fast-&gt;next;    }    // 然后 slow 和 fast 一起走，直到 fast 到达链表末尾    while (fast-&gt;next != nullptr) {        fast = fast-&gt;next;        slow = slow-&gt;next;    }    // 此时 slow 停在倒数第 n+1 个节点上，删除它的下一个节点    slow-&gt;next = slow-&gt;next-&gt;next;    // 返回新的头节点    ListNode* newHead = dummy-&gt;next;    delete dummy; // 释放哨兵节点    return newHead;}\r\nLRU\r\nLRU (Least Recently Used)\r\n缓存是一种常用的缓存淘汰策略，用于在缓存容量有限时，移除最久未使用的数据。LRU\r\n缓存通常使用哈希表和双向链表结合实现，以支持高效的插入、删除和访问操作。\r\nclass LRUCache {public:    struct DListNode{        int key;        int value;        DListNode* prev;        DListNode* next;        DListNode(int k, int v): key(k), value(v), prev(nullptr), next(nullptr){}    };private:    int capacity;    unordered_map&lt;int, DListNode*&gt; cache_map;    DListNode* head;    DListNode* tail;    void removeNode(DListNode* node){        node-&gt;next-&gt;prev = node-&gt;prev;        node-&gt;prev-&gt;next = node-&gt;next;    }    void addNodeToHead(DListNode* node){        node-&gt;next = head-&gt;next;        head-&gt;next-&gt;prev = node;        head-&gt;next = node;        node-&gt;prev = head;    }    void moveToHead(DListNode* node){        removeNode(node);        addNodeToHead(node);    }public:    LRUCache(int capacity): capacity(capacity) {        head = new DListNode(-1,-1);        tail = new DListNode(-1,-1);        head-&gt;next = tail;        tail-&gt;prev = head;    }    ~LRUCache(){        for(auto&amp; pair:cache_map){            delete pair.second;        }        delete head;        delete tail;    }        int get(int key) {        if(!cache_map.contains(key)){            return -1;        }        DListNode* node = cache_map[key];        moveToHead(node);        return node-&gt;value;    }        void put(int key, int value) {        if(cache_map.contains(key)){            DListNode* node = cache_map[key];            node-&gt;value = value;            moveToHead(node);        }else{            DListNode* newNode = new DListNode(key, value);            cache_map[key] = newNode;            addNodeToHead(newNode);            if(cache_map.size()&gt;capacity){                DListNode* lruNode = tail-&gt;prev;                cache_map.erase(lruNode-&gt;key);                removeNode(lruNode);                delete lruNode;            }        }    }}; ## 其余 ### 递归\r\n这里帮助大家确定下来递归算法的三个要素。每次写递归，都按照这三要素来写，可以保证大家写出正确的递归算法！\r\n\r\n确定递归函数的参数和返回值：\r\n确定哪些参数是递归的过程中需要处理的，那么就在递归函数里加上这个参数，\r\n并且还要明确每次递归的返回值是什么进而确定递归函数的返回类型。\r\n确定终止条件： 写完了递归算法,\r\n运行的时候，经常会遇到栈溢出的错误，就是没写终止条件或者终止条件写的不对，操作系统也是用一个栈的结构来保存每一层递归的信息，如果递归没有终止，操作系统的内存栈必然就会溢出。\r\n确定单层递归的逻辑：\r\n确定每一层递归需要处理的信息。在这里也就会重复调用自己来实现递归的过程。\r\n\r\n递归的实现就是：每一次递归调用都会把函数的局部变量、参数值和返回地址等压入调用栈中，然后递归返回的时候，从栈顶弹出上一次递归的各项参数，所以这就是递归为什么可以返回上一层位置的原因。\r\n另一种算法, 回溯, 其实是递归的副产品，只要有递归就会有回溯。\r\n递归时如果超时, 可能是递归时对某些元素重复计算了,\r\n这时可以考虑用记忆化搜索(Memoization)来优化递归算法,\r\n即可以用一个哈希表来缓存已经计算过的结果,\r\n避免重复计算.\r\n在函数的开始先检查哈希表中是否已经存在该结果,\r\n如果存在则直接返回该结果, 否则继续计算并将结果存入哈希表中.\r\n例如LeetCode 337\r\n","categories":["algorithms"],"tags":["algorithms"]},{"title":"聚类算法","url":"/2025/07/01/ai/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0ML/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","content":"聚类算法的目标是在没有预先定义类别的情况下，将数据集划分为若干个有意义的群组,\r\n使得同一类中的数据点彼此相似，而不同类中的数据点差异较大。\r\nK-均值聚类 (K-Means\r\nClustering)\r\nK-means 聚类是一种非常流行且基础的 无监督学习 (Unsupervised Learning)\r\n算法。它的主要目标是将一个给定的数据集根据数据点之间的相似性，自动划分为\r\nK 个不同的 簇\r\n(Cluster)。这里的”K”是一个需要预先指定的超参数，代表你希望最终得到的簇的数量。\r\n它的核心思想是\r\n“物以类聚，人以群分”。它通过迭代的方式，不断地优化每个簇的中心点————即质心\r\n(Centroid)，并根据数据点与质心的距离，将每个数据点分配给最近的簇。这个过程持续进行，直到质心的位置不再发生显著变化，或者达到了预设的迭代次数，此时我们认为聚类结果已经收敛。\r\n算法的目标是最小化簇内平方和(Within-Cluster Sum of\r\nSquares, WSS)，也被称为 惯性\r\n(Inertia)。简单来说，就是让同一个簇内的数据点尽可能地紧密，不同簇之间的数据点尽可能地远离。\r\n算法步骤\r\n\r\n初始化 (Initialization)\r\n\r\n操作：从数据集中随机选择 K 个数据点作为初始的质心 (μ₁, μ₂, …,\r\nμ_K)。\r\n说明：这是算法的起点。质心的初始位置会影响算法的收敛速度和最终结果。因为是随机选择，所以多次运行\r\nK-means 可能会得到不同的聚类结果。\r\n\r\n分配 (Assignment)\r\n\r\n操作：对于数据集中的每一个数据点 xi，计算它到 K\r\n个质心 μj\r\n的距离，并将其分配给距离最近的那个质心所在的簇 cj。\r\n说明：此步骤的目的是根据当前的质心位置，为每个数据点找到一个”归属”。最常用的距离度量是欧几里得距离\r\n(Euclidean Distance)。其数学表达式为： \r\n在实际计算中，为了提高效率，通常使用平方欧几里得距离，因为它省去了开方的计算，并且不会改变距离的相对大小关系。\r\n\r\n\r\n更新 (Update)\r\n\r\n操作：对于每一个簇 cj，重新计算其质心\r\nμj。新的质心是该簇内所有数据点的均值。\r\n说明：在第二步中，簇内的成员发生了变化，原来的质心可能不再是簇的几何中心。因此，需要通过计算均值来更新质心，使其移动到簇内数据点的中心位置。新的质心计算公式为：\r\n 其中 |cj| 是簇 cj\r\n中数据点的数量。\r\n\r\n迭代 (Iteration)\r\n\r\n操作：重复执行第二步（分配）和第三步（更新）。\r\n说明：这个迭代过程会不断地优化数据点的分配和质心的位置。当满足以下任一条件时，算法停止：\r\n\r\n质心的位置不再发生变化（或变化非常小，小于一个预设的阈值）。\r\n数据点的分配不再改变。\r\n达到了预设的最大迭代次数。\r\n\r\n\r\n\r\n数学原理\r\nK-means 算法的最终目标是最小化一个目标函数 (Objective\r\nFunction)，这个函数就是我们前面提到的簇内平方和\r\n(WSS)。其数学表达式为：\r\n\r\n\r\nJ：目标函数，即总的\r\nWSS。\r\nK：簇的数量。\r\ncj：第\r\nj 个簇。\r\nμj：第\r\nj 个簇的质心。\r\nxi：属于簇 cj\r\n的一个数据点。\r\n∥xi − μj∥2：数据点\r\nxi\r\n到其所属簇质心 μj\r\n的平方欧几里得距离。\r\n\r\n上述公式表示所有数据点与其所属簇质心之间的距离平方和。\r\n算法的两个核心步骤（分配和更新）正是为了以迭代的方式最小化这个 J 值：\r\n\r\n分配步骤：在保持质心 μj\r\n不变的情况下，将每个 xi 分配给能使其\r\n∥xi − μj∥2\r\n最小的簇。这一步是在对 cj\r\n进行优化。\r\n更新步骤：在保持簇分配 cj\r\n不变的情况下，为每个簇寻找一个新的质心 μj，使得该簇内的平方和\r\n∑xi ∈ cj∥xi − μj∥2\r\n最小。可以证明，这个最优的 μj\r\n就是簇内所有数据点的均值。\r\n\r\n这是一个典型的期望最大化 (Expectation-Maximization,\r\nEM) 思想的应用。\r\nK-means 的优缺点\r\n优点：\r\n\r\n简单高效：算法原理简单，容易实现，计算速度快。对于大规模数据集，其可伸缩性很好。\r\n解释性强：聚类结果直观，容易解释。\r\n\r\n缺点：\r\n\r\nK值需要预先指定：如何选择最优的 K 值是 K-means\r\n的一个核心难题。\r\n对初始质心敏感：不同的初始质心可能会导致完全不同的聚类结果，甚至可能陷入局部最优解。\r\n对异常值敏感：因为质心是基于均值计算的，个别的异常值（离群点）会对质心的位置产生较大影响。\r\n对非球形簇效果不佳：K-means\r\n倾向于发现大小相似、形状为球形的簇，对于形状不规则的簇、密度不均匀的簇效果较差。\r\n\r\nDBSCAN (Density-Based\r\nSpatial Clustering)\r\nDBSCAN，全称为 Density-Based Spatial Clustering of Applications with\r\nNoise（基于密度的含噪声应用空间聚类），是一种非常流行且强大的聚类算法。\r\n与 K-均值 (K-Means)\r\n算法试图找到球状的簇并且每个点都必须属于一个簇不同，DBSCAN\r\n的核心思想是：一个簇是数据空间中一个连续的高密度区域，并由低密度区域分隔开。\r\n这使得 DBSCAN 具有两大显著优势：\r\n\r\n能够发现任意形状的簇（例如，环形、S形），而不像\r\nK-均值那样只能处理凸形的簇。\r\n能够自动识别并标记出噪声点（离群点），而不是强行将它们分配到某个簇中。\r\n\r\n核心概念\r\n要理解 DBSCAN\r\n的工作原理，必须先掌握它的三个基本概念，这些概念都围绕着”密度”来定义。这需要我们先设定两个关键参数：\r\n\r\n半径 ϵ\r\n(Epsilon)：\r\n定义了一个点的”邻域”范围。它是一个距离值，用来画一个圈，圈内的所有点都被认为是这个点的邻居。\r\n最小点数 MinPts：\r\n定义了形成一个”高密度区域”所需要的点的最小数量阈值。\r\n\r\n基于这两个参数，我们可以定义三种类型的点：\r\n\r\n核心点 (Core Point)： 如果一个数据点 p 在其 ϵ 半径的邻域内，包含了至少 MinPts\r\n个点（包括 p 自身），那么\r\np 就是一个核心点。\r\n\r\n核心点是高密度区域的”内部成员”。它们是簇的”骨架”，簇就是从这些点开始生长和扩展的。\r\n\r\n边界点 (Border Point)： 如果一个数据点 q 不是核心点，但它落在了某个核心点\r\np 的 ϵ 邻域内，那么 q 就是一个边界点。\r\n\r\n边界点位于簇的”边缘”。它们本身密度不够，但它们是某个核心点的”邻居”，因此可以被归入该核心点所在的簇。\r\n\r\n噪声点 (Noise Point)：\r\n如果一个数据点既不是核心点，也不是边界点，那么它就是噪声点（或离群点）。\r\n\r\n这些点是稀疏区域中的孤立点，不属于任何一个簇。DBSCAN\r\n能够将它们有效地识别并分离出来。\r\n\r\n\r\n工作流程\r\nDBSCAN 的聚类过程就像在一个区域里寻找”人群”，并将它们连接起来。\r\n\r\n选择起点： 从数据集中任意选择一个尚未被访问过的点\r\np。 &gt;\r\n算法会遍历所有点，所以从哪里开始并不影响最终结果，只会影响发现簇的顺序。\r\n判断点的类型： 检查点 p 的 ϵ 邻域。\r\n\r\n情况一： 如果 p 是一个核心点（其邻域内的点数 ≥ MinPts）：\r\n\r\n创建一个新的簇，并将 p\r\n分配给这个簇。\r\n然后，扩展这个簇：检查 p\r\n的所有邻居点。对于每一个邻居点 q，如果 q 也是一个核心点，就将 q\r\n的所有邻居也加入到待处理的队列中。这个过程不断进行，直到所有通过核心点连接起来的（密度可达的）点都被加入到同一个簇中。\r\n这是算法最关键的一步，称为密度可达性扩展。它确保了一个完整的、高密度的区域被完整地识别为一个簇。\r\n\r\n情况二： 如果 p 不是一个核心点：\r\n\r\n暂时将 p\r\n标记为噪声点。\r\n这个点可能是真正的噪声，也可能是一个边界点。它未来的归属取决于它是否落入其他核心点的邻域内。如果后续在扩展其他簇时发现了它，它就会被吸纳为边界点并加入那个簇。\r\n\r\n\r\n重复过程：\r\n继续选择下一个尚未被访问过的点，重复步骤2，直到数据集中所有的点都被访问过。\r\n完成聚类：\r\n当所有点都被访问后，聚类过程结束。一些点被分配到不同的簇中，而另一些点则被最终标记为噪声。\r\n\r\nDBSCAN 的优缺点\r\n优点：\r\n\r\n无需指定簇数量： 与 K-均值不同，DBSCAN\r\n可以自动确定簇的数量。\r\n可发现任意形状的簇：\r\n其基于密度的特性使其不受簇形状的限制。\r\n对噪声不敏感：\r\n能够有效地识别并处理离群点，这在金融欺诈检测等场景中非常有用。\r\n\r\n缺点：\r\n\r\n对参数敏感： ϵ 和 MinPts\r\n的选择对结果影响巨大，调参可能需要经验和多次试验。\r\n不适合密度差异大的数据集：\r\n如果数据集中不同簇的密度相差很大，DBSCAN 可能难以用一套全局的 ϵ 和 MinPts\r\n参数来正确地识别所有簇。\r\n高维数据下的问题：\r\n在非常高的维度下（维度灾难），所有点之间的距离可能趋于一致，这使得基于距离的”密度”概念变得不那么有意义。\r\n\r\n谱聚类 (Spectral Clustering)\r\n谱聚类是一种基于图论的聚类方法，其核心思想是将聚类问题转化为图的分割问题。与传统的K-Means等基于距离的聚类算法不同，谱聚类能够识别任意形状的样本空间，并且对数据分布的适应性更强，因此在许多场景下表现优越。\r\n\r\n想象一下，我们有许多数据点，如何将它们分组？ -\r\n传统方法（如K-Means）：找到每个簇的中心点，然后将每个数据点分配给离它最近的中心点。这种方法隐含了一个假设：每个簇都是凸的（比如圆形或球形）。如果簇的形状是弯曲的、不规则的（例如月牙形），K-Means就很难处理。\r\n-\r\n谱聚类的思路：将所有数据点看作是图（Graph）中的节点（Vertices）。如果两个点彼此相似（距离近），就在它们之间连接一条边（Edge），边的权重表示它们的相似度。这样，整个数据集就变成了一张”相似度图”。\r\n现在，聚类的任务变成了如何切割这张图，使得分割后的不同子图之间连接的边的权重之和尽可能小（类间相似度低），而每个子图内部的边的权重之和尽可能大（类内相似度高）。\r\n-\r\n这个”切图”的思想就是谱聚类的精髓。它将一个在原始特征空间中难以解决的非线性问题，通过图论转化为了一个更容易处理的线性代数问题。\r\n\r\n谱聚类算法步骤\r\n原始数据 (N, P) ➔ [构建相似度图] ➔ 邻接矩阵 W (N, N) ➔ [计算D和L] ➔\r\n拉普拉斯矩阵 L_sym (N, N) ➔ [特征分解] ➔ 新特征矩阵 U (N, k) ➔\r\n[K-Means聚类] ➔ 最终聚类标签 (N, 1)\r\n构建相似度图 (Construct\r\nSimilarity Graph)\r\n将每一个数据点看作图中的一个节点\r\n(Vertex)。根据数据点之间的”相似度”，在节点之间连接边\r\n(Edge)。如果两个点非常相似，它们之间的边权重就高；反之则低。\r\n这是算法的奠基之举，它将原始的、可能呈非线性复杂分布的数据集，转化为了一个可以用图论工具分析的结构。图的结构（谁和谁相连，连接有多强）编码了数据的内在关联。\r\n如何定义”相似”并建图至关重要，常用方法有：\r\n\r\nk-近邻图 (k-NN Graph)：每个点只与它最近的 k\r\n个点相连。这是最常用、最稳健的方法之一。\r\n全连接图 (Fully-connected\r\nGraph)：所有点之间都有连接，边的权重通常由高斯核函数  决定。你需要选择合适的 σ 值。\r\nε-近邻图 (ε-neighborhood Graph)：连接所有距离在阈值 ε\r\n内的点对。(有时会将k-近邻图和ε-近邻图结合使用)\r\n\r\n计算邻接矩阵 W 和度矩阵 D\r\n即将上一步构建的图用数学语言来描述,\r\n将图的拓扑结构数字化、矩阵化，为下一步的计算做好准备。\r\n邻接矩阵 W：一个 N×N 的方阵（N 是数据点总数），Wij\r\n就是节点 i 和节点 j 之间边的权重。如果两点不相连，则为0\r\n(W是对称的稀疏矩阵)\r\n度矩阵 D：一个 N×N 的对角矩阵，Dii\r\n是节点 i 的”度”，即与它相连的所有边的权重之和 (Dii = ∑jWij)。\r\n计算拉普拉斯矩阵 L\r\n利用 W 和 D\r\n计算拉普拉斯矩阵。为了获得最好的效果，我们通常计算对称标准化的拉普拉斯矩阵\r\n(L_sym)。\r\nLsym = I − D−1/2WD−1/2\r\n（其中 I 是单位矩阵）\r\n这是整个算法的核心。拉普拉斯矩阵是一个神奇的矩阵，它的特征值和特征向量（合称”谱”）\r\n蕴含了图的最佳分割信息。可以说，这个矩阵内部就”藏着”如何切分图的答案。\r\n计算特征值和特征向量\r\n(执行”谱”分析)\r\n对拉普拉斯矩阵 L\r\n进行特征分解，求出其所有的特征值和对应的特征向量。\r\n这就是”谱聚类”中”谱”这个词的来源。我们通过这一步来”解锁”拉普拉斯矩阵中隐藏的分割信息。其中，最小的几个特征值对应的特征向量对我们来说最重要。\r\n降维与投影\r\n从上一步得到的所有特征向量中，选取与前 k 个最小特征值相对应的 k\r\n个特征向量。然后，将这 k 个特征向量按列排成一个新的 N×k\r\n的矩阵 U。\r\n这是一个降维的过程。它将每个原始数据点从它原来的特征空间，投影到了一个全新的、低维的”谱空间”中。在这个谱空间里，原始数据复杂的非线性结构被”拉平”和”理顺”，变得更容易被区分。矩阵\r\nU 的每一行就是原始数据点在这个新空间里的新坐标。\r\n使用 K-Means 进行最终聚类\r\n将第5步得到的新矩阵 U\r\n作为输入，对其每一行（即每个数据点的新坐标）运行一次标准的 K-Means\r\n算法，将其聚为 k 个簇。\r\n在前几步谱聚类已经完成了最困难的”结构梳理”工作。在新空间中，不同簇的数据已经变得界限分明，因此一个像\r\nK-Means\r\n这样简单的算法就足以完成最后的”收尾”工作，为每个点分配最终的聚类标签。\r\n示例代码\r\n\r\n使用sklearn包的SpectralClustering import numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import make_circlesfrom sklearn.cluster import SpectralClustering# 1. 生成数据集# 我们生成一个同心圆数据集# n_samples: 样本总数# factor: 内外圆之间的比例# noise: 噪声水平X, y_true = make_circles(n_samples=1000, factor=0.5, noise=0.05, random_state=0)# 2. 使用谱聚类进行聚类# n_clusters: 要找到的簇数# affinity: 构建邻接矩阵的方式。'rbf'是高斯核函数, 'nearest_neighbors'是k-NN图spectral = SpectralClustering(n_clusters=2,                               affinity='nearest_neighbors', # 使用k-NN构建图                              n_neighbors=20,             # k-NN的k值                              random_state=0)y_spectral = spectral.fit_predict(X)# 4. 可视化聚类结果plt.figure(figsize=(12, 6))plt.scatter(X[:, 0], X[:, 1], c=y_spectral, s=10, cmap='viridis')plt.title(\"Spectral Clustering (Success)\")plt.gca().set_aspect('equal', adjustable='box')plt.show()\r\n手写SpectralClustering import numpy as np# 假设 kmeans 函数已经定义好# from somewhere import kmeans def spectral(W, k):    \"\"\"    谱聚类算法 (使用标准化的拉普拉斯矩阵)    这个函数实现了谱聚类的核心流程。    输入:        W: 邻接矩阵 (Adjacency Matrix)，一个 N-by-N 的对称矩阵，表示数据点之间的相似度。        k: 目标聚类的簇数。    输出:        idx: 每个数据点最终的簇标签，一个长度为 N 的一维向量。    \"\"\"        # 获取数据点的数量 N    N = W.shape[0]    # --- 步骤1: 计算度矩阵 D (Degree Matrix) ---    # 度矩阵 D 是一个对角矩阵，其对角线上的元素 D[i, i] 是邻接矩阵 W 第 i 行所有元素的和。    # 它代表了图中每个节点的\"连接总强度\"或\"度\"。    D = np.diag(np.sum(W, axis=1))    # --- 步骤2: 计算对称标准化的拉普拉斯矩阵 L_sym (Symmetric Normalized Laplacian) ---    # 这是整个算法最关键的一步。相比非标准化的拉普拉斯矩阵(L = D - W)，    # 标准化的版本对不同大小和密度的簇有更好的适应性，聚类效果更鲁棒。    # 公式为: L_sym = I - D^(-1/2) * W * D^(-1/2)        # 为了计算 D^(-1/2)，我们先计算 D 的平方根的逆。    # 这里加上一个极小的数 1e-10 是为了防止 D 的对角线上有0（孤立点），从而导致除以零的错误，保证数值稳定性。    D_inv_sqrt = np.linalg.inv(np.sqrt(D + 1e-10))        # 根据公式计算 L_sym。`@` 是 Python 中的矩阵乘法运算符。    L_sym = np.identity(N) - D_inv_sqrt @ W @ D_inv_sqrt    # --- 步骤3: 特征分解 (Eigendecomposition) ---    # 我们对 L_sym 进行特征分解，求解其特征值和特征向量。这是\"谱\"分析的核心。    # 拉普拉斯矩阵的谱（特征值）蕴含了图的结构信息。    # np.linalg.eigh 专门用于求解对称/厄米矩阵，性能更高，且保证返回的特征值是实数并已从小到大排序。    eigenvalues, eigenvectors = np.linalg.eigh(L_sym)    # --- 步骤4: 构建新的低维特征空间 U ---    # 根据谱聚类理论，我们选取与 k 个最小特征值相对应的特征向量。    # 由于 eigh 的结果已排序，我们直接取特征向量矩阵的前 k 列即可。    # 这 k 个特征向量构成了一个新的、低维的表示空间，原始数据的复杂结构在这个空间中被简化。    U = eigenvectors[:, :k]    # --- 步骤5: (推荐的最佳实践) 标准化新的特征矩阵 U ---    # 将矩阵 U 的每一行都标准化为单位长度（L2范数为1）。    # 这样做可以消除 K-Means 算法对向量长度的敏感性，使得聚类更多地关注点在超球面上的角度关系，    # 从而在新空间中取得更稳定、更准确的聚类效果。        # 计算每一行（每个数据点在新空间中的向量）的L2范数。    # keepdims=True 确保结果是 (N, 1) 的列向量，以便于下一步的广播除法。    norm = np.linalg.norm(U, axis=1, keepdims=True)        # 执行行标准化。同样加上一个极小的数防止除以零。    U_norm = U / (norm + 1e-10)    # --- 步骤6: 使用 K-Means 在新空间中进行最终聚类 ---    # 谱聚类已经完成了最困难的\"特征转换\"工作。    # 在这个新的特征空间 U_norm 中，数据点已经被变换得更容易被线性分割。    # 因此，我们调用一个简单的 K-Means 算法来完成最后的分类任务。    idx = kmeans(U_norm, k)    # 返回最终的聚类结果    return idx\r\n\r\n高斯混合模型 (Gaussian\r\nMixture Model, GMM)\r\n","categories":["ML"]},{"title":"回溯","url":"/2025/10/12/algorithms/Coding%E6%8A%80%E5%B7%A7/%E5%9B%9E%E6%BA%AF/","content":"回溯算法是一种通过深度优先搜索 (DFS)\r\n策略，在问题的解空间树中系统性地寻找所有（或部分）解的算法。它本质上是一种有组织的、避免了暴力枚举所有可能性的“试错法”。当算法在搜索过程中发现当前选择的路径无法导向一个有效的解时，它会“回溯”（即撤销上一步的选择），然后尝试另一个可行的选择。\r\n\r\n其实是用递归解决多层嵌套循环\r\n\r\n回溯算法如何工作：选择、探索、撤销\r\n回溯算法的执行过程可以概括为以下三个步骤的循环：\r\n\r\n做出选择\r\n(Choose)：在当前状态下，根据问题的规则，从所有可能的选择中挑选一个。\r\n递归探索\r\n(Explore)：基于上一步的选择，进入下一层决策，递归地重复此过程。\r\n撤销选择 (Unchoose /\r\nBacktrack)：如果基于当前选择的后续探索最终没有找到解（或者已经找到了所有解），就必须撤销刚才的那一步选择，将状态恢复到做出选择之前的样子。\r\n\r\n这是回溯算法的精髓。撤销选择（例如，从路径列表中移除最后一个元素）是为了不影响在当前决策点的其他选择。就像走迷宫，你从死胡同退回到上一个岔路口后，才能去尝试其他的岔路。如果不撤销，之前的错误选择就会污染后续的搜索路径。\r\n\r\n\r\n另一方面, 解决一个回溯问题，通常需要明确以下三个要素：\r\n\r\n选择列表\r\n(Choices)：在当前状态下，你可以做出的所有选择的集合。\r\n路径\r\n(Path)：你已经做出的一系列选择，构成了通往可能解的路径。\r\n结束条件 (Termination Condition /\r\nGoal)：判断当前路径是否已经构成一个完整解的条件。\r\n\r\n回溯法树形结构\r\n回溯算法的过程可以形象地表示为一棵树形结构，称为决策树\r\n(Decision Tree) 或 回溯树 (Backtracking\r\nTree)。在这棵树中： -\r\n每个节点代表一个状态，包含当前已经做出的选择（路径）和剩余的可选选择（选择列表）。\r\n- 每条边代表从一个状态到另一个状态的选择。 -\r\n叶子节点代表一个完整的解，或者是一个无法继续探索的状态（死胡同）。\r\n- 对于子集问题，所有节点（包括中间节点）都可能是解。\r\n其中, 向下深入代表做出一个新选择(递归探索),\r\n水平移动代表在同一层次上尝试不同的选择(for 循环遍历)。\r\n回溯算法的代码模板\r\n下面是一个典型的回溯算法的代码模板，展示了如何实现上述的选择、探索和撤销过程：\r\nresult = [] // 存放最终结果path = []   // 存放当前路径, 已经做出的选择// backtrack 函数是核心// choices: 当前可以做出的选择列表, 一般是这一层循环的起始点function backtrack(choices) {    // 步骤说明：首先判断是否满足结束条件。    // 如果满足，说明找到了一个解，将其存入结果集并返回。    if (满足结束条件) {        add path to result;        return;    }    // 步骤说明：遍历当前状态下的所有可选路径。    for (选择 in choices) {        // 如果这个选择不合法，可以进行“剪枝”操作，跳过它        if (选择不合法) {            continue;        }        // 1. 做出选择        // 步骤说明：将当前选择添加到路径中。        将“选择”添加到 path 中;        // 2. 递归探索        // 步骤说明：基于新的路径和新的选择列表，进入下一层决策树。        backtrack(path, 新的选择列表);        // 3. 撤销选择 (这步是回溯的关键！)        // 步骤说明：将刚才添加的选择从路径中移除，        // 以便下一次循环可以尝试当前决策点的其他选择。        从 path 中撤销“选择”;    }}\r\n一些踩过的坑\r\n每次push_back之后，一定要记得pop_back撤销选择，否则会导致path不断增长，最终结果错误(可能会在一个backtrack调用中push多个值,\r\n每个都要对应一次pop)。\r\n一般适用于求解符合某种条件的所有解的问题，比如组合、排列、子集;\r\n而求解什么什么最值的问题，一般用动态规划更合适。\r\n有时候要求回溯算法返回路径树的所有节点而不仅仅是叶子节点，这时候结束条件就不是判断path是否构成完整解，而是每次进入backtrack函数时都把当前path加入结果集。\r\n&gt;\r\n一般来说：组合问题和排列问题是在树形结构的叶子节点上收集结果，而子集问题就是取树上所有节点的结果。\r\n对于排列问题, 在进入回溯函数的时候不需要传入startIndex,\r\n但是需要在选择列表中判断当前元素是否已经被选择过(可以用一个visited数组记录);\r\n而对于组合问题, 需要传入startIndex,\r\n保证每次选择都是从startIndex开始，避免重复选择。\r\n优缺点和适用场景\r\n优点：\r\n\r\n通用性强：能够解决一大类问题，如排列、组合、子集、棋盘问题等。\r\n可以找到所有解：能够系统性地遍历整个解空间，找到问题的所有可行解。\r\n概念清晰：基于深度优先搜索，代码结构相对固定，容易理解。\r\n\r\n缺点：\r\n\r\n时间复杂度高：在最坏情况下，需要遍历整个解空间，时间复杂度可能是指数级的（例如\r\nO(n!) 或 O(2^n)）。\r\n效率问题：如果解空间巨大，且没有有效的剪枝\r\n(Pruning)\r\n策略（即提前判断某条路径肯定无效并终止探索），算法可能会非常慢。\r\n\r\n典型应用场景:\r\n\r\n组合问题：在一个集合中找出所有满足条件的子集（例如：Combinations,\r\nSubsets）。\r\n排列问题：Permutations。\r\n棋盘问题：N皇后问题、数独求解器。\r\n路径寻找：迷宫问题、图的路径搜索。\r\n括号生成：生成所有有效的括号组合。\r\n\r\n示例\r\n示例1: 组合问题\r\n问题：给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。\r\n示例: 输入 n = 4, k = 2,\r\n输出：[[2,4],[3,4],[2,3],[1,2],[1,3],[1,4],]\r\n树结构如下:  class Solution {public:    vector&lt;vector&lt;int&gt;&gt; op;    vector&lt;int&gt; path;    void bt(int n, int k, int start){   // 组合问题按顺序选择, 所以需要start参数        if(path.size()==k){            op.emplace_back(path);            return;        }        for(int i=start;i&lt;n;i++){            path.push_back(i+1);            backtrace(n, k, i+1);  // 注意这里是 i+1, 保证每次选择都是从下一个元素开始            path.pop_back();        }    }    vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) {        bt(n, k, 0);        return op;    }};\r\n示例2: 组合总和\r\n问题: 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出\r\ncandidates 中所有可以使数字和为 target\r\n的组合。这里的数字可以无限制重复被选取。 示例: 输入: candidates =\r\n[2,3,6,7], target = 7, 所求解集为: [[7],[2,2,3]]\r\nclass Solution {public:    vector&lt;int&gt; path;    vector&lt;vector&lt;int&gt;&gt; ans;    void bt(vector&lt;int&gt;&amp; candidates, int target, int start){        if(accumulate(path.begin(), path.end(), 0)==target){            ans.push_back(path);            return;        }        if(accumulate(path.begin(), path.end(), 0)&gt;target){  // 可以重复选取, 因此必须手动限制终止条件            return;        }        for(int i = start;i&lt;candidates.size();i++){            path.push_back(candidates[i]);            bt(candidates, target, i);  // 可以重复选择            path.pop_back();        }    }    vector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) {        sort(candidates.begin(),candidates.end());        bt(candidates, target, 0);        return ans;    }};\r\n示例3: 路径总和(二叉树)\r\n问题:\r\n给定一个二叉树和一个目标和，找出所有从根节点到叶子节点路径总和等于给定目标和的路径。(LC\r\n113)\r\nclass Solution {public:    vector&lt;vector&lt;int&gt;&gt; op;    vector&lt;int&gt; path;    int sum = 0;    void bt(TreeNode* root, int targetSum){        if(!root) return;        sum += root-&gt;val;        path.push_back(root-&gt;val);        if(sum==targetSum &amp;&amp; root-&gt;left==nullptr &amp;&amp; root-&gt;right==nullptr){            op.push_back(path);        }                bt(root-&gt;left, targetSum);        bt(root-&gt;right, targetSum);        path.pop_back();        sum -= root-&gt;val;    }    vector&lt;vector&lt;int&gt;&gt; pathSum(TreeNode* root, int targetSum) {        bt(root, targetSum);        return op;    }};\r\n这是一个典型的树形回溯问题,\r\n每次进入一个节点就把节点值加入path和sum中, 然后递归左右子树,\r\n递归返回后撤销选择. 注意这里和之前的回溯问题不同,\r\n这里的选择要在进入节点时做出, 而不是在for循环中选择.\r\n示例: 复原 IP 地址\r\n","categories":["algorithms"],"tags":["algorithms","recursion"]},{"title":"感知机","url":"/2025/07/01/ai/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CNN/%E6%84%9F%E7%9F%A5%E6%9C%BA/","content":"感知机 (Perceptron) 是二分类的线性分类模型，属于判别模型。\r\n感知机模型\r\n感知机模型由以下几个部分组成：\r\n","categories":["NN"]},{"title":"预备知识","url":"/2025/09/14/algorithms/Computing%20Theory/%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/","content":"集合 (Sets)\r\n基本定义与性质\r\n集合 (Set)：一个无序的元素集合 (An unordered collection of elements)\r\n。\r\n空集 (Empty set)：记作 Ø 。\r\n子集\r\n(Subset)：表示一个集合是否被另一个集合所包含。其严格定义为：S⊆T⇔(∀x∈S⇒x∈T)。任何集合都是其自身的子集\r\n。\r\n集合相等 (Equal\r\nSets)：两个集合相等当且仅当它们包含完全相同的元素。这等价于两个集合互为子集：S=T⇔(S⊆T)∧(T⊆S)。例如，集合\r\n{1,2,3} 和 {3,2,1} 是相等的，因为元素的顺序无关紧要 。 ### 集合运算 (Set\r\nOperations)\r\n并集 (Union)：A∪B={x:x∈A or x∈B} 。\r\n交集 (Intersection) ：A∩B={x:x∈A and x∈B}\r\n。如果两个集合的交集为空，则称它们不相交 (disjoint) 。\r\n补集 (Complement)：，其中 U 是全集 (Universal Set)。\r\n差集 (Difference)：A-B={x:x∈A and x∉B} 。例如 B-A 。\r\n对称差 (Symmetric Difference) : A∆B={x:x∈A or x∈B but not both} ,\r\n表示两个集合中只属于其中一个集合但不同时属于两个集合的元素所组成的集合,\r\n是异或运算 (XOR) 的结果。\r\n集合恒等式\r\n这些恒等式是集合运算的基本定律 ：\r\n幂等律 (Idempotent Law) ：A∩A=A, A∪A=A 。\r\n交换律 (Commutative Law) ：A∪B=B∪A, A∩B=B∩A 。\r\n结合律 (Associative Law) ：A∪(B∪C)=(A∪B)∪C, A∩(B∩C)=(A∩B)∩C 。\r\n分配律 (Distributive Law) ：A∪(B∩C)=(A∪B)∩(A∪C) , A∩(B∪C)=(A∩B)∪(A∩C)\r\n。\r\n吸收律 (Absorption Law) ：A∪(A∩B)=A, A∩(A∪B)=A 。\r\n德摩根定律 (De Morgan’s Law) ：A−(B∪C)=(A−B)∩(A−C),\r\nA−(B∩C)=(A−B)∪(A−C) 。\r\n幂集 (Power Set)\r\n定义：一个集合 A 的幂集是 A 的所有子集的集合 (Set of all subsets of\r\nA)，记作 2A。\r\n符号表示：2A =\r\n{T|T⊆A}。\r\n示例：如果集合 S 是 {x, y, z} ，那么它的幂集是 \\${{\\emptyset,\\{x\\},\\{y\\},\\{z\\},\\{x,y\\},\\{x,z\\},\\{y,z\\},\\{x,y,z\\}}}\\$\r\n划分 (Partition)\r\n定义：一个非空集合 A 的划分 (partition) 是 2A 的一个子集 Π ，它需要满足以下三个条件：\r\nΠ 本身不为空集 (Π ≠ ∅)。\r\nΠ\r\n中任意两个不同的成员（它们本身是集合）的交集为空集。\r\nΠ 中所有成员的并集等于 A\r\n(⋃Π = A)。\r\n示例：集合 {1,2,3} 有五种划分 ：\r\n\r\n({1}, {2}, {3})\r\n({1,2}, {3})\r\n({1,3}, {2})\r\n({2,3}, {1})\r\n({1,2,3})\r\n\r\n关系与函数 (Relations and\r\nFunctions)\r\n关系 (Relations)\r\n基本概念\r\n有序对 (Ordered Pair)：一个包含两个元素的对\r\n(a,b)，其中元素的顺序是重要的\r\n。两个有序对相等当且仅当它们的对应元素分别相等：(a,b)=(c,d)⇔(a=c)∧(b=d)\r\n。\r\n笛卡尔积 (Cartesian Product)：两个集合 A 和 B 的笛卡尔积 A×B\r\n是所有可能有序对的集合，定义为 A×B={(a,b)∣a∈A∧b∈B}。\r\n二元关系 (Binary Relation)：一个从集合 A 到集合 B 的二元关系 R\r\n是笛卡尔积 A×B 的一个子集 (R⊆A×B)。\r\n关系的运算 (Operations of\r\nRelations)\r\n逆 (Inverse)：如果 R 是一个从 A 到 B 的关系 (R⊆A×B)，那么它的逆关系\r\nR−1 是一个从 B 到 A\r\n的关系 (R−1⊆B×A)\r\n。\r\n复合 (Composition)：给定从 A 到 B 的关系 R 和从 B 到 C 的关系\r\nS，它们的复合关系 R∘S 是一个从 A 到 C\r\n的关系。其定义为：R∘S={(a,c)∣∃b∈B,(a,b)∈R ∧ (b,c)∈S}。\r\n定义域与值域 (Domain and Range):\r\n定义域\r\n(Domain)：一个关系的定义域是该关系中所有输入值的集合 。\r\n值域\r\n(Range)：一个关系的值域是该关系中所有输出值的集合。\r\n函数 (Functions)\r\n定义 (Definition): 函数是一种特殊的二元关系 。一个从 A 到 B 的函数\r\nf:A→B 必须满足两个条件：它是一个关系，即f⊆A×B; 对于集合\r\nA 中的每一个元素 a，在集合 B\r\n中都存在唯一一个元素 b，使得\r\n(a,b)∈f。通常，我们将 (a,b)∈f 记作 f(a)=b 。\r\n函数类型 (Types of Functions)\r\n\r\n单射 (One-to-one /\r\nInjective)：如果定义域中任意两个不同的元素，它们在值域中的像也不同，即\r\n∀a,b∈A∧a≠b⇒f(a)≠f(b) 。\r\n满射 (Onto /\r\nSurjective)：如果值域中的每一个元素都至少是定义域中一个元素的像，即\r\n∀b∈B, ∃a∈A such that f(a)=b 。\r\n双射 (Bijective / One-to-one\r\ncorrespondence)：一个函数如果既是单射又是满射，则称其为双射。\r\n\r\n特殊类型的二元关系\r\n(Special Types of Binary Relations)\r\n关系的表示方法\r\n有向图 (Directed Graph): 可以将集合 A 上的任意关系 R\r\n表示为一个有向图。图中的节点 (node) 代表集合 A\r\n中的每个元素。如果存在有序对 (a, b) ∈ R，则从节点\r\na 到节点 b 画一条箭头 (arrow)，也称为图的边。\r\n矩阵 (Matrix):\r\n二元关系也可以用逻辑矩阵来表示。矩阵的行和列分别对应关系中两个集合的元素。矩阵中的元素\r\nmi, j\r\n定义如下： - 如果 (xi, yj) ∈ R，则\r\nmi, j = 1。\r\n- 如果 (xi, yj) ∉ R，则\r\nmi, j = 0。\r\n关系的基本性质\r\n对于一个定义在集合 A 上的关系 R (即，R⊆A×A)，它可能具有以下性质：\r\n自反性 (Reflexive)：对于 A 中的任意元素 a，都有\r\n(a,a)∈R。 对称性 (Symmetric)：如果 (a,b)∈R，那么一定有\r\n(b,a)∈R。 反对称性 (Antisymmetric)：如果 (a,b)∈R\r\n且 (b,a)∈R，那么一定有 a=b。 传递性\r\n(Transitive)：如果 (a,b)∈R 且\r\n(b,c)∈R，那么一定有 (a,c)**∈R。\r\n同时还需要掌握关系的性质对应到矩阵和有向图的表示.\r\n等价关系 (Equivalence\r\nRelation)\r\n定义：一个关系如果同时满足自反性、对称性和传递性，则称其为等价关系。\r\n等价类 (Equivalence Classes)：对于元素 a，其等价类 [a]\r\n被定义为集合中所有与 a\r\n等价的元素的集合(可以和a构成等价关系的元素的集合)，即\r\n[a]={b∣(a,b)∈R}。在图表示中，一个等价类对应一个完全连接的”簇”。\r\n例如，可以有 a ~ b ⟺ a ≡ b (mod\r\n3)，根据这个关系，整数可以被划分为三个等价类： [0] = {…, -6, -3, 0, 3,\r\n6, …}（模 3 余 0） [1] = {…, -5, -2, 1, 4, 7, …}（模 3 余 1） [2] = {…,\r\n-4, -1, 2, 5, 8, …}（模 3 余 2）\r\n用图表示就是完全连接簇,\r\n每个等价类就形成一个完全图（每两个节点之间都有边）\r\n与划分的关系 (Partition)：一个重要的定理指出，任何集合 A\r\n上的等价关系，其所有等价类的集合构成了对集合 A 的一个划分。\r\n序关系 (Order Relations)\r\n偏序 (Partial Order): 一个关系 ≤\r\n如果同时满足自反性、反对称性和传递性，则称其为偏序关系。\r\n相关概念： - 最小元素 (Least element)：如果对集合中所有元素\r\nb，都有 a≤b。 - 极小元素 (Minimal element)：如果不存在异于 a\r\n的元素 b 使得 b≤a(可以存在不可比的元素) - 最大元素 (Greatest\r\nelement)：如果对集合中所有元素 b，都有 b≤a。 - 极大元素\r\n(Maximal element)：如果不存在异于 a 的元素 b 使得 a≤b。\r\n全序 (Total Order):\r\n如果一个偏序关系满足对于集合中任意两个元素 a 和 b，都有\r\na≤b 或 b≤a\r\n成立（即任意两个元素都可比较），那么这个关系被称为全序或线性序\r\n(linear ordering)。\r\n有限集与无限集 (Finite\r\nand Infinite Sets)\r\n集合的等势与基数\r\n等势 (Equinumerous)：如果两个集合 A 和 B\r\n之间存在一个双射函数 (bijective\r\nfunction)，则称它们是等势的 (equinumerous)，记作 A∼B\r\n。等势关系是一种等价关系，满足自反性、对称性和传递性 。\r\n基数\r\n(Cardinality)：基数是衡量集合中元素“数量”的一个概念。如果两个集合等势，那么它们的基数相同\r\n。集合 A 的基数通常表示为 ∣A∣\r\n。广义基数理论允许我们区分不同类型的无穷大。\r\n有限集与无限集: 有限集 (Finite Set)指拥有有限数量成员的集合; 无限集\r\n(Infinite\r\nSet)指不是有限集的集合。无限集又可以进一步分为可数无限和不可数无限。\r\n可数无限集 (Countably\r\nInfinite Sets)\r\n定义：如果一个集合与自然数集 N\r\n等势，则称该集合是可数无限的 (countably infinite)。其基数记为\r\nℵ0。\r\n希尔伯特旅馆悖论 (Hilbert’s\r\nparadox)：这是一个著名的思想实验，用来说明可数无限集的反直觉性质。即使旅馆客满（有无限个房间且都住着人），它仍然可以容纳：\r\n- 有限个新客人 - 无限个新客人 - 无限辆巴士，每辆巴士载有无限个新客人\r\n性质与示例： -\r\n定理：可数无限个可数无限集的并集仍然是可数无限的。\r\n三种方法证明了集合 N×N 是可数无限的： - 对角线法图示 -\r\n构造一个双射函数 - 构造两个方向的单射函数来证明基数相等\r\n不可数集与康托定理\r\n(Uncountable Sets and Cantor’s Theorem)\r\n不可数集 (Uncountable Set)：如果一个无限集的基数大于自然数集 N\r\n的基数，则称其为不可数集。\r\n定理：实数集 R 是不可数的，即 |R| &gt; |N|。\r\n有趣的是，开区间 (0,1) 与整个实数集 R\r\n是等势的，可以通过反正切函数构造一个双射来证明。\r\n连续统假设 (Continuum\r\nhypothesis)：该假设由康托提出，它断言不存在一个基数严格介于整数基数 (ℵ₀)\r\n和实数基数 (ℵ₁) 之间。\r\n康托定理 (Cantor’s Theorem)：这是一个基础性的定理，它指出对于任何集合\r\nA，其基数严格小于其幂集 P(A) 的基数，即 card(A) &lt; card(P(A))。\r\n\r\n这意味着不存在”最大的无穷大”。\r\n该定理的证明使用了对角线法，通过构造一个特殊的集合 B = {x∈A |\r\nx∉f(x)} 来证明任何从 A 到其幂集 P(A) 的函数 f 都不可能是满射的。\r\n一个直接的推论是：自然数集的幂集 2ᴺ 是不可数的。\r\n\r\n三种基本证明技巧\r\n(Three Fundamental Proof Techniques)\r\n数学归纳法\r\n(The Principle of Mathematical Induction)\r\n这是一种用于证明关于自然数的命题的标准方法。\r\n原理：令 A 为一个自然数集合，如果满足以下两个条件： 1. 0∈A 2.\r\n对于任意自然数 n，如果 {0,1,2,…,n}⊆A，那么 n+1∈A\r\n则 A 包含所有自然数。\r\n证明步骤通常包含三个部分：\r\n\r\n基础步骤 (Base Case)：证明命题 P(1)（或P(0)）成立\r\n归纳假设 (Inductive Hypothesis)：假设命题 P(k) 对于某个 k 成立\r\n归纳步骤 (Inductive Step)：证明 P(k+1) 也成立\r\n\r\n鸽巢原理 (The Pigeonhole\r\nPrinciple)\r\n该原理描述了一个简单但在证明中非常有用的数量关系。\r\n定义有两种形式：\r\n\r\n函数形式：如果 A 和 B 是有限集且 |A|&gt;|B|，那么不存在从 A 到 B\r\n的单射函数\r\n物品形式：如果有 m 个物体要放入 n 个箱子，且\r\nm&gt;n，那么至少有一个箱子包含至少两个物体\r\n\r\n示例：讲义中用该原理证明了”对于球体上的任意五个点，必定存在一个闭合的半球包含其中至少四个点”。\r\n证明：讲义本身提供了一个使用数学归纳法来证明鸽巢原理的过程。\r\n对角线法 (The\r\nDiagonalization Principle)\r\n这是一种由康托首创的强大证明技巧，常用于证明无限集的不可数性。\r\n核心思想： 1. 给定一个集合 A 上的二元关系 R，我们可以为每个元素 a∈A\r\n定义一个”行集合” Ra={b|b∈A∧(a,b)∈R} 2.\r\n通过考察对角线上的元素，我们可以构造一个新的”对角集合” D={a|a∈A∧(a,a)∉R}\r\n3. 对角线法的关键在于，构造出的集合 D 与任何一个行集合 Ra 都不同\r\n重要应用：\r\n\r\n证明康托定理：\r\n\r\n假设存在一个从集合 A 到其幂集 P(A) 的双射函数 f\r\n构造对角集合 B={x∈A|x∉f(x)}\r\n这个集合 B 属于 P(A)，但不可能等于任何一个 f(x)\r\n由此产生矛盾，证明了函数 f 不可能是满射\r\n\r\n证明实数集 R 的不可数性：\r\n\r\n假设实数集是可数的，将其所有成员列成无限序列 r₀,r₁,r₂,…\r\n通过对角线法构造新实数 d，使其小数点后第 n 位与 rn 的第 n\r\n位不同\r\n构造出的数 d 必然不在序列中，从而产生矛盾\r\n\r\n证明 2ᴺ 的不可数性：\r\n\r\n假设 2ᴺ 是可数的，将其成员表示为列表 R₀,R₁,R₂,…\r\n构造对角集合 D={n∈N|n∉Rn}\r\n集合 D 是 N 的子集，但与列表中的任何 Rn 都不同，产生矛盾\r\n\r\n\r\n闭包 (Closure)\r\n闭包的基本思想\r\n闭包的核心思想是：将一个集合进行扩展，使其在某种运算下具有”封闭”的性质，并且这种扩展是最小的。\r\n示例：\r\n自然数集 N\r\n在减法运算下是不封闭的，因为两个自然数相减的结果不一定是自然数（例如，1-2=-1∉N）。\r\n整数集 Z 在减法运算下是封闭的。Z 是包含了 N\r\n且在减法运算下封闭的最小集合。\r\n因此，我们称 Z 是 N 在减法运算下的闭包（closure）。\r\n关系的闭包 (Closures of\r\nRelations)\r\n这个概念同样可以应用于二元关系，即寻找一个最小的扩展关系，使其满足某些性质（如自反性、对称性、传递性）。\r\n自反传递闭包\r\n(Reflexive Transitive Closure)\r\n表示符号：关系 R 的自反传递闭包通常记作 R*。\r\n定义：R* 是一个包含所有有序对 (a,b) 的集合，其中在 R\r\n的有向图表示中，存在一条从 a 到 b 的路径（path）。路径的长度可以为0（即\r\na 到 a 自身）。\r\n性质： - R* 包含了原始关系 R（R⊆R） - R 本身是自反的和传递的\r\n- R* 是包含了 R 并且满足自反性和传递性的最小关系\r\n传递闭包 (Transitive Closure)\r\n表示符号：关系 R 的传递闭包通常记作 R+。\r\n定义：R+ 是包含了 R 并且是传递的最小关系。它与 R* 的区别在于，R+\r\n不要求必须是自反的（即路径长度必须大于0）。\r\n形式化条件：一个关系是 R 的传递闭包 R+，必须满足： 1. R⊆R+ 2. R+\r\n是传递的 3. 对于任何其他包含了 R 并且是传递的关系 R’，都有 R+⊆R’\r\n字母表与语言 (Alphabet and\r\nLanguage)\r\n本节是连接前面纯数学概念与后续计算理论核心内容的桥梁\r\n。它形式化地定义了计算机科学中用于信息编码的基本单位：符号、字符串和语言\r\n。 ## 字母表与字符串 (Alphabet and Strings)\r\n字母表 (Alphabet)\r\n定义：字母表（记作 Σ）是一个任意的有限集合。\r\n符号 (Symbol)：字母表中的元素被称为符号。\r\n示例： - 二进制字母表：Σ = {0,1} - 英文字母表：Σ = {a,b,c}\r\n字符串 (Strings) 及其运算\r\n定义：字符串 (String)\r\n是由字母表中的符号组成的有限序列。字符串也常被称为词\r\n(Word)。\r\n\r\n这里需要知道, 由一个非空字母表所能构成的字符串集合是无限的,\r\n但是我们只把有限长度的字母组合叫做字符串, 也就是说, 一个无限长的 aaaa…\r\n序列根据这个标准定义，不被认为是一个“字符串”\r\n\r\n空字符串 (Empty string)：不含任何符号的特殊字符串，记作 e。\r\nΣ* ：表示在字母表 Σ\r\n上所有可能字符串的集合，包括空字符串 e。(也被称为字母表\r\nΣ 的 克林闭包（Kleene Closure）) - 因此Σ*永远不为空集(至少包含e)\r\n字符串运算：\r\n\r\n连接 (Concatenation)：将两个字符串 x 和 y 首尾相连形成新字符串\r\nxy。空字符串是连接运算的单位元，即对于任意字符串 w，we = ew = w。\r\n幂 (Exponentiation)：字符串 w 的 i 次幂 w^i 表示 w 自身连接 i\r\n次。w^0 = e。\r\n逆序 (Reversal)：字符串 w 的逆序 w^R 是将 w\r\n中的符号顺序颠倒。例如，如果 w = ua(a ∈ Σ), 则 w^R =\r\nau^R(递归定义)。\r\n\r\n语言 (Language)\r\n定义：一个语言 L\r\n是在某个字母表 Σ\r\n上所有字符串的集合 Σ*\r\n的一个任意子集（L ⊆ Σ*）。或者换句话说,\r\n语言 L\r\n是由符合特定规则的所有字符串组成的集合。\r\n示例： - 空语言 ⌀ -\r\n只包含空字符串的语言 {e} -\r\n字母表本身 Σ 以及 Σ* 都是合法的语言\r\n语言可以是： -\r\n有限语言：通过明确列出所有字符串来定义 -\r\n无限语言：通过描述字符串应满足的性质来定义，例如 L = {anbn ∣ n ≥ 1}\r\n关于数量的重要定理\r\n\r\n对于任意非空有限字母表 Σ，其上所有字符串的集合 Σ* 是可数无限的。\r\n任何一个语言 L（作为 Σ*\r\n的子集）都是可数的。\r\n在 Σ\r\n上所有可能语言的总数是不可数无限的，其基数与实数集相同。\r\n\r\n语言的运算\r\n标准集合运算： - 并集：L1 ∪ L2\r\n= {w ∣ w ∈ L1 ∨ w ∈ L2},\r\n代表或的关系 - 交集：L1 ∩ L2\r\n= {w ∣ w ∈ L1 ∧ w ∈ L2},\r\n代表且的关系 - 差集：L1 − L2\r\n= {w ∣ w ∈ L1 ∧ w ∉ L2}\r\n- 补集：\r\n语言特有运算：\r\n\r\n连接（Concatenation）： L1L2 = {w1w2 ∣ w1 ∈ L1 ∧ w2 ∈ L2}\r\n幂（Exponentiation）： \r\n克林星号/闭包（Kleene Star）：  表示由 L\r\n中字符串进行任意次数（包括零次）连接所能形成的所有字符串的集合。L* 是 L 在连接运算下的闭包。\r\n正闭包（Positive Closure）：  与 L*\r\n的唯一区别是不包含零次连接，即不包含空字符串 e（除非 e 本身在 L 中）。\r\n\r\n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"计算理论简介","url":"/2025/09/15/algorithms/Computing%20Theory/Index/","content":"计算理论是计算机科学的基石，它试图从根本上回答三个关于“计算”这一过程的终极问题：\r\n\r\n能做什么？什么是算法？（可计算性, 不可判定性）\r\n用什么模型来做？（自动机与模型）\r\n能多快/多好地做？（复杂性）(本课程未涉及)\r\n\r\n这门学科本质上是数学的一个分支，它使用严谨的、抽象的数学模型来探索计算的本质、能力和极限\r\n该课程安排在大三秋冬学期, 参考课本为《Elements of the Theory of\r\nComputation》. 课程的宏观框架如下:\r\n一、 数学预备知识（基础）\r\n在深入探讨计算理论之前，课程首先介绍了所需的基础数学语言和概念。这部分对应课本的第1章。\r\n核心内容：集合、关系、函数、有穷与无穷集合\r\n、基本的证明技术（如数学归纳法、鸽巢原理和对角化方法）、字母表与语言，以及算法的初步介绍\r\n。\r\n二、 形式语言与自动机理论\r\n这是计算理论的第一大核心板块。它主要研究“受限制的计算模型”\r\n，探索它们的能力边界，这些模型在电路设计和编译器（如词法分析）等领域有实际应用\r\n。这部分对应第2章和第3章。\r\n正则语言 (Regular Languages)：\r\n\r\n计算模型：使用有穷自动机 (Finite Automata)\r\n，包括确定型（DFA）和非确定型（NFA） 。\r\n语言表示：使用正则表达式 (Regular Expressions) 。\r\n关键结果：证明了非确定型有穷自动机、确定型有穷自动机和正则表达式三者在表达能力上是等价的\r\n。\r\n研究问题：状态最小化 、正则语言的泵定理（Pumping\r\nLemma）以及如何证明一个语言不是正则的 。\r\n\r\n上下文无关语言 (Context-Free Languages)：\r\n\r\n计算模型：使用下推自动机 (Pushdown Automata)\r\n。这是一种比有穷自动机更强，增加了“栈”（一种下推存储器）的计算模型\r\n。\r\n语言表示：使用上下文无关文法 (Context-Free Grammars) 。\r\n\r\n上下文无关语言 (Context-Free Languages)：\r\n\r\n计算模型：使用下推自动机 (Pushdown Automata)\r\n。这是一种比有穷自动机更强，增加了“栈”（一种下推存储器）的计算模型\r\n。\r\n语言表示：使用上下文无关文法 (Context-Free Grammars) 。\r\n研究问题：语法分析（Parsing）与语法分析树（Parse Trees）\r\n、文法的歧义性（Ambiguity）、以及上下文无关语言的泵定理。\r\n\r\n三、 可计算性理论 (Computability Theory)\r\n这是计算理论的第二大核心板块。它旨在建立一个“算法的一般模型”，并利用这个模型来回答计算机科学的根本问题：什么是可计算的？什么是不可计算的？这部分对应第4章和第5章。\r\n通用计算模型 (General Model of Computation)： -\r\n核心模型：Turing 机 (Turing Machine)\r\n。图灵机被视为描述任意算法的通用框架 。 -\r\n研究内容：引入Turing机的变种（如多带Turing机、随机存取Turing机）\r\n，并证明它们在计算能力上都等价于基本的Turing机模型 。这也引出了\r\nChurch-Turing 论题 。\r\n不可判定性 (Undecidability)： -\r\n核心问题：研究那些被证明“根本不可能用计算机解决”的问题 。 -\r\n关键结果：证明停机问题 (The Halting Problem) 是不可判定的 。 -\r\n研究内容：讨论其他不可判定的问题，如与文法或铺砖问题相关的不可解问题\r\n。\r\n最后一部分是计算复杂性理论 (Complexity Theory),\r\n这是计算理论的第三大核心板块。它研究那些可计算的问题，并根据其解决所需的资源（主要是时间或空间）来对其进行分类，探讨哪些问题存在“实际可行的算法”;\r\n这部分定义了计算复杂性的概念，如P类问题、NP类问题、NPC问题和NP完全问题等,\r\n由于课时安排暂且按下不表.\r\n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"召回","url":"/2024/06/26/algorithms/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E5%8F%AC%E5%9B%9E/","content":"基于物品的协同过滤\r\n(Item-Based Collaborative Filtering, ItemCF)\r\nItemCF的原理：如果用户喜欢物品 1，而且物品 1 与物品\r\n2 相似，那么用户很可能也喜欢物品 2。\r\n这个原理非常直观。在现实生活中，如果你喜欢一部科幻电影（比如《星际穿越》），那么推荐系统很可能会向你推荐另一部评价很高、风格类似的科幻电影（比如《盗梦空间》），因为它假设这两部电影是”相似”的。ItemCF\r\n就是将这种思想系统化和自动化。\r\n它的核心优势在于，物品之间的相似性在大多数情况下是相对稳定的，比用户兴趣的稳定性要高。因此，可以预先离线计算好物品之间的相似度，从而在线上实现快速推荐。\r\n当然，ItemCF\r\n也有局限性。它无法发掘用户的潜在兴趣，推荐结果往往比较局限，新颖性不足。对于新物品还存在\r\n冷启动 (Cold Start)\r\n问题，因为它没有被评分，无法计算相似度。\r\n计算两个物品之间相似度的公式\r\n余弦相似度: \r\n\r\n在隐式反馈场景，即只要用户喜欢过（比如点击过）like(u,i)=1的时候,\r\n公式进一步退化为最后一项。\r\n\r\n\r\ni1, i2：代表我们想要计算相似度的两个物品（例如，电影A和电影B）。\r\nW1：喜欢物品\r\ni1\r\n的所有用户的集合。\r\nW2：喜欢物品\r\ni2\r\n的所有用户的集合。\r\nV = W1 ∩ W2：同时喜欢物品\r\ni1 和 i2\r\n的所有用户的集合。这个交集是计算相似度的关键。\r\nlike(u, i)：代表用户\r\nu 对物品 i 的喜好程度。\r\n\r\n在隐式反馈场景中：如果用户 u 点击/播放/购买了物品 i，则 like(u, i) = 1，否则为\r\n0。\r\n在显式反馈场景中：like(u, i)\r\n可以是用户 u 对物品 i 的具体评分，比如 1 到 5 星。\r\n\r\n\r\n分子 (Numerator)\r\n\r\n含义：这部分计算的是两个物品被共同用户喜欢的程度的累积。\r\n步骤说明： 1. 找到所有同时喜欢过 i1 和 i2 的用户（即集合 V 中的每一个用户 v）。 2. 对于每一个这样的用户 v，取出他对 i1 的喜好分 like(v, i1)\r\n和他对 i2 的喜好分\r\nlike(v, i2)。\r\n3. 将这两个分数相乘。 4.\r\n将所有共同用户的计算结果（乘积）全部加起来。\r\n直观理解：如果共同喜欢这两个物品的用户，都给出了很高的评分，那么这个分子的值就会很大，说明这两个物品在”核心粉丝群”中的评价模式很一致。\r\n分母 (Denominator)\r\n\r\n含义：这部分是两个物品各自”热度”的体现，起到归一化 (Normalization)\r\n的作用，旨在消除物品流行度带来的影响。\r\n步骤说明： - 分母由两部分相乘构成： - 第一部分：\r\n - 找到所有喜欢物品 i1 的用户（集合 W1）。 - 计算每个用户对\r\ni1\r\n喜好程度的平方，并把它们全部加起来。 -\r\n最后对这个总和开平方根。这在数学上被称为向量的 L2 范数 (L2-norm)。 -\r\n第二部分：  - 对物品 i2\r\n进行完全相同的计算。\r\n直观理解：一个物品越热门，喜欢它的用户（W1 或 W2）就越多，它在分母上的值就越大。这就像一个惩罚项，可以降低超级热门物品与任何其他物品的相似度。\r\n预估用户对候选物品的兴趣\r\n计算出物品之间的相似度后，我们就可以为特定用户 u 预测他对某个候选物品\r\nj 的兴趣度（或评分）了。\r\n基本思路：\r\n\r\n找到该用户 u 过去喜欢过的所有物品集合 S(u)。\r\n对于候选物品 j，计算它和各个 S(u) 集合中物品的相似度。\r\n用户 u 对物品 j 的兴趣度 P(u,\r\nj)，可以通过加权平均的方式计算得出。\r\n\r\n公式：\r\nP(u, j) = ∑i ∈ S(u), i ≠ jlikeui ⋅ sim(i, j)\r\n\r\nsim(i, j)\r\n是物品 i 和物品 j 的相似度。\r\nlikeui\r\n是用户 u 对物品 i 的喜好程度。\r\nS(u) 是用户 u\r\n过去有过行为的物品集合。\r\n\r\n步骤说明：\r\n\r\n遍历用户历史行为：我们查看用户 u 过去喜欢的每一个物品 i 。\r\n查找相似度：找到物品 i 与目标物品 j 之间的相似度 。\r\n加权求和：将这个相似度作为权重，乘以用户对物品 i 的喜好程度。\r\n累加：将所有这些加权后的分数累加起来，就得到了用户 u 对物品 j\r\n的最终兴趣预测分。分数越高，代表用户可能越喜欢它。\r\n\r\n利用索引在线上快速做召回\r\n在大型推荐系统中，物品数量可能达到百万甚至千万级别。如果每次推荐请求都实时计算所有物品的相似度和预测得分，计算量会非常巨大，无法满足线上服务的低延迟要求。\r\n问题：\r\n线上服务要求在几十毫秒内返回推荐结果，实时计算是不可行的。\r\n解决方案：建立倒排索引 (Inverted Index)。\r\n具体做法：\r\n\r\n离线计算：在离线环境下，花费数小时甚至数天的时间，计算出所有物品两两之间的相似度。这是一个计算密集型任务。\r\n存储相似物品：对于每一个物品\r\ni，我们筛选出与它最相似的 K 个物品，并将这个关系 {i : [(j1, sim1), (j2, sim2), ...]}\r\n存储起来。这个结构就是一个倒排索引：键（Key）是物品\r\ni，值（Value）是一个列表，包含了与 i 最相似的物品及其相似度分数。\r\n线上召回 (Retrieval)：当一个用户 u\r\n发出推荐请求时，系统执行以下快速操作：\r\n\r\n\r\n获取该用户最近有过行为的物品列表（例如，最近点击的 10\r\n个商品）。\r\n\r\n\r\n对于列表中的每一个物品 i，通过倒排索引，瞬间查到与 i\r\n最相似的物品集合。\r\n\r\n\r\n将所有这些相似物品集合汇总、去重、排序，然后生成最终的推荐列表。\r\n\r\n\r\n\r\n优势：\r\n通过预计算和索引，线上的推荐过程从复杂的”计算”任务转变为高效的”查找”任务，极大地降低了响应时间，满足了实时推荐的需求。\r\n基于模型的协同过滤\r\n(Model-Based Collaborative Filtering, ModelCF)\r\n基于模型的协同过滤算法，通过构建用户和物品的潜在特征矩阵，旨在从稀疏的评分数据中学习到能够描述用户和物品特性的隐因子\r\n(Latent Factors)来预测用户对物品的兴趣。\r\n矩阵分解 (Matrix\r\nFactorization, MF)\r\n矩阵分解是基于模型的协同过滤算法中的一种，它将用户-物品评分矩阵分解为两个低维矩阵的乘积，从而揭示用户和物品的潜在特征。\r\n矩阵分解假设用户对物品的评分行为是由一些潜在的、无法直接观测到的共同因素决定的。例如，在电影推荐中，这些隐因子可能代表着电影的”喜剧成分”、“动作片成分”、“艺术性”，以及用户对这些成分的偏好程度。\r\n它的目标是将原始的 用户-物品评分矩阵 R (大小为\r\nm×n，m是用户数，n是物品数) 分解为两个低维度的\r\n隐因子矩阵：用户因子矩阵 P (大小为\r\nm×k)和物品因子矩阵 Q (大小为 n×k),\r\n其中k是隐因子的数量，是一个远小于 m 和 n 的超参数 (k≪m,n)。\r\n通过这两个矩阵，我们可以用它们的乘积来近似重构原始的评分矩阵：R ≈ P × QT\r\n\r\nP 矩阵：每一行 pu\r\n代表一个用户的 用户隐向量，描述了该用户在 k\r\n个隐因子上的偏好程度。\r\nQ 矩阵：每一行 qi\r\n代表一个物品的 物品隐向量，描述了该物品在 k\r\n个隐因子上的分布情况。\r\n\r\n预测评分：用户 u 对物品 i 的预测评分 r̂ui\r\n就是他们对应隐向量的 点积 (Dot Product)：\r\n\r\n如何进行分解？—— 模型学习\r\n由于原始评分矩阵 R 是高度稀疏的，我们无法直接进行像 奇异值分解\r\n(Singular Value Decomposition, SVD)\r\n这样的标准矩阵分解。因此，我们采用机器学习的方法来学习 P 和 Q 矩阵。\r\n\r\n定义目标函数 (Objective Function)： 我们的目标是让预测评分 r̂ui\r\n尽可能地接近已知的真实评分 rui。因此，我们定义一个基于均方根误差\r\n(RMSE) 的损失函数，并为了防止过拟合 (Overfitting)，加入\r\n正则化项 (Regularization Term)。\r\n\r\n\r\nminP, QL = ∑(u, i) ∈ K(rui − pu ⋅ qi)2 + λ(||pu||2 + ||qi||2)\r\nK：所有已知的用户-物品评分对的集合。\r\n(rui − pu ⋅ qi)2：平方误差项，衡量预测与真实的差距。我们只对已知的评分进行计算。\r\nλ(||pu||2 + ||qi||2)：L2\r\n正则化项，用于惩罚隐向量中元素值过大的情况，增强模型的泛化能力。λ\r\n是正则化系数。\r\n\r\n\r\n优化求解： 常用的优化算法有两种：\r\n\r\n\r\n交替最小二乘法 (Alternating Least Squares, ALS)\r\n\r\n这是一个两阶段的迭代过程。首先，固定 Q\r\n矩阵，此时目标函数是关于 P\r\n的二次函数，可以直接求解得到最优的\r\nP。然后，固定更新后的 P\r\n矩阵，用同样的方法求解最优的 Q。\r\n交替进行这两个步骤，直到收敛。ALS\r\n的优点是易于并行化实现，尤其适用于处理大规模的隐式反馈数据。\r\n\r\n随机梯度下降 (Stochastic Gradient Descent, SGD)\r\n\r\n随机选择一个已知的评分 (u,i)，计算损失函数对\r\npu 和\r\nqi\r\n的偏导数，并沿着梯度的反方向小步更新这两个向量。\r\n更新规则：\r\n\r\n\r\n其中，eui = rui − r̂ui\r\n是预测误差，η 是学习率。\r\n通过大量迭代，不断地对 P 和 Q\r\n进行微调，直到损失函数收敛。这种方法实现简单，计算速度快。\r\n\r\n\r\n矩阵分解的优缺点\r\n优点：\r\n\r\n处理稀疏数据能力强：通过低维的隐因子表示，极大地缓解了数据稀疏问题。\r\n泛化能力好：能够发现数据中潜在的关联模式，预测精度通常高于近邻方法。\r\n可扩展性强：模型训练好后，预测新评分的计算成本很低。\r\n\r\n缺点：\r\n\r\n缺乏可解释性：学习到的隐因子通常没有明确的物理意义，难以向用户解释推荐的原因。\r\n冷启动问题依然存在：对于新用户或新物品，由于没有历史数据，无法为其生成隐向量。\r\n\r\n","categories":["algorithms"],"tags":["搜广推"]},{"title":"推荐系统基础","url":"/2024/06/26/algorithms/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","content":"推荐系统（Recommender System）是一种信息过滤系统（Information\r\nFiltering\r\nSystem），其核心目标是解决在海量数据环境中用户与物品（Items）之间的信息过载（Information\r\nOverload）问题。系统通过建模用户偏好与物品属性，预测用户对于其未曾接触过的物品的偏好程度或评分，从而实现个性化推荐。\r\n推荐系统的基本概念\r\n从数据来源、效果评估到商业目标和工程实践，推荐系统主要包括四个核心方面：\r\n1. 用户行为（User\r\nBehaviors）—— 推荐系统的信号与养料\r\n用户与推荐内容交互时产生的各种行为，是推荐系统赖以生存的数据信号，模型通过学习这些信号来理解用户的偏好。\r\n\r\n点击（Click）\r\n\r\n定义：用户点击了推荐给他的某个物品（如一篇文章、一个视频、一件商品）。\r\n解读：最常见、最容易获取的行为信号，通常被认为是弱正反馈。表明用户对标题或封面图产生了兴趣，但不代表一定喜欢内容本身。\r\n\r\n点赞（Like）\r\n\r\n定义：用户对内容按下了”赞”按钮。\r\n解读：比”点击”更强的正反馈信号，明确表达了用户对内容的认可和喜爱。\r\n\r\n收藏（Favorite / Collect）\r\n\r\n定义：用户将内容加入到自己的收藏夹或列表中。\r\n解读：非常强的正反馈信号，意味着内容具有长期价值。\r\n\r\n转发（Share / Forward）\r\n\r\n定义：用户将内容分享到其他平台或发送给朋友。\r\n解读：最强的正反馈信号之一，用户愿意用自己的社交信誉为其背书。\r\n\r\n\r\n\r\n小结：在构建推荐模型时，通常会给这些不同的行为赋予不同的权重（Weight），如”收藏”权重高于”点击”。\r\n\r\n\r\n2.\r\n消费指标（Consumption Metrics）—— 衡量推荐算法好坏的尺子\r\n这些指标用于量化评估推荐系统在技术层面的表现，直接与用户行为挂钩。\r\n\r\n点击率（Click-Through Rate, CTR）\r\n\r\n定义：用户点击推荐内容的次数占总推荐曝光次数的比例。\r\n公式： CTR = 总点击次数 / 总曝光次数 × 100%\r\n解读：衡量推荐内容吸引力的核心指标，也是精排模型最常优化的目标之一。\r\n\r\n交互率（Engagement Rate）\r\n\r\n定义：用户与推荐内容发生”深度交互”的次数占总曝光次数的比例。\r\n公式： 总交互次数 = w1 × 点击数 + w2 × 点赞数 + w3 × 收藏数 + ...\r\n解读：比 CTR 更全面，反映内容质量和用户满意度。\r\n\r\n\r\n\r\n3.\r\n北极星指标（North Star Metric）—— 推荐系统服务的商业目标\r\n北极星指标是指引整个产品方向的最高层商业目标，推荐系统的所有优化最终都应服务于提升北极星指标。\r\n\r\n用户规模（User Scale）\r\n\r\n定义：如日活跃用户数（DAU）、月活跃用户数（MAU）。\r\n解读：好的推荐系统应提升用户留存率，扩大用户规模。\r\n\r\n消费（Consumption）\r\n\r\n定义：用户在产品中消费内容的总量。\r\n解读：如总观看时长、总阅读时长/篇数、总播放时长/曲数、总成交金额（GMV）等。\r\n\r\n发布（Publishing / Creation）\r\n\r\n定义：内容平台上内容创作者的发布数量和活跃度。\r\n解读：推荐系统要服务好消费者，也要服务好创作者，激励持续发布高质量内容。\r\n\r\n\r\n\r\n4.\r\n实验流程（Experimentation Process）—— 科学迭代的必经之路\r\n用于验证新推荐算法或策略是否有效，并安全应用到全量用户。\r\n\r\n离线实验（Offline Experiment）\r\n\r\n定义：在历史日志数据上进行模型训练和评估。\r\n步骤：将日志分为训练集和测试集，训练新模型并评估离线指标（如 AUC,\r\nPrecision, Recall）。\r\n优缺点：成本低、速度快、无风险，但与线上环境有差异。\r\n\r\nA/B 测试（A/B Testing）\r\n\r\n定义：将用户随机分组，线上同时运行不同算法，是验证算法效果的黄金标准。\r\n步骤：A 组用旧算法，B 组用新算法，比较线上指标。\r\n\r\n推全（Full Rollout / Deployment）\r\n\r\n定义：AB 测试证明新算法更优后，逐步部署到全部用户。\r\n步骤：通常灰度发布，逐步扩大覆盖比例，监控系统指标。\r\n\r\n\r\n\r\n推荐系统链路\r\n现代推荐系统采用多阶段排序（Multi-stage\r\nRanking）架构，像漏斗一样分阶段筛选和排序，平衡效果与效率。\r\n召回（Recall）\r\n召回是整个推荐流程的第一步，也是效率要求最高的一步。 -\r\n目标：从海量物品库中快速筛选出与用户兴趣相关的候选集。此阶段追求“宁可错杀一千，不可放过一个”，重在覆盖率（召可回率），即确保用户可能感兴趣的物品尽量都在这个候选集里。\r\n- 输入：全量物品库（几万~上亿）。 - 输出：初步候选集（几千）。 -\r\n方法：多路召回策略, 即通常会综合使用多种简单策略来共同组成候选集。 -\r\n协同过滤(Collaborative\r\nFiltering)：基于“物以类聚，人以群分”的思想，例如“购买了A的用户也购买了B,\r\n给用户推荐他喜欢过的物品的相似物品”（Item-based）或“与您相似的用户喜欢C,\r\n给用户推荐与他相似用户喜欢的东西”（User-based）。 -\r\n基于向量的召回\r\n(Embedding-based)：目前最主流的方法。将用户和物品都表示为高维空间中的向量（Embedding）。通过高效的向量相似度检索（如\r\nFAISS、Annoy），快速找到与用户向量最接近的物品向量。例如经典的双塔模型\r\n(Two-Tower Model)。 -\r\n内容模型召回：根据物品本身的属性（如类别、标签、关键词）进行匹配。\r\n-\r\n热门物品或趋势召回：对于新用户或兴趣不明确的用户，推荐近期热门的物品。\r\n- 为何需要此步骤:\r\n直接对全量物品进行复杂排序的计算成本是无法接受的。召回阶段通过简单、高效的模型，将计算范围缩小到千量级，为后续更复杂的排序模型做好准备。\r\n粗排（Coarse Ranking）\r\n\r\n目标：对召回候选集进行初步排序，，使用比召回更复杂、但比精排更简单的模型，进一步剔除相关性不高的物品，缩小候选集规模。\r\n输入：召回候选集（几千）。\r\n输出：更小的候选集（几百）。\r\n方法：简化机器学习模型（LR、GBDT、小型神经网络）。\r\n为何需要此步骤:\r\n它是一个承上启下的“中间层”。精排模型虽然效果好，但计算开销大，直接处理几千个物品依然很慢。粗排模型作为一个轻量级的排序模型，可以快速地为精排阶段减负。\r\n\r\n精排（Fine Ranking）\r\n精排是整个推荐链路中最为核心和复杂的环节，直接决定了推荐效果的天花板。\r\n-\r\n目标：精准排序。利用强大的、复杂的模型，对粗排筛选出的几百个物品进行精准的点击率（CTR）、转化率（CVR）等指标的预测，并按照预测分值进行排序。此阶段重在准确率（Precision）。\r\n- 输入：粗排候选集（几百）。 -\r\n输出：一个带有精确预测分数的、排序后的列表（几百物品）。 -\r\n方法：大规模深度学习模型（Wide &amp; Deep、DeepFM、DIN 等）。 -\r\n为何需要此步骤:\r\n在候选集规模已经大大减小的情况下，系统有充足的计算资源来运行复杂模型。这使得模型可以使用海量的特征，包括用户特征（年龄、性别、历史行为）、物品特征（类别、价格）、上下文特征（时间、地点）以及它们的交叉组合特征，从而做出最精准的判断。\r\n## 重排（Re-ranking） -\r\n目标：优化与多样性。在精排结果的基础上，进行最终的列表调整。重排考虑的不仅是单个物品的得分，而是整个列表呈现给用户时的整体体验。\r\n- 输入：精排列表（几百）。 - 输出：最终列表（几十）。 - 方法： -\r\n多样性（Diversity）：通过打散和插播策略，确保推荐结果中包含不同类别、不同风格的物品。例如，使用\r\nMMR (Maximal Marginal Relevance) 算法，平衡物品的相关性和多样性。 -\r\n业务规则干预：推广新品、促销品，或者对某些物品进行降权（例如已购买的物品）。\r\n- 上下文感知：去除重复项，避免短时间内重复推荐。 -\r\n公平性（Fairness）：确保不同商家或内容创作者能获得合理的曝光机会。 -\r\n为何需要此步骤:\r\n如果完全按照精排的预测分值排序，可能会出现结果高度相似（例如推荐一整排同款不同色的鞋子）、头部物品包揽所有流量、或忽略了新品曝光等问题。重排阶段就是为了解决这些问题，提升用户体验和满足业务需求。\r\n\r\n推荐系统的 AB 测试\r\n下列内容是在工业界进行大规模 A/B\r\n测试时非常核心且高级的概念，反映了顶级互联网公司如何在高并发和快速迭代环境下科学、高效地优化产品和算法。\r\n1. 分层实验（Layered\r\nExperiments）\r\n这是一种能够大幅提升实验效率的流量分配机制，其核心思想在于将互不干扰的实验叠加在同一批用户上。\r\n\r\n基本思想：一个推荐系统可以被拆分成不同的“模块”或“层面”，例如：\r\n\r\nUI 层：负责按钮颜色、字体大小等界面展示。\r\n召回策略层：负责从海量物料中捞取候选集。\r\n排序模型层：负责对候选集进行精准排序。\r\n分层实验平台允许我们为这些不同的层面独立地开设实验。\r\n\r\n同层互斥(Mutually Exclusive within a\r\nLayer)：在同一个层内，实验之间是互斥的。这意味着一个用户在某个时刻，只能被分配到该层的一个实验组中。例如，在“排序模型层”，一个用户要么看到A模型的结果，要么看到B模型的结果，不可能同时看到两者。流量在该层内被完整切分。\r\n不同层正交 (Orthogonal between\r\nLayers)：在不同的层之间，实验是正交（独立）的。这意味着一个用户可以同时属于不同层的多个实验组。例如，一个用户可以同时是“UI层-红色按钮”实验组的成员，又是“排序模型层-新版模型B”实验组的成员。系统假设UI的改变和排序模型的改变是两个独立事件，它们的效果不会相互影响。\r\n\r\n\r\n优势：允许多个团队并行开展实验，大幅提升创新速度。\r\n\r\n2. Holdout 机制（Holdback 实验）\r\n这是一种用于衡量长期、累积影响的宏观实验方法，其视角超越了单次A/B测试的短期收益。\r\n\r\n基本思想：从全部用户中，永久性地分出一小部分（例如\r\n1%\\~5%）作为“绝对对照组”或“Holdout\r\n组”。这个组的用户将永远不会体验到任何新的推荐功能或算法优化，他们使用的始终是一个非常稳定、原始的版本。而剩下\r\n95%~99% 的用户则会不断地体验到通过A/B测试胜出的新功能。\r\n作用：\r\n\r\n衡量部门的整体业务收益：单次的A/B测试衡量的是单个小改动的短期收益。但是，一个季度、一年下来，整个部门上线的几十上百个“胜出”的实验，它们累加起来的效果究竟有多大？会不会有些短期收益在长期来看会相互抵消，甚至产生负面作用（例如用户对某种策略产生疲劳）？\r\n步骤说明：通过在年底或季末比较“实验大盘用户”和“Holdout组用户”的核心业务指标（如留存率、总消费时长等），就可以清晰地衡量出，在这一整段时间里，整个推荐团队的所有努力共同创造的净业务价值。这为衡量团队的长期ROI（投资回报率）提供了最可靠的依据。\r\n\r\n比喻：Holdout 组就像科学实验中的”空白对照组”,\r\n它为我们评估所有变量的“混合累积效应”提供了一个不变的基准。\r\n\r\n3.\r\n实验推全（Full Rollout）与反转实验（Reverse Experiment）\r\n这是与实验生命周期管理相关的两个重要操作。\r\n实验推全\r\nAB 测试胜出后，将新策略逐步推向全体用户，通常采用灰度发布。 -\r\n基本思想：当一个A/B测试（例如，新算法B\r\nvs. 老算法A）在经过足够长的时间和数据收集后，被验证为显著优于对照组时（例如，新算法B的点击率显著更高），决策者就会决定将这个新算法B的策略应用到100%的全体用户。这个过程就是“推全”。\r\n-\r\n步骤说明：为了线上服务的稳定性，推全通常是逐步进行的（也称灰度发布），例如先推10%的流量，再到50%，最后到100%，并在此期间密切监控各项系统指标。\r\n### 反转实验 (Reverse Experiment)\r\n验证已上线老功能是否依然有效，或移除后是否有负面影响。 -\r\n基本思想：这是一种“回过头看”的实验，主要目的是验证已上线很久的老功能是否依然有效，或者说，移除它是否会带来损失。\r\n-\r\n操作流程：假设“功能F”在一年已经全量上线了。现在，我们将以“全体用户（都有功能F）”作为基线，然后开启一个反向的AB测试：\r\nA组（对照组）：保持现状，拥有功能F。\r\nB组（实验组）：移除功能F，体验没有该功能的状态。 - 为何需要此机制？ -\r\n确认长期价值：验证该功能是否至今仍在创造价值。如果移除后，B组的核心指标显著下跌，说明该功能依然重要。\r\n-\r\n清理“技术债务”：如果移除后，B组的指标没有任何变化，甚至有所提升，这说明该功能可能已经“过时”或产生了不易察觉的负面影响。这为工程师安全地移除老旧代码、简化系统提供了强有力的数据支持，避免产品功能无限膨胀和代码腐化。\r\n参考论文: Tang, Diane, et al. “Overlapping experiment\r\ninfrastructure: More, better, faster experimentation.”\r\nProceedings of the 16th ACM SIGKDD international conference on Knowledge\r\ndiscovery and data mining. 2010.\r\n推荐系统的前世今生: https://www.bilibili.com/video/BV1EE421G7dg/\r\n","categories":["algorithms"],"tags":["搜广推"]},{"title":"操作系统对象","url":"/2024/08/20/system/Old_OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%B9%E8%B1%A1/","content":"文件描述符\r\n在 Linux/Unix\r\n操作系统中，文件描述符是进行所有输入/输出（I/O）操作的基础。它是一个非负整数，作为程序与内核之间进行文件操作的“凭证”。理解文件描述符的关键在于掌握其背后的三层内核数据结构：进程文件描述符表、系统级打开文件表和\r\ni-node 表。\r\n回到定义, 文件描述符 (File Descriptor, fd)\r\n本质上是一个索引，指向一个进程内核区域中的特定数据结构。它的形式是一个非负整数（0,\r\n1, 2, 3,\r\n…）。当进程成功打开一个文件或创建一个管道/套接字时，内核会返回一个文件描述符。此后，程序所有对该文件的读、写、关闭等操作，都通过这个整数来标识，而无需再使用文件名。\r\n\r\n回忆“一切皆文件”：在 Unix\r\n哲学中，设备（如键盘、显示器）、网络连接（套接字）等都被抽象为文件，因此也都可以通过文件描述符来访问。\r\n\r\n需要注意的是, 当一个进程启动时，默认会拥有三个标准的文件描述符： - 0\r\n: 标准输入 (stdin) - 键盘 - 1 : 标准输出 (stdout) - 屏幕 - 2 : 标准错误\r\n(stderr) - 屏幕\r\n因此，程序中第一次成功 open() 一个新文件，通常返回的文件描述符是\r\n3。\r\n三层核心结构\r\n要彻底理解文件描述符的行为，必须了解其背后的三层内核结构。这三层结构清晰地分离了“哪个进程”、“哪次打开”和“哪个文件”的概念。\r\n\r\n第一层：进程文件描述符表 (Per-Process File Descriptor Table)\r\n\r\n\r\n归属：每个进程独立拥有一张。\r\n功能：它是一个简单的数组，索引就是文件描述符的整数值。数组的每个元素是一个指针，指向第二层中的一个“文件表项”。这张表将一个简单的整数（文件描述符）与一个具体的“文件打开实例”（文件表项）关联起来。它只告诉进程：“你的文件描述符\r\n3 对应的是那个文件打开实例”。\r\n\r\n\r\n第二层：系统级打开文件表 (System-wide Open File Table)\r\n\r\n\r\n归属：整个操作系统内核共享一张。\r\n功能：表中的每一个条目被称为 文件表项 (File Table\r\nEntry)，它代表了一次独立的文件打开操作。这是整个机制的核心，包含了：\r\n\r\n文件状态标志：文件是如何被打开的（如 O_RDONLY 只读, O_APPEND\r\n追加模式等）。\r\n当前文件偏移量\r\n(offset)：这是最重要的属性。它记录了下一次读/写操作在文件中的位置，即读写指针。\r\n引用计数：记录了有多少个来自第一层的指针指向此表项。\r\n指向 i-node 的指针：指向第三层，关联到文件的具体物理信息。\r\n\r\n这张表抽象了“打开的文件”这个概念。offset 存放在这里，意味着\r\noffset\r\n是跟“某次文件打开”这个行为绑定的，而不是跟进程或者文件本身绑定。\r\n\r\n\r\n第三层：i-node 表 (i-node Table)\r\n\r\n\r\n归属：系统内核级，代表物理存储上的文件。\r\n功能：每个文件或目录在文件系统中都有一个唯一的\r\ni-node。它存储了文件的元数据\r\n(metadata)，如文件大小、所有者、权限、创建时间以及数据在磁盘上的实际位置。i-node\r\n是文件的静态描述。无论一个文件被打开多少次，它在磁盘上都只有一个\r\ni-node。\r\n\r\n\r\nfork() 和 dup()\r\n对于offset的影响\r\nfork() 的情况:\r\n\r\n父进程打开一个文件，我们假设它得到 fd = 3。此时，三层结构是：\r\n\r\n\r\n父进程的 fd 表：fd[3] -&gt; 指向一个文件表项 A\r\n系统文件表：文件表项 A (offset = 0, 引用计数 = 1) -&gt; 指向\r\ni-node X\r\ni-node 表：i-node X (代表实际文件)\r\n\r\n\r\n父进程调用 fork() 创建子进程。\r\n\r\n\r\n子进程复制了父进程的文件描述符表。这意味着：\r\n\r\n子进程的 fd 表：fd[3] -&gt; 也指向同一个文件表项 A\r\n\r\n此时，文件表项 A 的状态变为：文件表项 A (offset = 0, 引用计数 =\r\n2) -&gt; 指向 i-node X\r\n\r\n结论：因为父子进程的 fd=3 都指向了同一个文件表项\r\nA，所以它们共享该表项中的所有信息，其中最重要的就是共享同一个\r\noffset。任何一方读取文件导致 offset 变化，另一方都会受到影响。\r\ndup() 的情况:\r\n\r\n进程打开一个文件，得到 fd = 3。\r\n\r\n\r\n进程 fd 表：fd[3] -&gt; 指向文件表项 A\r\n系统文件表：文件表项 A (offset = 0, 引用计数 = 1)\r\n\r\n\r\n进程调用 dup(3)，假设返回了新的文件描述符 fd = 4。\r\n\r\ndup() 的作用是在进程的 fd 表中创建一个新条目，让它指向与原 fd\r\n相同的那个文件表项。\r\n进程 fd 表：fd[3] -&gt; 指向文件表项 A； fd[4] -&gt; 也指向文件表项\r\nA\r\n结论：同样地，因为 fd=3 和 fd=4 指向了同一个文件表项\r\nA，所以它们也共享同一个 offset。\r\nmount (挂载)\r\nmount\r\n是一个将独立的“文件系统”集成到主文件系统树中的过程。简单来说，就是将一个存储设备（如硬盘分区、U盘）的内容，附加到主文件系统的一个目录下，让我们可以像访问普通目录一样访问该设备里的文件。\r\n例如, 执行 mount /dev/sdb1 /mnt/data 之后,\r\n便可以通过访问/mnt/data来直接访问挂载的存储文件系统的物理或虚拟设备，如\r\n/dev/sda1 (第一个硬盘的第一个分区)。\r\numount (卸载): 与 mount 相对，umount 命令（注意没有\r\n‘n’）则是将这个挂载文件系统从主文件系统树中移除。在拔掉 U\r\n盘等设备前，执行卸载是非常重要的安全操作。\r\npipe (管道)\r\n管道是 Unix 系统中历史最悠久也最强大的进程间通信 (Inter-Process\r\nCommunication, IPC)\r\n机制之一。它的作用是在两个进程之间建立一个单向的数据流。\r\n可以将管道想象成一条单向的传送带：\r\n\r\n一个进程（Write方）在传送带的一端放上物品（数据）。\r\n另一个进程（Read方）在传送带的另一端取走物品。\r\n传送带本身有容量限制，如果放满了，Write方就必须等待。\r\n如果传送带空了，Read方就必须等待。\r\n物品遵循“先进先出”(First-In, First-Out, FIFO) 的原则。\r\n\r\n管道的内部工作机制\r\n首先, 管道不是普通的磁盘文件，它存在于内核内存中的缓冲区 (Buffer),\r\n而且需要通过文件描述符访问.\r\n当一个进程调用 pipe() 系统调用时：\r\nint fd[2];pipe(fd);\r\n内核会执行以下操作：\r\n\r\n在内核中创建一个管道对象，这个对象包含一个内存缓冲区和相关的管理信息。\r\n在系统级打开文件表(第二级)中创建一个文件表项，这个表项指向新创建的管道对象。\r\n在调用进程的文件描述符表(第一级)中，分配两个连续的文件描述符，并让它们都指向同一个文件表项。\r\n\r\nfd[0] 被设置为只读端。\r\nfd[1] 被设置为只写端。\r\n\r\n\r\n管道的经典使用模式\r\n管道本身在一个进程中没有意义（自己写自己读），它的威力体现在与 fork()\r\n结合，用于父子进程间的通信。经典四步法如下：\r\n\r\n父进程创建管道：父进程调用 pipe(fd)，获得一个读描述符 fd[0]\r\n和一个写描述符 fd[1]。\r\n父进程创建子进程：父进程调用\r\nfork()。现在，子进程继承了父进程的文件描述符表，因此子进程也拥有了这对指向同一个管道的\r\nfd[0] 和 fd[1]。\r\n关闭不用的描述符：这是至关重要的一步，为了建立单向数据流。假设我们想让父进程写，子进程读：\r\n\r\n\r\n父进程：它只负责写，所以应该在父进程中使用下列指令关闭它的读端：close(fd[0]);\r\n子进程：它只负责读，所以应该在子进程中使用下列指令关闭它的写端：close(fd[1]);\r\n\r\n关闭不需要的一端不仅使得功能清晰, 而且也明确了结束信号\r\n(EOF)：读操作在管道为空时会阻塞。只有当所有指向管道写端的描述符都关闭后，读端再次读取时才会收到\r\nEOF (End-Of-File，返回值\r\n0)，从而知道数据已经全部发送完毕。如果子进程不关闭写端\r\nfd[1]，那么它在读完所有数据后会永远阻塞，因为它自己还持有一个“可能写入”的端口。\r\n\r\n通信：\r\n\r\n\r\n父进程通过 write(fd[1], …) 写入数据。\r\n子进程通过 read(fd[0], …) 读取数据。\r\n\r\n这个模型正是 Shell 中 | 操作符的实现原理。例如 ls -l | grep .txt，ls\r\n进程的标准输出被重定向到管道的写端，grep\r\n进程的标准输入被重定向到管道的读端。\r\n管道的类型\r\n匿名管道 (Anonymous Pipe)：由 pipe() 系统调用创建。\r\n\r\n特点：没有文件名，只能用于有亲缘关系（通常是父子）的进程间通信。它们随着进程的结束而消失。\r\n应用：Shell 中的 |。\r\n\r\n命名管道 (Named Pipe / FIFO)：由 mkfifo() 函数创建。\r\n\r\n特点：在文件系统中拥有一个可见的、特殊的文件名。这使得任何两个不相关的进程都可以通过打开这个特殊文件来进行通信。\r\n应用：用于一些需要在不同服务程序之间稳定交换数据的场景。\r\n\r\n终端和Shell\r\n终端和伪终端\r\n在计算机早期（上世纪 60-70\r\n年代），计算机主机非常昂贵且巨大，通常锁在专门的机房里。人们不是一人一台电脑，而是通过一种硬件设备来连接和使用主机。这种设备就是终端\r\n(Terminal)。\r\n它的本质就是一个纯粹的输入/输出设备,\r\n通常就是一个键盘和一个屏幕（早期甚至是类似打字机的纸张打印输出设备）。它本身几乎没有计算能力。它的唯一工作就是把你从键盘敲入的字符，通过一根串行电缆发送给计算机主机;\r\n同时接收从主机返回的字符，然后把它们显示在屏幕上。\r\n你可以把它想象成一个纯粹的“传话筒”和“显示板”。它不理解你输入的 ls\r\n是什么意思，它只负责把这两个字母传过去，再把主机返回的文件名列表显示出来。这种硬件设备也被称为\r\nTTY (Teletypewriter, 电传打字机) 的衍生品。\r\n随着技术发展，个人计算机普及了，我们不再需要一个独立的物理终端硬件。我们现在用的是功能强大的个人电脑，有图形用户界面\r\n(GUI)。因此当需要与计算机系统交互时, 我们通常会使用一个终端模拟器\r\n(Terminal Emulator)或者说伪终端(Pseudo-Terminal, PTY),\r\n也就是双击打开的黑色命令行窗口。它的工作就是用软件来模拟过去那种硬件的行为。\r\n所以，“伪”就伪在：\r\n\r\n它不是硬件，而是软件。\r\n它在软件层面模拟了一个物理终端的行为和接口。\r\n\r\n从 Shell的角度看，它感觉自己连接的从设备 (/dev/pts/N)\r\n和过去连接一个物理终端设备 (/dev/ttyS0)\r\n没什么两样。正是这种成功的“伪装”，让所有为传统终端设计的命令行程序（几乎是所有）都能在新时代的图形化窗口中无缝运行。\r\nShell\r\n而Shell,\r\n字面意思是“外壳”。这个名字非常形象，因为它就是包裹在内核这个核心之外的一层，为用户提供了一个与内核交互的界面。\r\n更详细一点, Shell\r\n是一个运行在用户空间的、作为命令解释器的应用程序。它是用户通过命令行与操作系统内核进行交互的主要接口。它接收你的文本命令，将其翻译成内核可以理解的请求（系统调用），然后将内核返回的结果显示给你。它既是强大的交互工具，也是一个功能完备的脚本编程环境。\r\n\r\n类比python(.py), 是一门解释性语言,\r\n通过python.exe这个解释器来解释执行; 同样, shell(.sh)也是一门解释性语言,\r\n通过shell解释器(例如bash, fish等)来解释执行,\r\n将文本命令翻译为系统调用\r\n\r\n作为编程语言的定位与特点\r\n虽然 Shell 是一种编程语言，但它的设计哲学和应用领域与 C++、Java 或\r\nPython 等通用编程语言（General-Purpose Language）有很大不同。\r\n\r\n领域特定语言（Domain-Specific Language）: Shell\r\n的主要设计目标是自动化系统管理任务和与操作系统交互。它的“领域”就是操作系统的命令行环境。\r\n胶水语言（Glue Language）: Shell\r\n最强大的能力是作为“胶水”，将操作系统中成百上千个小而专的命令行工具（如\r\nls, grep, awk, sed,\r\ncurl）粘合起来，通过管道（|）和重定向（&gt;）组合成强大的工作流。它的编程模型不是从零开始构建所有逻辑，而是编排和调度其他程序。\r\n解释型语言（Interpreted Language）: Shell\r\n脚本由解释器（如 bash,\r\nzsh）逐行读取并执行，无需预先编译。这使得开发和测试周期非常快，非常适合快速编写自动化脚本。\r\n\r\n不过, 其显著缺点则是数据结构有限和不擅长计算.\r\n原生POSIX标准仅支持字符串和一维数组，处理复杂的数据结构（如哈希表、树、对象）非常笨拙。且对于数学运算，尤其是浮点数运算，支持非常薄弱，通常需要借助\r\nbc 或 awk 等外部工具。\r\n区别cmd, pwsh与bash\r\n正如前面所说, Shell 是一个核心概念，它指代命令行解释器（Command Line\r\nInterpreter），即为用户提供与操作系统交互接口的程序。基于这一理念，业界诞生了多种具体的\r\nShell 实现。CMD (Command Prompt)是 Windows 的早期命令解释器,\r\n只是一个简单的、基于文本行的命令接口,\r\n现在已经被更现代化的命令行框架PowerShell替代。bash 则是 GNU\r\n项目的一部分，当下被广泛应用于Unix系统。\r\nBash (Bourne Again Shell) - 定位：类 Unix 系统（Linux,\r\nmacOS）的事实标准 Shell, 是 Unix-like 世界的通用语言。\r\n\r\n哲学：一切皆文件，一切皆文本流。Bash\r\n的核心优势在于处理纯文本。它通过管道（|）将一个个小而专的命令行工具（grep,\r\nawk, sed\r\n等）组合起来，形成强大的文本处理工作流。它是典型的“胶水语言”，用于粘合不同的程序。\r\n\r\nPowerShell - 定位：Windows\r\n的现代化、面向对象的自动化框架。(目前已实现Windows, Linux 和 macOS\r\n的跨平台)\r\n\r\n哲学：一切皆对象（Object）。这是 PowerShell\r\n与前两者最根本的区别。PowerShell\r\n不在命令之间传递无格式的文本流，而是传递结构化的 .NET\r\n对象。这使得它在进行复杂的系统管理和数据操作时，无需进行繁琐的文本解析，可以直接访问对象的属性和方法，更为精准和强大。\r\n其简单的语法习惯等兼容Unix/Linux Shell\r\n\r\n可执行文件\r\n可执行文件（Executable\r\nFile）是计算机中的一种特殊文件，它包含了一系列可以直接被操作系统加载并由CPU执行的机器指令。简单来说，它是程序的最终形态，可以独立运行，不需要其他辅助工具（如编译器或解释器）的帮助。\r\n\r\n可执行文件是一个描述状态机初始状态的数据结构 (字节序列)\r\n\r\n例如，在 Windows 系统上，你双击打开一个 .exe 文件，在 Linux\r\n系统上，你在终端输入 ls 或\r\n./a.out，你所操作的这些文件都是可执行文件。\r\n生成过程\r\n一个可执行文件是从人类可读的源代码到机器可读的二进制指令的复杂转换过程的终点。这个过程通常包括以下几个关键步骤：\r\n\r\n编写源代码：程序员用 C、C++、Java\r\n等高级语言编写程序代码。\r\n编译（Compilation）：编译器将源代码文件（如 .c\r\n文件）翻译成目标文件（Object\r\nFile），通常是二进制格式。这个阶段会进行语法检查，并将高级代码转换为汇编代码，再转换为机器指令，但此时的指令地址还不是最终地址，且无法独立运行。\r\n链接（Linking）：链接器将一个或多个目标文件，以及程序所需的库文件（如标准库），组合成一个完整的可执行文件。\r\n\r\n","categories":["system"],"tags":["system"]},{"title":"libc","url":"/2024/06/30/system/Old_OS/Libc/","content":"\r\n","categories":["system"],"tags":["system"]},{"title":"操作系统概论","url":"/2024/05/01/system/Old_OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/","content":"操作系统的角色和功能\r\n所谓操作系统, 就是软硬件之间的桥梁,\r\n通过调度硬件资源更好地运行软件\r\n\r\n向上（对软件）：它为应用程序（如微信、Word、游戏等）提供了一个一致的运行平台和接口。\r\n\r\n步骤说明：应用程序不需要知道具体硬件（比如某款特定声卡）的复杂细节，只需要向操作系统发出“播放声音”的请求，操作系统会负责将这个请求翻译给具体的硬件来执行。这极大地简化了软件开发的难度。\r\n\r\n向下（对硬件）：它直接控制和驱动所有硬件设备，如处理器（CPU）、内存、硬盘、键盘、鼠标等。\r\n\r\n步骤说明：操作系统将硬件的复杂物理特性抽象成简单的逻辑功能，例如，它将硬盘上复杂的磁道和扇区抽象成我们易于理解的“文件”和“文件夹”。\r\n\r\n\r\n我们可以将操作系统（Operating System, OS）\r\n理解为现代数字计算机的灵魂和总指挥。它是在计算机硬件（如CPU、内存、硬盘）之上运行的最基础、最核心的系统软件。没有操作系统，我们的电脑就是一堆无法有效工作的金属和塑料。\r\n操作系统核心任务：管理资源与提供服务\r\n资源管理器 (Resource Manager)\r\n计算机的资源是有限的，比如只有一个\r\nCPU（或者有限的核心）、固定大小的内存。当多个程序同时运行时，操作系统必须扮演一个公平且高效的“管家”。\r\n\r\n管理CPU：决定在某个瞬间，哪个程序可以使用处理器。\r\n\r\n目的：通过快速切换，实现宏观上的“多任务同时运行”，避免单个程序独占系统。\r\n\r\n管理内存：为每个程序分配所需的内存空间，并在程序关闭后回收它们，确保程序之间互不干扰。\r\n管理I/O设备：管理键盘输入、屏幕输出、磁盘读写等所有输入/输出操作。\r\n\r\n服务提供者 (Service Provider)\r\n操作系统通过提供一系列基础服务，让用户和应用程序能够方便地使用计算机。\r\n\r\n文件系统管理：提供创建、读取、更新和删除文件（CRUD）的功能。\r\n用户接口：提供与用户交互的方式，可以是图形用户界面（GUI），如\r\nWindows 的桌面和窗口；也可以是命令行界面（CLI）\r\n程序执行：负责将程序加载到内存中并开始运行。\r\n\r\n操作系统上的程序\r\n操作系统是连接软件和硬件的桥梁。因此想要理解操作系统，我们首先需要对操作系统的服务对象\r\n(应用程序) 有更精确和深刻的理解\r\n程序 = 状态机\r\n任何一个C程序，其从开始运行到结束的整个过程，都可以被严格地描述为一个状态机。\r\n&gt;\r\n状态机是拥有严格数学定义的对象。这意味着我们可以用一种精确的、无歧义的方式来描述和分析程序的行为，这种方法也称为形式化方法（Formal\r\nMethods）。\r\n什么是程序的状态 (State)\r\n程序在任何一个瞬间的“快照”就是它的状态。这个快照必须包含所有能决定程序未来行为的信息,\r\n即状态 = [StackFrame, StackFrame, …] + 全局变量\r\n\r\n栈帧（Stack\r\nFrame）：每当一个函数被调用时，系统就会为它在调用栈上创建一个栈帧。这个栈帧里包含了该函数的所有信息，例如：\r\n\r\n函数的参数（Arguments）。\r\n函数内部定义的局部变量（Local Variables）。\r\n程序计数器（Program Counter,\r\nPC）：它指向当前函数中，下一条将要被执行的语句的地址。\r\n返回地址（Return\r\nAddress）：当函数执行完毕后，应该返回到哪里继续执行。\r\n\r\n全局变量（Global\r\nVariables）：它们不属于任何一个函数，在程序的整个生命周期中都存在，因此是状态的一个独立组成部分。\r\n\r\n一个程序在任一时刻的精确状态，由“当前所有全局变量的值”和“整个调用栈（及其所有栈帧）的内容”共同唯一确定。\r\n什么是程序的初始状态\r\n(Initial State)\r\n程序的执行必须有一个明确的起点。这个起点就是初始状态。在程序语言的层面,\r\n可以理解为初始状态 = main 的第一条语句\r\n\r\n全局变量全部为初始值：\r\n\r\n所有全局变量和静态变量都被赋予它们的初始值（如果代码中指定了），或者被默认初始化为零。\r\n\r\n仅有一个 StackFrame(main, argc, argv, PC=0)：\r\n\r\n程序开始执行时，操作系统会调用 main 函数。\r\n此时，调用栈上只有一个为 main 函数创建的栈帧。\r\n这个栈帧里包含了传递给 main 的命令行参数 argc 和 argv。\r\nPC=0 （这里的 0 是一个相对位置）意味着程序计数器指向 main\r\n函数内部的第一条可执行语句。\r\n\r\n\r\n总的来说, 程序的初始状态是：所有全局变量初始化完毕，且调用栈上仅有\r\nmain 函数的栈帧，执行点位于 main 的开头。\r\n什么是状态迁移 (State\r\nTransition)\r\n状态机模型的核心在于状态如何从一个变为另一个，这就是状态迁移。\r\n总的来说, 状态迁移 = 执行 frames[-1].PC 处的简单语句\r\n, 这里的 frames[-1]\r\n指的是调用栈顶部的那个栈帧（也就是当前正在执行的函数）。.PC\r\n则是该函数内的程序计数器。\r\n状态迁移由执行一条最基本的、不可再分的指令触发。\r\n每执行这样一条指令，程序的状态就会发生一次微小的、确定的变化。例如：\r\n\r\n赋值操作：x = 10; 这条语句会改变变量 x\r\n的值，导致程序状态发生变化。\r\n函数调用：foo(); 这会导致一个新的栈帧（为 foo\r\n函数）被压入调用栈的顶部，PC会跳转到 foo\r\n函数的起始位置。这显然是一个状态迁移。\r\n函数返回：return;\r\n这会导致顶部的栈帧被弹出，PC恢复到调用该函数之前的位置。这也是一个状态迁移。\r\n控制流：if-else 或循环语句会根据条件改变 PC\r\n的值，从而改变下一条要执行的指令，引发状态迁移。\r\n\r\n程序通过一条条地执行简单指令，不断地从一个状态转移到下一个状态。整个程序的执行过程，就是一条从“初始状态”出发，经过一系列“状态迁移”而形成的轨迹。\r\n\r\n这个模型是调试器（Debugger）、编译器优化（Compiler\r\nOptimization）和程序形式化验证（Formal\r\nVerification）等技术的理论基础。调试器之所以能让你“单步执行”或“设置断点”，本质上就是因为它能暂停程序的状态迁移，并让你检查当前的状态（变量值、调用栈等）。\r\n\r\n如何改变外部状态\r\n我们之前讨论过，一个C程序可以被看作一个严谨的状态机。这个模型的“状态”由变量值和调用栈构成，而“状态迁移”由执行一条条简单的语句驱动。\r\n使用这个状态机模型，我们可以实现任何纯粹的计算（Pure\r\nComputation）。\r\n\n    什么是纯粹的计算 \n    \n      它指的是所有操作都局限在程序内部状态中的计算。它读取程序内存中的数据，处理后，再写回程序内存中。整个过程是自包含的，与外界隔离。例如：\r\n\r\nstrlen(s)：读取内存中字符串 s\r\n的数据，计算其长度，返回一个数字。整个过程只涉及内存读取。\r\nmemcpy(dest, src, n)：从内存地址 src 复制 n 个字节到内存地址\r\ndest。整个过程只是在程序自己的内存空间里移动数据。\r\nsprintf(buf, “%d”, 123)：将数字 123\r\n格式化成字符串，然后写入到程序提供的内存缓冲区 buf 中。\r\n\r\n这些函数的所有行为，都可以用我们之前讨论的状态机模型完美描述。它们的执行只会改变程序内部的变量和内存，不会对计算机的其他部分产生任何直接影响。\r\n\n    \n  \r\n然而, 仅靠程序无法实现的是改变“程序外的状态”, 例如:\r\n- 显示器上显示的内容 - 硬盘上的文件。 - 网络连接的状态。 -\r\n键盘、鼠标的输入。 - 程序自身的生与死（由操作系统管理）。\r\n当你在程序中输入putchar(‘A’), 这个函数的目的不是在内存里写入字符\r\n‘A’，而是要让 ‘A’\r\n这个字符出现在屏幕上。屏幕是程序外部的物理设备，它的显示内容就是一种“程序外的状态”。\r\n同理, 当我们键入exit(0)时,\r\n这个函数要终止程序自身的运行。一个程序如何“杀死”自己？这涉及到操作系统对进程的管理，这同样是“程序外的状态”。\r\n系统调用 (System Call)\r\n为什么程序不能直接操作外部世界？因为这是极其危险的。如果任何程序都能随意写硬盘、控制屏幕，整个系统将陷入混乱且毫无安全可言。\r\n因此，操作系统在程序（用户空间 User Space）和系统资源/硬件（内核空间\r\nKernel\r\nSpace）之间建立了一道不可逾越的屏障。程序运行在受限的“用户模式”下，而操作系统内核运行在拥有最高权限的“内核模式”下。\r\n当一个程序需要执行像“在屏幕上显示字符”这样超出“纯粹计算”范畴的操作时，它不能直接去做，而是必须向操作系统请求服务。这个请求服务的机制，就是系统调用。其基本过程如下：\r\n\r\n调用库函数：当我们在C代码调用\r\nputchar(‘A’)。这实际上是调用了C标准库（libc）中的一个函数。\r\n准备系统调用：putchar\r\n这个库函数会将要执行的操作（例如，在Linux上是 write\r\n系统调用）的编号和参数（要写入的字符’A’、目标是标准输出等）准备好，存放在CPU的特定寄存器中。\r\n触发陷阱（Trap）：库函数执行一条特殊的机器指令（例如在\r\nx86-64 上是 syscall，在 RISC-V 上是\r\necall）。这条指令会使CPU产生一个“陷阱”，中断当前程序的执行。\r\n切换到内核模式：CPU响应陷阱，立即将运行模式从用户模式切换到内核模式，并将控制权交给操作系统预先设定的一个“系统调用处理程序”。\r\n内核执行操作：操作系统内核根据程序放在寄存器里的请求编号和参数，得知程序想要“在标准输出写入字符’A’”。内核会验证这个请求的合法性，然后代替程序去执行这个操作，例如调用显卡驱动程序，最终将字符’A’显示在屏幕上。这是真正改变“程序外状态”的一步。\r\n返回用户模式：内核完成操作后，会将结果（如果有的话）放回寄存器，并将CPU切换回用户模式，控制权交还给程序中触发\r\nsyscall\r\n指令之后的位置。程序继续执行，就好像什么都没发生一样，但屏幕上已经多了一个’A’。\r\n\r\n\r\n像 putchar, exit, fopen, read, write\r\n这些看似普通的标准库函数，其内部都封装了复杂的系统调用过程，它们是程序向操作系统请求服务的用户友好接口。\r\n\r\nstrace (system call trace)\r\nstrace (system call\r\ntrace)，即系统调用跟踪。它能够跟踪一个进程执行时所进行的所有系统调用（system\r\ncalls）以及这些调用的参数、返回值和执行时间。\r\n使用示例\r\nstrace 的基本用法非常简单，你可以在想要追踪的命令前加上\r\nstrace。例如对下列的C程序代码:\r\n// test_write.c#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;int main() {    int fd;    const char *data = \"Hello, strace!\\n\";    // 打开文件    fd = open(\"output.txt\", O_CREAT | O_WRONLY | O_TRUNC, 0644);    if (fd == -1) {        perror(\"open\");        return 1;    }    // 写入数据    if (write(fd, data, strlen(data)) == -1) {        perror(\"write\");        close(fd);        return 1;    }    // 关闭文件    if (close(fd) == -1) {        perror(\"close\");        return 1;    }    printf(\"Data written to output.txt\\n\");    return 0;}\r\n采取下列命令编译并执行 gcc test_write.c -o test_writestrace ./test_write\r\n终端的输出结果如下 ...openat(AT_FDCWD, \"output.txt\", O_WRONLY|O_CREAT|O_TRUNC, 0644) = 3fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0write(3, \"Hello, strace!\\n\", 15) = 15close(3) = 0...\r\n\r\nopenat(…) = 3：程序调用 openat 系统调用打开名为 output.txt\r\n的文件。参数 O_WRONLY|O_CREAT|O_TRUNC\r\n表示以只写、创建（如果不存在则创建）和截断（如果文件已存在则清空其内容）模式打开。返回值\r\n3 是文件描述符。\r\nwrite(3, “Hello, strace!”, 15) = 15：程序调用 write\r\n系统调用向文件描述符 3（即 output.txt）写入 Hello, strace!这段数据，共\r\n15 个字节。返回 15 表示成功写入了 15 个字节。\r\nclose(3) = 0：程序调用 close 系统调用关闭文件描述符 3。返回 0\r\n表示成功关闭。\r\n\r\n通过这些输出，我们可以清晰地看到程序如何与文件系统进行交互，从而验证它的行为是否符合预期。\r\n\n    观测程序运行的常用手段 \n    \n      调试器\r\n(Debugger)：通常用于单步执行程序，设置断点，检查变量值，并修改程序执行流程。\r\n-\r\n提供微观、精确的控制和观测，适合深入分析特定代码段的逻辑错误或运行时行为。它关注的是“程序在某个点上，状态是什么样的？”。\r\nTrace (跟踪工具，例如\r\nstrace)：记录程序执行过程中的特定事件或交互，如系统调用、函数调用、消息传递等。\r\n\r\n提供宏观、连续的执行流视图，帮助我们理解程序的行为序列。strace特别关注程序与操作系统之间的交互，揭示了“程序做了什么系统操作？”以及“这些操作的顺序和结果如何？”。\r\n\r\nProfiler\r\n(剖析器/性能分析器)：测量程序的性能指标，如函数执行时间、CPU使用率、内存占用、缓存命中率等。\r\n\r\n提供性能优化所需的洞察。它关注的是“程序在哪里消耗了最多的资源？”或“哪个部分是性能瓶颈？”。\r\n\r\n\n    \n  \r\n理解操作系统上的应用程序\r\n作为用户, 我们是感受不到操作系统的,\r\n我们只能感受到操作系统上运行的程序(进程)\r\n但是总的来看, 应用程序 = 计算 + 操作系统 API.\r\n应用程序的魔法在于，它将操作系统提供的简单、原始的API，通过大量的计算和逻辑，组合、封装、抽象成了我们所见的复杂功能。\r\n下面是一个程序的生命周期 : 1. 诞生：由 execve 设置初始状态\r\n- 程序不会凭空开始运行。它总是由一个已存在的进程（例如，你正在使用的命令行 shell 或者桌面环境的图标点击处理器）通过执行 execve 这个系统调用来加载和启动。\r\n\r\n- execve 是一个核心的系统调用，它会加载新的程序代码到内存中，清空旧的进程数据，并设置好新程序的初始状态（例如，初始化CPU寄存器，设置程序计数器PC指向入口点），准备开始执行。\r\n\r\n运行：计算 + 系统调用 (Syscalls)\r\n\r\n一旦开始，程序的整个生命就是一部状态机执行的历史。这个过程只由两类活动构成：\r\n\r\n计算\r\n(Computation)：在程序内部进行的数据处理、逻辑判断等，这部分只会改变程序内部的状态。\r\n系统调用\r\n(Syscalls)：当程序需要与外部世界交互时，它必须通过系统调用向操作系统请求服务。\r\n\r\n\r\n\r\n\r\n常见的系统调用如下: 进程管理: fork (创建新进程), execve (执行新程序),\r\nexit (终止进程)。 文件/设备管理: open, close, read, write\r\n(对文件或设备进行读写，在Linux中“一切皆文件”，屏幕、键盘等设备也是通过这些API操作的)。\r\n存储管理: mmap (内存映射，一种高效的文件I/O和进程间共享内存的方式), brk\r\n(调整程序数据段的大小以分配/释放内存)。\r\n\r\n\r\n终结：调用 _exit 退出\r\n\r\n程序的生命最终会通过调用 _exit (在Linux中通常是 exit_group\r\n这个系统调用)\r\n来结束。这个调用会通知操作系统回收该程序占用的所有资源（内存、文件句柄等）。\r\n\r\n\r\n程序与操作系统的分层生态系统\r\n层次一：能直接看到的程序\r\n(Applications)\r\n这类程序是我们作为用户最熟悉的，它们是我们为了完成特定任务而主动打开并直接与之交互的软件。\r\n它们是操作系统“提供舒适抽象API”的最终消费者,\r\n可以全面地利用操作系统提供的各种API（系统调用）来实现丰富的功能，将底层的复杂性转换成用户友好的图形界面或功能。\r\n例如开发工具Vscode, 作为集成开发环境，它需要频繁地进行文件操作（open,\r\nread, write 来读写代码文件）、进程管理（调用 gcc 或 clang 等编译器，需要\r\nfork 和 execve）、以及网络功能（下载插件和更新，需要 socket API）。\r\n再比如日用软件Chrome浏览器是功能集大成者。它既是网络客户端（大量网络API），又是文件管理器（下载/上传），还是一个多媒体播放器（音频/视频API），甚至是一个程序平台（运行JavaScript和WebAssembly），其背后是成千上万次的系统调用。\r\n层次二：能直接看到的(幕后)程序\r\n(Utilities)\r\n这类程序通常没有华丽的图形界面，它们是开发者和系统管理员用来管理和操作系统的工具。普通用户可能不常接触，但它们是系统的基石。\r\n如果说Applications是OS服务的消费者，那么Utilities更像是直接操作OS所提供抽象的“钳子和扳手”。它们的功能与系统调用往往有更直接的对应关系。\r\nCore Utilities(coreutils) 例如GNU Coreutils,\r\nbusybox和toybox等, 它们提供了最基础的命令如 ls, cp, rm。ls 的核心是调用\r\nreaddir 来读取目录内容；cp 的核心是 read 一个文件再 write\r\n到另一个文件。它们是系统调用的“浅层封装”。\r\n系统/工具程序如Shell(bash)\r\n是命令行的“心脏”。它的核心循环就是：读取用户输入，然后通过 fork\r\n创建一个子进程，再通过 execve 在子进程中执行用户指定的命令（如 ls 或\r\nchrome）。它是操作系统的进程管理器的最直接用户界面。\r\n层次三：不能直接看到的后台程序\r\n(Daemons)\r\n这类程序在系统启动时就会自动运行，它们没有用户界面，默默地在后台工作，为整个系统提供关键服务。它们被称为守护进程\r\n(Daemon)。\r\n守护进程是操作系统功能的延伸和实现者。它们本身也是运行在用户空间的进程，但它们负责管理系统资源，并为上层的Applications和Utilities提供服务，是操作系统内核与用户应用程序之间的重要中间层。\r\n“守护进程” systemd: 在现代Linux系统中，systemd\r\n是1号进程，是所有用户空间进程的“始祖”。它负责启动和管理所有其他的守护进程，是系统服务的大管家。\r\n系统管理 (cron, udisksd): cron\r\n是定时任务守护进程，它使用定时器相关的系统调用来在特定时间唤醒并执行任务。udisksd\r\n监控硬件事件，当你插入U盘时，它会收到内核通知，并自动执行 mount\r\n等系统调用来挂载U盘。\r\n各类服务 (httpd, sshd): httpd (Apache) 和 sshd (SSH服务)\r\n是网络服务的提供者。它们在后台监听特定的网络端口 (bind,\r\nlisten)，等待客户端连接\r\n(accept)，为连接进来的用户提供Web或远程登录服务。\r\n总结：一个分层的生态系统\r\n这三类程序与操作系统的关系构成了一个清晰的层次结构：\r\n操作系统内核\r\n(Kernel)：提供最核心、最底层的服务和抽象（进程、文件、网络、内存管理等），通过系统调用作为API。\r\n守护进程\r\n(Daemons)：作为内核的延伸，在后台运行，管理系统资源，并为上层提供更高级、更方便的服务（如窗口管理、音频管理、定时任务）。\r\n实用工具\r\n(Utilities)：作为专业的“工具箱”，让高级用户和开发者能够直接、高效地操作和管理系统。\r\n应用程序\r\n(Applications)：作为生态系统的顶层，消费下面所有层提供的服务和抽象，专注于为用户提供完成特定任务的功能和体验。\r\n从本质上讲，它们全都是操作系统眼中的“进程”，都遵循着计算 +\r\n系统调用的模型。它们的区别在于其设计目的、运行方式以及在整个生态系统中所扮演的角色。\r\n操作系统上的最小程序\r\nminimal.S\r\nminimal.S 指的是一个最小化的汇编语言程序（.S\r\n是汇编文件的常见扩展名）。它的目标是剥离所有C语言、标准库等上层封装，只保留一个程序能够运行所需的最核心、最基本的元素，从而让我们能清晰地看到程序是如何启动、执行和退出的。\r\n认识 minimal.S\r\n在C语言中，我们写的第一个函数通常是 main。但 main\r\n并非程序的真正入口。在 main 函数执行前，C运行时库（C Runtime\r\nLibrary）已经做了大量的准备工作，比如设置堆栈、初始化全局变量等。\r\n为了获得最彻底的控制权，我们需要直接从操作系统交给我们的那个最原始的入口点,\r\n即一个名为 _start 的函数开始。\r\n然而，如果我们天真地写一个C函数 void _start() { … }\r\n并试图编译链接，程序很可能会因为 段错误（Segmentation Fault）\r\n而崩溃。这是因为C函数会默认自己拥有一个合法的、设置好的堆栈（Stack），但在这个最原始的入口点，堆栈环境可能并未完全准备好满足C语言的需求。\r\n因此，要编写这个最小的程序，我们必须使用比C更底层的汇编语言，这样才能完全、精确地控制每一条指令和每一个寄存器。这就是\r\nminimal.S 的由来。\r\nminimal.S\r\n如何工作：一个二进制状态机\r\n\r\n初始状态 (Initial State)\r\n\r\n由ABI规定：当操作系统通过 execve 加载我们的程序后，在跳转到\r\n_start\r\n之前，它会为我们的程序准备好一个“初始状态”。这个状态必须遵循应用二进制接口（Application\r\nBinary Interface, ABI） 的规范。\r\n关键初始状态：最重要的就是操作系统必须提供一个合法的、指向可用内存的栈指针寄存器\r\nsp。没有这个，几乎任何函数调用都会失败。\r\n\r\n入口点与状态迁移 (Entry Point &amp; State Transition)\r\n\r\n我们的 minimal.S 的代码就从 _start\r\n这个标签开始。我们要做的最简单、但又能证明程序成功运行的事，就是“正常退出”。\r\n然而, 根据上面介绍的程序知识, 程序自己是不能“停下来”的,\r\nCPU指令集中没有“停止”或“退出”指令。程序必须向操作系统发出请求，让操作系统来终结自己。这个请求就是通过系统调用（syscall,\r\n在RISC-V中为ecall） 来完成的。\r\n\r\nsyscall: 终极状态交接\r\n\r\n当程序执行 syscall\r\n指令时，它就完全放弃了控制权。CPU会立即陷入内核模式，程序的执行被暂停，操作系统的代码开始运行。\r\n操作系统接管：操作系统内核会检查 a7 寄存器的值，发现是\r\n93，就知道程序请求 exit。然后它会检查 a0 的值，知道退出码是 0。\r\n最终操作：操作系统收到请求后，执行所有清理工作（回收内存、关闭文件等），然后将这个进程彻底销毁。我们的程序，这个“状态机”，就此终结。\r\n\r\n\r\n一个在RISC-V Linux下的 minimal.S 文件内容如下： void _start() {    __asm__(        \"li a7, 93\\n\\t\"   // syscall/ecall: exit         \"li a0, 0\\n\\t\"    // status: 0        \"ecall\"    );}// 编译命令: // gcc -nostdlib -Os -o minimal minimal.c &gt; 在\r\nGCC 和 Clang 等常见的 C 编译器中，使用 asm 或 asm\r\n关键字来告诉编译器：“接下来的内容不是 C\r\n代码，请直接将其作为汇编指令处理”。这是一种在 C\r\n语言代码中直接嵌入汇编代码的语法，称为 内联汇编 (Inline Assembly)。\r\n硬件视角下的操作系统\r\nCPU = 状态机\r\n对 CPU\r\n而言，它只是一个忠实而无情的状态机，其毕生的使命就是不断重复一个简单的循环：根据程序计数器（PC,\r\nProgram Counter）寄存器的地址，从内存中取出一条指令，然后执行它。\r\n\r\n状态 (State)\r\n\r\n\r\n计算机在任何一个瞬间的“快照”就是它的状态。这个状态由所有存储单元中的数值共同定义，最核心的就是内存和\r\nCPU 内部所有寄存器的值。\r\n改变任何一个寄存器或内存单元的值，计算机的状态就发生了改变。\r\n\r\n\r\n初始状态 (Initial State)\r\n\r\n\r\n系统必须有一个确定的起点。这个起点由系统设计者规定，通常是通过\r\nCPU Reset（复位） 实现的。\r\n当你按下电脑的电源键或重启按钮时，硬件电路会将 CPU\r\n的所有寄存器（包括程序计数器 PC）设置为一个预先规定好的初始值。\r\n\r\n\r\n状态迁移 (State Transition)\r\n\r\n\r\n计算机的状态变化由执行指令、响应中断和输入输出三种方式实现\r\n执行指令：CPU 根据 PC\r\n寄存器的指向，从内存中取出指令并执行。执行这条指令的过程，就会改变寄存器或内存的值，从而完成一次状态迁移，进入下一个状态。\r\n\r\n在单处理器系统中，状态迁移是线性、串行的。CPU\r\n严格按照程序计数器（PC）的指引，一条一条地执行指令。\r\n在多处理器系统中,\r\n操作系统内核（作为运行在内核模式下的特权程序）负责调度，它决定在哪个时间点，在哪个处理器核心上，运行哪个进程（或线程）的哪部分指令。而对于多核的单个处理器,\r\n，它的工作模式并没有改变，依然是那个“无情的指令执行机”。\r\n\r\n响应中断 (Responding to Interrupts)：强制的控制权转移,\r\n可以理解为if (intr) goto vec;\r\n\r\nif (intr)：这部分代表硬件在每执行完一条指令后，都会去检查一个名为\r\nintr (interrupt)\r\n的物理信号线。如果某个硬件设备（如定时器、硬盘、网卡）完成了任务或需要关注，它就会在这条线上发出一个信号。\r\ngoto vec;：如果硬件检测到了中断信号，它会立即打断当前正常的执行流程（即不再去执行\r\nPC 指向的下一条指令），转而执行一个特殊的跳转。vec 指的是中断向量表\r\n(Interrupt Vector\r\nTable)。硬件会根据中断信号的类型，从这个表的特定位置取出一个地址，然后强制将这个地址加载到\r\nPC 寄存器中。\r\n最终的实现效果是, 无论当前正在运行什么程序，只要中断发生，CPU\r\n的控制权必然、强制性地被硬件移交给操作系统。\r\n\r\n输入输出 (Input/Output)：与外部世界的交互. I/O\r\n是计算机与外部世界（如用户、网络、存储设备）交换数据的过程，也是触发中断和系统调用的主要原因。\r\n\r\n应用程序想要读一个文件（访问“外部”的硬盘）,\r\n但是它不能直接向硬盘控制器发命令，于是执行一条\r\nsyscall（系统调用）指令，陷入（Trap）到内核。\r\n硬件检测到这是一条特权指令，于是像响应中断一样，将控制权移交给操作系统。\r\n操作系统在内核模式下，向硬盘控制器发出“读数据”的命令，然后可能会让该应用程序暂停（等待），并调度另一个程序运行。\r\n当硬盘准备好数据后，它会通过硬件发出一个中断信号。\r\n硬件再次捕获这个中断，将控制权交给操作系统的中断处理程序。\r\n操作系统从硬盘控制器读取数据，然后将数据交给等待的应用程序，并将其重新置为就绪状态，等待下一次被调度运行。\r\n\r\n\r\n操作系统：一个掌握特权的“普通程序”\r\n既然 CPU\r\n对所有指令一视同仁，那么操作系统是如何实现管理的呢？为什么它能凌驾于普通应用程序之上？\r\n答案是：操作系统本身就是一个普通的（二进制）程序，但它通过巧妙地利用硬件提供的特权机制和中断机制，实现了对整个系统的管理。\r\n理解特权\r\n现代 CPU 硬件通常包含至少两种操作模式（或称特权级）：\r\n\r\n内核模式 (Kernel\r\nMode)：拥有最高权限，可以执行所有指令，访问所有内存和硬件设备。\r\n用户模式 (User Mode)：权限受限，不能执行某些特权指令（如直接操作\r\nI/O 设备、修改页表等），只能访问分配给它的部分内存。\r\n\r\n操作系统内核的代码运行在内核模式下，而普通的应用程序运行在用户模式下。这道由硬件划分的鸿沟，是系统安全和稳定的基石。\r\n中断与陷阱：夺取控制权的关键\r\n这是整个机制中最核心、最巧妙的部分。操作系统通过“接管”中断，实现了对所有关键事件的控制。\r\n当一个事件发生时——无论是硬件发出的信号（如磁盘读写完成、网络包到达，这叫中断），还是应用程序请求服务（如读文件、创建进程，这需要执行一条特殊的“陷阱”指令\r\nsyscall，也叫陷阱或软中断）——CPU\r\n会硬件级别地、自动地停下当前的工作。\r\n此时CPU 会自动保存当前程序的执行上下文（比如 PC\r\n寄存器和一些关键寄存器的值），然后跳转到一个预先设定好的内存地址去执行新的指令。这个预设的地址表被称为中断向量表\r\n(Interrupt Vector Table)。\r\n\r\n操作系统在启动时，就会去修改这个中断向量表，把里面所有的地址都设置为指向它自己的代码——即各种中断处理程序。\r\n\r\n因此可以认为, 一旦启动后，操作系统就变成了一个中断处理程序。\r\n当应用程序需要访问 I/O\r\n设备时，它不能直接访问（因为处于用户模式，没有权限），只能通过 syscall\r\n指令请求操作系统。这个指令会触发一次陷阱，CPU\r\n自动跳转到操作系统的代码。操作系统在内核模式下代为完成 I/O\r\n操作，完成后再把控制权交还给应用程序。\r\n当中断发生时（比如用户敲击键盘），CPU\r\n也会立刻跳转到操作系统的中断处理程序，让操作系统决定如何响应。\r\n操作系统 = 状态机的管理者\r\n如果每个进程都是一个状态机，那么操作系统的角色就是这些状态机的管理者\r\n(Manager) 或调度器 (Scheduler)。它负责以下核心任务：\r\n\r\n状态机的创建与销毁 (Creation &amp;\r\nDestruction)\r\n\r\n创建 (spawn 或 fork):\r\n当一个进程请求创建另一个新进程时，操作系统负责为这个新的状态机分配资源（如内存空间、进程控制块PCB），并将其设置到一个可运行的初始状态。\r\n销毁 (exit):\r\n当一个进程执行完毕或被终止时，操作系统负责回收它占用的所有资源，彻底移除这个状态机。\r\n\r\n状态机的调度 (Scheduling)\r\n\r\n这是管理的核心。现代操作系统可以同时“容纳”多个程序状态机（即多任务）。但通常情况下，一个CPU核心在同一时刻只能执行一个状态机的一步。\r\n“选一个程序执行一步”: 操作系统的调度器 (Scheduler)\r\n的核心职责就是从所有处于“就绪”状态的状态机中，选择一个，让它在CPU上运行一小段时间（称为“时间片”）。\r\n上下文切换 (Context Switch):\r\n当一个进程的时间片用完，或者它因等待I/O而需要暂停时，操作系统会介入：\r\n\r\n保存现场：将当前进程的完整状态（PC、寄存器、内存状态等）保存下来。\r\n恢复现场：选择下一个要运行的进程，并将其之前保存的状态加载到CPU和内存中。\r\n继续执行：让新的进程从它上次暂停的地方继续执行。\r\n\r\n这个“保存-恢复”的过程就是上下文切换，它使得多个状态机看起来像是在同时运行，即并发\r\n(Concurrency)。\r\n\r\n响应状态迁移的请求 (Handling System Calls)\r\n\r\n当一个状态机（进程）执行系统调用时，它实际上是在向管理者（操作系统）发出一个请求。操作系统会接管控制权，执行相应的服务。\r\n例如，当进程调用 read():\r\n\r\n进程的状态从“运行”迁移到“阻塞”（等待I/O）。\r\n操作系统执行实际的硬件读取操作。\r\n当数据准备好后，操作系统将数据交给进程，并将其状态从“阻塞”改回“就绪”，等待下一次被调度器选中。\r\n\r\n\r\n资源分配与隔离 (Resource Allocation &amp;\r\nIsolation)\r\n作为管理者，操作系统必须确保各个状态机之间不会相互干扰，防止一个行为不当的进程搞垮整个系统。\r\n内存隔离：通过虚拟内存技术，操作系统为每个进程提供一个独立的、私有的地址空间。一个进程无法直接访问另一个进程的内存。\r\n权限控制：操作系统控制着对文件、设备等所有共享资源的访问权限。\r\n\r\n固件:\r\n硬件和操作系统之间的桥梁\r\n在我们之前的讨论中，我们已经明确： - CPU 是一个只会从内存指定地址（由\r\nPC 寄存器指向）取指令并执行的“无情机器”。\r\n\r\n操作系统是一个特殊的程序，它通过中断和特权级管理整个系统。\r\n\r\n这里就引出了一个关键的“鸡生蛋还是蛋生鸡”的问题：当计算机刚通电，CPU\r\n复位（Reset）后，它的 PC\r\n寄存器指向的那个初始地址，里面的代码究竟是什么？是谁在一切开始之前就把代码放在了那里？答案就是固件\r\n(Firmware)。\r\n什么是固件\r\n固件，顾名思义，就是被“固化”在硬件里的软件。它是系统厂商“固定”在计算机系统里的代码。它不存储在易失性的主内存（RAM）中，也不是存储在硬盘上，而是存在于主板上的一个特殊的非易失性存储芯片里。\r\n早期固件通常被烧录在 ROM (Read-Only Memory)\r\n芯片里。这意味着一旦出厂就无法更改。想要升级唯一的办法就是物理更换芯片。\r\n而现在普遍使用 Flash\r\nMemory（闪存）。这使得我们可以通过软件更新的方式来升级固件（例如，刷新主板的\r\nBIOS/UEFI），大大增加了灵活性。\r\n硬件电路的设计保证了，当 CPU 加电复位时，其 PC\r\n寄存器会被强制设置为一个固定的内存地址，而这个地址正好被内存映射\r\n(memory-map) 到存放固件的那个芯片上。\r\n因此，CPU\r\n执行的第一条指令必然来自固件。这就意味着，固件“‘出生’就有机器完整的控制权”，它是计算机世界里第一个“发号施令”的角色。\r\n固件的核心功能\r\n固件是连接纯硬件和操作系统的桥梁，它的使命主要分为两个阶段：\r\n\r\n硬件初始化与自检 (POST)\r\n\r\n\r\n在操作系统这个庞大的软件开始运行之前，必须确保硬件本身处于一个健康、可用的状态。这正是固件的首要任务。这个过程通常被称为\r\nPOST (Power-On Self-Test)，即开机自检。\r\n具体工作：检查 CPU 类型和速度; 检测内存条大小、频率并进行测试;\r\n配置 CPU 电压、内存时序等关键参数;\r\n检测并初始化显卡、硬盘、键盘等外围设备; 根据用户在 BIOS/UEFI\r\n设置界面中的配置，打开或关闭某些接口等。\r\n我们平常打开计算机进入的蓝色的 BIOS(Basic I/O\r\nSystem)或者更先进的UEFI (Unified Extensible Firmware Interface)\r\n设置界面，就是固件提供给我们的一个用户交互接口。\r\n\r\n\r\n引导加载操作系统 (Bootstrapping)\r\n\r\n\r\n当硬件检查和配置完毕后，固件的下一个任务，就是找到并启动操作系统。具体流程如下:\r\n\r\n固件根据用户设定的启动顺序（如：USB -&gt; SSD -&gt;\r\nHDD）去扫描这些存储设备。\r\n它会在设备的特定位置（如硬盘的 MBR 或 GPT 分区的 EFI\r\n文件）寻找一个非常小的程序，这个程序叫做引导加载程序\r\n(Bootloader)。\r\n固件将这个 Bootloader 加载到内存（RAM）中，然后将 CPU\r\n的控制权移交给它。\r\n至此，固件的使命就完成了。接下来，由 Bootloader\r\n负责找到完整的操作系统内核（例如 Windows 的 ntoskrnl.exe 或 Linux 的\r\nvmlinuz），将其加载到内存，最后再把控制权交给操作系统内核。\r\n\r\n\r\n","categories":["system"],"tags":["system"]},{"title":"程序和进程","url":"/2024/06/30/system/Old_OS/%E7%A8%8B%E5%BA%8F%E5%92%8C%E8%BF%9B%E7%A8%8B/","content":"fork(): 创建新进程的“克隆”技术\r\nfork() 是一个在类-UNIX 操作系统（如 Linux,\r\nmacOS）中使用的系统调用，其唯一的功能就是创建一个新的进程。\r\n这个新创建的进程被称为“子进程”（Child Process），而调用 fork()\r\n的那个进程则被称为“父进程”（Parent Process）。\r\n整个过程类似细胞分裂, 当调用 fork()\r\n时，操作系统会拿父进程作为“模板”，几乎原封不动地“克隆”出一个一模一样的副本，这个副本就是子进程。\r\nfork() 的工作机制\r\n当 fork()\r\n被调用时，子进程会获得父进程在调用那一刻的几乎所有资源的副本。\r\n\r\n内存空间：子进程会得到父进程整个虚拟地址空间的精确副本，包括代码段、数据段、堆和栈。这意味着父进程中的所有变量和数据，在\r\nfork() 的瞬间，子进程也有一份一模一样的。\r\n程序计数器（Program\r\nCounter）：子进程的程序计数器被设置为与父进程相同的值。它意味着子进程和父进程一样将从\r\nfork()\r\n调用返回之后的那条指令开始执行，而不是从程序的开头。\r\n文件描述符：父进程打开的所有文件描述符都会被复制到子进程中。如果父进程打开了一个文件，那么子进程也同样“持有”这个打开的文件。它们共享同一个文件表项，这意味着它们对文件的读写指针是同步的。\r\n其他资源：还包括用户和组ID、环境变量、工作目录、I/O\r\n缓冲区等。\r\n\r\n尽管是克隆，但父子进程并非100%相同，它们有各自独立的属性：\r\n\r\n进程ID\r\n(PID)：每个进程在系统中都有一个唯一的ID。子进程会获得一个新的、不同于父进程的PID。\r\n父进程ID (PPID)：子进程的PPID被设置为其父进程的PID。\r\n资源利用信息：如CPU使用时间等统计信息，子进程会从零开始计算。\r\nfork() 的返回值：这是区分父子进程的最关键机制\r\n\r\nfork() 返回值:\r\n一次调用，两次返回\r\nfork()\r\n最独特的地方在于它被调用一次，却在两个进程（父进程和子进程）中各返回一次。并且，这两次的返回值是不同的，这使得我们的程序能够根据返回值来区分当前代码是在父进程中运行还是在子进程中运行。\r\n\r\n在父进程中：fork() 返回新创建的子进程的PID（一个正整数）。\r\n\r\n原因：父进程需要知道它创建的子进程的ID，以便后续可以管理它（例如，等待它结束）。\r\n\r\n在子进程中：fork() 返回 0。\r\n\r\n原因：子进程可以通过 getppid()\r\n函数轻易地获取其父进程的ID，所以 fork()\r\n返回0就足以让它知道自己是一个子进程。\r\n\r\n如果出错：fork() 会在父进程中返回 -1，并且不会创建子进程。\r\n\r\n原因：通常是因为系统资源不足（如内存耗尽或进程数量达到上限）。\r\n\r\n\r\n下面是一个示例 #include &lt;stdio.h&gt;#include &lt;unistd.h&gt; // 包含 fork(), getpid(), getppid() 的头文件#include &lt;sys/types.h&gt; // 包含 pid_t 类型的头文件int main() {    pid_t pid; // pid_t 是专门用来存储进程ID的数据类型    printf(\"程序开始：我是父进程，我的PID是 %d\\n\", getpid());    // 关键步骤：调用 fork() 创建新进程    pid = fork();    // fork() 之后，这里的代码会被父子两个进程同时执行    // 我们需要通过 pid 的值来区分它们    if (pid &lt; 0) {        // 步骤1：检查 fork 是否失败        // 解释：如果返回值小于0，说明进程创建失败，需要进行错误处理。        fprintf(stderr, \"Fork 失败\\n\");        return 1;    } else if (pid == 0) {        // 步骤2：判断是否为子进程        // 解释：如果返回值为0，那么当前代码在子进程中运行。        printf(\"--- 我是子进程 ---\\n\");        printf(\"我的PID是 %d, 我的父进程PID是 %d\\n\", getpid(), getppid());        // 子进程可以执行独立的任务，例如在这里休眠几秒钟        sleep(2);        printf(\"--- 子进程执行完毕 ---\\n\");    } else {        // 步骤3：判断是否为父进程        // 解释：如果返回值大于0，那么当前代码在父进程中运行，        // 且 pid 变量的值就是刚刚创建的子进程的ID。        printf(\"+++ 我是父进程 +++\\n\");        printf(\"我创建的子进程PID是 %d\\n\", pid);        printf(\"+++ 父进程继续执行任务... +++\\n\");    }    // 这行代码父子进程都会执行，但执行时间点不同    printf(\"fork() 调用之后，我是PID为 %d 的进程\\n\", getpid());    return 0;} 编译并运行后输出如下: 程序开始：我是父进程，我的PID是 54321+++ 我是父进程 +++我创建的子进程PID是 54322+++ 父进程继续执行任务... +++fork() 调用之后，我是PID为 54321 的进程--- 我是子进程 ---我的PID是 54322, 我的父进程PID是 54321fork() 调用之后，我是PID为 54322 的进程--- 子进程执行完毕 --- &gt;\r\n(注意：由于操作系统调度的不确定性，父子进程的输出顺序可能会交错)\r\nfork() 经典示例\r\n下面是一个非常经典的 fork()\r\n习题，它巧妙地结合了进程创建和I/O缓冲区的知识。 #include &lt;stdio.h&gt;#include &lt;unistd.hh&gt;int main() {    for (int i = 0; i &lt; 2; i++) {        fork();        printf(\"Hello\\n\");    }    return 0;}\r\n这个程序的运行结果取决于它的输出是如何被处理的，这直接影响到 printf\r\n的缓冲策略。\r\n\n    当直接在终端执行 (./a.out) 时 \n    \n      \r\n循环开始前: 只有一个进程 (P0)。\r\ni = 0:\r\n\r\nP0 调用 fork()，创建了子进程 P1。现在有 2 个进程 (P0,\r\nP1)。\r\nP0 执行 printf(“Hello”)，打印一次。\r\nP1 执行 printf(“Hello”)，打印一次。\r\n此轮循环结束时，共打印了 2 次 “Hello”。\r\n\r\ni = 1:\r\n\r\n此时，P0 和 P1 两个进程都进入了第二次循环。\r\nP0 调用 fork()，创建了子进程 P2。\r\nP1 调用 fork()，创建了子进程 P3。\r\n现在总共有 4 个进程 (P0, P1, P2, P3)。\r\n这 4 个进程各自执行 printf(“Hello”)，每个打印一次。\r\n此轮循环结束时，又打印了 4 次 “Hello”。\r\n\r\n总计: 2 + 4 = 6 次 “Hello”。\r\n\r\n\n    \n  \r\n\n    如果通过管道执行 (./a.out | cat)时 \n    \n      \r\n循环开始前: 1 个进程 (P0), 且P0 的输出缓冲区是空的。\r\ni = 0:\r\n\r\nP0 调用 fork()，创建子进程 P1。\r\n缓冲区状态: P0 和 P1 的缓冲区都是空的。\r\nP0 执行 printf，“Hello” 被放入 P0 的缓冲区。\r\nP1 执行 printf，“Hello” 被放入 P1 的缓冲区。\r\n此时没有任何内容被打印到屏幕上，它们都在各自进程的内存缓冲区里。\r\n\r\ni = 1:\r\n\r\nP0 继续执行: 它调用 fork()，创建子进程 P2。\r\n\r\n关键: P2 被创建时，它完整地复制了 P0 的内存，因此 P2\r\n的缓冲区初始内容就是 “Hello”。\r\n\r\nP1 继续执行: 它调用 fork()，创建子进程 P3。同样，P3\r\n被创建时，复制了 P1 的内存，P3 的缓冲区初始内容也是 “Hello”。\r\n现在我们有 4 个进程：P0, P1, P2, P3。缓冲区初始状态为:\r\n\r\nP0: “Hello”\r\nP1: “Hello”\r\nP2: “Hello” (继承自 P0)\r\nP3: “Hello” (继承自 P1)\r\n\r\n接下来，这 4 个进程各自执行\r\nprintf(“Hello”)。执行后，缓冲区最终状态:\r\n\r\nP0 缓冲区: “Hello”\r\nP1 缓冲区: “Hello”\r\nP2 缓冲区: “Hello”\r\nP3 缓冲区: “Hello”\r\n\r\n\r\n程序结束:\r\n\r\n所有 4 个进程执行完毕，它们在退出前会冲刷各自的 stdout\r\n缓冲区。\r\n每个进程都将打印出其缓冲区中的两个 “Hello”。\r\n总计: 4 个进程 × 每个进程打印 2 次 = 8 次 “Hello”。\r\n\r\n\r\n\n    \n  \r\n要理解结果的差异，必须先理解 printf 函数的标准输出流 (stdout)\r\n缓冲机制。\r\n\r\n行缓冲 (Line-Buffered):\r\n当输出设备是交互式终端时（即我们直接在命令行运行 ./a.out），stdout\r\n默认为行缓冲。\r\n\r\nprintf 的内容会先暂存到一块内存缓冲区里。当遇到**换行符\r\n*，或者缓冲区满了，或者程序结束时，缓冲区的内容才会被真正“冲刷”（flush）到屏幕上。\r\n对于本题：printf(“Hello”) 中的 会立即触发冲刷，所以每次调用\r\nprintf 都会立刻看到输出。\r\n\r\n全缓冲 (Fully-Buffered): 当输出被重定向到文件或管道时（如 ./a.out\r\n| cat），stdout 会变为全缓冲。\r\n\r\n在这种模式下，只有当缓冲区被写满，或者程序正常结束时，内容才会被冲刷。不再能触发立即冲刷。\r\n对于本题：printf\r\n的内容会一直留在内存缓冲区中，直到进程结束时才被一次性打印出来。这是导致两种结果不同的根本原因。\r\n\r\n\r\n这个问题深刻地揭示了 fork()\r\n的一个核心特性：它创建的是父进程在调用那一刻的“快照”。这个快照不仅包括代码和数据，还包括像\r\nI/O 缓冲区这样的用户态资源。\r\nfork() 的主要用途\r\nexecve() : 一个复位状态机\r\n在操作系统中，我们经常将 fork() 和 execve() 放在一起讨论。\r\n\r\nfork()\r\n是新生：它像细胞分裂一样，从一个父进程完整地克隆出一个新的子进程。这个子进程拥有全新的进程ID（PID），但继承了父进程的全部内存状态。\r\nexecve()\r\n是重生：它不会创建新进程。相反，它会将调用它的那个进程彻底“变身”，用一个全新的程序来完全替换当前进程的内存空间。进程的ID（PID）保持不变，但它内部运行的程序已经焕然一新。\r\n\r\n或者从状态机的视角来看, execve 是一个复位状态机 (Reset State\r\nMachine)。它按下了一个“重置按钮”，将当前进程的“状态”——主要是内存中的内容——重置为目标可执行文件所描述的初始状态。\r\n","categories":["system"],"tags":["system"]},{"title":"链接和加载","url":"/2025/08/22/system/Old_OS/%E9%93%BE%E6%8E%A5%E5%92%8C%E5%8A%A0%E8%BD%BD/","content":"静态链接\r\n静态链接（Static\r\nLinking）是一种在程序编译后的链接阶段，将所有必需的库代码从静态库（Static\r\nLibrary）文件中复制到最终可执行文件中的过程。\r\n其核心思想是“一次性打包”。链接器在生成可执行文件时，会解析程序中所有对外部函数的调用（比如\r\nprintf()），然后从静态库文件中找到对应的函数代码，并将其直接嵌入到可执行文件内部。\r\n这个过程通常发生在编译的最后一步，由链接器（如 ld）完成：\r\n\r\n输入：链接器接收一个或多个由编译器生成的目标文件（Object Files，如\r\n.o 文件），以及程序所依赖的静态库文件（在 Linux 上通常是 .a 格式，在\r\nWindows 上是 .lib 格式）。 &gt; 静态库文件（在 Linux 上通常是 .a 格式，a\r\n代表 archive，意为“档案”或“归档”）本质上就是一系列目标文件（Object\r\nFiles，.o 文件）的归档文件, 保存了多个由编译器生成的 .o 文件，每个 .o\r\n文件都包含了某个函数或一组相关函数的机器码和数据。\r\n符号解析和代码嵌入：链接器会扫描所有目标文件，并解析其中对外部函数和变量的引用（即“符号”）。对于每一个被引用的外部符号，链接器会从静态库中找到对应的代码和数据，并将它们精确地复制到最终的可执行文件中。\r\n生成输出：链接器将所有目标文件中的代码、被引用的库代码以及其他必要的运行时信息（如文件头、数据段等）组合在一起，生成一个完整的、自包含的可执行文件。这个可执行文件在运行时不再需要外部库文件，因为它已经包含了所有必要的代码。\r\n\r\n静态链接的优缺点\r\n优点: -\r\n高度可移植性：由于静态链接后的可执行文件在运行时不再需要外部库文件，你可以轻松地将它复制到任何兼容的系统上运行，而不用担心动态链接时目标系统是否安装了特定的库版本。这解决了“依赖地狱”（Dependency\r\nHell）问题。\r\n\r\n运行时独立性：程序在运行时不需要额外的链接步骤，加载器只需要将整个文件加载到内存即可，这可能带来更快的程序启动速度。\r\n版本锁定：程序使用的库代码版本是固定的，不会因为系统库的更新而出现兼容性问题。这对于需要稳定运行环境的应用程序非常重要。\r\n\r\n缺点: -\r\n体积庞大：由于每个可执行文件都包含了所有必需的库代码，最终生成的文件会非常大。如果多个程序都使用了同一个静态库，那么每个程序都会有一份独立的库代码副本。\r\n\r\n内存浪费：在多进程环境中，如果多个静态链接的程序同时运行，它们会各自在内存中加载同一份库代码，造成内存资源的重复占用。\r\n更新不便：如果使用的某个静态库被发现有安全漏洞或\r\nBug，那么所有使用了这个库的程序都必须重新编译并重新分发，才能获得更新。这对于广泛部署的软件来说是一个巨大的维护负担。\r\n\r\n动态链接\r\n动态链接（Dynamic\r\nLinking）是一种将程序依赖的库代码的链接工作，推迟到程序运行时才进行的链接方式。\r\n其核心思想是“按需加载，共享使用”。程序在编译时并不会把库代码复制进来，而是在可执行文件中只保留对外部库函数的一个引用。当程序启动时，操作系统中的动态加载器（Dynamic\r\nLoader）会负责找到这些外部库文件，将它们加载到内存中，并完成最终的链接工作。\r\n动态链接的流程如下：\r\n\r\n编译器生成目标文件，其中对库函数的调用只是一个符号引用（例如，printf）。\r\n链接器生成最终的可执行文件，但它并不会将库代码嵌入进来。它只会在可执行文件的特定区域（例如，Windows\r\n的 IAT 或 Linux 的\r\nGOT/PLT）记录下程序所依赖的库名称和函数名。此时，可执行文件体积很小，因为它只包含自己的代码和对外部库的“占位符”。\r\n用户启动程序，操作系统将可执行文件加载到内存。此时操作系统的动态加载器接管控制权。它会读取可执行文件中的依赖列表，找到所需的动态库文件（例如，Windows\r\n的 .dll 或 Linux 的 .so）并将这些动态库加载到内存的某个位置。\r\n地址解析：加载器会“修补”可执行文件中的“占位符”，将对库函数的符号引用替换为这些库函数在内存中的实际地址。一旦所有依赖都成功加载和解析，加载器将控制权转交给程序，程序开始正式执行。\r\n\r\n优缺点\r\n优点: -\r\n节省磁盘空间：多个程序可以共享同一个动态库文件。磁盘上只需要存储一份库代码，大大减少了存储空间的占用。\r\n\r\n节省内存：在内存中，动态库的代码段通常只被加载一次。如果有多个程序同时使用同一个动态库，它们会共享这块内存区域，从而显著提高了内存利用率。\r\n便于程序升级与维护：当库文件被修复了 Bug\r\n或进行了安全更新后，开发者只需要替换旧的库文件即可。所有依赖这个库的程序在下次运行时都会自动使用新版本，而不需要重新编译或分发。这解决了“DLL\r\nHell”或“共享库地狱”的部分问题。\r\n模块化开发：大型程序可以被分解为多个动态库，每个库可以由不同的团队独立开发和更新。\r\n\r\n缺点: -\r\n依赖性问题：程序在运行时必须依赖于目标系统上存在特定版本的动态库。如果库文件缺失、版本不兼容或被意外删除，程序将无法启动。\r\n\r\n启动时性能开销：程序启动时，操作系统需要额外花费时间来定位、加载和链接动态库，这会比静态链接的程序有略微的启动延迟。\r\n版本冲突：当一个程序依赖于一个库的旧版本，而另一个程序依赖于这个库的新版本时，可能会发生冲突。\r\n\r\n","categories":["system"],"tags":["system"]},{"title":"RISC-V 的调用约定","url":"/2025/10/08/system/computer-architecture/RISC-V%20%E7%9A%84%E8%B0%83%E7%94%A8%E7%BA%A6%E5%AE%9A/","content":"什么是调用约定\r\n首先，我们需要理解什么是调用约定（Calling\r\nConvention）。它是一套规则，用于规定函数在调用时如何进行交互。这套规则确保了由不同程序员编写、甚至由不同编译器编译的函数能够正确地相互调用。\r\n调用约定通常定义了以下内容：\r\n\r\n参数传递：如何将参数传递给函数（使用寄存器还是栈）。\r\n返回值：函数如何将返回值传回给调用者。\r\n寄存器使用：调用者（Caller）和被调用者（Callee）如何划分和使用寄存器。\r\n栈管理：如何分配和释放栈帧（Stack Frame）。\r\n\r\nRISC-V 标准调用约定 (LP64)\r\nRISC-V\r\n的标准调用约定非常清晰和高效，主要依赖寄存器来传递参数。下面是其核心内容的总结，以标准的\r\n64 位架构（RV64I）为例。\r\n\r\n参数传递 (Argument Passing)\r\n\r\n\r\n整型/指针参数：前 8 个整型或指针参数通过寄存器 a0 到 a7 (x10 -\r\nx17) 传递。\r\n浮点参数：前 8 个浮点参数通过浮点寄存器 fa0 到 fa7\r\n传递。\r\n更多参数：如果参数超过 8\r\n个，多余的参数将从右到左依次压入栈（Stack）中进行传递。\r\n\r\n\r\n返回值 (Return Values)\r\n\r\n\r\n整型/指针返回值：返回值通常放在 a0 (x10) 中。如果返回值需要 128\r\n位（例如一个大的结构体），则高 64 位放在 a1 (x11) 中，低 64 位放在 a0\r\n中。\r\n浮点返回值：同样，浮点返回值使用 fa0 和 fa1。\r\n\r\n\r\n寄存器用途表 RISC-V 共有 32 个通用整型寄存器 (x0 -\r\nx31)，它们在调用约定中扮演着不同的角色。使用 ABI (Application Binary\r\nInterface) 名称可以更容易地记住它们的用途。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n寄存器 (ABI 名称)\r\n寄存器编号\r\n角色\r\n保存策略\r\n描述\r\n\r\n\r\n\r\n\r\nzero\r\nx0\r\n硬编码零\r\n-\r\n始终为 0，不可修改。\r\n\r\n\r\nra\r\nx1\r\n返回地址\r\nCaller-Saved\r\n保存函数调用后的返回地址。由 jal 和 jalr 指令隐式修改。\r\n\r\n\r\nsp\r\nx2\r\n栈指针\r\nCallee-Saved\r\n指向当前栈帧的顶部。\r\n\r\n\r\ngp\r\nx3\r\n全局指针\r\n-\r\n指向全局数据区，由链接器设定。\r\n\r\n\r\ntp\r\nx4\r\n线程指针\r\n-\r\n指向当前线程的私有数据区。\r\n\r\n\r\nt0-t2\r\nx5-x7\r\n临时寄存器\r\nCaller-Saved\r\n用于存放临时数据，函数可以随意使用。\r\n\r\n\r\ns0/fp\r\nx8\r\n保存寄存器/帧指针\r\nCallee-Saved\r\ns0 是被调用者保存寄存器，也可作为帧指针（Frame Pointer）。\r\n\r\n\r\ns1\r\nx9\r\n保存寄存器\r\nCallee-Saved\r\n被调用者保存寄存器。\r\n\r\n\r\na0-a1\r\nx10-x11\r\n函数参数/返回值\r\nCaller-Saved\r\n用于传递前两个参数和返回值。\r\n\r\n\r\na2-a7\r\nx12-x17\r\n函数参数\r\nCaller-Saved\r\n用于传递第 3 到第 8 个参数。\r\n\r\n\r\ns2-s11\r\nx18-x27\r\n保存寄存器\r\nCallee-Saved\r\n被调用者保存寄存器。\r\n\r\n\r\nt3-t6\r\nx28-x31\r\n临时寄存器\r\nCaller-Saved\r\n用于存放临时数据。\r\n\r\n\r\n\r\nCaller-Saved 与\r\nCallee-Saved 寄存器的区别\r\n这是调用约定中关于寄存器管理的核心。这个策略旨在最小化内存访问（保存/恢复寄存器到栈），从而提高性能。\r\n\r\n调用者保存寄存器 (Caller-Saved Registers)\r\n\r\n也称为临时寄存器（Temporary Registers）或易变寄存器（Volatile\r\nRegisters）。这些寄存器可以被被调用函数（Callee）自由地、无条件地修改。\r\n工作流程：\r\n\r\n调用前：如果一个调用者函数（例如 main）在一个 Caller-Saved\r\n寄存器（例如 t0）中存放了一个重要的值，并且希望在被调用函数（例如\r\nfuncA）返回后继续使用这个值。\r\n保存：那么 main 函数必须在执行 call funcA 指令之前，自己负责将 t0\r\n的值保存到栈上。\r\n调用后：funcA 返回后，main 函数再从栈上恢复 t0 的值。\r\n\r\n为什么这么设计？funcA\r\n可以无所顾忌地使用这些寄存器进行计算，而不需要执行任何保存/恢复操作，这使得那些简短的、不需要太多寄存器的叶子函数（leaf\r\nfunction）执行得非常快。例如RISC-V 中的ra, t0-t6, a0-a7等\r\n\r\n被调用者保存寄存器 (Callee-Saved Registers)\r\n\r\n也称为保存寄存器（Saved Registers）或非易变寄存器（Non-Volatile\r\nRegisters）。这些寄存器的值在函数调用前后必须保持不变。\r\n工作流程：\r\n\r\n调用前：调用者函数（main）可以放心地将一个长期有效的值（例如一个循环计数器）存放在一个\r\nCallee-Saved 寄存器（例如 s0）中，然后去调用 funcA。\r\n被调用者内部：如果 funcA 需要使用 s0\r\n寄存器，它必须在函数的开头（prologue）先把 s0\r\n的原始值保存到自己的栈帧中。\r\n返回前：在 funcA 返回之前（epilogue），它必须从栈中恢复 s0\r\n的原始值。\r\n调用后：这样，当 funcA 返回到 main 时，main 可以确信 s0\r\n里的值和调用前一模一样。\r\n\r\n为什么这么设计？调用者可以放心地使用这些寄存器来存储重要的局部变量，而不用在每次函数调用时都去保存和恢复它们，这减少了不必要的内存操作。在RISC-V\r\n中的例子有sp, s0-s11。\r\n","categories":["system"],"tags":["system"]},{"title":"第一章：基础概念","url":"/2025/08/27/system/computer-architecture/chapter1/","content":"第一章：基础概念\r\n这里是计算机体系结构基础概念的内容。\r\n"},{"title":"Linux入门","url":"/2025/06/29/system/linux/linux/","content":"Linux 目录结构\r\n与 Windows 使用多个盘符（C:、D:）不同，Linux\r\n采用单一的树状目录结构。整个文件系统从一个根目录 /\r\n开始，所有其他文件和目录都挂载在这个根目录下。这个结构遵循文件系统层次化标准\r\n(FHS)。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n目录\r\n名称\r\n功能说明\r\n\r\n\r\n\r\n\r\n/\r\nRoot\r\n根目录，整个文件系统的起点，所有目录的父目录。\r\n\r\n\r\n/bin\r\nBinaries\r\n存放所有用户都能使用的基本命令（二进制文件），如 ls, cp, cat。\r\n\r\n\r\n/sbin\r\nSystem Binaries\r\n存放只有系统管理员（root用户）才能使用的系统管理命令，如 reboot,\r\nfdisk。\r\n\r\n\r\n/etc\r\nEtcetera\r\n存放系统和各种程序的配置文件。几乎所有服务的配置都在这里。\r\n\r\n\r\n/home\r\nHome\r\n用户主目录。每个普通用户在这里都有一个自己的文件夹，如\r\n/home/ziyipei。\r\n\r\n\r\n/root\r\nRoot\r\n系统管理员（root用户）的主目录。\r\n\r\n\r\n/dev\r\nDevices\r\n存放设备文件。在 Linux\r\n中，所有硬件设备（如硬盘、键盘）都以文件的形式存在于此。\r\n\r\n\r\n/var\r\nVariable\r\n存放经常变化的文件，如日志文件 (/var/log)、缓存文件\r\n(/var/cache)。\r\n\r\n\r\n/tmp\r\nTemporary\r\n存放临时文件，系统重启后这里的文件通常会被清空。\r\n\r\n\r\n/usr\r\nUnix System Resources\r\n存放用户安装的应用程序、库文件和文档。这是系统中最大的目录之一。\r\n\r\n\r\n/boot\r\nBoot\r\n存放启动 Linux 系统所需的文件，包括 Linux 内核本身和引导加载程序\r\n(GRUB)。\r\n\r\n\r\n/lib\r\nLibraries\r\n存放系统和程序运行所必需的共享库文件。\r\n\r\n\r\n/opt\r\nOptional\r\n用于存放可选的第三方软件包，比如手动安装的商业软件（如 Google\r\nChrome）。\r\n\r\n\r\n/mnt, /media\r\nMount\r\n用于临时挂载外部设备，如 U 盘、移动硬盘、光驱等。\r\n\r\n\r\n\r\n常见命令汇总\r\nLinux 的强大之处在于其命令行界面 (CLI)。命令的基本格式为：command\r\n[options] [arguments]。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n命令\r\n功能说明\r\n示例\r\n\r\n\r\n\r\n\r\nls\r\n列出目录内容\r\nls -l（长格式显示），ls -a（显示隐藏文件）\r\n\r\n\r\ncd\r\n切换目录\r\ncd /home/ziyipei，cd ..（返回上一级）\r\n\r\n\r\npwd\r\n显示当前工作目录的绝对路径\r\npwd\r\n\r\n\r\nmkdir\r\n创建新目录\r\nmkdir documents\r\n\r\n\r\nrm\r\n删除文件或目录\r\nrm file.txt，rm -r directory（递归删除目录）\r\n\r\n\r\ncp\r\n复制文件或目录\r\ncp source.txt destination.txt\r\n\r\n\r\nmv\r\n移动或重命名文件/目录\r\nmv old_name.txt new_name.txt\r\n\r\n\r\ntouch\r\n创建空文件或更新文件时间戳\r\ntouch new_file.txt\r\n\r\n\r\ncat\r\n查看文件全部内容\r\ncat /etc/hosts\r\n\r\n\r\nless, more\r\n分页查看文件内容\r\nless /var/log/syslog\r\n\r\n\r\nhead, tail\r\n查看文件开头/结尾部分\r\ntail -n 20 file.txt（查看最后20行）\r\n\r\n\r\ngrep\r\n在文件中搜索指定文本\r\ngrep \"error\" /var/log/syslog\r\n\r\n\r\nsudo\r\n以管理员权限执行命令\r\nsudo apt update\r\n\r\n\r\nhistory\r\n查看历史命令及执行指定历史命令\r\nhistory，!序号（执行历史指令的指定序号的一条）\r\n\r\n\r\n\r\n常用终端快捷键\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n快捷键\r\n功能说明\r\n\r\n\r\n\r\n\r\nTab\r\n自动补全命令、文件名或目录名（最重要、最常用）。\r\n\r\n\r\nCtrl + C\r\n强制中断并终止当前正在运行的程序。\r\n\r\n\r\nCtrl + L\r\n清空屏幕，效果等同于 clear 命令。\r\n\r\n\r\nCtrl + D\r\n退出当前的 Shell 会话，或表示输入结束 (EOF)。\r\n\r\n\r\nCtrl + A\r\n将光标移动到命令行的开头。\r\n\r\n\r\nCtrl + E\r\n将光标移动到命令行的结尾。\r\n\r\n\r\nCtrl + R\r\n反向搜索历史命令。\r\n\r\n\r\n上/下方向键\r\n浏览之前输入过的历史命令。\r\n\r\n\r\nCtrl + Z\r\n将当前前台运行的进程暂停并放到后台。\r\n\r\n\r\nCtrl + U\r\n清除从光标位置到行首的所有字符。\r\n\r\n\r\nCtrl + K\r\n清除从光标位置到行尾的所有字符。\r\n\r\n\r\n\r\nLinux内核\r\nLinux 内核是操作系统的核心，它是一个宏内核（Monolithic\r\nKernel）架构的实现。其根本职责是作为硬件资源的唯一仲裁者和软件服务的提供者，为上层用户空间应用程序提供一个统一、抽象和安全的执行环境。\r\n内核的所有功能可以被逻辑地划分为如下几个相互协作的核心子系统。\r\n进程管理 (Process Management)\r\n进程管理子系统的核心目标是高效且公平地在多个并发任务之间共享 CPU\r\n资源。\r\n\r\n核心抽象与数据结构\r\n\r\n进程\r\n(Process)：不仅仅是一个“运行中的程序”，而是一个执行上下文的完整体现。在内核中，每个进程由一个\r\ntask_struct\r\n结构体描述，它包含了进程状态、调度信息、内存映射、打开的文件描述符、凭证等所有必要信息。\r\n线程 (Thread)：是 CPU 调度的基本单位。Linux\r\n内核实际上没有严格区分进程和线程，它们都由 task_struct 表示。通过\r\nclone()\r\n系统调用创建线程时，可以使其与父进程共享地址空间、文件描述符等资源，因此线程也被称为“轻量级进程”。\r\n\r\n进程调度器 (Process Scheduler) 调度器是决定下一个在 CPU\r\n上运行哪个任务的逻辑核心。主要的策略有下面三种:\r\n\r\nSCHED_OTHER (或 SCHED_NORMAL):\r\n这是为普通分时进程设计的默认策略。在现代 Linux\r\n内核中，它由完全公平调度器 (Completely Fair Scheduler, CFS) 实现。\r\n\r\nCFS\r\n核心思想：它摒弃了传统的时间片（timeslice）概念，致力于为每个任务提供“理想的、无限精确的多任务\r\nCPU”。它使用一个红黑树 (Red-Black Tree)\r\n来组织所有可运行的任务，每次总是选择虚拟运行时间（vruntime）最小的任务来执行，从而达到近乎完美的公平性。\r\n\r\nSCHED_FIFO (First-In,\r\nFirst-Out)：这是一种实时（Real-time）调度策略。它没有时间片。一旦一个\r\nFIFO 任务获得 CPU，它会一直运行，直到它主动阻塞（如等待 I/O）、主动调用\r\nsched_yield() 放弃 CPU，或者被一个更高优先级的实时任务抢占。\r\nSCHED_RR (Round-Robin)：这是另一种实时调度策略。它与 FIFO\r\n类似，但增加了时间片的概念。当一个 RR\r\n任务的时间片用完后，如果同优先级队列中还有其他任务，它将被移动到队列末尾，让其他任务有机会运行。\r\n\r\n\r\n内存管理 (Memory Management)\r\n内存管理子系统的目标是高效、安全地管理系统的物理内存（RAM），并为每个进程提供独立的虚拟地址空间。其核心机制与组件如下：\r\n\r\n虚拟内存 (Virtual\r\nMemory)：这是现代操作系统的基石。内核为每个进程提供一个巨大、私有且连续的虚拟地址空间（例如，在\r\n64 位系统上是 256TB）。这带来了几个好处：\r\n\r\n进程隔离：一个进程的内存访问不会干扰到其他进程或内核。\r\n简化编程：程序员无需关心物理内存的碎片化和具体位置。\r\n高效利用物理内存：通过按需分页 (Demand\r\nPaging)，只有在进程实际访问某块内存时，内核才会将其从磁盘加载到物理内存中。\r\n\r\n内存管理单元\r\n(MMU)：这是一个硬件组件，负责将进程访问的虚拟地址实时地翻译成物理地址。内核的主要工作就是设置和管理\r\nMMU 使用的页表 (Page Tables)。\r\n物理内存分配器：\r\n\r\n伙伴系统 (Buddy System)：这是内核管理物理页帧（Page\r\nFrame）的核心算法。它将所有空闲的物理内存页组织成 2 的幂次方大小的块（1,\r\n2, 4, 8, …\r\n页），能够高效地分配和回收连续的物理内存块，但容易产生内部碎片。\r\nSlab 分配器 (Slab\r\nAllocator)：它构建在伙伴系统之上，用于解决小对象的内存分配问题。Slab\r\n维护着常用内核对象（如 inode, dentry,\r\ntask_struct）的缓存池，避免了反复初始化和销毁对象的开销，并大大减少了内存碎片。\r\n\r\n\r\n虚拟文件系统 (Virtual File\r\nSystem, VFS)\r\nVFS\r\n是一个至关重要的抽象层，其目标是为用户空间程序提供一个统一、标准的文件操作接口，屏蔽底层具体文件系统的实现差异。\r\nVFS 定义了一个通用文件模型，主要由四个核心对象组成：\r\n\r\n超级块\r\n(Superblock)：代表一个已挂载的文件系统实例，存储该文件系统的元信息（如文件系统类型、块大小等）。\r\n索引节点\r\n(Inode)：代表一个具体的文件或目录。它包含了文件的所有元数据，如权限、所有者、大小、时间戳以及指向数据块的指针，但不包含文件名。\r\n目录项 (Dentry)：代表一个目录条目，它将一个文件名与一个 Inode\r\n关联起来，形成文件路径。Dentry\r\n缓存（dcache）极大地加速了路径查找过程。\r\n文件对象 (File\r\nObject)：代表一个由进程打开的文件。它存储了文件指针（读写位置）、访问模式等与特定进程相关的信息。\r\n\r\n工作机制：当一个应用程序执行 open(“/path/to/file”) 系统调用时，VFS\r\n会利用 dentry 缓存解析路径，找到每一级目录和最终文件的\r\ninode，然后创建一个文件对象并返回一个文件描述符给应用程序。所有后续的\r\nread(), write() 等操作都会通过这个文件对象，由 VFS\r\n路由到具体文件系统（如 ext4, XFS, NFS）提供的实现函数上。\r\n网络协议栈 (Networking Stack)\r\n网络协议栈的目标是实现标准化的网络协议，使得 Linux\r\n系统能够与世界各地的其他计算机进行通信。其核心架构与数据结构为：\r\n\r\nBSD 套接字接口 (BSD Socket\r\nAPI)：为应用程序提供了一套标准的网络编程接口（如 socket(), bind(),\r\nconnect() 等），使其可以忽略底层网络实现的复杂性。\r\n分层架构：Linux 网络栈在逻辑上严格分层，与 TCP/IP\r\n模型类似，主要包括：\r\n\r\n系统调用接口层：将用户空间的网络操作转换为内核操作。\r\n协议无关层：如 Socket 层。\r\n传输层：实现 TCP 和 UDP 协议。\r\n网络层：实现 IP 协议，负责路由和数据包转发。\r\n链路层/设备驱动层：与物理网络硬件（如网卡）交互。\r\n\r\n套接字缓冲区 (Socket Buffer,\r\nsk_buff)：这是网络栈中最核心的数据结构。一个 sk_buff\r\n代表一个在网络栈中流动的数据包。当数据包从上层向下层传递时，各层协议会将自己的头部（Header）添加到\r\nsk_buff\r\n中；反之，当数据包从下层向上层传递时，各层会剥离自己的头部并进行处理。\r\n\r\n进程间通信\r\n(Inter-Process Communication, IPC)\r\n由于进程之间地址空间是隔离的，IPC\r\n子系统提供了多种机制，允许进程之间进行数据交换和同步。\r\n\r\n管道 (Pipes) 和命名管道\r\n(FIFO)：提供半双工的字节流通信，是父子进程或有亲缘关系进程间通信的常用方式。\r\n信号\r\n(Signals)：一种异步通知机制，用于向进程发送一个事件发生的信号（如\r\nSIGKILL, SIGTERM）。\r\nSystem V IPC：一组传统的 IPC 机制，包括：\r\n\r\n消息队列 (Message\r\nQueues)：允许进程以消息的形式进行通信，克服了信号传递信息量少的缺点。\r\n信号量\r\n(Semaphores)：一个计数器，用于控制多个进程对共享资源的访问，是经典的同步工具。\r\n共享内存 (Shared\r\nMemory)：允许两个或多个进程共享同一块物理内存。这是最快的 IPC\r\n方式，因为它避免了内核的数据拷贝。\r\n\r\nPOSIX IPC：对 System V IPC 的改进和标准化。\r\n套接字 (Sockets)：特别是Unix 域套接字 (Unix Domain\r\nSockets)，它在同一台主机上的进程间通信效率很高，并提供了与网络套接字一致的\r\nAPI。\r\n\r\n","categories":["system"],"tags":["system"]},{"title":"智能投顾","url":"/2025/07/01/misc/Fintech/%E6%99%BA%E8%83%BD%E6%8A%95%E9%A1%BE/","content":"等权重投资组合（Equal\r\nWeight Portfolio, EW）\r\n等权重投资组合是一种简单的投资策略，它将资金平均分配给所有可用的资产。这意味着每个资产在投资组合中的权重是相同的。其根本原则是\r\n“民主化”，即投资组合中的每一只股票或资产都拥有相同的”投票权”或重要性，无论这家公司的规模有多大（市值高低）、股价是高是低。\r\n\n    运作方式：一个简单的例子 \n    \n      假设你有 100,000元 资金，想要投资于一个由\r\n4只股票（股票A、股票B、股票C、股票D）组成的投资组合。你的操作是将总投资比例（100%）除以资产的数量（4）,\r\n最终每只股票的权重 = 100%/4=25%。接着将总资金乘以每项资产的权重,\r\n最终投资到每只股票的金额 = 100,000元×25%=25,000元。\r\n随着时间的推移，由于股价波动，你的投资组合会自然偏离最初的等权重状态。假设股票A大涨，其市值在组合中占比可能上升到30%；而股票D下跌，其占比可能降至20%。\r\n为了维持等权重策略，您需要定期进行 “再平衡”。这意味着您需要：\r\n\r\n卖出一部分表现优异的资产（卖出一部分股票A）。\r\n买入一部分表现不佳的资产（增持一部分股票D）。\r\n\r\n通过这种操作，使每项资产的权重重新回到最初设定的25%。这个过程隐含了一种\r\n“高卖低买” 的逆向投资逻辑。\r\n\n    \n  \r\n马科维茨投资组合策略\r\n(Markowitz Portfolio Strategy, 也称作均值-方差模型 Mean-Variance,\r\nMV)\r\n这是现代投资组合理论的基石，是一种经典的静态优化策略。\r\n马科维茨策略的核心目标是在风险和收益之间找到最佳平衡。它不是在每个交易日都进行调整，而是基于对未来一段时间市场（如预期收益率和协方差）的预测，一次性计算出一个”最优”的资产配置比例。其优化目标通常是：\r\n\r\n在给定可接受的风险水平下，最大化预期收益。\r\n或在给定期望的收益水平下，最小化投资组合的风险（通常用方差来衡量）。\r\n\r\nMVO的数学目标函数\r\nMVO (均值-方差优化) 是指将MV理论付诸实践的数学优化过程.\r\n这是一个计算过程或应用，旨在从有效前沿上找到一个具体的、最符合投资者目标的投资组合。\r\n核心步骤:\r\n\r\n输入:\r\n提供具体的参数估计值，包括对未来资产收益的预期（均值）、对资产风险的预测（方差）以及资产间的协方差矩阵。\r\n设定目标: 定义一个明确的优化目标，例如：\r\n\r\n在满足最低预期收益率 R 的前提下，最小化投资组合的方差。\r\n在可接受的最大风险 V 内，最大化投资组合的预期收益。\r\n找到能最大化夏普比率 (Sharpe Ratio)\r\n的投资组合（也称为切点组合）。\r\n\r\n\r\n求解:\r\n使用数学规划求解器（如二次规划求解器）来计算出能达成该目标的精确投资权重。\r\n有效前沿（Efficient Frontier）\r\n指数梯度 (Exponential\r\nGradient, EG)\r\n这是一种经典的在线投资组合（Online Portfolio）\r\n算法，与静态的马科维茨模型有本质区别。它的假设是近期表现好的资产，在下一个交易日可能依然表现良好。\r\nEG\r\n算法不需要对未来进行预测。它是一种自适应策略，在每个交易周期结束时，根据刚刚过去的这个周期里各个资产的真实表现来动态调整投资权重。其基本逻辑是：\r\n\r\n奖励赢家：对于上一期表现好的资产，增加其权重。\r\n惩罚输家：对于上一期表现差的资产，减少其权重。\r\n\r\n这个调整过程是通过乘法更新 (Multiplicative Updates)\r\n来实现的，因此算法名称中带有 “Exponentiated”（指数化）。\r\n指数梯度算法步骤\r\nEG算法的详细步骤如下：\r\n\r\n初始化 (Initialization)\r\n\r\n在第1天开始时，我们没有任何信息，所以通常采用等权重投资组合。\r\n例如，如果有 m\r\n只股票，每只股票的初始权重都是 。\r\n\r\n观察上一期收益 (Observe Last Period’s Return)\r\n\r\n在第 t\r\n天收盘后，计算当天（即从 t − 1\r\n天收盘到 t\r\n天收盘）每只股票的收益情况。\r\n用一个价格相对向量 yt\r\n表示，其中每个元素 yt, i\r\n是第 i\r\n只股票的当日价格变化率（例如，1.05 代表上涨 5%，0.98 代表下跌\r\n2%）。\r\n\r\n更新权重 (Update the Weights)\r\n\r\n这是算法的核心。根据上一期的权重 wt\r\n和刚刚观察到的收益 yt，计算下一期的未归一化新权重\r\nŵt + 1。\r\n对于组合中的第 i\r\n只股票，其新权重的计算公式为：\r\nŵt + 1, i = wt, i × exp (η ⋅ yt, i)\r\n其中:\r\n\r\nwt, i：第\r\ni 只股票在第 t 天的权重。\r\nyt, i：第\r\ni 只股票在第 t 天的收益表现。\r\nexp (...)：自然指数函数，实现”指数级”奖励。\r\nη (eta)：学习率 (Learning\r\nRate)，控制算法的”反应速度”。\r\n\r\n高 η：算法对近期收益反应剧烈，大幅增加赢家权重。\r\n低 η：算法反应温和，权重调整幅度较小。\r\n\r\n\r\n\r\n归一化 (Normalization)\r\n\r\n第3步计算出的权重相加通常不等于1。为了使其成为一个有效的投资组合，需要进行归一化。\r\n计算所有未归一化权重的总和：\r\n\r\n将每个未归一化权重除以总和，得到最终的、下一期的投资组合权重：\r\n\r\n\r\n\r\n原论文定理\r\n指数梯度（EG）算法遗憾界（Regret Bound）完整推导\r\n定理内容：\r\n假设存在一个固定的投资组合 u，以及一个价格相对向量序列 x1, ..., xT。对于所有的\r\ni, t，都有 xi, t ≥ r &gt; 0\r\n且 maxixi, t = 1。EG(η) 算法的累计对数财富满足：\r\n\r\n证明过程：\r\n\r\n定义势函数变化量 Δt：\r\n令势函数为相对熵 DRE，其单步变化为\r\nΔt = DRE(u∥wt + 1) − DRE(u∥wt)\r\n根据相对熵定义 ，展开上式： \r\n代入 EG 算法更新规则：\r\nEG 算法的更新规则为  取对数并整理得：  代入 Δt 的表达式中：\r\n\r\n为 log Zt\r\n寻找上界：\r\n利用凸性不等式和对数不等式，可以得到 \r\n推导 Δt\r\n的最终上界：\r\n\r\n利用不等式 1 − z ≤ −log z（令 ）：\r\n\r\n累加并得到最终结论：\r\n对 Δt\r\n从 t = 1 到 T 求和：  由于 DRE(u∥wT + 1) ≥ 0\r\n且 wt ⋅ xt ≥ r，上式可放缩为\r\n 移项整理，将 ∑log (wt ⋅ xt)\r\n单独置于一边，并同除以 η，得证： \r\n\r\n在线牛顿步 (Online Newton\r\nStep, ONS)\r\n这同样是一种在线投资组合算法，可以看作是 EG\r\n算法的一个更复杂、更强大的进阶版本。\r\n如果说 EG 算法只考虑了资产过去的收益（一阶信息，类似于梯度），那么\r\nONS\r\n算法则试图利用更多的信息来做出更优的决策。它借鉴了优化理论中的牛顿法\r\n(Newton Method)\r\n的思想，不仅考虑了”哪个方向是好的”（一阶信息），还试图预估”往这个方向走多远是合适的”（二阶信息）。这使得\r\nONS 能够更积极地调整其投资组合，期望能更快地适应市场变化。\r\n\r\n梯度下降 (EG的思路): 只沿着当前最陡峭的方向（近期回报最高）走一小步。\r\n牛顿法 (ONS的思路):\r\n不仅看方向，还通过分析地形的”曲率”（回报的协方差），来计算出一个更直接、通往最优点的”快捷方式”，从而能更快、更准地调整方向。\r\n\r\n在线牛顿步算法步骤\r\nONS 算法的详细步骤如下：\r\n\r\n初始化 (Initialization)\r\n\r\n和 EG 一样，从一个等权重的投资组合开始，例如： \r\n\r\n观察上一期收益 (Observe Last Period’s Return)\r\n\r\n在第 t\r\n天收盘后，观察并记录当天的收益向量 yt。\r\n\r\n更新累计信息 (Update Accumulated Information)\r\n\r\n这是 ONS 与 EG 最大的不同。ONS 会维护两个非常重要的累计变量：\r\n\r\n累计梯度向量 bt：所有过去收益向量的总和。\r\nbt = bt − 1 + yt\r\n累计二阶信息矩阵 At：一个 m × m\r\n的矩阵，近似于所有过去收益的协方差矩阵。\r\nAt = At − 1 + ytyt⊤\r\n\r\n其中 yt⊤\r\n是 yt\r\n的转置。\r\n\r\n\r\n\r\n计算理想组合方向 (Calculate Ideal Portfolio\r\nDirection)\r\n\r\nONS\r\n使用累计的信息来计算一个理想的投资组合方向。这一步的核心是矩阵求逆，这也是”牛顿步”的体现：\r\nŵt + 1 ≈ At−1bt\r\n这里的 At−1（矩阵\r\nA\r\n的逆）利用历史波动性和相关性信息，对简单的累计收益 bt\r\n进行了”扭曲”和”缩放”，从而给出一个更优的更新方向。\r\n\r\n投影与归一化 (Projection and Normalization)\r\n\r\n第4步计算出的 ŵt + 1\r\n只是一个理想的方向，通常不满足投资组合的约束（权重加总为1，且权重为正）。\r\n需要一个额外的、复杂的投影步骤，将这个理想向量”投影”到有效的投资组合空间上，得到最终的权重\r\nwt + 1。\r\n\r\n\r\n优缺点\r\n优点：\r\n\r\n适应性更强：利用资产间的相关性信息，能比 EG\r\n更快地适应市场变化。\r\n性能更优：在理论上和很多实际测试中，ONS\r\n的长期累积回报通常高于 EG。\r\n理论基础好：拥有更强的理论性能保证（较低的”后悔值”）。\r\n\r\n缺点：\r\n\r\n计算成本极高：核心步骤涉及到 m × m\r\n矩阵的求逆，其计算复杂度约为 O(m3)。当资产数量\r\nm\r\n很大时（例如上百只股票），这几乎是不可行的。\r\n数值不稳定性：矩阵 At\r\n可能因为数据问题变得不可逆或病态，导致计算失败或结果不稳定。实际应用中需要加入”正则化”等技巧来缓解此问题。\r\n\r\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"第二章：指令系统","url":"/2025/08/27/system/computer-architecture/chapter2/","content":"第二章：指令系统\r\n这里是计算机体系结构指令系统的内容。\r\n"},{"title":"用户","url":"/2025/08/12/system/linux/%E7%94%A8%E6%88%B7/","content":"Linux 用户账户基础\r\n在 Linux 和类 Unix 系统中，大致有三类用户角色: 超级用户 (root),\r\n普通用户 (Regular User)和系统用户 (System User).\r\n\r\n超级用户 (root) : UID 为 0,\r\n拥有系统的最高、无限制的权限。可以执行任何操作，包括修改系统文件、管理所有用户和进程。\r\n普通用户 (Regular User)：UID通常从 1000 开始, 权限受限,\r\n默认只能在自己的家目录 (/home/username)\r\n内自由读写文件，对系统级的文件和目录只有读取权限或完全没有权限。\r\n\r\n我们执行日常任务，如开发、浏览网页、文档处理通常处在这一层级\r\n\r\n系统用户 (System User)：UID 通常在 1 到 999 之间,\r\n这些用户不是为人类交互设计的。它们被各种系统服务（如 www-data 用于\r\nApache/Nginx，postfix\r\n用于邮件服务）所使用，以便以受限的权限运行，从而提高系统安全性。\r\n\r\n登录 (Login)：创建全新的会话\r\n“登录”是指用户向系统证明自己身份（认证），并由系统为其创建一个全新的、隔离的工作会话（Session）的过程。其可以分为本地登录和远程登录两类.\r\n本地登录 (Local Login): 指直接在连接到计算机的物理设备上登录。\r\n远程登录 (Remote Login):\r\n指通过网络从一台计算机连接到另一台计算机。常见的远程登录方式有SSH登录\r\n\r\nSSH (Secure\r\nShell)：是进行远程服务器管理的最主要、最安全的方式。\r\n\r\n使用 SSH 客户端命令 ssh\r\nusername@hostname_or_ip。服务器会要求你通过密码或 SSH\r\n密钥进行认证。\r\n与本地登录一样，SSH 成功认证后会在远程服务器上为你启动一个全新的\r\n登录 Shell。\r\n\r\n\r\n用户切换\r\n(Switching)：在现有会话中改变身份\r\n\r\n(那我为什么不创建一个新的shell登录呢)\r\n\r\n“切换”是指在一个已经登录的会话中，临时获取另一个用户的身份和权限，而无需退出当前会话。\r\n","categories":["system"],"tags":["system"]},{"title":"知识图谱","url":"/2025/07/08/misc/Fintech/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/","content":"知识图谱\r\n知识图谱是一种用图（Graph）结构来建模和存储现实世界中实体（Entity）、概念（Concept）及其之间复杂关系的知识库。它的核心目标是将互联网上非结构化的海量信息（如文本、图片）转化为结构化的知识，从而让机器能够像人类一样去理解和运用这些知识。\r\n这个概念在2012年被谷歌（Google）正式提出并应用于其搜索引擎，极大地优化了搜索结果的质量和用户的体验，使得搜索不再是简单的关键词匹配，而是能够理解问题的意图并直接给出答案。\r\n简单来说，知识图谱就是一张巨大的“知识之网”，网中的每个节点代表一个实体（比如一个人、一个地方、一部电影），而连接节点的边则代表它们之间的关系（比如“出生于”、“导演是”）。\r\n核心构成\r\n知识图谱的基本组成单位是“三元组（Triple）”，即“实体-关系-实体”或“实体-属性-属性值”的结构。\r\n\r\n实体（Entity）：指代现实世界中可识别、可区分的独立事物。在图中，实体表现为节点（Node）。\r\n\r\n例如：“爱因斯坦”、“《相对论》”、“德国”都是实体。\r\n\r\n关系（Relation）：描述不同实体之间存在的某种联系。在图中，关系表现为连接节点的边（Edge）。\r\n\r\n例如：“爱因斯坦”与“德国”之间的关系是“出生地”。“爱因斯坦”与“《相对论》”之间的关系是“提出者”。\r\n\r\n属性（Attribute）：描述单个实体所具有的内在特征。它是一种特殊的关系，其连接的不是另一个实体，而是一个具体的字面值（Literal）。\r\n\r\n例如：“爱因斯坦”的“出生日期”属性是“1879年3月14日”。\r\n属性也可以基于关系, 例如在 Neo4j\r\n这样的图数据库中允许直接在边（Edge）上附加键值对（Key-Value）属性。这种方式称为属性图模型\r\n(Property Graph)\r\n\r\n\r\n知识图谱与传统数据库的区别\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\n传统关系型数据库\r\n知识图谱（通常使用图数据库）\r\n\r\n\r\n\r\n\r\n数据模型\r\n基于预先定义的、严格的表格（Table）结构\r\n基于灵活的、无固定模式的图（Graph）结构\r\n\r\n\r\n核心焦点\r\n数据的存储和一致性\r\n知识的关联、推理和发现\r\n\r\n\r\n查询方式\r\n通过SQL进行复杂的表连接（JOIN）操作，当关系复杂时性能急剧下降\r\n直接通过图的遍历来查询关系，查询多层深度关系时性能极高\r\n\r\n\r\n灵活性\r\n结构死板，修改和扩展（Schema Change）成本高\r\n结构灵活，可以随时轻松地添加新的实体、属性和关系\r\n\r\n\r\n应用场景\r\n适合处理结构化、事务性强的数据，如ERP、财务报表\r\n适合处理高度互联、关系复杂的数据，如社交网络、金融风控\r\n\r\n\r\n\r\nNeo4j 图数据库\r\nNeo4j 是一个用 Java\r\n开发的、开源的、高性能的原生图数据库管理系统（Graph\r\nDatabase Management System,\r\nGDBMS）。它秉承知识图谱的思想,\r\n将数据以“图”的形式进行存储，而不是传统的表格（如MySQL）或键值对（如Redis）形式。\r\n\r\n原生图数据库： Neo4j\r\n从底层设计就是为了高效地存储和处理图结构。它的存储引擎直接面向节点和关系，使得在查询深度关联数据（例如“朋友的朋友的朋友”）时，性能远超传统数据库。\r\nACID兼容：Neo4j\r\n是一个完全事务性的数据库，支持ACID（原子性、一致性、隔离性、持久性）特性，保证了数据的可靠性和业务的一致性，可以用于企业级的生产环境。\r\n\r\nNeo4j 特别擅长处理数据之间存在复杂、多层、多变关系的应用场景。\r\n\r\n社交网络：分析好友关系、社群发现。\r\n金融风控：识别欺诈团伙、反洗钱、分析关联交易。\r\n推荐引擎：提供实时、精准、可解释的个性化推荐。\r\n知识图谱：构建和查询各领域（如医疗、电商、企业管理）的知识网络。\r\n网络与IT运维：分析网络拓扑、依赖关系和故障影响。\r\n\r\nCypher：为图而生的查询语言\r\nCypher 是类SQL的用于 Neo4j\r\n的声明式图查询语言，其设计哲学是让查询语句本身看起来就像一个图。它使用一种被称为“ASCII-Art”的语法，非常直观。\r\n例如 // 查找所有在《黑客帝国》中出演的演员MATCH (actor:Person)-[:ACTED_IN]-&gt;(movie:Movie {title: '黑客帝国'})RETURN actor.name, movie.title\r\n\r\n() 用圆括号表示一个节点。\r\n[] 用方括号表示一个关系。\r\n–&gt; 或 &lt;– 表示关系的方向。\r\n: 后面跟着的是标签或关系类型。\r\n{} 用花括号表示属性。\r\nMATCH 是匹配图模式的关键字。\r\nRETURN 是指定返回结果的关键字。\r\n\r\npy2neo：连接 Python 与 Neo4j\r\n的桥梁\r\npy2neo 是一个功能强大且维护活跃的 Python\r\n客户端库（或称为“驱动”），专门用于与 Neo4j 数据库进行交互。它为 Python\r\n开发者提供了一套简洁、优雅的API，使得在 Python 程序中操作 Neo4j\r\n变得非常方便。\r\n\r\n数据库连接管理：轻松建立、管理与 Neo4j 数据库的连接。\r\n执行 Cypher 查询：可以直接在 Python 中执行原生的 Cypher\r\n语句，并方便地处理返回的结果。\r\n图数据操作：提供了丰富的 API\r\n来以编程方式创建、更新、删除节点和关系。\r\n对象图映射（Object-Graph Mapping, OGM）：类似于传统数据库的\r\nORM（Object-Relational Mapping）。它允许你将图中的节点定义为 Python\r\n的类（Class），将节点属性映射为类的属性，从而可以用更面向对象的方式来操作图数据，而不仅仅是写\r\nCypher 字符串。\r\n与 Pandas, Jupyter 等数据科学生态集成：可以方便地将查询结果转换为\r\nPandas DataFrame，非常适合进行数据分析和可视化。\r\n\r\n示例如下: from py2neo import Graph, Node, Relationship# 1. 连接到 Neo4j 数据库# 默认情况下，Neo4j 启动在 bolt://localhost:7687，用户名为 neo4j# 请将 \"your_password\" 替换为你的 Neo4j 密码try:    graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"your_password\"))    print(\"成功连接到 Neo4j 数据库！\")except Exception as e:    print(f\"连接失败: {e}\")    exit()# 2. 清理数据库（可选，用于演示）print(\"清理数据库...\")graph.delete_all()# 3. 创建节点 (Node)# 创建两个 Person 节点alice = Node(\"Person\", name=\"Alice\", age=30)bob = Node(\"Person\", name=\"Bob\", age=32)# 创建一个 Company 节点google = Node(\"Company\", name=\"Google\")# 4. 创建关系 (Relationship)# 关系可以有自己的属性alice_knows_bob = Relationship(alice, \"KNOWS\", bob, since=2015)bob_works_for_google = Relationship(bob, \"WORKS_FOR\", google, position=\"Engineer\")# 5. 将创建的节点和关系写入数据库# graph.create() 是原子操作，会一次性创建所有内容print(\"正在创建节点和关系...\")graph.create(alice_knows_bob)graph.create(bob_works_for_google)print(\"创建完成！\")# 6. 执行 Cypher 查询print(\"\\n--- 开始查询 ---\")# 查询1: 找到所有年龄大于 31 岁的人query1 = \"MATCH (p:Person) WHERE p.age &gt; 31 RETURN p.name, p.age\"print(f\"执行查询: {query1}\")results1 = graph.run(query1)for record in results1:    print(f\"  找到的人: {record['p.name']}, 年龄: {record['p.age']}\")# 查询2: 找到所有为 Google 工作的人query2 = \"MATCH (p:Person)-[:WORKS_FOR]-&gt;(c:Company {name: 'Google'}) RETURN p.name, c.name\"print(f\"\\n执行查询: {query2}\")results2 = graph.run(query2)for record in results2:    print(f\"  {record['p.name']} 在 {record['c.name']} 工作。\")\r\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"隐私保护","url":"/2025/07/07/misc/Fintech/%E9%9A%90%E7%A7%81%E4%BF%9D%E6%8A%A4/","content":"常见的隐私保护技术\r\n差分隐私(Differential Privacy,\r\nDP)\r\n差分隐私是一种保护个人数据隐私的技术，它通过在数据中添加噪声来保护个人隐私。差分隐私技术可以有效地保护个人数据隐私，同时保证数据分析的准确性。\r\n其核心思想可以用一个非常直观的方式来理解：在一个数据集中，无论是否包含某个特定个体的数据，对该数据集进行查询分析的结果都应该是极其相似的。\r\n换句话说，如果一个攻击者，哪怕他掌握了除你之外所有人的信息，也无法通过查询结果来判断你的个人信息是否存在于这个数据集中。通过在这种“无法区分”的模糊性中，差分隐私为每个人的数据提供了坚实的保护。\r\n它通过向查询结果中注入经过精确计算的随机噪声来实现这一目标。这种噪声足够大，可以掩盖任何单个个体对结果的贡献；但又足够小，使得从整体数据中得出的统计结论（如平均值、总数等）仍然保持其可用性。\r\nϵ-差分隐私 (ϵ-Differential\r\nPrivacy)\r\nϵ-差分隐私是差分隐私的一种最基础的形式，它通过向查询结果中注入经过精确计算的随机噪声来实现这一目标,\r\n实现了将这种隐私保护程度进行精确的数学度量, 即:\r\n一个随机算法（或机制）M 被认为是满足 ϵ-差分隐私的，如果对于任意两个仅相差一个个体记录的“邻近”数据集\r\nD1 和 D2，以及任意可能的输出结果子集\r\nS，下面的不等式恒成立：\r\nPr [M(D1) ∈ S] ≤ eϵ × Pr [M(D2) ∈ S]\r\n\r\nPr […]：表示事件发生的概率。\r\nM(D)：表示在数据集 D 上应用随机算法 M 后的输出结果。\r\nD1, D2：两个邻近数据集。例如，D1 包含了你的信息，而\r\nD2\r\n中没有，其他所有人的信息都完全相同。\r\nϵ\r\n(Epsilon)：这是一个核心参数，被称为“隐私预算” (Privacy Budget)。\r\n\r\nϵ\r\n是一个非负实数，它精确地控制着隐私保护的强度。\r\n\r\n更小的 ϵ\r\n意味着更强的隐私保护：当 ϵ\r\n趋近于 0 时，eϵ 趋近于\r\n1。这意味着算法在包含或不包含你个人信息的数据集上，产生相同结果的概率几乎完全一样。攻击者几乎不可能分辨出你的数据是否存在。\r\n更大的 ϵ\r\n意味着更高的数据可用性：随着 ϵ\r\n的增大，隐私保护程度减弱。算法允许在两个邻近数据集上的输出结果有更大的差异，这意味着添加的噪声更少，查询结果更接近“真实值”，数据的统计可用性更高。\r\n\r\n联邦学习\r\n联邦学习是一种分布式机器学习技术，其核心思想是：在不将用户的本地数据上传到中央服务器的情况下，通过在多个独立的设备（如手机、电脑或物联网设备）上进行模型训练，共同构建一个全局的机器学习模型。\r\n简单来说，联邦学习实现了“数据不动，模型动”的理念。传统的机器学习需要将所有数据集中到一个服务器上进行训练，这引发了严重的数据隐私和安全问题。联邦学习通过将模型训练的过程分发到数据所在的本地设备，从而有效保护了用户数据的隐私。\r\n联邦学习的工作流程\r\n联邦学习的整个过程是一个迭代循环，通常包含以下几个关键步骤：\r\n第一步：模型初始化与分发\r\n\r\n中央服务器创建一个初始的机器学习模型（可以是一个基础模型，或是在公开数据集上预训练过的模型），并将其分发给所有参与训练的客户端设备（例如用户的手机）。\r\n此步骤为所有参与方提供了一个统一的训练起点，确保大家在同一个“起跑线”上开始优化模型。\r\n\r\n第二步：本地模型训练\r\n\r\n每个客户端设备使用自己的本地数据对接收到的模型进行训练。例如，手机上的输入法会使用用户本地的打字记录来训练语言预测模型。\r\n这是联邦学习保护隐私的关键。所有敏感的原始数据都保留在用户本地，从不离开设备。训练过程利用了这些数据来优化模型，使其适应特定用户的数据模式。\r\n\r\n第三步：模型更新的上传\r\n\r\n在本地训练完成后，每个客户端设备并不上传原始数据，而是只将模型的更新信息（例如模型的权重梯度或更新后的模型参数）发送回中央服务器。\r\n这些“更新信息”可以被看作是模型在本地学到的“知识”或“经验总结”，它们本身不包含具体的原始数据，从而在分享知识的同时保护了隐私。\r\n\r\n第四步：安全聚合 (Secure Aggregation)\r\n\r\n中央服务器收集来自所有（或部分）客户端的模型更新。然后，它使用一种聚合算法（最著名的是联邦平均算法\r\nFedAvg）将这些更新整合起来，从而优化全局模型。\r\n\r\n联邦平均算法的基本思想是：将所有客户端上传的模型参数进行加权平均，以得到一个新的、性能更优的全局模型。\r\n\r\n聚合步骤的目的是汇集所有客户端的“智慧”。通过综合从不同数据集中学到的知识，全局模型变得比任何单一客户端的模型都更加稳健和泛化。\r\n\r\n第五步：全局模型的分发与迭代\r\n\r\n中央服务器将经过聚合优化的新版全局模型再次分发给所有客户端，以替代它们原有的旧模型。\r\n客户端获取到更新后的全局模型后，会进入下一轮的本地训练。整个过程（步骤2至步骤5）会重复进行多轮，直到全局模型的性能达到预设的目标或收敛稳定。通过这种迭代，模型性能得以持续提升。\r\n\r\n联邦学习的挑战\r\n系统异构性 (System\r\nHeterogeneity)：不同客户端设备的计算能力、存储空间和网络连接状况差异巨大，这给协同训练带来了困难。\r\n数据异构性 (Statistical\r\nHeterogeneity)：不同用户的数据分布通常是非独立同分布 (Non-IID)\r\n的，这可能会导致模型训练不稳定或收敛缓慢。\r\n通信成本：虽然比上传原始数据少，但频繁的模型更新对于大规模设备网络仍然是一个不小的负担。\r\n安全风险：联邦学习并非绝对安全，它仍然可能面临模型逆向攻击（从模型更新中推断部分原始数据）等高级安全威胁，需要额外的隐私增强技术（如差分隐私、同态加密）来加固。\r\n同态加密\r\n同态加密是一种加密技术，它允许在加密的数据上进行计算，而无需解密数据。同态加密技术可以有效地保护个人数据隐私，同时保证数据分析的准确性。\r\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"风险控制","url":"/2025/07/11/misc/Fintech/%E9%A3%8E%E9%99%A9%E6%8E%A7%E5%88%B6/","content":"\r\n","categories":["Fintech","misc"],"tags":["misc","Fintech"]},{"title":"有效市场理论","url":"/2025/10/16/misc/%E9%87%91%E8%9E%8D%E7%90%86%E8%AE%BA/%E6%9C%89%E6%95%88%E5%B8%82%E5%9C%BA%E7%90%86%E8%AE%BA/","content":"有效市场理论 (Efficient Market Hypothesis, EMH)\r\n是金融经济学中的一个重要理论，最早由经济学家尤金·法马 (Eugene Fama) 在\r\n1960\r\n年代提出。该理论的核心观点是，金融市场上的资产价格已经充分反映了所有可获得的信息，因此没有任何投资者能够通过分析公开信息来持续获得超额收益。\r\n说人话:\r\n如果一个市场是“有效的”，那么任何信息一旦出现，就会立即、完全地反映到资产价格中。这意味着投资者无法持续地通过利用信息（无论是公开的还是私有的）来获得超额收益（即高于市场平均或风险调整后的收益）。\r\n也就是说, 在有效市场中，资产价格的变动遵循随机游走（Random\r\nWalk）模式，因为价格变动只由不可预测的“新信息”驱动。\r\nEMH 的三个层次\r\n有效市场理论根据信息集的不同，分为三个层次：弱式、半强式和强式。\r\n半强式有效市场\r\n(Semi-Strong Form Efficiency)\r\n在半强式有效市场中，资产价格充分反映了所有公开可用的信息。“公开信息”包括但不限于：\r\n\r\n公司财报（利润表、资产负债表）。\r\n新闻报道、分析师报告、经济数据。\r\n历史价格和交易量数据（即包含了弱式有效市场的信息集）。\r\n公司的公告、分红、股票拆分等所有通过官方渠道发布的信息。\r\n\r\n再这样的情境下, 一些投资策略将失去效力：\r\n\r\n技术分析无效：\r\n由于历史价格和交易量是公开信息，因此任何基于分析历史价格模式的技术分析（Technical\r\nAnalysis）将无法持续获得超额收益。\r\n\r\n当人人都遵循同一个信号时，信号本身就会被交易行为所抵消。例如, 如果\r\n20\r\n日均线被突破被认为是强烈的买入信号，那么在价格刚刚突破的那一瞬间，所有人都试图买入，将价格推高。价格的快速上涨使得这个“信号”所暗示的未来利润空间立刻消失，当前价格已经反映了突破带来的所有价值。因此，后续买入的投资者无法再获得超额收益。\r\n\r\n基本面分析无效（利用公开信息）：\r\n投资者如果仅依靠分析公开的财务报表、行业数据等进行基本面分析（Fundamental\r\nAnalysis），也无法获得超额收益，因为这些信息已经被市场消化并反映在价格中。\r\n内幕信息有效： 在这种市场下，内幕信息（Private/Insider\r\nInformation）仍然是有价值的，拥有内幕信息的人仍有可能获得超额收益。\r\n\r\n根据半强式有效市场理论，对于大多数投资者而言，持续获得超额收益是一项非常困难的任务。他们最好的策略通常是采用被动投资策略，如购买指数基金，追求市场平均回报;\r\n同时需要专注于风险管理和资产配置,\r\n收益主要来自于承担适当的市场风险，而非信息优势。\r\n弱式有效市场 (Weak-Form\r\nEfficiency)\r\n信息集： 资产价格充分反映了所有历史价格和交易量数据。\r\n推论： 技术分析无法持续获得超额收益。\r\n强式有效市场 (Strong-Form\r\nEfficiency)\r\n信息集： 资产价格充分反映了所有信息，包括公开信息和内幕信息。\r\n推论：\r\n即使是拥有内幕信息的人，也无法持续获得超额收益。这是一个最严格的假设，在现实中几乎不存在，因为法规禁止利用内幕信息交易。\r\n有效市场理论的现实意义\r\n实际市场通常被认为处于弱式有效和半强式有效之间，并更接近于半强式有效，但存在许多“摩擦”和“异常”。\r\n弱式有效性在于,\r\n很难有投资者能够仅凭分析历史价格图表（即技术分析）来持续、稳定地跑赢扣除交易成本后的市场基准。任何明显的、基于历史价格的模式，一旦被发现，就会被高频交易者和量化基金迅速利用，从而消除套利空间。因此，技术分析很难成为持续获得超额收益的基础。\r\n半强式有效性表现在,\r\n公开的基本面信息（如财报、新闻等）通常会被市场迅速消化并反映在价格中。大多数专业投资者和机构都有能力获取和分析这些信息，因此很难通过简单的基本面分析来持续跑赢市场。\r\n同时,\r\n半强式有效性方面的一些市场异常现象表明，市场并非完全是半强式有效性。例如：\r\n\r\n行为金融学偏差：\r\n投资者的情绪、过度自信、恐惧和贪婪等因素，会导致价格短期内出现超涨或超跌（例如市场泡沫或恐慌性抛售）。\r\n信息传递滞后：\r\n对于规模较小、流动性差的公司，信息传递可能较慢，某些公开信息（如地方新闻）需要更长的时间才能被市场完全消化。\r\n“价值溢价”和“小盘股溢价”：\r\n某些基于公开信息的策略（例如购买低市盈率的股票或小市值股票）在长期可能确实能跑赢市场，这被认为是风险溢价或市场效率不完善的体现。\r\n\r\n因此, 在实际市场中，量化交易员和投资者的共识是：\r\n\r\n别想通过简单的技术指标持续赚钱（因为市场很可能是弱式有效的）。\r\n公开的基本面分析要比普通人做得更深入、更快，才能获得优势（因为市场大致是半强式有效的）。\r\n真正的超额收益往往来自于：\r\n\r\n承担更高的流动性或结构性风险（如因子投资）。\r\n处理和分析非传统/非公开的数据（另类数据）。\r\n利用市场的行为偏差（捕捉超涨超跌）。\r\n极度高效的执行速度（高频交易）。\r\n\r\n\r\n","categories":["misc"],"tags":["misc"]},{"url":"/2025/09/25/web/Computer%20Network/%E5%8D%8F%E8%AE%AE/","content":"ARP协议\r\nARP (Address Resolution Protocol)，即“地址解析协议”,\r\n用于在一个局域网（LAN）内，将一个已知的IP地址（逻辑地址）解析（翻译）成对应的MAC地址（物理地址）。\r\n当主机A想要给同一局域网内的主机B发送数据时，主机A通常只知道主机B的IP地址（例如，你在ping\r\n192.168.1.101）。但是，数据在局域网内最终是以数据帧的形式传播的，而帧的头部必须包含目标MAC地址。交换机根据这个MAC地址来转发帧。因此，主机A在发送数据之前，必须先获得主机B的MAC地址。\r\nARP的工作原理\r\nARP的工作过程可以分为两个核心步骤：ARP请求 和\r\nARP应答。我们通过一个例子来说明。\r\n假设局域网内有两台主机：\r\n\r\n主机A: IP地址 192.168.1.100，MAC地址 AA-AA-AA-AA-AA-AA\r\n主机B: IP地址 192.168.1.101，MAC地址 BB-BB-BB-BB-BB-BB\r\n\r\n现在，主机A 想要向 主机B 发送数据。\r\n步骤1：检查ARP缓存\r\n主机A首先会检查自己的 ARP缓存表（ARP\r\nCache）。这是一个存储了近期IP地址与MAC地址映射关系的动态表格(为了提高效率，避免每次通信都进行一次广播查询)。\r\n如果找到 192.168.1.101\r\n对应的MAC地址，则直接使用该地址封装数据帧并发送，整个ARP过程结束;\r\n如果没有找到，则进入下一步。\r\n步骤2：发送ARP请求（广播）\r\n主机A会在局域网内发送一个 ARP请求（ARP Request）\r\n报文。\r\n这个请求的核心信息是：“谁的IP地址是 192.168.1.101？请告诉我的IP地址\r\n192.168.1.100，我的MAC地址是 AA-AA-AA-AA-AA-AA”。\r\n这个ARP请求报文会被封装在一个以太网帧中。这个帧的特殊之处在于源MAC地址是主机A的MAC地址\r\n(AA-AA-AA-AA-AA-AA),\r\n目标MAC地址却是一个特殊的广播地址\r\n(FF-FF-FF-FF-FF-FF)。使用广播地址意味着这个帧会被发送到该局域网内的所有设备。\r\n步骤3：网络中所有主机处理ARP请求\r\n局域网内的所有设备（包括主机B和其他主机）都会接收到这个广播帧。\r\n其他主机会检查ARP请求中的目标IP地址（192.168.1.101），发现与自身的IP地址不符，因此会静默丢弃这个请求，不作任何响应。\r\n而主机发现ARP请求中的目标IP地址正是自己的IP地址, 执行下一个阶段。\r\n步骤4：发送ARP应答（单播）\r\n主机B在确认请求是发给自己的之后，会构造一个 ARP应答（ARP Reply）\r\n报文。\r\n报文内容：应答的核心信息是：“我就是 192.168.1.101，我的MAC地址是\r\nBB-BB-BB-BB-BB-BB”。\r\n这个ARP应答报文也会被封装在一个以太网帧中，但这次是单播：源MAC地址是主机B的MAC地址\r\n(BB-BB-BB-BB-BB-BB), 目标MAC地址是主机A的MAC地址\r\n(AA-AA-AA-AA-AA-AA)。主机B之所以知道主机A的MAC地址，是因为它在最初的ARP请求中已经包含了。\r\n单播可以直接将应答信息发送给请求者（主机A），而不需要再打扰网络中的其他设备。\r\n步骤5：更新ARP缓存并通信\r\n主机A收到主机B的ARP应答后，就获取了 192.168.1.101 对应的MAC地址\r\nBB-BB-BB-BB-BB-BB。\r\n接着,\r\n主机A会将这个映射关系存入自己的ARP缓存表，并设置一个老化时间（例如2分钟）。在老化时间内，再次向\r\n192.168.1.101\r\n发送数据时，就可以直接从缓存中查找，无需再次发送ARP请求。\r\n主机A现在可以愉快地将数据封装成以太网帧（目标MAC为BB-BB-BB-BB-BB-BB），并通过交换机准确地发送给主机B了。\r\n总之, ARP\r\n协议可以认为是网络层在与数据链路层交互时所使用的一个“工具”或“接口”,\r\n利用网络层的IP地址获取数据链路层的MAC地址，以便在物理网络上进行通信\r\nARP 数据报格式\r\nIP协议\r\nIP地址: 可以在网络环境中, 唯一标识一台主机 端口号:\r\n可以在网络的一台主机中, 唯一标识一个进程 IP地址+端口号:\r\n可以在网络环境中, 唯一标识一台主机的一个进程\r\nTCP三次握手与四次挥手\r\nTCP\r\n协议中至关重要的两个过程：三次握手（用于建立连接）和四次挥手（用于断开连接）是确保\r\nTCP 协议实现可靠、面向连接的通信基础。\r\nTCP 报文段\r\n在开始之前，我们先了解几个 TCP 头部中起关键作用的标志位 (Flags)：\r\n\r\nSYN (Synchronize):\r\n请求建立连接。在三次握手中的前两次会使用。\r\nACK (Acknowledgement):\r\n确认号字段有效。表示对收到数据的确认。\r\nFIN (Finish):\r\n请求断开连接。表示发送方已经没有数据要发送了。\r\nseq (Sequence Number):\r\n序列号。用于标识 TCP 数据段中数据的字节流顺序。\r\nack (Acknowledgement Number):\r\n确认号。表示期望收到对方下一个数据段的起始序列号。\r\n\r\n三次握手 (Three-Way\r\nHandshake)\r\nTCP\r\n是一个面向连接的协议，在数据传输开始前，客户端和服务器必须先建立一个可靠的连接。这个过程就是“三次握手”。\r\n核心目的是确认双方的收发能力, 确保客户端能发能收，服务器也能发能收;\r\n还可以同步初始序列号 (ISN),\r\n双方协商一个初始序列号，为后续可靠的数据传输做准备。\r\n\r\n第一次握手 (Client → Server)\r\n\r\n动作：客户端向服务器发送一个连接请求报文段。\r\n标志位：SYN = 1, ACK = 0。\r\n序列号：客户端随机选择一个初始序列号\r\nseq = x。\r\n状态：客户端进入 SYN_SENT 状态。\r\n含义：“你好，服务器。我想和你建立连接，我的初始序列号是 x。”\r\n\r\n第二次握手 (Server → Client)\r\n\r\n动作：服务器收到客户端的请求后，回复一个确认报文段。\r\n标志位：SYN = 1, ACK = 1。\r\n序列号：服务器也随机选择一个自己的初始序列号\r\nseq = y。\r\n确认号：ack = x + 1。这个值表示“我已成功收到你的序列号\r\nx，希望下一个收到的数据从 x+1 开始”。\r\n状态：服务器进入 SYN_RCVD 状态。\r\n含义：“好的，我收到了你的请求。我也准备好了，我的初始序列号是\r\ny。同时，我确认收到了你的 x。”\r\n\r\n第三次握手 (Client → Server)\r\n\r\n动作：客户端收到服务器的确认后，再发送一个确认报文段。\r\n标志位：SYN = 0, ACK = 1。\r\n序列号：seq = x + 1。\r\n确认号：ack = y + 1。表示“我已成功收到你的序列号\r\ny，希望下一个收到的数据从 y+1 开始”。\r\n状态：客户端进入 ESTABLISHED\r\n状态。服务器收到这个确认后，也进入\r\nESTABLISHED 状态。\r\n含义：“好的，我收到了你的确认。现在连接正式建立，我们可以开始传输数据了。”\r\n\r\n\r\n为什么需要三次握手，而不是两次？这是为了防止已失效的连接请求报文段(第一次)突然又传送到了服务器，从而产生错误。如果是两次握手，服务器收到这个失效的请求后会立即建立连接，并等待客户端发送数据，这会浪费服务器资源。而三次握手时，客户端不会对这个过时的确认进行响应，服务器也就不会建立错误的连接。\r\n四次挥手 (Four-Way Handshake)\r\n当数据传输结束后，通信双方都可以发起请求来终止连接。由于 TCP\r\n连接是全双工的（数据可以在两个方向上同时传输），因此断开连接需要双方各自关闭自己的发送通道。这个过程就是“四次挥手”。\r\n核心目的是安全、优雅地关闭连接，确保双方所有待发送的数据都已发送完毕。\r\n\r\n第一次挥手 (Client → Server)\r\n\r\n动作：客户端（主动关闭方）发送一个连接释放报文段。\r\n标志位：FIN = 1。\r\n序列号：seq = u (u\r\n是客户端已发送数据的最后一个字节的序列号+1)。\r\n状态：客户端进入 FIN_WAIT_1 状态。\r\n含义：“我这边的数据已经全部发送完了，我要关闭发送通道了。”\r\n\r\n第二次挥手 (Server → Client)\r\n\r\n动作：服务器（被动关闭方）收到 FIN 后，发送一个确认报文段。\r\n标志位：ACK = 1。\r\n确认号：ack = u + 1。\r\n状态：服务器进入 CLOSE_WAIT 状态。客户端收到后，进入 FIN_WAIT_2\r\n状态。\r\n含义：“收到了你的关闭请求。但请等一下，我可能还有数据没有发完。”\r\n注意：此时连接处于半关闭 (Half-Close)\r\n状态。客户端不能再发送数据，但服务器仍然可以向客户端发送数据,\r\n客户端可以接受。\r\n\r\n第三次挥手 (Server → Client)\r\n\r\n动作：服务器确认自己所有的数据也发送完毕后，向客户端发送一个连接释放报文段。\r\n标志位：FIN = 1, ACK = 1。\r\n序列号：seq = v (v\r\n是服务器已发送数据的最后一个字节的序列号+1)。\r\n确认号：ack = u + 1。\r\n状态：服务器进入 LAST_ACK 状态，等待客户端的最后确认。\r\n含义：“我这边的数据也全部发送完了，现在我也要关闭发送通道了。”\r\n\r\n第四次挥手 (Client → Server)\r\n\r\n动作：客户端收到服务器的 FIN 后，发送最后一个确认报文段。\r\n标志位：ACK = 1。\r\n确认号：ack = v + 1。\r\n状态：客户端进入 TIME_WAIT 状态。经过\r\n2MSL（两倍报文最大生存时间）后，客户端才进入 CLOSED 状态。服务器收到这个\r\nACK 后，立即进入 CLOSED 状态。\r\n含义：“好的，我也收到了你的关闭请求。连接正式关闭。”\r\n\r\n\r\n为什么挥手需要四次？因为 TCP 是全双工的。当一方（客户端）发送 FIN\r\n请求关闭时，只表示它不会再发送数据了，但仍然可以接收数据。另一方（服务器）收到后，会先回复一个\r\nACK 确认，但它可能还有数据需要处理和发送，所以不能立即发送自己的\r\nFIN。只有当服务器也准备好关闭时，才会发送自己的 FIN。因此，ACK 和 FIN\r\n通常是分开发送的，这就构成了四次挥手。\r\n为什么客户端最后要进入 TIME_WAIT 状态并等待 2MSL？确保最后的 ACK\r\n能到达服务器：如果这个 ACK 丢失，服务器会超时重传 FIN。TIME_WAIT\r\n状态可以确保客户端有足够的时间来响应这个重传，从而使服务器能够正常关闭;\r\n另一方面，等待 2MSL\r\n可以确保本次连接中产生的所有报文段都从网络中消失，从而避免影响到下一个使用相同端口号的新连接。\r\nTCP连接状态图\r\n\r\n\r\nalt text\r\n\r\n这张图精准地描述了一个 TCP\r\n连接从创建到销毁的整个生命周期中所有可能的状态，以及在不同事件（如收到一个数据包、应用程序发起一个操作）驱动下，状态之间是如何转换的。\r\n\r\n方框：代表 TCP 连接可能处于的状态 (State)，例如 LISTEN,\r\nESTABLISHED。\r\n箭头：代表状态的转换 (Transition)。\r\n箭头上的文字：代表触发这个转换的事件 (Event) 或 动作 (Action)。\r\n\r\n整个过程可以分为三个主要部分：\r\n\r\n连接建立（三次握手）：图的上半部分，从 CLOSED 到 ESTABLISHED。\r\n数据传输：中间的核心状态 ESTABLISHED。\r\n连接断开（四次挥手）：图的下半部分，从 ESTABLISHED 回到\r\nCLOSED。\r\n\r\n第一阶段：连接建立（三次握手）\r\n这个过程涉及两方：客户端（主动打开方） 和 服务器（被动打开方）。\r\n\r\n服务器的路径（被动打开）\r\n\r\nCLOSED → LISTEN：初始状态是 CLOSED（关闭）, 服务器调用 listen()\r\n函数后，进入 LISTEN\r\n状态，开始监听指定的端口，等待客户端的连接请求。\r\nLISTEN → SYN_RCVD：\r\n\r\n事件：在 LISTEN 状态下，服务器收到了一个来自客户端的 SYN\r\n请求报文。\r\n动作：服务器发送自己的 SYN 和对客户端 SYN 的 ACK\r\n作为响应（即第二次握手）。\r\n转换：服务器状态变为 SYN_RCVD (SYN\r\nReceived)，表示已收到连接请求，正在等待客户端的最终确认。\r\n\r\nSYN_RCVD → ESTABLISHED：\r\n\r\n事件：在 SYN_RCVD 状态下，服务器收到了客户端发来的 ACK\r\n确认报文（即第三次握手）。\r\n转换：服务器状态变为\r\nESTABLISHED，表示连接已成功建立，可以开始数据传输。\r\n\r\n\r\n客户端的路径（主动打开）\r\n\r\nCLOSED → SYN_SENT：初始状态是 CLOSED, 客户端调用 connect()\r\n函数，主动打开连接，并发送一个 SYN 请求报文（即第一次握手）,\r\n此时客户端状态变为 SYN_SENT (SYN\r\nSent)，表示已发送连接请求，正在等待服务器的响应。\r\nSYN_SENT → ESTABLISHED：\r\n\r\n事件：在 SYN_SENT 状态下，客户端收到了服务器的 SYN 和 ACK\r\n报文（即第二次握手）。\r\n动作：客户端发送最后一个 ACK 确认报文（即第三次握手）。\r\n转换：客户端状态变为 ESTABLISHED，连接成功建立。\r\n\r\n\r\n\r\n第二阶段：数据传输\r\nESTABLISHED：这是整个 TCP\r\n连接的核心状态。当客户端和服务器都处于此状态时，它们可以自由地、双向地进行数据传输。图中的“数据传送阶段”指的就是这个状态。\r\n第三阶段：连接断开（四次挥手）\r\n这个过程同样涉及两方：主动关闭方和被动关闭方。我们以客户端主动关闭为例。\r\n\r\n客户端的路径（主动关闭方）\r\n\r\nESTABLISHED → FIN_WAIT_1：\r\n\r\n动作：客户端应用程序调用 close()，主动关闭连接，发送一个 FIN\r\n报文，表示自己没有数据要发送了。\r\n转换：客户端进入 FIN_WAIT_1 状态。\r\n\r\nFIN_WAIT_1 → FIN_WAIT_2：\r\n\r\n事件：客户端收到了服务器对自己 FIN 报文的 ACK 确认。\r\n转换：客户端进入 FIN_WAIT_2\r\n状态。此时连接处于半关闭状态，客户端不能再发送数据，但可以接收来自服务器的数据。\r\n\r\nFIN_WAIT_2 → TIME_WAIT：\r\n\r\n事件：客户端收到了服务器发送的 FIN\r\n报文，表示服务器也准备关闭连接了。\r\n动作：客户端发送最后一个 ACK 作为确认。\r\n转换：客户端进入 TIME_WAIT 状态。\r\n\r\nTIME_WAIT → CLOSED：\r\n\r\n事件：TIME_WAIT 是一个等待状态，通常会持续\r\n2MSL（两倍报文最大生存时间）。\r\n目的：确保网络中所有与此连接相关的报文都已消失，并能处理可能丢失的最后一个\r\nACK。\r\n转换：等待计时结束后，连接彻底关闭，状态回到 CLOSED。\r\n\r\n\r\n服务器的路径（被动关闭方）\r\n\r\nESTABLISHED → CLOSE_WAIT：\r\n\r\n事件：服务器收到了来自客户端的 FIN 报文。\r\n动作：服务器发送一个 ACK 进行确认。\r\n转换：服务器进入 CLOSE_WAIT\r\n状态。这个状态告诉上层应用程序：“对方已经关闭了连接，请处理剩余的数据并准备关闭”。\r\n\r\nCLOSE_WAIT → LAST_ACK：\r\n\r\n动作：服务器的应用程序完成数据处理后，调用 close()，发送自己的 FIN\r\n报文。\r\n转换：服务器进入 LAST_ACK 状态，等待客户端的最后确认。\r\n\r\nLAST_ACK → CLOSED：\r\n\r\n事件：服务器收到了客户端发来的最后一个 ACK。\r\n转换：服务器状态变为 CLOSED，连接彻底关闭。\r\n\r\n\r\n\r\n图中还包含了一些特殊的状态转换，例如：\r\n\r\n同时打开 (SYN_SENT → SYN_RCVD)：双方同时向对方发送 SYN\r\n请求，这种情况比较罕见。\r\n同时关闭 (FIN_WAIT_1 → CLOSING)：双方同时向对方发送 FIN 请求，会进入\r\nCLOSING 状态，等待收到对方的 ACK 后再进入 TIME_WAIT。\r\n\r\n"},{"title":"Docker介绍及应用","url":"/2025/06/28/tools/docker/docker/","content":"Docker\r\n是一种开源的应用容器引擎，它彻底改变了现代软件的开发、交付和运行方式。通过将应用程序及其所有依赖项打包到一个标准化的单元中，即容器\r\n(Container)，Docker 确保了应用程序在任何环境中都能以相同的方式运行。\r\n\r\n在 Docker\r\n出现之前，软件开发和运维团队经常面临一个经典难题：“在我电脑上明明是好的啊！”\r\n(“It works on my\r\nmachine!”)。这个问题源于开发、测试和生产环境之间的差异，例如操作系统版本、依赖库、环境变量配置等不同，导致应用程序在一个地方能跑，换个地方就出错。\r\n而Docker\r\n的诞生正是为了解决这一痛点。它通过“集装箱化”的思想，提供了一个标准、一致的运行环境。\r\n\r\nDocker 的三大核心概念\r\n要理解 Docker，必须掌握它的三个基本组成部分：镜像 (Image)、容器\r\n(Container) 和 仓库 (Registry)。\r\n镜像 (Image)\r\n镜像是 Docker 的“构建”部分，它是一个只读的模板，用于创建 Docker\r\n容器。\r\n\r\n定义：一个镜像是一个轻量级、可执行的软件包，其中包含了运行某个软件所需的一切：代码、运行时环境、系统工具、系统库和设置。\r\n特性：镜像是分层的，并且是不可变的。任何对镜像的修改都会创建一个新的镜像层。\r\n类比：如果说容器是面向对象编程中的一个“对象\r\n(Object)”，那么镜像就是创建这个对象的“类 (Class)”。\r\n\r\n容器 (Container)\r\n容器是 Docker 的“运行”部分，它是从镜像创建出来的运行实例。\r\n\r\n定义：容器是镜像的运行时实例。我们可以对容器进行启动、停止、删除等操作。每个容器都是相互隔离的、保证安全的平台。\r\n特性：容器是可写的，并且拥有自己独立的文件系统、网络和进程空间，与宿主机系统和其他容器隔离开来。\r\n(注意docker只是操作系统级的虚拟化。所有容器仍然共享宿主机的操作系统内核,\r\n而不是像虚拟机那样各自拥有独立的操作系统内核)\r\n类比：接上一个比喻，如果镜像是“类”，那么容器就是通过 new\r\n这个类而创建出来的“实例对象”。同一个镜像可以创建出任意多个功能完全相同的容器。\r\n\r\n仓库 (Registry)\r\n仓库是 Docker 的“分发”部分，用于集中存放和分发镜像。\r\n\r\n定义：一个集中的存储、分发镜像的服务。最著名的公共仓库是 Docker\r\nHub，它也是 Docker\r\n官方维护的默认仓库。此外，每个人也可以搭建自己的私有仓库。\r\n类比：我们可以把仓库看作是代码界的 GitHub。开发者将代码上传到\r\nGitHub，其他人可以下载使用；同样，开发者可以将镜像推送到 Docker\r\nHub，其他人可以拉取使用。\r\n\r\n","categories":["tools"],"tags":["tools"]},{"title":"智能体范式","url":"/2025/09/29/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/Agent%E5%85%A5%E9%97%A8/%E6%99%BA%E8%83%BD%E4%BD%93%E8%8C%83%E5%BC%8F/","content":"ReAct\r\nReAct (Reason + Act)\r\n核心思想是模仿人类解决问题的方式，将推理 (Reasoning)\r\n与行动 (Acting)\r\n显式地结合起来，形成一个“思考-行动-观察”的循环。\r\n在ReAct诞生之前，主流的方法可以分为两类：一类是“纯思考”型，如思维链\r\n(Chain-of-Thought)，它能引导模型进行复杂的逻辑推理，但无法与外部世界交互，容易产生事实幻觉；另一类是“纯行动”型，模型直接输出要执行的动作，但缺乏规划和纠错能力。\r\nReAct的巧妙之处在于，它认识到思考与行动是相辅相成的。思考指导行动，而行动的结果又反过来修正思考。为此，ReAct范式通过一种特殊的提示工程来引导模型，使其每一步的输出都遵循一个固定的轨迹：\r\n\r\nThought (思考):\r\n这是智能体的“内心独白”。它会分析当前情况、分解任务、制定下一步计划，或者反思上一步的结果。\r\nAction (行动):\r\n这是智能体决定采取的具体动作，通常是调用一个外部工具，例如\r\nSearch[‘华为最新款手机’]。\r\nObservation (观察):\r\n这是执行Action后从外部工具返回的结果，例如搜索结果的摘要或API的返回值。\r\n\r\n智能体将不断重复这个 Thought -&gt; Action -&gt; Observation\r\n的循环，将新的观察结果追加到历史记录中，形成一个不断增长的上下文，直到它在Thought中认为已经找到了最终答案，然后输出结果。这个过程形成了一个强大的协同效应：推理使得行动更具目的性，而行动则为推理提供了事实依据。\r\n"},{"title":"GDB介绍及应用","url":"/2025/06/28/tools/gdb/gdb/","content":"\r\n","categories":["tools"],"tags":["tools"]},{"title":"初识 Wireshark","url":"/2025/09/16/web/Wireshark/Wireshark/","content":"捕获过滤器\r\n“捕获过滤器”是在你开始捕获之前设置的一个规则。它的作用是告诉\r\nWireshark：“请你只记录符合这个规则的数据包，其他所有的包都直接丢弃，不要保存。”\r\n\r\n捕获过滤器 (Capture\r\nFilter)：捕获前设置，只保存匹配的包（数据量小）。\r\n显示过滤器 (Display\r\nFilter)：捕获后设置，捕获所有包，但根据选择只显示匹配的包（数据量大，但分析灵活）。\r\n\r\n捕获过滤器的语法示例如下图: \r\n\r\nEthernet address 00:00:5e:00:53:00: ether host\r\n00:00:5e:00:53:00\r\n\r\n作用：只捕获数据链路层（以太网）的源 MAC 地址 或 目标 MAC 地址等于\r\n00:00:5e:00:53:00 的数据包。\r\n\r\nEthernet type 0x0806 (ARP): ether proto 0x0806\r\n\r\n作用：只捕获以太网帧类型字段为 0x0806 的数据包。由于 0x0806 是 ARP\r\n协议的类型编号，所以这条规则等同于“只捕获 ARP 包”。\r\n\r\nNo Broadcast and no Multicast: not broadcast and not multicast\r\n\r\n作用：不捕获任何广播包和多播（组播）包，只保留单播包。\r\n\r\nNo ARP: not arp\r\n\r\n作用：不捕获任何 ARP 协议的包。\r\n\r\nIPv4 only: ip\r\n\r\n作用：只捕获所有 IPv4 协议的数据包。\r\n\r\nIPv4 address 192.0.2.1: host 192.0.2.1\r\n\r\n作用：只捕获源 IP 地址 或 目标 IP 地址等于 192.0.2.1 的 IPv4\r\n数据包。\r\n\r\nIPv6 only: ip6\r\n\r\n作用：只捕获所有 IPv6 协议的数据包。\r\n\r\nTCP only: tcp\r\n\r\n作用：只捕获 TCP 协议的数据包（会排除 UDP, ICMP 等）。\r\n\r\nUDP only: udp\r\n\r\n作用：只捕获 UDP 协议的数据包。\r\n\r\nNon-DNS: not port 53\r\n\r\n作用：不捕获源端口 或 目标端口是 53\r\n的数据包。DNS（域名解析）服务通常使用 53 端口，所以这条规则是“排除所有\r\nDNS 流量”。\r\n\r\nTCP or UDP port 80 (HTTP): port\r\n80（最后一行被部分截断，但通常是这个）\r\n\r\n作用：只捕获源端口 或 目标端口是 80\r\n的数据包。HTTP（网页）服务通常使用 80 端口。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"vector","url":"/2025/09/23/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/vector/","content":"std::vector 是 C++ 标准模板库 (STL)\r\n中最常用的序列容器之一。它提供了动态数组的功能，允许在运行时动态调整大小，并且支持高效的随机访问。\r\n#include &lt;vector&gt;std::vector&lt;T&gt; vector_name; - T: 存储的元素类型。\r\n常用接口\r\n获取元素\r\nstd::vector 提供了多种方式来获取元素： - operator[]:\r\n通过下标访问元素，返回对元素的引用。 - at():\r\n通过下标访问元素，返回对元素的引用，并进行边界检查。 - front():\r\n返回对第一个元素的引用。 - back():\r\n返回对最后一个元素的引用。 - data(): 返回指向元素数组的指针。\r\n添加元素: push_back,\r\nemplace_back\r\nstd::vector 有两个向末尾添加元素的方法：push_back 和 emplace_back。 -\r\npush_back(T&amp;&amp;\r\nvalue)：接受一个已经构造好的对象，然后将其拷贝或移动到容器的末尾。\r\n- emplace_back(Args&amp;&amp;…\r\nargs)：接受构造对象所需的参数，然后在容器的末尾直接构造这个对象。它避免了创建临时对象再进行拷贝或移动的开销，效率更高。\r\n例如: std::vector&lt;std::string&gt; vec;vec.push_back(\"Hello\"); // 使用 push_back 添加字符串vec.emplace_back(\"World\"); // 使用 emplace_back 直接构造字符串\r\n\r\n注意, 如果要使用这两种方法填充vector, 在声明vector时就不能指定大小,\r\n否则会导致默认将指定大小的空间初始化,\r\n之后再push_back或emplace_back元素到后面. 例如: std::vector&lt;int&gt; v(10); // 声明时指定大小为10, 这时v已经有10个元素了v.push_back(1); // 这时v会变成11个元素, 不是在原有10个元素上覆盖 ####\r\n拼接\r\n\r\nstd::vector 还提供了 insert 方法，可以将另一个 vector\r\n或一段范围内的元素插入到指定位置。 iterator insert( iterator pos, InputIt first, InputIt last ); - pos:\r\n插入位置的迭代器。 - first, last: 要插入的元素范围。 - 返回值:\r\n指向插入的第一个新元素的迭代器。\r\n示例: std::vector&lt;int&gt; v1 = {1, 2, 3};std::vector&lt;int&gt; v2 = {4, 5, 6};v1.insert(v1.end(), v2.begin(), v2.end()); // v1 现在是 {1, 2, 3, 4, 5, 6}\r\n删除元素\r\n在 C++ 中，vector 的 erase 函数用于删除元素，它有两种主要的参数形式,\r\n都是传递迭代器类型参数 iterator erase(iterator position);iterator erase(iterator first, iterator last); 第一种: 删除 position\r\n所指向的单个元素,\r\n返回一个迭代器，指向被删除元素之后的下一个元素。 第二种: 删除从 first 到\r\nlast（不包括 last）之间的所有元素,\r\n返回一个迭代器，指向被删除区域之后的第一个元素。\r\n需要十分注意的点: - 删除成功后容器的迭代器失效,\r\n不过erase()的返回值会返回指向下一个元素的迭代器,\r\n这在for循环中必须额外处理, 使得只有在删除失败时才it++ -\r\n删除操作会导致后续元素前移，容器大小(size)减小，但容量(capacity)不变。\r\n另外, erase()函数不接受反向迭代器作为参数,\r\n只能传递正向迭代器. 为了传递反向迭代器, 需要使用 base()\r\n方法将其转换为正向迭代器,\r\n但要注意转换后的迭代器指向的是反向迭代器所指元素的下一个位置。\r\nstd::vector&lt;int&gt; v = {1, 2, 3, 4, 5};auto rit = v.rbegin() ; // 指向元素 5v.erase(rit.base() - 1); // 删除元素 5// rit 现在无效，需要重新获取rit = v.rbegin(); // 现在指向新的最后一个元素 4\r\nrit.base()\r\n返回的是当前反向迭代器指向元素的下一个位置(正向来看)，所以你需要减去 1\r\n才能正确删除 rit 所指的元素。\r\n同时, 由于 erase() 返回的是正向迭代器,\r\n如果需要继续使用反向迭代器,\r\n只能重新获取反向迭代器而不能直接重新赋值.\r\n正向迭代器标准处理流程for (auto it = lst.begin(); it != lst.end();) {        if (*it % 2 == 0) {            it = lst.erase(it);  // 删除后，it指向下一个元素        } else {            ++it;                // 未删除时手动递增        }    }\r\n此外, vector 还提供了 pop_back()\r\n方法，用于删除容器末尾的元素。这个方法不返回被删除的元素,\r\n也不会调整容量(capacity)。\r\n查找元素\r\n在 C++ 中，vector 本身并没有内建的查找函数，但我们可以使用 STL\r\n提供的算法来实现查找功能\r\nstd::find:\r\n查找等于某个值的元素，返回找到的元素的迭代器(成功)或末尾迭代器(失败),\r\n输入参数是迭代器(查找范围)的始末位置和要查找的值。 auto it = std::find(v.begin(), v.end(), target);if (it != v.end()) { /* 找到了 */ }\r\nstd::binary_search: 用于已排序的\r\nvector，判断某个值是否存在,\r\n但只能返回bool值代表是否存在而不能定位。 std::sort(v.begin(), v.end());bool found = std::binary_search(v.begin(), v.end(), target);\r\n### 迭代器遍历\r\n反向迭代器:\r\n指的是从容器的末尾向前遍历元素的迭代器。C++ STL 提供了 rbegin() 和\r\nrend() 成员函数来获取反向迭代器,\r\n它们分别指向容器的最后一个元素和第一个元素之前的位置。\r\nfor (auto rit = v.rbegin(); rit != v.rend(); ++rit) {    std::cout &lt;&lt; *rit &lt;&lt; \" \";}\r\n元素去重\r\n使用 std::unique\r\nC++ STL 提供了 std::unique\r\n算法来移除相邻的重复元素。它需要先对 vector 进行排序，然后使用\r\nstd::unique 来将重复元素移动到容器的末尾，最后使用 erase\r\n删除这些重复元素。\r\n#include &lt;algorithm&gt;#include &lt;vector&gt;std::vector&lt;int&gt; v = {1, 2, 2, 3, 4, 4, 5};std::sort(v.begin(), v.end());auto last = std::unique(v.begin(), v.end());v.erase(last, v.end());\r\n这里的 std::unique 原型为: template&lt; class ForwardIt &gt;ForwardIt unique( ForwardIt first, ForwardIt last );\r\n其作用是重新排列范围[first, last)中的元素，使得每个元素只出现一次，并返回一个指向新逻辑结尾的迭代器。而其他重复的元素会被移动到范围的末尾,\r\n因此需要使用 erase 方法将这些多余的元素删除。\r\n需要注意的是，std::unique\r\n只会移除相邻的重复元素，因此在使用之前通常需要先对容器进行排序。\r\n使用 std::set\r\n另一种去重的方法是使用\r\nstd::set，它是一个自动排序且不允许重复元素的容器。可以将 vector\r\n的元素插入到 set 中，然后再将 set 的元素复制回 vector。\r\n#include &lt;set&gt;#include &lt;vector&gt;std::vector&lt;int&gt; v = {1, 2, 2, 3, 4, 4, 5};std::set&lt;int&gt; s(v.begin(), v.end()); // 利用 set 去重v.assign(s.begin(), s.end());        // 复制回 vector\r\n需要注意的是，使用 std::set 会改变元素的顺序，因为 set\r\n会对元素进行排序。\r\n这里的std::assign函数原型为: template&lt; class InputIt &gt;void assign( InputIt first, InputIt last );\r\n它的作用是将范围[first, last)内的元素复制到容器中，替换掉原有的所有元素。\r\n而另一个类似的函数std::copy则是将元素复制到指定位置, 例如:\r\ntemplate&lt; class InputIt, class OutputIt &gt;OutputIt copy( InputIt first, InputIt last, OutputIt d_first );\r\n例如, 将set中的元素复制到vector的开头: std::copy(s.begin(), s.end(), std::back_inserter(v));\r\n这里的std::back_inserter是一个适配器，用于将元素插入到容器的开头。可能有人会问,\r\n为什么不使用std::vector的begin()作为输出迭代器? 因为std::back_inserter\r\n是一个特殊的输出迭代器，它不会直接进行赋值，而是每次写入时都调用目标容器的\r\npush_back() 方法。这会动态地为 std::vector\r\n分配内存并添加元素。如果直接使用 begin()\r\n作为输出迭代器, 那么在复制过程中如果目标容器的大小不足以容纳所有元素,\r\n就会导致未定义行为。\r\n底层实现\r\nstd::vector\r\n底层通常是通过一个动态分配的数组来实现的。它维护了三个关键属性： -\r\n**_start: 指向数组的起始位置。 - _finish:\r\n指向当前最后一个元素的下一个位置。 - _end_of_storage**:\r\n指向分配的内存的末尾。\r\n下面是一个简化版的 std::vector 实现示例，展示了其核心机制：\r\n#include &lt;cstddef&gt;   // for size_t#include &lt;memory&gt;    // for std::allocator, std::uninitialized_copy, etc. (高级实现)#include &lt;utility&gt;   // for std::move#include &lt;stdexcept&gt; // for std::out_of_range#include &lt;iostream&gt;  // for debugging outputtemplate &lt;typename T&gt;class MyVector {public:    // --- 1. 构造函数, 析构函数, 和赋值运算符 (Rule of Five) ---    // 默认构造函数    MyVector() noexcept : _start(nullptr), _finish(nullptr), _end_of_storage(nullptr) {        std::cout &lt;&lt; \"[Default Constructor]\\n\";    }    // 拷贝构造函数    MyVector(const MyVector&amp; other) {        std::cout &lt;&lt; \"[Copy Constructor]\\n\";        // 分配足够大的新空间        _start = new T[other.size()];        // 逐个拷贝元素        std::uninitialized_copy(other._start, other._finish, _start);        _finish = _start + other.size();        _end_of_storage = _finish; // 容量等于大小    }    // 移动构造函数    MyVector(MyVector&amp;&amp; other) noexcept        : _start(other._start), _finish(other._finish), _end_of_storage(other._end_of_storage) {        std::cout &lt;&lt; \"[Move Constructor]\\n\";        // “窃取”资源后，将源对象置为空状态，防止其析构函数释放我们刚窃取的内存        other._start = other._finish = other._end_of_storage = nullptr;    }    // 拷贝赋值运算符 (使用 copy-and-swap 惯用法)    MyVector&amp; operator=(const MyVector&amp; other) {        std::cout &lt;&lt; \"[Copy Assignment Operator]\\n\";        if (this != &amp;other) {            MyVector temp(other); // 调用拷贝构造函数            swap(*this, temp);   // 交换内部指针        }        return *this;    }    // 移动赋值运算符    MyVector&amp; operator=(MyVector&amp;&amp; other) noexcept {        std::cout &lt;&lt; \"[Move Assignment Operator]\\n\";        if (this != &amp;other) {            free(); // 释放当前对象的资源            // 窃取源对象的资源            _start = other._start;            _finish = other._finish;            _end_of_storage = other._end_of_storage;            // 将源对象置空            other._start = other._finish = other._end_of_storage = nullptr;        }        return *this;    }    // 析构函数    ~MyVector() {        std::cout &lt;&lt; \"[Destructor] Cleaning up \" &lt;&lt; size() &lt;&lt; \" elements.\\n\";        free();    }    // --- 2. 容量相关 ---    size_t size() const noexcept { return _finish - _start; }    size_t capacity() const noexcept { return _end_of_storage - _start; }    bool empty() const noexcept { return _start == _finish; }    // --- 3. 元素访问 ---    T&amp; operator[](size_t n) { return _start[n]; }    const T&amp; operator[](size_t n) const { return _start[n]; }    // --- 4. 修改器 ---    void push_back(const T&amp; value) { // 拷贝版本        std::cout &lt;&lt; \"push_back (copy)\\n\";        if (_finish == _end_of_storage) {            reallocate();        }        // 使用 placement new 在已分配的原始内存上构造对象        new (_finish) T(value);        ++_finish;    }    void push_back(T&amp;&amp; value) { // 移动版本        std::cout &lt;&lt; \"push_back (move)\\n\";        if (_finish == _end_of_storage) {            reallocate();        }        // 使用 placement new 并通过 std::move 转发，调用移动构造函数        new (_finish) T(std::move(value));        ++_finish;    }    // --- 5. 迭代器 (简化版，仅为指针) ---    T* begin() noexcept { return _start; }    T* end() noexcept { return _finish; }    const T* begin() const noexcept { return _start; }    const T* end() const noexcept { return _finish; }private:    // --- 6. 私有辅助函数 ---    void free() {        if (_start) {            // 必须先手动调用析构函数            for (T* p = _start; p != _finish; ++p) {                p-&gt;~T();            }            // 再释放原始内存            delete[] reinterpret_cast&lt;char*&gt;(_start);        }    }    void reallocate() {        // 策略：容量为0时分配1，否则加倍, 这里是两倍的策略        size_t new_capacity = size() == 0 ? 1 : 2 * capacity();        size_t old_size = size();                // 分配原始内存，注意这里用 char* 是为了避免调用T的默认构造        T* new_start = reinterpret_cast&lt;T*&gt;(new char[new_capacity * sizeof(T)]);                // 移动旧元素到新内存        // 使用 std::uninitialized_move 来处理移动并构造，更安全高效        for(size_t i = 0; i &lt; old_size; ++i) {            new (new_start + i) T(std::move(_start[i]));        }        // 释放旧内存        free();        // 更新指针        _start = new_start;        _finish = _start + old_size;        _end_of_storage = _start + new_capacity;    }    // 友元函数，用于 copy-and-swap    friend void swap(MyVector&amp; first, MyVector&amp; second) noexcept {        using std::swap;        swap(first._start, second._start);        swap(first._finish, second._finish);        swap(first._end_of_storage, second._end_of_storage);    }    T* _start;  // 指向数据的起始位置    T* _finish;  // 指向当前最后一个元素的下一个位置    T* _end_of_storage;  // 指向分配的内存的末尾};\r\n这里的std::uninitialized_copy和std::uninitialized_move是C++标准库中的两个函数模板，分别用于在未初始化的内存区域中拷贝和移动对象。它们通常用于容器类的实现中，以便在分配新内存后正确地构造对象。\r\n底层实现的关键：size vs\r\ncapacity\r\n要深入理解\r\nstd::vector，就必须明白它内部的内存管理机制，这涉及到两个核心概念：大小\r\n(size) 和 容量 (capacity)。\r\n\r\n大小\r\n(Size)：指容器中当前实际存储的元素数量。你可以通过\r\nsize() 成员函数获取。\r\n容量\r\n(Capacity)：指在不重新分配内存的情况下，容器最多可以容纳的元素数量。你可以通过\r\ncapacity() 成员函数获取。\r\n\r\n可以在上述实现中看到, size 是通过 _finish - _start 计算得到的, 而\r\ncapacity 是通过 _end_of_storage - _start 计算得到的。\r\n当你向 vector 添加元素时（例如通过 push_back），如果当前的 size\r\n达到了 capacity，vector 会调用 reallocate()\r\n函数来分配一块更大的内存区域，通常是当前容量的两倍。然后，它会将旧元素移动到新内存中，并释放旧内存。\r\n这个过程是昂贵的，因为它涉及内存分配和所有元素的移动。但是，由于每次扩容都是指数级增长，这种昂贵的操作不会频繁发生。因此，push_back\r\n的平均时间复杂度（摊还时间复杂度）依然是\r\nO(1)。\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"哈希 Hash","url":"/2025/09/03/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C-map-set/","content":"哈希函数对象 (Hash Functor) –\r\nstd::hash\r\nstd::hash 是 C++ 标准库中定义的一个类模板，位于 \r\n头文件中。它的主要作用是作为一个函数对象（Functor），为给定的数据类型计算一个唯一的、稳定的哈希值。\r\n从本质上讲，std::hash\r\n是一个提供了标准哈希计算接口的工具或者说算法(算子)。\r\n// 主模板, 用于传入自定义类实现哈希函数template&lt;class Key&gt; struct hash;// 为int类型特化template&lt;&gt;struct hash&lt;int&gt; {    size_t operator()(int value) const noexcept {        // 对于整数，最简单的哈希就是其本身的值, 或者其他哈希算法。        return static_cast&lt;size_t&gt;(value);    }};// --- 为指针类型特化 ---template&lt;typename T&gt;struct hash&lt;T*&gt; {    size_t operator()(T* ptr) const noexcept {        // 指针的哈希值就是其内存地址的整数表示。        return reinterpret_cast&lt;size_t&gt;(ptr);    }};// --- 为字符串类型特化 ---template&lt;&gt;struct hash&lt;std::string&gt; {    size_t operator()(const std::string&amp; str) const noexcept {        // 使用一个简单且经典的 djb2 字符串哈希算法。        // 核心思想：遍历字符串，将每个字符融入一个不断变化的哈希值中。        size_t hash_value = 5381;        for (char c : str) {            // hash = (hash * 33) + character_value            hash_value = ((hash_value &lt;&lt; 5) + hash_value) + c;        }        return hash_value;    }};\r\n它的形式如上, 我们可以为不同的数据类型实例化它,\r\n从而实现传入某个类型的数据, 返回计算得到的哈希值(size_t). 它也重载了\r\noperator()并返回一个 size_t\r\n类型的哈希值，使其可以像函数一样被调用。例如，std::hash&lt;std::string&gt;()(\"hello\")\r\n会返回字符串 “hello” 的哈希值。\r\n\r\nstd::hash&lt;std::string&gt;()(\"hello\")是创建一个临时哈希对象并调用它的operator()函数,\r\n等价于\r\nauto hasher = std::hash&lt;std::string&gt;{}; size_t value = hasher(\"hello\");\r\n\r\n如何使用 std::hash\r\nstd::hash\r\n的使用分为两种情况：对标准库内置支持的类型使用，以及对自定义类型使用。\r\n对内置支持的类型使用\r\n标准库已经为所有基本数据类型（如 int, char, float, double,\r\nbool）、指针、以及一些常用库类型（如 std::string, std::thread::id,\r\nstd::shared_ptr 等）提供了 std::hash 的特化版本。因此可以直接使用它们，\r\n#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;functional&gt; // 包含 std::hashint main() {    std::string s = \"Hello, World!\";    int i = 12345;    double d = 3.14159;    // 创建不同类型的 hash 对象    std::hash&lt;std::string&gt; string_hasher;    std::hash&lt;int&gt; int_hasher;    std::hash&lt;double&gt; double_hasher;    // 调用 operator() 计算哈希值    size_t string_hash = string_hasher(s);    size_t int_hash = int_hasher(i);    size_t double_hash = double_hasher(d);    std::cout &lt;&lt; \"Hash of \\\"\" &lt;&lt; s &lt;&lt; \"\\\" is \" &lt;&lt; string_hash &lt;&lt; std::endl;    std::cout &lt;&lt; \"Hash of \" &lt;&lt; i &lt;&lt; \" is \" &lt;&lt; int_hash &lt;&lt; std::endl;    std::cout &lt;&lt; \"Hash of \" &lt;&lt; d &lt;&lt; \" is \" &lt;&lt; double_hash &lt;&lt; std::endl;    return 0;}\r\n对自定义类型使用\r\n如果你想将自定义的类或结构体作为 std::unordered_map\r\n的键或者哈希算子的参数，编译器默认是不知道如何计算其哈希值的。这时，你需要为你的自定义类型\r\n特化（Specialize） std::hash 模板。\r\n特化步骤主要是： - 定义你的自定义类型（例如 struct Student）。 - 在\r\nstd 命名空间内，为你的类型提供一个 std::hash\r\n的模板特化版本。 - 在这个特化版本中，实现\r\noperator()，它接受一个你的自定义类型的常量引用，并返回一个\r\nsize_t 类型的哈希值。 - 在实现 operator()\r\n时，你需要设计一种算法，将对象的各个成员的哈希值组合成一个总的哈希值。\r\n可以看出, 获得自定义对象的哈希值比较麻烦,\r\n还需使用者来设计哈希算法.\r\n// 一个自定义类型，用于展示如何为其提供哈希支持struct Student {    int id;    std::string name;    // 注意: 哈希容器还需要 operator== 来处理哈希冲突, 因此在自定义类中也要实现    bool operator==(const Student&amp; other) const {        return id == other.id &amp;&amp; name == other.name;    }};namespace std{    template&lt;&gt;    struct hash&lt;Student&gt; {        size_t operator()(const Student&amp; s) const noexcept {            // 核心思想：分别计算每个成员的哈希值，然后将它们组合起来。                        // 计算 id 的哈希值 (复用了上面的 hash&lt;int&gt;)            size_t id_hash = SimpleHash::hash&lt;int&gt;{}(s.id);                        // 计算 name 的哈希值 (复用了上面的 hash&lt;std::string&gt;)            size_t name_hash = SimpleHash::hash&lt;std::string&gt;{}(s.name);            // 通过位运算将两个哈希值组合成一个，这是常用技巧。            return id_hash ^ (name_hash &lt;&lt; 1);        }    };}\r\n哈希表（Hash Table） 容器\r\n对于哈希, 我们在平时使用更多的反而是根据哈希函数对象创建的哈希表容器.\r\n这些容器包括：\r\n\r\nstd::unordered_map\r\nstd::unordered_set\r\nstd::unordered_multimap\r\nstd::unordered_multiset\r\n\r\n主要使用的是前两者. multi 版本除了允许重复的键存在,\r\n其他用法和接口基本相同, 因此这里不做赘述.\r\nunordered_set\r\nstd::unordered_set\r\n是一个基于哈希表实现的用于存储唯一元素的关联容器。它的主要设计目标是提供平均时间复杂度为\r\nO(1)\r\n的元素查找、插入和删除操作。可以把它想象成一个数学上的集合：一个无序的、包含唯一元素的集合.\r\n\r\n与\r\nstd::set（基于红黑树实现，提供有序存储和\r\nO(log N) 的操作复杂度）不同，std::unordered_set\r\n更侧重于快速访问，但不保证元素的顺序。\r\n\r\n相比 unordered_map, 它只存储键, 没有值,\r\n因此它更多用于需要快速判断某个元素是否存在的场景。\r\n也可以用于去除重复元素：将一个包含重复元素的列表（如\r\nstd::vector）转换为\r\nstd::unordered_set，可以快速得到一个不含重复元素的集合。\r\nvector&lt;int&gt; numbers = {1, 2, 5, 2, 1, 4};// 直接用 vector 的开始和结束迭代器来构造 setstd::unordered_set&lt;int&gt; uniqueNumbers(numbers.begin(), numbers.end());// uniqueNumbers 现在是 {1, 2, 4, 5}\r\n函数签名如下: #include &lt;unordered_set&gt;template&lt;    class T,    class Hash = std::hash&lt;T&gt;,  // 默认使用 std::hash 作为哈希函数    class KeyEqual = std::equal_to&lt;T&gt;,  // 默认使用 std::equal_to 作为键比较函数    class Allocator = std::allocator&lt;T&gt;  // 默认分配器&gt; class unordered_set; 使用时一般只需要关注第一个模板参数 T\r\n即可，表示元素的类型,\r\n可以是任何可哈希的类型（如 int, std::string,\r\n自定义类型等）, vector 等不可哈希类型不能作为元素类型.\r\n基本接口\r\n\r\n插入元素：\r\n\r\ninsert(key):\r\n插入一个新元素。如果元素已存在，则插入失败, 返回一个\r\npair，包含指向该元素的迭代器和一个布尔值表示插入是否成功。\r\nemplace(args…):\r\n直接在容器内构造一个新元素，避免不必要的拷贝或移动。\r\n\r\n查找元素：\r\n\r\nfind(key): 返回指向该元素的迭代器，如果不存在则返回\r\nend()。\r\ncontains(key) (C++20):\r\n直接返回一个布尔值，表示元素是否存在。\r\ncount(key): 返回元素的数量（0 或 1，因为元素是唯一的）。\r\n\r\n删除元素：\r\n\r\nerase(key):\r\n删除指定值的元素。\r\nclear(): 清空集合中的所有元素。\r\n\r\n获取集合信息：\r\n\r\nsize(): 返回集合中元素的数量。\r\nempty(): 检查集合是否为空。\r\n\r\n\r\n\r\n\r\n迭代访问：\r\n\r\n\r\nbegin() 和 end():\r\n返回指向集合开头和结尾的迭代器，用于遍历所有元素。\r\n范围 for 循环也可以直接用于遍历。 此时每个元素是类型\r\nT，可以直接使用。\r\n\r\n\r\n下面是一个简单的示例，展示了如何使用 std::unordered_set：\r\n#include &lt;iostream&gt;#include &lt;unordered_set&gt;#include &lt;string&gt;int main() {    // 创建一个 unordered_set，元素类型为字符串    std::unordered_set&lt;std::string&gt; fruitSet;    // 插入元素    fruitSet.insert(\"apple\");    fruitSet.insert(\"banana\");    fruitSet.insert(\"orange\");    // 尝试插入重复元素    auto result = fruitSet.insert(\"apple\");    if (!result.second) {  // 返回的 second 为 false 表示插入失败        std::cout &lt;&lt; \"Element 'apple' already exists in the set.\" &lt;&lt; std::endl;    }    // 获取集合的信息    std::cout &lt;&lt; \"Total unique fruits: \" &lt;&lt; fruitSet.size() &lt;&lt; std::endl;    std::cout &lt;&lt; \"Is set empty? \" &lt;&lt; (fruitSet.empty() ? \"Yes\" : \"No\") &lt;&lt; std::endl;    // 检查元素是否存在    if (fruitSet.find(\"banana\") != fruitSet.end()) {        std::cout &lt;&lt; \"'banana' is in the set.\" &lt;&lt; std::endl;    }    // 使用 contains (C++20)    if (fruitSet.contains(\"grape\")) {        std::cout &lt;&lt; \"'grape' is in the set.\" &lt;&lt; std::endl;    } else {        std::cout &lt;&lt; \"'grape' not found.\" &lt;&lt; std::endl;    }    // 遍历所有元素    for (const auto&amp; fruit : fruitSet) {        std::cout &lt;&lt; fruit &lt;&lt; std::endl;    }    // 删除一个元素    fruitSet.erase(\"orange\");    return 0;}\r\nunordered_map\r\nstd::unordered_map\r\n是一个基于哈希表实现的关联容器，用于存储键值对\r\n(Key-Value Pairs)。它的设计目标是提供平均时间复杂度为\r\nO(1)\r\n的元素查找、插入和删除操作。\r\n\r\n对比\r\nstd::map（基于红黑树实现，提供有序存储和\r\nO(log N) 的操作复杂度），std::unordered_map\r\n更侧重于快速访问，但不保证元素的顺序。\r\n\r\n函数签名如下: #include &lt;unordered_map&gt;template&lt;    class Key,    class T,    class Hash = std::hash&lt;Key&gt;,  // 默认使用 std::hash 作为哈希函数    class KeyEqual = std::equal_to&lt;Key&gt;,  // 默认使用 std::equal_to 作为键比较函数    class Allocator = std::allocator&lt; std::pair&lt;const Key, T&gt; &gt;  // 默认分配器&gt; class unordered_map; 一般只需要关注前两个模板参数 Key 和 T\r\n即可，分别表示键的类型和值的类型。哈希表映射的关键就在于键,\r\n因此需要仔细考虑选择什么类型作为键,\r\n以及它是否具有”唯一性”.\r\n\r\n并且这里的 key 的类型必须是可哈希的 (Hashable)\r\n和可判等的 (Equality\r\nComparable)，以确保哈希表能够正确地存储和查找键值对, 例如 std::string,\r\nint, char 等基本类型都是可以的, 但是 vector 不可以作为 key 类型\r\n\r\n它的使用场景主要包括需要快速查找、插入和删除键值对的应用。例如，频繁查询某个键对应的值，或者需要动态更新键值对。\r\n基本接口包括： 1. 检查是否存在某个键： - find(key):\r\n返回指向该键值对的迭代器，如果不存在则返回 end()。 -\r\ncontains(key) (C++20):\r\n直接返回一个布尔值，表示键是否存在。 - count(key):\r\n返回键的数量（0 或 1，因为键是唯一的）。 2. 插入或更新键值对： -\r\ninsert({key, value}): 插入一个新的键值对，如果键已存在则插入失败。 -\r\noperator[key]:\r\n访问或插入键对应的值。如果键不存在，会插入一个默认值。\r\n3. 删除键值对： - erase(key):\r\n删除指定键的键值对。 - clear():\r\n清空映射中的所有键值对。 4. 获取映射信息： - size():\r\n返回映射中键值对的数量。 - empty(): 检查映射是否为空。 5. 迭代访问： -\r\nbegin() 和 end(): 返回指向映射开头和结尾的迭代器，用于遍历所有键值对。 -\r\n范围 for 循环也可以直接用于遍历。此时每个元素是一个\r\nstd::pair&lt;const Key, T&gt;, 可以通过 first 和 second\r\n访问键和值。\r\n下面是一个简单的示例，展示了如何使用 std::unordered_map：\r\n#include &lt;iostream&gt;#include &lt;unordered_map&gt;#include &lt;string&gt;int main() {    // 创建一个 unordered_map，键为字符串，值为整数    std::unordered_map&lt;std::string, int&gt; wordCount;    // 插入键值对    wordCount[\"apple\"] = 2;    wordCount[\"banana\"] = 3;    // 更新键值对    wordCount[\"apple\"] += 1;  // apple 的计数变为 3    // 获取map的信息    std::cout &lt;&lt; \"Total unique words: \" &lt;&lt; wordCount.size() &lt;&lt; std::endl;    std::cout &lt;&lt; \"Is map empty? \" &lt;&lt; (wordCount.empty() ? \"Yes\" : \"No\") &lt;&lt; std::endl;    // 检查键是否存在    if (wordCount.find(\"banana\") != wordCount.end()) {        std::cout &lt;&lt; \"Banana count: \" &lt;&lt; wordCount[\"banana\"] &lt;&lt; std::endl;    }    // 使用 contains (C++20)    if (wordCount.contains(\"orange\")) {        std::cout &lt;&lt; \"Orange count: \" &lt;&lt; wordCount[\"orange\"] &lt;&lt; std::endl;    } else {        std::cout &lt;&lt; \"Orange not found.\" &lt;&lt; std::endl;    }    // 遍历所有键值对    for (const auto&amp; pair : wordCount) {        std::cout &lt;&lt; pair.first &lt;&lt; \": \" &lt;&lt; pair.second &lt;&lt; std::endl;    }    // 删除一个键值对    wordCount.erase(\"banana\");    return 0;}\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"字符串","url":"/2025/09/03/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2/","content":"std::string 是 C++ 标准库中用于处理字符串的类，位于 \r\n头文件中，命名空间为 std &gt; 在 C++ 中，强烈建议使用 string\r\n类表示字符串，因为它是真正的字符串类型。而在 C\r\n语言中实际上没有字符串类型，只是用字符数组和字符指针来模拟字符串，而且后者不太安全\r\n\r\nchar* (C 风格字符串)：本身没有成员函数，不能使用 .size() 或\r\n.length()。要获取其长度，必须使用 C 语言的库函数\r\nstrlen()，这个函数定义在  (或 C 的 &lt;string.h&gt;)\r\n头文件中。\r\n\r\n\r\nC++ 字符串末尾没有 \\0 字符。事实上，除了 C\r\n语言外，其他语言都是将字符串本身及其长度存在内存中，因此不用 \\0\r\n标记结尾\r\n\r\n其迭代器是随机访问迭代器, 支持跳跃式访问\r\n常用接口:\r\n\r\nsize() / length()：获取字符串长度\r\nempty()：判断字符串是否为空\r\nclear()：清空字符串\r\nreserve(n)：预分配内存\r\nappend() / +=：字符串连接\r\ncompare()：字符串比较\r\nsubstr(pos, len)：获取子字符串\r\nfind() / rfind()：查找子字符串\r\ninsert(pos, str)：插入子字符串\r\nerase(pos, len)：删除子字符串\r\npush_back(char) /\r\npop_back()：在字符串末尾添加或删除字符\r\n\r\n定义和初始化\r\n#include &lt;string&gt;using namespace std;string s1;          // 空字符串string s2(\"Hello\"); // 用C字符串初始化string s2 = \"Hello\";string s5 = {\"C++11\"}; // C++11列表初始化string s3(s2);      // 拷贝构造string s4(5, 'a');  // 5个'a'： \"aaaaa\"（重复字符串）\r\nvector&lt;char&gt;和string\r\n在实际使用中, vector可以很方便地和string互相转换:\r\nstring str = \"Hello, World!\";vector&lt;char&gt; charVec(str.begin(), str.end()); // string -&gt; vector&lt;char&gt;string str2(charVec.begin(), charVec.end()); // vector&lt;char&gt; -&gt; string\r\n因此, 如果需要动态修改字符串内容,\r\n也可以用vector来代替string以获得更灵活的接口\r\n\r\n当 std::string str 这行代码执行完毕后，变量 str\r\n已经拥有了一个确定的、合法的、可用的值。它不是未定义的、也不是指向 null\r\n的 ( RAII 的体现 )。std::string\r\n的默认构造函数会将字符串初始化为一个空字符串 (Empty\r\nString), 具有以下明确的属性：\r\n\r\n值为 ““：它不包含任何字符。\r\n长度为 0：调用 str.length() 或 str.size() 会返回 0。\r\n是“空的”：调用 str.empty() 会返回 true。\r\n是有效的：可以立即对它进行各种操作，而不会导致程序错误。\r\n\r\n因为 std::string 是一个 类 (Class)，而不是像 int 或\r\nchar[] 这样的基础数据类型。在 C++\r\n中，当一个类的对象被创建时，会自动调用其相应的构造函数\r\n(Constructor) 来进行初始化。\r\n\r\n访问和赋值\r\nchar c1 = s[0];     // 通过[]访问（不检查越界）, 但注意此时s[i]返回的是char类型的单个字符char c2 = s.at(1);  // 通过at()访问（越界抛出异常）char front = s.front(); // 首字符（C++11）char back = s.back();   // 尾字符（C++11）string s;s = \"Hello\";        // 直接赋值s[0] = 'J';s.assign(\"World\");  // assign函数赋值（string类的方法）s.assign(s, 1, 3); // 从s2的索引1开始取3个字符：\"orl\"赋值给s\r\n在赋值时和 C 字符串的差别:\r\nchar char1[20];char char2[20] = \"jaguar\";string str1;string str2;char1 = char2;                // illegalstr1 = str2;                  // legal\r\n\r\nC 风格字符串 (char[]) 本质是“数组”, 当声明 char char1[20];\r\n时，实际是在内存的栈上请求了一块连续的、包含 20 个 char\r\n类型元素的空间。char1 这个名字就代表了这块内存的起始地址。\r\n尝试执行 char1 = char2; 时，实际上是在命令编译器：“请把 char1\r\n这个地址常量，修改为 char2\r\n这个地址常量所代表的地址”。这在逻辑上是行不通的，也是 C/C++\r\n语法所禁止的。编译器会报错，通常提示“表达式必须是可修改的左值”或“数组类型不可赋值”。\r\n\r\n字符串长度\r\nint len = s.size();  // 或 s.length()int len = s.length();bool isEmpty = s.empty(); // 是否为空s.clear();           // 清空字符串s.reserve(100);      // 预分配内存\r\n字符串连接\r\nstring s = \"Hello\";s += \" World\";      // 追加字符串s.append(\"!!\");     // 追加：\"Hello World!!\"s.push_back('!');   // 追加单个字符string str3;str3 = str1 + str2;\r\n字符串比较\r\nstring a = \"apple\", b = \"banana\";if (a == b) { /* ... */ } // 直接比较，同理&gt;和&lt;、&lt;=等也一样，比较字典顺序int cmp = a.compare(b);   // 返回0（相等）、正数（a &gt; b）、负数（a &lt; b）\r\n关于单引号和双引号:\r\n\r\n\r\n\r\n符号\r\n用途\r\n类型\r\n内存内容\r\n示例\r\n\r\n\r\n\r\n\r\n’ ’\r\n单个字符\r\nchar\r\nASCII 值\r\n‘A’\r\n\r\n\r\n” ”\r\n字符串\r\nconst char*\r\n字符序列 + \\0\r\n“Hello”\r\n\r\n\r\n\r\n因此对于string类型的s, 下列代码不正确s[i] == “V”而应该是s[i] ==\r\n‘V’\r\n子串操作\r\nsubstr() 函数 - 获取子字符串：s.substr(pos, len), 注意参数不是迭代器\r\n- 参数： - pos：起始索引。 - len：长度（可选，默认到字符串末尾）(\r\n不是终点位置!!! 已知终点算长度要 pos-start) string s = \"Hello World\";string sub1 = s.substr(6);    // \"World\"（从索引6开始到结尾）string sub2 = s.substr(0, 5); // \"Hello\"（从0开始取5个字符）\r\n子串查找\r\nsize_t pos = s.find(\"World\");    // 查找子串，返回起始索引，找不到返回 string::npossize_t pos = s.find('o', 5);     // 从索引5开始查找字符'o'size_t pos = s.rfind(\"lo\");      // 反向查找子串  \r\n插入和删除\r\ns.insert(5, \" INSERTED \"); // 在索引5插入字符串s.erase(5, 8);             // 从索引5删除8个字符, (pos, length)s.erase(s.begin() + 2);   // 删除迭代器指向的字符\r\n字符串输入和输出\r\nstd::string s;std::cin &gt;&gt; s; // 默认停止读取空格，分隔多单词输入std::getline(std::cin, s); // 读取整行内容，包括空格std::string s(\"Hello\");std::cout &lt;&lt; s &lt;&lt; std::endl; // 输出 \"Hello\"\r\n\r\n如果 cin 之后用到 getline，由于 cin\r\n遇到空白字符时就停止往后读，输入流里可能还有未被读取的换行符，而 getline\r\n将会读取一行字符串，直到遇到换行符。所以在使用 getline 前，应当先用\r\ncin.get() 读取换行符（这个函数的功能是读取单个字符），然后再用\r\ngetline。\r\n\r\nstring和栈\r\nstring本身提供了push_back()和pop_back()方法,\r\n可以把string当作栈来用\r\n#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;stack&gt;using namespace std;int main() {    string s;    s.push_back('a');    s.push_back('b');    s.push_back('c');    cout &lt;&lt; \"String as stack: \" &lt;&lt; s &lt;&lt; endl; // 输出 \"abc\"    s.pop_back();    cout &lt;&lt; \"After pop_back: \" &lt;&lt; s &lt;&lt; endl; // 输出 \"ab\"    // 使用标准库的 stack    stack&lt;char&gt; charStack;    charStack.push('x');    charStack.push('y');    charStack.push('z');    cout &lt;&lt; \"Stack top: \" &lt;&lt; charStack.top() &lt;&lt; endl; // 输出 'z'        charStack.pop();    cout &lt;&lt; \"After pop, new top: \" &lt;&lt; charStack.top() &lt;&lt; endl; // 输出 'y'    return 0;}\r\n底层实现\r\nstd::string\r\n通常在底层使用动态数组来存储字符数据。它会自动管理内存的分配和释放，以适应字符串长度的变化。常见的实现细节包括：\r\n- 动态内存分配：当字符串长度超过当前容量时，std::string\r\n会分配更大的内存块，并将现有数据复制过去。 - 小字符串优化\r\n(SSO)：许多 std::string\r\n实现会使用小字符串优化技术，将较短的字符串直接存储在对象内部的固定大小缓冲区中，以减少动态内存分配的开销。\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"栈和队列","url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/","content":"“栈和队列是以底层容器完成其所有的工作，对外提供统一的接口，底层容器是可插拔的”\r\n这句话描述的是一种经典的设计模式————适配器模式\r\n(Adapter Pattern)。在 C++ 标准库中，std::stack 和 std::queue\r\n正是这种模式的绝佳范例，它们并不是底层容器,\r\n而被称为“容器适配器 (Container Adapters)”。\r\n适配器模式 (Adapter Pattern)\r\n\r\n适配器模式是一种结构型设计模式，它允许将一个类的接口转换成客户端所期望的另一个接口。通过这种方式，原本由于接口不兼容而无法一起工作的类可以协同工作。\r\n\r\n回到标题, std::stack 和 std::queue\r\n类本身并不真正存储数据。它们内部包含了一个底层容器的对象（比如一个\r\nstd::deque\r\n对象），并将所有的数据操作委托（Delegate）给这个内部对象来完成。\r\n\r\n当你对一个 std::stack 执行 push() 操作时，std::stack\r\n内部实际上调用的是其底层容器的 push_back() 方法。\r\n当你执行 pop() 操作时，它内部调用的是底层容器的 pop_back()\r\n方法。\r\n当你执行 top() 操作时，它内部调用的是底层容器的 back()\r\n方法来获取最后一个元素的引用。\r\n\r\n因此, stack 类的实现就像一个“中间人”或“代理”: // 概念伪代码template&lt;class T, class Container&gt;class stack {protected:    Container c; // 内部包含一个底层容器对象 c, 可以是 std::vector, std::deque 等public:    void push(const T&amp; val) {        c.push_back(val); // 将 push 操作委托给底层容器的 push_back    }    void pop() {        c.pop_back(); // 将 pop 操作委托给底层容器的 pop_back    }    T&amp; top() {        return c.back(); // 将 top 操作委托给底层容器的 back    }    // ... 其他接口如 empty(), size() 也都委托给 c};\r\n当然, 底层容器（如\r\nstd::vector）的功能非常强大，它提供了在任意位置插入 (insert())、删除\r\n(erase())、随机访问 (operator[])\r\n等多种操作。但是，一个“栈”的逻辑是严格的后进先出 (Last-In, First-Out,\r\nLIFO)。你不应该能在栈的中间插入或删除元素。\r\n因此，std::stack\r\n适配器屏蔽了底层容器的大部分接口，只暴露出符合栈逻辑的几个关键接口(限制和简化接口):\r\n- push(): 在栈顶添加元素。 - pop(): 从栈顶移除元素。 - top():\r\n查看栈顶元素。 - empty(): 判断栈是否为空。 - size():\r\n获取栈中元素的数量。\r\n通过这种方式，std::stack 强制保证了其 LIFO\r\n的行为特性，使得代码更安全、逻辑更清晰。你无法意外地对一个栈执行不符合其数据结构逻辑的操作。std::queue（先进先出,\r\nFirst-In, First-Out, FIFO）也是同理。\r\n与此同时, 底层容器是可插拔的.\r\n这体现了设计的灵活性和复用性。C++ 通过模板 (Templates)\r\n机制实现了这一点。std::stack 和 std::queue 的定义如下： template&lt;    class T,    class Container = std::deque&lt;T&gt;&gt; class stack;template&lt;    class T,    class Container = std::deque&lt;T&gt;&gt; class queue;\r\n可以看出, T是存储元素的类型;\r\nContainer是选择的底层容器类型。它有一个默认值 std::deque,\r\n我们可以显式指定为 std::vector 或 std::list。 #include &lt;stack&gt;#include &lt;vector&gt;#include &lt;list&gt;#include &lt;deque&gt; // 默认使用它std::stack&lt;int&gt; s1; // 底层是 std::deque&lt;int&gt;// 显式指定 std::vector&lt;int&gt; 作为底层容器std::stack&lt;int, std::vector&lt;int&gt;&gt; s2;// 显式指定 std::list&lt;int&gt; 作为底层容器std::stack&lt;int, std::list&lt;int&gt;&gt; s3;\r\n\r\n不是任何容器都可以作为 stack\r\n的底层容器。它必须满足一定的接口要求，比如必须提供 back(), push_back(),\r\npop_back() 这几个函数。\r\n\r\n\r\n还要注意, stack和queue并不支持迭代器 (Iterators), 你无法像遍历 vector\r\n或 deque 那样遍历 stack 或\r\nqueue。因为它们的设计初衷就是提供一种受限的访问方式，以符合栈和队列的逻辑。\r\n\r\n栈 (Stack)\r\n栈是一种严格遵循“后进先出”（Last-In, First-Out）原则的数据结构。\r\n头文件: 要使用 std::stack，你需要包含以下头文件:\r\n#include &lt;stack&gt;\r\n定义和初始化: std::stack\r\n是一个模板类，你需要指定存储的元素类型。你也可以选择性地指定底层容器。\r\n#include &lt;iostream&gt;#include &lt;stack&gt;#include &lt;vector&gt;#include &lt;list&gt;#include&lt;string&gt;// 1. 使用默认的底层容器 std::dequestd::stack&lt;int&gt; s1;// 2. 显式指定 std::vector 作为底层容器std::stack&lt;std::string, std::vector&lt;std::string&gt;&gt; s2;// 3. 显式指定 std::list 作为底层容器std::stack&lt;double, std::list&lt;double&gt;&gt; s3;\r\n核心成员函数: std::stack\r\n的接口非常简洁，主要包含以下几个核心操作：\r\n\r\npush(const T&amp; value): 将元素压入栈顶。\r\npop():\r\n移除栈顶元素。注意：这个函数没有返回值，它只负责移除。\r\ntop():\r\n返回对栈顶元素的引用。你可以通过它读取或修改栈顶元素。\r\n\r\n如果栈为空，调用 top() 会导致未定义行为 (Undefined Behavior)。\r\n\r\nempty(): 检查栈是否为空。如果为空，返回 true；否则返回 false。\r\nsize(): 返回栈中元素的数量。\r\n\r\n#include &lt;iostream&gt;#include &lt;stack&gt;int main() {    // 创建一个存储 int 类型的栈，底层使用默认的 std::deque    std::stack&lt;int&gt; my_stack;    // --- 压入元素 ---    std::cout &lt;&lt; \"Pushing 10, 20, 30 onto the stack...\" &lt;&lt; std::endl;    my_stack.push(10); // 栈: [10]    my_stack.push(20); // 栈: [10, 20]    my_stack.push(30); // 栈: [10, 20, 30] &lt;- 30 是栈顶    // --- 访问和检查 ---    std::cout &lt;&lt; \"Stack size is: \" &lt;&lt; my_stack.size() &lt;&lt; std::endl; // 输出: 3    if (!my_stack.empty()) {        std::cout &lt;&lt; \"Top element is: \" &lt;&lt; my_stack.top() &lt;&lt; std::endl; // 输出: 30    }    // --- 弹出元素 ---    std::cout &lt;&lt; \"\\nPopping elements from the stack:\" &lt;&lt; std::endl;    while (!my_stack.empty()) {        // 步骤1：访问栈顶元素        int top_element = my_stack.top();        std::cout &lt;&lt; \"Popping: \" &lt;&lt; top_element &lt;&lt; std::endl;                // 步骤2：移除栈顶元素        my_stack.pop();    }    // 循环结束后，栈为空    // --- 检查栈是否为空 ---    if (my_stack.empty()) {        std::cout &lt;&lt; \"\\nThe stack is now empty.\" &lt;&lt; std::endl;    }    return 0;}\r\n队列 (Queue)\r\nstd::queue 是 C++\r\n标准模板库（STL）中的一个容器适配器（Container\r\nAdapter）。它提供了一种先进先出(尾进头出)（First-In,\r\nFirst-Out, FIFO）的数据结构。默认情况下，std::queue 使用\r\nstd::deque（双端队列）作为其底层容器。\r\n使用前需要包含头文件: #include &lt;queue&gt;\r\nstd::queue 的接口非常简洁，主要包含以下几个核心操作：\r\n\r\npush(const T&amp; value):\r\n在队列的尾部添加一个元素。这被称为“入队”（enqueue）。\r\npop():\r\n移除队列头部的元素。这被称为“出队”（dequeue）。\r\n\r\n此函数不返回任何值 (void)。如果想获取头部元素的值，必须在调用 pop()\r\n之前先调用 front()。\r\n\r\nfront():\r\n返回对队列头部的第一个元素的引用。你可以通过它读取或修改头部元素，但不会将其从队列中移除。\r\nback(): 返回对队列尾部的最后一个元素的引用。\r\nempty():\r\n检查队列是否为空。如果队列中没有任何元素，返回 true；否则返回\r\nfalse。\r\nsize(): 返回队列中元素的数量。\r\n\r\n注意: Queue没有迭代器 (Iterators), 你无法像遍历 vector 或 deque\r\n那样遍历 queue。如果需要遍历, 可以考虑使用 deque 代替.\r\n双端队列 (Deque)\r\n双端队列（Deque，全称 Double-Ended\r\nQueue）是一种允许在两端进行插入和删除操作的线性数据结构。与传统的队列（Queue）和栈（Stack）不同，双端队列既支持先进先出（FIFO）的操作，也支持后进先出（LIFO）的操作。\r\n使用前需要包含头文件: #include &lt;deque&gt;\r\n其常用函数包括： - push_back(const T&amp; value):\r\n在队列的尾部添加一个元素。 - push_front(const T&amp; value):\r\n在队列的头部添加一个元素。 - pop_back(): 移除队列尾部的元素。 -\r\npop_front(): 移除队列头部的元素。 - front(): 返回对队列头部元素的引用。\r\n- back(): 返回对队列尾部元素的引用。 - empty(): 检查队列是否为空。 -\r\nsize(): 返回队列中元素的数量。\r\n#include &lt;iostream&gt;#include &lt;deque&gt;int main() {    std::deque&lt;int&gt; my_deque;    // 在尾部添加元素    my_deque.push_back(10); // 队列: [10]    my_deque.push_back(20); // 队列: [10, 20]    // 在头部添加元素    my_deque.push_front(5); // 队列: [5, 10, 20]    // 访问头部和尾部元素    std::cout &lt;&lt; \"Front element: \" &lt;&lt; my_deque.front() &lt;&lt; std::endl; // 输出: 5    std::cout &lt;&lt; \"Back element: \" &lt;&lt; my_deque.back() &lt;&lt; std::endl;   // 输出: 20    // 移除头部元素    my_deque.pop_front(); // 队列: [10, 20]    // 移除尾部元素    my_deque.pop_back();  // 队列: [10]    // 检查队列是否为空    if (!my_deque.empty()) {        std::cout &lt;&lt; \"Deque size: \" &lt;&lt; my_deque.size() &lt;&lt; std::endl; // 输出: 1    }    return 0;}\r\n其在头部或尾部插入/删除元素的时间复杂度都是 O(1)\r\n单调队列\r\n单调队列是一种特殊的数据结构，它在保持队列基本功能的同时，还维护了队列中元素的单调性（递增或递减）。单调队列常用于解决一些需要在滑动窗口内快速获取最大值或最小值的问题。\r\n例如 Leetcode 239 题“滑动窗口最大值”就是单调队列的经典应用场景。\r\n给你一个整数数组 nums，有一个大小为 k\r\n的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k\r\n个数字。滑动窗口每次只向右移动一位。返回 滑动窗口中的最大值。\r\nclass Solution {private:    class Monotonicqueue{    public:        deque&lt;int&gt; que;        void pop(int value){            if(!que.empty()&amp;&amp; value==que.front()){                que.pop_front();            }        }        void push(int value){            while(!que.empty()&amp;&amp;value&gt;que.back()){                que.pop_back();            }            que.push_back(value);        }        int front(){            return que.front();        }    };public:    vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) {        Monotonicqueue que;        vector&lt;int&gt; result;        for (int i = 0; i &lt; k; i++) { // 先将前k的元素放进队列            que.push(nums[i]);        }        result.push_back(que.front()); // result 记录前k的元素的最大值        for (int i = k; i &lt; nums.size(); i++) {            que.pop(nums[i - k]); // 滑动窗口移除最前面元素            que.push(nums[i]); // 滑动窗口前加入最后面的元素            result.push_back(que.front()); // 记录对应的最大值        }        return result;    }};\r\n这是个单调递减队列（从队头到队尾，front\r\n→\r\nback）。这意味着队列的头部是最大的元素，尾部是最小的元素\r\n\r\npop(int value): 如果队列头部的元素等于\r\nvalue，则将其移除。这是为了在滑动窗口移动时，移除过期的元素。\r\n\r\n之所以要和 value\r\n比较，是因为只有当要移除的元素正好是队列头部时，才需要将其移除;\r\n否则，说明该元素已经被之前的 push 操作移除掉了。\r\n\r\npush(int value): 将新元素 value 插入队列。插入前，会移除所有小于\r\nvalue 的元素，以保持队列的单调递减性质。\r\n\r\n队列中存在的所有小于 value\r\n的元素都不可能成为当前或未来窗口的最大值，因此可以安全地移除它们。\r\n\r\nfront(): 返回队列头部的最大元素。\r\n\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"array","url":"/2025/09/30/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/array/","content":"std::array 是在 C++11\r\n中引入的一个容器模板，它封装了一个固定大小的数组。它结合了C风格数组的性能优势（静态分配、无额外开销）和STL容器的便利性与安全性。\r\n#include &lt;array&gt;std::array&lt;T, N&gt; array_name;\r\n\r\nT: 存储的元素类型 (例如 int, double, std::string)。\r\nN: 数组的大小，必须是一个编译时常量。\r\n\r\n主要特性\r\n\r\n空间固定且内存连续：一旦声明之后大小就不能改变。这与\r\nstd::vector 不同，后者是动态大小的。并且, std::array&lt;T, N&gt;\r\n的内存布局与 T[N]\r\n完全相同。它不包含任何额外的元数据，比如虚函数表指针、大小变量等。它在内存中就是一块连续的、大小为\r\nN * sizeof(T) 的空间。\r\n栈上分配：和C风格数组一样，如果作为局部变量声明，它通常在栈上分配内存，速度非常快。\r\n完整的容器接口：它表现得像一个标准的STL容器，提供了许多方便的成员函数：\r\n\r\nat(pos):\r\n访问指定位置的元素，会进行边界检查。如果越界，会抛出\r\nstd::out_of_range 异常。\r\noperator[]:\r\n访问指定位置的元素，不进行边界检查（为了性能，与C风格数组行为一致）。\r\nfront() / back(): 访问第一个/最后一个元素。\r\nsize() / max_size(): 返回数组的大小。\r\nempty(): 检查数组是否为空 (对于 std::array 来说，如果 N &gt; 0\r\n则永远不为空)。\r\nfill(value):\r\n用一个指定的值填充整个数组。\r\nbegin() / end():\r\n提供迭代器支持，可以轻松与STL算法（如\r\nstd::sort）配合使用。\r\n\r\n\r\n底层实现\r\nstd::array\r\n的底层实现非常简单，它在内部只包含一个公开的、C风格的普通数组作为其唯一的非静态数据成员。标准库围绕这个内置数组提供了一系列成员函数（如\r\nsize(), at(), begin() 等），以赋予它现代容器的行为和安全性。\r\n这个设计的关键在于，所有这些“包装”工作都在编译时完成，几乎不会产生任何运行时的性能开销。\r\n以下是一个简化的示例：\r\n#include &lt;cstddef&gt; // for size_t#include &lt;stdexcept&gt; // for std::out_of_range#include &lt;algorithm&gt; // for std::filltemplate&lt;typename T, std::size_t N&gt;struct MyArray {    // 核心：内部就是一个公开的C风格数组    // 命名为 _data 以避免与用户代码冲突（标准库实现有自己的命名规则）    T _data[N];    // --- 成员函数实现 ---    // size()：返回大小。因为N是编译时常量，所以这个函数可以标记为 constexpr    constexpr std::size_t size() const noexcept {        return N;    }    // operator[]：直接访问内部数组，不进行边界检查    T&amp; operator[](std::size_t index) noexcept {        return _data[index];    }    const T&amp; operator[](std::size_t index) const noexcept {        return _data[index];    }    // at()：访问内部数组，但带有边界检查    T&amp; at(std::size_t index) {        if (index &gt;= N) {            throw std::out_of_range(\"MyArray::at() index out of range\");        }        return _data[index];    }    const T&amp; at(std::size_t index) const {        if (index &gt;= N) {            throw std::out_of_range(\"MyArray::at() index out of range\");        }        return _data[index];    }        // begin() 和 end()：返回指向内部数组的指针，实现迭代器支持    T* begin() noexcept {        return _data; // 或者 &amp;_data[0]    }    const T* begin() const noexcept {        return _data;    }        T* end() noexcept {        return _data + N; // 指向数组末尾的后一个位置    }    const T* end() const noexcept {        return _data + N;    }    // fill()：填充数组    void fill(const T&amp; value) {        std::fill(begin(), end(), value);    }};// ------------------- 使用示例 -------------------#include &lt;iostream&gt;int main() {    MyArray&lt;int, 5&gt; arr = {1, 2, 3, 4, 5};    std::cout &lt;&lt; \"Size: \" &lt;&lt; arr.size() &lt;&lt; std::endl;    arr[0] = 100;        for(int val : arr) { // 可以使用范围for循环，因为有 begin() 和 end()        std::cout &lt;&lt; val &lt;&lt; \" \";    }    std::cout &lt;&lt; std::endl;}\r\n聚合类型 (Aggregate Type)\r\n与初始化\r\nstd::array\r\n被设计成一个聚合类型。在C++中，聚合类型大致是指没有用户定义的构造函数、没有私有或保护的非静态数据成员、没有基类、没有虚函数的类或结构体。\r\n因为 std::array 内部只有一个公开的C风格数组 T\r\n_data[N];，它符合聚合类型的定义。\r\n这使得我们可以使用大括号 {}\r\n进行聚合初始化，就像初始化一个普通的C风格数组一样，非常直观。\r\nstd::array&lt;int, 3&gt; arr = {10, 20, 30}; // 直接初始化内部的C风格数组\r\n零成本抽象 (Zero-Cost\r\nAbstraction)\r\n这是 std::array\r\n最重要的特性。这意味着你获得了更高的安全性（at()）、便利性（size()、迭代器）和类型安全，在开启编译器优化后，其性能与手写的C风格数组代码完全相同。\r\n如何实现？下面是几个关键点：\r\n\r\nsize(): size() 函数返回的是模板参数\r\nN，它是一个编译时常量。编译器在编译时就可以直接将\r\narr.size() 替换为具体数字（例如\r\n5）。这个函数调用在最终的机器码中不存在(也就是说根本不存在这样一个size变量或者函数调用)\r\noperator[], begin(), end():\r\n这些函数非常简单，通常只有一条返回语句。编译器可以轻易地进行内联\r\n(inlining)，即把函数调用替换为函数体本身。最终生成的汇编代码与直接操作C风格数组的指针或索引完全一样(没有额外的函数调用开销)。\r\n范围for循环: for (auto&amp; element :\r\narr)之所以能工作，是因为编译器会将其转换为基于迭代器的代码 for (auto it\r\n= arr.begin(); it != arr.end(); ++it)。由于 begin() 和 end()\r\n会被内联，最终的循环代码与操作C风格数组的指针循环效率相同。\r\n\r\n类型系统与模板元编程\r\ntd::array 的强大之处在于它将数组的大小 N\r\n融入了类型系统。std::array&lt;int, 5&gt; 和 std::array&lt;int, 10&gt;\r\n是完全不同的、不兼容的类型, 因为 N 是一个非类型模板参数\r\n(non-type template parameter)。\r\n\r\n非类型模板参数是指模板参数不是一个类型，而是一个值（如整数、枚举值、指针等）。在\r\nstd::array 中，N 是一个 std::size_t\r\n类型的非类型模板参数，表示数组的大小。\r\n\r\n这使得我们可以在编译时捕获许多错误。例如，试图将一个\r\nstd::array&lt;int, 5&gt; 赋值给 std::array&lt;int, 10&gt;\r\n会导致编译错误，而不是运行时错误。\r\n同时, 还可以防止数组退化：当把 std::array\r\n传递给函数时，传递的是一个完整的对象，函数签名中包含了确切的大小信息。编译器可以检查类型匹配，不会再出现数组退化为指针、丢失大小信息的问题。\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"排序算法","url":"/2025/09/29/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"排序算法是计算机科学中用于将一组数据按照特定顺序进行排列的算法。本节不讨论\r\nC++ STL中的排序算法，而是介绍一些基本的排序算法及其实现。\r\n对于当前的排序算法, 主要分为两大类: 1. 比较排序算法\r\n(Comparison-based Sorting Algorithms):\r\n这些算法通过比较元素之间的大小关系来决定它们的顺序。常见的比较排序算法包括快速排序\r\n(Quick Sort)、归并排序 (Merge\r\nSort)、堆排序 (Heap Sort) 、冒泡排序\r\n(Bubble Sort) 和插入排序 (Insertion Sort) 等。 2.\r\n非比较排序算法 (Non-comparison-based Sorting\r\nAlgorithms):\r\n这些算法不直接比较元素的大小，而是利用元素的特定属性进行排序。常见的非比较排序算法包括计数排序\r\n(Counting Sort)、基数排序 (Radix Sort)\r\n和桶排序 (Bucket Sort) 等。\r\n插入排序 (Insertion Sort)\r\n插入排序是一种简单直观的排序算法，适用于小规模数据集。它的基本思想是将数组分为已排序和未排序两部分，然后逐步将未排序部分的元素插入到已排序部分的正确位置。\r\nvoid InsertSorting(vector&lt;int&gt;&amp; nums){  if(nums.size()&lt;=1) return;  // 如果向量为空或只有一个元素，则它已经是有序的  // 从第二个元素（索引为 1）开始遍历  // 我们假设第一个元素（索引为 0）构成了初始的已排序子序列  for(int i=1;i&lt;nums.size();i++){    // 1. 选定当前需要插入的元素并保存起来    //    `key` 是我们要在 `nums[0...i-1]` 这个已排序序列中找到合适位置的元素    int key = nums[i];    // 2. 在已排序序列中从后向前查找, `j` 指向已排序序列的最后一个元素    int j = i-1;    // 3. 移动元素    //    循环条件：    //    a. `j &gt;= 0`：确保我们没有越过数组的起始边界    //    b. `nums[j] &gt; key`：如果当前已排序序列中的元素 `nums[j]` 大于 `key`    //    //    操作：    //    将 `nums[j]` 向右移动一位到 `nums[j+1]`    //    然后 `j` 向前移动一位，继续与 `key` 比较    while(j&gt;=0 &amp;&amp; nums[j]&gt;key){      nums[j+1] = nums[j];   // 元素向右移动      j--;            // 索引向前移动    }    // 4. 插入元素    //    当循环停止时，`j` 的位置有两种可能：    //    a. `j = -1`：意味着 `key` 比所有已排序的元素都小，应放在最前面（索引 0）。    //    b. `nums[j] &lt;= key`：意味着 `key` 应该插入到 `nums[j]` 的后面。    //        //    在这两种情况下，`j + 1` 都是 `key` 应该在的正确位置。    nums[j + 1] = key;  }}\r\n它的特点包括: - 时间复杂度：平均和最坏情况下为\r\nO(n^2)，最好情况下为 O(n)。 -\r\n空间复杂度：O(1)，属于原地排序算法。 -\r\n稳定性：插入排序是稳定的排序算法。 -\r\n适用场景：适用于小规模数据集或部分有序的数据集。\r\n冒泡排序 (Bubble Sort)\r\n冒泡排序是一种简单的排序算法，其基本思想是通过重复遍历要排序的数列，比较相邻元素并交换它们的位置，使得较大的元素逐渐“冒泡”到数列的末端。\r\nvoid BubbleSorting(vector&lt;int&gt;&amp; nums){  int n = nums.size();  if(n&lt;=1) return; // 如果向量为空或只有一个元素，则它已经是有序的  // 1. 外层循环：控制总共需要进行的“趟数”  //    对于 n 个元素，最多需要 n-1 趟。  //    i 表示已经有多少个元素被“冒泡”到了它们在数组末尾的最终位置。  //    i 不到 n-1 是因为最后一个元素在前面的趟数中已经被排序好了。  for (int i = 0; i &lt; n - 1; ++i) {            // 2. 优化标志：      //    设置一个标志 `swapped`，用于检查在这一趟中是否发生了交换。      //    如果在一整趟内层循环中都没有发生交换，说明数组已经有序，      //    可以提前终止排序。      bool swapped = false;      // 3. 内层循环：执行一趟冒泡      //    j 遍历当前未排序的部分。      //    比较的范围是 nums[0] 到 nums[n - 1 - i]。      //    \"- i\" 是因为数组末尾的 i 个元素在之前的趟数中已经被确定是最大的，无需再比较。      //    \"- 1\" 是因为我们要比较 j 和 j+1。      for (int j = 0; j &lt; n - 1 - i; ++j) {                    // 4. 比较和交换          //    如果前一个元素 (nums[j]) 大于后一个元素 (nums[j+1])          if (nums[j] &gt; nums[j + 1]) {                            // 执行交换，将较大的元素向右“冒泡”              std::swap(nums[j], nums[j + 1]);                            // 标记在这一趟中发生了交换              swapped = true;          }      }      // 5. 检查优化标志      //    如果这一趟 (整个内层 j 循环) 没有任何交换发生      if (!swapped) {          // 说明数组已经完全有序，跳出外层循环          break;      }  }}\r\n它的特点包括: - 时间复杂度：平均和最坏情况下为\r\nO(n^2)，最好情况下为 O(n)。 -\r\n空间复杂度：O(1)，属于原地排序算法。 -\r\n稳定性：冒泡排序是稳定的排序算法。 -\r\n适用场景：适用于小规模数据集，但通常不如插入排序高效。\r\n快速排序 (Quick Sort)\r\n快速排序是一种高效的排序算法，采用分治法的思想。基本步骤如下：\r\n1. 选择基准 (Pivot)：从数组中挑选一个元素，称为“基准”或“枢轴”(pivot)。\r\n2. 分区\r\n(Partition)：重新排列数组，将所有小于基准的元素移动到基准的左边，所有大于基准的元素移动到基准的右边。在此操作之后，基准元素就位于其最终的排序位置。\r\n3. 递归\r\n(Recurse)：递归地对基准左边的子数组和基准右边的子数组应用上述步骤。\r\n// 快速排序的递归辅助函数void quickSortRecursive(std::vector&lt;int&gt;&amp; nums, int low, int high) {        // 递归的基线条件 (Base Case):    // 如果子数组有 0 或 1 个元素 (low &gt;= high)，则它已经有序。    if (low &lt; high) {  // 开始 partitioning                 // 1. 选取基准 (Pivot)        //    我们选择这个子数组的最后一个元素 (nums[high]) 作为 pivot。        int pivotValue = nums[high];        // 2. 初始化 \"小于\" 区域的边界        //    `i` 用来追踪 \"小于\" pivot 区域的最后一个元素的索引。        //    初始时，这个区域是空的，所以 i 设置为 low - 1。        int i = low - 1;        // 3. 遍历子数组 (从 low 到 high-1)        //    `j` 是当前正在检查的元素。        for (int j = low; j &lt; high; ++j) {                        // 4. 比较当前元素与 pivot            //    如果当前元素 nums[j] 小于 pivotValue            if (nums[j] &lt; pivotValue) {                                // 5. 扩展 \"小于\" 区域                //    将 `i` 向右移动一位，并与 `nums[j]` 交换。                //    这确保了 [low...i] 范围内的所有元素都小于 pivot。                i++;                std::swap(nums[i], nums[j]);            }        }        // 6. 将 pivot 放到正确的位置        //    循环结束后，[low...i] 都是小于 pivot 的。        //    [i+1...high-1] 都是大于等于 pivot 的。        //    因此，pivot (它在 nums[high]) 应该在的位置是 i + 1。        std::swap(nums[i + 1], nums[high]);        // 7. 获取 pivot 的最终索引        //    这个索引 'pi' 将用于分割下一次递归。        int pi = i + 1;                // 8. 递归排序左半部分        //    对 pivot 左边的子数组 (从 low 到 pi - 1) 进行快速排序。        quickSortRecursive(nums, low, pi - 1);        // 9. 递归排序右半部分        //    对 pivot 右边的子数组 (从 pi + 1 到 high) 进行快速排序。        quickSortRecursive(nums, pi + 1, high);    }}void QuickSort(std::vector&lt;int&gt;&amp; nums) {    int n = nums.size();    if (n &lt;= 1) return;        // 调用递归辅助函数，对整个数组 (索引 0 到 n-1) 进行排序    quickSortRecursive(nums, 0, n - 1);}\r\n它的特点包括: - 时间复杂度：平均情况下为 O(n\r\nlog n)，最坏情况下为 O(n^2)（当数组已经有序或接近有序时）。 -\r\n空间复杂度：O(log n)，主要用于递归调用栈空间。 -\r\n不稳定性：快速排序通常是不稳定的排序算法。 -\r\n适用场景：适用于大规模数据集，是实际应用中非常常用的排序算法。\r\n\r\n优化:\r\n为了避免最坏情况，可以采用随机选择基准或三数取中法来选择基准元素。\r\n\r\n快速选择\r\n快速选择 (Quickselect) 是一种用于在无序数组中查找第 k\r\n大/小元素的高效算法。它基于快速排序的分区思想，但只递归处理包含第\r\nk 小元素的那一部分数组，从而提高效率。\r\n例如, 给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。(LC\r\n215)\r\nclass Solution {public:    int partition(vector&lt;int&gt;&amp; nums, int left, int right){        int pivot_val = nums[right];        int i = left-1;        int pivot_cnt = 1;        for(int j=left;j&lt;right;j++){            if(nums[j]&lt;pivot_val){                i++;                swap(nums[i], nums[j]);            }else if(nums[j] == pivot_val){                if (pivot_cnt % 2 == 1) {   // 将大量的和基准元相同的元素均匀分布                    i++;                    swap(nums[i], nums[j]);                }                pivot_cnt++;             }        }        swap(nums[right], nums[i+1]);  // 从而最终pivot位于相对中间位置        return i;    }    int findKthLargest(vector&lt;int&gt;&amp; nums, int k) {        int n = nums.size();        int target_index = n-k;        int left = 0, right = n-1;        while(left&lt;=right){            int pivot_index = partition(nums, left, right);            if(pivot_index==target_index){                return nums[pivot_index];            }else if(pivot_index&lt;target_index){                left = pivot_index+1;            }else{                right = pivot_index-1;            }        }        return -1;    }};\r\n这里的partition函数与快速排序中的类似，但为了处理大量重复元素的情况，做了一些调整，使得与基准相同的元素均匀分布，避免退化。\r\n而findKthLargest函数则只关注包含第 k\r\n大元素的那一半子数组，其平均时间复杂度为 O(n)。\r\n\r\n&lt;algorithms&gt;标准库中的\r\nstd::nth_element\r\n函数就是基于快速选择算法实现的，可以用来高效地找到第 k 大/小元素。 例如,\r\nnth_element(v.begin(), v.begin() + (k - 1), v.end());\r\n会将第 k 小的元素放到正确的位置上, 并且保证该位置左边的元素都不大于它,\r\n右边的元素都不小于它.\r\n\r\n桶排序\r\n桶排序 (Bucket Sort)\r\n是一种非比较排序算法，适用于均匀分布的数据。它的基本思想是将数据分布到多个“桶”中，然后对每个桶内的数据进行排序，最后再将所有桶中的数据合并起来。\r\nvoid bucketSort(std::vector&lt;int&gt;&amp; nums, int bucketSize) {    if (nums.empty()) return;    // 1. 找到数据的最小值和最大值    int minValue = *std::min_element(nums.begin(), nums.end());    int maxValue = *std::max_element(nums.begin(), nums.end());    // 2. 计算桶的数量    int bucketCount = (maxValue - minValue) / bucketSize + 1;    std::vector&lt;std::vector&lt;int&gt;&gt; buckets(bucketCount);    // 3. 将元素分配到各个桶中    for (int num : nums) {        int bucketIndex = (num - minValue) / bucketSize;        buckets[bucketIndex].push_back(num);    }    // 4. 对每个桶内的元素进行排序（这里使用插入排序）    nums.clear();    for (auto&amp; bucket : buckets) {        InsertSorting(bucket);  // 使用前面定义的插入排序函数        nums.insert(nums.end(), bucket.begin(), bucket.end());    }}\r\n其特点包括: - 时间复杂度：平均情况下为 O(n +\r\nk)，其中 n 是元素数量，k 是桶的数量。最坏情况下为\r\nO(n^2)（当所有元素都落入同一个桶时）。 - 因为每个桶内使用插入排序,\r\n有k个桶, 每个桶平均有n/k个元素, 所以每个桶排序的时间复杂度为O((n/k)^2),\r\n总共k个桶, 所以总时间复杂度为O(k*(n/k)^2) = O(n^2/k). 当k接近n时,\r\n时间复杂度接近O(n). - 空间复杂度：O(n + k)，需要额外的空间来存储桶。 -\r\n稳定性：桶排序是稳定的排序算法（取决于桶内排序算法）。\r\n-\r\n适用场景：适用于均匀分布的数据集，尤其是当数据范围较大且元素数量较少时。\r\n堆排序\r\n堆排序 (Heap Sort)\r\n是一种基于堆数据结构的比较排序算法。它的基本思想是将数组构建成一个最大堆，然后不断地将堆顶元素（最大值）与数组的最后一个元素交换，并缩小堆的范围，重复此过程直到堆为空。\r\nvoid heapify(std::vector&lt;int&gt;&amp; nums, int n, int i) {    int largest = i;       // 初始化最大值为根节点    int left = 2 * i + 1; // 左子节点    int right = 2 * i + 2; // 右子节点    // 如果左子节点比根节点大    if (left &lt; n &amp;&amp; nums[left] &gt; nums[largest])        largest = left;    // 如果右子节点比当前最大值还大    if (right &lt; n &amp;&amp; nums[right] &gt; nums[largest])        largest = right;    // 如果最大值不是根节点    if (largest != i) {        std::swap(nums[i], nums[largest]); // 交换        // 递归地堆化受影响的子树        heapify(nums, n, largest);    }}\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"List","url":"/2025/09/28/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/List/","content":"std::list\r\n是一个序列容器，它的底层实现是双向链表（Doubly-Linked\r\nList）。理解了“双向链表”这个数据结构，就理解了 std::list\r\n的所有优缺点和行为特性。\r\nstd::list 的核心特性\r\n与 std::vector（动态数组）的连续内存布局截然不同，std::list\r\n的元素在内存中是非连续存储的。每个元素（节点）都包含三部分信息：\r\n\r\n存储的数据本身。\r\n一个指向前一个元素节点的指针 (prev)。\r\n一个指向后一个元素节点的指针 (next)。\r\n\r\n这种结构赋予了 std::list 一系列独特的特性：\r\n\r\n快速的插入和删除: 这是 std::list\r\n最主要的优点。在链表的任何位置（开头、中间、结尾）插入或删除一个元素，时间复杂度都是常数时间\r\nO(1)（前提是你已经有了指向该位置的迭代器）。\r\n\r\n原因：插入/删除操作只需要修改相邻节点的 next 和 prev\r\n指针，将新节点“链接”进去或将旧节点“断开链接”，而不需要像 std::vector\r\n那样移动大量后续元素。\r\n\r\n慢速的随机访问: 这是 std::list\r\n最主要的缺点。它不支持快速的随机访问。\r\n\r\n由于内存不连续，你无法像数组那样通过计算偏移量来直接定位到第 n\r\n个元素。要访问第 n\r\n个元素，必须从头节点（或尾节点）开始，沿着指针逐个遍历 n\r\n次。因此，访问操作的时间复杂度是线性时间 O(n)。\r\n\r\n正因如此，std::list 没有提供 operator[] 访问符。\r\n\r\n迭代器稳定性: 这是一个非常重要的优点。向 std::list\r\n中插入或删除元素，不会导致指向其他元素的迭代器失效。\r\n\r\n插入或删除只影响被操作节点及其邻居的指针，其他节点在内存中的位置和它们之间的链接关系保持不变。而在\r\nstd::vector 中，一次插入或删除就可能导致所有或部分迭代器失效。\r\n\r\n更高的内存开销: 相比 std::vector，std::list\r\n的每个元素都需要额外的空间来存储前向和后向指针，因此总的内存占用会更大。\r\n\r\n常用操作\r\n使用 std::list 需要包含头文件 。\r\n初始化\r\n#include &lt;list&gt;std::list&lt;int&gt; myList; // 创建一个空的整数列表std::list&lt;int&gt; myList2 = {1, 2, 3, 4, 5}; // 使用初始化列表创建std::list&lt;int&gt; myList3(myList2); // 通过拷贝另一个列表创建std::list&lt;int&gt; myList4(10, 42); // 指定个数和初始化内容创建, 创建一个包含10个42的列表\r\n添加元素\r\nstd::list 提供了在头部和尾部快速添加元素的方法。 #include &lt;list&gt;#include &lt;iostream&gt;std::list&lt;int&gt; myList;// 在尾部添加元素myList.push_back(10); // {10}myList.push_back(20); // {10, 20}// 在头部添加元素 (vector 没有这个方法)myList.push_front(5); // {5, 10, 20}\r\n删除元素\r\n同样，std::list 也能在头部和尾部快速删除元素 myList.pop_back();  // 删除尾部元素 {5, 10}myList.pop_front(); // 删除头部元素 {10}\r\n遍历\r\n遍历 std::list 通常使用迭代器或范围 for 循环。 std::list&lt;int&gt; numbers = {1, 2, 3, 4, 5};for (int num : numbers) {    std::cout &lt;&lt; num &lt;&lt; \" \"; // 输出: 1 2 3 4 5}for (auto it = numbers.begin(); it != numbers.end(); ++it) {    std::cout &lt;&lt; *it &lt;&lt; \" \"; // 输出: 1 2 3 4 5}\r\n在中间插入和删除\r\n使用 insert() 和 erase()\r\n方法，需要一个指向特定位置的迭代器。 auto it = numbers.begin(); // it 指向 1++it; // it 指向 2// 在 it 指向的位置(2)之前插入 99numbers.insert(it, 99); // {1, 99, 2, 3, 4, 5}numbers.insert(it+2, 100); // 注意这是错误的用法, list 迭代器不支持随机访问// 删除 it 指向的元素(2)// erase 会返回指向被删除元素下一个元素的迭代器it = numbers.erase(it); // {1, 99, 3, 4, 5}\r\n同样, erase()成功后迭代器会自动前进一位, 需要额外考虑\r\nstd::list 特有的高效操作\r\nstd::list 提供了一些 std::vector\r\n所没有的高效成员函数，这些函数充分利用了其链表结构的优势，通过直接操纵节点指针来完成，避免了元素的拷贝。\r\n\r\nsplice()：将一个 list 的全部或部分元素“剪切”并“粘贴”到另一个 list\r\n中。这是一个 O(1) 的操作，非常高效。\r\nmerge()：将一个已排序的 list 合并到另一个已排序的 list\r\n中，并保持排序。\r\nsort()：std::list 拥有自己的 sort()\r\n成员函数。不能使用全局的 std::sort()，因为 std::sort\r\n要求随机访问迭代器，而 list 的迭代器是双向的。\r\nreverse()：反转链表中元素的顺序。\r\nunique()：移除连续的重复元素。\r\n\r\n什么时候应该使用 std::list\r\n根据以上对比，我们可以得出结论, 你应该在以下情况考虑使用\r\nstd::list：\r\n\r\n需要频繁地在序列的任意位置（尤其是中间）进行插入和删除操作。\r\n对迭代器的稳定性有很高的要求，不希望因为插入/删除操作而需要频繁更新迭代器。\r\n不需要进行频繁的随机访问操作。\r\n\r\n现代 C++ 的观点和建议是, 尽管 std::list\r\n在特定场景下有其理论上的优势，但在现代 C++ 编程中，std::vector\r\n仍然是绝大多数场景下的首选默认容器。\r\n原因是现代计算机的 CPU\r\n拥有多级缓存（Cache）。std::vector\r\n的连续内存布局具有极佳的缓存友好性，CPU\r\n可以预取数据，从而大大加快遍历速度。而 std::list\r\n的节点分散在内存各处，遍历时会导致频繁的缓存未命中（Cache\r\nMiss），这带来的性能损失往往会抵消其 O(1) 插入/删除的理论优势。\r\n除非你的程序经过性能分析（Profiling），明确显示出瓶颈在于 std::vector\r\n的中间插入/删除，否则请优先使用 std::vector。\r\n"},{"title":"算法","url":"/2025/10/20/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95/","content":"算法（Algorithm）是解决特定问题的一系列步骤或规则的集合。在计算机科学中，算法通常用于处理数据、执行计算和解决各种问题。C++\r\n标准库（STL）提供了丰富的算法支持，涵盖了排序、搜索、修改等多种操作。\r\nstd::sort：最常用的排序算法\r\n这是最常使用的排序算法\r\n\r\n特点：速度极快，但不保证稳定性。\r\n底层实现：通常是内省排序\r\n(Introsort)，一种混合排序算法。它首先使用快速排序，当递归深度过深时转为堆排序以防止最坏情况，最后对小分区使用插入排序进行优化。\r\n时间复杂度：平均为 O(NlogN)。\r\n\r\n它的函数签名如下: template&lt; class RandomIt &gt;void sort( RandomIt first, RandomIt last );  // RandomIt 必须是随机访问迭代器, 参数是迭代器的范围 [first, last)template&lt; class RandomIt, class Compare &gt;void sort( RandomIt first, RandomIt last, Compare comp );  // 使用自定义比较函数 comp, 可以是函数指针或函数对象\r\n这里重点介绍第二个版本, 它允许我们传入一个自定义的比较函数\r\ncomp, 常常使用lambda表达式来定义排序规则。\r\n这个比较函数接受两个参数,\r\n返回一个布尔值, 用于定义排序的顺序。 例如,\r\n如果我们想要按降序排序一个整数数组, 可以这样写: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {5, 2, 8, 1, 3};    // 使用自定义比较函数进行降序排序    std::sort(vec.begin(), vec.end(), [](int a, int b) {        return a &gt; b;    });    // 输出排序结果    for (const auto&amp; elem : vec) {        std::cout &lt;&lt; elem &lt;&lt; \" \";    }    return 0;}\r\n返回的布尔值表示: 如果 comp(a, b) 返回\r\ntrue, 则 a 应该排在 b 前面。\r\nstd::reverse：反转序列\r\nstd::reverse 是 C++ STL 中用于反转一个范围内元素顺序的算法。它定义在\r\n 头文件中。使用时只需提供要反转的范围的迭代器。\r\n函数签名如下: template&lt; class BidirIt &gt;void reverse( BidirIt first, BidirIt last ); - BidirIt:\r\n双向迭代器类型，表示可以向前和向后遍历的迭代器。 - first:\r\n指向要反转范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要反转范围的结束位置的迭代器（不包含该位置）。\r\n该函数会将 [first, last) 范围内的元素顺序进行反转。例如:\r\n#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};    // 反转整个向量    std::reverse(vec.begin(), vec.end());    // 输出反转后的结果    for (const auto&amp; elem : vec) {        std::cout &lt;&lt; elem &lt;&lt; \" \"; // 输出: 5 4 3 2 1    }    return 0;}\r\nstd::accumulate：累加求和\r\nstd::accumulate 是 C++ STL 中用于计算范围内元素累加和的算法。它定义在\r\n 头文件中。使用时需要提供要累加的范围的迭代器以及一个初始值。\r\n函数签名如下: template&lt; class InputIt, class T &gt;T accumulate( InputIt first, InputIt last, T init ); - InputIt:\r\n输入迭代器类型，表示可以读取元素的迭代器。 - first:\r\n指向要累加范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要累加范围的结束位置的迭代器（不包含该位置）。 - init:\r\n累加的初始值。\r\n该函数会将 [first, last) 范围内的元素与初始值\r\ninit 进行累加，并返回最终的结果。例如: #include &lt;numeric&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};    // 计算向量元素的累加和，初始值为0    int sum = std::accumulate(vec.begin(), vec.end(), 0);    std::cout &lt;&lt; \"Sum: \" &lt;&lt; sum &lt;&lt; std::endl; // 输出: Sum: 15    return 0;}\r\nstd::advance：迭代器前进\r\nstd::advance 是 C++ STL\r\n中用于将迭代器前进或后退指定步数的算法。它定义在\r\n&lt;iterator&gt;\r\n头文件中。使用时需要提供一个迭代器和一个整数值，表示要前进（正值）或后退（负值）的步数。\r\n函数签名如下: template&lt; class InputIt, class Distance &gt;void advance( InputIt&amp; it, Distance n ); - InputIt:\r\n迭代器类型，表示可以读取元素的迭代器。 - it: 要前进或后退的迭代器引用。\r\n- n: 要前进（正值）或后退（负值）的步数。 该函数会将迭代器\r\nit 前进或后退 n 步。例如: #include &lt;iterator&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {10, 20, 30, 40, 50};    auto it = vec.begin();    // 将迭代器前进2步    std::advance(it, 2);    std::cout &lt;&lt; \"Element after advancing 2 steps: \" &lt;&lt; *it &lt;&lt; std::endl; // 输出: 30    // 将迭代器后退1步    std::advance(it, -1);    std::cout &lt;&lt; \"Element after retreating 1 step: \" &lt;&lt; *it &lt;&lt; std::endl; // 输出: 20    return 0;}\r\nstd::count：计数元素出现次数\r\nstd::count 是 C++ STL\r\n中用于计算范围内某个特定值出现次数的算法。它定义在 \r\n头文件中。使用时需要提供要搜索的范围的迭代器以及要计数的值。\r\n函数签名如下: template&lt; class InputIt, class T &gt;typename std::iterator_traits&lt;InputIt&gt;::difference_typecount( InputIt first, InputIt last, const T&amp; value ); - InputIt:\r\n输入迭代器类型，表示可以读取元素的迭代器。 - first:\r\n指向要搜索范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要搜索范围的结束位置的迭代器（不包含该位置）。 - value:\r\n要计数的特定值。 - 返回值: 范围内等于 value\r\n的元素数量。\r\n该函数会计算并返回 [first, last) 范围内等于\r\nvalue 的元素数量。例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 2, 3, 2, 4, 2, 5};    // 计算数字2在向量中出现的次数    int count_of_2 = std::count(vec.begin(), vec.end(), 2);    std::cout &lt;&lt; \"Count of 2: \" &lt;&lt; count_of_2 &lt;&lt; std::endl; // 输出: Count of 2: 3    return 0;}\r\nstd::find：查找元素\r\nstd::find 是 C++ STL 中用于在范围内查找特定值的算法。它定义在\r\n\r\n头文件中。使用时需要提供要搜索的范围的迭代器以及要查找的值。\r\n函数签名如下: template&lt; class InputIt, class T &gt;InputIt find( InputIt first, InputIt last, const T&amp; value ); - InputIt:\r\n输入迭代器类型，表示可以读取元素的迭代器。 - first:\r\n指向要搜索范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要搜索范围的结束位置的迭代器（不包含该位置）。 - value:\r\n要查找的特定值。 - 返回值: 指向第一个等于 value\r\n的元素的迭代器；如果未找到，则返回 last。 该函数会在\r\n[first, last) 范围内查找第一个等于 value\r\n的元素，并返回其迭代器。例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {10, 20, 30, 40, 50};    // 查找数字30在向量中的位置    auto it = std::find(vec.begin(), vec.end(), 30);    if (it != vec.end()) {        std::cout &lt;&lt; \"Found 30 at position: \" &lt;&lt; std::distance(vec.begin(), it) &lt;&lt; std::endl; // 输出: Found 30 at position: 2    } else {        std::cout &lt;&lt; \"30 not found in the vector.\" &lt;&lt; std::endl;    }    return 0;}\r\nstd::transform：转换元素\r\nstd::transform 是 C++ STL\r\n中用于对范围内的元素应用指定操作并将结果存储到另一个范围的算法。它定义在\r\n\r\n头文件中。使用时需要提供要转换的范围的迭代器、目标范围的起始迭代器以及一个函数或函数对象。\r\n函数签名如下: template&lt; class InputIt, class OutputIt, class UnaryOperation &gt;OutputIt transform( InputIt first1, InputIt last1,                      OutputIt d_first, UnaryOperation unary_op ); - InputIt:\r\n输入迭代器类型，表示可以读取元素的迭代器。 - OutputIt:\r\n输出迭代器类型，表示可以写入元素的迭代器。 - UnaryOperation:\r\n一元操作函数或函数对象类型。 - first1:\r\n指向要转换范围的起始位置的迭代器（包含该位置）。 - last1:\r\n指向要转换范围的结束位置的迭代器（不包含该位置）。 - d_first:\r\n指向目标范围起始位置的迭代器。 - unary_op:\r\n应用于每个元素的一元操作函数或函数对象。\r\n该函数会对 [first1, last1) 范围内的每个元素应用\r\nunary_op，并将结果存储到从 d_first\r\n开始的目标范围中。例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 2, 3, 4, 5};    std::vector&lt;int&gt; result(vec.size());    // 将每个元素乘以2并存储到result中    std::transform(vec.begin(), vec.end(), result.begin(),                   [](int x) { return x * 2; });    // 输出转换后的结果    for (const auto&amp; elem : result) {        std::cout &lt;&lt; elem &lt;&lt; \" \"; // 输出: 2 4 6 8 10    }    return 0;}\r\nstd::unique：移除重复元素\r\nstd::unique 是 C++ STL 中用于移除范围内连续重复元素的算法。它定义在\r\n 头文件中。使用时需要提供要处理的范围的迭代器。 函数签名如下:\r\ntemplate&lt; class ForwardIt &gt;ForwardIt unique( ForwardIt first, ForwardIt last ); - ForwardIt: 前向迭代器类型，表示可以向前遍历的迭代器。 -\r\nfirst: 指向要处理范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要处理范围的结束位置的迭代器（不包含该位置）。 - 返回值:\r\n指向新范围结束位置的迭代器。 该函数会移除 [first, last)\r\n范围内的连续重复元素，并返回新范围的结束位置。例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 1, 2, 2, 3, 3, 3, 4, 4, 5};    // 移除连续重复元素    auto new_end = std::unique(vec.begin(), vec.end());    // 输出处理后的结果    for (auto it = vec.begin(); it != new_end; ++it) {        std::cout &lt;&lt; *it &lt;&lt; \" \"; // 输出: 1 2 3 4 5    }    return 0;}\r\n如果要对整个容器进行去重，通常会先对容器进行排序，然后再调用\r\nstd::unique，最后使用容器的 erase 方法删除多余的元素。\r\n#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {4, 2, 1, 3, 2, 4, 5, 1};    // 先排序    std::sort(vec.begin(), vec.end());    // 移除重复元素    auto new_end = std::unique(vec.begin(), vec.end());    // 删除多余的元素    vec.erase(new_end, vec.end());    // 输出去重后的结果    for (const auto&amp; elem : vec) {        std::cout &lt;&lt; elem &lt;&lt; \" \"; // 输出: 1 2 3 4 5    }    return 0;}\r\nstd::lower_bound 和\r\nstd::upper_bound\r\nstd::lower_bound 和 std::upper_bound 是 C++ STL\r\n中用于在有序范围内查找元素位置的算法。它们定义在 \r\n头文件中。使用时需要提供要搜索的范围的迭代器以及要查找的值。\r\n函数签名如下: template&lt; class ForwardIt, class T &gt;ForwardIt lower_bound( ForwardIt first, ForwardIt last, const T&amp; value );ForwardIt upper_bound( ForwardIt first, ForwardIt last, const T&amp; value ); - ForwardIt:\r\n前向迭代器类型，表示可以向前遍历的迭代器。 - first:\r\n指向要搜索范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要搜索范围的结束位置的迭代器（不包含该位置）。 - value:\r\n要查找的特定值。 - 返回值: - lower_bound\r\n返回指向第一个大于等于 value\r\n的元素的迭代器。 - upper_bound 返回指向第一个大于\r\nvalue 的元素的迭代器。 - 如果未找到符合条件的元素，则返回\r\nlast。\r\n\r\n它们的名字看上去都“往上找”，但为什么一个叫 lower（下界）、一个叫\r\nupper（上界） 呢？ 这个名字来源于数学中的“上下确界”概念: - lower_bound\r\n找到的是“下确界”（greatest lower\r\nbound），即第一个大于等于给定值的元素位置。 - upper_bound\r\n找到的是“上确界”（least upper bound），即第一个大于给定值的元素位置。\r\n例如: v = {1, 3, 3, 5, 7} - 对于 value = 3, lower_bound\r\n返回指向第一个 3 的迭代器, 即索引1的位置(3的下边界) -\r\n假如你要插入value, lower_bound 找到的是可以放下 value\r\n的最早位置（lower edge） - 而 upper_bound\r\n返回指向第一个大于3的元素5的迭代器,\r\n即索引3的位置(3的上边界, 不包含3本身) - 假如你要插入value, upper_bound\r\n找到的是 value “延伸结束”的上边界（upper edge）\r\n\r\n这两个函数通常用于有序范围内的二分查找。例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {1, 2, 4, 4, 5, 6, 8};    int value = 4;    // 查找 lower_bound    auto lower = std::lower_bound(vec.begin(), vec.end(), value);    std::cout &lt;&lt; \"Lower bound of \" &lt;&lt; value &lt;&lt; \" is at position: \"               &lt;&lt; std::distance(vec.begin(), lower) &lt;&lt; std::endl; // 输出: 2(索引位置), 即第一个4的位置    // 查找 upper_bound    auto upper = std::upper_bound(vec.begin(), vec.end(), value);    std::cout &lt;&lt; \"Upper bound of \" &lt;&lt; value &lt;&lt; \" is at position: \"               &lt;&lt; std::distance(vec.begin(), upper) &lt;&lt; std::endl; // 输出: 4(索引位置), 即第一个大于4的元素的位置    return 0;}\r\nstd:: min_element 和 std::\r\nmax_element\r\nstd::min_element 和 std::max_element 是 C++ STL\r\n中用于查找范围内最小和最大元素的算法。它们定义在 \r\n头文件中。使用时需要提供要搜索的范围的迭代器。其内部使用线性搜索算法来查找最小和最大元素,\r\n复杂度为 O(N)。\r\n函数签名如下: template&lt; class ForwardIt &gt;ForwardIt min_element( ForwardIt first, ForwardIt last );ForwardIt max_element( ForwardIt first, ForwardIt last ); - ForwardIt:\r\n前向迭代器类型，表示可以向前遍历的迭代器。 - first:\r\n指向要搜索范围的起始位置的迭代器（包含该位置）。 - last:\r\n指向要搜索范围的结束位置的迭代器（不包含该位置）。 - 返回值: -\r\nmin_element 返回指向范围内最小元素的迭代器。 -\r\nmax_element 返回指向范围内最大元素的迭代器。 -\r\n如果范围为空，则返回 last。\r\n例如: #include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;iostream&gt;int main() {    std::vector&lt;int&gt; vec = {5, 2, 8, 1, 3};    // 查找最小元素    auto min_it = std::min_element(vec.begin(), vec.end());    if (min_it != vec.end()) {        std::cout &lt;&lt; \"Minimum element: \" &lt;&lt; *min_it &lt;&lt; std::endl; // 输出: 1    }    // 查找最大元素    auto max_it = std::max_element(vec.begin(), vec.end());    if (max_it != vec.end()) {        std::cout &lt;&lt; \"Maximum element: \" &lt;&lt; *max_it &lt;&lt; std::endl; // 输出: 8    }    return 0;}\r\n","categories":["language"],"tags":["language","cpp"]},{"title":"概念","url":"/2025/10/01/lang/CPP/%E5%9F%BA%E7%A1%80/%E6%A6%82%E5%BF%B5/","content":"变量相关\r\n全局变量若在其他文件中使用，需要用extern关键字声明(告诉编译器该变量在其他文件中定义)，否则会报错”未定义的引用”。\r\n// file1.cppint globalVar = 42; // 定义全局变量 // file2.cppextern int globalVar; // 声明全局变量\r\n若用”static”修饰的全局变量，仅限当前文件使用，避免与其他文件同名变量冲突。\r\n// file1.cppstatic int staticGlobalVar = 100; // 仅在 file1.cpp 中可见\r\n静态局部变量在函数内定义，生命周期贯穿程序运行，但作用域仅限函数内部,\r\n可保留上次的值 void func() {    static int count = 0; // 静态局部变量    count++;    std::cout &lt;&lt; \"Function called \" &lt;&lt; count &lt;&lt; \" times.\" &lt;&lt; std::endl;}// 每次调用 func() 时，count 的值都会递增，而不是每次都重新初始化为 0。\r\n全局变量默认初始化为零，静态局部变量也会被自动初始化为零，而普通局部变量则不进行自动初始化，使用前必须手动赋值\r\n在之前, 静态成员变量必须在类外部单独定义，以便为其分配存储空间\r\nclass MyClass {public:    static int staticMember; // 声明静态成员变量};int MyClass::staticMember = 0; // 定义并初始化静态成员变量 不过, C++17 引入了内联变量(inline\r\nvariable)的概念, 允许在类内直接初始化静态成员变量,\r\n这样就不需要在类外单独定义了 class MyClass {public:    inline static int staticMember = 0; // C++17 及以上版本允许这样做};\r\nnew操作符从自由存储区上为对象动态分配内存空间 自由存储区是 C++\r\n语言抽象出的概念，用来描述 new 和 delete\r\n操作符进行动态内存分配和释放时所使用的内存区域。一般来说，自由存储区对应于操作系统提供的堆内存（heap\r\nmemory）, 但程序员可以重载 operator\r\nnew，让自由存储区从非堆内存（如一个预先分配好的内存块或内存池）进行分配，从而绕过标准的堆分配机制，这在嵌入式系统或高性能计算中非常重要。\r\n如果constexpr声明中定义了一个指针变量，那么该指针必须在编译时就能确定其指向的地址。(constexpr仅对指针有效，和所指对象无关)\r\nconstexpr int value = 42;constexpr int* ptr = &amp;value; // 合法，因为 &amp;value 是一个常量表达式\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"堆","url":"/2025/10/01/lang/CPP/STL%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%A0%86/","content":"堆 (Heap)\r\n堆也称作优先队列,\r\n是一种特殊的树形数据结构，满足堆性质：在最大堆中，父节点的值总是大于等于其子节点的值；在最小堆中，父节点的值总是小于等于其子节点的值。\r\n在 C++ 中，可以使用标准库中的 std::priority_queue\r\n来实现堆, 需要头文件\r\n&lt;queue&gt;。默认情况下，std::priority_queue\r\n实现的是最大堆。如果需要实现最小堆，可以通过自定义比较函数来实现:\r\nstd::priority_queue&lt;Type, std::vector&lt;Type&gt;, std::greater&lt;Type&gt;&gt; minHeap;\r\n函数签名: template&lt;    class T,    class Container = std::vector&lt;T&gt;,    class Compare = std::less&lt;typename Container::value_type&gt;&gt; class priority_queue; - T：堆中存储的元素类型。 -\r\nContainer：底层容器类型，默认是\r\nstd::vector&lt;T&gt; -\r\nCompare：比较函数对象类型，默认是\r\nstd::less，用于实现最大堆。使用 std::greater\r\n可以实现最小堆。\r\n构造函数: -\r\npriority_queue()：默认构造函数，创建一个空堆。 -\r\npriority_queue(InputIt first, InputIt last)：使用范围\r\n[first, last) 内的元素构造堆。\r\n\r\n不能在构造函数中直接传入 n\r\n来表示堆的大小，因为堆的大小是动态变化的，可以通过 push 和\r\npop 操作来调整。\r\n\r\n标准库中的堆主要支持以下操作: -\r\npush(const Type&amp; value)：将元素 value 插入堆中,\r\n复杂度为 O(log n)。 - pop()：移除堆顶元素, 复杂度为 O(log\r\nn), 因为需要重新调整堆结构。 - top()：返回堆顶元素,\r\n复杂度为 O(1)。 - empty()：检查堆是否为空。 -\r\nsize()：返回堆中元素的数量。 #include &lt;queue&gt;#include &lt;vector&gt;#include &lt;functional&gt;  // 用于 std::greaterint main() {    // 最大堆    std::priority_queue&lt;int&gt; maxHeap;    maxHeap.push(3);    maxHeap.push(1);    maxHeap.push(4);    int maxTop = maxHeap.top();  // maxTop = 4    maxHeap.pop();  // 移除最大元素 4    // 最小堆    std::priority_queue&lt;int, std::vector&lt;int&gt;, std::greater&lt;int&gt;&gt; minHeap;    minHeap.push(3);    minHeap.push(1);    minHeap.push(4);    int minTop = minHeap.top();  // minTop = 1    minHeap.pop();  // 移除最小元素 1    std::vector&lt;int&gt; nums = {5, 2, 8, 1, 3};    std::priority_queue&lt;int&gt; heap(nums.begin(), nums.end());  // 使用范围构造函数初始化堆, 复杂度为 O(n), 比逐个push更高效    return 0;}\r\n对顶堆 (Dual Heaps)\r\n对顶堆是一种同时维护最大堆和最小堆的数据结构，常用于动态数据流中查找中位数等问题。通过将数据分为两部分，最大堆存储较小的一半元素，最小堆存储较大的一半元素，可以高效地获取中位数。\r\n例如 LC295: 数据流的中位数, 实现一个支持以下两种操作的数据结构: -\r\nvoid addNum(int num) - 从数据流中添加一个整数到数据结构中。\r\n- double findMedian() - 返回目前所有元素的中位数。\r\nclass MedianFinder {private:    priority_queue&lt;int&gt; maxHeap; // 存储较小一半的元素    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minHeap; // 存储较大一半的元素public:    MedianFinder() {}    // 我们的目的是保持两个堆的大小尽量平衡, 即 maxHeap 的大小要么等于 minHeap, 要么比 minHeap 多 1    void addNum(int num) {        maxHeap.push(num);   // 在添加新元素时, 先将其添加到最大堆中        minHeap.push(maxHeap.top());  // 然后将最大堆的堆顶元素移动到最小堆中(因为此时最大堆的堆顶可能大于最小堆的堆顶)        maxHeap.pop();        if(maxHeap.size()&lt; minHeap.size()){ // 保持两个堆的大小平衡            maxHeap.push(minHeap.top());            minHeap.pop();        }    }        double findMedian() {        if(maxHeap.empty()) return 0;        if(maxHeap.size()&gt;minHeap.size()) return (double)maxHeap.top();  // 如果最大堆比最小堆多一个元素, 则中位数就是最大堆的堆顶        else return (double)(maxHeap.top()+minHeap.top())/2;  // 否则中位数就是两个堆顶的平均值            }};/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder* obj = new MedianFinder(); * obj-&gt;addNum(num); * double param_2 = obj-&gt;findMedian(); */ 下面是 addNum\r\n函数的详细步骤说明(先假定再平衡)\r\n\r\n插入新元素到最大堆\r\n首先将 num 插入到 maxHeap，即\r\nmaxHeap.push(num);。此时，maxHeap\r\n可能出现一个“叛徒”元素（即最大值），它实际上应该属于“后半部分”。\r\n维护排序不变性\r\n将 maxHeap 的堆顶元素（最大值）移动到\r\nminHeap：\r\nint elementToMove = maxHeap.top();maxHeap.pop();minHeap.push(elementToMove); 这样可以保证\r\nmaxHeap.top() &lt;= minHeap.top()，即“排序不变性”得到满足。\r\n维护平衡不变性\r\n经过前两步，maxHeap 和 minHeap\r\n的元素数量可能失衡。需要检查并调整：\r\nif (minHeap.size() &gt; maxHeap.size()) {     int elementToMoveBack = minHeap.top();     minHeap.pop();     maxHeap.push(elementToMoveBack);} 这样可以保证\r\nmaxHeap.size() &gt;= minHeap.size()，即“平衡不变性”得到满足。\r\n\r\n\r\n总结：每次 addNum 操作的时间复杂度为 O(log N)。\r\n\r\n堆中元素是pair\r\n堆中的元素类型可以是\r\nstd::pair，这在需要根据多个属性进行排序时非常有用。堆的排序是基于\r\npair\r\n的第一个元素进行的，如果第一个元素相等，则比较第二个元素。\r\n例如LC347: 给你一个整数数组 nums 和一个整数 k\r\n，请你返回其中出现频率前 k 高的元素。你可以按 任意顺序 返回答案。\r\nclass Solution {public:    vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) {        unordered_map&lt;int, int&gt; freq_map;        for(const auto&amp; num:nums){            freq_map[num]++;        }        // num: freq        priority_queue&lt;pair&lt;int,int&gt;, vector&lt;pair&lt;int,int&gt;&gt;, greater&lt;pair&lt;int,int&gt;&gt;&gt; minHeap;        for(const auto&amp; pair: freq_map){            int number = pair.first;            int freq = pair.second;            minHeap.push({freq, number});            if(minHeap.size()&gt;k){                minHeap.pop();            }        }        vector&lt;int&gt; ans;        while(!minHeap.empty()){            ans.push_back(minHeap.top().second);            minHeap.pop();        }        return ans;    }}; 这里我们的目的当然是要频率最高的 k 个元素,\r\n因此我们使用了最小堆来维护当前频率最高的 k\r\n个元素。但是如果堆中之存储频率的话, 那么当有多个元素频率相同的时候,\r\n我们就无法区分到底是哪些元素了. 因此我们需要再堆中存储一个 pair,\r\n不过在建立哈希表的时候, 我们是以 num 为 key, freq 为 value 的,\r\n因此在插入堆的时候, 如果直接插入 {num, freq} 这样的话, 堆会根据 num\r\n来排序, 这显然是不对的. 因此我们需要将 pair 的顺序反过来, 插入一个临时的\r\n{freq, num}, 这样堆就会根据 freq 来排序了.\r\nO(N) 建堆\r\n堆的构建可以通过两种主要方法完成：逐个插入元素和使用“堆化”过程。逐个插入元素的时间复杂度为\r\nO(N log N)，而使用堆化过程的时间复杂度为\r\nO(N)。下面介绍如何使用堆化过程来高效地构建堆。\r\n\r\n标准库中的 std::make_heap 函数,\r\n以及构造函数中直接传入迭代器起始位置都是使用堆化的方法将一个范围内的元素转换为堆结构，时间复杂度为\r\nO(N)。\r\n\r\nvoid sift_down(std::vector&lt;int&gt;&amp; heap, int n, int rootIndex) {    // 步骤说明：将当前根节点视为最大值    int largest = rootIndex;         // 步骤说明：计算左右子节点的索引 (0-based 索引)    int leftChild = 2 * rootIndex + 1;    int rightChild = 2 * rootIndex + 2;    // 步骤说明：检查左子节点是否存在，并且是否大于当前最大值    if (leftChild &lt; n &amp;&amp; heap[leftChild] &gt; heap[largest]) {        largest = leftChild;    }    // 步骤说明：检查右子节点是否存在，并且是否大于当前最大值    if (rightChild &lt; n &amp;&amp; heap[rightChild] &gt; heap[largest]) {        largest = rightChild;    }    // 步骤说明：如果根节点不是最大的 (largest != rootIndex)    if (largest != rootIndex) {        // 步骤说明：将最大值交换到根节点        std::swap(heap[rootIndex], heap[largest]);        // 步骤说明：由于交换，原根节点的值被“下沉”到了 largest 位置，        // 必须递归地对以 largest 为根的新子树继续执行下沉操作。        sift_down(heap, n, largest);    }    // 否则，根节点已经是最大值，符合堆性质，停止操作。}void build_heap(std::vector&lt;int&gt;&amp; arr) {    int n = arr.size();        // 步骤说明：找到最后一个非叶子节点。    // 在 0-based 索引中，最后一个元素是 n-1，    // 其父节点索引是 floor((n-1 - 1) / 2) = floor(n / 2) - 1。    int lastParent = (n / 2) - 1;    // 步骤说明：从最后一个非叶子节点开始，自底向上，    // 依次对每个节点执行“下沉”操作。    for (int i = lastParent; i &gt;= 0; i--) {        sift_down(arr, n, i);    }}\r\n我们将一个数组（arr）视为一个“完全二叉树”。所有的叶子节点（在数组的后半部分，约\r\nN/2 个）天然地满足堆的定义（因为它们没有子节点）。\r\n我们从最后一个非叶子节点开始，向前遍历到根节点（arr[0]）。\r\n\r\n最后一个非叶子节点在数组中的索引是 (N/2) - 1。\r\n对遍历到的每个节点，执行一次\r\nsift-down（下滤）操作。\r\n\r\nsift-down\r\n就是比较该节点与其子节点，如果不满足堆属性（例如最小堆中父节点比子节点大），就将它与较小的子节点交换，交换后，原节点\r\ni 的值（现在位于 left或right\r\n处）可能又小于了它新的子节点，因此必须递归地对 left 位置继续调用\r\nsift_down\r\n\r\n\r\n复杂度数学证明（O(N)）： - 假设堆的高度为 h（h ≈ log N）。 -\r\n堆中高度为 0 的节点（即叶子节点）有 N/2 个。它们不需要下滤，工作量为 0。\r\n- 堆中高度为 1 的节点（叶子的父节点）有 N/4 个。它们最多下滤 1 层。 -\r\n堆中高度为 2 的节点有 N/8 个。它们最多下滤 2 层… - 堆中高度为 h\r\n的节点（根节点）有 1 个。它最多下滤 h 层。 - 总工作量 S = (N/4 * 1) +\r\n(N/8 * 2) + (N/16 * 3) + … + (1 * h), 可以近似计算为 S ≈ N * (1/2 + 1/4\r\n+ 1/8 + … ) = N * 1 = O(N)。\r\n","categories":["language","CPP"],"tags":["language"]},{"url":"/2025/10/24/lang/CPP/%E5%B8%B8%E7%94%A8%E5%BA%93/%E6%97%B6%E9%97%B4%E5%BA%93_chrono/","content":"\r\n"},{"title":"Intro to AI, Rational Agents","url":"/2025/08/03/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/1/","content":"第一章笔记是该课程的开篇介绍, 核心是定义什么是智能体 (Agent)\r\n以及智能体所处的环境 (Environment)\r\n智能体 (Agents)\r\nAI的中心问题是创建一个理性的智能体 (rational agent)\r\n。理性智能体是一个拥有目标或偏好，并试图执行一系列行动以期在这些目标下获得最佳（或最优）期望结果的实体\r\n。\r\n\r\n智能体的“理性”并非指无所不知或完美，而是在其知识范围内做出最优的期望选择。\r\n\r\n智能体的构成与环境：\r\n\r\n智能体存在于一个环境 (environment)\r\n中，该环境是针对特定智能体实例的 。\r\n智能体通过传感器 (sensors) 与环境交互，并通过执行器 (actuators)\r\n对环境施加影响 。\r\n智能体与其所处的环境共同构成一个世界 (world)\r\n。例如，一个跳棋程序的“世界”就是虚拟棋盘和对手 。\r\n\r\n\r\n环境类型 (Types of\r\nEnvironments)\r\n智能体的设计在很大程度上取决于其所处环境的类型\r\n。因此，理解环境的属性至关重要。根据不同的分类依据,\r\n智能体所处的环境可以有如下几种:\r\n\r\n可观察性 (Observability)：\r\n\r\n在完全可观察 (fully observable) 的环境中，智能体完全了解其状态\r\n。\r\n在部分可观察 (partially observable)\r\n的环境中，智能体无法获得关于状态的全部信息，因此必须维护一个对世界状态的内部估计\r\n。\r\n\r\n确定性 (Determinism)：\r\n\r\n在确定性 (deterministic)\r\n环境中，在特定状态下执行一个行动只有一个确定的结果 。\r\n在随机性 (stochastic)\r\n环境中，转移模型存在不确定性，即一个行动可能有多个不同概率的结果\r\n。\r\n\r\n智能体数量 (Number of Agents)：\r\n\r\n在多智能体 (multi-agent) 环境中，一个智能体需要与其他智能体共同行动\r\n。为了避免行为被其他智能体预测，它可能需要将其行动随机化 (randomize)\r\n。\r\n\r\n动态性 (Dynamism)：\r\n\r\n如果环境在智能体行动时不会发生变化，则称之为静态 (static) 环境\r\n。\r\n动态 (dynamic) 环境则会随着智能体的交互而改变 。\r\n\r\n物理规则 (Physics)：\r\n\r\n如果环境具有已知的物理规则 (known\r\nphysics)，智能体就了解其转移模型（即使是随机的），并可以在规划时利用这些知识\r\n。\r\n如果物理规则是未知的\r\n(unknown)，智能体则需要通过有目的的行动来学习这些动态规律 。\r\n\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Bayes Nets -- Inference(12)","url":"/2025/08/23/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/12/","content":"上一讲我们学会了如何用贝叶斯网络来紧凑地表示一个复杂的联合概率分布。这一讲的核心问题是：有了这个紧凑的表示，我们如何高效地进行计算，从而回答概率查询(也就是推理问题)？\r\n\r\n推理问题可以分为精确推理和近似推理,\r\n这一节我们考虑精确推理\r\n\r\n首先, 假如我们有一个完整的联合概率分布表,\r\n只需要查表就可以得到所要的结果, 但是在贝叶斯网络的基础上,\r\n我们有一种更智能的算法，能够在不生成完整联合分布的情况下完成推理。这个算法就是变量消除\r\n(Variable Elimination)。\r\n变量消除 (Variable\r\nElimination)\r\n变量消除是一种高效的精确推理算法，其核心思想是通过重新排列计算顺序来避免重复计算。\r\n当我们想计算某个变量的边缘概率或条件概率时，不需要先计算出整个联合概率分布，而是通过将求和操作推入乘积内部，逐一消去无关的变量，从而大大降低计算复杂度。这个过程被称为“求和-乘积”算法（Sum-Product\r\nAlgorithm）。\r\n整个过程可以概括为以下四个主要步骤：\r\n\r\n初始化:\r\n将贝叶斯网络中的每一个条件概率表（CPT）视为一个独立的因子（Factor）。这些因子是关于其所依赖变量的函数。\r\n迭代消除变量:\r\n根据预定的消除顺序，逐一处理每个需要被消除的变量。对于每个待消除的变量，执行以下操作：\r\n\r\n\r\n找出相关因子：找到所有包含该变量的因子。\r\n因子相乘：将这些相关因子全部相乘，生成一个新的、更大的临时因子。\r\n求和消除：对这个新的临时因子，关于待消除的变量进行求和（或积分）。这个操作的结果是一个不包含该变量的新因子。\r\n更新因子集：将原始的相关因子从集合中移除，并将新生成的因子加入到集合中。\r\n\r\n\r\n重复直至求出目标:\r\n重复第二步，直到所有需要被消除的变量都被处理完毕。此时，剩下的因子只包含我们所查询的目标变量（以及任何给定的证据变量）。\r\n最终计算与归一化:\r\n将所有剩余的因子相乘，得到一个包含目标变量边缘概率的最终因子。如果需要计算条件概率，最后一步还要进行归一化处理，使所有可能结果的概率之和为1。\r\n\r\n\r\n示例分析\r\n让我们通过一个简单的”草地湿润”例子来展示变量消除的过程。\r\n假设我们有一个包含四个二元变量（真/假）的贝叶斯网络： -\r\nC：多云（Cloudy） - S：洒水器打开（Sprinkler On） - R：下雨（Rain） -\r\nW：草地湿润（Grass is Wet）\r\n这个网络的依赖关系如下图所示： - C→S - C→R\r\n- S→W - R→W\r\n对应的条件概率表（CPT）如下（为了便于计算，我们使用简单的数值）：\r\nP(C): - P(C = T) = 0.5 -\r\nP(C = F) = 0.5\r\nP(S|C): |\r\nC | S=T | S=F | |:–|:—–|:—–| | T | 0.1 | 0.9 | | F | 0.5 | 0.5 |\r\nP(R|C): |\r\nC | R=T | R=F | |:–|:—–|:—–| | T | 0.8 | 0.2 | | F | 0.1 | 0.9 |\r\nP(W|S, R):\r\n| S | R | W=T | W=F | |:–|:–|:—–|:—–| | T | T | 0.99 | 0.01 | | T | F |\r\n0.9 | 0.1 | | F | T | 0.9 | 0.1 | | F | F | 0.0 | 1.0 |\r\n我们的目标是：计算草地湿润的边缘概率 P(W = T)。\r\n变量消除法的具体过程：\r\n步骤 1: 建立联合概率分布表达式\r\n首先，根据贝叶斯网络的结构，我们可以使用链式法则将整个网络的联合概率分布表示为所有节点的条件概率的乘积：\r\nP(C, S, R, W) = P(C) ⋅ P(S|C) ⋅ P(R|C) ⋅ P(W|S, R)\r\n步骤 2: 设定求和表达式\r\n为了得到 P(W = T)，我们需要对除了\r\nW 以外的所有变量进行求和（即积分），并将 W 的状态设定为 T：\r\nP(W = T) = ∑C∑S∑RP(C, S, R, W = T)\r\n如果直接进行计算，我们需要构建一个包含 24 = 16\r\n种组合的巨大表格，然后逐行求和。变量消除法通过改变求和顺序来优化这个过程。\r\n步骤 3: 确定消除顺序和重写表达式\r\n变量消除法的关键是将求和操作推入乘积内部。我们可以选择一个合适的消除顺序（例如，在本例中我们按\r\nC→R→S 的顺序进行消除），将上一步的表达式改写为：\r\nP(W = T) = ∑S∑R[∑CP(C) ⋅ P(S|C) ⋅ P(R|C)] ⋅ P(W = T|S, R)\r\n为什么要这样做？这样改写后，我们每次只对表达式中的一小部分进行求和，而不是对整个联合概率分布求和。每次求和的结果是一个新的”因子”或”表格”，这个新表格的维度比原始联合分布小得多。\r\n步骤 4: 逐个消除变量\r\n\r\n消除变量 C\r\n\r\n我们首先计算表达式中与 C 相关的那一部分：\r\nf1(S, R) = ∑CP(C) ⋅ P(S|C) ⋅ P(R|C)\r\n这个新的因子 f1(S, R)\r\n是一个关于 S 和 R 的表格。它代表了 P(S, R)\r\n的联合概率分布。\r\n我们来计算 f1(S, R)\r\n表格中的每一项：\r\nf1(S = T, R = T)：\r\n\r\nf1(S = T, R = F)：\r\n\r\nf1(S = F, R = T)：\r\n\r\nf1(S = F, R = F)：\r\n\r\n\r\n消除变量 R\r\n\r\n将上一步得到的 f1(S, R)\r\n因子与 P(W = T|S, R)\r\n相乘，并对 R 求和。我们得到一个新的因子 f2(S, W = T)：\r\nf2(S, W = T) = ∑Rf1(S, R) ⋅ P(W = T|S, R)\r\nf2(S = T, W = T)：\r\n\r\nf2(S = F, W = T)：\r\n\r\n\r\n消除变量 S\r\n\r\n最后，我们对剩下的因子 f2(S, W = T)\r\n进行求和，得到最终结果 P(W = T)：\r\n\r\n结论和总结： 通过变量消除法，我们成功计算出了 P(W = T)\r\n的精确值，为 0.62235。\r\n计算代价对比\r\n1. 暴力计算法的计算量\r\n目标：计算 P(W = T) = ∑C∑S∑RP(C, S, R, W = T)\r\n步骤 1:\r\n构建完整的联合概率分布表\r\n为了计算联合概率分布 P(C, S, R, W)，我们需要为每个可能的变量组合（2 × 2 × 2 × 2 = 16 种组合）计算其概率值。\r\n每一行的计算都需要将四个概率相乘：P(C) ⋅ P(S|C) ⋅ P(R|C) ⋅ P(W|S, R)。这涉及到\r\n3 次乘法。\r\n例如，计算第一行 P(C = T, S = T, R = T, W = T)：\r\n0.5 × 0.1 × 0.8 × 0.99 （3次乘法）\r\n总乘法次数：16 行 × 3 次乘法/行 = 48 次乘法。\r\n步骤 2: 对变量 C, S, R 求和\r\n在得到完整的16行联合概率表之后，我们需要找出所有 W=T 的行（共有 23 = 8\r\n行），然后将它们的概率值相加。\r\n总加法次数：将 8 个数字相加需要 7 次加法。\r\n暴力计算法总结\r\n\r\n总计算量：48 次乘法 + 7 次加法 = 55 次运算\r\n内存需求：需要存储一个包含 16 行的完整联合概率表\r\n\r\n2. 变量消除法的计算量\r\n现在我们回顾一下变量消除法的每一步，并统计运算次数。\r\n步骤 1: 消除变量 C，生成因子\r\nf1(S, R)\r\n这个因子 f1(S, R)\r\n是一个 2 × 2 的表格，有 4\r\n个条目。计算每个条目都需要一次求和，求和的每一项都是三个概率的乘积。\r\n例如： f1(S = T, R = T) = [P(C = T)P(S = T|C = T)P(R = T|C = T)] + [P(C = F)P(S = T|C = F)P(R = T|C = F)]\r\n计算一个条目所需的运算： - 方括号内各有 2 次乘法，共 2 × 2 = 4 次乘法 - 两个方括号相加，需要 1\r\n次加法\r\n总运算量：4 个条目 × (4 次乘法 + 1 次加法) = 16 次乘法 + 4 次加法\r\n内存需求：生成一个包含 4 行的新表 f1(S, R)\r\n步骤 2: 消除变量 R，生成因子\r\nf2(S, W = T)\r\n这个因子 f2(S, W = T)\r\n是一个 2 × 1 的表格，有 2 个条目。\r\n例如： f2(S = T, W = T) = [f1(S = T, R = T) ⋅ P(W = T|S = T, R = T)] + [f1(S = T, R = F) ⋅ P(W = T|S = T, R = F)]\r\n计算一个条目所需的运算： - 方括号内各有 1 次乘法，共 1 × 2 = 2 次乘法 - 两个方括号相加，需要 1\r\n次加法\r\n总运算量：2 个条目 × (2 次乘法 + 1 次加法) = 4 次乘法 + 2 次加法\r\n内存需求：生成一个包含 2 行的新表 f2(S, W = T)\r\n步骤 3: 消除变量\r\nS，得到最终结果 P(W = T)\r\nP(W = T) = f2(S = T, W = T) + f2(S = F, W = T)\r\n总运算量：1 次加法\r\n变量消除法总结\r\n\r\n总乘法次数：16 + 4 = 20 次乘法\r\n总加法次数：4 + 2 + 1 = 7 次加法\r\n总计算量：20 次乘法 + 7 次加法 = 27 次运算\r\n内存需求：在整个计算过程中，我们创建的最大的中间表是 f1(S, R)，它只有\r\n4 行\r\n\r\n信念传播（Belief Propagation,\r\nBP）\r\n信念传播 (Belief Propagation, BP)\r\n是一种在概率图模型（如贝叶斯网络或马尔可夫随机场）上进行推断的算法。它的核心思想可以被形象地描述为：图中的每个节点都是一个独立的计算单元，它们通过相互之间“传递消息”\r\n(passing messages) 来不断更新自己对某个变量状态的“信念” (belief)。\r\n\r\n信念 (Belief)：指的是一个节点（变量）的边际概率分布 (Marginal\r\nProbability\r\nDistribution)。简单来说，就是综合了图中所有可用信息后，我们对这个变量取不同值的可能性有多大的判断。\r\n消息\r\n(Message)：一个节点传递给其邻居节点的信息。这个消息总结了除了从那个邻居接收到的信息之外，它所知道的所有其他信息。这就像是在说：“嘿，这是我从其他所有人那里听到的所有消息汇总，现在我告诉你，但不包括你告诉我的那部分。”\r\n\r\n信念传播算法通过一个迭代的消息传递过程来计算每个节点的信念。我们可以把它分为两种主要情况：\r\n在树状结构图上：精确推断\r\n当概率图的结构是一个树 (Tree) 或者 多义树\r\n(Polytree)（即图中没有任何无向环路）时，信念传播是一种精确推断算法。它能准确地计算出每个变量的边际概率。\r\n步骤说明：\r\n初始化: 随机选择一个根节点。\r\n消息收集 (从叶到根):\r\n从图的叶子节点开始，每个节点收集来自其子节点的所有消息，然后计算并向其父节点发送一条新的消息。这个过程一直持续到根节点收到了来自其所有子节点的消息。\r\n消息分发 (从根到叶):\r\n根节点收到所有消息后，开始向其子节点分发消息。然后，每个节点再根据从父节点收到的消息，计算并向它的子节点继续分发消息，直到消息传递到所有的叶子节点。\r\n计算信念:\r\n当每个节点都收到了来自其所有邻居的消息后，它就可以利用这些消息来计算自己的最终信念（即边际概率）。\r\n为什么是精确的？\r\n因为在树状结构中，从任何一个邻居传来的信息路径都是唯一的，信息不会“绕一圈”回来，所以消息的传递不会产生冗余或循环依赖，保证了计算的准确性。\r\n在带环路的图上：环路信念传播\r\n(Loopy Belief Propagation)\r\n当图中存在环路 (Cycles)\r\n时，情况就变得复杂了。一个节点发出的消息可能会沿着环路绕一圈后，又以某种形式传回给自己。这违反了标准信念传播算法的基本假设。\r\n在这种情况下，我们使用的算法被称为 环路信念传播 (Loopy Belief\r\nPropagation, LBP)。\r\n核心思想:\r\n尽管理论上不再保证准确性，但我们可以假装图没有环路，然后像在树上一样，让所有节点并行地、迭代地向邻居发送消息。\r\n步骤说明:\r\n初始化: 用随机值或均匀分布初始化所有消息。\r\n迭代更新:\r\n在每一步迭代中，每个节点都根据它上一轮从邻居那里收到的消息，计算并更新它将要发送给邻居的新消息。\r\n重复:\r\n重复这个过程，直到消息收敛（即消息值不再有明显变化）或者达到预设的最大迭代次数。\r\n计算信念: 算法停止后，用最后一次迭代的消息来估算每个节点的信念。\r\n结果: LBP\r\n是一种近似推断算法。它不保证能收敛，即使收敛了，其计算出的信念也只是真实边际概率的一个近似值。然而，在实践中，LBP\r\n在许多应用（如计算机视觉、纠错码领域）中都表现得非常出色，常常能给出很好的近似结果。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Bayes Nets -- Sampling(13)","url":"/2025/08/25/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/13/","content":"上一讲我们学习了变量消除等算法，它们能精确地计算出概率查询的结果。但我们也知道，精确推理在最坏情况下是NP难的，对于非常庞大和复杂的贝叶斯网络，精确计算仍然是不可行的。\r\n这一讲的核心思想是：当我们无法承担精确计算的巨大代价时，我们可以退而求其次，通过生成大量随机样本来“近似”地估算概率。这种方法被称为近似推理\r\n(Approximate Inference)，而采样 (Sampling) 是实现它的核心技术。\r\n先验采样\r\n(Prior Sampling)和拒绝采样 (Rejection Sampling)\r\n先验采样是最基础、最简单的采样方法,\r\n它直接模拟贝叶斯网络的生成过程来创建一个完整的样本。\r\n算法流程为:\r\n\r\n按照贝叶斯网络的拓扑顺序（从父节点到子节点）遍历所有变量。\r\n对于每个变量 X，根据其条件概率表 P(X|Parents(X))（此时其所有父节点的值都已被采样确定），随机采样一个值赋给\r\nX。\r\n重复此过程，直到所有变量都被赋值，就得到了一个完整的样本。\r\n\r\n显而易见,\r\n这种方法非常低效，尤其是在处理带证据的查询时。如果我们想计算 P(C|−t)，而 $P(-t)\r\n的概率只有1%。那么，先验采样生成的样本中，大约有99%的样本都会因为 T=+t\r\n而与证据不符，这些样本最终都会被丢弃。为了得到足够多的有效样本，我们需要生成海量的总样本，造成巨大的计算浪费。\r\n而拒绝采样就是对先验采样的一个简单优化。它在生成样本的过程中，一旦发现某个变量的采样值与证据不符，就立刻停止并拒绝这个样本，然后重新开始一个新的。\r\n它避免了为那些注定要被丢弃的样本浪费后续的计算时间。然而,\r\n虽然有所改进，但它仍然没有解决根本问题。在证据本身是小概率事件的情况下，绝大多数的采样尝试仍然会在早期就被拒绝，效率依然很低。\r\n似然加权 (Likelihood\r\nWeighting)\r\n这是本次讲义介绍的第一个真正实用的采样算法，它保证了生成的每一个样本都与证据相符。\r\n核心思想：我们不再随机地生成所有变量的值，而是强制将所有证据变量的值固定为观测到的值。但是，这种“强行设定”会扭曲样本的原始概率分布。为了修正这个偏差，我们为每个样本引入一个权重\r\n(weight)。\r\n\r\n证据变量指的是值固定的变量, 例如P(S ∣ C)中的C;\r\n非证据变量是需要被采样的变量, 例如上述概率公式中的S。\r\n\r\n算法流程（以计算 P(T|+c, +e)\r\n为例）：\r\n\r\n初始化：将样本权重 w 设为 1.0。将证据变量 C 和 E 的值固定为 +c 和\r\n+e。\r\n遍历变量（按拓扑序）：\r\n\r\n对于非证据变量（如 T 和\r\nS）：像先验采样一样，根据其父节点的值进行随机采样。\r\n对于证据变量（如 C 和 E）：不进行采样。而是，将当前样本的权重 w\r\n乘以该证据变量在其父节点取相应值时的条件概率。\r\n例如，当处理到 C 时，我们将权重更新为 w = w * P(+c | tⱼ)，其中 tⱼ\r\n是 T 在当前样本中的采样值。这个乘法操作的含义是：“在给定父节点 tⱼ\r\n的情况下，我们观测到 +c\r\n这个证据的可能性有多大？”这个可能性就被作为权重的一部分。\r\n\r\n最终计算：在收集了足够多的带权样本后，我们不再是简单地计数，而是计算加权计数。例如，要计算\r\nP(+t|+c, +e)，我们将所有\r\nT=+t 的样本的权重相加，然后除以所有样本的总权重。\r\n\r\n原理推导\r\n首先我们给出结论，似然加权方法之所以具有一致性，是因为它通过为样本分配权重，巧妙地使加权后的采样分布等同于真实的全联合概率分布。这意味着，通过对这些加权样本进行求和或计算平均值，我们能够得到对真实概率分布的无偏估计。\r\n\r\n采样分布 SWS(z, e)\r\n\r\n这个公式描述了似然加权算法生成一个特定样本的概率：\r\nSWS(z, e) = ∏jP(zj|parents(Zj))\r\n其中： - z：需要采样的变量集合 - e：固定的证据变量集合 -\r\n显然，这两组变量的并集就是网络中的所有变量。\r\n解释：在似然加权中，我们只对非证据变量进行采样。这个公式是所有被采样变量(zj)的条件概率乘积。例如，如果W是证据变量，那么C,S,R是被采样的变量。这个采样的分布就是P(C) ⋅ P(S|C) ⋅ P(R|C)。\r\n\r\n样本权重 w(z, e)\r\n\r\n这个公式定义了每个生成样本的权重：\r\nw(z, e) = ∏kP(ek|parents(Ek))\r\n解释：这个权重是所有证据变量(ek)的条件概率的乘积，每个证据变量的条件概率是基于其在当前样本中的父节点值。这个权重衡量了当前生成的样本与已知证据的一致程度。\r\n\r\n联合分布的一致性证明\r\n\r\n这是证明似然加权正确性的核心：\r\nSWS(z, e) ⋅ w(z, e) = (∏jP(zj|parents(Zj)))(∏kP(ek|parents(Ek)))\r\n解释：当我们将采样分布和样本权重相乘时，我们得到的是所有变量（包括被采样的zj和证据ek）的条件概率乘积。这正是贝叶斯网络中全联合概率分布的定义：\r\nP(z, e) = ∏iP(Xi|parents(Xi))\r\n当这两部分的结果相乘时，它们精确地、完整地重建了原始的全联合概率分布。这就是为什么加权后的采样分布能够无偏地代表真实的联合概率分布，从而保证了算法的一致性。因此，我们可以得出结论：\r\nSWS(z, e) ⋅ w(z, e) = P(z, e)\r\n示例分析\r\n\r\n网络结构：C→S, C→R, S→W, R→W\r\n查询目标：计算\r\nP(C=T∣S=T,W=T)，即在洒水器打开(S=True)且草地湿润(W=True)的情况下，多云(C=True)的概率\r\n证据变量：e={S=T,W=T}\r\n非证据变量：Z={C,R}\r\n\r\n条件概率表如下:\r\nP(C): | C | P(C) | |:—–:|:——-:| | T | 0.5 |\r\nP(S∣C): | C | P(S=T∣C) | |:—–:|:——-:| | T | 0.1 | |\r\nF | 0.5 |\r\nP(R∣C): | C | P(R=T∣C) | |:—–:|:——-:| | T | 0.8 | |\r\nF | 0.2 |\r\nP(W∣S,R): | S | R | P(W=T∣S,R) | |:—:|:—:|:————-:| |\r\nT | T | 0.99 | | T | F | 0.9 |\r\n下面展示似然加权生成一个样本的全过程:\r\n\r\n初始化\r\n\r\n\r\n证据：S=T,W=T\r\n样本权重：w=1.0\r\n\r\n\r\n处理变量 C\r\n\r\n\r\nC是非证据变量，需采样\r\n根据P(C)采样，结果：C=F\r\n当前样本：{C=F}，w=1.0\r\n\r\n\r\n处理变量 S\r\n\r\n\r\nS为证据变量(S=T)\r\n更新权重：w = w × P(S=T∣C=F) = 1.0 × 0.5 = 0.5\r\n当前样本：{C=F}，w=0.5\r\n\r\n\r\n处理变量 R\r\n\r\n\r\nR是非证据变量，需采样\r\n根据P(R∣C=F)采样，结果：R=T\r\n当前样本：{C=F,R=T}，w=0.5\r\n\r\n\r\n处理变量 W\r\n\r\n\r\nW为证据变量(W=T)\r\n更新权重：w = w × P(W=T∣S=T,R=T) = 0.5 × 0.99 = 0.495\r\n最终样本：{C=F,R=T}，w=0.495\r\n\r\n下面验证”加权采样分布 = 真实联合概率”：\r\n\r\n采样概率SWS(z,e)：\r\n\r\nSWS = P(C=F) × P(R=T∣C=F) = (1-0.5) × 0.2 = 0.1\r\n\r\n样本权重w(z,e)：\r\n\r\nw = P(S=T∣C=F) × P(W=T∣S=T,R=T) = 0.5 × 0.99 = 0.495\r\n\r\n两者相乘：\r\n\r\nSWS × w = 0.1 × 0.495 = 0.0495\r\n\r\n真实联合概率P(z,e)：\r\n\r\nP(C=F,S=T,R=T,W=T) = P(C=F) × P(S=T∣C=F) × P(R=T∣C=F) ×\r\nP(W=T∣S=T,R=T)\r\n= 0.5 × 0.5 × 0.2 × 0.99 = 0.0495\r\n\r\n\r\n可以看出验证的结果是两者完全相等.\r\n重复上述过程多次后，使用以下公式计算：\r\nP(C=T∣S=T,W=T) ≈ 所有的样本的权重之和所有样本的权重总和\r\n这个例子展示了似然加权如何通过采样和加权来模拟真实的联合概率分布，从而计算出所需的条件概率。\r\n缺点与不足\r\n似然加权最大的不足之处是上游变量的值不受下游证据的影响。由于采样过程是前向的（从上游到下游），在对某个变量进行采样时，我们无法利用其子节点（下游）的证据信息。\r\n这意味着如果证据变量位于网络中许多独立的下游节点，每个证据都会使最终的权重呈指数级下降。这可能导致权重变得极小，从而引发数值上的不稳定问题。\r\n同时,\r\n当大多数样本的权重都非常小时，最终的概率估计可能完全由一个或少数几个权重异常大的“幸运”样本决定。这会导致估计的方差很高，结果不稳定。\r\n这个局限性意味着似然加权在进行诊断式推理（从结果推断原因）时效率很低。它生成样本的方式和证据是脱节的，只能在最后通过权重来“亡羊补牢”，这导致了大量的计算浪费。\r\n\n    举个栗子 \n    \n      例如, 让我们构建一个非常简单的贝叶斯网络来模拟交通事故。\r\n\r\n上游变量 (原因): D (司机分心 - Distracted)，可能取值为 T (是) 或\r\nF (否)。\r\n下游变量 (结果): A (发生事故 - Accident)，可能取值为 T (是) 或 F\r\n(否)。\r\n\r\n此时的网络结构为: D→A (司机分心会导致事故)\r\n假设的概率:\r\n\r\nP(D=T)=0.1 (在正常情况下，司机分心的概率是10%)\r\nP(A=T∣D=T)=0.6 (如果司机分心，发生事故的概率是60%)\r\nP(A=T∣D=F)=0.01 (如果司机没分心，发生事故的概率是1%)\r\n\r\n现在，我们有了一个下游证据：确实发生了一场事故\r\n(A=T)。我们的目标是推断上游原因：司机当时分心的概率是多少？即\r\nP(D=T∣A=T)。\r\n从直觉上，既然事故已经发生了，那么司机分心的可能性应该会远高于平时的10%。\r\n现在我们来看似然加权算法是如何一步步处理这个问题的，并观察其局限性。\r\n第1步：采样上游变量 D : 算法开始生成第一个样本。它遇到的第一个变量是\r\nD。算法会问：“我应该如何为 D 采样？”\r\n由于采样过程是纯粹前向的，它完全看不到下游已经发生的事故证据\r\nA=T。它唯一能依据的就是 D 的先验概率分布 P(D)。\r\n\r\n有 10% 的概率，它会采样得到 D=T。\r\n有 90% 的概率，它会采样得到 D=F。\r\n\r\n这就是问题的核心所在！尽管我们知道事故已经发生，这应该让我们更倾向于相信司机分心了，但算法在采样\r\nD 的时候，完全忽略了这个信息。它依然会花费 90%\r\n的精力去生成“司机没有分心”这种与证据非常不符的样本。\r\n第2步：计算权重\r\n在采样完 D 之后，算法才会考虑证据 A=T，并用它来计算权重。\r\n\r\n情况一 (90%的概率发生): 算法在上一步采样得到 D=F。此时的权重\r\nw=P(A=T∣D=F)=0.01。这是一个极低的权重。\r\n情况二 (10%的概率发生): 算法在上一步采样得到 D=T。此时的权重\r\nw=P(A=T∣D=T)=0.6。这是一个相对高很多的权重。\r\n\r\n通过上面的过程，我们可以清晰地看到这个局限性体现在哪里：\r\n\r\n盲目采样：算法在生成样本的“构思”阶段是盲目的。它像一个不知道最终结局的编剧，按照通常的概率写故事的开头（采样上游变量）。\r\n效率低下：算法花费了大量的计算资源（90%的样本）去探索那些几乎不可能导致已知证据（事故）发生的情况（司机没分心）。这些样本最终只会得到一个微不足道的权重，对最终结果的贡献极小。\r\n结果被“幸运样本”主导：最终的概率估计，几乎完全依赖于那少数（10%）采样到了\r\nD=T\r\n的“幸运样本”。如果样本总数不够多，我们可能采不到足够多的幸运样本，导致最终结果的方差很大，非常不稳定。\r\n\r\n\n    \n  \r\n吉布斯采样 (Gibbs Sampling)\r\n这是一种完全不同的采样策略，属于马尔可夫链蒙特卡洛 (Markov Chain\r\nMonte Carlo - MCMC) 方法的一种。\r\n\r\n为了理解吉布斯采样，首先要理解它所属的 MCMC 方法是什么意思: 蒙特卡洛\r\n(Monte Carlo)指代任何依赖于重复随机采样的算法。而马尔可夫链 (Markov\r\nChain)指的是一个状态序列，其中下一个状态的概率只取决于当前状态，而与之前的任何状态都无关\r\n\r\n与似然加权那种“一气呵成”的前向采样不同，吉布斯采样的核心思想是迭代式地修正（Iterative\r\nRefinement）。它不试图一次性生成一个完美的样本，而是从一个随机的、不完美的完整状态开始,\r\n通过轮流地、逐个地对变量进行重新采样来不断修正这个状态。在经过足够多的修正后，这个状态就会稳定下来，并开始在真实的目标概率分布附近“徘徊”。此时的状态就可以被当作一个有效的样本。\r\n基本的算法流程如下：\r\n\r\n初始化：从一个随机的完整状态 x\r\n开始（但证据变量的值是固定的）。\r\n迭代循环：\r\n\r\n选择一个非证据变量 Zᵢ。\r\n重新采样：将 Zᵢ 的当前值“清空”，然后根据所有其他变量的当前值，为\r\nZᵢ 重新采样一个新值。这个新值来自于条件概率分布 P(Zi|mb(Zi))，其中\r\nmb(Z_i) 是 Zᵢ 的马尔可夫毯 (Markov\r\nBlanket)（即它的父节点、子节点、以及子节点的其他父节点）。\r\n\r\n收集样本：每完成一次（或若干次）这样的重采样，当前的状态 x\r\n就被当作一个样本记录下来。\r\n\r\n其优势在于,\r\n吉布斯采样在每次重采样时，都会同时考虑“上游”和“下游”的变量（通过马尔可夫毯），因此信息可以在整个网络中双向传播。这使得它在处理似然加权遇到的“下游证据”问题时通常表现得更好。\r\n示例分析\r\n网络结构如下: C → S, C → R, S → W, R → W\r\n查询目标: P(C = T|S = T, W = T)\r\n\r\n证据变量 (E): S = T, W = T\r\n(值是固定的)\r\n非证据变量 (Z): C, R\r\n(我们需要对它们进行迭代采样)\r\n概率表 (CPT): 我们继续使用之前例子中的概率。\r\n\r\n吉布斯采样 (Gibbs Sampling) 流程为:\r\n步骤 1: 初始化 - 固定证据: 我们将 S 的值锁定为 T，将 W 的值锁定为\r\nT。\r\n\r\n随机初始化: 我们为所有非证据变量 C, R 随机赋一个初始值。\r\n\r\n比如，我们随机选择 C=F 和\r\nR=F。现在，我们的马尔可夫链的初始状态是：C = F, R = F, S = T, W = T。\r\n\r\n\r\n步骤 2: 迭代循环: 我们将轮流对非证据变量 C 和 R 进行重新采样。\r\n首先是第 1 轮迭代\r\nPart A: 重新采样变量 C\r\n\r\n“冻结”其他变量: 将其他所有变量的值固定在当前状态：R = F, S = T, W = T。\r\n计算条件概率: 我们需要计算 P(C|R = F, S = T, W = T)。\r\n\r\nP(C = T|...) ∝ P(C = T, R = F, S = T, W = T)\r\n = P(C = T) ⋅ P(S = T|C = T) ⋅ P(R = F|C = T) ⋅ P(W = T|S = T, R = F)\r\n = (0.5) ⋅ (0.1) ⋅ (0.2) ⋅ (0.9) = 0.009\r\nP(C = F|...) ∝ P(C = F, R = F, S = T, W = T)\r\n = P(C = F) ⋅ P(S = T|C = F) ⋅ P(R = F|C = F) ⋅ P(W = T|S = T, R = F)\r\n = (0.5) ⋅ (0.5) ⋅ (0.8) ⋅ (0.9) = 0.18\r\n归一化并采样:\r\nP(C = T|...) ≈ 0.009/(0.009 + 0.18) ≈ 0.048\r\n(约 5%)\r\nP(C = F|...) ≈ 0.18/(0.009 + 0.18) ≈ 0.952\r\n(约 95%)\r\n根据这个概率，我们为 C 重新采样。有极大概率我们会采样到\r\nC=F。假设我们这次采样的结果就是 C=F。此时更新状态: 系统的当前状态现在是\r\nC = F, R = F, S = T, W = T\r\n(这次 C 的值恰好没变)。\r\nPart B: 重新采样变量 R\r\n\r\n“冻结”其他变量: 将其他变量的值固定在当前最新的状态：C = F, S = T, W = T。\r\n计算条件概率: 我们需要计算 P(R|C = F, S = T, W = T)。\r\n\r\nP(R = T|...) ∝ P(R = T|C = F) ⋅ P(W = T|S = T, R = T)\r\n = (0.2) ⋅ (0.99) = 0.198\r\nP(R = F|...) ∝ P(R = F|C = F) ⋅ P(W = T|S = T, R = F)\r\n = (0.8) ⋅ (0.9) = 0.72\r\n归一化并采样:\r\nP(R = T|...) ≈ 0.198/(0.198 + 0.72) ≈ 0.216\r\n(约 22%)\r\nP(R = F|...) ≈ 0.72/(0.198 + 0.72) ≈ 0.784\r\n(约 78%)\r\n根据这个概率，我们为 R 重新采样。假设这次我们采样的结果是\r\nR=F。然后更新状态: 第1轮迭代结束，系统的最终状态是 C = F, R = F, S = T, W = T。\r\n在之后的第 2 轮迭代 (及后续)中,\r\n我们会重复上面的过程。在第2轮迭代开始时，我们会先重新采样\r\nC，此时它将基于 R = F, S = T, W = T\r\n来计算条件概率（与第一轮相同）。然后，我们会根据新采样的 C\r\n值和固定的证据，再次为 R 重新采样。\r\n随着迭代的进行，状态 C, R\r\n会不断在各种可能的值之间跳转，但跳转的频率会符合它们在证据 S = T, W = T\r\n下的真实后验概率。\r\n步骤 3: 收集样本并得出结论\r\n在经过足够长的”热身”期后，我们开始记录每一轮迭代结束时的状态。例如，我们可能收集到以下10,000个样本（只记录非证据变量）：\r\nC = F, R = F\r\nC = F, R = F\r\nC = F, R = T\r\n…\r\nC = T, R = T\r\n…\r\n最后，我们要回答查询 P(C = T|S = T, W = T)。我们只需要在收集到的10,000个样本中，计算出\r\nC=T 的样本所占的比例即可\r\n理论证明,\r\n只要这个过程重复足够多次，算法生成的样本分布最终会收敛到真实的后验概率分布\r\nP(Q|e)。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"HMMs (Forward Algorithm, Viterbi Algorithm)(15)","url":"/2025/08/26/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/15/","content":"上一讲我们学习了如何对一个状态完全可观察的、随时间演化的系统进行建模和预测。然而，在现实世界中，我们往往无法直接观察到系统的真实状态，只能通过一些间接的、带有噪声的观测来进行推断。\r\n这一讲的核心就是解决这个问题：当系统的真实状态是“隐藏”的时，我们如何通过一系列的观测证据来推断这个隐藏状态？\r\n这个强大的工具就是隐马尔可夫模型 (Hidden Markov Models - HMMs)。\r\n\r\n马尔可夫模型 (Markov Model)：我们能直接看到每天的天气（状态）。\r\n隐马尔可夫模型 (Hidden Markov\r\nModel)：我们看不到真实的天气（状态是隐藏的），但我们每天能看到天气预报（证据/观测）。我们需要根据天气预报来推断真实的天气。\r\n\r\n隐马尔可夫模型 (Hidden\r\nMarkov Models)\r\n\r\nHMM 在马尔可夫模型的基础上，增加了一层可观测的证据变量 (evidence\r\nvariable)****\r\n\r\n状态变量 (State Variable)：Wi，代表在时间 i\r\n的隐藏状态（例如，真实天气）。\r\n证据变量 (Evidence Variable)：Fi，代表在时间 i\r\n的可观测证据（例如，天气预报）。\r\n\r\n因此, 一个平稳的 HMM 可以由三个部分紧凑地表示：\r\n\r\n初始分布：P(W0)，和马尔可夫模型一样。\r\n转移模型：P(Wi + 1|Wi)，和马尔可夫模型一样。\r\n传感器模型 (Sensor Model)：P(Fi|Wi)，这是新增的部分。它描述了在给定真实状态\r\nWᵢ 的情况下，观测到证据 Fᵢ 的概率。\r\n\r\n另一方面, 对于HMM模型, 由于我们往往无法直接得到隐藏状态,\r\n所以更关注两个概念:\r\n\r\n置信度 (Belief) B(Wₜ): 在观测到截至时刻 t 的所有证据后，对状态 Wₜ\r\n的概率分布。即, B(Wₜ) = P(Wₜ|f₁,…,fₜ)\r\n预测置信度 (Predicted Belief) B’(Wₜ): 在观测到截至时刻 t-1\r\n的证据后，对状态 Wₜ 的概率分布。即, B’(Wₜ) = P(Wₜ|f₁,…,fₜ₋₁)\r\n\r\n更多时候, 我们使用 λ = (A, B, π)\r\n代表整个HMM, 其中: - A：状态转移概率矩阵,\r\n表示从一个隐藏状态转移到另一个隐藏状态的概率。 - 如果有 N 个隐藏状态，A\r\n是一个 N×N 的矩阵，其中 A[i][j] 表示从状态 i 转移到状态 j 的概率。 -\r\nB：观测概率矩阵（或称发射概率矩阵）:\r\n表示在某个隐藏状态下，生成某个观测值的概率。 - 如果有 M\r\n个可能的观测值，B 是一个 N×M 的矩阵，其中 B[i][k] 表示在隐藏状态 i\r\n下观察到观测值 k 的概率。 - π：初始状态概率向量:\r\n表示系统在时间 t=1 时处于每个隐藏状态的概率。 - π[i]\r\n是系统一开始处于状态 i 的概率。\r\n前向算法\r\n在隐马尔可夫模型中，我们拥有一系列随时间变化的、不可直接观测的隐藏状态（例如，每天的真实天气\r\nWt），以及在每个时间点上可以观测到的证据（例如，天气预报\r\nFt）。\r\n前向算法的核心目标是计算在观测到所有历史证据后，当前隐藏状态的概率分布。这个分布就是我们前面提到的置信度（Belief）。换句话说，算法要计算的是\r\nP(Wt|f1, f2, ..., ft)，即在已知从第1天到第t天的所有天气预报的情况下，第t天真实天气的概率分布。\r\n前向算法通过一个迭代过程，从 B(Wi)\r\n计算出 B(Wi + 1)。这个过程可以分解为两个关键步骤：时间流逝更新(Time\r\nElapse Update) 和 观测更新 (Observation Update)\r\n第一步：时间流逝更新\r\n(Time Elapse Update)\r\n目标：从当前时刻 i 的置信度 B(Wi)\r\n推导出下一时刻 i+1 的预测置信度 B′(Wi + 1)。这一步相当于在没有看到新证据之前，对未来状态进行预测。\r\n推导过程如下：\r\n\r\n从定义出发：我们想要求解 B′(Wi + 1) = P(Wi + 1|f1, ..., fi)。\r\n\r\n\r\n引入上一时刻的状态 Wi：为了将 B(Wi)\r\n引入计算，我们使用边缘化（Marginalization），对 Wi\r\n的所有可能取值 wi 进行求和:\r\nB′(Wi + 1) = ∑wiP(Wi + 1, wi|f1, ..., fi)\r\n这个公式的意义是，“在已知历史证据的情况下，下一状态为 Wi + 1\r\n的概率”等于”在同样证据下，当前状态为某个具体值 wi 且下一状态为\r\nWi + 1\r\n的所有可能情况的概率之和”。\r\n\r\n\r\n应用条件概率的链式法则：将联合概率 P(Wi + 1, wi|...)\r\n分解: B′(Wi + 1) = ∑wiP(Wi + 1|wi, f1, ..., fi)P(wi|f1, ..., fi)\r\n\r\n\r\n这是条件概率的基本性质，将联合概率分解为两个条件的乘积。\r\n利用HMM的条件独立性假设：HMM假设未来的状态 Wi + 1\r\n仅依赖于当前状态 Wi，而与过去的所有证据\r\nf1, ..., fi\r\n无关。这被称为马尔可夫性。\r\n因此，P(Wi + 1|wi, f1, ..., fi)\r\n可以简化为 P(Wi + 1|wi)，这就是转移模型（Transition\r\nModel）。\r\n\r\n\r\n识别置信度：同时，我们发现 P(wi|f1, ..., fi)\r\n正是当前置信度 B(wi)\r\n的定义。\r\n\r\n\r\n得出最终公式：将简化后的项代入，得到时间更新的最终形式: B′(Wi + 1) = ∑wiP(Wi + 1|wi)B(wi)\r\n这个公式表明，对下一状态的预测是所有可能当前状态的置信度 B(wi)，按照它们各自转移到下一状态的概率\r\nP(Wi + 1|wi)\r\n进行加权求和的结果。\r\n\r\n第二步：观测更新 (Observation\r\nUpdate)\r\n目标：在获得 i+1 时刻的新证据 fi + 1\r\n后，将预测置信度 B′(Wi + 1)\r\n更新为真实置信度 B(Wi + 1)。\r\n推导过程如下：\r\n\r\n从定义出发：我们想要求解 B(Wi + 1) = P(Wi + 1|f1, ..., fi, fi + 1)。\r\n\r\n\r\n应用贝叶斯法则（或条件概率定义）：\r\n我们将求解目标中的条件 fi + 1\r\n移到分子中，形成一个联合概率。\r\n\r\n\r\n引入归一化技巧：分母 P(fi + 1|f1, ..., fi)\r\n是一个常数，因为它不随 Wi + 1\r\n的变化而改变。为了简化计算，我们可以暂时忽略它，用比例关系 ∝ 来表示: B(Wi + 1) ∝ P(Wi + 1, fi + 1|f1, ..., fi)\r\n\r\n\r\n这意味着 B(Wi + 1)\r\n的分布形状由分子决定，我们可以在所有计算完成后再进行归一化，使其概率和为1。\r\n接着再次应用链式法则：对分子进行分解: B(Wi + 1) ∝ P(fi + 1|Wi + 1, f1, ..., fi)P(Wi + 1|f1, ..., fi)\r\n\r\n\r\n利用HMM的条件独立性假设：HMM假设当前证据 fi + 1\r\n仅依赖于当前状态 Wi + 1，而与过去的状态和证据无关。\r\n\r\n\r\n因此，P(fi + 1|Wi + 1, f1, ..., fi)\r\n可以简化为 P(fi + 1|Wi + 1)，这被称为传感器模型（Sensor\r\nModel）。\r\n\r\n\r\n识别预测置信度：同时，我们发现 P(Wi + 1|f1, ..., fi)\r\n正是我们在第一步中计算出的预测置信度 B′(Wi + 1)。\r\n\r\n\r\n得出最终公式：将简化后的项代入，得到观测更新的最终形式, 即: B(Wi + 1) ∝ P(fi + 1|Wi + 1)B′(Wi + 1)\r\n这个公式的意义是，结合新证据后的置信度，与”预测置信度”和”新证据在该状态下的出现概率”的乘积成正比。如果观测到的证据在某个状态下很可能发生，那么这个状态的置信度就会相应提高。\r\n\r\n前向算法的核心\r\n通过将上述两个步骤结合起来，我们就得到了一个从 B(Wi)\r\n计算 B(Wi + 1)\r\n的完整迭代公式：\r\nB(Wi + 1) ∝ P(fi + 1|Wi + 1)B′(Wi + 1)\r\nB(Wi + 1) ∝ P(fi + 1|Wi + 1)∑wiP(Wi + 1|wi)B(wi)\r\n这个公式就是前向算法的核心。从初始置信度 B(W0)\r\n开始，我们可以通过这个公式逐步递推，计算出任何时刻 t 的置信度分布 B(Wt)。在计算出每个\r\nB(Wi + 1)\r\n的非归一化值后，只需将所有可能状态的概率值相加，再用每个值除以这个总和，即可完成归一化，得到最终的概率分布。\r\n示例分析\r\n我们首先需要定义模型的三个核心部分：初始分布、转移模型和传感器模型。\r\n\r\n初始置信度 B(W0)表示第0天的天气概率分布。\r\n\r\n\r\n\r\n\r\nW0\r\nB(W0)\r\n\r\n\r\n\r\n\r\nsun\r\n0.8\r\n\r\n\r\nrain\r\n0.2\r\n\r\n\r\n\r\n\r\n转移模型 P(Wi + 1|Wi)表示从今天的天气转移到明天天气的概率。\r\n\r\n\r\n\r\n\r\nWi\r\nWi + 1\r\nP(Wi + 1|Wi)\r\n\r\n\r\n\r\n\r\nsun\r\nsun\r\n0.6\r\n\r\n\r\nsun\r\nrain\r\n0.4\r\n\r\n\r\nrain\r\nsun\r\n0.1\r\n\r\n\r\nrain\r\nrain\r\n0.9\r\n\r\n\r\n\r\n\r\n传感器模型 P(Fi|Wi)表示在某种真实天气下，观测到特定天气预报的概率。\r\n\r\n\r\n\r\n\r\nWi\r\nFi\r\nP(Fi|Wi)\r\n\r\n\r\n\r\n\r\nsun\r\ngood\r\n0.8\r\n\r\n\r\nsun\r\nbad\r\n0.2\r\n\r\n\r\nrain\r\ngood\r\n0.3\r\n\r\n\r\nrain\r\nbad\r\n0.7\r\n\r\n\r\n\r\n我们的目标是计算第1天的置信度 B(W1)，假设我们观测到第1天的天气预报是”good”\r\n(f1 = good)。\r\n整个计算过程遵循前向算法的两个核心步骤：时间流逝更新和观测更新。\r\n第一步是时间流逝更新（预测）: 根据第0天的置信度 B(W0)，预测第1天的天气概率分布\r\nB′(W1)，此时我们尚未考虑第1天的天气预报。\r\n公式为：B′(W1) = ∑w0P(W1|w0)B(w0)\r\n第1天是晴天的预测概率，等于”第0天是晴天且第1天也是晴天”的概率，加上”第0天是雨天但第1天是晴天”的概率。\r\nB′(W1 = sun) = P(W1 = sun|W0 = sun)B(W0 = sun) + P(W1 = sun|W0 = rain)B(W0 = rain)\r\n = (0.6 · 0.8) + (0.1 · 0.2)  = 0.48 + 0.02 = 0.5\r\nB′(W1 = rain) = P(W1 = rain|W0 = sun)B(W0 = sun) + P(W1 = rain|W0 = rain)B(W0 = rain)\r\n = (0.4 · 0.8) + (0.9 · 0.2)  = 0.32 + 0.18 = 0.5\r\n经过时间更新后，我们得到的预测置信度为：\r\n\r\n\r\n\r\nW1\r\nB′(W1)\r\n\r\n\r\n\r\n\r\nsun\r\n0.5\r\n\r\n\r\nrain\r\n0.5\r\n\r\n\r\n\r\n这表明，在不考虑任何新证据的情况下，我们预测第1天晴天和雨天的概率各占一半。\r\n第二步是观测更新（修正）: 现在我们引入观测证据 f1 = good，用它来修正我们的预测，得到最终的置信度\r\nB(W1)。\r\n公式为：B(W1) ∝ P(f1|W1)B′(W1)\r\nB(W1 = sun) ∝ P(F1 = good|W1 = sun)B′(W1 = sun)\r\n ∝ 0.8 · 0.5 = 0.4\r\nB(W1 = rain) ∝ P(F1 = good|W1 = rain)B′(W1 = rain)\r\n ∝ 0.3 · 0.5 = 0.15\r\n在第二步之后,\r\n我们得到了未经归一化的置信度值：sun为0.4，rain为0.15。\r\n第三步是归一化,\r\n将上述结果转换为合法的概率分布（即各项概率之和为1）。\r\n计算总和：0.4 + 0.15 = 0.55\r\n归一化： B(W1 = sun) = 0.4/0.55 = 8/11\r\nB(W1 = rain) = 0.15/0.55 = 3/11\r\n经过完整的计算，我们得到第1天的最终置信度分布 B(W1) 如下：\r\n\r\n\r\n\r\nW1\r\nB(W1)\r\n\r\n\r\n\r\n\r\nsun\r\n8/11 (≈ 0.727)\r\n\r\n\r\nrain\r\n3/11 (≈ 0.273)\r\n\r\n\r\n\r\n最开始，我们对第1天的天气预测是晴雨概率各占50% (B′(W1))。然而，当我们观测到”预报为good”这个证据后，我们对”第1天是晴天”的信心大大增加，从50%\r\n(1/2) 上升到了约73%\r\n(8/11)。这完全符合直觉，因为晴天时出现”good”预报的概率（0.8）远高于雨天时（0.3）。这个例子清晰地展示了前向算法是如何融合历史信息和当前证据来动态更新对隐藏状态的信念的。\r\n维特比算法（Viterbi\r\nAlgorithm）\r\n前向算法回答的是“在时刻 N，最可能的状态是什么？”。而 Viterbi\r\n算法回答的是一个不同但同样重要的问题：“给定从时刻1到 N\r\n的所有观测，最可能的状态序列是什么？”\r\n换句话说，算法旨在找到一个完整的隐藏状态序列（一条路径），使得这个序列在给定观测证据的情况下出现的概率最大\r\n。\r\n公式化表达即为寻找最可能的隐藏状态序列 x1 : N*。\r\nx1 : N* = arg maxx1 : NP(x1 : N|e1 : N)\r\n\r\n想象一下，你每天都会收到一份天气预报（观测证据），但你无法直接知道每天的真实天气（隐藏状态）。几天过后，你手上有一系列的预报记录，比如“（好，好，坏）”。你现在想推断出这几天最可能发生的真实天气序列是什么。是“（晴，晴，雨）”还是“（晴，雨，雨）”？\r\n\r\n维特比算法采用动态规划来解决这个问题。其核心思想可以概括为一句话：\r\n“如果要找在时刻 t 到达状态 A 的最优路径，我们只需要知道在时刻 t-1\r\n到达所有可能前置状态（A, B, C, …）的最优路径即可。”\r\n我们不需要关心到达状态 B 或 C\r\n的完整历史路径是什么，只需要知道它们各自由最优路径到达自己的概率是多少。然后我们就可以计算从\r\nA 到 A, 从 B 到 A 和从 C 到 A 的新得分，选择其中更高分的那条作为到达 A\r\n的最优路径。\r\n基本步骤\r\n假设我们有一个隐藏马尔可夫模型，它由以下要素组成：\r\n\r\n隐藏状态集合 S = {s1, s2, ..., sN}：我们无法直接观察到的状态。\r\n观测状态集合 O = {o1, o2, ..., oM}：我们能够直接观察到的结果。\r\n初始状态概率 π = {π1, π2, ..., πN}：模型在时间\r\nt=1 时处于每个隐藏状态的概率。\r\n状态转移概率矩阵 A = {aij}：从隐藏状态\r\nsi 转移到\r\nsj\r\n的概率。\r\n发射概率矩阵 B = {bj(k)}：在隐藏状态\r\nsj\r\n下观察到观测 ok\r\n的概率。\r\n\r\n维特比算法的目标是找到最有可能的隐藏状态序列 Q = {q1, q2, ..., qT}，使得\r\nP(Q|O)\r\n的值最大，其中 O = {O1, O2, ..., OT}\r\n是已知的观测序列。\r\n维特比算法分为四个主要步骤：初始化、递归计算、终结和回溯。\r\n步骤一：初始化\r\n在第一个时间步 t=1，我们计算到达每个隐藏状态 si\r\n的最大概率。这个概率是该状态的初始概率 πi\r\n与在该状态下观测到第一个观测值 O1 的发射概率 bi(O1)\r\n的乘积。\r\n操作：对于每个隐藏状态 si，计算维特比变量\r\nδ1(i):\r\nδ1(i) = πi ⋅ bi(O1)\r\n这一步是为动态规划的起点做准备。我们计算了所有可能的路径中，在时间\r\nt=1 结束于状态 si\r\n的最大概率。\r\n步骤二：递归计算\r\n从时间步 t=2 到\r\nT，我们对每个时间步和每个隐藏状态进行迭代计算。对于每个状态 sj，我们需要考虑所有从上一个时间步\r\nt-1 的状态 si 转移到 sj\r\n的可能性，并选择其中概率最大的路径。\r\n操作：对于每个时间步 t (2≤t≤T) 和每个隐藏状态 sj，计算维特比变量\r\nδt(j)\r\n和回溯指针 ψt(j)。\r\n数学公式: δt(j) = maxi[δt − 1(i) ⋅ aij] ⋅ bj(Ot)\r\nψt(j) = arg maxi[δt − 1(i) ⋅ aij]\r\nδt(j)\r\n的计算：maxi[δt − 1(i) ⋅ aij]\r\n寻找了从前一个时间步的任意状态 si 到达当前状态\r\nsj\r\n的最可能路径。然后将其乘以在当前状态 sj 下观测到\r\nOt 的概率\r\nbj(Ot)，得到在时间\r\nt 结束于状态 sj\r\n的整体最大概率。\r\nψt(j)\r\n的计算：它记录了在时间 t 达到状态 sj\r\n的最可能路径是从时间 t-1 的哪个状态 si\r\n转移过来的。这个回溯指针是最终重建路径的关键。\r\n步骤三：终结 在处理完所有时间步后，我们找到最后一个时间步 T\r\n中，概率最大的那个状态，这将是我们的最优路径的终点。\r\n操作：找到在时间 t=T 时，所有维特比变量 δT(i)\r\n中的最大值。\r\n数学公式：\r\nP* = maxi[δT(i)]\r\nqT* = arg maxi[δT(i)]\r\n解释：P*\r\n是整个观测序列下，最有可能隐藏状态序列的概率。qT*\r\n是该最优序列的最后一个状态。\r\n步骤四：回溯\r\n这是重建最优路径的关键步骤。我们从最后一个状态 qT*\r\n开始，利用之前记录的回溯指针 ψt(j)\r\n逆向推导出整个序列。\r\n操作：从 t=T 向 t=1 循环，通过回溯指针确定前一个状态。\r\n数学公式：\r\nqt − 1* = ψt(qt*)\r\n这一步利用了动态规划的特性。由于我们在每一步都记录了最优的前驱状态，我们只需要从终点倒推，就能唯一地确定一条由局部最优解构成的全局最优路径。\r\n示例分析\r\n让我们用一个经典的”天气-心情”例子来演示维特比算法。\r\n\r\n隐藏状态：S = {晴天, 雨天}\r\n观测序列：O = {开心, 难过, 开心}\r\n\r\n参数：\r\n\r\n初始概率 π：π晴天 = 0.6,\r\nπ雨天 = 0.4\r\n转移概率 A：\r\n\r\n晴天晴天\r\n晴天雨天\r\n雨天晴天\r\n雨天雨天\r\n\r\n发射概率 B：\r\n\r\nP(开心|晴天) = 0.8\r\nP(难过|晴天) = 0.2\r\nP(开心|雨天) = 0.3\r\nP(难过|雨天) = 0.7\r\n\r\n\r\n计算过程如下：\r\n\r\n时间步 t = 1 (观测：开心):\r\n初始概率乘发射概率来实现初始化\r\n\r\nδ1(晴天) = π晴天 ⋅ b晴天(开心) = 0.6 ⋅ 0.8 = 0.48\r\nδ1(雨天) = π雨天 ⋅ b雨天(开心) = 0.4 ⋅ 0.3 = 0.12\r\n这样,\r\n我们计算了第一天是晴天（概率0.48）和雨天（概率0.12）的各自最大概率路径。\r\n\r\n时间步 t = 2 (观测：难过):\r\n计算 δ2 和 ψ2\r\n\r\nδ2(晴天) = max [δ1(晴天) ⋅ a晴天, 晴天, δ1(雨天) ⋅ a雨天, 晴天] ⋅ b晴天(难过)\r\n = max [0.48 ⋅ 0.7, 0.12 ⋅ 0.4] ⋅ 0.2 = max [0.336, 0.048] ⋅ 0.2 = 0.336 ⋅ 0.2 = 0.0672\r\nψ2(晴天) = 晴天\r\n（因为 0.336 &gt; 0.048）\r\nδ2(雨天) = max [δ1(晴天) ⋅ a晴天, 雨天, δ1(雨天) ⋅ a雨天, 雨天] ⋅ b雨天(难过)\r\n = max [0.48 ⋅ 0.3, 0.12 ⋅ 0.6] ⋅ 0.7 = max [0.144, 0.072] ⋅ 0.7 = 0.144 ⋅ 0.7 = 0.1008\r\nψ2(雨天) = 晴天\r\n（因为 0.144 &gt; 0.072）\r\n在第二天，我们分别计算了结束于”晴天”和”雨天”的两种可能路径的最大概率。我们发现，要到达”晴天”状态，最可能的前一天状态是”晴天”；要到达”雨天”状态，最可能的前一天状态也是”晴天”。\r\n\r\n时间步 t = 3 (观测：开心):\r\n计算 δ3 和 ψ3\r\n\r\nδ3(晴天) = max [δ2(晴天) ⋅ a晴天, 晴天, δ2(雨天) ⋅ a雨天, 晴天] ⋅ b晴天(开心)\r\n = max [0.0672 ⋅ 0.7, 0.1008 ⋅ 0.4] ⋅ 0.8 = max [0.04704, 0.04032] ⋅ 0.8 = 0.04704 ⋅ 0.8 = 0.037632\r\nψ3(晴天) = 晴天\r\nδ3(雨天) = max [δ2(晴天) ⋅ a晴天, 雨天, δ2(雨天) ⋅ a雨天, 雨天] ⋅ b雨天(开心)\r\n = max [0.0672 ⋅ 0.3, 0.1008 ⋅ 0.6] ⋅ 0.3 = max [0.02016, 0.06048] ⋅ 0.3 = 0.06048 ⋅ 0.3 = 0.018144\r\nψ3(雨天) = 雨天\r\n\r\n终结和回溯\r\n\r\n比较 δ3(晴天)\r\n和 δ3(雨天),\r\n有0.037632 &gt; 0.018144\r\n因此，最优路径的最后一个状态是 晴天。\r\n最后我们回溯路径即可得到结果：\r\nq3* = 晴天\r\nq2* = ψ3(q3*) = ψ3(晴天) = 晴天\r\nq1* = ψ2(q2*) = ψ2(晴天) = 晴天\r\n因此, 最有可能的隐藏状态序列是：{晴天, 晴天, 晴天}。\r\n应用领域\r\n维特比算法因其高效和准确性，在许多领域有广泛应用，例如：\r\n\r\n语音识别：根据声学模型（隐藏状态）和声音信号（观测）找到最可能的单词序列。\r\n自然语言处理：\r\n\r\n用于词性标注（Part-of-Speech\r\nTagging），根据单词序列（观测）找到最可能的词性序列（隐藏状态）。\r\n用于命名实体识别（Named Entity\r\nRecognition），根据文本序列（观测）找到最可能的实体序列（隐藏状态）。\r\n\r\n生物信息学：用于基因识别，根据 DNA\r\n序列（观测）找到编码区和非编码区（隐藏状态）。\r\n无线通信：在编码理论中用于信道解码。\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"HMMs -- Markov Chains, HMMs(14)","url":"/2025/08/25/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/14/","content":"之前的贝叶斯网络（如警报系统）处理的是一个“快照”式的静态世界。而现实世界是不断变化的，比如天气、股票价格、机器人的位置等等。马尔可夫模型就是用来描述这种随时间演化的随机过程的经典工具。\r\n马尔可夫模型可以被看作是一种链式的、无限长的贝叶斯网络。它专注于表示变量在时间维度上的依赖关系。现在我们从处理静态的、一次性的概率问题，转变为处理动态的、随时间演化的概率问题中。\r\n马尔可夫模型 (Markov Models)\r\n一个马尔科夫过程是指状态间的转移仅依赖于前n个状态的过程。这个过程被称之为n阶马尔科夫模型，其中n是影响下一个状态选择的（前）n个状态。最简单的马尔科夫过程是一阶模型，它的状态选择仅与前一个状态有关。\r\n\r\n这里要注意它与确定性系统并不相同，因为下一个状态的选择由相应的概率决定，并不是确定性的。\r\n\r\n在下面的内容中,\r\n我们用一个一阶马尔可夫模型来描述一个随时间变化的状态序列。我们用一系列带时间戳的随机变量来表示状态，如\r\nW0, W1, W2, ...，其中\r\n假设Wi\r\n代表第 i 天的天气。\r\n根据一阶马尔科夫性质,\r\n未来的状态只依赖于当前状态，而与过去的所有状态都无关。这也被称为“无记忆性\r\n(memoryless property)”。数学表示为：P(Wi + 1|Wi, Wi − 1, ..., W0) = P(Wi + 1|Wi)\r\n\r\n直观理解：要知道明天的天气，我只需要知道今天的天气就够了，昨天、前天的天气信息对于预测明天不再提供额外帮助。\r\n\r\n我们要研究的模型的组成部分：\r\n\r\n初始分布 (Initial Distribution)：P(W0)，描述了在时间起点（第0天）时，系统处于各个状态的概率。\r\n转移模型 (Transition Model)：P(Wi + 1|Wi)，描述了从一个状态转移到下一个状态的概率。\r\n\r\n\r\n\r\n平稳性假设 (Stationary\r\nAssumption)：通常我们假设转移模型是不随时间变化的。也就是说，从“晴天”到“雨天”的概率，无论是今天到明天，还是明年到后年，都是一样的。这个假设使得我们只需要一张转移概率表就可以描述整个无限长的过程。\r\n\r\n在这样的情景下, 联合概率计算变为为：\r\n\r\n\r\n这个公式再次体现了紧凑表示的威力。我们只需要初始分布和一张转移表，就可以计算任意长度序列的概率，而不需要一个指数级大小的联合分布表。\r\n\r\n迷你前向算法 (The\r\nMini-Forward Algorithm)\r\n这是在马尔可夫模型中进行时间推断 (Temporal Inference)\r\n的基础算法。它的目标是计算在未来某个时间点 t，系统处于各个状态的概率分布\r\nP(Wt)。其核心思想为：通过迭代的方式，一步步地将概率分布“向前推进”。\r\n递推公式：P(Wt + 1) = ∑wtP(Wt + 1|wt)P(wt)\r\n首先, 我们从已知的初始分布 P(W0)\r\n开始。利用上面的公式，我们可以计算出 P(W1)。然后，再用刚刚算出的\r\nP(W1)\r\n作为输入，计算出 P(W2)。以此类推，直到我们计算出所需时间点的概率分布。\r\n稳态分布 (Stationary\r\nDistribution)\r\n一个自然的问题是：随着时间无限推移，这个系统最终会达到一个什么样的状态？这个最终的、不再变化的概率分布就是稳态分布。\r\n其定义如下: 一个概率分布 P(W∞)\r\n是稳态的，如果它在经过一次时间转移后保持不变。\r\n其数学表示为：P(Wt + 1) = P(Wt)\r\n利用稳态分布,\r\n我们可以将稳态的定义代入迷你前向算法的递推公式中，得到一个关于未知稳态概率的方程组,\r\n此时结合概率分布和为1的基本约束, 往往就能解出这个稳态概率的值。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Bayes Nets -- Bayesian Networks(11)","url":"/2025/08/23/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/11/","content":"上一讲(概率论基础)我们学到，只要有完整的联合概率分布，我们就能回答任何概率问题。但同时也暴露了一个致命问题：这个联合分布表的大小会随着变量数量的增加而指数级增长，在现实问题中完全不可行。\r\n这一讲的核心就是解决这个问题：如何利用变量间的独立性关系，来紧凑、高效地表示一个完整的联合概率分布。这个解决方案就是贝叶斯网络\r\n(Bayesian Networks)。\r\n不过在介绍贝叶斯网络之前, 我们先介绍在其之上的一个概念,\r\n概率图模型.\r\n概率图模型\r\n概率图模型（Probabilistic Graphical\r\nModel，PGM）是一种用图结构来表示和推断多元随机变量之间条件独立性的概率模型。图模型提供了一种直观且有效的方式来描述高维空间中的概率分布，通过图结构表示随机变量之间的关系，使得模型的参数量得以减少。\r\n\r\n概率论负责处理不确定性和随机性,\r\n图论提供了一种直观且强大的数据结构，用来表示变量之间的依赖关系。\r\n\r\n条件概率\r\n考虑一个由 K 个离散随机变量\r\nX1, X2, …, XK\r\n组成的随机向量 X = [X1, X2, …, XK]T，其中每个变量都有\r\nM\r\n个可能的取值，其联合概率在高维空间中的分布很难直接建模。在没有任何独立性假设的情况下，我们需要为每一种组合分配一个概率值。每个变量有\r\nM 个可能的取值，因此有 MK\r\n种可能的组合。由于概率的总和必须等于1，所以最后一个概率值可以通过对其他概率值进行补充得到，因此，我们需要\r\nMK − 1\r\n个参数。\r\n当 M = 2 且 K = 100 时，参数量(约为 1030)将远远超出目前计算机的存储能力。为了有效减少参数量，可以使用独立性假设。一个\r\nK 维随机向量 X 的联合概率可以分解为 K\r\n个条件概率的乘积。如果某些变量之间存在条件独立性，参数量就可以显著减少。\r\n对于一个 K 维随机向量 X，其联合概率可以分解为条件概率的乘积：\r\np(x) ≜ P(X = x) = ∏_k = 1Kp(x_k|x_1, …, x_k − 1)\r\n它被称为概率的链式法则 (Chain Rule of\r\nProbability)。它将一个复杂的多维联合概率问题，分解成了一系列更简单的一维条件概率的乘积。\r\n\n    概率回忆 \n    \n      什么是概率分布:\r\n一个概率分布描述了一个随机变量所有可能取值及其对应的概率。我们通常用一个数学函数p(x)来精确地描述这个对应关系，这个函数被称为概率质量函数\r\n(PMF)（对于离散型变量）或概率密度函数 (PDF)（对于连续型变量）。\r\n因此对于上述公式, p(x)=…是一个以 x 为变量的函数表达式,\r\n这个函数的功能是，你给它任何一个可能的具体向量值 x,\r\n它就能告诉你这个特定向量值发生的概率;\r\n而这个函数本身，完整地刻画了随机向量 X\r\n的概率分布(因此在离散情况下假如让你求类似的表达式,\r\n也就是让你求出所有可能情况的分布)。\r\n\r\n大写粗体字母 X：代表一个随机向量 (Random Vector)\r\n\r\n它是一个变量，其值是随机的，并且是一个向量。可以把它想象成一个“容器”或一个“抽象概念”\r\n如果我们同时掷两枚骰子，可以用一个二维随机向量 X = (X1, X2)\r\n来描述这个随机事件。X 代表了从 (1,1) 到 (6,6)\r\n所有36种可能结果的整个概率空间。\r\n\r\n小写粗体字母 x：代表随机向量的一个具体实现\r\n(Realization) 或观测值\r\n\r\n它是从随机向量 X\r\n的所有可能性中取出的一个特定的、具体的数值向量。\r\n如果我们实际掷了一次两枚骰子，得到的结果是第一枚为3点，第二枚为5点，那么这次观测值就是\r\nx=(3,5)。这个 x 就是随机向量 X 的一个具体实现。\r\n\r\n\r\n\n    \n  \r\n其中，x = [x1, x2, …, xK]\r\n表示变量 X\r\n的取值。通过这种分解，我们可以将原本需要 MK\r\n个参数的问题，降低到对每个变量的条件概率的参数的数量之和。如果某些变量之间存在条件独立关系，那么相应的条件概率的参数量就可以大幅减少。\r\n概率图模型中，贝叶斯网络和马尔可夫网络都利用了这种条件独立性的结构，以更紧凑的方式表示联合概率分布，从而提高了模型的可解释性和计算效率。\r\n条件独立\r\n条件独立是指在给定某个特定条件（或第三个事件）C\r\n已经发生的前提下，两个事件（或随机变量）A 和 B\r\n变得独立。这意味着，一旦我们知道了条件 C 的信息，事件 A\r\n的发生与否，就对事件 B\r\n在该条件下的概率没有影响了。你可以把它理解为一种有条件的独立性。\r\n对于三个事件 A, B, 和 C，A 与 B 在给定 C\r\n的条件下条件独立当且仅当下列二者之一成立： - P(A, B ∣ C) = P(A ∣ C)P(B ∣ C)\r\n- P(A ∣ B, C) = P(A ∣ C)\r\n\n    举个例子 \n    \n      想象一下一个简单的医疗情景：\r\n事件 A：病人有发烧的症状。\r\n事件 B：病人有咳嗽的症状。\r\n事件 C：病人患有流感。\r\n首先，我们不考虑任何其他信息，只看事件 A（发烧）和事件\r\nB（咳嗽）。问题是, 发烧和咳嗽是相互独立的吗？\r\n答案当然不是。如果一个病人有发烧，你会自然地认为他生病了，比如感冒或流感。而这些疾病通常也会伴随着咳嗽。因此，发烧的存在增加了病人有咳嗽的可能性。反之亦然。\r\n我们可以用因果关系来理解：因为流感这种病因可能同时导致发烧和咳嗽这两种症状。当流感这个“共同原因”未知时，两种症状看起来是相互关联的。\r\n现在，我们引入条件\r\nC。假设我们已经通过化验或其他诊断方法，确定病人患有流感。此时的问题是,\r\n在已经知道病人患有流感的前提下，发烧和咳嗽还相互依赖吗？\r\n答案当然是不再依赖。在这种情况下，我们已经找到了导致这两种症状的根本原因——流感。流感这个疾病本身就可以独立地引发发烧，也可以独立地引发咳嗽。\r\n你已经知道病人有流感了，那么发烧这个症状的出现，并不会给你提供更多关于咳嗽的额外信息。因为你已经知道他们都有可能由流感引起。\r\n因此,\r\n条件独立关注的是在“幕后黑手”已经被揭示出来的前提下，两个事件的关系。一旦这个共同原因被确定，它们之间的表观关联就被“解释掉了”，从而变得独立。\r\n\n    \n  \r\n下面我们将条件独立引入之前的条件概率和联合概率：\r\n首先, 根据条件概率公式, 有: p(x1, x2, x3, x4) = p(x1) ⋅ p(x2|x1) ⋅ p(x3|x1, x2) ⋅ p(x4|x1, x2, x3)\r\n通过假设条件独立并引入条件独立性假设，可以减少参数量\r\n例如，在已知 X1\r\n时，X2 和 X3 独立，即有：\r\n\r\np(x2|x1, x3) = p(x2|x1)\r\np(x3|x1, x2) = p(x3|x1)\r\n\r\n在已知 X2 和\r\nX3 时，X4 也和 X1 独立，即有：\r\n\r\np(x4|x1, x2, x3) = p(x4|x2, x3)\r\n\r\n这样可以将联合概率分解为四个局部条件概率的乘积，从而减少参数量：\r\np(x) = p(x1) ⋅ p(x2|x1) ⋅ p(x3|x1) ⋅ p(x4|x2, x3)\r\np(x1)\r\n的参数数量为 1; p(x2|x1)\r\n的参数数量为 2（在给定 X1 的条件下）; p(x3|x1)\r\n的参数数量为 2（在给定 X1 的条件下）; p(x4|x2, x3)\r\n的参数数量为 4（在给定 X2 和 X3 的条件下, 因为X2 和 X3组合有四种情况）\r\n所以总的独立参数数量为 1 + 2 + 2 + 4 = 9 , 远小于指数级参数。\r\n概率图模型的总体框架\r\n\r\n从图中可以看出, 概率图模型涉及到三个基本问题:\r\n\r\n表示问题：这个问题涉及如何选择和设计图结构，以有效地表示变量之间的依赖关系。在贝叶斯网络中，这通常涉及到选择合适的有向边，而在马尔可夫网络中，涉及到选择无向边。图结构的选择直接影响了概率模型的表达能力和推断效率。\r\n学习问题：学习问题可以进一步分为两个部分：图结构的学习和参数的学习。在图结构的学习中，目标是从数据中推断出最合适的图结构，描述变量之间的依赖关系。在参数的学习中，已知图结构的情况下，目标是估计模型中的参数，使得模型与观测数据的拟合最好。\r\n推断问题：推断问题涉及在给定部分变量的观测值时，计算其他变量的条件概率分布。这可以通过贝叶斯推断、变分推断等方法来解决。推断在概率图模型中是一个关键的任务，因为它允许我们根据观测到的证据来推断未观测到的变量的状态，从而进行概率推理。\r\n\r\n贝叶斯网络\r\n\r\n有向图模型（Directed Graphical\r\nModels）是概率图模型的一类，其中最为知名的代表是贝叶斯网络。这种模型在处理多变量概率关系方面表现出色，提供了一种直观、清晰的方法来描述随机变量之间的因果关系。\r\n\r\n根据我们前面提到的内容 ,一个包含 n 个变量、每个变量有 d\r\n个取值的联合概览分布表需要 dn\r\n个条目来存储信息, 极度耗费空间。\r\n贝叶斯网利用条件概率和条件独立性的思想，将这个大表分解为：\r\n\r\n一个有向无环图 (Directed Acyclic Graph -\r\nDAG)：用于直观地表示变量之间的依赖关系。\r\n\r\n节点\r\n(Nodes)：图中的每个节点代表一个随机变量。这个变量可以是离散的（例如：天气是晴天、阴天还是雨天），也可以是连续的（例如：温度）。\r\n有向边 (Edges)：从节点 A 指向 B 的箭头通常表示 A 对 B\r\n有直接影响。A 被称为 B 的父节点 (parent)。\r\n\r\n箭头不一定代表严格的因果关系，它只表示变量之间可能存在某种概率上的依赖。\r\n\r\n\r\n一组小的条件概率表 (Conditional Probability Tables -\r\nCPTs)：每个变量都附有一个CPT，描述了它在其父节点取不同值时的概率分布。\r\n\r\n每个节点 X 都有一个与之关联的CPT，即 P(X|Parents(X))。\r\n\r\n这个表列出了在给定其所有父节点所有可能取值组合的情况下，节点 X\r\n本身取每个值的概率。\r\n\r\n没有父节点的节点（根节点），其CPT就是一个简单的先验概率分布 P(X)。\r\n\r\n\r\n有向图模型/贝叶斯网络最核心的优势在于，在这个情境下一个变量的取值只与它的父节点有关,\r\n因此能够将所有变量的复杂联合概率分布分解为一系列更简单的局部条件概率分布的乘积。具体来说，整个网络的联合概率可以表示为：\r\n这个公式的含义是，计算所有变量同时发生的总概率时，我们只需要计算每个变量在其父节点发生的条件下的概率，然后将它们全部相乘。在这样的情况下,\r\n原本指数级增长的参数数量，大幅降低到只与每个节点的父节点数量相关的程度，从而使大规模模型的构建和学习变得可行。\r\n几类应用\r\n上述思维导图中列出了一些典型的有向图模型，它们在不同领域有广泛应用：\r\n\r\n朴素贝叶斯模型（Naive Bayes Model）\r\n\r\n\r\n特点：这是一种最简单的贝叶斯网络，它有一个根节点（通常代表类别），所有其他叶子节点（代表特征）都直接从这个根节点引出,\r\n就像一棵两层的树一样。\r\n核心假设：它做出了一个非常“朴素”的假设——在给定类别的情况下，所有特征之间是相互独立的。\r\n应用：虽然假设很强，但它在文本分类和垃圾邮件过滤等领域表现出奇的好。\r\n\r\n\r\n隐马尔可夫模型（Hidden Markov Model, HMM）,\r\n这个我们之后会涉及到\r\n\r\n\r\n特点：专门用于处理序列数据。它包含一个隐藏状态序列和一个可观测序列。隐藏状态是不可见的，但它们决定了可观测序列的生成。\r\n核心假设：它遵循马尔可夫假设——当前隐藏状态只依赖于前一个隐藏状态。\r\n应用：广泛用于语音识别、自然语言处理中的序列标注（如词性标注）等。\r\n\r\n\r\n深度信念网络（Deep Belief Network, DBN）\r\n\r\n\r\n特点：它是一种生成式概率模型，连接了经典图模型和现代深度学习。它由多层受限玻尔兹曼机（RBM）堆叠而成。\r\n核心思想：通过分层的方式学习数据的高维表示，每层都捕捉了数据中更抽象的特征。\r\n应用：在深度学习兴起初期，常用于无监督预训练，以提高神经网络的性能。\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Dynamic Programming for MDP (18)","url":"/2025/08/30/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/18/","content":"上一讲我们定义了MDP，并得到了一个核心的数学关系——贝尔曼方程 (Bellman\r\nEquation)，它描述了最优状态价值的递归性质。这一讲的核心问题是：我们如何通过计算来求解这些贝尔曼方程，从而最终找到最优策略\r\nπ*？\r\n由于贝尔曼方程是一组非线性的联立方程，直接求解非常困难。因此，我们采用动态规划\r\n(Dynamic Programming)\r\n的思想，通过迭代的方式逐步逼近最优的效用值和策略。这一讲介绍了两种实现这一思想的经典算法。\r\n策略迭代 (Policy Iteration)\r\n在介绍策略迭代之前，我们先引入一个概念——策略评估\r\n(Policy Evaluation)。策略评估的目标是计算给定策略 π 的状态价值函数\r\nV(π)。\r\n\r\n上一讲我们提到贝尔曼方程分为贝尔曼最优方程和贝尔曼期望方程，策略评估的目标是计算给定策略\r\nπ 的状态价值函数 V(π)，即贝尔曼期望方程。\r\n\r\n策略评估\r\n策略评估的基本思路是从任意一个状态价值函数开始，依据给定的策略，结合贝尔曼期望方程、状态转移概率和奖励同步迭代更新状态价值函数，直至其收敛，得到该策略下最终的状态价值函数。\r\n假设在第 t 轮迭代已经计算出了所有状态的状态价值 V^t(s’)，那么在第 t+1\r\n轮可以利用第 t 轮计算出的状态价值计算出第 t+1 轮的状态价值\r\nV^{t+1}(s)。这是通过贝尔曼期望方程来完成的，即通过 Bellman expectation\r\nbackup 进行迭代\r\nVt + 1(s) = ∑a ∈ Aπ(a|s)(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vt(s′))\r\n理解迭代过程\r\n首先, 上面的迭代公式由贝尔曼期望方程得到:\r\nVπ(s) = ∑a ∈ Aπ(a|s)(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vπ(s′))\r\n这是一个陈述或一个平衡状态的定义。它描述了一个事实：对于一个给定的策略\r\nπ，其”真实”的价值函数 Vπ\r\n必须满足这种自洽性。\r\n这个公式可以看作是一个由 N\r\n个方程组成的方程组（N是状态的数量）。在方程的左边和右边出现的 Vπ\r\n是同一个未知数。它表达的是：“一个状态的真实价值（左边），等于遵循策略后所有可能后续状态的期望价值（右边）”。\r\n而迭代方程则将Vπ(s)\r\n替换为 Vt + 1(s)\r\n，得到：\r\nVt + 1(s) = ∑a ∈ Aπ(a|s)(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vt(s′))\r\n根本原因在于,\r\n贝尔曼算子（由第一个式子的右半部分定义）是一个压缩映射(符合迭代收敛的条件),\r\n这个数学性质保证了，我们可以通过第二个式子描述的迭代方法，来找到第一个式子定义的那个唯一解。\r\n随着 k 越来越大，我们计算出的估计值 Vk(s)\r\n会收敛 (converge) 到那个”真实”的价值 Vπ(s)。\r\n当 k → ∞ 时，Vk(s) → Vπ(s)。我们把一个寻找平衡点的问题，转化成了一个保证能走到平衡点的计算流程。\r\n\r\n压缩映射定理保证了，只要一个算子是压缩的，那么它有且仅有一个不动点（即\r\nv_pi 是唯一存在的）; 从任何初始点（任何初始猜测\r\nv_0）开始，反复应用这个算子，最终都必定会收敛到这个唯一的不动点。\r\n\r\n示例分析\r\n下面通过一个具体的示例理解策略评估的过程。\r\n这是一个经典的Grid\r\nWorld的例子。有一个4x4的16宫格。只有左上和右下的格子是终止格子。\r\n\r\n状态 (S): 14个可移动的格子。左上角 (0,0) 和右下角 (3,3)\r\n是终止状态。\r\n动作 (A): {上, 下, 左, 右}。\r\n策略 (π):\r\n一个固定的随机策略。在任何一个非终止状态下，智能体都以均等的概率（各25%）选择上、下、左、右四个动作中的一个。\r\n奖励 (R): 每次移动的即时奖励为 -1。\r\n折扣因子 (γ):\r\nγ=1。这意味着未来的惩罚和当前的惩罚同等重要。\r\n目标:\r\n我们的目标是评估这个随机策略，即计算出在这个策略下，从每一个格子出发，到达终点所期望的累积总回报（也就是状态价值函数\r\nVπ(s)）。\r\n\r\n图片左侧展示了价值函数从 k=0\r\n开始的迭代计算过程。这个计算的核心是反复使用贝尔曼期望方程进行更新。对于这个特定的例子，更新公式为：\r\nVk + 1(s) = −1 + (0.25 ⋅ Vk(sup′) + 0.25 ⋅ Vk(sdown′) + 0.25 ⋅ Vk(sleft′) + 0.25 ⋅ Vk(sright′))\r\n其中，sup′,\r\nsdown′\r\n等表示上一迭代中四个邻居格子的价值。\r\n下面展示k = 0 时的迭代:\r\n\r\n初始化所有非终止状态的价值为 0。这是一个任意的起点。\r\n此时，因为所有格子的价值都一样，所以看不出任何格子的好坏。\r\n\r\nk = 1 时的迭代:\r\n\r\n对所有非终止格子应用一次更新公式,\r\n利用上一步的价值计算这一步的价值。\r\n计算: V1(s) = −1 + (0.25 ⋅ V0(...) + ...) = −1 + (0.25 ⋅ 0 + ...) = −1\r\n所有的非终止格子的价值都变成了\r\n-1。这代表了”走一步”所付出的代价。此时，我们只考虑了即时奖励，还没有考虑未来的奖励。\r\n\r\nk = 2 时的迭代:\r\n\r\n使用 k=1 的价值来计算 k=2 的价值。价值的差异开始出现。\r\n计算示例 (以第(0,1)格为例):\r\n\r\n四个邻居状态：\r\n\r\n(0,0): 终止状态，价值为0\r\n(1,1): 价值为-1\r\n(0,2): 价值为-1\r\n(0,1): 往左撞墙，价值为-1\r\n\r\n\r\nV2(0, 1) = −1 + [0.25 ⋅ V1(0, 0) + 0.25 ⋅ V1(1, 1) + 0.25 ⋅ V1(0, 2) + 0.25 ⋅ V1(0, 1)]\r\nV2(0, 1) = −1 + [0.25 ⋅ 0 + 0.25 ⋅ (−1) + 0.25 ⋅ (−1) + 0.25 ⋅ (−1)] = −1 − 0.75 = −1.7\r\n分析:\r\n靠近终止状态（价值为0）的格子，其价值变得”不那么负”，因为它们有25%的概率一步就”逃离”并停止付出代价。而离终止状态远的格子，比如中心位置，其价值会变得更负（-2.0），因为它周围都是需要继续付出代价的格子。\r\n\r\nk = 3 时的迭代:\r\n\r\n随着迭代的继续，价值信息会像波一样从终止状态向远处传播。\r\n迭代次数越多，价值函数就考虑得越”长远”。一个格子的价值反映了从它出发，在随机策略下平均需要走多少步才能到达终点。例如，在\r\nk=∞\r\n时，中心的四个格子价值收敛为-20，表示从那里出发平均需要”走”20步才能结束。而紧邻终点的格子价值为-14，因为它们离”出口”更近。\r\n\r\n\r\n回到策略迭代\r\n既然我们已经根据策略评估计算出了价值函数，那么我们就可以根据价值函数来改进策略。这就是策略迭代的过程。\r\n如何调整呢？最简单的方法就是贪婪法。考虑一种如下的贪婪策略：个体在某个状态下选择的行为是其能够到达后续所有可能的状态中状态价值最大的那个状态。如上面的图右边。当计算出最终的状态价值后发现，第二行第一个格子周围的价值分别是0,-18,-20，此时用贪婪法，调整行动策略为向状态价值为0的方向移动，而不是随机移动。也就是图中箭头向上。而此时第二行第二个格子周围的价值分别是-14,-14,-20,\r\n-20。那么整行动策略为向状态价值为-14的方向移动，也就是图中的向左向上。\r\n图片右侧展示的内容就是策略迭代 (Policy Iteration)\r\n思想的实际运用。这一列的箭头表示，如果我们根据左侧计算出的当前价值 vk来做出“贪心”决策，我们应该选择哪个方向。所谓“贪心”，就是选择能移动到的那个价值最高的邻居格子。\r\n演变过程如下:\r\n\r\nk = 0:\r\n因为所有邻居价值都是0，所以往哪走都一样，策略是随机的。\r\nk = 1:\r\n邻居中只有终止状态的价值（0）高于其他格子（-1），所以所有邻近终止状态的格子，其贪心策略都指向了终止状态。\r\nk = 2, 3…:\r\n随着价值函数的精确化，贪心策略也变得越来越明确。箭头开始清晰地指向通往最近的终止状态的最短路径。\r\nk = 10, ∞:\r\n此时，贪心策略已经稳定下来，不再改变。这个最终稳定下来的策略，就是该问题的最优策略\r\nπ*\r\n\r\n\r\n因此策略迭代分为两步:\r\n\r\n策略评估 (Policy Evaluation)\r\n\r\n对于当前固定的策略 π，我们需要计算出它所对应的真实的状态价值函数\r\nVπ(s)。这个过程本身是一个迭代计算，通过反复应用贝尔曼期望方程的更新规则来进行，直到价值函数收敛。\r\n计算公式 (迭代形式):\r\nVk + 1(s) ← ∑a ∈ Aπ(a|s)(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vk(s′))\r\n在这个内循环中，我们不断用上一轮的价值估计 Vk\r\n来计算新一轮的价值估计 Vk + 1，直到\r\nVk 和\r\nVk + 1\r\n之间的差异足够小（小于某个阈值 θ）。\r\n\r\n策略改进 (Policy Improvement)\r\n\r\n我们利用上一步评估出的价值函数 Vπ(s)，对每一个状态的动作选择进行贪心\r\n(Greedy) 的优化。\r\n首先, 对于每个状态 s，我们先计算出所有可能的动作 a 的动作价值 Qπ(s, a)。这个q值代表了，如果仅在当前这一步选择动作\r\na，然后后续继续遵循旧策略\r\nπ，所能带来的期望总回报。\r\nQπ(s, a) = R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vπ(s′)\r\n然后，我们为状态 s\r\n选择那个能够带来最大 q 值的动作，作为我们新策略 πnew\r\n的选择。\r\nπnew(s) ← arg maxaQπ(s, a)\r\n\r\n价值迭代 (Value Iteration)\r\n价值迭代算法的目标非常纯粹：它旨在直接计算出每个状态的最优价值 U*(s)。它认为，只要我们知道了每个状态的“终极价值”，那么在任何状态下，选择能通往更高价值邻居的动作，自然就是最优策略。\r\n价值迭代的引擎只有一个，就是反复执行贝尔曼最优方程 (Bellman\r\nOptimality Equation) 的更新操作。\r\nVi + 1(s) ← maxa ∈ A(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vi(s′))\r\n然后直接提取最优策略 π:\r\nπ*(s) ← arg maxa (R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ Vend(s′))\r\n\r\n最后, 我们总结这一讲的两种策略:\r\n\r\n值迭代是在价值空间中进行搜索。它通过贝尔曼更新，逐步将效用函数逼近最优效用函数。\r\n策略迭代则是在策略空间中进行搜索。它通过“评估-改进”的循环，一步步地跳向更优的策略。\r\n\r\n他们都涉及到了动态规划的本质：利用问题的最优子结构（一个状态的价值依赖于其后继状态的价值），并通过迭代的方式，将后继状态的价值信息“备份”回当前状态，最终求解出全局最优解。\r\n另一方面, 这两个算法都假设我们完全知道MDP的模型（即转移函数 T\r\n和奖励函数\r\nR）。它们是所谓的“基于模型的”方法。这为后续学习强化学习奠定了基础。\r\n强化学习研究的核心问题之一就是：当智能体不知道这些模型时，如何通过与环境的交互来学习到最优策略。我们将会看到，强化学习中的许多算法，都可以被看作是值迭代或策略迭代的无模型\r\n(model-free) 版本。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Markov Decision Process, MDP(17)","url":"/2025/08/30/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/17/","content":"强化学习任务通常使用马尔可夫决策过程（MDP）来描述。MDP\r\n是一个为具有不确定性的序贯决策问题提供数学模型的框架。其核心在于一个智能体（Agent）与环境（Environment）的持续交互：智能体感知当前状态，执行一个动作，环境随之转移到一个新的状态，并给予智能体一个奖励。这个循环不断持续，智能体的目标是学习一个最优策略，以最大化其长期累积奖励。\r\n\r\n所谓序贯决策，指的是决策者需要连续不断地做出决策，并且每个决策都会影响到未来的结果。\r\n\r\n参考内容: MDP与强化学习\r\n马尔可夫决策过程 (MDP)\r\n一个MDP由以下几个核心要素构成：\r\n\r\n状态集合 (A set of states S)：智能体可能所处的所有状态。\r\n行动集合 (A set of actions\r\nA)：智能体在每个状态下可以采取的行动。\r\n转移函数 (A transition function T(s, a,\r\ns’))：这是对世界动态的概率性描述。T(s, a, s’) = P(s’ | s, a) 表示在状态\r\ns 执行行动 a 后，转移到状态 s’ 的概率。\r\n奖励函数 (A reward function R(s, a, s’))：描述了智能体从状态\r\ns 采取行动 a 并转移到状态\r\ns’\r\n后获得的即时奖励。这个奖励反映了智能体的“偏好”。智能体的目标是最大化其长期累积奖励，而不是眼前的单步奖励。\r\n折扣因子 (A discount factor\r\nγ)：一个介于0和1之间的数，用于平衡即时奖励和未来奖励的重要性。\r\n\r\nγ 越接近1，智能体越有“远见”，会更看重未来的长期回报。\r\nγ 越接近0，智能体越“短视”，只关心眼前的即时奖励。\r\n一个在时间步 t 发生的奖励 R，其价值会被折扣为 γt × Rt\r\n它保证了即使在一个无限时间的过程中，效用的总和也是一个有限值，从而使问题在数学上是可解的。\r\n\r\n\r\n策略（Policy, π）\r\n一个策略 π\r\n是一个从状态到行动的映射，即 π(s) =\r\na。它告诉智能体在每个状态下应该做什么。一个最优策略 π*\r\n则是那个能够最大化期望的总折扣奖励(Discounted\r\nCumulative Reward)，也称为回报（Return）的策略。\r\n回报与折扣（Return &amp;\r\nDiscounting）\r\n一个状态序列的效用被定义为所有奖励的折扣总和： U = R(s0, a0, s1) + γR(s1, a1, s2) + γ2R(s2, a2, s3) + ...\r\n当 0 &lt; γ &lt; 1 时，这个无限序列的和是有限的，其上界为 Rmax/(1 − γ)，其中\r\nRmax\r\n是可能的最大单步奖励\r\n价值函数\r\n为了评估一个策略的好坏，我们使用价值函数来量化一个状态或一个”状态-动作”对的长期价值。\r\n\r\n最优状态价值函数 (Optimal Value Function, U*(s) 或 V*(s))：代表从状态\r\ns\r\n出发，并从此遵循最优策略，所能获得的期望总回报。\r\n最优动作价值函数 (Optimal Q-Value Function, Q*(s, a))：代表在状态\r\ns 采取动作 a\r\n后，再遵循最优策略，所能获得的期望总回报。\r\n\r\n这也被称为 (s, a) 对的 Q值 (Q-value)。\r\n\r\n\r\n这两者之间的关系非常直观：一个状态的最优价值，等于从该状态出发所有可能的动作中，能带来的最优动作价值的最大值。\r\nU*(s) = maxaQ*(s, a)\r\n贝尔曼方程 (The Bellman\r\nEquation)\r\n贝尔曼方程是 MDP\r\n中最核心的方程，它通过一种递归的方式将一个状态的价值与其后续状态的价值关联起来，是求解\r\nMDP 的基础 。\r\n贝尔曼期望方程\r\n(Bellman Expectation Equation)\r\n用途：用于评估一个已知且固定的策略\r\nπ。它回答的问题是：“如果我遵循这个策略，每个状态/动作的长期价值是多少？”\r\n。\r\n\r\n状态价值函数 (vπ(s))：计算在遵循策略\r\nπ 时，状态 s 的期望回报。\r\n\r\nvπ(s) = ∑a ∈ Aπ(a|s)(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ vπ(s′))\r\n\r\n动作价值函数 (qπ(s, a))：计算在状态\r\ns 执行动作 a 后，继续遵循策略 π 所带来的期望回报。\r\n\r\nqπ(s, a) = R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ vπ(s′)\r\n贝尔曼最优方程\r\n(Bellman Optimality Equation)\r\n用途：用于求解最优价值函数，它定义了一个价值函数在最优时必须满足的条件。它回答的问题是：“在所有可能的策略中，每个状态/动作能达到的最大价值是多少？”\r\n\r\n最优状态价值函数 (v*(s) 或 U*(s))：计算状态\r\ns 在所有策略中可能达到的最大期望回报。\r\n\r\nv*(s) = maxa(R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ v*(s′))\r\n\r\n最优动作价值函数 (q*(s, a)\r\n或 Q*(s, a))：计算在状态\r\ns 执行动作 a 后，按照最优策略执行所带来的最大期望回报。\r\n\r\nq*(s, a) = R(s, a) + γ∑s′ ∈ SP(s′|s, a) ⋅ v*(s′)\r\n因为我们的研究方向是最优解, 因此后续的分析中主要关注贝尔曼最优方程。\r\n而贝尔曼最优方程可以被看作是动态规划的两步：\r\n\r\n计算期望：对于每个动作 a，计算其期望价值 Q*(s, a)（类似于Expectimax算法中的机会节点）。\r\n取最大值：选择那个使 Q*(s, a)\r\n最大的动作，其价值就是 U*(s)（类似于最大化节点）。\r\n\r\n到这里,\r\n我们不要忘记核心目标是找到求解贝尔曼方程的方法，从而找到最优策略。这通常通过动态规划算法实现，我们将在下一讲学习具体的算法，如值迭代\r\n(Value Iteration) 和策略迭代 (Policy Iteration)。\r\n除此之外,\r\n还可以通过强化学习的方法解决MDP问题。它们的核心区别是环境是否已知,\r\n这是区分传统 MDP 解决方法（如动态规划）和强化学习方法的关键点。\r\n如果 MDP 的所有要素（S,A,T,R,γ）都是已知的：\r\n\r\n这种情况下，我们称之为基于模型的（Model-Based）\r\n方法。我们可以使用动态规划（Dynamic Programming）\r\n等方法直接计算出最优策略，例如通过价值迭代（Value\r\nIteration）或策略迭代（Policy Iteration）。\r\n\r\n如果 MDP 的转移概率 P 和/或奖励函数 R 是未知的：\r\n\r\n这在现实世界中非常常见。例如，我们不知道机器人执行“向北”指令后，具体会以多大概率到达哪个新位置。智能体必须通过与环境的实际交互（试错）来学习。\r\n强化学习正是为了解决这类问题而生的。它是一套无模型（Model-Free）\r\n或试图学习模型的算法。智能体在未知的环境中，通过不断地尝试、观察结果（下一个状态和奖励），逐步地学习和改进自己的策略。\r\n常见的 RL 算法：\r\n\r\nQ-Learning 和 SARSA\r\n这类基于价值的算法，通过估计每个“状态-动作”对的价值来学习策略。\r\n策略梯度（Policy Gradient） 方法，直接对策略函数进行优化。\r\n深度强化学习（Deep Reinforcement Learning, DRL），如 DQN、A3C\r\n等，将深度学习与强化学习结合，使其能够处理高维度的状态空间（例如，直接从游戏屏幕的像素学习）。\r\n\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- State Spaces, Uninformed Search","url":"/2025/08/04/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/2/","content":"为了让一个理性的规划智能体能够行动，我们首先需要一种数学化的方式来描述它所处的环境\r\n。搜索问题 (Search Problem)\r\n的核心就是：给定智能体当前的状态，如何以最优的方式找到一条路径，到达满足其目标的新状态\r\n。\r\n搜索问题的形式化定义\r\n一个搜索问题由以下六个核心要素构成 ：\r\n\r\n状态空间 (State Space)：在一个特定世界中所有可能状态的集合 。\r\n行动集合 (Actions)：在每个状态下，智能体可以采取的一系列行动 。\r\n转移模型 (Transition\r\nModel)：描述了当在当前状态下采取一个特定行动后，会转移到哪个新状态\r\n。\r\n行动成本 (Action Cost)：从一个状态转移到另一个状态所产生的代价\r\n。\r\n初始状态 (Start State)：智能体最初所处的状态 。\r\n目标测试 (Goal Test)：一个函数，用于判断给定的状态是否是目标状态\r\n。\r\n\r\n状态空间 (State Space)\r\n状态空间 (State Space) 是搜索问题中最重要的概念之一\r\n。它定义了在特定世界中所有可能的状态 。\r\n其中主要区分两种状态空间：世界状态 vs. 搜索状态\r\n\r\n世界状态 (World State) 包含了一个状态的所有信息 。\r\n\r\n搜索状态 (Search State) 只包含对规划必要的信息，这主要是为了节省空间\r\n。\r\n\r\n状态空间图和搜索树(State\r\nSpace Graph and Search Tree)\r\n这是理解搜索算法如何工作的两个关键结构。\r\n\r\n状态空间图 (State Space Graph)\r\n\r\n节点是状态，有向边是行动 。\r\n每个状态在图中只出现一次 。\r\n\r\n搜索树 (Search Tree)\r\n\r\n节点不仅代表一个状态，更代表一条从初始状态到达该状态的完整路径\r\n。\r\n由于从起点到同一个状态可能有多条路径，因此同一个状态可能在树中出现多次\r\n。\r\n算法在解决问题时，会按需 (on-demand)\r\n构建搜索树，只存储和扩展当前需要处理的节点（即“前沿”），从而应对其巨大的潜在规模\r\n。\r\n\r\n\r\n\r\n无信息搜索 (Uninformed\r\nSearch)\r\n当智能体对目标状态的位置没有任何先验知识时，它只能采用无信息搜索策略\r\n。这些策略都基于上述提到的通用的树搜索 (Tree Search)\r\n框架，即维护一个待扩展节点的前沿\r\n(frontier)，并根据不同策略选择下一个要扩展的节点 。\r\n树搜索框架 (Tree Search)\r\n树搜索不是一次性构建整个搜索树，而是通过维护和扩展前沿来逐步、动态地构建这棵树，这个框架可以被概括为以下几个步骤：\r\n1.初始化前沿：搜索开始时，将包含初始状态的节点（即搜索树的根节点）放入前沿。这是我们探索的起点\r\n。\r\n2.循环探索：只要前沿不为空（意味着还有未探索的路径），就继续循环。如果前沿为空，则说明所有可达路径都已探索完毕，但仍未找到目标，因此搜索失败\r\n。\r\n3.选择并移除节点：根据预设的策略，从前沿中选择一个节点并将其移除。正是这个选择策略，决定了搜索算法是DFS、BFS还是UCS。\r\n4.目标测试：检查刚刚移除的节点是否包含目标状态。如果是，那么从该节点回溯至根节点的路径就是我们找到的解决方案，搜索成功结束\r\n。\r\n5.扩展节点：如果上一步的节点不是目标，我们就对其进行“扩展”。这意味着，我们会考虑从该节点所代表的状态出发，可以执行的所有行动，并为每个行动在原先的节点基础上加上一个新的子节点（代表新的路径和新的状态）。然后，将这些新生成的子节点加入到前沿中，等待未来的探索\r\n。\r\n\n    示例 \n    \n      假设我们的目标是从城市 S 到达城市 G。\r\n\r\n初始状态: 前沿 (Frontier): [ Node(S) ] ,\r\n此时我们的探索列表里只有一个起点。\r\n第 1 轮循环:\r\n\r\n移除: 算法从前沿中选择并移除 Node(S)。\r\n当前前沿: [ ] (暂时为空)\r\n目标测试: S 是不是目标 G？不是。\r\n扩展: 我们对 Node(S) 进行扩展。假设从 S 可以到达 A 和\r\nB。\r\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;A) 和\r\nNode(S-&gt;B)。\r\n加入前沿: 将这两个新节点加入前沿。\r\n当前前沿: [ Node(S-&gt;A), Node(S-&gt;B) ]\r\n\r\n第 2 轮循环 (假设使用BFS策略，选择最浅的节点):\r\n\r\n移除: 算法从前沿中选择并移除 Node(S-&gt;A)。\r\n当前前沿: [ Node(S-&gt;B) ]\r\n目标测试: A 是不是目标 G？不是。\r\n扩展: 我们对 Node(S-&gt;A) 进行扩展。假设从 A 可以到达 C 和\r\nD。\r\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;A-&gt;C) 和\r\nNode(S-&gt;A-&gt;D)。\r\n加入前沿: 将这两个新节点加入前沿。\r\n当前前沿: [ Node(S-&gt;B), Node(S-&gt;A-&gt;C),\r\nNode(S-&gt;A-&gt;D) ]\r\n\r\n第 3 轮循环 (继续使用BFS策略):\r\n\r\n移除: 算法从前沿中选择并移除 Node(S-&gt;B)。\r\n当前前沿: [ Node(S-&gt;A-&gt;C), Node(S-&gt;A-&gt;D) ]\r\n目标测试: B 是不是目标 G？不是。\r\n扩展: 我们对 Node(S-&gt;B) 进行扩展。假设从 B 可以到达 E 和\r\nG。\r\n步骤说明：我们生成了两个新的子节点：Node(S-&gt;B-&gt;E) 和\r\nNode(S-&gt;B-&gt;G)。\r\n加入前沿: 将这两个新节点加入前沿。\r\n当前前沿: [ Node(S-&gt;A-&gt;C), Node(S-&gt;A-&gt;D),\r\nNode(S-&gt;B-&gt;E), Node(S-&gt;B-&gt;G) ]\r\n\r\n第 4 轮循环:\r\n\r\n移除: 算法从前沿中选择并移除 Node(S-&gt;A-&gt;C)…\r\n这个过程会继续下去。\r\n直到某一次循环，比如第 N 轮：\r\n移除: 算法从前沿中选择并移除 Node(S-&gt;B-&gt;G)。\r\n目标测试: G 是不是目标 G？是的！\r\n返回结果: 搜索成功，返回\r\nNode(S-&gt;B-&gt;G)。通过这个节点，我们可以回溯出完整的路径是 S -&gt; B\r\n-&gt; G。\r\n\r\n\r\n总之,\r\n这里的移除一个节点，并不是把它丢弃或忘记，而是把它从“待办事项”列表（前沿）中拿出来，准备对其进行处理。\r\n而扩展一个节点，就是基于当前路径，探索所有下一步的可能性,\r\n例如查看状态A所有可能的行动（比如可以去B、C、D），然后为每一个行动生成一个新的子节点。\r\n\n    \n  \r\n# pseudocode for tree searchfunction TREE-SEARCH(problem, frontier) return a solution or failure    frontier ← INSERT(MAKE-NODE(INITIAL-STATE[problem]), frontier)    while not IS-EMPTY(frontier) do        node ← POP(frontier)        if problem.IS-GOAL(node.STATE) then            return node        end        for each child-node in EXPAND(problem, node) do            add child-node to frontier        end    end    return failurefunction EXPAND(problem, node) yields nodes    s← node.STATE    for each action in problem.ACTIONS(s) do        s′ ← problem.RESULT(s, action)    end    yield NODE(STATE=s′, PARENT=node, ACTION=action)\r\n三种核心策略\r\n\r\n对于每种策略，我们也将介绍其一些基本性质，从以下几个方面进行说明：\r\n每种搜索策略的完备性————如果搜索问题存在解，该策略是否在无限计算资源下保证能找到解？\r\n每种搜索策略的最优性————如果搜索问题存在解，该策略是否能找到最优解？\r\n每种搜索策略的时间和空间复杂度 分支因子\r\nb -\r\n每次从前沿队列中取出一个节点并用其子节点替换时，前沿节点数量增加的量是\r\nO(b)。在搜索树的深度 k 处，存在 O(b^k)个节点。\r\n\r\n\r\n深度优先搜索 (Depth-First Search - DFS)\r\n\r\n描述：总是选择最深的前沿节点进行扩展 。\r\n前沿表示：使用后进先出 (LIFO)\r\n栈，因为它总是优先处理最新加入的节点（即更深的节点）\r\n。\r\n性质：\r\n\r\n完备性：不完备。如果状态空间图中存在环路，搜索树可能会无限深，导致DFS陷入死循环\r\n。\r\n最优性：不最优。它找到的是搜索树中“最左侧”的解，不考虑路径成本\r\n。\r\n\r\n时间复杂度：O(bm)，其中\r\nb 是分支因子，m 是最大深度 。\r\n空间复杂度：O(bm)。这是它的主要优势，因为它只需要存储一条路径上的节点\r\n。 &gt; 一条路径的最大长度是\r\nm。在这条路径上的每个节点，最多在生成的时候扩展了 b-1\r\n个兄弟节点存储在前沿（栈）中，等待当前路径探索失败后回溯时使用。因此，总共需要存储的节点数大约是\r\n(b − 1) * m\r\n\r\n广度优先搜索 (Breadth-First Search - BFS)\r\n\r\n描述：总是选择最浅的前沿节点进行扩展 。\r\n前沿表示：使用先进先出 (FIFO)\r\n队列，以保证按层级顺序访问节点 。\r\n性质：\r\n\r\n完备性：完备。因为它保证会搜索到最浅的解所在的有限深度 s\r\n。\r\n最优性：当所有行动成本相同时，它是最优的，因为它找到的是深度最浅的解\r\n。\r\n\r\n时间复杂度：O(bs)，其中\r\ns 是最浅解的深度 。\r\n空间复杂度：O(bs)。这是它的主要缺点，前沿需要存储整层的节点\r\n。\r\n\r\n一致成本搜索 (Uniform Cost Search - UCS)\r\n\r\n描述：UCS 是 BFS\r\n的一个重要泛化，它从“找到步数最少的路径”升级为“找到成本最低的路径”,\r\n其总是选择从初始状态到当前节点路径成本最低的前沿节点进行扩展\r\n。\r\n\r\nUCS 的策略与著名的 Dijkstra 算法完全相同。主要区别在于，UCS\r\n在找到第一个目标状态时就停止，而 Dijkstra\r\n算法会继续运行，直到找到从起点到图中所有节点的最短路径。\r\n\r\n前沿表示：使用基于堆的优队列 (Priority\r\nQueue)，节点的优先级由其路径成本决定 。\r\n\r\n每个节点被放入优先队列时，它的优先级被设定为其从初始状态到该节点的路径成本。\r\n优先队列的特性保证了成本最低的节点总是位于队列的“顶部”。\r\n当算法需要选择下一个节点时，它只需从队列顶部取出一个即可。\r\n当新的子节点被加入队列时，优先队列会自动根据它们的路径成本进行内部排序（“重新洗牌”），以确保成本最低的节点始终在最前面。\r\n\r\n性质：\r\n\r\n完备性：完备（只要存在有限成本的解） 。\r\n最优性：最优（只要行动成本非负）。因为它按路径成本递增的顺序扩展节点\r\n。\r\n\r\n负成本问题：如果存在负成本的边，UCS\r\n的最优性保证就会失效，因为它可能先找到一条看起来成本低的路径，但之后却发现另一条更长的路径因为有负成本边而总成本更低。\r\n\r\n\r\n时间复杂度：O(bC*/ϵ)\r\n\r\nC*：最优解的路径成本。\r\nϵ：任意两个节点之间最小的行动成本（必须大于0）。\r\nC*/ϵ：这个比值可以理解为最优路径的“有效深度”。它粗略地告诉我们，要凑够最优成本\r\nC*，在最理想的情况下（即每一步都走成本最低的\r\nϵ\r\n路径），大约需要走多少步。如果所有行动成本都是1，那么 ϵ = 1，C* = s，这个比值就等于最浅解的深度\r\ns，复杂度就退化为 BFS 的 O(bs)\r\n这个“有效深度”的概念，将 UCS 的行为与 BFS 统一了起来。BFS\r\n是在探索一个“深度圈”，而 UCS\r\n是在探索一个“成本圈”。C*/ϵ\r\n就是这个成本圈的半径的近似度量。\r\n\r\n空间复杂度：O(bC*/ϵ)\r\n\r\n和 BFS 类似，UCS 的空间瓶颈在于前沿 (frontier)\r\n的大小。在即将找到成本为 C*\r\n的最优解时，前沿中会包含大量路径成本约等于 C* 的节点。\r\n\r\n\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Particle Filtering, Utility Theory(16)","url":"/2025/08/26/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/16/","content":"我们已经学习了隐马尔可夫模型（HMMs），但当状态空间变得非常大或连续时，精确的前向算法在计算上变得不可行。粒子滤波提供了一种强大的近似推理方法来解决这个问题,\r\n是HMMs的“采样”版本。。\r\n粒子滤波\r\n粒子滤波的核心目标是，在一个动态系统中，根据一系列带噪音的、不完整的观测数据，实时地、近似地追踪一个我们无法直接看到的隐藏状态。\r\n它专门用于解决那些状态空间巨大或连续的问题，例如：\r\n\r\n机器人定位：机器人在一个连续的2D或3D空间中的精确位置。\r\n物体追踪：追踪雷达信号中飞机的精确位置和速度。\r\n金融预测：追踪一个经济体背后那个复杂且不可见的“真实状态”。\r\n\r\n在这些问题中，像前向算法那样的精确算法因为需要处理无限或天文数字级别的状态而完全不可行。\r\n其核心思想是, 用“群体智慧”近似“真实情况”,\r\n放弃了为每个可能状态计算精确概率的想法，转而采用一种基于采样的“群体模拟”思想\r\n在HMM模型下的步骤\r\n\r\nHMM是描述问题的“理论框架”，而粒子滤波则是解决这个框架下特定问题的一种实用算法\r\n\r\n首先, 我们再次阐述HMM的模型结构:\r\n\r\n隐藏状态 (Xt)：我们关心但无法直接观测的变量（例如，物体的真实位置）。\r\n观测证据 (Et)：我们能实际测量到的数据（例如，摄像头的读数）。\r\n初始分布 (P(X0))：描述了在最开始时，隐藏状态的概率分布。\r\n转移模型 (P(Xt + 1|Xt))：描述了隐藏状态随时间演变的规律（例如，物体如何从一个位置移动到另一个位置）。\r\n发射模型 (P(Et|Xt))：描述了在某个隐藏状态下，产生特定观测证据的概率（例如，在某个真实位置，摄像头读数为某值的概率）。\r\n\r\nHMM的目标之一：计算在给定所有历史观测证据 e1 : t\r\n的情况下，当前隐藏状态 Xt\r\n的概率分布，即 P(Xt|e1 : t)。当状态空间巨大时，粒子滤波就是实现这一目标的强大工具。\r\n而粒子滤波的每一步, 恰恰精确地对应了HMM框架的每一个组成部分：\r\n\r\n初始化 (Initialization) 算法操作：生成 N\r\n个初始粒子，每个粒子代表一个对初始隐藏状态的猜测。\r\n\r\nHMM中的对应：这个过程直接使用了HMM的初始分布 P(X0)。算法会根据\r\nP(X0)\r\n来进行采样。如果初始分布是均匀的，粒子就会被均匀地撒在所有可能的状态上；如果初始分布集中在某个区域，那么大部分粒子就会被生成在该区域。\r\n\r\n提议 (Proposal)\r\n算法操作：对于现有的每一个粒子，预测它在下一个时间步的位置。这也被称为时间流逝更新。\r\n\r\nHMM中的对应：这个预测过程完全由HMM的转移模型 P(Xt + 1|Xt)\r\n驱动。对于一个当前状态为 xt\r\n的粒子，算法会从条件概率分布 P(Xt + 1|Xt = xt)\r\n中随机采样一个新的状态 xt + 1，作为该粒子移动后的新位置。\r\n\r\n加权 (Weighting) 算法操作：在粒子完成移动后，我们获取了新的观测证据\r\net + 1。现在，我们需要根据这个新证据为每一个粒子打分（赋予权重）。\r\n\r\nHMM中的对应：这个打分过程精确地使用了HMM的发射模型 P(Et|Xt)。对于一个预测位置为\r\nxt + 1\r\n的粒子，它的权重正比于 P(Et + 1 = et + 1|Xt + 1 = xt + 1)。这意味着，如果一个粒子的预测位置能够很好地”解释”我们看到的证据，它的权重就高；反之则权重低。\r\n\r\n重采样 (Resampling)\r\n算法操作：淘汰低权重的粒子，复制高权重的粒子，生成新一代的粒子群。\r\n\r\nHMM中的对应：这一步是整个滤波（Filtering）过程的核心。它将由发射模型提供的信息（即权重）“吸收”到粒子群中，使得新的粒子群能够更好地近似后验概率分布\r\nP(Xt + 1|e1 : t + 1)。具体步骤是从旧的粒子中进行有放回的随机抽样来生成新100个粒子。一个粒子被抽中的概率正比于它的权重。这是实现”用观测来修正预测”的关键机制。\r\n效用与决策 (Utilities\r\n&amp; Decision Networks)\r\n这部分将我们从单纯的“信念推理”带入到“理性决策”的领域。\r\n理性偏好 (Rational\r\nPreferences)\r\n核心问题：一个理性智能体应该如何做出选择？讲义指出，它必须遵循最大化期望效用\r\n(Maximum Expected Utility) 的原则。\r\n换句话说, 它必须遵从以下五条理性的公理 (Axioms of Rationality)：\r\n\r\n可排序性\r\n(Orderability)：对于任意两个选项，总能做出偏好判断。\r\n传递性 (Transitivity)：偏好不能形成循环。\r\n连续性\r\n(Continuity)：对于不同偏好的选项，总能找到一个概率组合使其等价。\r\n可替代性\r\n(Substitutability)：如果两个选项等价，那么它们在更复杂的选择中可以相互替换。\r\n单调性\r\n(Monotonicity)：如果更喜欢A而不是B，那么在其他条件相同时，会选择获得A概率更高的那个选项。\r\n\r\n如果一个智能体的偏好满足这些公理，那么必然存在一个实值效用函数\r\nU，使得智能体的行为可以被描述为在最大化这个函数的期望值。\r\n决策网络 (Decision Networks)\r\n决策网络是贝叶斯网络的一个扩展，它将概率、行动和效用整合到了一个统一的图形模型中,\r\n可以被看作是贝叶斯网络和期望最大化 (Expectimax) 算法的结合体 。\r\n其具有三种节点类型：\r\n\r\n机会节点 (Chance\r\nNodes)：椭圆形，代表随机变量，和贝叶斯网络中的节点一样。\r\n行动节点 (Action\r\nNodes)：矩形，代表智能体可以选择的行动。\r\n效用节点 (Utility\r\nNodes)：菱形，代表最终的效用值。效用节点是决策网络的核心，它没有子节点，其父节点通常是行动节点和一些机会节点\r\n。它的作用是根据其父节点的状态（即采取的行动和随机事件的结果）输出一个数值，这个数值代表了智能体在该情况下的“满意度”或“回报”\r\n。\r\n\r\n使用决策网络的最终目标是选择能带来最大期望效用\r\n(Maximum Expected Utility, MEU)\r\n的行动。这个过程可以通过一个清晰的、分步骤的算法来实现：\r\n\r\n第一步：实例化证据并进行概率推理(计算)\r\n\r\n首先，我们将所有已知的证据（例如，天气预报是“坏”）在网络中进行实例化\r\n。然后，利用贝叶斯网络的推理算法（如变量消除或采样），计算出效用节点的所有机会父节点的后验概率分布\r\n。\r\n这一步的目的是更新我们对世界状态的信念。例如，当我们得知天气预报是“坏”时，下雨的概率会比不知道预报时更高。我们需要这个更新后的概率来更准确地评估行动的后果。\r\n\r\n第二步：为每个可能的行动计算期望效用\r\n接下来，我们遍历行动节点中的每一个可能行动。对于每个行动 a，我们根据第一步计算出的后验概率，计算其期望效用\r\nEU(a|e)\r\n。计算公式如下：\r\n\r\nEU(a|e) = ∑x1, ..., xnP(x1, ..., xn|e)U(a, x1, ..., xn)\r\n其中：\r\na 是当前考虑的行动。\r\ne 是已知的证据。\r\nx1, ..., xn\r\n是效用节点的所有机会父节点的各种状态组合。\r\nP(x1, ..., xn|e)\r\n是在给定证据 e\r\n的情况下，这些机会节点处于特定状态组合的后验概率。\r\nU(a, x1, ..., xn)\r\n是在采取行动 a 且机会事件为\r\n(x1, ..., xn)\r\n时，效用节点给出的具体效用值。\r\n这个公式本质上是在计算一个加权平均值\r\n。我们将每种可能结果的效用值，乘以该结果发生的概率，然后将所有可能结果的加权效用相加，就得到了采取该行动的平均期望回报。\r\n第三步：选择最优行动\r\n最后，我们比较所有行动的期望效用，并选择那个能够产生最高期望效用的行动\r\n。这个最高的期望效用值就是 MEU(e)。\r\nMEU(e) = maxaEU(a|e)\r\n这一步是最终的决策环节。作为一个理性的智能体，我们选择那个在统计上最有可能给我们带来最佳结果的行动。\r\n示例分析\r\n\r\n这个例子的目标是，在已知”天气预报是坏消息” (Forecast = bad)\r\n的前提下，计算出能带来最大期望效用 (MEU) 的行动。\r\n第一步：明确已知信息:\r\n在采取行动前，我们已经通过贝叶斯网络推理获得了关键信息, 即后验概率\r\n(Posterior Probabilities)给定预报为”坏”，实际天气的概率分布如下。\r\n\r\nP(Weather = sun|Forecast = bad) = 0.34\r\nP(Weather = rain|Forecast = bad) = 0.66\r\n\r\n效用表 (Utility Table)：不同行动和天气组合下的效用值如下。\r\n\r\nU(leave, sun) = 100\r\n(不带伞，天晴，完美)\r\nU(leave, rain) = 0\r\n(不带伞，下雨，最糟)\r\nU(take, sun) = 20\r\n(带伞，天晴，有点累赘)\r\nU(take, rain) = 70\r\n(带伞，下雨，非常明智)\r\n\r\n第二步：计算每个行动的期望效用 (EU)\r\n我们使用期望效用公式 EU(a|e) = ∑wP(w|e)U(a, w)\r\n来分别评估两个行动。\r\n\r\n行动：不带伞 (leave)\r\n这个行动的期望效用是两种天气结果（晴天和雨天）的效用与其相应概率的加权和。\r\n\r\nEU(leave|bad) = P(sun|bad) × U(leave, sun) + P(rain|bad) × U(leave, rain)\r\nEU(leave|bad) = (0.34 × 100) + (0.66 × 0)\r\nEU(leave|bad) = 34 + 0 = 34\r\n这个计算告诉我们，在预报为坏的情况下，如果不带伞，我们平均可以期望获得\r\n34 个单位的效用。这个值综合了 34% 的概率获得 100 效用和 66% 的概率获得 0\r\n效用的情况。\r\n\r\n行动：带伞 (take) 同理，我们计算带伞这一行动的期望效用。\r\n\r\nEU(take|bad) = P(sun|bad) × U(take, sun) + P(rain|bad) × U(take, rain)\r\nEU(take|bad) = (0.34 × 20) + (0.66 × 70)\r\nEU(take|bad) = 6.8 + 46.2 = 53\r\n这个计算表明，如果带伞，我们平均可以期望获得 53\r\n个单位的效用。它平衡了”天晴时带伞有点麻烦”（效用20）和”下雨时带伞非常有用”（效用70）这两种可能性。\r\n第三步：选择最优行动\r\n最后一步是比较两个行动的期望效用，并选择值最大的那个。\r\nMEU(F = bad) = max(EU(leave|bad), EU(take|bad))\r\nMEU(F = bad) = max(34, 53) = 53\r\n结论：因为行动”带伞 (take)“的期望效用 (53) 大于”不带伞 (leave)”\r\n(34)，所以理性的决策是带伞\r\n完美信息价值\r\n(Value of Perfect Information - VPI)\r\n在决策时，我们常常面临一个问题：是否值得花成本去获取更多的信息？\r\n完美信息的价值 (VPI)\r\n就是一个用来量化“新信息能给我们的决策带来多大好处”的工具 。VPI\r\n的核心思想是计算在获取新证据之前和获取新证据之后，最大期望效用的差值\r\n。\r\nVPI 的计算公式定义为：VPI(E′|e) = MEU(e, E′) − MEU(e)\r\n其中：\r\n\r\nMEU(e)\r\n是仅基于当前证据 e\r\n所能得到的最大期望效用。\r\nMEU(e, E′)\r\n是在决定观察新证据变量 E′ （但还不知道 E′\r\n的具体值）之后，我们期望能得到的最大期望效用。它的计算方式是：\r\n\r\nMEU(e, E′) = ∑e′P(e′|e)MEU(e, e′)\r\n这里 P(e′|e)\r\n是观察到新证据具体值为 e′ 的概率，MEU(e, e′)\r\n是当我们同时拥有旧证据 e\r\n和新证据 e′\r\n时的最大期望效用。\r\n\r\n\r\n示例分析 : 是否要看天气预报？\r\n假设我们一开始没有任何证据（e 为空集 ∅），我们想知道”看天气预报”这个信息的价值是多少。\r\n下面我们先计算无证据时的 MEU：\r\n首先，我们用先验概率 P(W) 计算 MEU(∅)。假设 P(sun) = 0.7, P(rain) = 0.3\r\n。\r\nEU(leave) = 0.7 × 100 + 0.3 × 0 = 70\r\nEU(take) = 0.7 × 20 + 0.3 × 70 = 14 + 21 = 35\r\nMEU(∅) = max (70, 35) = 70\r\n。\r\n下面我们计算获取新信息后的期望 MEU：\r\n我们需要计算如果我们看了天气预报 (F)，期望的 MEU\r\n是多少。我们需要知道 P(F) 的分布，假设 P(F = good) = 0.59，P(F = bad) = 0.41\r\n。\r\n我们已经计算出 MEU(F = bad) = 53\r\n。假设我们同样可以计算出 MEU(F = good) = 95\r\n。\r\n那么，期望的 MEU 是：\r\nMEU(F) = P(F = good)MEU(F = good) + P(F = bad)MEU(F = bad)\r\nMEU(F) = (0.59 × 95) + (0.41 × 53) = 56.05 + 21.73 = 77.78\r\n计算 VPI： VPI(F) = MEU(F) − MEU(∅) = 77.78 − 70 = 7.78\r\n。\r\n这个结果意味着，天气预报这个”完美信息”平均能给我们的决策带来 7.78\r\n个效用单位的提升。如果获取预报的成本（例如时间、金钱）低于这个值，那么我们就应该去获取它\r\n。\r\nVPI 的重要性质\r\n\r\n非负性：VPI(E′|e) ≥ 0。获取新信息永远不会让你的期望决策变得更糟，最差也是保持不变\r\n。\r\n非可加性：VPI(Ej, Ek|e) ≠ VPI(Ej|e) + VPI(Ek|e)。通常情况下，不同信息之间的价值不是简单相加的，因为它们可能包含重叠或互补的信息\r\n。\r\n顺序无关性：VPI(Ej, Ek|e) = VPI(Ej|e) + VPI(Ek|e, Ej)。获取一组信息的总价值与你观察它们的顺序无关\r\n。\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- Informed Search - A* and Heuristics","url":"/2025/08/08/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/3/","content":"无信息搜索（如UCS）虽然能保证找到最优解，但它像是在黑暗中摸索，会向所有方向均匀扩展，效率低下。如果我们能给智能体一些关于“目标大概在哪个方向”的提示，搜索就能变得更高效。这种提示就是启发式\r\n(Heuristics)。\r\n启发式 (Heuristics)\r\n启发式是一个函数 h(n)，它接收一个状态 n\r\n作为输入，输出一个对“从状态 n\r\n到达目标的剩余成本”的估计值。\r\n启发式的来源：松弛问题\r\n(Relaxed Problem)\r\n好的启发式通常来自于对原问题的“松弛” (Relaxed Problem)\r\n松弛问题是通过移除原问题的一些约束得到的简化版问题。下面以吃豆人寻路示例：\r\n\r\n原问题：吃豆人必须在迷宫中穿行，不能穿墙。\r\n约束：不能穿墙。\r\n松弛：我们移除“不能穿墙” 这个约束。\r\n松弛问题：在一个没有墙的开放网格中，从A点到B点的最短路径是什么？\r\n松弛问题的精确解：这个解就是曼哈顿距离 (|x₁ - x₂| + |y₁ - y₂|)\r\n。\r\n\r\n原问题比松弛问题有更多的约束（比如有墙），所以在原问题中从 n\r\n到目标的真实最短路径成本 h*(n)，必然大于或等于在松弛问题中的最短路径成本。\r\n因此，松弛问题的解 h(n) 永远不会高估真实成本，即 h(n) ≤ h*(n)。这正是我们稍后会讲到的可采纳性\r\n(Admissibility) 的关键特征。\r\n综上所述, 对应吃豆人问题, 曼哈顿距离 (|x₁ - x₂| + |y₁ - y₂|)\r\n是在原问题的松弛版（无墙迷宫）中的精确解，因此它可以作为原问题（有墙迷宫）的一个估计值。这种通过简化问题来获得估计值的方法，是设计启发式函数的一条重要原则。\r\n两种有信息搜索策略\r\n有信息搜索策略 (Informed Search)\r\n是基于启发式信息来指导搜索的策略。\r\n贪婪/贪心搜索 (Greedy Search)\r\n这是一种完全由启发式驱动的“短视”策略。它在选择下一个要扩展的节点时，只看\r\nh(n) 的值，即它认为“离目标最近”的那个 。\r\n前沿表示：和UCS一样使用优先队列，但优先级由 h(n) 决定 。\r\n它的特点是不完备且不最优：贪婪搜索完全不考虑已经走过的路径成本\r\ng(n)。它可能会被一个看似离目标很近、但实际上需要绕远路的陷阱所吸引，从而找不到解，或者找到一个成本很高的解。\r\nA* 搜索 (A* Search)\r\nA* 搜索结合了 UCS 和贪婪搜索的优点，它选择估计的总成本 f(n) 最低的节点进行扩展,\r\n这个函数同时考虑了过去和未来 。\r\n这里的f(n) = g(n) + h(n)\r\n\r\ng(n)：从起点到当前节点的实际已知成本（UCS的部分）。\r\nh(n)：从当前节点到目标的估计剩余成本（贪婪搜索的部分）。\r\n\r\nA* 搜索的特点是完备且最优（在特定条件下）,\r\n选择的是估计总路径成本最低的节点,\r\n被誉为“集大成者”，因为它既考虑了已付出的代价（通过\r\ng(n)），又具有前瞻性（通过\r\nh(n)），因此在效率和最优性上取得了完美的平衡。\r\n启发式的性质\r\nA* 搜索的完备性和最优性并非无条件的，它严重依赖于启发式函数 h(n)\r\n的质量。\r\n可采纳性 (Admissibility)\r\n一个启发式是可采纳的，当且仅当它从不高估到目标的真实成本。即对于所有节点\r\nn，0 ≤ h(n) ≤ h*(n)，其中\r\nh*(n) 是从\r\nn 到目标的真实最低成本。\r\n可采纳性是保证 A* 树搜索 (Tree Search) 最优性的关键条件。\r\n一个“乐观”的启发式函数是可采纳的,\r\n同时一个好的启发式函数也要在足够乐观的同时尽可能客观(即启发式函数要在较小的里面挑选更大的)。它可能会告诉你“目标(启发函数值)比实际更近”，但绝不会告诉你“目标比实际更远”。这种乐观使得A*算法不会过早地放弃一条可能通往最优解的、当前看起来成本较高的路径。\r\n一致性 (Consistency)\r\n一致性是一个更强的条件。它要求启发式不仅不能高估到目标的总距离，也不能高估任意一步的成本。对于任意节点\r\nA 和其子节点 C，从 A 到 C 的启发式成本差，不应大于 A 到 C 的实际行动成本\r\n。数学上表示为：h(A) − h(C) ≤ cost(A, C)\r\n。\r\n一致性是保证 A* 图搜索 (Graph Search) 最优性的关键条件 。\r\n支配性 (Dominance)\r\n如果对于所有节点 n，启发式 ha(n) ≥ hb(n)，那么我们说\r\nha 支配\r\nhb。\r\n在所有可采纳的启发式中，值越大的（即越接近真实成本 h*(n)\r\n的）启发式越好，因为它能提供更精确的引导，让 A* 扩展更少的节点。\r\n组合启发式的思想：多个可采纳（或一致）的启发式的最大值，仍然是一个可采纳（或一致）的启发式，并且它会支配所有单个的启发式。这为我们构建更好的启发式提供了一种实用的方法。\r\n\r\n图搜索 (Graph Search)\r\n在之前的笔记中，我们讨论的算法（DFS, BFS, UCS,\r\nA*）都可以在两种模式下运行：树搜索模式和图搜索模式。\r\n树搜索 (Tree Search)：它不检查是否重复访问了同一个状态。\r\n图搜索 (Graph\r\nSearch)：这是对树搜索的优化。它会记录所有已经访问并扩展过的状态，以避免重复工作。\r\n从中可见, 树搜索有两个严重的问题，尤其是在状态空间图包含环路 (cycles)\r\n或多条路径到达同一状态时：\r\n\r\n无限循环：如果状态空间中有环（例如 A -&gt; B -&gt; C -&gt;\r\nA），一个简单的树搜索（特别是DFS）可能会永远地在这个环里打转，永远找不到解，导致算法不完备\r\n。\r\n冗余工作：即使没有环路，也常常存在多条不同的路径可以到达同一个状态。树搜索会把每一条路径都当作一个全新的节点来探索，导致对同一个状态及其后续路径进行大量重复计算，极大地浪费时间\r\n。\r\n\r\n而图搜索通过在算法中维护一个额外的集合，通常称为 reached 或\r\nclosed set（已达集合）来优化这个问题, 其步骤如下: 1.\r\n初始化一个空的 reached 集合。\r\n\r\n当算法从前沿 (frontier)\r\n中取出一个节点准备扩展时，首先检查该节点所代表的状态是否已经在\r\nreached 集合中。\r\n\r\n\r\n如果在，则跳过这个节点，不进行扩展，直接进入下一次循环。\r\n如果不在，则将该状态加入 reached\r\n集合，然后正常扩展该节点，将其子节点加入前沿。\r\n\r\n通过这个简单的机制，图搜索保证了每个状态最多只会被扩展一次，从而避免了无限循环和冗余计算。\r\n然而, 图搜索的一个附带问题是，即使使用可采纳的启发式，它也往往会破坏\r\nA* 的最优性, 例如下图: \r\n在上面的例子中，很明显最佳路径是遵循 S → A → C → G，总路径成本为\r\n1+1+3=5。通往目标的其他唯一路径 S → B → C → G 的路径成本为\r\n1+2+3=6。然而，由于节点 A 的启发式值远大于节点 B 的启发式值，节点 C\r\n首先沿着第二条次优路径作为节点 B\r\n的子节点被展开。然后它被放入”已到达”集合中，因此 A 图搜索在它作为节点 A\r\n的子节点访问时未能重新展开它，所以它永远找不到最优解。因此，为了在 A\r\n图搜索下保持最优性，我们需要比可采纳性更强的性质,\r\n也就是之前提到的一致性.\r\n\r\n这也为我们设计更加严格的启发式函数提出了挑战\r\n\r\n下图为一个启发式函数的设计示例\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Search -- Local Search","url":"/2025/08/08/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/4/","content":"局部搜索 (Local Search)概述\r\n与前几讲（如A*搜索）不同，局部搜索算法解决的是另一类问题。在之前的搜索中，我们不仅关心是否能到达目标，还关心如何到达，即找到一条完整的路径\r\n。\r\n然而，在很多问题中，我们只关心最终的解决方案状态，而不关心到达该状态的具体步骤\r\n。\r\n局部搜索 (Local Search)\r\n就是为这类问题设计的。它不维护从起点开始的路径，而是从一个完整的、可能是随机的配置（状态）开始，然后通过一系列局部的、微小的修改，逐步改进这个配置，直到找到一个满足约束或优化了某个目标函数\r\n(objective function) 的状态 。 \r\n爬山算法 (Hill-climbing)\r\n这是最基础的局部搜索算法。它非常“贪婪”，在当前状态下，它会审视所有邻近的状态，并选择那个能使目标函数值提升最大的方向移动一步\r\n。这个过程也被称为最陡峭上升 (steepest-ascent)。\r\n它不维护搜索树, 只保留当前的状态，内存开销极小 。\r\n它的缺点是容易陷入困境：由于其“贪婪”的本性，一旦到达一个局部最大值，它就会因为周围没有更高的点而“卡住”，错误地认为已经找到了顶峰\r\n。同样，它也可能在“高原”上迷失方向 。\r\n其伪代码如下 function HILL-CLIMBING(problem) returns a state    current &lt;- make-node(problem.initial-state)    loop do        neighbor &lt;- a highest-valued successor of current        if neighbor.value ≤ current.value then            return current.state        current &lt;- neighbor\r\n其变体与改进有如下两种：\r\n\r\n随机爬山法 (Stochastic\r\nHill-Climbing)：不是选择最好的上坡方向，而是在所有可能的上坡方向中随机选择一个。这增加了探索性，有时能找到更好的解，但通常需要更多步数\r\n。\r\n随机重启爬山法 (Random-Restart\r\nHill-Climbing)：这是解决局部最大值问题的最有效方法之一。它多次从一个随机生成的初始状态开始运行爬山法。如果一次搜索陷入了局部最大值，就放弃它，重新开始一次新的搜索。这个方法在理论上是完备的，因为只要有足够多的重启次数，总有一次会从全局最大值的“山坡”上开始攀登\r\n。\r\n\r\n模拟退火 (Simulated\r\nAnnealing)\r\n模拟退火是一种更智能的算法，它试图结合爬山法的效率和随机游走的完备性\r\n。它的核心思想是：在搜索初期，允许一些“坏”的移动（即走向目标函数值更低的状态），以帮助算法“跳出”局部最大值的陷阱\r\n。\r\n算法机制：\r\n\r\n接受好移动：如果一个随机选择的移动能提升目标函数值，则总是接受它\r\n。\r\n概率性接受坏移动：如果移动会降低目标函数值，则以一定的概率接受它\r\n。\r\n温度 (Temperature)：这个接受概率由一个叫做“温度”的参数 T\r\n控制。在开始时，T\r\n很高，接受“坏”移动的概率也较高，算法有更多的探索性。随着时间的推移，T\r\n会根据一个“退火时间表\r\n(schedule)”逐渐降低，使得算法越来越倾向于只接受“好”的移动，最终稳定在某个最大值上\r\n。\r\n\r\n理论保证：如果温度下降得足够慢，模拟退火理论上能以趋近于1的概率找到全局最优解\r\n。\r\n局部束搜索 (Local Beam\r\nSearch)\r\n这是爬山法的一个变种，但它不是只维护一个当前状态，而是同时维护 k\r\n个状态（称为一个“束”或“线程”）\r\n它不是简单地并行运行 k 次独立的爬山法 。在每一步，算法会生成这 k\r\n个状态的所有后继状态，然后从这些所有的后继状态中，选择最好的\r\nk 个作为下一代的新状态束 。\r\n这种机制允许信息在不同的搜索路径之间共享。如果某个状态（线程）进入了一个很有希望的区域，它的优良后代就有可能被选中，从而“吸引”其他搜索力量向这个区域集中\r\n。\r\n\r\n遗传算法 (Genetic Algorithms)\r\n遗传算法是一种受生物进化论启发的局部搜索技术，可以看作是局部束搜索\r\n(Local Beam Search) 的一种高级变体。\r\n与传统的爬山法或模拟退火不同，遗传算法不是只维护一个或少数几个状态，而是维护一整个种群\r\n(Population)\r\n的状态。这个种群会像生物世界一样，经历一代又一代的进化，通过选择\r\n(Selection)、交叉 (Crossover) 和变异\r\n(Mutation)，最终演化出适应环境的、高质量的解决方案。\r\n其关键概念如下: - 个体\r\n(Individual)：种群中的每一个成员，代表了问题的一个完整解（状态）。\r\n\r\n基因编码\r\n(Encoding)：每个个体需要被编码成一个字符串，这就像生物的DNA。讲义中以8皇后问题为例，一个解决方案（棋盘布局）被编码为一个8位数字串，如\r\n24748552，其中第 i 个数字代表第 i 列上皇后的行号。\r\n适应度函数 (Fitness\r\nFunction)：这就是局部搜索中的目标函数。它用来评估每个个体的“优劣”程度。对于8皇后问题，适应度函数计算的是不互相攻击的皇后对的数量。一个完美的解，其适应度为\r\n(8*7)/2 = 28。\r\n\r\n\r\n下面以上图的八皇后问题来展示遗传算法的核心流程: - 步骤 (a): 初始种群\r\n(Initial Population) - 算法从一个随机生成的、包含 k\r\n个个体的种群开始。这为进化提供了最初的“基因库”。 -\r\n图中展示了4个随机生成的8皇后棋盘布局的编码。\r\n\r\n步骤 (b): 适应度评估 (Fitness Function)\r\n\r\n使用适应度函数评估种群中每个个体的“好坏”。这个评价值决定了个体在下一轮繁殖中被选中的概率。\r\n图中计算了4个个体的适应度（24, 23, 20,\r\n11），并根据适应度高低计算出它们被选中的概率（31%, 29%, 26%,\r\n14%）。\r\n\r\n步骤 (c): 选择 (Selection)\r\n\r\n模拟“适者生存”的过程。适应度越高的个体，越有可能被选中作为“父母”来繁殖下一代。\r\n根据(b)中的概率，进行了4次随机选择，选出了两对“父母”。注意，适应度较高的个体\r\n32752411 被选中了两次，而最低的 32543213 未被选中。\r\n\r\n步骤 (d): 交叉 (Crossover)\r\n\r\n这是遗传算法最核心、最强大的环节。算法为每一对父母随机选择一个交叉点，然后将它们的“基因串”在该点切开并交换后半部分，从而创造出两个全新的子代。\r\n为什么交叉如此重要？\r\n它允许在不同父代中独立进化出的优良“基因片段”（即解决方案的好的局部结构）被组合在一起，从而有潜力创造出远优于其父代的全新解决方案。\r\n父代 32752411 和 24748552 在第3位后交叉，生成了子代\r\n32748552。这个子代继承了第一个父代的前3个皇后位置和第二个父代的后5个皇后位置。\r\n\r\n\r\n步骤 (e): 变异 (Mutation)\r\n\r\n在子代生成后，其基因串上的每一个位置都有一个很小的概率发生随机突变。\r\n为什么需要变异？\r\n变异为种群引入了新的基因多样性，有助于防止算法过早收敛到某个局部最优解，增加了跳出陷阱、找到全局最优解的可能性。\r\n图中，有三个子代的基因发生了突变（方框标出的数字）。\r\n\r\n\r\n这个“评估 -&gt; 选择 -&gt; 交叉 -&gt;\r\n变异”的循环会不断重复，直到找到一个满足条件的解，或者达到预设的迭代次数。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Games -- Trees, Minimax, Pruning","url":"/2025/08/11/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/5/","content":"进入新的一章,\r\n我们从单智能体环境（智能体与一个被动的世界互动）进入到多智能体的对抗性搜索\r\n(Adversarial Search)\r\n环境中。在这里，环境中存在其他智能体（对手），它们会主动采取行动来阻挠我方目标的实现。\r\n当存在一个理性对手时，一个智能体不能再简单地寻找一条通往目标的路径。它必须假设对手也会采取最优的行动来对抗自己。因此，智能体的策略必须是：在所有可能的对手回应中，选择那个能保证自己获得“最坏情况下的最好结果”的行动。\r\n对抗搜索与博弈树\r\n(Adversarial Search &amp; Game Trees)\r\n对抗搜索问题通常被形式化为博弈 (Games)。这些博弈是零和 (zero-sum)\r\n的，意味着一个玩家的收益就是另一个玩家的损失。\r\n思考这类游戏最简单的方式是将其定义为单个变量值，其中一方或智能体试图最大化，而另一方或智能体试图最小化，从而形成直接竞争。在《吃豆人》中，这个变量是你的得分，你试图通过快速高效地吃豆子来最大化得分，而鬼魂则试图通过首先吃掉你来最小化得分。许多常见的家用游戏也属于这类游戏：如Checkers(跳棋),\r\nChess(国际象棋), Go(围棋)等.\r\n与返回全面计划的常规搜索不同，对抗性搜索返回一个策略或政策，它仅根据我们的智能体及其对手的某种配置推荐最佳可能的移动。\r\n而博弈树 (Game Tree),\r\n就是表示博弈的一种形象方式。其具有以下几个组成部分: - 节点\r\n(Nodes)：代表博弈中的状态 (states)。\r\n\r\n边 (Edges)：代表玩家可以采取的行动 (moves)。\r\n叶节点 (Terminal\r\nNodes)：代表博弈结束的状态，每个叶节点都有一个效用值 (utility\r\nvalue)，表示该结局对第一个玩家（通常称为MAX）的好坏程度。\r\n\r\nMinimax 算法\r\nMinimax 是在对抗博弈中找到最优策略的基础算法,\r\n该算法基于一个激励性的假设运行，即我们面对的对手会采取最优行为，并且始终执行对我们最不利的移动。\r\n同时, 它的名字完美地概括了其核心逻辑：最大化 (Maximize)\r\n自己在对手最小化 (Minimize) 自己收益后的得分。\r\n玩家角色：\r\n\r\nMAX 玩家：试图最大化最终的效用值。\r\nMIN 玩家：试图最小化MAX玩家的最终效用值。\r\n\r\n算法流程（自底向上递归） ：\r\n\r\n生成博弈树：从当前状态开始，一直向下探索到博弈结束的终端状态。\r\n计算终端节点的效用：根据游戏规则，为每个终端状态（叶节点）分配一个效用值。\r\n递归回溯：从叶节点开始，逐层向上计算每个非终端节点的Minimax值。\r\n\r\n对于 MIN\r\n节点：该节点的Minimax值是其所有子节点中的最小值。\r\n对于 MAX\r\n节点：该节点的Minimax值是其所有子节点中的最大值。\r\n\r\n做出决策：在根节点，MAX玩家选择那个通往具有最高Minimax值的子节点的行动。\r\n\r\n\r\n在实现中，minimax 的行为与深度优先搜索类似，计算节点的值的顺序与 DFS\r\n相同，从最左边的终端节点开始，依次向右迭代。更精确地说，它对游戏树进行后序遍历。\r\n\r\nMinimax算法可以为任何有限的、确定性的、完全信息下的双人零和博弈找到最优的行动策略。但它的缺点是必须遍历整个博弈树，时间复杂度为\r\nO(bm)，在像国际象棋这样复杂的博弈中是不可行的。\r\n\r\nAlpha-Beta 剪枝 (Alpha-Beta\r\nPruning)\r\nAlpha-Beta剪枝是Minimax算法的一个极其重要的优化，它可以在不影响最终决策的情况下，剪掉博弈树中大量不必要的分支。\r\n其核心思想是,\r\n在搜索过程中，如果一个分支的探索结果已经被证明不可能比当前已找到的最佳选择更好，那么就没有必要再继续探索这个分支了。\r\n两个关键变量：\r\n\r\nα\r\n(Alpha)：在从根节点到当前节点的路径上，MAX玩家目前能确保获得的最低分数。\r\nβ\r\n(Beta)：在从根节点到当前节点的路径上，MIN玩家目前能确保获得的最高分数（即MAX玩家能获得分数的上限）。\r\n\r\n剪枝规则 ：\r\n\r\nAlpha 剪枝 (在MIN节点)：如果一个MIN节点的某个子节点的值 v\r\n小于或等于当前路径上的 α 值，那么这个MIN节点就可以被剪枝了。\r\n\r\n因为我们知道MAX玩家在MIN的同一层其他兄弟上已经有了一个至少能得到 α\r\n的选择。而当前这个MIN节点保证了MAX玩家最多只能得到\r\nv（因为MIN会选择最小的）。既然 v ≤ α，MAX玩家就绝不会选择走向这个MIN节点的路径。因此，该MIN节点的其他子节点无需再探索。\r\n\r\n\r\n\r\n如图, 当探索完左侧节点3之后, MAX根节点已经至少得到了3,\r\n而中间的MIN节点此时最好情况也是2,\r\n因此MAX根本不需要考虑这个节点的其余子节点\r\n\r\nBeta 剪枝 (在MAX节点)：如果一个MAX节点的某个子节点的值 v\r\n大于或等于当前路径上的 β 值，那么这个MAX节点就可以被剪枝了。\r\n\r\n因为我们知道MIN玩家在更高层已经有了一个能把MAX玩家的得分限制在 β\r\n以下的选择。而当前这个MAX节点至少能得到 v。既然 v ≥ β，MIN玩家就绝不会让游戏走到这个MAX节点的路径上来。因此，该MAX节点的其他子节点无需再探索。\r\n\r\n\r\n需要注意的是,\r\n剪枝的效率高度依赖于行动的顺序。如果总是先探索最好的行动，Alpha-Beta剪枝可以将需要探索的节点数从\r\nO(bm)\r\n减少到大约 O(bm/2)，这相当于将可搜索的深度加倍，是一个巨大的提升。\r\n评估函数 (Evaluation\r\nFunctions)\r\n为什么需要评估函数？——\r\n现实的妥协\r\nMinimax 和 Alpha-Beta\r\n剪枝算法在理论上是完美的，它们能为任何有限的、确定性的博弈找到最优解。但这里有一个巨大的现实障碍：计算资源的限制。\r\n对于像国际象棋（分支因子约35，深度可达80层）或围棋这样的复杂博弈，其完整的博弈树比宇宙中的原子还要多。即使是最高效的\r\nAlpha-Beta\r\n剪枝算法，也无法在有限的时间内（比如比赛规定的几分钟内）搜索到游戏的终局。\r\n既然我们无法“看到”游戏的结局，我们就必须在某个点停止搜索，并对当前的局面进行“估算”。这个“估算”就是通过评估函数来完成的。\r\n简单来说，评估函数是我们在无法进行完美、完整的逻辑推演时，所采用的一种基于经验和特征的、不完美的“直觉”判断。\r\n定义\r\n评估函数是一个启发式函数，它接收一个非终端的游戏状态（例如，一个中盘的棋局）作为输入，并输出一个数值，这个数值估计了该状态对\r\nMAX 玩家的最终效用值。\r\n它将一个非终端节点“伪装”成一个终端节点。当 Alpha-Beta\r\n搜索达到预设的深度限制 (depth limit)\r\n时，它就不再继续向下扩展，而是调用评估函数来为这个“叶”节点打分。这个分数随后会被用于\r\nMinimax 的回溯计算中。\r\n与启发式 h(n) 的区别：\r\n\r\n在A*搜索中，启发式 h(n)\r\n估计的是从当前状态到目标的剩余成本。\r\n在博弈中，评估函数估计的是从当前状态开始，如果双方都下得很好，最终整个游戏的结局对MAX玩家的效用。\r\n\r\n\r\n如何设计评估函数？\r\n一个好的评估函数需要能够快速而准确地判断局势的优劣。这通常通过以下步骤实现：\r\n\r\n提取特征 (Features)：\r\n\r\n\r\n首先，我们需要从游戏状态中提取出一系列能够反映局势优劣的关键特征。\r\n国际象棋示例：\r\n\r\n棋子自身优势 (Material\r\nAdvantage)：这是最基础的特征。通常会给每个棋子赋一个分值（例如，兵=1，马=3，象=3，车=5，后=9），然后计算双方棋子分值的差。\r\n棋子位置和机动性 (Piece Position &amp;\r\nMobility)：一个位于中心位置的马比在角落里的马更有价值。一个能够移动到很多位置的棋子比被困住的棋子更有价值。\r\n兵形结构 (Pawn Structure)：是否存在孤兵、叠兵等弱点。\r\n\r\n\r\n\r\n加权线性函数 (Weighted Linear Function)：\r\n\r\n\r\n常见的做法是将这些特征组合成一个加权线性函数，来计算总的评估值。\r\nEVAL(s) = w₁f₁(s) + w₂f₂(s) + ... + wₙfₙ(s)\r\n\r\ns：当前的游戏状态。\r\nfᵢ(s)：第 i\r\n个特征在状态 s 下的数值（例如，f₁\r\n可能是白方棋子总分减去黑方棋子总分）。\r\nwᵢ：第 i\r\n个特征的权重。这个权重反映了该特征在决定胜负中的重要性。例如，王的安全性的权重可能比兵形结构的权重要高。\r\n\r\n\r\n这些特征和权重的选择，是深层领域知识的体现。在国际象棋中，它们来自于数百年人类大师对弈经验的总结。在现代AI中，这些权重也可以通过机器学习的方法，让程序通过分析大量的棋局数据（甚至是自我对弈）来自动学习和优化。\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Games -- Expectimax, Monte Carlo Tree Search","url":"/2025/08/12/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/6/","content":"这一讲涉及到的是一个更复杂、也更贴近现实的博弈世界。\r\n核心的转变是：从处理确定性的、纯粹策略对抗的博弈，转向包含随机性或机会元素\r\n(chance) 的博弈。\r\n在之前的Minimax博弈中，只有两个玩家：MAX和MIN。MAX的每一个行动，MIN都会用最优的策略来回应。然而，在许多现实世界的博弈中，例如扑克或双陆棋，结果不仅仅取决于你和对手的选择，还取决于机会——比如你摸到什么牌，或者掷出什么样的骰子。\r\n为了在这种不确定的环境中做出理性决策，我们不能再简单地假设最坏情况的发生，而是需要计算期望的结果。\r\nExpectimax\r\nExpectimax 是 Minimax\r\n算法的一个直接扩展，专门用于处理包含机会节点的博弈。\r\n在博弈树中，除了原有的MAX节点（我方决策）和MIN节点（对手决策），我们引入了机会节点。\r\n机会节点代表了环境中的随机事件（如掷骰子）。从机会节点出发的每条边代表一个可能发生的随机结果，并且每条边都关联一个概率。\r\n例如,\r\n在一个掷骰子的游戏中，机会节点会有6个子节点，分别对应掷出1到6点，每个子节点的概率都是1/6。\r\n在Expectimax 的计算规则中, MAX 节和MIN 节点都与 MINIMAX一致,\r\n选择效用最大/最小的节点,\r\n核心区别在于机会节点：机会节点的值不是取最大或最小值，而是计算其所有子节点效用的期望值\r\n(Expected Value)，即加权平均值。\r\n\r\n公式：Value(ChanceNode) = Σ(P(outcomeᵢ) * Value(childᵢ))\r\n\r\n另外值得注意的是,\r\n在Expectimax中，评估函数的绝对数值变得至关重要.\r\n以往在Minimax中，评估函数的相对顺序占据主导。只要 EVAL(A) &gt;\r\nEVAL(B)，我们就会选择A。\r\n但在Expectimax中，因为我们要计算加权平均值，所以一个评估值为100和一个评估值为10，在计算期望时会产生截然不同的结果。一个微小的可能性乘以一个巨大的回报（或损失），可能会完全改变最终的期望效用。\r\nExpectimax 同样需要遍历博弈树，其时间复杂度与Minimax类似，为 O(bm)（其中\r\nb\r\n现在也包括了机会节点的分支）。对于分支因子巨大（如围棋）或深度很深的博弈，它仍然是不可行的\r\n蒙特卡洛树搜索\r\n(Monte Carlo Tree Search - MCTS)\r\n传统的博弈算法，如 Minimax 和 Alpha-Beta\r\n剪枝，试图通过深度搜索和逻辑推理来找到最佳行动。它们就像一个深思熟虑的棋手，试图穷尽所有可能性来评估一个局面的好坏。然而，当博弈变得极其复杂时（例如，围棋的分支因子高达361），这种“深度思考”在计算上是不可行的。\r\n蒙特卡洛树搜索 (MCTS)\r\n采用了一种截然不同的、更接近人类直觉的策略。它放弃了对博弈树的完整遍历，转而通过进行大量、快速、随机的模拟对局\r\n(playouts) 来评估一个局面的潜力。\r\n\r\n想象一下，你正在下一个你不太懂的棋。为了决定下一步怎么走，你不在脑海里进行复杂的逻辑推演，而是采用一种更简单的方法：对于每个可能的下一步，你都和朋友快速地、随机地把这盘棋下完，下个几百盘。最后，你发现从某个特定的第一步出发，你赢的次数最多。于是，你就决定走这一步。\r\n\r\n这就是 MCTS\r\n的精髓：用统计上的成功概率来代替静态的、手工设计的评估函数。\r\nMCTS 的四个核心步骤\r\nMCTS\r\n算法通过一个不断重复的循环来逐步构建一棵不对称的、聚焦于有希望区域的搜索树。每一次循环都包含以下四个步骤：\r\n\r\n选择 (Selection):\r\n在已经构建的搜索树中，找到一个最有潜力的、值得进一步探索的“叶”节点。\r\n\r\n\r\n从根节点（当前真实的游戏局面）开始，算法会根据一个选择策略，一层一层地向下走。这个策略必须巧妙地平衡两个目标：\r\n\r\n利用\r\n(Exploitation)：倾向于选择那些过去表现很好（胜率高）的节点。\r\n探索\r\n(Exploration)：也要给那些探索次数较少的节点一些机会，因为它们可能潜力巨大，只是我们还没发现。\r\n\r\n常用策略：UCT (Upper Confidence bounds applied to Trees)\r\n是一种非常流行的选择策略，它通过一个公式来计算每个节点的“紧迫性”，完美地平衡了利用和探索。\r\n\r\n\r\n扩展 (Expansion):\r\n当“选择”步骤到达一个叶节点时，我们需要扩展这棵树的边界。\r\n\r\n\r\n算法会为这个叶节点创建一个或多个新的子节点，代表从该局面出发可以采取的、之前从未探索过的行动。\r\n\r\n\r\n模拟 (Simulation / Playout):\r\n快速地对新扩展的节点进行一次“价值评估”。\r\n\r\n\r\n从新扩展的某个子节点开始，算法会进行一次完全随机（或者基于一个非常简单的策略）的快速对局，直到游戏分出胜负。这个过程不需要动脑筋，只需要速度快。\r\n模拟（Simulation）\r\n阶段完全脱离了已有的博弈树。它从一个新节点（树的叶子）出发，进入一个“想象中的”对局。它不需要再访问树中的任何其他节点，也不需要构建新的树节点。它只是在一个临时的游戏状态副本上，一路“走到底”。\r\n\r\n\r\n反向传播 (Backpropagation):\r\n将模拟的结果反馈给搜索树，更新我们的“知识库”。\r\n\r\n\r\n模拟的结果（赢或输）会沿着“选择”阶段的路径，从下至上地传回根节点。路径上的每一个节点都会更新它们的统计数据，例如赢的次数\r\n(wins)和总模拟次数 (visits)\r\n\r\n这个“选择 -&gt; 扩展 -&gt; 模拟 -&gt;\r\n反向传播”的循环会进行成千上万次。当分配的时间用尽时,\r\n此时经过大量的迭代后，根节点的每个子节点都积累了大量的统计数据。最终，算法会选择那个被访问次数最多且胜率也较高的子节点所对应的行动。\r\nUCT\r\n(Upper Confidence bounds applied to Trees) - 应用于树的上置信界\r\nUCT 并不是一个全新的算法，而是将 UCB (Upper Confidence\r\nBound) 公式具体应用到蒙特卡洛树搜索 (MCTS) 的”选择\r\n(Selection)“阶段的策略。为了更好地理解UCT，我们先介绍其理论基础——UCB算法。\r\nUCB 算法基础\r\nUCB (Upper Confidence Bound)\r\n是一种通用的决策算法，专门用于解决多臂老虎机问题 (Multi-Armed\r\nBandit Problem)。这个问题正是”探索与利用”困境的经典模型。\r\n\r\n想象一下，你走进一家赌场，面前有多台老虎机（Slot Machine）,\r\n这些老虎机看起来一模一样，但每台老虎机吐出奖励的概率（或者说奖励的期望值）是不同的，而且这个概率对你来说是未知的。\r\n你的目标是在有限的尝试次数内，最大化你获得的总奖励。\r\n\r\n而UCB 为每一个可选项（比如，每一台老虎机，或者 MCTS\r\n中的每一步棋）计算一个综合分数：\r\nUCB 分数 = 当前平均回报 + 探索奖励\r\n1. 当前平均回报 (Exploitation\r\nTerm)\r\n\r\n含义：该选项到目前为止的平均表现\r\n在MCTS中：节点的当前胜率 (赢的次数 /\r\n总访问次数)\r\n作用：值越高，说明该选项在过去的试验中表现越好，越有理由”利用”它\r\n\r\n2. 探索奖励 (Exploration Term)\r\n\r\n含义：鼓励尝试那些被选择次数较少的选项的奖励项\r\n特点：奖励大小与该选项被访问的次数成反比\r\n作用：访问次数越少，不确定性越大，探索其潜在价值的收益越高\r\n\r\n3. 决策机制\r\n算法选择UCB分数最高的选项，自动在”已被证明是好的”和”可能是更好的未知选项”之间做出权衡。\r\nUCT 在 MCTS 中的应用\r\n在 MCTS\r\n的选择步骤中，当算法从一个非叶节点（父节点P）向下选择子节点时，它将P的所有子节点视为一个”多臂老虎机问题”。算法为每个子节点C计算UCT值，并选择值最高的子节点继续探索。\r\nUCT 公式详解\r\n\r\n公式组成部分：\r\n利用项： - W：子节点C赢得的模拟次数 - N：子节点C被访问的总次数 -\r\n这个比值就是子节点C的当前胜率\r\n探索项： - Np：父节点P被访问的总次数 - N：子节点C被访问的总次数 - c：探索常数，可调的超参数，用于平衡探索和利用的权重\r\n公式工作原理：\r\n\r\n探索阶段：当子节点C的访问次数N很小时，分母N很小，导致探索项的值很大，该节点更有可能被选中（鼓励探索）\r\n利用阶段：随着子节点被访问次数N的增加，探索项逐渐减小，节点选择更多地取决于其胜率（鼓励利用）\r\n平衡机制：探索常数c控制探索与利用的平衡程度，较大的c值倾向于更多探索，较小的c值倾向于更多利用\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Logic -- Propositional Logic and Planning","url":"/2025/08/12/ai/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI/CS188/7/","content":"之前的智能体（如搜索智能体）虽然能解决问题，但它们的“知识”是隐式的,\r\n内嵌在状态表示、行动函数和启发式函数中。而从这一讲开始，我们将探索如何让智能体拥有显式的、声明式的知识，并利用这些知识进行推理\r\n## 基于知识的智能体 (Knowledge-Based Agent)\r\n它的核心组件是一个知识库 (Knowledge Base -\r\nKB)，这是一个由形式化语言写成的语句 (sentences) 的集合。\r\n整个智能体的工作模式为:\r\n\r\n告知\r\n(TELL)：将新的知识（来自感知、学习或直接告知）以语句的形式添加到知识库中。\r\n询问 (ASK)：通过一个通用的推理引擎 (Inference Engine)\r\n向知识库提问，推导出新的结论来指导行动。\r\n\r\n这是一种声明式 (Declarative)\r\n的方法。我们只需要描述“世界是怎样的”，而不需要编写具体的“如何做”的代码。一个通用的推理算法可以解决所有可回答的问题，这极大地提高了智能体的灵活性和可扩展性。\r\n逻辑的基本概念\r\n为了让智能体能够“知道”事情，我们需要一种精确的语言。逻辑就是这样一种语言，它由两个基本部分组成：\r\n\r\n语法 (Syntax):\r\n语法是一套规则，它规定了什么样的符号组合是合法的语句。\r\n\r\n就像英语语法规定了 “x &gt; y” 是合法的，而 “x &gt; y =”\r\n不是。语法只关心句子的形式，不关心其含义。\r\n\r\n语义 (Semantics):\r\n语义定义了语句的含义。它通过将语句与“可能的世界” (Possible\r\nWorlds) 或“模型” (Models)\r\n联系起来，来确定一个语句的真假。\r\n\r\n可能的世界/模型：一个模型代表了世界的一种具体状态。在命题逻辑中，一个模型就是对所有命题符号的一个真值指派（例如，{P=真,\r\nQ=假}）。\r\n真值\r\n(Truth)：语义的核心是定义一个语句在哪个模型中为真，在哪个模型中为假。\r\n\r\n\r\n命题逻辑 (Propositional\r\nLogic)\r\n这是我们学习的第一个形式化逻辑语言。\r\n语法：由命题符号 (X₁, X₂…) 和五个逻辑连接词 (¬, ∧, ∨, =&gt;, ⇔)\r\n构成。\r\n\r\n需要额外注意的是 =&gt;(蕴含,\r\nimplication)：“如果A，那么B”。这是最容易混淆的一个。它只有在一种情况下为假：当\r\nA 为真而 B 为假时。\r\n\r\n语义：通过真值表来定义。一个模型就是对所有命题符号的一个真/假赋值。\r\n推理 (Inference)\r\n推理是一个计算过程，它通过应用推理规则从已有的语句中推导出新的语句。其有两种主要方法：\r\n\r\n模型检验 (Model\r\nChecking)：通过枚举所有可能的模型来检查蕴含关系是否成立。对于命题逻辑是可行的，因为模型数量有限。\r\n定理证明 (Theorem\r\nProving)：应用推理规则（如三段论）来构建一个从前提到结论的证明 (proof)\r\n链条。\r\n\r\n而蕴含 (Entailment)是逻辑推理的核心目标。它的意思是：在所有使得 α\r\n为真的模型中，β 也必然为真。\r\n\r\n定义：α |= β (读作 “alpha entails beta”)\r\n与蕴含 (=&gt;) 的区别 ：\r\n\r\nα =&gt; β\r\n是一个逻辑语句，它本身可以在某个模型中为真或为假。\r\nα |= β\r\n是一个关于两个语句之间关系的断言，它要么成立，要么不成立。\r\n\r\n\r\n","categories":["AI"],"tags":["AI","CS188"]},{"title":"Ctypes","url":"/2025/10/14/lang/python/%E6%89%A9%E5%B1%95%E5%86%85%E5%AE%B9/ctypes/","content":"ctypes 的全称是 C types foreign function library for\r\nPython。它的主要作用是在 Python 中加载并调用 C\r\n语言动态链接库（Shared\r\nLibrary），并在两种语言之间传递数据, 实现 Python\r\n与底层高性能代码的无缝结合。\r\n基本用法结构\r\nimport ctypes# 1️⃣ 加载动态库lib = ctypes.CDLL(\"./mylib.so\")  # Linux# 或：ctypes.WinDLL(\"mylib.dll\")  # Windows# 或：ctypes.CDLL(\"./mylib.dylib\")  # macOS# 2️⃣ 声明函数参数类型和返回值类型lib.add.argtypes = [ctypes.c_double, ctypes.c_double]  # 声明add函数的参数类型lib.add.restype = ctypes.c_double                 # 声明add函数的返回值类型# 3️⃣ 调用函数result = lib.add(1.5, 2.3)print(result)  # 输出 3.8\r\n主要功能分类\r\n加载动态库 ctypes\r\n提供了多种函数来加载不同类型的动态库，常用的有:\r\n函数 说明 ctypes.CDLL(path) 加载普通 C 动态库（标准调用约定）\r\nctypes.WinDLL(path) Windows 专用，适用于 stdcall 调用约定\r\nctypes.PyDLL(path) Python 扩展库加载（保留 GIL）\r\n常见的 C 类型映射 C 类型 Python 映射 int\r\nctypes.c_int float ctypes.c_float double ctypes.c_double char\r\nctypes.c_char char* ctypes.c_char_p void* ctypes.c_void_p bool\r\nctypes.c_bool struct 自定义 ctypes.Structure 子类\r\n传递数组 C 语言中常常需要传递数组指针, 可以用 ctypes\r\n的 POINTER 或 Array 来完成。\r\nPOINTER的作用是创建一个指向某种类型的指针类型。\r\nimport ctypes# 创建一个 double 数组DoubleArray = ctypes.c_double * 5arr = DoubleArray(1.0, 2.0, 3.0, 4.0, 5.0)# 假设 C 函数定义：double mean(double* arr, int n)lib.mean.argtypes = [ctypes.POINTER(ctypes.c_double), ctypes.c_int]lib.mean.restype = ctypes.c_doubleprint(lib.mean(arr, 5))\r\n除此之外, 还可以直接用 NumPy 数组的 .ctypes 接口拿到指针：\r\nimport numpy as nparr = np.arange(10, dtype=np.double)ptr = arr.ctypes.data_as(ctypes.POINTER(ctypes.c_double))lib.mean(ptr, len(arr))\r\n示例\r\n下面是一个完整的示例，展示了如何用 ctypes 调用一个简单的 C\r\n动态库函数。 # Python 端代码import ctypesimport numpy as np# 加载C++编译的动态库# 假设 'fast_indicators.so' 是由 C++ 源码编译而来的lib = ctypes.CDLL('./fast_indicators.so')# 声明C++函数接口# 告诉 Python，C++ 中的 calculate_sma 函数的参数类型lib.calculate_sma.argtypes = [    ctypes.POINTER(ctypes.c_double), # prices (价格数组指针)    ctypes.c_int,                    # length (数组长度)    ctypes.c_int,                    # period (移动平均周期)    ctypes.POINTER(ctypes.c_double)  # result (结果数组指针)]def fast_sma(prices, period):    \"\"\"使用C++实现的快速移动平均\"\"\"        # 1. 将 Python 数据转换为 C++ 兼容的类型    prices_arr = (ctypes.c_double * len(prices))(*prices)    result_arr = (ctypes.c_double * len(prices))() # 创建一个空的 C 类型数组来接收结果    # 2. 调用 C++ 函数    lib.calculate_sma(prices_arr, len(prices), period, result_arr)    # 3. 将 C++ 返回的结果转换回 Python 的 numpy 数组    return np.array(result_arr)# 在Python策略中调用class HybridStrategy:    def __init__(self):        self.prices = []    def on_tick(self, price):  # 模拟接收行情数据        self.prices.append(price) # 收集价格数据        if len(self.prices) &gt; 100:            # 用 C++ 计算移动平均，速度快很多            # 只取最后100个价格计算周期为20的SMA            sma_values = fast_sma(self.prices[-100:], 20)                        # 获取计算出的最新的SMA值            sma = sma_values[-1]            # 用Python写交易逻辑，清晰易懂            if price &gt; sma:                return \"BUY\"            elif price &lt; sma:                return \"SELL\"                return \"HOLD\"if __name__ == \"__main__\":    strategy = HybridStrategy()    # 模拟接收行情数据    for price in np.random.rand(200) * 100:        action = strategy.on_tick(price)        if action != \"HOLD\":            print(f\"Price: {price:.2f}, Action: {action}\")\r\n","categories":["language"],"tags":["language","python"]},{"title":"动态规划(Dynamic Programming)","url":"/2025/09/02/algorithms/Coding%E6%8A%80%E5%B7%A7/DynamicProgramming/DynamicProgramming/","content":"动态规划（Dynamic Programming, DP）\r\n是一种通过将复杂问题分解为更小的、重叠的子问题来求解的算法思想。它与分治法（Divide\r\nand\r\nConquer）有些相似，但不同之处在于，动态规划适用于子问题重叠的场景，即不同的子问题会共享更小的子子问题。\r\nDP的核心思想是 “记忆化” 或\r\n“表格法”，即计算过一次的子问题的解，就将其存储起来，避免重复计算。这是一种典型的\r\n“空间换时间”\r\n的策略，通过使用额外的内存来存储中间结果，从而显著降低计算的时间复杂度。\r\n适用条件\r\n一个问题能否使用动态规划来解决，通常取决于它是否满足以下三个核心特征：\r\n最优子结构 (Optimal Substructure)\r\n\r\n问题的最优解包含其子问题的最优解。换句话说，我们可以通过组合子问题的最优解来构造出原问题的最优解。\r\n例如：在最短路径问题中，从A到C的最短路径，如果经过B点，那么这条路径中从A到B的部分也必然是A到B的最短路径。\r\n\r\n重叠子问题 (Overlapping Subproblems)\r\n\r\n在问题的求解过程中，许多子问题会被反复计算。DP的威力正体现在此，它通过存储已解决的子问题的答案来避免这种不必要的重复计算。\r\n例如：在计算斐波那契数列时，F(5) 依赖 F(4) 和 F(3)，而 F(4) 依赖\r\nF(3) 和 F(2)。F(3) 就是一个被重复计算的重叠子问题。\r\n\r\n无后效性 (No Aftereffect)\r\n\r\n一旦某个阶段的状态确定，它就不会再被后续的决策所改变。当前状态只与之前的状态有关，而与之后的状态无关。我们做的每一个决策都是基于当前已有的信息，而不用担心未来的决策会反过来影响当前决策的正确性。\r\n\r\n解题步骤\r\n解决一个动态规划问题，通常可以遵循以下四个步骤，这是一个系统性的思考框架。\r\n第一步：定义状态\r\n这是动态规划中最关键，也往往是最困难的一步。状态定义需要清晰、无歧义，并且能够涵盖解决问题所需的所有信息。\r\n一个常见且可行的操作是创建一个数组（通常称为 dp\r\n数组），并明确 dp[i] 或 dp[i][j] 代表什么。\r\n\r\n例如：在计算斐波那契数列时，dp[i] 可能代表“第i个斐波那契数”。\r\n例如：在爬楼梯问题中，dp[i] 可能代表“爬到第i级台阶的方法数”。\r\n例如：在背包问题中，dp[i][j]\r\n可能代表“前i个物品在容量为j的背包中的最大价值”。\r\n\r\n状态的定义必须能够帮助我们推导出最终的答案。一个好的状态定义是成功的一半。\r\n第二步：确定状态转移方程\r\n状态转移方程是动态规划的核心，它描述了不同状态之间是如何关联和演进的。\r\n具体而言, 我们需要找出 dp[i] 与 dp[i-1], dp[i-2], …\r\n等之前状态的关系。\r\n这个方程是问题的数学模型。它告诉我们如何利用已知的子问题的解来计算出当前问题的解。例如，爬楼梯问题中，爬到第\r\ni 级台阶的方法数等于爬到第 i-1 级和第 i-2\r\n级的方法数之和，其状态转移方程就是 dp[i] = dp[i − 1] + dp[i − 2]。\r\n第三步：初始化\r\n任何递推关系都需要一个或多个起点，这就是初始状态。\r\n我们需要根据状态定义，为 dp 数组中的基础情况（base case）赋初值。\r\n例如，在斐波那契数列中，dp[0] = 0, dp[1] = 1\r\n就是初始状态。如果初始化错误，后续的所有计算都会是错误的。\r\n第四步：确定遍历顺序\r\n根据状态转移方程，我们需要确定计算 dp 数组的顺序,\r\n也就是决定循环是从前向后还是从后向前，或者对于二维数组是逐行还是逐列。\r\n遍历顺序必须保证，在计算 dp[i] 时，所有它所依赖的状态（如\r\ndp[i-1]）都已经计算出来了。这通常意味着从小规模的问题向大规模问题进行迭代。\r\n两种模式\r\n动态规划 (Dynamic Programming, DP)\r\n的核心是将一个大问题分解成若干个子问题，并存储子问题的解以避免重复计算。它主要有两种实现方式：\r\n\r\n自顶向下 (Top-Down) DP：通常通过 递归 + 记忆化 来实现。\r\n自底向上 (Bottom-Up) DP：通常通过 迭代 + 表格 来实现。\r\n\r\n\r\n自顶向下 (Top-Down) 动态规划 — 记忆化搜索\r\n\r\n这种方法也称为 记忆化搜索\r\n(Memoization)。核心思想是从我们最终要求解的大问题出发，通过递归函数去解决它。如果在这个过程中遇到了一个子问题，我们先检查是否已经计算过这个子问题（即“记忆”里有没有）。\r\n如果计算过，直接从“记忆”中取出答案;\r\n如果没有计算过，就递归地去解决这个子问题，并将计算出的结果存入“记忆”中，以备后用。\r\n这个过程就像是从树的顶部（根节点，即原始问题）开始，向下探索到树的底部（叶子节点，即最小的子问题）。\r\n\r\n自底向上 (Bottom-Up) 动态规划 — 表格法\r\n\r\n这种方法也称为 表格法\r\n(Tabulation)。核心思想完全反过来，我们不从大问题开始，而是从能够直接求解的、最小的子问题开始。然后利用这些小问题的解，像搭积木一样，一步步地构建出更大问题的解，直到最终解决了我们想要的那个大问题。\r\n这个过程通常用一个数组或矩阵（我们称之为 dp\r\n表）来完成，通过迭代（for循环）的方式，按照从小到大的顺序填充表格。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特征 (Feature)\r\n自顶向下 (Top-Down)\r\n自底向上 (Bottom-Up)\r\n\r\n\r\n\r\n\r\n实现方式\r\n递归 + 记忆化 (Memoization)\r\n迭代 + 表格法 (Tabulation)\r\n\r\n\r\n思路方向\r\n从 大问题 分解到 小问题\r\n从 小问题 构建到 大问题\r\n\r\n\r\n子问题计算\r\n按需计算：只计算解决最终问题所必需的子问题。\r\n计算所有：通常会计算出所有可能的子问题的解。\r\n\r\n\r\n代码直观性\r\n通常更符合人类的直觉，因为其逻辑直接遵循问题的递归定义。\r\n可能需要更仔细地设计循环和状态转移的顺序。\r\n\r\n\r\n性能\r\n可能会因递归深度过大导致栈溢出。函数调用有一定开销。\r\n没有递归开销，通常性能略好一些。\r\n\r\n\r\n\r\n二维降一维\r\n在动态规划中，很多问题的状态可以用二维数组来表示，例如 dp[i][j]\r\n代表某个子问题的解。然而，二维数组往往会占用较多的空间，有时我们可以通过观察状态转移方程，发现某些情况下，当前状态只依赖于前一行或前一列的状态，从而将二维数组优化为一维数组(节省了空间,\r\n但是循环仍旧是二维的)。\r\n例如, 在某道题的二维 DP 中，状态转移方程是：\r\ndp[i][j] = dp[i − 1][j] + dp[i][j − 1]\r\n这个公式告诉我们，要计算当前单元格 (i, j)\r\n的路径数，我们只需要它正上方的单元格 (i-1, j) 和它正左方的单元格 (i,\r\nj-1) 的路径数。\r\n这意味着，当我们在计算第 i\r\n行的数据时，我们实际上只用到了第 i-1\r\n行（上一行）和当前行但是前一个的数据。更早的行（如第\r\ni-2 行、第 i-3 行）的数据已经不再需要了。\r\n因此，我们没有必要存储整个 m×n\r\n的二维表格，这造成了空间浪费。我们可以用一个一维数组来“滚动”计算，从而将空间复杂度从\r\nO(m×n) 优化到\r\nO(n)。这个一维数组在每次迭代中，都保存着“上一行”的计算结果。\r\n原代码：\r\nclass Solution {public:    int uniquePaths(int m, int n) {        vector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n));        dp[0][0] = 1;        int i,j;        for(i=1;i&lt;n;i++){            dp[0][i] = 1;        }        for(i=1;i&lt;m;i++){            dp[i][0] = 1;        }        for(i=1;i&lt;m;i++){            for(j=1;j&lt;n;j++){                dp[i][j] = dp[i-1][j] + dp[i][j-1];            }        }        return dp[m-1][n-1];    }};\r\n优化后：\r\nclass Solution {public:    int uniquePaths(int m, int n) {        // 1. 初始化        vector&lt;int&gt; dp(n, 1);        // 2. 遍历行        for (int j = 1; j &lt; m; j++) {            // 3. 遍历列            for (int i = 1; i &lt; n; i++) {                // 4. 状态转移                dp[i] += dp[i - 1];            }        }                // 5. 返回结果        return dp[n - 1];    }};\r\n第一步是创建一个大小为 n (网格的列数) 的一维数组\r\ndp，并将其所有元素初始化为 1。\r\n这步操作相当于计算了二维网格中第一行\r\n的所有路径数。对于第一行的任何一个单元格 (0,\r\nj)，都只有一条路径可以到达，那就是从起点 (0, 0) 一直向右走。所以\r\ndp[0][j] 恒为 1。\r\ndp 数组此时的状态是 {1, 1, 1, …, 1}，代表了第一行 m=0\r\n时每个位置的路径数。\r\n接着每一次外层循环的开始，dp 数组里存储的都是 上一行\r\n(j-1) 的计算结果。我们的目标是在这次循环中，利用这些结果计算出\r\n当前行 (j) 的结果，并更新 dp 数组。\r\n这一步是核心: dp[i] += dp[i - 1];\r\n在执行 dp[i] += dp[i-1] 这行代码时：\r\n\r\n= 左边的 dp[i]：它里面存储的还是\r\n上一行\r\n的值，因为它在本次内层循环中还没有被更新。这正好对应二维公式中的\r\ndp [j−1][i] (来自上方的路径)。\r\n= 右边的\r\ndp[i-1]：它在本次内层循环的上一步 (i 的值还是\r\ni-1 时) 已经被更新了。所以它存储的是\r\n当前行左边单元格的值。这正好对应二维公式中的 dp\r\n[j][i−1] (来自左方的路径)。\r\n\r\n因此，dp[i] += dp[i-1] 就等价于： dp[i]新 = dp[i]旧 + dp[i − 1]新\r\n这完美地实现了二维状态转移方程的功能，但只用了一个一维数组。\r\n例题\r\n例题2: 单词拆分\r\n给你一个字符串 s 和一个字符串列表 wordDict\r\n作为字典。如果可以利用字典中出现的一个或多个单词拼接出 s 则返回\r\ntrue。注意：不要求字典中出现的单词全部都使用，并且字典中的单词可以重复使用。\r\n示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”] 输出: true\r\n解释: 返回 true 因为 “leetcode” 可以由 “leet” 和 “code” 拼接成。\r\n示例 2： 输入: s = “applepenapple”, wordDict = [“apple”, “pen”] 输出:\r\ntrue 解释: 返回 true 因为 “applepenapple” 可以由 “apple” “pen” “apple”\r\n拼接成。\r\n示例 3： 输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”,\r\n“and”, “cat”] 输出: false\r\n\n    思路 1 \n    \n      采取动态规划的思路, 要解决s能否被组合, 我们得考虑比s更小的子问题,\r\n即s的子串是否能被组合. 基于此, 一个思路便产生了: dp[i]\r\n代表s[0:i]是否能被wordDict中的单词组合而成. 那么为了推导dp[i],\r\n我们需要考虑所有可能的分段方式, 即s[0:j]和s[j+1:i]两部分的组合情况,\r\n只要存在某个j使得dp[j]为true且s[j+1:i]在wordDict中, 那么dp[i]就为true.\r\n当然, 还要考虑s[0:i]本身在wordDict中的情况. 基本代码如下:\r\nbool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) {       size_t n = s.length();       vector&lt;bool&gt; dp(n,false);       unordered_set&lt;string&gt; set(wordDict.begin(), wordDict.end());       dp[0] = set.contains(string(1, s[0]))? true:false;       for(int i=1;i&lt;n;i++){           for(int j=0;j&lt;i;j++){               if(dp[j]&amp;&amp;set.contains(s.substr(j+1,i-j))){                   dp[i] = true;                   break;               }           }           if(set.contains(s.substr(0,i+1))) dp[i] = true;       }       return dp[n-1];   }\r\n上面的解法将 dp[i] 含义定义为了下标 i 处的字符包含在内的子串 s[0:i]\r\n是否能被 wordDict 中的单词拼接而成。然而，这种定义导致在计算 dp[i]\r\n时，我们遍历后还需要额外检查 s[0:i] 本身是否在 wordDict\r\n中，这增加了不必要的复杂性。\r\n因此, 我们可以定义一个一维的数组dp[i]表示字符串 s 中，长度为\r\ni 的前缀（即子串 s[0…i-1]）是否可以被字典中的单词拼接而成,\r\n而dp[i]拆分为的两部分不必都是dp数组(从而造成冗余),如果满足以下两个条件，那么\r\ndp[i] 就可以是 true：\r\n\r\ndp[j] 是 true：这说明从字符串开头到 j 点的这一段前缀 s[0…j-1]\r\n已经被成功拼接了。\r\n从 j 到 i 的这一段子串 s.substr(j, i-j)\r\n本身就是字典里的一个单词。\r\n\r\nclass Solution {public:    bool wordBreak(string s, vector&lt;string&gt;&amp; wordDict) {        int n = s.length();        // 1. 将字典转为哈希集合，提高查询效率        // std::find 在 vector 上是 O(N)，在 unordered_set 上是 O(1)        unordered_set&lt;string&gt; wordSet(wordDict.begin(), wordDict.end());        // 2. 定义 dp 数组，大小为 n+1        // dp[i] 表示 s 的前 i 个字符能否被拼接        vector&lt;bool&gt; dp(n + 1, false);        // 3. 初始化初值        // dp[0] 表示空字符串，是合法的起点        dp[0] = true;        // 4. 构建递推        // 外层循环遍历所有前缀长度 i，从 1 到 n        for (int i = 1; i &lt;= n; ++i) {            // 内层循环遍历所有可能的分割点 j            for (int j = 0; j &lt; i; ++j) {                // 如果 dp[j] 为 true，并且 s[j...i-1] 是一个字典词                if (dp[j] &amp;&amp; wordSet.count(s.substr(j, i - j))) {                    dp[i] = true;                    break; // 找到了一个可行方案，无需再检查其他分割点 j                }            }        }        return dp[n];    }};\r\n\n    \n  \r\n例题3: 0-1背包问题\r\n\r\n背包问题指的是对于有 n 件物品和一个容量为 V 的背包。每件物品 i\r\n有一个重量 w[i] 和一个价值\r\nv[i]。求解在不超过背包容量的前提下，能够装入背包的物品的最大总价值。\r\n\r\n而根据每件物品的数量和是否可以重复选择，背包问题可以分为以下几种类型：\r\n\r\n现阶段我们主要考虑的是0-1背包和完全背包,\r\n完全背包又是由0-1背包演化而来, 因此0-1背包是重点\r\n\r\n状态定义: 0-1背包问题的状态定义为: dp[i][j] 代表前 i\r\n件物品可选的情况下, 放入容量为 j 的背包可以获得的最大价值\r\n初始化: dp[i][0] = 0, dp[0][j] = j&gt;w[0]?value[0]:0\r\n状态转移方程: dp[i][j] = max(dp[i − 1][j], dp[i − 1][j − weight[i]] + value[i])(j &gt;  = weight[i])\r\n\r\n以上过程，抽象化如下：对于第 i 件物品和容量为 j\r\n的背包，最大价值有两种选择可以到达： -\r\n不放物品i：背包容量为j，里面不放物品i的最大价值是dp[i -\r\n1][j]。 - 放物品i：背包空出物品i的容量后，背包容量为j -\r\nweight[i]，dp[i - 1][j - weight[i]] 为背包容量为j -\r\nweight[i]且不放物品i的最大价值，那么dp[i - 1][j - weight[i]] + value[i]\r\n（物品i的价值），就是背包放物品i得到的最大价值\r\n\r\n遍历顺序: i从1到n-1, j从0到V\r\n\r\nfor (int i = 1; i &lt;= n; ++i) {    for (int j = 0; j &lt;= V; ++j) {        // 状态转移        if (j &gt;= weight[i]) {            dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i]);        } else {            dp[i][j] = dp[i-1][j];        }    }}\r\n举个例子, 假如背包最大重量为4。物品为：        重量\t价值物品0\t1\t 15物品1\t3\t 20物品2\t4\t 30\r\n求背包能背的物品最大价值是多少？\r\n更新完毕后的示意图如下: \r\n二维降一维\r\n在0-1背包问题中，二维数组 dp[i][j] 代表前 i 件物品可选的情况下,\r\n放入容量为 j 的背包可以获得的最大价值。我们注意到，计算 dp[i][j]\r\n时，只依赖于上一行 dp[i-1][…]\r\n的值。因此，我们可以将二维数组降为一维数组。\r\n\r\n需要满足的条件是上一层可以重复利用，直接拷贝到当前层。\r\n\r\nvector&lt;int&gt; dp(V + 1, 0);for (int i = 1; i &lt;= n; ++i) {    for (int j = V; j &gt;= weight[i]; --j) {        dp[j] = max(dp[j], dp[j - weight[i]] + value[i]);    }}\r\n\r\ndp定义:\r\n在一维dp数组中，dp[j]表示：容量为j的背包，所背的物品价值可以最大为dp[j]。\r\n&gt; 其实dp[j]隐含了一个条件：在计算dp[j]时，物品i是可选的,\r\n只不过我们没有显式地表示i. &gt; 在循环的过程中,\r\ndp[j]的值会随着i的变化而变化, 直到最后一个i,\r\n此时的dp[j]才是最终结果\r\n初始化: dp[0] = 0, dp[j] = j &gt;  = weight[0]?value[0] : 0\r\n状态转移方程: dp[j] = max(dp[j], dp[j − weight[i]] + value[i])(j &gt;  = weight[i])\r\n遍历顺序: i从1到n-1, j从V到weight[i]\r\n\r\n这里的关键在于内层循环的遍历顺序。我们必须从后向前遍历\r\nj（从 V 到 weight[i]），以确保在计算 dp[j] 时，dp[j -\r\nweight[i]] 仍然是上一行的值（即不包含当前物品 i 的情况）。\r\n假如还是正序遍历, 此时计算 dp[j], 我们需要用到 dp[j−weight[i]]\r\n的值。而根据正序遍历的规则，当程序执行到 j 时，所有小于 j\r\n的索引（包括 j -\r\nweight[i]）都已经在本轮（即针对物品 i\r\n的循环中）被更新过了。此时我们用到的 dp[j−weight[i]]\r\n已经不是 dp[i−1][j−weight[i]]（上一轮的状态），而是\r\ndp[i][j−weight[i]]（本轮更新后的状态）。\r\n这意味着在计算 dp[i][j] 时，我们参考了已经放入过物品 i 的状态\r\ndp[i][j−weight[i]]。这相当于物品 i\r\n在一轮决策中被重复放入了多次(变成了完全背包), 这就违背了 0-1\r\n背包问题中每件物品只能放入一次的原则。\r\n而在二维动态规划中，我们在计算第 i\r\n行（dp[i]）的任何一个值时，所依赖的 全部是 第 i-1\r\n行（dp[i-1]）的数据。无论内层循环（遍历背包容量\r\nj）是正序还是倒序，dp[i][j] 始终从上一行 dp[i-1]\r\n获取数据。本行的更新（例如先计算了 dp[i][j-1]）不会“污染”到计算 dp[i][j]\r\n时所需要的数据源\r\n上述示例的一维示意图: \r\n二维0-1背包问题\r\n完全背包问题\r\n有N件物品和一个最多能背重量为W的背包。第i件物品的重量是weight[i]，得到的价值是value[i]\r\n。每件物品都有无限个（也就是可以放入背包多次），求解将哪些物品装入背包里物品价值总和最大。\r\n完全背包和01背包问题唯一不同的地方就是，每种物品有无限件。\r\n但做法上和01背包问题非常类似, 只需要在状态转移方程上做出调整即可\r\n\r\n状态定义: dp[i][j] 代表前 i 件物品可选的情况下, 放入容量为 j\r\n的背包可以获得的最大价值\r\n初始化: dp[i][0] = 0, dp[0][j] =\r\nj&gt;=weight[0]?value[0]*(j/weight[0]):0\r\n状态转移方程: dp[i][j] = max(dp[i − 1][j], dp[i][j − weight[i]] + value[i])(j &gt;  = weight[i])\r\n注意到这里的区别, 01背包是dp[i-1][j-weight[i]],\r\n而完全背包是dp[i][j-weight[i]], 也就是说, 在完全背包中,\r\n我们在计算放入物品i时, 允许再次放入物品i\r\n遍历顺序: i从1到n-1, j从0到V for (int i = 1; i &lt;= n; ++i) {    for (int j = 0; j &lt;= V; ++j) {        // 状态转移        if (j &gt;= weight[i]) {            dp[i][j] = max(dp[i-1][j], dp[i][j-weight[i]] + value[i]);        } else {            dp[i][j] = dp[i-1][j];        }    }}\r\n\r\n完全背包中的排列和组合问题\r\n在完全背包问题中, 我们经常会遇到两种不同的计算方式:\r\n计算组合数和计算排列数. 例如:\r\n\r\n零钱兑换 II (LeetCode 518): 给你一个整数数组 coins\r\n表示不同面额的硬币，以及一个整数 amount\r\n表示总金额。计算并返回可以凑成总金额的硬币组合数。\r\n组合总和 IV (LeetCode 377): 给你一个由不同整数组成的数组\r\nnums，和一个目标整数 target。请你从 nums 中找出并返回总和为 target\r\n的元素组合的个数, 不同顺序认为是不同的组合。\r\n\r\n这两道题的唯一区别在于: 前者是组合问题, 后者是排列问题. 也就是说,\r\n在前者中, [1,2] 和 [2,1] 被视为同一种组合; 而在后者中, [1,2] 和 [2,1]\r\n被视为两种不同的组合.\r\n它们的核心在于,\r\n元素的使用顺序是否影响结果。这个看似微小的区别，将直接导致我们动态规划解题策略，特别是遍历顺序上的根本不同。\r\n组合问题 (Combination)\r\n\r\n问题本质：不关心元素加入的顺序，只关心最终由哪些元素构成了目标总和。例如，凑成\r\n4，(1, 3) 和 (3, 1) 被视为同一种组合。\r\nDP 定义: dp[j] 表示凑成总和为 j 的组合总数。\r\n核心策略：固定物品，更新背包。我们依次遍历每一个物品，用这个物品去更新所有它能影响到的背包容量。\r\n\r\n当我们外层循环遍历物品时，我们等于在说：“现在只允许用第一个物品，看看能凑成哪些金额？”、“好了，现在在前者的基础上，再加入第二个物品，看看又能多凑出哪些组合？”。这个过程人为地固定了物品的考虑顺序，从而避免了排列的产生。\r\n\r\n\r\n#include &lt;iostream&gt;#include &lt;vector&gt;int combination_2d(const std::vector&lt;int&gt;&amp; coins, int amount) {    int n = coins.size();    // DP 定义：dp[i][j] 表示使用前 i 种硬币凑成金额 j 的组合数    std::vector&lt;std::vector&lt;long long&gt;&gt; dp(n, std::vector&lt;long long&gt;(amount + 1, 0));    // 步骤说明：初始化基础情况。    // 凑成金额 0 的组合数永远是 1（即什么都不选）。    for (int i = 0; i &lt; n; ++i) {        dp[i][0] = 1;    }    // 步骤说明：外层遍历物品（硬币）。    // 这是组合问题的关键，我们按顺序将物品加入考虑范围。    for (int i = 1; i &lt; n; ++i) {        // 步骤说明：内层遍历背包（金额）。        for (int j = 1; j &lt;= amount; ++j) {            // 不使用第 i 种硬币的方法数            long long count1 = dp[i - 1][j];            // 使用第 i 种硬币的方法数            long long count2 = (j &gt;= coins[i]) ? dp[i][j - coins[i]] : 0;                        dp[i][j] = count1 + count2;        }    }    return dp[n-1][amount];}int combination_1d(const std::vector&lt;int&gt;&amp; coins, int amount) {    // DP 定义：dp[j] 表示凑成金额 j 的组合数    std::vector&lt;unsigned int&gt; dp(amount + 1, 0);    // 步骤说明：初始化基础情况。    dp[0] = 1;    // 步骤说明：外层遍历物品（硬币）。    // 这个顺序保证了我们是按物品的种类来计算组合，避免了排列。    for (int coin : coins) {        // 步骤说明：内层遍历背包（金额）。        // 正序遍历，因为物品可以重复使用（完全背包）。        for (int j = coin; j &lt;= amount; ++j) {            // 递推公式：dp[j] 的值由不包含当前 coin 的旧 dp[j] 和            // 包含了当前 coin 的 dp[j-coin] 累加而来。            dp[j] += dp[j - coin];        }    }    return dp[amount];}\r\n\r\n这个一维 DP\r\n的循环结构，其第一轮迭代本身就完成了对第一个物品的初始化计算。它把二维\r\nDP\r\n中对第一行的特殊处理，自然而然地融合进了通用的循环逻辑里。而在二维\r\nDP 中，我们需要对第一行进行特殊初始化, 这是因为递推公式通常是 dp[i][j] =\r\ndp[i-1][j] + …。这意味着计算第 i 行需要依赖第 i-1 行。当 i=1 时，它需要\r\ni=0（即第一行）的数据。因此，我们必须先有第一行的数据，才能递推出后续所有行。所以二维解法常常会有一个单独的循环来填充第一行。\r\n\r\n排列问题 (Permutation)\r\n\r\n问题本质：元素的加入顺序至关重要，顺序不同即为不同的解。例如，凑成\r\n4，(1, 3) 和 (3, 1) 被视为两种不同的排列。\r\nDP 定义: dp[j] 表示凑成总和为 j 的排列总数。\r\n核心策略：固定背包，尝试物品。我们依次遍历每一个背包容量（目标总和），然后考虑用哪个物品可以作为最后一步来达到这个容量。\r\n\r\n步骤说明：当我们外层循环遍历背包容量 j 时，我们等于在问：“要凑成\r\nj，最后一步可以是哪个数字？” 它可以是在凑成 j-num1 的基础上加上\r\nnum1，也可以是在凑成 j-num2 的基础上加上 num2… 由于我们对每个 j\r\n都尝试了所有 nums\r\n中的数字作为最后一步的可能性，自然就包含了所有的排列情况。\r\n\r\n\r\n#include &lt;iostream&gt;#include &lt;vector&gt;int permutation_1d(const std::vector&lt;int&gt;&amp; nums, int target) {    // DP 定义：dp[j] 表示凑成目标 j 的排列数    std::vector&lt;unsigned long long&gt; dp(target + 1, 0);    // 步骤说明：初始化基础情况。    // 凑成目标 0 只有一种方法（空排列）。    dp[0] = 1;    // 步骤说明：外层遍历背包（目标总和）。    // 这是排列问题的关键，我们对每个目标值 j，都考虑所有可能的最后一步。    for (int j = 1; j &lt;= target; ++j) {        // 步骤说明：内层遍历物品（数字）。        for (int num : nums) {            if (j &gt;= num) {                // 递推公式：凑成 j 的方法数，是所有“凑成 j-num 再加上以 num 结尾”                // 的方法数之和。                dp[j] += dp[j - num];            }        }    }    return dp[target];}\r\n总之:\r\n\r\n解决组合问题，应该外层遍历物品，内层遍历背包。这相当于固定物品，看它能对不同容量的背包做什么贡献。\r\n解决排列问题，应该外层遍历背包，内层遍历物品。这相当于固定目标（背包容量），看它可以由哪些物品作为最后一步凑成。\r\n\r\n二维 DP\r\n经典序列 DP (LCS &amp; LIS)\r\n专门处理两个（或一个）序列/字符串之间的关系。 - 最长公共子序列 (LCS,\r\nLongest Common Subsequence) - 最长递增子序列 (LIS, Longest Increasing\r\nSubsequence) - 编辑距离 (Edit Distance)\r\n这类问题的核心在于，状态定义通常涉及两个维度，分别对应两个序列的索引位置。通过比较这两个位置的元素，我们可以决定如何更新\r\nDP 表格，从而逐步构建出最终的解。\r\n例题: 最长公共子序列 (LCS)\r\n给定两个字符串 text1 和\r\ntext2，返回这两个字符串的最长公共子序列的长度。如果不存在公共子序列，返回\r\n0 。 class Solution {public:    int longestCommonSubsequence(string text1, string text2) {        int m = text1.size();        int n = text2.size();        vector&lt;vector&lt;int&gt;&gt; dp(m+1,vector&lt;int&gt;(n+1,0));        for(int i=1;i&lt;=m;i++){            for(int j=1;j&lt;=n;j++){                if(text1[i-1]==text2[j-1]){                    dp[i][j] = 1+dp[i-1][j-1];                }else{                    dp[i][j] = max(dp[i-1][j],dp[i][j-1]);                }            }        }        return dp[m][n];    }}; 状态定义: dp[i][j]. 我们定义 dp[i][j] 表示 text1\r\n的前 i 个字符（即 text1[0…i-1]）与 text2 的前 j 个字符（即\r\ntext2[0…j-1]）的最长公共子序列的长度。\r\n重点：\r\n\r\ndp 表的大小：如果 text1 长度为 m，text2 长度为\r\nn，我们需要一个大小为 (m+1) x (n+1) 的 dp 表。\r\n+1 的目的：dp[0][j] 和 dp[i][0]\r\n用来表示“空字符串”与另一个字符串的 LCS。\r\n\r\ndp[0][j]：text1 取前 0 个字符（空串）与 text2 前 j 个字符的\r\nLCS，结果显然是 0。\r\ndp[i][0]：text1 取前 i 个字符与 text2 前 0 个字符（空串）的\r\nLCS，结果也显然是 0。\r\n这种定义让我们的base case (基础情况) 变得非常清晰。\r\n\r\n状态转移方程: 要计算 dp[i][j]，我们需要观察 text1 的第 i\r\n个字符（即 text1[i-1]）和 text2 的第 j 个字符（即\r\ntext2[j-1]）。这里只有两种情况：\r\n\r\n情况一：两个字符相等, if (text1[i-1] == text2[j-1]) -\r\n说明：我们找到了一个新的公共字符！例如，比较 “abc” 和 “adc” 时，我们发现\r\nc == c。 - 操作：这个新的公共字符 c 必然可以被包含在 LCS 中。当前的 LCS\r\n长度，等于 “ab” 和 “ad” 的 LCS 长度 再加 1。 - 对应到 dp 表：dp[i][j]\r\n等于 dp[i-1][j-1] (即 “ab” 和 “ad” 的LCS) + 1。 - 转移方程 (1)：dp[i][j]\r\n= 1 + dp[i-1][j-1]\r\n情况二：两个字符不相等, if (text1[i-1] != text2[j-1]) -\r\n说明：这两个字符无法同时作为公共子序列的结尾。例如，比较 “abc” 和 “ade”\r\n时，c != e。 - 操作：我们必须在 “abc” 和 “ade”\r\n中“丢弃”一个字符，然后取两种情况下的最优解（最大值）。\r\n- 丢弃 text1 的 c：我们去比较 “ab” 和 “ade”。对应 dp 表：dp[i-1][j] -\r\n丢弃 text2 的 e：我们去比较 “abc” 和 “ad”。对应 dp 表：dp[i][j-1] -\r\n例如：LCS(“abc”, “ade”) 应该等于 max(LCS(“ab”, “ade”), LCS(“abc”,\r\n“ad”))。 - 转移方程 (2)：dp[i][j] = max(dp[i-1][j], dp[i][j-1])\r\n\r\n\r\n为什么是一道 DP\r\n问题？我们要找“最长”的公共子序列。这暗示着我们要做出最优决策。当我们比较两个字符串\r\ntext1 和 text2 时，例如 text1 = “abcde” 和 text2 =\r\n“ace”，我们从头开始看：\r\n\r\n‘a’ vs ‘a’：它们匹配。很好，LCS 至少为\r\n1。我们接下来该做什么？我们应该去求解 “bcde” 和 “ce” 的 LCS。\r\n‘b’ vs ‘c’：不匹配。我们现在有两个选择：跳过 ‘b’，去比较 “cde” 和\r\n“ce”; 跳过 ‘c’，去比较 “bcde” 和 “e”。\r\n我们发现，原问题 LCS(“abcde”, “ace”) 被分解为了 1 + LCS(“bcde”,\r\n“ce”)，而 LCS(“bcde”, “ce”) 又被分解为求解 LCS(“cde”, “ce”) 和\r\nLCS(“bcde”, “e”) 中的最大值…这就是“最优子结构”和“重叠子问题”，是 DP\r\n的完美应用场景。\r\n\r\n为什么要用二维 DP？与“最长递增子序列”（一维 DP）不同，LCS\r\n问题有两个变量在同时变化：text1 的索引 i 和 text2 的索引 j。\r\n因此，我们的 DP\r\n状态必须由这两个变量共同决定。这自然地导出了一个二维 dp\r\n表。\r\n例题: 最长递增子序列\r\n给你一个整数数组 nums\r\n，找到其中最长严格递增子序列的长度。子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7]\r\n是数组 [0,3,1,6,2,2,7] 的子序列。\r\n要计算 dp[i]（以 nums[i] 结尾的 LIS 长度），我们需要考虑 nums[i]\r\n能“接”在哪个子序列的后面。我们必须遍历 i 之前的所有元素 nums[j]（其中 j\r\n从 0 到 i-1）： - 如果 nums[i] &gt; nums[j]： -\r\n说明：这满足“严格递增”的要求。nums[i] 可以接在以 nums[j]\r\n结尾的那个递增子序列的后面。 - 操作：形成了一个新的、更长的、以 nums[i]\r\n结尾的子序列。它的长度是 dp[j] + 1 (即 …nums[j] 的序列长度 dp[j]，加上\r\nnums[i] 这个元素)。\r\n\r\n如果 nums[i] &lt;= nums[j]：\r\n\r\n说明：nums[i] 不能接在以 nums[j] 结尾的子序列后面。\r\n\r\n\r\ndp[i] 的初始值是什么？ 任何一个元素 nums[i] 自身都可以构成一个长度为\r\n1 的子序列。所以 dp[i] 的保底值（基础情况）是 1。\r\n推导方程： dp[i] 应该是所有可能的 dp[j] + 1 (对于 j &lt; i 且 nums[i]\r\n&gt; nums[j]) 和它的保底值 1 之间，取一个最大值。\r\nint lengthOfLIS(vector&lt;int&gt;&amp; nums) {    int n = nums.size();    if (n == 0) {        return 0;    }    // dp[i] 表示以 nums[i] 结尾的最长递增子序列的长度    vector&lt;int&gt; dp(n);        int global_max_length = 0;    for (int i = 0; i &lt; n; ++i) {        // 1. 初始化：        // 任何子序列的最小长度都是 1 (即 nums[i] 自身)        dp[i] = 1;         // 2. 状态转移：        // 遍历 i 之前的所有元素 j        for (int j = 0; j &lt; i; ++j) {            // 如果 nums[i] &gt; nums[j]，说明 nums[i] 可以接在 nums[j] 后面            if (nums[i] &gt; nums[j]) {                // 我们要找一个最长的 dp[j] 来接                dp[i] = max(dp[i], dp[j] + 1);            }        }                // 3. 更新全局答案：        // 最终答案是所有 dp[i] 中的最大值        global_max_length = max(global_max_length, dp[i]);    }    return global_max_length;}\r\n方法2: 二分查找 + 贪心\r\nint lengthOfLIS(vector&lt;int&gt;&amp; nums) {    vector&lt;int&gt; tails;    for(int num:nums){        auto it = lower_bound(tails.begin(),tails.end(),num);        if(it==tails.end()){            tails.push_back(num);        }else{            *it = num;        }    }    return tails.size();}\r\n核心思想：耐心排序 (Patience Sorting).\r\n这个算法的灵感来自于一种叫做“耐心排序”的纸牌游戏。 游戏规则：\r\n你有一堆乱序的牌（nums\r\n数组），你需要把它们一张张发到桌上的几个牌堆（tails 数组）里。\r\n\r\n规则 1：你一次拿一张牌 num。\r\n规则 2：你必须把 num 放到某个牌堆的顶部。你只能放在牌堆顶部 &gt;=\r\nnum 的牌堆上。\r\n规则 3：如果你有多个选择（例如 num=3，牌堆顶部有 [2, 5,\r\n8]），你必须选择最左边的那个（即 5）。\r\n规则 4：如果 num 比所有牌堆的顶部都大（例如 num=10，牌堆顶部 [2, 5,\r\n8]），你必须在最右边新建一个牌堆。\r\n\r\n结论：当你发完所有牌后，桌上牌堆的数量就是 LIS 的长度。\r\ntails 数组是什么？tails\r\n数组就是这个游戏中，桌上所有牌堆顶部的牌的集合。\r\ntails[k] 存储的是 “牌堆 k” 的顶部卡片。由于规则 4，tails\r\n数组（即所有牌堆的顶部）必然是严格递增的。\r\n\r\ntails = [pile1_top, pile2_top, pile3_top, …]\r\n\r\n因为只有当 num 大于 所有\r\n顶牌时，才允许你新建牌堆（push_back），所以新牌堆的顶牌一定比所有旧顶牌都大。\r\n因为 tails 数组是严格递增的，所以我们可以使用二分查找来应用规则\r\n3。\r\n让我们把“游戏规则”翻译成“代码逻辑”：\r\n\r\ntails 数组：存储所有牌堆的顶部。\r\n遍历 nums 中每个 num：\r\n\r\n二分查找：在 tails 数组中，找到第一个大于或等于 num 的位置 it (即\r\nstd::lower_bound)。\r\nif (it == tails.end())：\r\n\r\n游戏翻译：num 比所有牌堆的顶部都大（规则 4）。\r\n代码逻辑：在最右边新建一个牌堆。\r\n操作：tails.push_back(num)。\r\n结果：LIS 的长度增加了 1。\r\n\r\nif (it != tails.end())：\r\n\r\n游戏翻译：我们找到了一个牌堆 *it (例如 5)，num (例如 3)\r\n可以放在它上面（规则 2 &amp; 3）。\r\n代码逻辑：用 num 替换掉 *it。\r\n操作：*it = num。\r\n结果：LIS 的长度没有变，但这个牌堆的顶部变小了（5 变成了 3）。\r\n\r\n\r\n\r\n核心就是在更新tails数组时使用了二分查找,\r\n使得整体时间复杂度降为O(nlogn)\r\n状态机 DP\r\n这是“入门 DP”中 dp[i] 的自然演进。在一维 DP（如打家劫舍）中，dp[i]\r\n的决策只依赖于 dp[i-1] 和 dp[i-2]。但在更复杂的问题中，dp[i]\r\n的决策不仅依赖于 i-1，还依赖于 i-1 所处的状态。\r\n例如“买卖股票(带冷冻期)”，在第 i\r\n天，你能做的操作（买、卖、持有不动）取决于你在第 i − 1\r\n天是“持有股票”还是“未持有股票”, 未持有是在冷冻期还是不在冷冻期。状态机\r\nDP 就是用来解决这种“在不同状态间转换”的最优解问题。\r\n我们不再用一个简单的 dp[i] 来表示“到第 i\r\n天的最大收益”，因为这个信息不够。 我们使用 dp[i][j]，其中：\r\n\r\ni：代表时间（第 i 天，或考虑第 i 个元素）。\r\nj：代表在 i 时刻所处的状态（状态 j）。\r\ndp[i][j] 的值：表示在第 i 天，处于状态 j\r\n时，所能获得的最大收益（或最长长度、最少次数等）。\r\n\r\n解决状态机 DP 的“四部曲”: 这是一个几乎可以套用在所有状态机 DP\r\n问题上的标准流程。\r\n\r\n第 1 步：确定状态 (Define States)\r\n\r\n问自己：“在任何一天 i，我可能处于哪些互斥的状况下？”\r\n例 (LC 122)：\r\n\r\n状态 0：今天结束时，手里持有股票。\r\n状态 1：今天结束时，手里未持有股票。\r\n\r\n\r\n第 2 步：绘制状态转移图 (Draw the Diagram)\r\n\r\n这是最关键的一步。画出状态（节点）和事件（带箭头的边）。\r\n例 (LC 122)：\r\n\r\n状态 0 (未持有) 买入 状态 1\r\n(持有)\r\n状态 1 (持有) 卖出 状态 0\r\n(未持有)\r\n状态 0 (未持有) 休息 状态 0\r\n(未持有)\r\n状态 1 (持有) 休息 状态 1\r\n(持有)\r\n\r\n\r\n第 3 步：写出状态转移方程 (Write Equations), 把“图”翻译成“数学”。\r\n\r\ndp[i][j] 的值，等于所有“能转移到 j 状态”的 i-1 状态的最大值。\r\n\r\ndp[i][0] (今天未持有) = max(昨天就未持有，今天休息：dp[i-1][0],\r\n昨天持有，今天卖了：dp[i-1][1] + prices[i])\r\ndp[i][1] (今天持有) = max(昨天就持有，今天休息：dp[i-1][1],\r\n昨天未持有，今天买了：dp[i-1][0] - prices[i])\r\n\r\n\r\n第 4 步：确定 Base Cases (Initialize)\r\n\r\ndp[0][0]：第 0 天，未持有 → 利润为\r\n0。\r\ndp[0][1]：第 0 天，持有 →\r\n意味着在第 0 天买了 → 利润为\r\n-prices[0]。\r\n\r\n\r\n经典示例：LC 309\r\n(带冷冻期的股票)\r\n题目：卖出股票后，你必须在第二天（冷冻期）休息，不能买入。\r\n第 1\r\n步：确定状态(这里的状态一定是采取行动之后处于的状态) -\r\n状态 0：持有 - 状态 1：未持有（今天刚卖出，处于冷冻期） - 状态\r\n2：未持有（不在冷冻期，可以买入） -\r\n说明：我们必须把“未持有”拆成两种状态，因为它们对明天的决策（能否买入）有影响。\r\n第 2 步：绘制状态转移图 - 状态 0 (持有) 卖出 状态 1 (冷冻) -\r\n状态 1 (冷冻) 休息 状态 2 (可买) -\r\n状态 2 (可买) 买入 状态 0 (持有) -\r\n状态 0 (持有) 休息 状态 0 (持有) -\r\n状态 2 (可买) 休息 状态 2 (可买)\r\n第 3 步：状态转移方程 - dp[i][0] (持有) =\r\nmax(昨天就持有：dp[i-1][0]昨天是“可买”，今天买了：dp[i-1][2] -\r\nprices[i]) - dp[i][1] (冷冻) = max(昨天持有，今天卖了：dp[i-1][0] +\r\nprices[i]) - dp[i][2] (可买) =\r\nmax(昨天就是“可买”，今天休息：dp[i-1][2]昨天是“冷冻”，今天解冻了：dp[i-1][1])\r\n第 4 步：Base Cases - dp[0][0] = -prices[0] - dp[0][1] = 0 (第 0\r\n天不可能处于冷冻期) - dp[0][2] = 0 (第 0 天未持有)\r\n最终答案：max(dp[n-1][1], dp[n-1][2])\r\n(因为最后一天持有股票利润肯定不是最大的)。 int maxProfit(vector&lt;int&gt;&amp; prices) {    int n = prices.size();    if(n&lt;=1) return 0;    vector&lt;vector&lt;int&gt;&gt; dp(n,vector&lt;int&gt;(3,0));    // dp[i][0]: 第 i 天, 处于 \"持有\" 状态的最大利润    // dp[i][1]: 第 i 天, 处于 \"可买\" (非冷冻期、未持有) 状态的最大利润    // dp[i][2]: 第 i 天, 处于 \"冷冻\" 状态的最大利润    dp[0][0] = -prices[0];   // 持有    dp[0][1] = 0;       // 可买    dp[0][2] = 0;   // 冷冻期    for(int i=1;i&lt;n;i++){        dp[i][0] = max(dp[i-1][0], dp[i-1][1]-prices[i]);        dp[i][1] = max(dp[i-1][2], dp[i-1][1]);        dp[i][2] = dp[i-1][0]+prices[i];    }    return max(dp[n-1][1],dp[n-1][2]);}\r\n划分型 DP (Partition DP)\r\n核心思想：解决“将一个序列（数组/字符串）分割成若干段，以求最优解”的问题。例如：“将字符串分割为最少的美丽子字符串”、“将数组分割为\r\nk 段使最大和最小”。\r\n状态定义（递推）：通常有两种状态定义： - 不限段数 (如 LC 139)：dp[i]\r\n= 考虑前 i 个元素\r\na[0…i-1]，将其分割的最优解（如 bool 能否分割，int 最小代价）。 - 限制\r\nk 段 (如 LC 410)：dp[k][i] =\r\n将前 i 个元素 a[0…i-1]\r\n分割成恰好 k\r\n段的最优解。\r\n状态转移：枚举最后一段！这是划分型 DP 的灵魂。\r\ndp[i] 的值，是通过枚举最后一段的起点 j 来确定的: dp[i] = 最优(dp[j] + cost(j, i − 1))\r\n(其中 0 ≤ j &lt; i) -\r\ndp[j]：前 j\r\n个元素的最优解（子问题）。 - cost(j, i-1)：将 a[j…i-1]\r\n作为一个整体（最后一段）的代价/合法性。\r\n区间 DP (Interval DP)\r\n区间 DP\r\n主要用于解决“区间”或“子区间”相关的问题，通常涉及对一个序列（数组或字符串）进行划分、合并或计算某种属性。区间\r\nDP\r\n的核心在于状态定义和状态转移方程，它们通常基于区间的起点和终点。\r\n\r\n核心思想：当一个大区间 [i, j]\r\n的最优解，依赖于它内部的、更小的子区间（如 [i+1,\r\nj]、[i, j-1]、[i, k] 和 [k+1, j]）的最优解时，使用区间\r\nDP。这通常用于“合并”或“消除”问题，例如戳气球、合并石头、最长回文子序列。\r\n状态定义（递推）： dp[i][j] = 在闭区间[i, j] 上能获得的最优解。\r\n状态转移： 你需要思考最后一步操作。\r\n\r\n情况 1 (两端相关)：如“最长回文子序列”，dp[i][j]\r\n的值依赖 dp[i+1][j-1]。\r\n情况 2 (枚举分割点)：如“戳气球”，dp[i][j] 的值依赖\r\ndp[i][k] + dp[k+1][j]。\r\n\r\n关键：遍历顺序 dp[i][j]\r\n依赖于更短的区间。所以你不能for i ... for j ...。\r\n你必须按照区间长度 (len)来遍历： for (int len = 1; len &lt;= n; ++len) {    for (int i = 0; i &lt;= n - len; ++i) {        int j = i + len - 1; // 区间右端点        // ... 计算 dp[i][j] ...    }}\r\n\r\n例如, 对于最大回文子序列问题: int longestPalindromeSubseq(string s) {    int n = s.length();    if (n == 0) return 0;    // 1. 状态定义: dp[i][j] = s[i...j] 上的 LPS 长度    vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(n, 0));    // 2. 递推顺序: 按照区间长度 len 从 1 到 n 遍历    for (int len = 1; len &lt;= n; ++len) {                // 遍历所有可能的起始点 i        // j 是由 i 和 len 决定的        for (int i = 0; i &lt;= n - len; ++i) {            int j = i + len - 1; // 区间的结束点            // 3. Base Case: len = 1            if (len == 1) {                dp[i][j] = 1;                continue; // 计算下一个区间            }            // 4. 状态转移: len &gt; 1            if (s[i] == s[j]) {                // 情况一: s[i] == s[j]                // dp[i][j] = dp[i+1][j-1] + 2                // 注意: 当 len=2 时 (例如 \"aa\"), i+1 &gt; j-1                // 此时 dp[i+1][j-1] (例如 dp[1][0]) 是 0 (因为 j &lt; i)                // 所以 dp[i][j] = 0 + 2 = 2，是正确的。                dp[i][j] = dp[i + 1][j - 1] + 2;            } else {                // 情况二: s[i] != s[j]                dp[i][j] = max(dp[i + 1][j], dp[i][j - 1]);            }        }    }    // 5. 最终答案: dp[0][n-1]    return dp[0][n - 1];} 第 1 步：状态定义\r\n\r\ndp[i][j]：表示字符串 s 在区间 [i, j]（即子串\r\ns[i…j]）上的最长回文子序列的长度。\r\ni 是区间的起始索引，j 是区间的结束索引。\r\n\r\n第 2 步：最终答案\r\n\r\n我们要求的是整个字符串 s 的 LPS，即 s[0…n-1] 的解。\r\n答案：dp[0][n-1]\r\n\r\n第 3 步：Base Case (递推的起点)\r\n\r\n我们需要从“最短的区间”开始。\r\n区间长度 len = 1：即 i == j 时，例如 dp[0][0] (“b”), dp[1][1]\r\n(“b”)。\r\n任何单个字符本身就是回文，长度为 1。\r\nBase Case: dp[i][i] = 1\r\n\r\n第 4 步：状态转移 (灵魂)\r\n\r\n我们要计算 dp[i][j]，此时区间长度 len &gt;\r\n1。我们只看这个区间的两个端点：s[i] 和 s[j]。\r\n情况一：两端字符相等 s[i] == s[j], 例如 s[i…j] = “a…a”\r\n\r\n分析：太好了！s[i] 和 s[j] 可以作为回文序列的“外壳”。\r\n操作：LPS 的长度至少为 2（s[i] 和 s[j]）。\r\n子问题：我们只需要再知道内部区间 [i+1, j-1] 的 LPS 长度（即\r\ndp[i+1][j-1]）即可。\r\n转移方程 (1)：dp[i][j] = dp[i+1][j-1] + 2\r\n\r\n情况二：两端字符不等 s[i] != s[j]\r\n\r\n例如：s[i…j] = “a…b”\r\n分析：s[i] 和 s[j] 不能同时作为回文的“外壳”。我们必须丢弃一个。\r\n操作：我们有两个选择，取其中能得到最长回文的那一个：\r\n\r\n丢弃 s[i]：我们在区间 [i+1, j] 中寻找 LPS。解是 dp[i+1][j]。\r\n丢弃 s[j]：我们在区间 [i, j-1] 中寻找 LPS。解是 dp[i][j-1]。\r\n\r\n转移方程 (2)：dp[i][j] = max(dp[i+1][j], dp[i][j-1])\r\n\r\n\r\n树形DP\r\n树形DP是一类特殊的动态规划问题，通常用于解决树结构上的最优子结构问题。与传统的线性动态规划不同，树形DP需要考虑节点之间的层级关系和子树结构。\r\n且树形DP通常采用后序遍历的方式进行状态转移，因为每个节点的状态依赖于其子节点的状态。这样还会导致树形DP通常依旧使用递归实现，而不是迭代保存dp表这样的做法.\r\n例题: 在二叉树上“打家劫舍”，不能偷相邻（父子）的。 分析：对于一个节点\r\nroot，它的最优解依赖于 root-&gt;left 和 root-&gt;right\r\n的最优解。(Leetcode 337题) unordered_map&lt;TreeNode*,int&gt; map;  // 来缓存已经计算过的节点结果int rob(TreeNode* root) {    if(root==nullptr) return 0;    if(map.contains(root)) return map[root];  // 如果已经计算过，直接返回缓存结果    int max1 = rob(root-&gt;left)+rob(root-&gt;right);    // 不偷 root, 取左右子树的和    // 偷 root, 则不能偷左右子节点, 转而偷左右子节点的子节点    int max2 = 0;    if(root-&gt;left!=nullptr) max2+=rob(root-&gt;left-&gt;left)+rob(root-&gt;left-&gt;right);    if(root-&gt;right!=nullptr) max2+=rob(root-&gt;right-&gt;left)+rob(root-&gt;right-&gt;right);    max2 += root-&gt;val;  // 加上 root 的值    map[root] = max(max1,max2);  // 缓存结果    return max(max1,max2);  // 返回结果}\r\n","categories":["algorithms"],"tags":["algorithms","动态规划"]},{"title":"MPMC队列","url":"/2025/10/19/lang/CPP/%E9%AB%98%E6%95%88%E7%BB%93%E6%9E%84/MPMC%E9%98%9F%E5%88%97/","content":"MPMC (Multiple-Producer,\r\nMultiple-Consumer)，即多生产者、多消费者队列，是并发编程中最灵活的数据结构。它允许：\r\n\r\n任意数量的生产者线程同时向队列中添加元素。\r\n任意数量的消费者线程同时从队列中取出元素。\r\n\r\n你可以把它想象成一个繁忙的物流中心，有多个卸货平台（生产者）和多个装货平台（消费者），它们可以全天候、并行地工作，而不会导致货物混乱。\r\n应用场景\r\n由于其极高的灵活性，MPMC 队列是许多通用并发系统的基石：\r\n\r\n线程池的任务队列 (Task Queue)：这是 MPMC\r\n最经典、最核心的应用。系统中的任何线程（生产者）都可以将一个任务（例如一个函数对象）提交到队列中。线程池中任何一个空闲的工作线程（消费者）都可以从队列中获取一个任务来执行。\r\n并行数据处理流水线：在一个复杂的数据处理流程中，如果某个处理阶段本身就是并行的（有多个工作线程），并且下一个阶段也是并行的，那么这两个阶段之间就需要一个\r\nMPMC 队列来传递数据。\r\n高性能日志系统：在大型应用中，多个业务线程（生产者）会高频地产生日志消息。为了不阻塞业务线程，这些日志消息被快速扔进一个\r\nMPMC 队列。后台有多个专门的 I/O\r\n线程（消费者）负责从队列中取出日志并写入文件或网络。\r\n\r\n核心挑战：双端竞争与 ABA 问题\r\nMPMC 的实现难度远超其他类型的队列，因为它面临着最复杂的并发挑战。\r\n双端竞争 (Double-Ended Contention)\r\n\r\n生产者端：多个生产者线程会同时竞争，试图更新队列的\r\ntail（尾部）指针。\r\n消费者端：多个消费者线程会同时竞争，试图更新队列的\r\nhead（头部）指针。\r\n\r\n在 SPSC 中，两端都没有竞争。在 MPSC/SPMC 中，只有一端存在竞争。而在\r\nMPMC\r\n中，两端都存在激烈的竞争，这使得简单的原子指针更新变得不可行，必须使用更复杂的同步原语，如\r\nCAS (Compare-And-Swap) 循环。\r\nABA 问题\r\n这是无锁编程中一个非常著名且致命的陷阱，在 MPMC\r\n的朴素实现中极易出现。\r\n假设有两个线程 T1 和 T2, 线程 T1 读取内存地址 P 的值为 A。然后 T1\r\n被操作系统挂起。\r\n\r\n挂起指的是操作系统临时中断某个线程的执行，将其从运行状态切换到等待或休眠状态。被挂起的线程不会继续执行自己的代码，直到操作系统再次调度它恢复运行。在并发场景下，线程被挂起后，其他线程可能会修改共享数据，这就为\r\nABA 问题的发生创造了条件。\r\n\r\n与此同时，线程 T2 修改 P 的值为 B，然后又修改回 A。\r\nT1 恢复执行，它检查 P 的值，发现仍然是 A。T1\r\n错误地认为从它上次读取到现在什么都没有改变，于是继续执行后续操作。\r\n在 MPMC 队列中，这种情况可能发生在 head 或 tail\r\n指针上。这种情况是非常危险的，因为它可能导致数据结构的状态被错误地解释，进而引发数据损坏或程序崩溃。\r\n假设一个基于链表的队列，T1 准备对头节点 head（其地址为\r\nA）执行出队操作。在 T1 被挂起时，T2 可能已经将 A\r\n节点出队、销毁，然后又有一个新节点恰好在相同的内存地址 A 处被分配。当 T1\r\n恢复时，它看到的 head 地址仍然是 A，但这个 A\r\n已经是一个全新的、不相关的节点了。如果 T1\r\n继续操作，就会导致数据损坏或程序崩溃。\r\n实现策略\r\n实现一个正确且高效的 MPMC\r\n无锁队列是世界级的难题。工业界主要采用以下几种经过验证的算法。\r\n经典算法：Michael-Scott 队列\r\n这是教科书中最常介绍的 MPMC\r\n无锁队列算法，基于无锁链表实现。\r\n\r\n数据结构：一个单向链表，包含 head 和 tail 两个原子指针。\r\n哨兵节点 (Sentinel Node)：队列初始化时包含一个“哑节点”（dummy\r\nnode），head 和 tail\r\n都指向它。这个哨兵节点简化了边界条件（空队列/单元素队列），并有效地将生产者和消费者的竞争点分离开。\r\n入队 (Enqueue)：\r\n\r\n创建一个新节点。\r\n使用 CAS 循环，尝试将新节点链接到当前 tail 节点的 next\r\n指针上。\r\n成功后，再尝试更新 tail 指针指向新的尾节点。\r\n\r\n出队 (Dequeue)：\r\n\r\n使用 CAS 循环，尝试将 head 指针移动到它的下一个节点\r\n(head-&gt;next)。\r\n成功后，旧的\r\nhead（现在是哨兵节点）就可以被安全地回收了。\r\n\r\n\r\n解决 ABA 问题：通常通过“标记指针” (Tagged Pointer) 或版本计数器\r\n(Version Counter) 来解决。即将指针和\r\n一个计数器打包成一个更大的原子类型（如 128\r\n位），每次修改指针时都增加计数器。CAS\r\n操作需要同时比较指针和计数器，确保两者都未被改变。\r\n现代高性能实现\r\n(基于环形缓冲区)\r\n虽然 Michael-Scott\r\n队列是无界的（unbounded），但其性能通常受限于内存分配和链表遍历。现代很多高性能\r\nMPMC 队列是有界的（bounded），并且基于环形缓冲区，因为这能更好地利用 CPU\r\n缓存。\r\n其实现远比 SPSC 环形缓冲区复杂，核心思想是给每个槽位 (slot)\r\n加上版本号或序列号，以协调生产者和消费者。\r\n基本思路 (Ticket-Based)是维护两个原子计数器：enqueue_ticket 和\r\ndequeue_ticket。\r\n生产者： 1. 原子地获取并递增\r\nenqueue_ticket，得到一个唯一的入队“票号”。 2. 计算该票号对应的缓冲区索引\r\nidx = ticket % capacity。 3. 自旋等待，直到 buffer[idx]\r\n的版本号等于其票号（这表示消费者已经消费完该槽位的旧数据，可以写入了）。\r\n4. 写入数据。 5. 将 buffer[idx]\r\n的版本号加一，以通知消费者数据已准备好。\r\n消费者： 1. 原子地获取并递增\r\ndequeue_ticket，得到一个唯一的出队“票号”。 2. 计算该票号对应的缓冲区索引\r\nidx = ticket % capacity。 3. 自旋等待，直到 buffer[idx]\r\n的版本号等于其票号（这表示生产者已经写入新数据，可以消费了）。 4.\r\n读取数据。 5. 将 buffer[idx]\r\n的版本号加一，以通知生产者数据已被消费。\r\n这种设计将对 head/tail\r\n指针的直接竞争，转化为了对槽位版本号的等待，在很多场景下能提供更高的吞吐量。\r\n示例代码\r\n下面是基于经典的 Michael-Scott 队列算法 的 MPMC\r\n无锁队列的简化实现：\r\n#ifndef MPMC_QUEUE_H#define MPMC_QUEUE_H#include &lt;atomic&gt;#include &lt;thread&gt; // For std::this_thread::yield()template&lt;typename T&gt;class MPMCQueue {private:    struct Node {        T data;        std::atomic&lt;Node*&gt; next;        Node(T val) : data(std::move(val)), next(nullptr) {}    }; // 节点结构, 在类内定义, 但是类并不包含节点实例    // 缓存行对齐以避免伪共享    alignas(64) std::atomic&lt;Node*&gt; head_;   // 头指针, 指向链表的第一个节点    alignas(64) std::atomic&lt;Node*&gt; tail_;  // 尾指针, 指向链表的最后一个节点public:    MPMCQueue() {        // 关键设计：创建一个哨兵节点 (dummy node), 为了简化边界条件        // 队列初始化时，head 和 tail 都指向这个空节点        Node* sentinel = new Node(T{});  // 这里的T{}是默认构造的哨兵数据        head_.store(sentinel);        tail_.store(sentinel);    }    ~MPMCQueue() {        // 清理所有剩余的节点        T dummy;        while (try_dequeue(dummy)) {}        // 删除最后的哨兵节点        delete head_.load();    }    // 禁止拷贝和赋值    MPMCQueue(const MPMCQueue&amp;) = delete;    MPMCQueue&amp; operator=(const MPMCQueue&amp;) = delete;    /**     * @brief [多生产者线程调用] 尝试将一个元素入队。     */    void enqueue(T value) {        Node* new_node = new Node(std::move(value));                // CAS 循环：持续尝试，直到成功将新节点链接到链表尾部        while (true) {            Node* last = tail_.load(std::memory_order_acquire);  // 获取当前尾节点, 一开始是哨兵节点            Node* next = last-&gt;next.load(std::memory_order_acquire);  // 获取尾节点的下一个节点            // 检查 tail_ 是否在我们读取后被其他线程改变了(一致性检查, 防止 ABA 问题)            if (last == tail_.load(std::memory_order_relaxed)) {                if (next == nullptr) {                    // 这是正常情况：tail_ 指向的是真正的尾节点                    // 尝试将新节点链接到尾部, 确保只有一个线程能够成功链接到旧的尾部。如果失败（被其他线程抢先链接了），循环重新开始。                    if (last-&gt;next.compare_exchange_weak(next, new_node, std::memory_order_release)) {                        // 链接成功！现在尝试更新 tail_ 指针                        // 即使下面这步失败也没关系，其他线程会帮忙推进 tail_                        tail_.compare_exchange_weak(last, new_node, std::memory_order_release);                        return; // 成功入队                    }                } else {  // next != nullptr, 即已经有其他线程在添加节点                    // 帮助其他线程：tail_ 指针落后了，我们帮它更新到真正的尾节点                    tail_.compare_exchange_weak(last, next, std::memory_order_release);                }            }        }    }    /**     * @brief [多消费者线程调用] 尝试从队列中取出一个元素。     */    bool try_dequeue(T&amp; value) {        // CAS 循环：持续尝试，直到成功取出一个节点        while (true) {            Node* first = head_.load(std::memory_order_acquire);            Node* last = tail_.load(std::memory_order_acquire);            Node* next = first-&gt;next.load(std::memory_order_acquire);            if (first == head_.load(std::memory_order_relaxed)) {  // 一致性检查，防止 ABA 问题                if (first == last) {                    // 队列为空，或者 tail_ 指针落后了                    if (next == nullptr) {                        return false; // 队列确定为空                    }                    // tail_ 落后，帮助其他线程推进它                    tail_.compare_exchange_weak(last, next, std::memory_order_release);                } else {                    // 队列不为空，尝试移动 head_ 指针                    // 我们要取出的值在 next 节点中（因为 first 是哨兵节点）                    if (head_.compare_exchange_weak(first, next, std::memory_order_release)) {                        value = std::move(next-&gt;data);                                                // ### UNSAFE ###                        // 危险！这里是这个实现最不安全的地方。                        // 在一个真实的 MPMC 队列中，你不能立即删除 'first' 节点，                        // 因为其他线程可能仍然持有指向它的指针。                        // 必须使用险象指针等技术来确保安全回收。                        delete first; // 在此教学实现中，我们简化为直接删除                                                return true; // 成功出队                    }                }            }        }    }};#endif // MPMC_QUEUE_H\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"SPSC队列","url":"/2025/10/19/lang/CPP/%E9%AB%98%E6%95%88%E7%BB%93%E6%9E%84/SPSC%E9%98%9F%E5%88%97/","content":"SPSC 是 Single Producer, Single Consumer\r\n的缩写，直译为“单生产者，单消费者”。\r\nSPSC\r\n队列是一种特殊的并发数据结构，它被设计用于一个非常明确的场景：有且只有一个线程（生产者）向队列中添加元素，同时有且只有一个另外的线程（消费者）从队列中取出元素。\r\n这种严格的约束使得 SPSC\r\n队列可以进行高度优化，从而实现极高的性能和极低的延迟。\r\n核心优势\r\n在通用的并发编程中，我们经常使用\r\nstd::mutex（互斥锁）来保护共享数据（例如一个标准的\r\nstd::queue），以防止多个线程同时读写造成数据竞争。然而，锁机制有其固有的开销和问题：\r\n\r\n性能开销：每次加锁和解锁都是一次操作系统内核调用，会涉及上下文切换，这在高并发场景下会严重影响性能。\r\n线程阻塞：如果一个线程持有锁，其他需要这个锁的线程就必须等待，无法继续执行。\r\n复杂性问题：锁的使用容易引发死锁（Deadlock）和优先级反转（Priority\r\nInversion）等棘手的问题。\r\n\r\nSPSC\r\n队列的核心优势在于它通常是“无锁的”（Lock-Free）.\r\n它不使用互斥锁、自旋锁等阻塞性同步原语。取而代之的是，它利用现代 CPU\r\n提供的原子操作（Atomic Operations）\r\n和内存屏障（Memory Fences）\r\n来确保数据在生产者和消费者线程之间的安全可见性和一致性。\r\n带来的好处：\r\n\r\n极高的吞吐量：由于没有锁竞争，生产者和消费者线程可以最大程度地并行执行，极大地提高了数据传输效率。\r\n极低的延迟：入队和出队操作非常快，因为它们只包含几个原子指令和内存读写，延迟非常稳定和可预测。\r\n避免死锁：无锁设计从根本上消除了由锁引起的死锁问题。\r\n\r\nSPSC 队列的实现原理\r\n尽管实现一个正确且高效的无锁 SPSC\r\n队列非常复杂，但其核心思想是直观的。最常见的实现是基于环形缓冲区（Ring\r\nBuffer）。\r\n数据结构\r\n一般来说, 其SPSC队列的数据结构如下： -\r\n一个固定大小的数组（或连续内存块）作为缓冲区。 - 两个索引（或指针）： -\r\nhead (或\r\nread_idx)：由消费者线程持有并唯一修改。它指向下一个要读取的元素位置(因为队列是尾进头出).\r\n- tail (或\r\nwrite_idx)：由生产者线程持有并唯一修改。它指向下一个要写入的元素位置,\r\n为空.\r\n入队和出队操作\r\n这里的关键在于，head 只被消费者写，tail\r\n只被生产者写。但是，它们需要读取对方的索引来判断队列的状态（空或满）。\r\n对于生产者（入队操作）： - 读取 head\r\n索引，以确定队列是否已满。 - 如果未满，将新元素放入\r\ntail 指向的位置。 - 更新 tail\r\n索引，使其指向下一个可写位置。\r\n对于消费者（出队操作）： - 读取 tail\r\n索引，以确定队列是否为空。 - 如果非空，从 head\r\n指向的位置取出元素。 - 更新 head\r\n索引，使其指向下一个可读位置。\r\n为了保证在没有锁的情况下，一个线程对索引的更新能被另一个线程正确地观察到，head\r\n和 tail\r\n索引必须是原子类型（std::atomic&lt;size_t&gt;）。\r\n内存顺序（Memory Ordering）\r\n这是无锁编程中最精妙也最困难的部分。为了确保数据和索引的同步，必须使用正确的内存顺序。\r\n\r\n生产者在更新 tail 时，需要使用\r\nstd::memory_order_release。\r\n\r\n这确保了在 tail\r\n索引被更新之前，所有对缓冲区中元素数据的写入操作都已经完成，并且对其他线程可见。这就像一个屏障，防止它之前的写操作被重排到它之后。\r\n\r\n消费者在读取 tail 时，需要使用\r\nstd::memory_order_acquire。\r\n\r\n这确保了在读取 tail\r\n索引之后，才能去读取缓冲区中的数据。它与生产者的\r\nrelease\r\n配对，保证消费者能看到生产者写入的所有数据。\r\n\r\n\r\n通过这种 acquire-release\r\n语义，可以在没有锁的情况下，安全地在两个线程间传递数据。\r\n代码示例\r\n#ifndef SPSC_QUEUE_H#define SPSC_QUEUE_H#include &lt;vector&gt;#include &lt;atomic&gt;#include &lt;cstddef&gt; // For size_t#include &lt;new&gt;     // For std::hardware_destructive_interference_size// --- 关键性能优化：缓存行对齐 ---// 在 C++17 之前，我们通常会硬编码一个值，比如 64。// C++17 提供了标准的宏来获取这个值，以提高可移植性。#ifdef __cpp_lib_hardware_interference_size    constexpr size_t CACHE_LINE_SIZE = std::hardware_destructive_interference_size;#else    // 64 字节是现代 x86 CPU 缓存行的常见大小，是一个安全的选择。    constexpr size_t CACHE_LINE_SIZE = 64;#endiftemplate&lt;typename T&gt;class SPSCQueue {public:    explicit SPSCQueue(size_t capacity)        : capacity_(capacity + 1),          buffer_(capacity_ + 1) // 分配多一个元素空间，用于区分满/空状态    {        // 确保 T 是可移动构造或可移动赋值的类型        static_assert(std::is_move_constructible&lt;T&gt;::value, \"T must be move constructible\");        static_assert(std::is_move_assignable&lt;T&gt;::value, \"T must be move assignable\");    }    // 禁止拷贝和赋值    SPSCQueue(const SPSCQueue&amp;) = delete;    SPSCQueue&amp; operator=(const SPSCQueue&amp;) = delete;    ~SPSCQueue() {        // 析构函数：确保队列中所有剩余的 T 对象都被正确销毁        T dummy;        while (try_dequeue(dummy)) {            // 循环出队，直到队列为空            // dummy 的析构函数会在每次循环结束时被调用        }    }    // [生产者线程调用] 尝试将一个元素入队, 注意这里T&amp;&amp;不是万能引用, 因为对于类的函数, 在编译时由于T作用在成员变量上, 类模板参数T已经确定.    bool try_enqueue(T&amp;&amp; value) {        // memory_order_relaxed: 生产者本地读取自己的 tail，不用同步，因为只有自己写它        const auto current_tail = tail_.load(std::memory_order_relaxed);  // 获取当前 tail 位置, 即要写入的位置        const auto next_tail = (current_tail + 1) % capacity_;  // 计算下一个 tail 位置, 用于判断队列是否已满        // 读取消费者的 head 位置, 用于判断队列是否已满, 因此需要使用 acquire 语义确保读取到最新值        // 因为留一个空位作为队列满的标志, 所以当 next_tail == head 时表示队列已满        if (next_tail == head_.load(std::memory_order_acquire)) {            return false; // 队列已满        }        // 将数据移动到缓冲区        buffer_[current_tail] = std::move(value);        // 写入完成后，更新 tail 位置, 使用 release 语义确保数据写入对消费者可见        tail_.store(next_tail, std::memory_order_release);                return true;    }        // 为左值提供一个重载    bool try_enqueue(const T&amp; value) {        T temp = value;        return try_enqueue(std::move(temp));    }    // [消费者线程调用] 尝试从队列中取出一个元素, value 用于接收出队元素的引用。    bool try_dequeue(T&amp; value) {        // memory_order_relaxed: 此操作只与本线程相关。        const auto current_head = head_.load(std::memory_order_relaxed);        // memory_order_acquire: 确保我们能看到生产者线程对 tail_ 的最新更新。        // 它与生产者 enqueue 中的 release 操作配对。        if (current_head == tail_.load(std::memory_order_acquire)) {            return false; // 队列为空        }        // 从缓冲区移动数据        value = std::move(buffer_[current_head]);        // memory_order_release: 确保 head_ 的更新对生产者线程可见，        // 这样生产者就能知道一个槽位被释放了。        // 它与生产者 enqueue 中的 acquire 操作配对。        head_.store((current_head + 1) % capacity_, std::memory_order_release);        return true;    }    /**     * @brief 获取队列的近似大小。     * @note 在并发环境下，返回的值可能在你读取它之后立即就过时了。     * 主要用于监控和调试。     */    size_t size() const {        // 为了获取一个相对一致的快照，需要使用 acquire 语义        const auto current_tail = tail_.load(std::memory_order_acquire);        const auto current_head = head_.load(std::memory_order_acquire);                if (current_tail &gt;= current_head) {            return current_tail - current_head;        }        return capacity_ + current_tail - current_head;    }    bool empty() const {        return size() == 0;    }private:    const size_t capacity_;    std::vector&lt;T&gt; buffer_;    // --- 避免伪共享 (False Sharing) ---    // head_ 和 tail_ 会被不同核心上的不同线程高频访问。    // alignas 确保它们位于不同的缓存行，避免一个核心的写操作    // 导致另一个核心的缓存行失效，从而大幅提升性能。    alignas(CACHE_LINE_SIZE) std::atomic&lt;size_t&gt; head_{0};  // 初始化为0    alignas(CACHE_LINE_SIZE) std::atomic&lt;size_t&gt; tail_{0};};#endif // SPSC_QUEUE_H\r\n伪共享（False Sharing）\r\n假设你有这样一个结构： struct Data {    int a; // Thread 1 修改    int b; // Thread 2 修改};Data d; 现在, 线程 1 不断修改 d.a,\r\n而线程 2 不断修改 d.b. 看起来两个线程没有共享变量，互不干扰, 但问题是 ——\r\n它们俩的 a 和 b 很可能在同一个缓存行中！\r\n因为 CPU\r\n缓存是通过缓存一致性协议（MESI）维护的,\r\n当一个核心修改了自己缓存中的缓存行，其他核心上该缓存行就会被标记为无效。\r\n\r\n线程 1 改 a →\r\n它所在的缓存行被标记为“已修改”。\r\nCPU\r\n通知其他核心：“这个缓存行无效了！”\r\n线程 2 再改 b 时，发现缓存行无效 →\r\n重新从内存或其他核心拉取最新版本。\r\n\r\n⚠️ 尽管 a 和 b 互不相关，它们还是在不停地“打架”.\r\n这样两个核心之间不断传递缓存行，导致总线流量激增，性能急剧下降。这种“伪共享”不会导致错误，但会导致严重的性能退化。\r\n伪共享是指在多线程环境中，多个线程访问不同的变量，但这些变量恰好位于同一个缓存行中，从而导致不必要的缓存一致性开销。在我们的\r\nSPSC 队列中，head_ 和 tail_\r\n是两个频繁被不同线程访问的变量。为了避免它们之间的伪共享，我们使用\r\nalignas(CACHE_LINE_SIZE)\r\n将它们对齐到缓存行的边界上。这样可以确保它们位于不同的缓存行中，从而减少缓存失效的可能性，提高性能。\r\n应用场景和总结\r\nSPSC 队列是解决特定问题的“特种兵”，在以下场景中非常有用：\r\n\r\n线程间任务分发：一个主线程（生产者）接收外部请求或生成任务，然后放入队列，一个工作线程（消费者）从队列中取出任务并执行。例如，日志系统、事件处理系统。\r\n高性能计算：在流水线（Pipeline）处理模式中，前一个阶段的计算线程（生产者）将结果传递给下一个阶段的计算线程（消费者）。\r\n低延迟系统：在高频交易（HFT）\r\n或实时音视频处理中，一个线程负责从网络或硬件接收数据（生产者），另一个线程负责处理这些数据（消费者），对延迟的要求极为苛刻。\r\n游戏开发：一个输入线程（生产者）收集玩家的操作，放入队列，主游戏循环线程（消费者）取出并处理这些操作。\r\n\r\n目前, boost::lockfree::spsc_queue 就是一个成熟且高效的 SPSC 队列实现,\r\n可以直接使用.\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"侵入式数据结构 (Intrusive Data Structures)","url":"/2025/10/19/lang/CPP/%E9%AB%98%E6%95%88%E7%BB%93%E6%9E%84/%E4%BE%B5%E5%85%A5%E5%BC%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"侵入式数据结构是一种特殊的链式或树形数据结构设计模式。与传统的非侵入式\r\n(Non-Intrusive)\r\n数据结构不同，它要求被存储的数据对象本身包含用于维护数据结构关系（如链表的\r\nnext/prev 指针或树的子节点指针）的链接字段 (link\r\nfields)。\r\n核心概念\r\n非侵入式（传统）数据结构:\r\n在传统的非侵入式设计中，数据结构（例如 std::list&lt;T&gt;\r\n或 std::map&lt;Key, T&gt;）是独立于它所存储的数据 T\r\n存在的。\r\n容器内部维护一个节点结构 Node，这个 Node\r\n包含两个部分：链接字段（如指针）和数据字段，用于存储一个\r\nT 类型的对象。例如, 对于\r\nstd::list&lt;MyClass&gt;，链表节点中会有一个 MyClass\r\n的完整拷贝或指针。\r\n侵入式数据结构:\r\n而在侵入式设计中，链接字段被侵入到要存储的数据对象\r\nT 内部。\r\n数据对象 T\r\n必须继承或包含用于数据结构维护的基础节点结构\r\n(Base Node)。\r\n容器（或操作函数）只处理这些基础节点指针，通过指针算术（如\r\noffsetof 宏或 C++ 的类型转换技巧）来找到包含该基础节点的数据对象 T\r\n的起始地址。例如, 要将 MyClass 对象放入一个侵入式链表，MyClass 必须包含\r\nIntrusiveListNode 成员。\r\n这种设计将数据和结构维护信息紧密耦合在一起。数据结构的操作函数只通过类型安全的指针技巧（如\r\ncontainer_of 宏或 boost::intrusive 库提供的 to_value_ptr\r\n机制）来访问真正的用户数据。\r\n优点与缺点\r\n侵入式设计模式主要在需要高性能、低内存开销和高级控制的系统（如操作系统内核、嵌入式系统或高性能服务器）中被广泛使用。\r\n\r\n内存效率 (Memory Efficiency): 每个节点只维护一次数据结构信息,\r\n非侵入式结构需要额外的 Node\r\n结构体开销，而侵入式结构避免了额外的封装节点，减少了内存碎片。\r\n高性能 (Performance):\r\n避免了额外的指针解引用。在非侵入式结构中，从节点指针到实际数据需要一次解引用；侵入式结构中，数据和链接信息在同一块内存中，通常通过简单的指针偏移即可访问，这可能改善缓存局部性。\r\n常数时间复杂度删除 (Constant Time Complexity):\r\n操作可以在常数时间 O(1)\r\n内移除一个已知对象，而无需通过迭代器查找。因为对象本身包含了链接信息，可以直接执行\r\nunlink 操作。\r\n多重归属 (Multiple Membership):\r\n一个对象可以同时属于多个不同的数据结构（例如，一个对象同时在一个“最近访问”链表和一个“待处理”树中），只需要在对象中包含多个独立的链接字段集。\r\n零内存开销操作 (Zero-Cost Abstraction):\r\n数据结构不需要关心内存分配/释放，因为它只操作已存在的对象，没有 new 或\r\ndelete 的开销。\r\n\r\n容器操作（如 push_front 或\r\nremove）仅是修改指针。它们不涉及任何内存的申请或释放,\r\n所有的内存分配和释放都可以放在上层应用中集中处理，从而实现真正的零运行时内存管理开销。这使得侵入式结构成为实现自定义内存管理（例如内存池、竞技场分配器）或无锁数据结构的理想选择。\r\n\r\n\r\n虽然优势显著，但侵入式设计也带来了一些限制和复杂性：\r\n\r\n侵入性 (Intrusiveness)：\r\n目标数据类型必须被修改以包含链接字段。这意味着它无法用于第三方库或内置类型（如\r\nint 或 std::string），除非进行包装。\r\n安全性与复杂性：\r\n这种设计对程序员要求更高，必须确保对象的生命周期管理得当。如果一个对象被销毁，但它仍然在数据结构中，则会导致悬空指针\r\n(dangling pointers)。\r\n类型耦合：\r\n数据类型和数据结构类型之间存在强耦合，降低了代码的通用性。\r\n接口不一致： 侵入式数据结构往往不能直接使用标准的 C++\r\n迭代器和容器接口（如 std::list）。\r\n\r\nC++ 中的实践与工具\r\n在 C++\r\n标准库中没有侵入式数据结构的实现。但在实际应用中，主要依赖以下工具和模式：\r\n\r\ncontainer_of 宏（C 语言风格）: 这是一个在 Linux\r\n内核中常用的模式，虽然不是标准的 C++\r\n做法，但它体现了侵入式结构的核心思想：通过知道结构体内部成员的地址，反向推导出整个结构体的起始地址。\r\nstruct_ptr = (Type*)((char*)member_ptr − offsetof(Type, member))\r\n\r\nmember_ptr：指向对象内部链接字段的指针。\r\noffsetof：获取链接字段相对于对象起始地址的偏移量。\r\n通过将成员地址减去该成员在结构体中的偏移量，即可得到父结构体的起始地址。\r\n\r\nBoost.Intrusive 库: Boost\r\n库提供了成熟、类型安全且功能强大的侵入式数据结构实现，如\r\nboost::intrusive::list、boost::intrusive::set 等。\r\n\r\n使用方式：用户定义的数据类只需要继承或包含\r\nboost::intrusive::list_base_hook&lt;&gt; 等“钩子\r\n(hook)”类，即可将对象放入对应的侵入式容器中。\r\n优势：它提供了一种 C++\r\n惯用且类型安全的方式来使用侵入式设计，是生产环境中实现侵入式结构的标准选择。\r\n\r\n\r\n示例代码\r\n下面使用 C++ 风格的面向对象方式，通过继承来实现链接字段的“侵入”,\r\n实现一个侵入式双向链表 (Intrusive Doubly Linked List) \r\n基础节点结构 (Hook):\r\n我们首先定义一个基础的节点结构，它只包含维护双向链表所需的指针。任何想要加入这个链表的类都必须继承它。\r\n/** * @brief IntrusiveListNode (侵入式链表节点) * * 这是侵入式链表的基础钩子(Hook)。 * 任何想要被链表管理的类都需要继承它，以提供链表所需的链接字段。 */class IntrusiveListNode {public:    IntrusiveListNode *prev_ = nullptr; // 指向前一个元素的指针    IntrusiveListNode *next_ = nullptr; // 指向下一个元素的指针    // 默认构造函数    IntrusiveListNode() = default;    // 步骤说明：将析构函数声明为虚函数，以确保当通过基类指针删除派生类对象时，    // 能够正确调用派生类的析构函数。但在侵入式设计中，通常由用户管理内存，    // 容器不负责删除，所以此处保留默认或简单虚函数即可。    virtual ~IntrusiveListNode() = default;    // 检查节点是否已连接到某个链表。    bool is_linked() const {        return prev_ != nullptr || next_ != nullptr;    }};\r\n用户数据结构（被侵入的类）: 接下来，我们定义一个用户数据类\r\nMyData，它继承自 IntrusiveListNode。 /** * @brief MyData (用户数据类) * * 继承 IntrusiveListNode，使其可以作为侵入式链表的节点。 * 注意：链表指针 prev_ 和 next_ 现在是 MyData 对象的一部分。 */class MyData : public IntrusiveListNode {public:    int value_; // 存储的实际数据    MyData(int val) : value_(val) {}    // 打印数据    void print() const {        std::cout &lt;&lt; \"Data: \" &lt;&lt; value_ &lt;&lt; std::endl;    }};\r\n侵入式链表容器 (List): 容器类 IntrusiveList\r\n不再维护数据节点，它只维护指向\r\nIntrusiveListNode\r\n对象(链接类)的指针，并通过类型转换来访问实际的 MyData 对象。\r\n/** * @brief IntrusiveList (侵入式链表容器) * * 容器本身只管理 IntrusiveListNode 类型的指针。 * 泛型 T 必须继承自 IntrusiveListNode。 */class IntrusiveList {private:    IntrusiveListNode head_; // 链表头（哨兵节点）    // 私有函数：执行实际的连接操作    void link_nodes(IntrusiveListNode* prev, IntrusiveListNode* curr) {        // 步骤说明：将 curr 节点插入到 prev 节点之后。        // 这是双向链表连接的标准操作，确保链接的准确性。        curr-&gt;next_ = prev-&gt;next_;        curr-&gt;prev_ = prev;        prev-&gt;next_-&gt;prev_ = curr;        prev-&gt;next_ = curr;    }    // 私有函数：执行实际的移除操作    void unlink_node(IntrusiveListNode* curr) {        // 步骤说明：将 curr 节点从链表中移除，但不会释放内存。        // 这是侵入式数据结构的关键：只操作链接，不管理内存。        curr-&gt;prev_-&gt;next_ = curr-&gt;next_;        curr-&gt;next_-&gt;prev_ = curr-&gt;prev_;        curr-&gt;prev_ = nullptr; // 清除链接信息，表示已断开        curr-&gt;next_ = nullptr;    }public:    IntrusiveList() {        // 步骤说明：初始化哨兵节点。        // 链表头节点的 prev/next 都指向自身，形成一个空循环链表。        head_.prev_ = &amp;head_;        head_.next_ = &amp;head_;    }    // --- 核心操作：在头部插入 ---    void push_front(IntrusiveListNode* node) {        // 步骤说明：将节点插入到头节点之后，即链表最前面。        link_nodes(&amp;head_, node);    }    // --- 核心操作：移除（常数时间复杂度） ---    // 注意：这个操作可以直接作用于任意链表中的节点，无需查找！    void remove(IntrusiveListNode* node) {        // 数学准确性：如果节点未连接，尝试移除会造成错误，因此需要检查。        if (node-&gt;is_linked()) {            unlink_node(node);        }    }    // --- 遍历示例（使用类型转换获取用户数据） ---    void print_all() const {        IntrusiveListNode* current = head_.next_;        while (current != &amp;head_) {            // 步骤说明：将基础节点指针转换为 MyData 对象指针。            // 由于 MyData 继承自 IntrusiveListNode，因此这种向下转型是安全的。            // **注意：在泛型实现中，这里需要用到 Boost::intrusive 或 container_of 宏。**            // **但在本示例中，我们使用 C++ 的多态性（继承）进行简化。**            MyData* data_ptr = static_cast&lt;MyData*&gt;(current);            data_ptr-&gt;print(); // 访问并打印实际数据            current = current-&gt;next_; // 移动到下一个节点        }    }};\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"OOP","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/OOP/","content":"类和实例基础\r\nPython\r\n允许在运行时动态地为某个实例添加、修改或删除属性。\r\nclass Dog:    def __init__(self, name):        self.name = namedog1 = Dog(\"Buddy\")print(dog1.name)  # 输出: Buddy# 动态添加属性dog1.age = 3print(dog1.age)   # 输出: 3# 动态修改属性dog1.name = \"Max\"print(dog1.name)  # 输出: Max# 动态删除属性del dog1.ageprint(hasattr(dog1, 'age'))  # 输出: False\r\n在Python中，实例的变量名如果以**__开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问\r\nclass Cat:    def __init__(self, name):        self.__name = name  # 私有变量    def get_name(self):        return self.__name  # 通过方法访问私有变量cat1 = Cat(\"Whiskers\")print(cat1.get_name())  # 输出: Whiskersprint(cat1.__name)  # 报错: AttributeError: 'Cat' object has no attribute '__name' &gt; 注意：Python\r\n并没有真正的私有变量机制，这只是通过名称重整**（name\r\nmangling）来实现的。实际上，私有变量可以通过\r\n_ClassName__varname\r\n的方式访问，但这不推荐这样做，因为它违反了封装的原则。例如上面的例子中，其实可以通过\r\ncat1._Cat__name 来访问私有变量 __name。\r\n实例属性和类属性\r\n正如我们前面所说,\r\n由于Python是动态语言，根据类创建的实例可以任意绑定属性。给实例绑定属性的方法是通过实例变量动态绑定，或者通过self变量(在__init__函数中)：\r\nclass Dog:    def __init__(self, name, age):        self.name = name  # 实例属性        self.age = age    # 实例属性dog1 = Dog(\"Buddy\", 3)dog1.breed = \"Golden Retriever\"  # 动态绑定属性\r\n在Python中，实例属性是属于某个具体实例的属性，而类属性是属于类本身的属性，所有实例共享同一个类属性。\r\nclass Dog:    species = \"Canis familiaris\"  # 类属性    def __init__(self, name, age):        self.name = name  # 实例属性        self.age = age    # 实例属性dog1 = Dog(\"Buddy\", 3)dog2 = Dog(\"Max\", 5)print(dog1.name)  # 输出: Buddyprint(dog2.name)  # 输出: Maxprint(dog1.species)  # 输出: Canis familiarisprint(dog2.species)  # 输出: Canis familiarisprint(Dog.species)   # 输出: Canis familiaris\r\n如果你在实例中创建了和类属性同名的属性，那么实例属性会覆盖类属性.\r\n因此, 在编写程序的时候，千万不要对实例属性和类属性使用相同的名字.\r\ndog1.species = \"Canis lupus\"print(dog1.species)  # 输出: Canis lupusprint(dog2.species)  # 输出: Canis familiaris\r\n获取对象信息\r\nPython 提供了内置函数 type()\r\n来获取对象的类型，isinstance()\r\n来检查对象是否是某个类的实例(其实也是检查类型)，dir()\r\n来列出对象的所有属性和方法。\r\nclass Animal:    def speak(self):        return \"Animal sound\"class Dog(Animal):    def speak(self):        return \"Woof!\"dog1 = Dog()print(type(dog1))  # 输出: &lt;class '__main__.Dog'&gt;print(isinstance(dog1, Dog))  # 输出: Trueprint(isinstance(dog1, Animal))  # 输出: Trueprint(dir(dog1))  # 输出: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'speak']\r\n注意这里的 dir()\r\n函数返回的是一个列表，包含了对象的所有属性和方法，包括内置的和自定义的,\r\n其中 __ 开头和结尾的方法是 Python\r\n的魔法方法，用于实现特定的行为, 而没有 __\r\n的是普通方法, 例如speak() 方法。\r\n比如__len__方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法，所以，下面的代码是等价的：\r\nclass MyList:    def __init__(self, items):        self.items = items    def __len__(self):        return len(self.items)my_list = MyList([1, 2, 3, 4, 5])print(len(my_list))  # 输出: 5print(my_list.__len__())  # 输出: 5\r\n仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态：\r\n- getattr(obj, 'attr')：获取对象 obj 的属性\r\nattr 的值。 -\r\nsetattr(obj, 'attr', value)：设置对象 obj\r\n的属性 attr 的值为 value。 -\r\nhasattr(obj, 'attr')：检查对象 obj 是否有属性\r\nattr，返回布尔值。 class Person:    def __init__(self, name):        self.name = nameperson1 = Person(\"Alice\")print(getattr(person1, 'name'))  # 输出: Alicesetattr(person1, 'age', 30)print(getattr(person1, 'age'))  # 输出: 30print(hasattr(person1, 'name'))  # 输出: Trueprint(hasattr(person1, 'address'))  # 输出: False\r\n鸭子类型\r\n在Python中，鸭子类型（Duck\r\nTyping）是一种动态类型系统的概念，它强调的是对象的行为（方法和属性）而不是对象的实际类型。\r\n换句话说，如果一个对象看起来像鸭子、叫起来像鸭子，那么它就可以被当作鸭子来对待。也就是说，只要一个对象实现了某个方法或属性，就可以被视为具有该行为，而不需要显式地继承某个类或实现某个接口。\r\nclass Duck:    def quack(self):        return \"Quack!\"class Dog:    def quack(self):        return \"Woof!\"def make_it_quack(animal):    print(animal.quack())duck = Duck()dog = Dog()make_it_quack(duck)  # 输出: Quack!make_it_quack(dog)   # 输出: Woof!\r\n这里的 make_it_quack\r\n函数接受任何对象，只要该对象有 quack\r\n方法，就可以调用它，而不关心该对象的实际类型, 这就是鸭子类型的体现。\r\n多继承和MixIn\r\n与C++一样，Python也支持多继承，但它通过一种非常明确且可预测的方式——MRO（方法解析顺序）——解决了多继承中的二义性问题，尤其是菱形继承问题。\r\nPython的多继承\r\n在Python中，一个类可以同时从多个父类继承，从而获得所有父类的属性和方法。\r\nclass Bird:    def fly(self):        print(\"I am flying!\")class Mammal:    def walk(self):        print(\"I am walking!\")# Bat 同时继承 Bird 和 Mammalclass Bat(Bird, Mammal):    pass# 创建实例b = Bat()b.fly()  # 输出: I am flying! (继承自 Bird)b.walk() # 输出: I am walking! (继承自 Mammal)\r\n而当遇到菱形继承时，Python并不会像C++那样需要开发者使用virtual关键字来解决。相反，Python使用\r\nC3线性化算法\r\n来计算出一个确定的方法解析顺序（Method Resolution\r\nOrder, MRO）。\r\nMRO是一个列表，它定义了当调用一个方法时，Python解释器查找该方法的顺序。你可以通过类的\r\nmro 属性或 mro() 方法来查看它。 class A:    def who_am_i(self):        print(\"I am an A\")class B(A):    def who_am_i(self):        print(\"I am a B\")class C(A):    def who_am_i(self):        print(\"I am a C\")class D(B, C):    passd = D()d.who_am_i() # 输出会是什么？\r\n在这个例子中，D的对象调用 who_am_i()\r\n时，Python会遵循MRO来查找。我们可以打印出D类的MRO来理解其查找顺序。\r\nprint(D.mro())# 或者 print(D.__mro__)# 输出: [&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;] 这里MRO列表的顺序是 [D, B, C, A, object]。当调用\r\nd.who_am_i() 时，Python首先在 D 类中查找。D 中没有定义，于是继续。接着在\r\nB 类中查找。B 中定义了该方法，于是调用 B.who_am_i()。因此，最终输出是 I\r\nam a B。查找在找到第一个匹配项后就停止了，不会再继续查找 C 或 A。\r\nMRO保证了无论继承结构多复杂，方法的查找路径都是唯一且确定的，从而优雅地解决了二义性问题。\r\nMixIn 设计模式\r\n虽然多继承很强大，但如果滥用，会使类的层次结构变得混乱且难以维护。为了以一种更可控、更清晰的方式利用多继承，Python社区广泛采用\r\nMixIn 设计模式。\r\nMixIn (或 Mix-in)\r\n是一个类，它包含了一组特定的、可重用的功能，旨在通过多继承的方式“混入”到其他类中，为这些类添加某些功能，而不是为了建立\r\n“is-a” (是一个) 的父子关系。我们可以把MixIn看作是一个功能插件。\r\nMixIn类通常有以下特点：\r\n\r\n功能单一、职责明确：一个MixIn类通常只提供一种特定的功能，例如日志记录、序列化、对象表示等。\r\n不用于实例化：MixIn类通常不应该被直接实例化。它存在的意义就是被其他类继承。\r\n通常无 init\r\n构造函数：为了避免与主类的构造函数发生冲突，MixIn通常**不定义自己的__init__方法**。如果需要初始化，也应确保它能与super()链良好协作。\r\n命名约定：为了清晰起见，MixIn类的命名通常以后缀 Mixin\r\n结尾，例如 LoggingMixin、JSONMixin。\r\n\r\n假设我们有几个不同的类，我们都希望它们能方便地将自身属性转换为字典或JSON格式。我们可以为此创建一个\r\nSerializationMixin。\r\nimport json# 1. 定义一个 MixIn 类class SerializationMixin:    \"\"\"一个将对象属性序列化为字典和JSON的MixIn。\"\"\"    def to_dict(self):        # vars(self) 返回对象 __dict__ 属性，即其所有实例变量        return vars(self)    def to_json(self):        return json.dumps(self.to_dict(), indent=2)# 2. 定义一些业务类class Book:    def __init__(self, title, author):        self.title = title        self.author = authorclass Course:    def __init__(self, name, teacher, duration):        self.name = name        self.teacher = teacher        self.duration = duration# 3. 将 MixIn “混入”到业务类中class SerializableBook(SerializationMixin, Book):    passclass SerializableCourse(SerializationMixin, Course):    pass# 4. 使用“混入”的功能book = SerializableBook(\"The Lord of the Rings\", \"J.R.R. Tolkien\")course = SerializableCourse(\"Computer Networking\", \"Dr. Smith\", \"16 weeks\")print(\"--- Book Object ---\")print(book.to_dict())print(book.to_json())print(\"\\n--- Course Object ---\")print(course.to_dict())print(course.to_json())\r\n这里 SerializationMixin 提供了 to_dict() 和 to_json()\r\n两个方法。它本身不关心操作的是什么对象，只负责通用的序列化逻辑。\r\nSerializableBook 通过继承 SerializationMixin 和\r\nBook，既拥有了Book的属性和逻辑，又“免费获得”了序列化的能力。\r\n\r\n注意继承顺序很重要：我们将 SerializationMixin\r\n放在前面。根据MRO，如果Book中也有一个to_dict方法，那么SerializationMixin中的版本会优先被调用。\r\n\r\n","categories":["python"],"tags":["language","python"]},{"title":"函数","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%87%BD%E6%95%B0/","content":"函数的参数(Parameters)\r\n在 Python\r\n中，函数的参数可以分为以下几种类型：必选参数、默认参数、可变参数\r\n(*args)、命名关键字参数和关键字参数 (**kwargs)。并且在定义函数时,\r\n必须按照这样的顺序来排列参数. def complex_function(pos1, pos2, default_arg='default', *args, kw_only1, kw_only2='default', **kwargs):    # 函数体    pass\r\n必选参数 (Positional\r\nor Required Arguments)\r\n这是最基本的参数类型。在调用函数时，必须为这些参数传递值，并且传递的顺序要与函数定义中的顺序一致(或者也可以指定名称传递,\r\n这样就不需要按顺序来)。因为它们没有默认值，所以是“必选的”。\r\ndef describe_person(name, age):    \"\"\"显示一个人的姓名和年龄。\"\"\"    print(f\"Name: {name}, Age: {age}\")  # f-string 格式化字符串# 正确调用describe_person(\"Alice\", 30)describe_person(age=30, name=\"Alice\")  # 使用关键字参数, 不需要按顺序# 错误调用 - 缺少参数# describe_person(\"Alice\")  # TypeError: describe_person() missing 1 required positional argument: 'age'\r\n默认参数 (Default Arguments)\r\n在定义函数时，可以为一个或多个参数提供默认值。如果在调用函数时没有为这些参数提供值，Python\r\n将使用预设的默认值(可选提供，若不提供则使用默认值)\r\n定义时在参数名后使用 = 赋值, 并且要注意:\r\n默认参数必须定义在所有必选参数之后。 def send_greeting(name, message=\"Hello\"):    \"\"\"发送问候语。\"\"\"    print(f\"{message}, {name}!\")# 使用默认参数send_greeting(\"Bob\")  # 输出: Hello, Bob!# 覆盖默认参数send_greeting(\"Charlie\", \"Good morning\")  # 输出: Good morning, Charlie!\r\n默认参数必须指向不变对象\r\n一个常见的错误是使用可变对象（如列表或字典）作为默认参数。这会导致意想不到的行为，因为默认参数在函数定义时只被计算一次，而不是每次调用函数时都重新计算。\r\n默认参数的值在函数定义时就被计算和存储了。如果默认参数是一个可变对象（如列表或字典），并且在函数调用中被修改，那么这个修改会影响到后续的函数调用。\r\ndef append_to_list(value, my_list=[]):    \"\"\"将值添加到列表中。\"\"\"    my_list.append(value)    return my_listprint(append_to_list(1))  # 输出: [1]print(append_to_list(2))  # 输出: [1, 2] -- 这里的 my_list 不是一个新的列表，而是上次调用时的列表\r\n正确的做法是使用 None\r\n作为默认值，然后在函数体内创建一个新的列表：\r\ndef append_to_list(value, my_list=None):    \"\"\"将值添加到列表中。\"\"\"    if my_list is None:        my_list = []    my_list.append(value)    return my_listprint(append_to_list(1))  # 输出: [1]print(append_to_list(2))  # 输出: [2] -- 每次调用 都是一个新的列表\r\n为什么要设计str、None这样的不变对象呢？因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。\r\n可变参数 (*args)\r\n当你希望函数能够处理任意数量的位置参数时，可以使用可变参数。Python\r\n会将所有传入的多余位置参数收集到一个元组 (tuple)\r\n中。\r\n实现方法是, 在参数名前加一个星号 *。按照惯例，我们通常将其命名为\r\nargs, 用于接收任意多个位置参数。\r\ndef calculate_sum(*numbers):    \"\"\"计算所有输入数字的和。\"\"\"    total = 0    print(f\"Received numbers: {numbers}\") # numbers 是一个元组    for number in numbers:        total += number    return totalprint(calculate_sum(1, 2, 3))         # 输出: Received numbers: (1, 2, 3) -&gt; 6print(calculate_sum(10, 20, 30, 40))  # 输出: Received numbers: (10, 20, 30, 40) -&gt; 100\r\n如果已经有一个列表或元组, 想把它当作可变参数传入函数, 可以使用 *\r\n号来解包: nums = [1, 2, 3, 4]print(calculate_sum(*nums))  # 输出: Received numbers: (1, 2, 3, 4) -&gt; 10\r\n关键字参数 (**kwargs)\r\n当你希望函数能处理任意数量的关键字参数时，可以使用这种类型。Python\r\n会将这些参数收集到一个字典 (dict) 中。\r\n\r\n可变参数处理的是位置参数，而关键字参数处理的是命名参数, 也就是说,\r\n可变参数只能接收没有名称的参数, 而关键字参数接收的是有名称的参数.\r\n\r\n实现方式是在参数名前加两个星号 。按照惯例，我们通常将其命名为\r\nkwargs**。\r\ndef create_user_profile(**user_info):    \"\"\"创建一个用户信息的字典。\"\"\"    print(f\"Received info: {user_info}\") # user_info 是一个字典    for key, value in user_info.items():        print(f\"{key.title()}: {value}\")create_user_profile(name=\"Eve\", age=28, city=\"New York\")  # 需要输入 key=value 形式的参数# 输出:# Received info: {'name': 'Eve', 'age': 28, 'city': 'New York'}# Name: Eve# Age: 28# City: New York\r\n同样, 如果已经有一个字典, 想把它当作关键字参数传入函数, 可以使用 **\r\n号来解包: user_data = {'name': 'Frank', 'age': 35, 'city': 'Los Angeles'}create_user_profile(**user_data)# 输出:# Received info: {'name': 'Frank', 'age': 35, 'city': 'Los Angeles'}# Name: Frank   # Age: 35# City: Los Angeles\r\n注意user_info获得的dict是user_data的一份拷贝，对user_info的改动不会影响到函数外的user_data。\r\n命名关键字参数\r\n(Named-Keyword Arguments)\r\n对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。有时候，我们希望函数能够接受一些特定的关键字参数，而不是任意的关键字参数。这时，可以使用命名关键字参数。\r\n这种参数用于强制调用者必须使用制定关键字的形式来传递参数值，而不是通过位置。这可以提高代码的可读性，明确参数的意图。\r\n也就是说, 必须以 key=value 的形式提供，不能通过位置传递。 -\r\n如果前面有 args，则直接在 args 后面定义。 - 如果没有\r\nargs，则需要一个单独的星号  作为分隔符。\r\ndef process_data(initial_value, *data, status, is_valid):    \"\"\"处理数据，status 和 is_valid 必须用关键字指定。\"\"\"    print(f\"Initial Value: {initial_value}\")    print(f\"Data tuple: {data}\")    print(f\"Status: {status}\")    print(f\"Is Valid: {is_valid}\")# 正确调用process_data(100, 1, 2, 3, status=\"active\", is_valid=True)# 错误调用 - 未使用关键字# process_data(100, 1, 2, 3, \"active\", True) # TypeError: process_data() takes 1 positional argument but 4 were given\r\ndef set_config(*, theme, font_size, show_toolbar):    \"\"\"配置设置，所有参数必须用关键字指定。\"\"\"    print(f\"Theme: {theme}\")    print(f\"Font Size: {font_size}\")    print(f\"Show Toolbar: {show_toolbar}\")# 正确调用set_config(theme=\"dark\", font_size=14, show_toolbar=False)# 错误调用 - 尝试使用位置参数# set_config(\"dark\", 14, False) # TypeError: set_config() takes 0 positional arguments but 3 were given\r\n类型注解 (Type Annotations)\r\nPython\r\n允许在函数定义中使用类型注解来指定参数和返回值的预期类型。这有助于提高代码的可读性，并且可以被静态类型检查工具（如\r\nmypy）使用来检测类型错误。\r\n使用类型注解的语法是在参数名后使用冒号\r\n:，然后跟上类型名称(如果参数有默认值,\r\n则默认值放在类型名称后面, 用=连接):\r\n对于返回值，可以在参数列表后使用箭头 -&gt;\r\n来指定返回类型。\r\ndef greet(name: str, age: int = 20) -&gt; str:    \"\"\"返回一个问候语字符串。\"\"\"    return f\"Hello, {name}. You are {age} years old.\"print(greet(\"Alice\", 30))  # 输出: Hello, Alice. You are 30 years old.\r\n类型注解并不会影响函数的运行时行为，它们只是提供了额外的信息，帮助开发者理解代码的意图。\r\n同时, 类型注解也可以用于变量声明: age: int = 25self.records: List[Dict[str, Any]] = [] # 表示 records 是一个包含字典的列表\r\n高阶函数 (Higher-order\r\nFunction)\r\n要理解高阶函数，首先必须接受 Python\r\n中的一个核心设计哲学：函数是“一等公民” (First-class Citizen)。\r\n\r\n所谓“一等公民”，是指在 Python\r\n中，函数可以像其他数据类型（如整数、字符串、列表等）一样被赋值给变量、作为参数传递给其他函数、作为函数的返回值返回。\r\n\r\n一个函数如果满足以下两个条件中的至少一个，它就是高阶函数：\r\n\r\n接受一个或多个函数作为参数。\r\n将函数作为返回值。\r\n\r\n简单来说：一个操作其他函数的函数，就是高阶函数。\r\n接受函数作为参数\r\n这是高阶函数最常见的形式。它允许我们将行为“注入”到一个函数中，使这个函数变得更加灵活和通用。\r\n# 这是一个普通的函数def say_hello(name):    return f\"Hello, {name}\"def say_goodbye(name):    return f\"Goodbye, {name}\"# 这就是一个高阶函数，因为它接受一个函数(fn)作为参数def be_polite(fn):    # 在内部，它调用了传入的函数 fn    greeting = fn(\"John\")    # 并在其基础上增加了一些行为    return greeting + \", have a nice day!\"# --- 使用高阶函数 ---# 1. 把 say_hello 函数作为“值”传入 be_politepolite_hello = be_polite(say_hello)print(polite_hello)  # 输出: Hello, John, have a nice day!# 2. 把 say_goodbye 函数作为“值”传入 be_politepolite_goodbye = be_polite(say_goodbye)print(polite_goodbye) # 输出: Goodbye, John, have a nice day!\r\n同时, Python 提供了很多非常有用的内置高阶函数，最典型的就是 map(),\r\nfilter() 和 sorted()。\r\n\r\nmap(function, iterable): 对 iterable 中的每个元素执行 function\r\n操作, 并把结果作为新的 Iterator 返回。 def f(x):     return x * xr = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])list(r)   # 输出: [1, 4, 9, 16, 25, 36, 49, 64, 81]\r\n这里 map()\r\n返回的不是一个“现成的列表”，而是一个惰性计算的迭代器\r\n(Iterator), 也就是说结果不会一次性全部算出来，而是按需计算. 当你对 r\r\n进行迭代（比如 for x in r: 或 list(r)）时，它才会逐个调用\r\nf(x)，生成结果。\r\nfilter(function, iterable): 使用 function 过滤\r\niterable 中的元素，只保留使 function 返回 True 的元素。\r\ndef is_odd(n):    return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15]\r\nsorted(iterable, key=function): sorted 的 key\r\n参数就是一个函数，它定义了排序的规则。\r\nsorted([36, 5, -12, 9, -21], key=abs)# 输出: [5, 9, -12, -21, 36]\r\n\r\n将函数作为返回值\r\n高阶函数也可以动态地“创建”并返回一个新的函数。这通常与闭包 (Closure)\r\n的概念紧密相关。\r\n假设我们想创建一些功能专一的函数，比如“乘以2的函数”、“乘以3的函数”等\r\n# 这就是一个高阶函数，因为它返回一个函数def create_multiplier(n):    # 这个内部函数 \"multiplier\" 就是将要被返回的    def multiplier(x):        return x * n  # 注意：这里引用了外部函数的变量 n        return multiplier # 返回的是函数本身，不是调用的结果# --- 使用高阶函数 ---# 调用 create_multiplier(2) 并不执行乘法，而是创建了一个新的函数# 这个新函数“记住”了 n=2double = create_multiplier(2) # 调用 create_multiplier(3) 创建了另一个新函数# 这个新函数“记住”了 n=3triple = create_multiplier(3)# 现在我们可以使用这些新创建的函数了print(f\"double(10) is {double(10)}\") # 输出: double(10) is 20print(f\"triple(10) is {triple(10)}\") # 输出: triple(10) is 30print(f\"double(5) is {double(5)}\")   # 输出: double(5) is 10 在这个例子中，create_multiplier\r\n是一个“函数工厂”。你给它一个参数\r\nn，它就为你生产出一个“乘以n”的定制函数。返回的函数 multiplier\r\n捕获并持有了外部环境中的变量 n，这就是一个闭包。\r\n装饰器 (Decorators)\r\n理解了高阶函数后，你就能理解 Python 中最强大的特性之一, 装饰器。\r\n装饰器本质上就是一个高阶函数，它接受一个函数作为参数，并返回一个被“装饰”过的、功能更强的新函数。\r\nimport time# a_decorator 本质上就是一个高阶函数def a_decorator(func):    def wrapper(*args, **kwargs):        print(f\"Calling function '{func.__name__}'...\")        start_time = time.time()                result = func(*args, **kwargs) # 调用原始函数                end_time = time.time()        print(f\"Function '{func.__name__}' took {end_time - start_time:.4f} seconds.\")        return result    return wrapper# @a_decorator 是 Python 的语法糖# 它等价于: slow_function = a_decorator(slow_function)@a_decoratordef slow_function():    time.sleep(1)    print(\"Function finished.\")slow_function()\r\n","categories":["python"],"tags":["language","python"]},{"title":"可迭代对象和迭代器","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1/","content":"可迭代对象 (Iterable)\r\n是指那些能够逐一返回其内部成员的对象(返回迭代器)。换句话说，任何你可以用\r\nfor 循环进行遍历的对象，都是可迭代对象。\r\n常见的可迭代对象\r\n常见的可迭代对象包括：\r\n\r\n序列 (Sequence)：如列表 (list)、元组 (tuple)、字符串 (str)。\r\n集合 (Set)：如 set、frozenset。\r\n映射 (Mapping)：如字典 (dict)。\r\n文件对象。\r\n通过 yield 关键字创建的生成器 (Generator)。\r\n\r\n# 列表是可迭代的my_list = [1, 2, 3]for item in my_list:    print(item)# 字符串是可迭代的my_string = \"hello\"for char in my_string:    print(char)# 字典是可迭代的（默认遍历键）my_dict = {'a': 1, 'b': 2}for key in my_dict:    print(key)# 如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。for value in my_dict.values():    print(value)for k, v in my_dict.items():    print(k, v)\r\n如何判断一个对象是可迭代对象\r\n你可以使用 collections.abc.Iterable\r\n和isinstance来检查一个对象是否是可迭代的：\r\nfrom collections.abc import Iterableprint(isinstance([1, 2, 3], Iterable))  # True，列表是可迭代的print(isinstance(\"hello\", Iterable))    # True，字符串是可迭代的print(isinstance(42, Iterable))         # False，整数不是可迭代的\r\n迭代器协议 (Iterator\r\nProtocol)\r\n一个对象之所以“可迭代”，是因为它遵守了 Python\r\n的迭代器协议。这个协议规定了对象如何支持迭代。我们可以从两个角度来理解这个协议：\r\n\r\n可迭代对象 (Iterable)\r\n\r\n定义：一个对象如果实现了 iter()\r\n方法，那么它就是可迭代对象。\r\n作用：iter() 方法的职责是返回一个迭代器\r\n(Iterator) 对象。\r\nList、Tuple、String、Dict、Set 等内置类型都实现了\r\niter() 方法，因此它们都是可迭代对象。\r\n\r\n迭代器 (Iterator)\r\n\r\n定义：一个对象如果同时实现了 iter() 和\r\nnext() 方法，那么它就是迭代器。\r\niter() 的作用：对于迭代器本身，其\r\niter() 方法通常只是返回它自己 (self)。\r\nnext()\r\n的作用：这是迭代器的核心。每次调用该方法时，它会返回序列中的下一个元素。当所有元素都返回完毕后，再次调用\r\nnext() 会抛出 StopIteration\r\n异常，以告知外部调用者迭代已经结束。\r\nGenerator\r\n对象就是一种特殊的迭代器，它们是通过生成器函数创建的。\r\n\r\n\r\n需要注意的是,\r\nList、Tuple、String、Dict、Set等内置类型不是迭代器，因为它们没有实现\r\nnext() 方法,\r\n也就意味着他们不能通过next()逐个访问下一元素(因为他们本身就是有限的集合,\r\n没有必要逐个生成逐个next()访问).\r\n可以使用isinstance()判断一个对象是否是Iterator对象：\r\n&gt;&gt;&gt; from collections.abc import Iterator&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True&gt;&gt;&gt; isinstance([], Iterator)False&gt;&gt;&gt; isinstance({}, Iterator)False&gt;&gt;&gt; isinstance('abc', Iterator)False\r\nfor 循环的幕后工作原理\r\n当我们使用 for 循环时，Python 解释器在背后实际上执行了以下步骤：\r\n\r\n获取迭代器：调用可迭代对象的 iter()\r\n方法来获取一个迭代器。\r\n循环取值：在一个循环中，不断地调用迭代器的\r\nnext() 方法来获取下一个元素。\r\n处理异常：当 next() 方法抛出 StopIteration\r\n异常时，for 循环会捕获这个异常并优雅地结束循环。 my_list = [10, 20, 30]# 1. 获取迭代器#    这相当于调用了 my_list.__iter__()my_iterator = iter(my_list)# 2. 循环取值和处理异常while True:    try:        # 相当于调用了 my_iterator.__next__()        item = next(my_iterator)        print(item)    except StopIteration:        # 3. 迭代结束，跳出循环        break\r\n\r\n","categories":["python"],"tags":["language","python"]},{"title":"生成器","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E7%94%9F%E6%88%90%E5%99%A8/","content":"生成器是一种特殊的迭代器，它不需要你手动去实现迭代器协议（即\r\niter() 和 next()\r\n方法）。它允许你用一种更简单、更像普通函数的方式来生成一个值的序列。\r\n生成器的核心思想是 “懒加载” (Lazy Evaluation) 或\r\n“延迟计算”。它不会一次性在内存中创建并存储所有元素，而是在你请求下一个元素时才实时生成它。\r\n为什么要使用生成器？\r\n生成器最主要的优点是内存效率极高。想象一下，你需要处理一个包含一百万个元素的序列。\r\n\r\n使用列表：会立即在内存中创建并存储这一百万个元素，占用大量内存。\r\n使用生成器：它只在你需要时才逐一生成元素。在任何时刻，内存中只有一个元素存在，极大地节约了内存资源。\r\n\r\n这使得生成器非常适合处理：\r\n\r\n大规模数据集：如大型日志文件、数据库查询结果等。\r\n无限序列：例如，生成一个永不停止的斐波那契数列。\r\n数据流处理：在数据处理管道中，数据可以像水流一样通过各个生成器节点，而无需将整个数据集加载到内存中。\r\n\r\n创建生成器\r\n主要有两种方式可以创建生成器：\r\n\r\n生成器函数 (Generator Functions)\r\n这是最常见的方式。一个普通的函数，只要包含了\r\nyield 关键字，它就变成了一个生成器函数。\r\n\r\nyield 关键字：这是生成器的魔法所在。yield 的作用类似于\r\nreturn，但它并不会终止函数。相反，它会“暂停”函数的执行，并将其当前状态（包括局部变量）保存下来，然后将\r\nyield 后面的值返回给调用者。当下次请求值时（例如通过\r\nnext() 或 for\r\n循环），函数会从上次暂停的地方继续执行。\r\ndef countdown(n):    print(\"开始倒计时！\")    while n &gt; 0:        yield n  # 暂停并返回 n 的值        n -= 1    print(\"倒计时结束！\")# 1. 调用生成器函数，返回一个生成器对象，此时函数内的代码还未执行c = countdown(3)print(type(c)) # &lt;class 'generator'&gt;# 2. 第一次调用 next()，函数开始执行，直到遇到第一个 yieldprint(next(c)) # 输出 \"开始倒计时！\" 和 3# 3. 第二次调用 next()，函数从上次暂停处继续执行print(next(c)) # 输出 2# 4. 第三次调用 next()print(next(c)) # 输出 1# 5. 第四次调用 next()，循环结束，函数执行完毕#    由于没有更多的 yield，函数会隐式地抛出 StopIteration 异常try:    next(c) # 输出 \"倒计时结束！\" 然后抛出异常except StopIteration:    print(\"生成器已耗尽。\")\r\n注意,\r\n调用generator函数会创建一个generator对象，多次调用generator函数会创建多个相互独立的generator。假如在上面的代码中这样做:\r\nprint(next(countdown(3))) # 每次调用都会创建一个新的生成器对象, 所以每次都是输出 3print(next(countdown(3))) # 每次调用都会创建一个新的生成器对象, 所以每次都是输出 3\r\n正确的写法是创建一个generator对象，然后不断对这一个generator对象调用next()或者使用for循环.\r\n\r\n生成器表达式 (Generator Expressions)\r\n生成器表达式是列表生成式的近亲，语法上非常相似，但它返回的是一个生成器对象，而不是一个列表。\r\n\r\n语法：将列表生成式的 [] 替换为 () 即可\r\n# 列表生成式my_list = [x * x for x in range(5)]print(my_list) # 输出: [0, 1, 4, 9, 16]# 生成器表达式my_generator = (x * x for x in range(5))print(my_generator) # 输出: &lt;generator object &lt;genexpr&gt; at 0x...&gt;# 像使用其他迭代器一样使用它for num in my_generator:    print(num, end=' ') # 输出: 0 1 4 9 16\r\n","categories":["python"],"tags":["language","python"]},{"title":"列表与元组","url":"/2025/09/29/lang/python/%E5%9F%BA%E6%9C%AC%E6%95%99%E7%A8%8B/%E5%88%97%E8%A1%A8/","content":"列表 (List)\r\n列表是一个有序的、可变的集合，可以包含任意类型的对象，例如数字、字符串、甚至其他列表。\r\n列表使用方括号 [] 来定义，元素之间用逗号分隔。\r\n\r\n有序性\r\n(Ordered)：列表中的元素按照它们被添加的顺序进行存储。每个元素都有一个唯一的索引（位置编号），从\r\n0 开始。\r\n可变性\r\n(Mutable)：你可以在列表创建后，随时添加、删除或修改其中的元素。\r\n异构性\r\n(Heterogeneous)：列表中可以包含不同数据类型的元素，比如整数、字符串和另一个列表同时存在。\r\n动态性\r\n(Dynamic)：列表的长度是动态变化的，可以根据需要增长或缩减。\r\n\r\n创建列表\r\n直接使用方括号 []: # 创建一个空列表empty_list = []# 创建一个包含整数的列表numbers = [1, 2, 3, 4, 5]# 创建一个包含字符串的列表fruits = [\"apple\", \"banana\", \"cherry\"]# 创建一个混合类型的列表mixed_list = [1, \"hello\", 3.14, True, [\"a\", \"b\"]]print(numbers)      # 输出: [1, 2, 3, 4, 5]print(mixed_list)   # 输出: [1, 'hello', 3.14, True, ['a', 'b']] 也可以使用 list()\r\n函数从其他可迭代对象（如字符串、元组或范围）创建列表：\r\n# 从字符串创建列表char_list = list(\"Python\")print(char_list)    # 输出: ['P', 'y', 't', 'h', 'o', 'n']# 从元组创建列表tuple_example = (10, 20, 30)tuple_to_list = list(tuple_example)print(tuple_to_list) # 输出: [10, 20, 30]\r\n访问列表元素（索引）\r\n可以通过索引来访问列表中的单个元素, 正向索引从 0 开始, 反向索引从 -1\r\n开始。 fruits = [\"apple\", \"banana\", \"cherry\", \"date\"]# 正向索引 (从 0 开始)print(fruits[0])  # 输出: 'apple'print(fruits[2])  # 输出: 'cherry'print(fruits[4])  # 报错: IndexError: list index out of range (索引超出范围)# 反向索引 (从 -1 开始)print(fruits[-1]) # 输出: 'date' (最后一个元素)print(fruits[-2]) # 输出: 'cherry' (倒数第二个元素)print(fruits[-5]) # 报错: IndexError: list index out of range (索引超出范围)\r\n列表切片 (Slicing)\r\n切片允许你提取列表的一个子集，通过指定起始和结束索引来实现。切片的语法是\r\nlist[start:end:step]，左闭右开, 其中： -\r\nstart：切片的起始索引（包含该索引对应的元素）,\r\n如果省略，默认为 0。 -\r\nend：切片的结束索引（不包含该索引对应的元素）,\r\n如果省略，默认为列表末尾, 包含末尾元素。 -\r\nstep：步长，表示每隔多少个元素取一个，默认为 1; 如果是负数,\r\n则表示逆序取元素。\r\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]# 获取索引 2 到 4 的元素 (索引 5 不包含)print(numbers[2:5])   # 输出: [2, 3, 4]# 获取从开头到索引 3 的元素print(numbers[:4])    # 输出: [0, 1, 2, 3]# 获取从索引 5 到末尾的元素print(numbers[5:])    # 输出: [5, 6, 7, 8, 9]# 获取整个列表的副本print(numbers[:])     # 输出: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]# 每隔一个元素取一个print(numbers[::2])   # 输出: [0, 2, 4, 6, 8]# 倒着取元素print(numbers[-2:-1:]) # 输出: [8]  # 注意: -1 是结束索引, 不包含print(numbers[-1:-2:]) # 输出: []  # 步长为正，起始索引在结束索引之后，结果为空列表 print(numbers[-1:-2:-1]) # 输出: [9] # 步长为负，起始索引在结束索引之后，可以取到元素# 逆序列表print(numbers[::-1])  # 输出: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\r\n修改、添加和删除元素\r\n由于列表是可变的，我们可以很方便地操作其内容。\r\n修改元素: 直接通过索引赋值即可。\r\ncolors = [\"red\", \"green\", \"blue\"]colors[1] = \"yellow\"print(colors) # 输出: ['red', 'yellow', 'blue']\r\n添加元素: -\r\nappend()：在列表末尾添加一个元素,\r\n函数原型为 list.append(element)。 -\r\ninsert()：在指定索引位置插入一个元素,\r\n函数原型为 list.insert(index, element)。 -\r\nextend()：用另一个可迭代对象（如列表、元组、字符串等）扩展当前列表，将其中的所有元素添加到末尾。函数原型为\r\nlist.extend(iterable)，这里参数不是专门限定为列表，而是任何可迭代对象，因此更灵活。\r\ncolors.append(\"purple\")print(colors) # 输出: ['red', 'yellow', 'blue', 'purple']colors.insert(1, \"orange\") # 在索引 1 处插入 'orange'print(colors) # 输出: ['red', 'orange', 'yellow', 'blue', 'purple']more_colors = [\"cyan\", \"magenta\"]colors.extend(more_colors)print(colors) # 输出: ['red', 'orange', 'yellow', 'blue', 'purple', 'cyan', 'magenta']colors.extend(\"pink\") # 也可以传入字符串, 会把每个字符作为单独元素添加colors.extend((1, 2, 3)) # 也可以传入元组\r\n删除元素: - del\r\n语句：根据索引删除元素, 语法为\r\ndel list[index], 注意 del 不是列表的方法, 而是 Python\r\n的一个关键字。 - remove()\r\n方法：根据值删除第一个匹配的元素,\r\n语法为 list.remove(value)。 - pop()\r\n方法：删除并返回指定索引的元素,\r\n可以用一个变量接受返回值. 如果不指定索引, 默认删除并返回最后一个元素,\r\n语法为 list.pop([index])。\r\ndel colors[1] # 删除索引为 1 的 'orange'print(colors) # 输出: ['red', 'yellow', 'blue', 'purple', 'cyan', 'magenta', 'p', 'i', 'n', 'k', 1, 2, 3]colors.remove(\"yellow\") # 删除值 'yellow'print(colors) # 输出: ['red', 'blue', 'purple', 'cyan', 'magenta', 'p', 'i', 'n', 'k', 1, 2, 3]last_color = colors.pop() # 删除并返回 'magenta'print(f\"Removed color: {last_color}\")print(colors) # 输出: ['red', 'blue', 'purple', 'cyan', 'p', 'i', 'n', 'k', 1, 2]\r\n常用的列表方法\r\n除了上面提到的，列表还有许多非常有用的内置方法。\r\nsort()：对列表进行原地排序（会修改原列表）。\r\nsorted() 函数：返回一个排序后的新列表，不修改原列表。\r\nreverse()：将列表中的元素原地反转。\r\nlen() 函数：返回列表的长度（元素个数）。\r\ncount()：返回指定元素在列表中出现的次数。\r\nindex()：返回指定元素在列表中首次出现的索引。\r\ncopy()：返回列表的一个浅拷贝。\r\n列表推导式 (List\r\nComprehensions)/列表生成式\r\n列表生成式是一种优雅且高效的创建列表的方式。它允许你用一行代码代替多行的\r\nfor 循环，使代码更具可读性和 Pythonic 风格。\r\n它的基本结构如下： new_list = [expression for item in iterable if condition]\r\n我们可以将这个结构拆解成四个部分来理解： - expression\r\n(表达式)：基于 item 计算得出的新列表中的元素。 - for\r\nitem in iterable\r\n(循环)：遍历一个可迭代对象，将每个元素赋值给\r\nitem。这是必须的部分。 - if condition\r\n(条件判断)：一个可选的过滤器。只有当 condition 为 True\r\n时，expression 的结果才会被添加到新列表中, 不过不能加 else。 - []\r\n(方括号)：表示我们正在创建一个列表。\r\n为了更好地理解，我们来看几个从传统 for 循环演变到列表生成式的例子\r\n# 传统的 for 循环方式squares = []for x in range(10):    squares.append(x**2)print(squares)  # 输出: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]# 使用列表生成式squares = [x**2 for x in range(10)]print(squares)  # 输出: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\r\n还可以在表达式中使用条件判断(if …\r\nelse): # 注意：if-else 结构在表达式部分，而不是在末尾number_types = ['even' if x % 2 == 0 else 'odd' for x in range(10)]print(number_types)# 输出: ['even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd', 'even', 'odd'] 可见，在一个列表生成式中，for前面的if …\r\nelse是表达式，而for后面的if是过滤条件，不能带else。\r\n列表生成式的优点: -\r\n代码简洁：将多行代码浓缩为一行，减少了代码的冗余。 -\r\n可读性强：对于熟悉其语法的开发者来说，列表生成式能够更清晰地表达代码的意图。\r\n- 性能更高：列表生成式通常比等效的 for 循环和 append 操作要快。这是因为\r\nPython 解释器可以为其进行专门的优化，避免了在循环中重复调用 append\r\n方法的开销。\r\n\r\n除了列表生成式，Python\r\n还提供了类似的字典生成式和集合生成式，它们的语法结构非常相似：\r\n{key_expr: val_expr for item in iterable} (字典生成式) {expr for item in\r\niterable} (集合生成式)\r\n\r\n元组 (Tuple)\r\n元组是一个有序的、不可变的集合，可以包含任意类型的对象。元组使用圆括号\r\n() 来定义，元素之间用逗号分隔。\r\n","categories":["python"],"tags":["language","python"]},{"title":"上下文无关语言和下推自动机","url":"/2025/10/15/algorithms/Computing%20Theory/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E8%AF%AD%E8%A8%80%E5%92%8C%E4%B8%8B%E6%8E%A8%E8%87%AA%E5%8A%A8%E6%9C%BA/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E8%AF%AD%E8%A8%80%E5%92%8C%E4%B8%8B%E6%8E%A8%E8%87%AA%E5%8A%A8%E6%9C%BA/","content":"上下文无关语言\r\n(Context-Free Language, CFL)\r\n上下文无关语言是一类形式语言，它们可以由上下文无关文法\r\n(Context-Free Grammar, CFG)\r\n生成。上下文无关语言在计算理论和编译原理中具有重要地位，因为它们能够描述许多编程语言的语法结构。\r\n上下文无关文法\r\n(Context-Free Grammar, CFG)\r\n一个上下文无关文法 (CFG) 是一个四元组 G = (V, Σ, R, S)\r\n，其中： - V：是一个字母表（Alphabet），包含了所有的符号 。 - Σ\r\n(Sigma)：是终端符号（Terminal Symbols）的集合\r\n。终端符号就是构成语言中最终字符串的那些“基本”符号（例如\r\na, b, +, *）。它必须是 V 的一个子集（Σ ⊆ V） 。 -\r\nS：是起始符号（Start Symbol）\r\n。它是一个特殊的非终端符号，是所有推导的起点。 -\r\nR：是规则（Rules）的有限集合 。规则的形式是：A → u，其中 A\r\n必须是一个非终端符号（Nonterminal），而非终端符号的集合就是\r\nV − Σ - u\r\n是一个由终端符号和/或非终端符号组成的字符串（u ∈ V*） 。 -\r\nV − Σ：这个集合中的元素被称为非终端符号\r\n(nonterminals) 或变量\r\n(variables)。它们是推导过程中的“占位符”或“中间变量”。\r\n例如，对于语言 L = {anbn|n ≥ 0}，它的\r\nCFG 可以这样写： - V = {S, a, b}\r\n- Σ = {a, b}\r\n- S = S - R = {S → aSb, S → e}\r\n(这里的 e 代表空字符串 ϵ)\r\nCFG, 在某种程度上就类似正则表达式, 它们都是“生成设备” (generation\r\ndevices)。正则语言是由正则表达式生成的, 而上下文无关语言 (CFL)\r\n是由上下文无关文法 (CFG) 生成的。\r\n上下文无关语言 (CFL)\r\n上下文无关语言 (CFL) 是指可以由某个上下文无关文法 (CFG)\r\n生成的语言集合。换句话说，如果存在一个 CFG G，使得 L(G) = L，那么语言\r\nL 就是一个上下文无关语言。\r\n所有正则语言都是上下文无关语言 (CFL).\r\n\r\n这意味着 CFL\r\n是一个更庞大的语言集合，它完全包含了所有的正则语言。我们之前学的 anbn\r\n是一个 CFL，但不是正则语言；而像 a*b*\r\n这样的正则语言，既是正则语言，也是 CFL。\r\n\r\n证明 (通过直接构造)\r\n：我们可以证明这个定理，通过展示如何将任何一个确定性有限自动机 (DFA)\r\n转换成一个等价的 CFG。\r\n\r\n假设我们有一个 DFA M = (K, Σ, δ, s, F)\r\n28。\r\n我们可以构造一个 CFG G = (V, Σ, R, S)，使得\r\nL(G) = L(M)\r\n29。\r\n构造步骤：\r\n\r\n非终端符号 (V − Σ)：CFG\r\n的非终端符号就是 DFA 的所有状态 (K) 30。\r\n终端符号 (Σ)：两者共享相同的终端符号 31。\r\n起始符号 (S)：CFG\r\n的起始符号 S 就是 DFA\r\n的起始状态 s 32。\r\n规则 (R)：规则分为两类\r\n33：\r\n\r\n转移规则：对于 DFA 中的每一条转移 δ(q, a) = p（在状态\r\nq 读入 a 变为状态 p），我们都在 CFG\r\n中添加一条规则：q → ap 34。\r\n接受规则：对于 DFA 中的每一个接受状态 q ∈ F，我们都在 CFG\r\n中添加一条规则：q → e\r\n(空字符串) 35。\r\n\r\n\r\n构造的直观理解：CFG 的推导过程 S ⇒ a1q1 ⇒ a1a2q2 ⇒ … ⇒ a1…anqn ⇒ a1…ane。这完全模拟了\r\nDFA 的计算路径 。q → ap 规则\r\n36意味着“DFA 消耗了 a\r\n并转移到了状态 p”；而 q → e 规则 37 意味着“DFA\r\n在状态 q 停机，并且 q 是一个合法的接受状态”。\r\n\r\n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"正则语言与有限自动机","url":"/2025/09/15/algorithms/Computing%20Theory/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%92%8C%E6%9C%89%E9%99%90%E8%87%AA%E5%8A%A8%E6%9C%BA/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%9C%89%E9%99%90%E8%87%AA%E5%8A%A8%E6%9C%BA/","content":"计算模型：有限自动机 (Finite\r\nAutomata)\r\n有限自动机（Finite Automata，简称 **FA** 或 FSM）是一种基础的计算模型。它拥有**有限数量的状态**，并且**没有额外的可读写存储**。自动机从初始状态出发，逐步读取输入字符串的每个符号，根据**当前状态**和**输入符号**通过**状态转移函数**切换到**下一个状态**。输入处理完毕后，若停在某个**接受状态**，则该字符串被自动机接受。它的主要任务是**判断**一个**给定的输入字符串** $w$ 是否属于**它所定义的语言** $L(M)$, 即 $w \\in L(M)$。 这里的$L(M)$ 也就是该自动机对应的**正则语言**。有限自动机分为两类：**确定性有限自动机** (DFA) 和**非确定性有限自动机** (NFA)。### 确定性有限自动机 (DFA)确定性有限自动机（DFA）在每一步计算中，当前状态和输入符号**唯一决定**下一个状态。**形式化定义：**  DFA 可表示为五元组 $M = (K, \\Sigma, \\delta, s, F)$，其中：- $K$：有限状态集合, $K = \\{q_0, q_1, \\ldots, q_{n-1}\\}$- $\\Sigma$：输入字母表, 一个有限符号集合, 如 $\\Sigma = \\{a, b\\}$ - $\\delta$：状态转移函数，$\\delta: K \\times \\Sigma \\to K$ , 定义了在状态 $q \\in K$ 下读取输入符号 $a \\in \\Sigma$ 时，自动机转移到的下一个状态 $\\delta(q, a)$- $s \\in K$：初始状态, $M$ 开始计算时所在的状态  - $F \\subseteq K$：接受状态集合, 如果计算结束时自动机停在 $F$ 中的某个状态，则输入字符串被接受。  ![alt text](image.png)需要注意的是, 假如已知 $M$ 接受 $L$ , 它的补集 $\\overline{L}$ 也可以被一个DFA接受, 只需将 $M$ 的接受状态和非接受状态互换即可。![alt text](image-1.png)#### 运算过程我们已经定义了机器的结构，现在来看它的运算过程。- **配置 (Configuration)：** DFA 的配置由**当前状态**和**尚未读取的输入字符串**组成，记为序对 $(q, w)$。- **一步产生关系 ($\\vdash_M$)：** 若机器在状态 $q$，输入字符串为 $aw'$，且 $\\delta(q, a) = q'$，则 $(q, aw') \\vdash_M (q', w')$，表示机器从配置 $(q, aw')$ 一步转移到 $(q', w')$。- **多步产生关系 ($\\vdash_M^*$)：** 表示零步或多步的产生关系，是 $\\vdash_M$ 的**自反传递闭包**。例如，$(n, WSSW) \\vdash_M^* (n, \\epsilon)$ 表示从初始状态 $n$ 处理完整输入 $WSSW$ 后停在状态 $n$。- **字符串的接受：** 字符串 $w$ 被 $M$ 接受，当且仅当，从初始配置 $(s, w)$ 出发，经过若干步计算到达某个配置 $(q, \\epsilon)$，且 $q$ 属于接受状态集合 $F$。### 非确定性有限自动机 (NFA)非确定性有限自动机（NFA）允许在**某个状态**和**输入符号**下有**多个可能的下一个状态**，也可能**没有可选状态**（计算终止）。NFA 还支持 $\\varepsilon$-转移，即可以在**不消耗输入符号的情况下进行状态转换**。即 NFA 的三大特点：多重选择, 没有选择, 空串转移。**接受条件：**  一个字符串 $w$ 被 NFA 接受，当且仅当存在**至少一条合法的计算路径**，在消耗完 $w$ 后，自动机停在某个接受状态。![alt text](image-2.png)如上的正则表达式要识别 $L=(ab \\cup aba)^*$ , 可以选择DFA来实现, 但是显然状态数更多, 可读性更差. 而使用NFA可以更简洁地表示该语言.&gt; 在DFA中, 像 $q_4$ 这样的状态，虽然在识别正确的语言中没有使用到, 但是仍然具有非常重要的功能，它通常被称为死状态（Dead State）或陷阱状态（Trap State）。&gt; 当自动机进入死状态后，无论接收到什么输入符号，都会一直停留在该状态，无法再转移到其他状态。死状态的存在保证了 DFA 的确定性和完整性，并处理无效的输入序列。对于NFA, 其形式化定义与DFA类似, 但**状态转移函数**有所不同: DFA的状态转移函数 $\\delta$ 是一个确定性的映射，而 NFA 的状态转移函数 $\\delta$ 则是一个**非确定性的映射**(或者说是一种**关系**)，允许多个可能的下一个状态。NFA 可表示为五元组 $M = (K, \\Sigma, \\delta, s, F)$，其中：- $K$：有限状态集合, $K = \\{q_0, q_1, \\ldots, q_{n-1}\\}$- $\\Sigma$：输入字母表, 一个有限符号集合, 如 $\\Sigma = \\{a, b\\}$ - $\\delta$：状态转移函数，$\\delta: K \\times (\\Sigma \\ \\cup \\{\\varepsilon\\}) \\to P(K)$ , 定义了在状态 $q \\in K$ 下读取输入符号 $a \\in \\Sigma$ 或 $\\varepsilon$ 时，自动机可以转移到的**下一个状态集合** $\\delta(q, a) \\subseteq K$- $s \\in K$：初始状态, $M$ 开始计算时所在的状态  - $F \\subseteq K$：接受状态集合, 如果计算结束时自动机停在 $F$ 中的某个状态，则输入字符串被接受。至于其运算过程, 与DFA类似, 只是需要考虑多条路径的情况.![alt text](image-3.png)### DFA 与 NFA 的等价性DFA 和 NFA 在**描述语言的能力**上是完全等价的。也就是说，任何可以被 NFA 接受的语言，也可以被某个等价的 DFA 接受，反之亦然。且任意DFA都可以转换为等价的NFA, 反之亦然. 但NFA转换为DFA时, 可能会导致状态数指数级增长.首先, 任意DFA都可以看作是特殊的NFA, 因为DFA的每个状态和输入符号下只有一个确定的下一个状态, 这正是NFA的一种特例. 而证明NFA可以转换为DFA, 我们需要使用下面的子集构造法**证明核心：子集构造法 (Subset Construction)**首先, DFA和NFA有两个重要的区别:1. NFA允许多个可能的下一个状态，而DFA在每一步只有一个确定的下一个状态。也就是两者的形式化定义中, 状态转移函数 $\\delta$ 的不同:   - 对于DFA: $\\delta: K \\times \\Sigma \\to K$   - 对于NFA: $\\delta: K \\times (\\Sigma \\cup \\{\\varepsilon\\}) \\to P(K)$2. NFA允许$\\varepsilon$-转移，而DFA不允许。即:    - 对于DFA: 没有$\\varepsilon$-转移    - 对于NFA: 允许$\\varepsilon$-转移, 即 $\\delta(q, \\varepsilon)$ 可以非空下面我们的转换的核心就是处理这两个区别.我们不再追踪 NFA “可能”处于的单一状态，而是追踪它在任何时刻“可能处于的所有状态的集合”。具体来说，**子集构造法**的核心思想是：构造一台新的 DFA，使其每个状态都对应于原 NFA 的一个**状态集合**。&gt; 为了解决 NFA 中的 $\\varepsilon$-转移（即无需消耗输入即可转移），我们引入$\\varepsilon$-闭包（epsilon-closure），记作 $E(q)$。$E(q)$ 表示：从**状态 $q$ 出发**，**仅通过 $\\varepsilon$-转移**（不读取任何输入），能够到达的**所有状态的集合**（包括 $q$ 本身）。#### 子集构造法步骤假设有一台 NFA $M$，我们要构造一台等价的 DFA $M'$，其定义如下：- **状态集 $K'$**：$M'$ 的每个状态是 $M$ 的状态集的一个子集（即 $K'$ 是 $K$ 的幂集）。  - $K' = P(K) = 2^K$  - 从这里可以看出, 如果NFA有 $n$ 个状态, 则对应的DFA最多有 $2^n$ 个状态, 也就是复杂度的指数级增长. 不过很多状态是不可达的, 因此实际状态数通常远**小于 $2^n$**.- **初始状态 $s'$**：$M'$ 的初始状态是 $M$ 的初始状态 $s$ 的 $\\varepsilon$-闭包，即 $E(s)$。  - $s' = E(s)$- **字母表 $\\Sigma$**：与 NFA 相同。- **转移函数 $\\delta'$**：对于 $M'$ 的任意状态 $Q \\subseteq K$ 和输入符号 $a$，其转移定义为：$\\delta'(Q, a) = \\bigcup_{q \\in Q} E(\\delta(q, a))$  1. 对 **$Q$ 中每个状态 $q$**，计算 $q$ 读入 $a$ 后能到达的所有状态的集合 $S$。  2. 对 $S$ 中每个状态，取其 **$\\varepsilon$-闭包**。  3. 取所有这些 $\\varepsilon$-闭包的**并集**，作为 $M'$ 在 $Q$ 读入 $a$ 后的下一个状态。  - 一般来说, DFA 的状态集 $K'$ 是通过一种按需计算的方式构建的。从起始状态开始, 根据输入符号逐步计算和添加新的状态子集, 接着利用得到的状态子集继续计算, 直到不再有新的状态子集被发现为止。- **接受状态 $F'$**：$M'$ 的接受状态集合是**所有**包含 $M$ 至少一个接受状态的状态子集。  - $F' = \\{Q \\subseteq K \\mid Q \\cap F \\neq \\emptyset\\}$这种方法保证了 DFA 能“模拟”NFA 的所有可能路径，从而接受与原 NFA 相同的语言。#### 示例![alt text](image-4.png)![alt text](image-5.png)**第一步：NFA $M$ 定义整理与 $\\varepsilon$-闭包预计算**- 状态集 $K$：$\\{q_0, q_1, q_2, q_3, q_4\\}$- 字母表 $\\Sigma$：$\\{a, b\\}$- 起始状态 $s$：$q_0$- 接受状态 $F$：$\\{q_4\\}$- 转移关系 $\\Delta$：  - 非 $\\varepsilon$ 转移：    - $\\delta(q_0, b) = \\{q_2\\}$    - $\\delta(q_2, b) = \\{q_4\\}$    - $\\delta(q_1, a) = \\{q_0, q_4\\}$    - $\\delta(q_3, a) = \\{q_4\\}$  - $\\varepsilon$ 转移：    - $\\delta(q_0, \\varepsilon) = \\{q_1, q_2, q_3\\}$    - $\\delta(q_1, \\varepsilon) = \\{q_2, q_3\\}$    - $\\delta(q_4, \\varepsilon) = \\{q_3\\}$- $\\varepsilon$-闭包计算：  - $E(q_2) = \\{q_2\\}$  - $E(q_3) = \\{q_3\\}$  - $E(q_4) = \\{q_3, q_4\\}$  - $E(q_1) = \\{q_1, q_2, q_3\\}$  - $E(q_0) = \\{q_0, q_1, q_2, q_3\\}$**第二步：构造 DFA $M'$ 的状态和转移**我们从 DFA 的初始状态开始，采用按需计算的方式，逐步构建 DFA 的状态集和转移函数。DFA **初始状态** $s'$ = $A = E(q_0) = \\{q_0, q_1, q_2, q_3\\}$（非接受状态）接着从状态 $A$ 开始，计算它对每个输入符号的转移。- **处理状态 $A = \\{q_0, q_1, q_2, q_3\\}$**  - $\\delta'(A, a)$ 的计算：    - NFA 目标状态：$\\delta(q_1, a) \\cup \\delta(q_3, a) = \\{q_0, q_4\\} \\cup \\{q_4\\} = \\{q_0, q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_0) \\cup E(q_4) = \\{q_0, q_1, q_2, q_3\\} \\cup \\{q_3, q_4\\} = \\mathbf{\\{q_0, q_1, q_2, q_3, q_4\\}}$    - 得到新状态 $B = \\{q_0, q_1, q_2, q_3, q_4\\}$。$B$ 包含 $q_4$，因此是接受状态。  - $\\delta'(A, b)$ 的计算：    - NFA 目标状态：$\\delta(q_0, b) \\cup \\delta(q_2, b) = \\{q_2\\} \\cup \\{q_4\\} = \\{q_2, q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_2) \\cup E(q_4) = \\{q_2\\} \\cup \\{q_3, q_4\\} = \\mathbf{\\{q_2, q_3, q_4\\}}$    - 得到新状态 $C = \\{q_2, q_3, q_4\\}$。$C$ 包含 $q_4$，因此是接受状态。- **处理状态 $B = \\{q_0, q_1, q_2, q_3, q_4\\}$**  - $\\delta'(B, a)$ 的计算：    - NFA 目标状态：$\\delta(q_1, a) \\cup \\delta(q_3, a) = \\{q_0, q_4\\} \\cup \\{q_4\\} = \\{q_0, q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_0) \\cup E(q_4) = \\{q_0, q_1, q_2, q_3, q_4\\} = \\mathbf{B}$    - 转移到自身。  - $\\delta'(B, b)$ 的计算：    - NFA 目标状态：$\\delta(q_0, b) \\cup \\delta(q_2, b) = \\{q_2\\} \\cup \\{q_4\\} = \\{q_2, q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_2) \\cup E(q_4) = \\{q_2\\} \\cup \\{q_3, q_4\\} = \\mathbf{C}$    - 转移到状态 $C$。- **处理状态 $C = \\{q_2, q_3, q_4\\}$**  - $\\delta'(C, a)$ 的计算：    - NFA 目标状态：$\\delta(q_3, a) = \\{q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_4) = \\mathbf{\\{q_3, q_4\\}}$    - 得到新状态 $D = \\{q_3, q_4\\}$。$D$ 包含 $q_4$，因此是接受状态。  - $\\delta'(C, b)$ 的计算：    - NFA 目标状态：$\\delta(q_2, b) = \\{q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_4) = \\mathbf{\\{q_3, q_4\\}}$    - 转移到状态 $D$。- **处理状态 $D = \\{q_3, q_4\\}$**  - $\\delta'(D, a)$ 的计算：    - NFA 目标状态：$\\delta(q_3, a) = \\{q_4\\}$    - 取 $\\varepsilon$-闭包并集：$E(q_4) = \\mathbf{\\{q_3, q_4\\}} = \\mathbf{D}$    - 转移到自身。  - $\\delta'(D, b)$ 的计算：    - NFA 目标状态：$\\emptyset$    - 取 $\\varepsilon$-闭包并集：$\\mathbf{\\emptyset}$    - 得到新状态 $E = \\emptyset$（死状态）。$E$ 不包含 $q_4$，因此不是接受状态。- **处理状态 $E = \\emptyset$（死状态）**  - $\\delta'(E, a) = \\emptyset = \\mathbf{E}$  - $\\delta'(E, b) = \\emptyset = \\mathbf{E}$所有可达状态都已计算完毕。第三步：最终的 DFA $M'$状态集 - **状态集 $K'$**：    $\\{A, B, C, D, E\\}$    - $A = \\{q_0, q_1, q_2, q_3\\}$    - $B = \\{q_0, q_1, q_2, q_3, q_4\\}$    - $C = \\{q_2, q_3, q_4\\}$    - $D = \\{q_3, q_4\\}$    - $E = \\emptyset$- **初始状态 $s'$**：$A$- **接受状态 $F'$**：$\\{B, C, D\\}$, 因为含有 $q_4$。- **转移函数 $\\delta'$（表格形式）：**  | 状态 | $a$ | $b$ | 接受 |  |------|-----|-----|------|  | $A$  | $B$ | $C$ | 否   |  | $B$  | $B$ | $C$ | 是   |  | $C$  | $D$ | $D$ | 是   |  | $D$  | $D$ | $E$ | 是   |  | $E$  | $E$ | $E$ | 否   |这样，原 NFA 被转换为等价的 DFA，所有状态和转移均已明确。## 语言表示：正则表达式 (Regular Expressions)正则表达式是一种用于描述语言的代数工具。其核心思想是：从**最基本的语言**（如空语言 $\\emptyset$ 和单符号语言 $\\{a\\}$）出发，通过**三种基本运算**构造更复杂的语言。一个正则表达式 $\\alpha$ 及其表示的语言 $L(\\alpha)$ 递归定义如下：- 基础情况：  - $\\emptyset$ 是正则表达式，表示空语言 $L(\\emptyset) = \\emptyset$  - 对于字母表 $\\Sigma$ 中的每个符号 $a$，$a$ 是正则表达式，表示语言 $L(a) = \\{a\\}$- 归纳步骤：若 $\\alpha$ 和 $\\beta$ 都是正则表达式，则  - 连接 (Concatenation)：$(\\alpha\\beta)$ 是正则表达式，表示语言 $L((\\alpha\\beta)) = L(\\alpha)L(\\beta)$  - 并 (Union)：$(\\alpha \\cup \\beta)$ 是正则表达式，表示语言 $L((\\alpha \\cup \\beta)) = L(\\alpha) \\cup L(\\beta)$  - Kleene 星号 (Kleene Star)：$\\alpha^*$ 是正则表达式，表示语言 $L(\\alpha^*) = L(\\alpha)^*$，即 $L(\\alpha)$ 中 0 个或多个字符串的所有连接**正则语言**的定义：所有**能够用正则表达式描述的语言**称为正则语言。下面是一个定理: **一个语言是正则的，当且仅当它能被一台有穷自动机接受**。 这是一个“当且仅当”的命题，所以我们需要从两个方向来证明。- 方向一：如果一个语言是正则的，那么它一定能被一台有穷自动机接受。- 方向二：如果一个语言能被一台有穷自动机接受，那么它一定是正则的。### 从正则表达式到有穷自动机我们的任务是：给定任意一个正则表达式，我们都能构造出一台接受它所描述语言的有穷自动机（通常是NFA，因为更方便）。我们的策略是递归构造。回顾正则表达式的定义：  - **基础情况**：最简单的正则表达式是 $\\emptyset$（空语言）和单个符号 $a$。我们可以为每种情况分别构造一个非常简单的 NFA。  - 对于 $\\emptyset$，构造一个没有接受状态的自动机。  - 对于 $a$，构造一个只有两个状态的自动机，从初始状态读入 $a$ 转移到接受状态。- **递归步骤**：更复杂的正则表达式通过并 (Union)、连接 (Concatenation) 和 Kleene 星号 (Kleene Star) 运算组合而成。    - 如果 $L_1$ 和 $L_2$ 都能被自动机接受，则可以构造自动机分别接受 $L_1 \\cup L_2$、$L_1 L_2$ 和 $L_1^*$。    - 关键在于证明：有限自动机接受的语言在这三种运算下是**封闭的**。      - **并运算**：通过新建初始状态，使用 **$\\varepsilon$-转移**分别连接到两个自动机的初始状态。    - **连接运算**：将第一个自动机的所有**接受状态**通过 **$\\varepsilon$-转移**连接到第二个自动机的**初始状态**，并将第二个自动机的接受状态作为整体的接受状态。    - **Kleene 星号**：新建初始状态和接受状态，允许从接受状态通过 $\\varepsilon$-转移回到初始状态，同时允许直接接受空串。- 通过递归应用上述构造方法，可以为**任意正则表达式**构造出一个**等价的 NFA**，从而证明正则表达式描述的语言都能被有限自动机接受。### 从有穷自动机到正则表达式现在我们来证明更难的另一个方向：**给定任意一台有限自动机（FA），如何构造出一个等价的正则表达式？**#### **状态消除法**（State Elimination Method）我们采用一种叫做**状态消除法**（State Elimination Method）的动态规划思想。其核心步骤如下：1. 预处理：转换为广义有限自动机 (GFA)- 首先，将原始自动机改造为**广义有限自动机（GFA）**。GFA 与 NFA 类似，但**转移边上的标记可以是任意正则表达式**，而不仅仅是单个符号。改造标准如下：  - 只有一个唯一的接受状态。  - 没有转移进入初始状态，也没有转移从接受状态出去。- 通常通过增加新的初始状态和新的接受状态，并用 $\\varepsilon$-转移连接它们实现。2. 状态消除过程- 逐步消除 GFA 的中间状态。每消除一个状态 $q$，需要修复所有经过它的路径：  - 假设有一条从 $q_i$ 到 $q_j$ 的路径，标记为 $\\delta$。  - 还有一条从 $q_i$ 经过 $q$ 到 $q_j$ 的路径，$q_i \\to q$ 标记为 $\\alpha$，$q \\to q_j$ 标记为 $\\beta$，且 $q$ 上可能有自环，标记为 $\\gamma$。  - 消除 $q$ 后，新增一条直接路径，其正则表达式为 $\\alpha \\gamma^* \\beta$。  - 从 $q_i$ 到 $q_j$ 的新转移标记为原标记和新路径的并集，即 $\\delta \\cup \\alpha \\gamma^* \\beta$。- 重复此过程，直到只剩下初始状态和接受状态。3. 最终结果: 此时，从初始状态到接受状态的**唯一转移边上的**正则表达式，就是与原始自动机等价的正则表达式。![alt text](image-6.png)- **初始 GFA**：将原 FA 转换为广义有限自动机（GFA），添加新的起始状态 $q_4$ 和唯一接受状态 $q_5$，并用 $\\varepsilon$-转移连接。- **消除 $q_1$**：移除 $q_1$，将所有经过 $q_1$ 的路径合并。例如，从 $q_4$ 经过 $q_1$ 到 $q_3$ 的路径合并为一条标记为 $a^*b$ 的新边；从 $q_2$ 经过 $q_1$ 到 $q_3$ 的路径合并为 $ba^*b$。- **消除 $q_2$**：移除 $q_2$，将 $q_3$ 经过 $q_2$ 回到 $q_3$ 的路径与 $q_3$ 的自环合并，得到新的自环 $a \\cup ba^*ba^*b$。- **消除 $q_3$**：移除 $q_3$，将 $q_4$ 到 $q_3$ 的路径、$q_3$ 的自环、以及 $q_3$ 到 $q_5$ 的路径合并，得到从 $q_4$ 到 $q_5$ 的唯一路径。- **最终正则表达式**：所有中间状态消除后，GFA 只剩下起始和接受状态，两者之间的唯一转移边标记的正则表达式即为原 FA 的等价正则表达式：$\\boxed{a^*b(a \\cup ba^*ba^*b)^*}$。#### 数学归纳描述定义 $R(i, j, k)$ 表示：从状态 $q_i$ 到 $q_j$，且所有中间状态编号不超过 $k$ 的所有路径所对应的字符串集合。- 基础情况（Base Case, $k=0$）：$R(i, j, 0)$ 表示从 $q_i$ 到 $q_j$ 的路径，且**不经过任何中间状态**（编号 $&gt;0$）。这只可能是一步直接转移，因此 $R(i, j, 0)$ 就是所有能直接从 $q_i$ 到 $q_j$ 的符号的集合。如果 $i = j$，还包括空串 $\\varepsilon$。这个集合是有限的，可以用正则表达式（如 $a \\cup b \\cup c$）描述。- 归纳步骤（Inductive Step）：假设对于所有 $i, j$，$R(i, j, k-1)$ 都可以用正则表达式描述。递推公式如下：  $$  R(i, j, k) = R(i, j, k-1) \\cup R(i, k, k-1) \\left(R(k, k, k-1)\\right)^* R(k, j, k-1)  $$  - 公式解释：从 $q_i$ 到 $q_j$，中间状态编号不超过 $k$ 的所有路径分为两类：    1. **不经过 $q_k$ 的路径**：这些路径的中间状态编号都不超过 $k-1$，即 $R(i, j, k-1)$。    2. **经过 $q_k$ 的路径**：可以分解为三部分：      - 从 $q_i$ 到 $q_k$（中间状态不超过 $k-1$）：$R(i, k, k-1)$      - 在 $q_k$ 循环任意次（中间状态不超过 $k-1$）：$\\left(R(k, k, k-1)\\right)^*$      - 从 $q_k$ 到 $q_j$（中间状态不超过 $k-1$）：$R(k, j, k-1)$    由于正则表达式的三种运算（并、连接、星号）都是封闭的，且归纳假设 $R(\\cdot, \\cdot, k-1)$ 都是正则的，因此 $R(i, j, k)$ 也必然是正则的。因此, 正则语言的核心理论结果是，DFA、NFA 和正则表达式在**描述语言的能力**上是完全等价的。- **NFA 与 DFA 等价**：对于每一台非确定型有限自动机（NFA），都存在一台等价的（接受相同语言的）确定型有限自动机（DFA）。证明方法为“子集构造法”，即将 NFA 的状态集合映射为 DFA 的单个状态。  - 这意味着，NFA带来的所有便利性，都只是“表面上”的。在**计算能力的本质上**，它并没有超越DFA。- **自动机与正则表达式等价**：一个语言是正则的（即可以用正则表达式表示）当且仅当它被一台有限自动机接受。证明思路包括：  - 从任意正则表达式构造等价的 NFA：为基础情况构造简单自动机，利用自动机在并、连接和 Kleene 星号运算下的封闭性递归组合。  - 从任意有限自动机构造等价的正则表达式：使用状态消除法，逐步移除中间状态并更新转移边的正则表达式，直到只剩下初始和接受状态。## 正则语言与非正则语言 (Languages that are and are not regular)。到目前为止，我们已经学习了三种强大的工具来描述和证明一个语言是正则的：- 为它构造一台有限自动机 (FA) 。- 为它写出一个正则表达式 。- 利用正则语言的闭包性质 (Closure Properties)，比如并、交、补、连接和克林星号等，从已知的正则语言构造出它 。**示例1**: 假设字母表 $\\Sigma$ 是 $\\{0, 1, ..., 9\\}$。语言 $L$ 是所有能被 2 和 3 整除的非负整数的十进制表示（并且没有多余的前导零）。请证明 $L$ 是一个正则语言。第一步：分解问题。我们要证明的语言 $L$ 是“能被 2 整除”的语言 $L_2$ 和“能被 3 整除”的语言 $L_3$ 的交集，即 $L = L_2 \\cap L_3$。根据正则语言的闭包性质，只要 $L_2$ 和 $L_3$ 都是正则的，它们的交集 $L$ 也一定是正则的。第二步：证明 $L_2$ 是正则的。一个数能被 2 整除，等价于它的十进制表示最后一位是 $0, 2, 4, 6, 8$。所有合法的非负整数的十进制表示组成的语言 $L_1$ 可以用正则表达式 $0 \\cup [1-9][0-9]^*$ 表示（假设 $\\Sigma = \\{0,1,\\ldots,9\\}$）。$L_2$ 就是 $L_1$ 中以偶数结尾的字符串，即 $L_2 = L_1 \\cap [0-9]^*[0,2,4,6,8]$。由于 $L_1$ 和 $[0-9]^*[0,2,4,6,8]$ 都是正则语言，交集 $L_2$ 也是正则的。&gt; $[1-9][0-9]^*$ 这一部分表示所有非零的非负整数。  &gt; - **子部分 B1**：$[1-9]$ 是 $\\{1, 2, \\dots, 9\\}$ 的简写，它由基本正则语言 $\\{1\\}, \\{2\\}, \\dots, \\{9\\}$ 通过有限次并集 $\\cup$ 得到。由于正则语言对并集运算封闭，$L_{B1} = \\{1, 2, \\dots, 9\\}$ 是正则语言。  &gt; - **子部分 B2**：$[0-9]^*$ 是 $\\{0, 1, \\dots, 9\\}^*$ 的简写，同样是正则语言（通过有限次并集和 Kleene 星号运算）。因此 $L_{B2} = \\{0, 1, \\dots, 9\\}^*$ 也是正则语言。  &gt; - **连接 B1 和 B2**：部分 B 是由 $L_{B1}$（非零数字）和 $L_{B2}$（任意数字串）通过连接运算（$L_{B1}L_{B2}$）得到的。由于正则语言对连接运算封闭，$L_B = [1-9][0-9]^*$ 也是正则语言。第三步：证明 $L_3$ 是正则的。一个数能被 3 整除，当且仅当它的各位数字之和能被 3 整除。我们可以设计一个 3 个状态的 DFA，状态分别表示“数字和模 3 余 0、1、2”。初始状态（也是接受状态）表示余 0。每读入一个数字 $d$，就从当前状态 $q$ 转移到 $((q + d) \\bmod 3)$。这台 DFA 能接受所有各位数字和能被 3 整除的字符串，因此 $L_3$ 是正则语言。第四步：结论。由于 $L_2$ 和 $L_3$ 都是正则语言，且正则语言对交集运算封闭，所以 $L = L_2 \\cap L_3$ 也是正则语言。证毕。我们再来看一个更抽象的例子来巩固闭包性质的应用。**问题**：假设 $L'$ 是一个已知的正则语言，证明语言 $L = \\{xy \\mid x \\in L',\\ y \\notin L'\\}$ 也是正则的。**证明**：首先分析 $L$ 的结构。$L$ 中的字符串由两部分组成：第一部分 $x$ 属于 $L'$，第二部分 $y$ 不属于 $L'$。也就是说，$y$ 来自 $L'$ 的补集 $\\overline{L'}$。因此，$L$ 可以表示为 $L = L' \\circ \\overline{L'}$，即 $L'$ 与 $\\overline{L'}$ 的连接。根据正则语言的闭包性质：- 正则语言对补集运算封闭，所以 $\\overline{L'}$ 也是正则语言。- 正则语言对连接运算封闭，所以 $L' \\circ \\overline{L'}$ 也是正则语言。综上，$L$ 是正则语言。下面是一些正则语言的例子：- $L = \\{a^n \\mid n \\ge 0\\}$ 是正则的，因为它的正则表达式就是 $a^*$。- $L = \\{a^n \\mid n \\text{ is even}\\}$ 也是正则的，对应的正则表达式为 $(aa)^*$。- 如果 $L_0$ 是正则的，那么它的反转语言 $\\{w^R \\mid w \\in L_0\\}$ 也是正则的（正则语言对反转运算封闭）。一个非正则语言的例子：- $L = \\{w \\in \\{a, b\\}^* \\mid w \\text{ 中 } a \\text{ 和 } b \\text{ 的数量相等}\\}$ 不是正则的。  - 为什么？可以用闭包性质和反证法证明：  - 假设 $L$ 是正则的。我们知道 $a^*b^*$ 是正则语言（正则表达式为 $a^*b^*$）。由于正则语言对交集封闭，$L \\cap a^*b^*$ 也应是正则的。但 $L \\cap a^*b^*$ 实际上就是 $\\{a^n b^n \\mid n \\ge 0\\}$，即所有先若干个 $a$ 再若干个 $b$，且 $a$ 和 $b$ 数量相等的字符串。我们将会证明 $\\{a^n b^n \\mid n \\ge 0\\}$ 不是正则语言，这样就产生了矛盾。因此，$L$ 不是正则的。实际上, 非正则语言数量远大于正则语言. 下面我们从集合了的角度给予分析:- **问题1：一个非空字母表能组成多少个字符串？**    答案是**可数无穷多**（countably infinite）。因为所有字符串都是有限长度的，可以按长度和字典序一一列举出来。- **问题2：一个语言是可数的吗？**    是的。任何**语言都是字符串集合的子集**，所以它本身至多是可数无穷的。- **问题3：一个非空字母表上，总共有多少种可能的语言？**    答案是**不可数无穷多**。因为所有语言的集合，是可数无穷字符串集合的幂集，而**可数集的幂集是不可数**的（其基数与实数集相同）。- **问题4：有多少种正则语言？**    答案是**可数无穷多**。原因在于，每一个正则语言都可以用一个有限长度的字符串来描述（如正则表达式或有限自动机的描述），而所有有限字符串的集合是可数的。**结论**：  我们有不可数无穷多种语言，但只有可数无穷多种正则语言。这意味着，绝大多数的语言都是非正则的！为什么有些语言不是正则的呢？本质原因在于有限自动机（FA）的“有限性”：它只有有限个状态，因此**只能记住有限的信息**。以 $\\{a^n b^n\\}$ 为例，判断一个字符串是否属于这个语言，需要机器在读完所有的 $a$ 后，**准确记住 $a$ 的数量**，以便后续与 $b$ 的数量进行匹配。如果 $n$ 可以任意大，这就要求机器拥有**无限的记忆能力或无限个状态**，而有限自动机无法做到这一点。类似地，像平衡括号这样的语言，也需要无限的计数能力来确保左右括号严格匹配，这超出了有限自动机的能力范围。因此，凡是需要“**无限记忆**”或“**精确计数**”的语言，都不是正则语言。下面列出了一些经典的、将在本章被证明为非正则的语言：- $L_1 = \\{a^n b^n \\mid n \\ge 0\\}$  - $L_2 = \\{a^n \\mid n \\text{ is prime}\\}$  - $L_3 = \\{ww^R \\mid w \\in \\{a,b\\}^*\\}$（回文串）- $L_4 = \\{ww \\mid w \\in \\{a,b\\}^*\\}$（重复串）这些语言的共同点在于：它们都要求**对字符串的不同部分进行精确的数量或结构匹配**，而这种匹配超出了有限自动机（FA）**有限内存的能力范围**，因此不是正则语言。### 泵定理 (Pumping Theorem)直观的理解很好，但我们需要一个严格的数学工具来证明一个语言不是正则的。这个工具就是大名鼎鼎的**泵定理** (Pumping Theorem)。一台有穷自动机 $M$ 被定义为一个五元组 $M = (K, \\Sigma, \\delta, s, F)$。其中，状态集合 $K$ 是一个有穷集合 (a finite set of states)。假设这台 DFA $M$ 拥有的状态总数是 $n$（即 $|K| = n$）。现在, 我们考虑一个非常长的字符串 $w$，它的长度 $|w|$ 大于或等于状态的总数 $n$。当 DFA $M$ 从初始状态开始，读取这个长字符串 $w$ 的前 $n$ 个符号时，它会经历 $n$ 步转移，访问 $n+1$ 个状态。- 鸽巢（Pigeonholes）：DFA 拥有的状态总数 $n$。- 鸽子（Pigeons）：DFA 在读取前 $n$ 个符号时，按时间顺序依次访问的 $n+1$ 个状态。  - 初始状态 $q_0$ (第 0 步)  - 第 1 个状态 $q_1$ (第 1 步)  - ...  - 第 $n$ 个状态 $q_n$ (第 $n$ 步)根据鸽巢原理：如果有 $n+1$ 只鸽子要飞入 $n$ 个鸽巢，那么至少有一个鸽巢里必须有两只或两只以上的鸽子。这意味着：在这 $n+1$ 个被访问的状态序列中，必定有两个状态是同一个状态。结论：环路的产生假设自动机在第 $i$ 步和第 $j$ 步（其中 $0 \\le i &lt; j \\le n$）访问了同一个状态 $q$ ：$$q_i = q_j = q$$机器在第 $i$ 步和第 $j$ 步之间读取的那段子字符串，就是导致机器从 $q$ 重新回到 $q$ 的那段路径。这段路径在状态图上表现为一个环路（loop）。如果 $|w| \\ge n$，环路必须发生在字符串前 $n$ 个符号所对应的路径中。这就是泵定理证明的第一步，通过严格的鸽巢原理，证明了对于**足够长的字符串**，**有限自动机**中必然存在一个或多个**环路**。现在我们就可以把字符串拆分了：- $x$ 是从开头到 $q_i$ 的部分 ($a_1 \\dots a_{i-1}$)。- $y$ 是从 $q_i$ 绕一圈回到 $q_i$ 的部分 ($a_i \\dots a_j$)。- $z$ 是剩下的部分 ($a_{j+1} \\dots a_m$)。泵定理的正式陈述：如果 L 是一个正则语言，那么必然存在一个整数 n≥1（我们称之为“**泵长度**”），使得任何在 L 中且长度不小于 n 的字符串 w，都可以被**拆分成三段** w=xyz，并且满足以下三个条件：  - $y \\ne \\epsilon$ (中间的“泵”部分非空)。  - $|xy| \\le n$ (循环必定发生在字符串的前 $n$ 个字符以内)。  - 对于所有的 $i \\ge 0$，字符串 **$xy^iz$** 仍然属于 $L$ (这就是“泵”的含义：可以泵任意次)。#### 如何使用泵定理泵定理是一个破坏性工具。它只能用来**证明一个语言不是正则的**，而不能用来证明一个语言是正则的。证明方法：**反证法** (Proof by contradiction)。使用泵定理的过程，就像是在玩一个游戏。- 对手：一个“AI”，它坚信语言 $L$ 是正则的。- 你：一个“反方辩手”，你的目标是证明AI是错的。- 游戏规则：  - AI先出招，它给出一个泵长度 $n$。（你不知道 $n$ 是多少，但你知道它存在）。  - 轮到你了，你必须挑选一个非常聪明的字符串 $w \\in L$，且 $|w| \\ge n$。  - AI再出招，它把你的 $w$ 分解成 $xyz$，但它必须遵守规则（$|xy| \\le n, y \\ne \\epsilon$）。它会尽可能地以对它有利的方式来分解。  - 你的最后一击：你必须指出，**无论AI怎么分解**，你总能找到一个 $i$（通常是0或2），使得**泵出的新字符串 $xy^iz$ 不在语言 $L$ 中**。如果你能做到这一点，你就制造了矛盾，证明了AI的观点是错误的，因此 $L$ 不是正则的。##### 示例: $L=\\{a^ib^i \\mid i \\ge 0\\}$ 不是正则的我们要证明这个语言——所有由一串 $a$ 跟着一串数量完全相等的 $b$ 组成的字符串——不是正则的。严格按照泵定理的反证步骤：1. **假设**：假设 $L$ 是正则语言。2. **泵长度**：根据泵定理，存在一个泵长度 $n$。3. **选择字符串**：取一个长度大于 $n$ 的字符串 $w = a^n b^n$，显然 $w \\in L$ 且 $|w| = 2n \\ge n$。4. **拆分规则**：AI 必须将 $w$ 拆分为 $xyz$，满足 $|xy| \\le n$ 且 $y \\ne \\epsilon$。     - 因为 $|xy| \\le n$，所以无论怎么拆分, $x$ 和 $y$ 都只包含 $a$，$y = a^i$，其中 $i &gt; 0$。5. **泵操作**：选择 $i = 0$，得到新字符串 $xz = a^{n-i} b^n$。6. **矛盾**：如果 $L$ 是正则语言, 那么根据泵定理，得到的新字符串 $xz$ 也是正则语言, 但$xz$ 中 $a$ 的数量为 $n-i &lt; n$，$b$ 的数量为 $n$，两者不相等，因此 $xz \\notin L$。7. **结论**：存在 $i$ 使得 $xy^i z \\notin L$，与泵定理矛盾。因此，$L$ 不是正则语言。##### 证明 $L=\\{a^n \\mid n \\text{ is prime}\\}$ 不是正则的我们采用泵定理进行反证：1. **假设**：假设 $L$ 是正则语言。2. **泵长度**：根据泵定理，存在一个泵长度 $n$。3. **选择字符串**：选择一个大于 $n$ 的素数 $k$，令 $w = a^k$，显然 $w \\in L$ 且 $|w| = k \\ge n$。4. **拆分规则**：AI 必须将 $w$ 拆分为 $xyz$，满足 $|xy| \\le n$ 且 $y \\ne \\varepsilon$。由于 $w$ 全由 $a$ 组成，设 $x = a^p$, $y = a^q$, $z = a^r$，其中 $p+q \\le n$, $q &gt; 0$, $p+q+r = k$。5. **泵操作**：根据泵定理，任意 $i \\ge 0$，$xy^iz = a^{p + iq + r}$ 应属于 $L$，即 $p + iq + r$ 必须为素数。6. **构造反例**：令 $i = k + 1$，则新字符串长度为 $p + (k + 1)q + r = (p + q + r) + kq = k + kq = k(q + 1)$。  - $k$ 是素数且 $q \\ge 1$，所以 $q + 1 \\ge 2$，因此 $k(q + 1)$ 是合数（大于 $k$ 且可分）。7. **矛盾**：$a^{k(q+1)}$ 不属于 $L$，因为其长度不是素数。与泵定理要求矛盾。**结论**：存在 $i$ 使得 $xy^iz \\notin L$，因此 $L$ 不是正则语言。### 问题：证明 $L=\\{uu^Rv \\mid u,v \\in \\{a,b\\}^+\\}$ 不是正则的。这个语言 $L = \\{uu^Rv \\mid u, v \\in \\{a, b\\}^+\\}$ 表示一个非空回文串 $uu^R$ 后面跟着另一个非空串 $v$。直接对 $L$ 使用泵定理较难，因为 $v$ 的存在让结构复杂。我们可以先与一个精心设计的**正则语言**求**交**，得到一个**更简单但同样非正则的语言** $L'$，从而让问题转化为证明 $L'$ 不是正则的。**第一步：与正则语言求交集**选择正则语言 $(ab)^+(ba)^+$，与 $L$ 求交得到 $L' = L \\cap (ab)^+(ba)^+ = \\{(ab)^n(ba)^m \\mid m &gt; n \\ge 1\\}$。其中 $u = (ab)^n$，$u^R = (ba)^n$，$v = (ba)^{m-n}$，要求 $m &gt; n$ 保证 $v$ 非空。**第二步：对 $L'$ 使用泵定理**假设 $L'$ 是正则语言。根据泵定理，存在泵长度 $p$。选择字符串 $w = (ab)^p(ba)^{p+1} \\in L'$，满足 $|w| \\ge p$。将 $w$ 拆分为 $w = xyz$，其中 $|xy| \\le p$，$y \\ne \\varepsilon$。由于 $|xy| \\le p$，$x$ 和 $y$ 都在最前面的 $(ab)^p$ 部分。$y$ 可能是完整的 $(ab)^k$，或是部分片段（如 $a$、$ab$、$b$ 等）。无论如何拆分 $y$，都可以选择 $i = 0$ 或 $i = 3$，使得泵出后的字符串 $xy^iz$ 不满足 $m &gt; n$，即 $(ab)^{p+q}(ba)^{p+1}$，其中 $q$ 是泵的次数。这样得到的字符串不属于 $L'$，与泵定理矛盾。**结论**$L'$ 不是正则语言。由于正则语言的交集仍为正则，而 $L'$ 非正则，因此原语言 $L$ 也不是正则语言。## 关键研究问题1. **状态最小化目标**：给定一台 DFA，找到一台接受完全相同语言、且状态数最少的等价 DFA。Myhill-Nerode 定理为最小化提供了理论基础。它定义了一种关于字符串的等价关系 $\\approx_L$（如果 $x \\approx_L y$，意味着对于任何后缀 $z$，字符串 $xz$ 和 $yz$ 要么都属于 $L$，要么都不属于 $L$）。该定理证明了一个语言是正则的，当且仅当 $\\approx_L$ 关系具有有穷个等价类，并且这些等价类的数量，恰好就是接受 $L$ 的最小 DFA 的状态数。最小化算法：首先移除所有从初始状态不可达的状态，然后迭代地识别并合并“等价”的状态。算法开始时，将所有状态分为两个集合：终结状态 $F$ 和非终结状态 $K-F$。在随后的每一步迭代中，检查当前同一集合中的任意两个状态 $p$ 和 $q$。如果存在任何一个输入符号 $a$，使得 $\\delta(p, a)$ 和 $\\delta(q, a)$ 落在上一轮迭代所划分出的不同集合中，那么 $p$ 和 $q$ 就必须被分离。重复这个细化过程，直到某轮迭代后不再有任何集合被分离为止。此时剩下的集合中的状态都是真正等价的，可以合并为最小自动机的一个状态。2. **泵定理 (Pumping Lemma) 用途**：这不是用来证明语言是正则的，而是用来证明一个语言不是正则的。定理断言，任何正则语言 $L$ 都存在一个常数 $n$（称为“泵长度”，该值取决于接受它的 DFA 的状态数）。对于 $L$ 中任何长度至少为 $n$ 的字符串 $w$，$w$ 都可以被拆分为三部分 $w=xyz$，且满足以下所有条件：$y \\ne \\varepsilon$（中间部分非空），$|xy| \\le n$（拆分发生在字符串的靠前部分），对于所有的 $i \\ge 0$（包括 $i=0$ 时删除 $y$），字符串 $xy^iz$ 必须仍然在 $L$ 中。工作原理：如果一个 DFA 有 $n$ 个状态，它在读取一个长度为 $n$ 或更长的字符串时，根据鸽巢原理，必定至少重复访问了某一个状态。这个状态重复访问路径所对应的字符串就是 $y$。既然这是一条回路，那么这条回路可以被遍历任意多次（或 0 次），机器最终仍会到达相同的接受状态。3. **证明语言不是正则的方法**：使用泵定理进行反证法证明。步骤如下：   - 假设目标语言 $L$ 是正则的。   - 根据泵定理，必然存在某个泵长度 $n$。   - 选择一个特定的字符串 $w \\in L$，要求 $|w| \\ge n$。   - 对手可以将 $w$ 拆分为 $w=xyz$，其中 $y \\ne \\varepsilon$ 且 $|xy| \\le n$。   - 证明无论如何拆分 $w$，总能选择一个 $i$ 值（通常是 $i=0$ 或 $i=2$），使得生成的字符串 $xy^iz$ 不在 $L$ 中。   - 这导致了矛盾，因此最初的假设（$L$ 是正则的）是错误的。   经典示例：证明 $L = \\{a^nb^n : n \\ge 0\\}$ 不是正则的。选择 $w = a^nb^n$，由于 $|xy| \\le n$，$y$ 必须完全由 $a$ 组成（形如 $a^j$ 且 $j&gt;0$）。如果选择 $i=0$，得到的字符串 $xz = a^{n-j}b^n$，a 和 b 的数量不再相等，故 $xz \\notin L$，产生矛盾。\r\n","categories":["algorithms"],"tags":["algorithms","Computing Theory"]},{"title":"Structures","url":"/2025/09/28/system/OS/Structures/Structures/","content":"操作系统服务与接口\r\n这部分主要介绍了操作系统（OS）为用户和系统本身提供的核心功能，以及用户与操作系统交互的方式。\r\n操作系统服务 (Operating\r\nSystem Services)\r\n操作系统提供的服务可以从两个角度来看：为用户提供便利和确保系统高效运行。\r\n面向用户的服务：\r\n\r\n用户界面 (User\r\nInterface)：几乎所有操作系统都提供用户界面，主要包括命令行界面（CLI）、图形用户界面（GUI）和批处理界面（Batch）\r\n。\r\n程序执行 (Program\r\nExecution)：系统必须能够将程序加载到内存中并运行，以及正常或异常地终止程序\r\n。\r\nI/O 操作 (I/O Operations)：运行中的程序可能需要与文件或 I/O\r\n设备进行交互 。\r\n文件系统操作 (File-system\r\nManipulation)：程序需要创建、删除、读写文件和目录，并管理其权限\r\n。\r\n通信\r\n(Communications)：允许进程之间交换信息，无论是在同一台计算机上（通过共享内存）还是跨网络（通过消息传递）\r\n。\r\n错误检测 (Error\r\nDetection)：操作系统需要持续监控硬件和软件中可能发生的错误，并采取适当措施确保系统稳定\r\n。\r\n\r\n面向系统的服务 ：\r\n\r\n资源分配 (Resource\r\nAllocation)：当多个用户或任务同时运行时，必须为它们分配 CPU\r\n时间、内存、文件存储等资源 。\r\n记录 (Accounting)：跟踪记录用户使用的资源类型和数量 。\r\n保护与安全 (Protection and\r\nSecurity)：保护是确保所有对系统资源的访问都受控制\r\n；安全则是通过用户身份验证等手段，防止外部非法访问 。\r\n\r\n用户操作系统接口\r\n(User Operating System Interface)\r\n用户主要通过以下两种方式与操作系统交互：\r\n\r\n命令行界面 (CLI)：允许用户直接输入命令来执行操作\r\n。它的实现有时在内核中，有时由一个名为 “shell” 的系统程序提供\r\n。\r\n图形用户界面\r\n(GUI)：提供了一个用户友好的桌面环境，用户通过鼠标、键盘与图标、窗口等图形元素交互\r\n。GUI 的概念最早由施乐帕克研究中心（Xerox PARC）发明 。\r\n\r\n许多现代操作系统（如 Windows, macOS）同时提供这两种接口 。\r\n系统调用 (System Calls)\r\n系统调用是操作系统提供给程序的编程接口。它们允许用户级程序请求内核执行特权操作，如文件操作、进程控制和设备管理\r\n。\r\n程序通常不直接使用系统调用，而是通过高级语言的应用程序编程接口\r\n(API)，如 Windows 的 Win32 API 或类 UNIX 系统的 POSIX API 。API\r\n库函数（如 C 语言的 printf）在内部会调用相应的系统调用（如\r\nwrite）来完成任务 。\r\n实现机制：每个系统调用都有一个唯一的编号。当程序调用一个 API 时，该\r\nAPI\r\n会将对应的系统调用编号和参数传递给操作系统。操作系统通过一个表来查找并执行内核中相应的代码\r\n。这个过程对程序员是透明的 。\r\n参数传递：将参数从用户程序传递给内核有三种主要方法 ：\r\n通过\r\n寄存器 传递（最简单，但数量有限） 。\r\n将参数存在内存的\r\n块或表 中，然后将该块的地址通过寄存器传递（Linux 和 Solaris\r\n采用此法） 。\r\n将参数压入\r\n栈 中，由操作系统从栈中弹出 。\r\n系统调用类型：系统调用根据功能可分为几大类，如进程控制、文件管理、设备管理、信息维护、通信和保护\r\n。\r\n操作系统设计与结构\r\n这部分探讨了操作系统设计的核心原则和几种主流的内部结构模型。\r\n设计与实现原则 (Design\r\nand Implementation)\r\n设计目标：需要平衡用户目标（易用、可靠、快速）和系统目标（易于设计、实现和维护）\r\n。\r\n策略与机制分离 (Separation of Policy and\r\nMechanism)：这是一个非常重要的设计原则 。\r\n机制 (Mechanism)：定义 如何 去做某件事（例如，提供一个定时器来限制\r\nCPU 使用） 。\r\n策略 (Policy)：决定 要做什么（例如，决定一个进程可以使用 CPU\r\n多长时间） 。\r\n将两者分离可以使系统更加灵活，因为改变策略（如访问权限）时无需修改底层机制（如门禁卡系统）\r\n。\r\n操作系统结构 (Operating\r\nSystem Structure)\r\n简单结构 (Simple Structure)：如\r\nMS-DOS，功能模块之间没有明确的划分，接口和功能层次不清晰，目标是在最小的空间内提供最多的功能\r\n。\r\n分层方法 (Layered\r\nApproach)：将操作系统划分为多个层次，每一层都建立在更低层次之上\r\n。最底层是硬件（第0层），最高层是用户界面（第N层） 。\r\nUNIX 结构：被认为是 宏内核 (Monolithic) 结构\r\n。其内核包含了文件系统、CPU 调度、内存管理等几乎所有的核心功能 。\r\n微内核 (Microkernel)：将尽可能多的功能从内核态移到用户态\r\n。内核只保留最基本的功能，如进程间通信、内存管理和 CPU 调度。\r\n优点：更可靠、更安全、易于扩展和移植 。\r\n缺点：用户态和内核态之间的通信会带来性能开销 。\r\n模块化 (Modules)：大多数现代操作系统采用此方法\r\n。它使用面向对象的方法，将内核划分为多个独立的核心组件，这些组件通过明确的接口相互通信，并且可以根据需要在内核中动态加载\r\n。这种结构比分层方法更灵活 。\r\n其他结构：\r\nExokernel：一种极简内核，只负责安全地分配硬件资源，将所有硬件抽象都交给用户空间的库来管理\r\n。性能高但开发难度大 。\r\nUnikernel：将应用程序与所需的操作系统库静态链接，形成一个单一、专门的启动镜像\r\n。非常适合云服务，启动速度极快 。\r\n高级概念与系统启动\r\n这部分介绍了虚拟化技术以及操作系统的生成与启动过程。\r\n虚拟机 (Virtual Machines)\r\n虚拟机是分层方法的一种逻辑延伸，它将硬件和操作系统内核视为一个整体，并在此之上模拟出多个独立的、与底层硬件接口完全相同的虚拟计算机\r\n。\r\n优点：\r\n完全隔离：每个虚拟机都与其他虚拟机隔离，提供了极高的系统资源保护\r\n。\r\n开发与研究：是操作系统研究和开发的理想平台，因为可以在虚拟机上进行开发而不影响物理主机的正常运行\r\n。\r\n实现：通过一个名为 虚拟机监视器 (Hypervisor)\r\n的软件层来共享物理计算机的资源，为每个虚拟机创建出独立的处理器和内存的假象\r\n。\r\n操作系统生成与启动\r\n(OS Generation and System Boot)\r\n系统生成\r\n(SYSGEN)：操作系统通常被设计为可以在一类机器上运行，因此需要通过一个名为\r\nSYSGEN 的程序来配置系统，以适应特定计算机的硬件配置 。\r\n系统引导 (System Boot)：\r\n定义：指通过加载内核来启动计算机的过程 。\r\n引导程序 (Bootstrap\r\nProgram)：一段存储在只读存储器（ROM）或固件中的小程序 。\r\n过程：当计算机通电时，硬件会从一个固定的内存地址开始执行引导程序。该程序负责定位操作系统内核，将其加载到内存中，然后开始执行内核，从而完成系统的启动\r\n。\r\n","categories":["system","OS"],"tags":["system"]},{"title":"Thread","url":"/2025/10/21/system/OS/Thread/Thread/","content":"多线程模型\r\n首先, 我们需要了解两种基本的线程类型：\r\n\r\n用户线程 (User\r\nThreads)：由用户空间的线程库（比如一个语言的运行时）来管理（例如\r\nPthreads, Java\r\nthreads）。操作系统内核对这些线程一无所知，它只看到了一个单线程进程。\r\n\r\n核心意义：轻量级与高效切换\r\n\r\n创建与销毁快：创建线程不需要经过操作系统，只是在用户空间分配一些数据结构。\r\n切换（上下文切换）极快：线程A切换到线程B，只是库函数的一次调用，保存一下CPU寄存器，然后跳转到线程B的执行点。这个过程不需要陷入内核\r\n(System Call)，开销非常小。\r\n\r\n重大局限：\r\n\r\n阻塞问题：由于内核“看”不到这些用户线程，它只“看”到这一个进程（或者说，承载这些用户线程的那个内核线程）。如果其中任何一个用户线程发起了一个阻塞式的系统调用（例如\r\nread\r\n等待磁盘I/O），内核会把整个进程（或承载线程）挂起。这意味着，该进程内的所有其他用户线程，即使它们是就绪的，也无法运行。\r\n无法利用多核：内核只知道一个执行实体，它只会把这个进程调度到一个CPU核心上。你无法通过纯粹的用户线程实现真正的并行（Parallelism），只能实现并发（Concurrency）。\r\n\r\n\r\n内核线程 (Kernel\r\nThreads)：由操作系统内核直接支持和管理。几乎所有现代操作系统（Windows,\r\nSolaris, Linux, macOS）都实现了内核线程。\r\n\r\n核心意义：真正的并发与健壮性\r\n\r\n内核调度：内核“看得到”每一个线程。如果线程A因为I/O阻塞了，内核知道它被阻塞了，会立刻调度同一个进程中的线程B（如果B是就绪态）去运行。\r\n多核并行：内核调度器可以将同一个进程的多个内核线程，同时调度到不同的CPU核心上运行，实现真正的并行计算。\r\n\r\n相应代价: 开销更高.\r\n线程的创建、销毁和切换（上下文切换）都必须陷入内核来完成。这个模式切换（User\r\nMode &lt;-&gt; Kernel Mode）的开销远大于用户空间的函数调用。\r\n\r\n\r\n而多线程模型就是描述如何将用户线程映射到内核线程的三种不同方式。\r\n多对一 (Many-to-One) 模型\r\n将许多用户级线程映射到一个内核级线程上 。\r\n\r\n线程管理（创建、销毁、调度）完全在用户空间由线程库完成。\r\n操作系统内核根本不知道这些用户线程的存在，它只认为这是一个普通的单线程进程\r\n。\r\n\r\n优点： -\r\n高效：由于线程管理不需要进入内核，没有系统调用的开销，因此速度非常快\r\n。\r\n缺点： -\r\n阻塞问题：最大的问题是，如果任何一个用户线程执行了阻塞的系统调用（例如读取文件），那么整个进程（包括所有其他用户线程）都会被阻塞\r\n。 -\r\n无法并行：由于在任何时刻只有一个内核线程在运行，因此即使在多核处理器上，该进程也无法实现真正的并行。\r\n一对一 (One-to-One) 模型\r\n将每一个用户级线程都映射到一个单独的内核级线程 。\r\n\r\n每当创建一个用户线程，线程库就会相应地请求内核创建一个内核线程。\r\n线程的调度和管理主要由内核完成。\r\n\r\n优点： - 高并发性：一个线程的阻塞不会影响其他线程 。 -\r\n支持并行：由于有多个内核线程，该进程可以在多核处理器上实现真正的并行执行。\r\n缺点： -\r\n开销大：每创建一个用户线程都需要创建一个对应的内核线程，这会带来显著的开销和资源占用\r\n。系统能支持的内核线程数量是有限的。\r\n主流应用：这是目前最主流的模型，被 Windows、Linux 和现代 Solaris\r\n等操作系统采用 。\r\n多对多 (Many-to-Many) 模型\r\n将多个用户级线程复用到多个内核级线程上 。\r\n\r\n这是一种混合模型。内核线程的数量可以少于或等于用户线程的数量。\r\n用户空间的线程库负责将“准备就绪”的用户线程调度到可用的内核线程上去执行\r\n。\r\n\r\n优点：\r\n\r\n灵活性高：结合了前两种模型的优点 。\r\n解决阻塞问题：一个用户线程阻塞时，内核可以调度同一个进程中的另一个用户线程（通过另一个内核线程）来执行。\r\n开销适中：允许程序创建任意多的用户线程，而内核线程的数量则可以由操作系统根据负载动态调整\r\n。\r\n\r\n缺点：实现起来非常复杂。\r\n变体：二级 (Two-level) 模型\r\n定义：这本质上是“多对多”模型的一个变体，它额外允许一个用户线程绑定\r\n(bound)到某一个特定的内核线程上 。\r\n工作方式：大部分用户线程在多个内核线程池中灵活调度（多对多），而个别需要高优先级或实时响应的线程则可以“霸占”一个内核线程（一对一）。\r\n优点：提供了极高的灵活性，兼顾了高效调度和实时响应的需求。\r\n实际应用\r\n在现代主流操作系统中（如 Linux, Windows,\r\nmacOS），我们平时使用的线程模型绝大多数是 1:1 模型。\r\n它意味着你（用户）在代码中每创建一个线程，操作系统内核就会为你创建一个对应的内核线程。\r\n你用来创建线程的库（如 C++ 的 std::thread，C 的\r\npthread，Python 的 threading.Thread，Java 的\r\nThread）实际上只是一个“包装器”（Wrapper）。\r\n当你调用 std::thread myThread(func) 时，std::thread\r\n的构造函数内部会调用系统API（例如 Linux 上的 clone()\r\n系统调用）来请求内核创建一个内核线程。\r\n我们享受着内核线程的所有好处：一个线程阻塞I/O，不影响其他线程；多线程可以被自动调度到多核上并行运行。\r\n我们也承受着它的代价：创建和切换线程是有固定开销的。因此，我们不能无限制地创建成千上万个线程（这会导致资源耗尽和调度开销过大）。\r\n不过,\r\n“用户线程”的核心思想（即在用户空间实现极轻量级的切换）并没有消失，它以一种新的形式回归了，这就是我们常说的协程\r\n(Coroutines)。\r\n协程是一种 M:N 模型, 它结合了用户线程和内核线程的优点。\r\n\r\n系统创建 N 个内核线程（通常等于CPU核心数，组成一个线程池）。\r\n语言运行时（Runtime，如 Go 的调度器、Python 的 asyncio\r\n事件循环）在用户空间创建 M 个协程（M 可以非常大，如成千上万个，M\r\n&gt;&gt; N）。\r\n运行时负责将这 M 个协程“投放”到 N\r\n个内核线程上执行。\r\n\r\n这就是现代版的“用户线程”：Go 语言的 Goroutine\r\n是最典型的例子。你可以轻松创建几十万个 Goroutine。Go\r\n的调度器会在用户态管理它们，并将它们调度到少量的OS线程（内核线程）上。\r\n当一个 Goroutine\r\n遇到I/O（Go的运行时会使用非阻塞I/O），Go调度器会自动将其“挂起”，并让这个OS线程去执行另一个就绪的\r\nGoroutine。\r\nPython 的 asyncio、C# 的\r\nasync/await、Rust 的 tokio\r\n也是同理。它们都在一个（或少数几个）内核线程上，通过事件循环在用户态管理着大量的“任务”（Tasks）或“协程”。\r\n一些多线程问题\r\nfork() 和 exec()\r\n系统调用的语义\r\n当一个多线程进程中的某个线程调用 fork()\r\n来创建新进程时，会产生一个歧义：新的子进程是应该复制父进程的所有线程，还是只复制那个调用\r\nfork() 的线程？\r\n\r\n如果子进程复制了所有线程，那么它也必须复制所有线程的锁、状态等，这非常复杂且容易出错。\r\n如果子进程只复制了调用 fork()\r\n的线程，那么其他线程（例如可能持有锁的线程）就消失了，这可能导致子进程立即陷入死锁。\r\n\r\n解决方案是：一些 UNIX 系统提供了两个不同版本的 fork()\r\n，一个只复制调用者线程，另一个复制所有线程，让程序员根据需求选择。\r\n不过 POSIX 标准倒是规定：fork()\r\n会创建一个新的子进程，这个子进程的内存空间是父进程的完整副本，但它的执行实体（线程）只有一个，即那个调用了\r\nfork() 的线程的副本。\r\n\r\n但是在大部分情况下，fork()与exec()会配合使用,\r\n因此带来的锁问题根本不重要。因为子进程在有机会再次使用那个有问题的锁之前，它的整个内存就被\r\nexec() 覆盖了。\r\n\r\n不过与 fork() 不同，exec() 的语义是清晰的 。当任何线程调用\r\nexec()\r\n时，它会用一个新程序替换整个进程，包括该进程中的所有线程和资源。\r\n线程取消 (Thread\r\nCancellation)\r\n线程取消是指一个线程请求终止另一个线程的执行。这在多线程编程中是一个复杂的问题，因为强制终止一个线程可能会导致资源泄漏、不一致状态等问题。\r\n两种取消方式 ：\r\n\r\n异步取消 (Asynchronous\r\ncancellation)：一个线程立即终止另一个目标线程 。\r\n\r\n这种方式非常危险，因为目标线程可能正处于更新共享数据或持有锁的中间状态。强行终止它会导致数据不一致或资源无法释放。\r\n\r\n延迟取消 (Deferred\r\ncancellation)：目标线程会周期性地检查一个标志位，看自己是否应该被取消\r\n。\r\n\r\n这是更安全的方式。线程只会在代码中预设的“安全点”（称为取消点）检查标志位。如果发现需要被取消，它可以先执行必要的清理工作（如释放锁、关闭文件），然后再安全地自行终止。\r\n\r\n\r\n信号处理 (Signal Handling)\r\n信号 (Signals) 是 UNIX\r\n系统中用于通知进程发生某个事件（如非法内存访问或 Ctrl+C）的机制\r\n。在一个多线程进程中，当一个信号到达时，应该由哪个线程来接收和处理它？\r\nPOSIX\r\n标准规定：信号可以被传递给进程中的任何一个线程，具体取决于线程的信号掩码\r\n(Signal Mask)\r\n。如果一个线程没有屏蔽某个信号，那么该信号可以被传递给它。\r\n可能的传递情况 ：\r\n\r\n将信号传递给该信号所适用的特定线程 。\r\n将信号传递给进程中的每一个线程 。\r\n将信号传递给进程中的某些特定线程 。\r\n指派一个特定的线程来接收该进程的所有信号 。\r\n\r\n为了简化信号处理，程序员通常会创建一个专门的线程来处理信号。这个线程会阻塞所有其他信号，只等待和处理特定的信号事件\r\n。这样可以避免多个线程同时处理同一个信号导致的竞态条件和复杂性。\r\n线程私有数据 (Thread-Specific\r\nData)\r\n虽然线程的主要优点是共享数据，但有时我们希望每个线程拥有自己的私有数据副本\r\n。例如，每个线程可能需要一个唯一的错误码变量（errno）或事务ID。\r\n为此，许多线程库（如 Pthreads）提供了线程局部存储\r\n(Thread-Local Storage, TLS) 机制\r\n。程序员可以为每个线程定义私有数据，这些数据对其他线程不可见。\r\n实现方式 ： - 使用特殊的关键字（如 C++11 的\r\nthread_local）来声明线程局部变量。 - 使用线程库提供的\r\nAPI（如 pthread_key_create, pthread_setspecific,\r\npthread_getspecific）来管理线程私有数据。\r\n这样，每个线程都可以安全地访问和修改自己的私有数据，而不会干扰其他线程。\r\n具体实现\r\n线程的实现通常涉及以下几个关键组件： - 线程控制块 (Thread Control\r\nBlock, TCB)：每个线程都有一个\r\nTCB，包含线程的状态、寄存器上下文、堆栈指针、优先级等信息。 -\r\n线程调度器 (Thread\r\nScheduler)：负责管理线程的创建、销毁和调度。它决定哪个线程获得 CPU\r\n时间片。 - 同步机制 (Synchronization\r\nMechanisms)：如互斥锁 (Mutexes)、条件变量 (Condition Variables)\r\n等，用于协调线程之间的访问共享资源。 - 上下文切换\r\n(Context\r\nSwitching)：当线程被调度时，操作系统需要保存当前线程的状态并加载下一个线程的状态。这涉及保存和恢复寄存器、堆栈指针等信息。\r\n- 信号处理 (Signal\r\nHandling)：线程需要能够处理异步事件，如信号。线程库通常提供机制来注册信号处理程序。\r\n- 线程库 (Thread Libraries)：提供创建、管理和同步线程的\r\nAPI，如 Pthreads、Windows 线程 API 等。\r\n这些组件协同工作，实现了多线程的高效管理和调度，使得程序能够充分利用多核处理器的计算能力，同时保持数据的一致性和完整性。\r\nPthreads\r\nPthreads\r\n是一个标准，而不是一个具体的实现。它为多线程编程提供了一套统一的“规则”或“接口”。\r\n它是 POSIX 标准 (IEEE 1003.1c)\r\n的一部分，它定义了一套用于线程创建和同步的 C 语言 API。\r\n不过该标准只规定了 API 的行为（例如，pthread_create()\r\n函数应该如何被调用，它会做什么），但并不规定它在操作系统内部的具体实现\r\n。这意味着不同的操作系统可以有不同的方式来实现这套标准。\r\n目前, Pthreads 是 UNIX 类操作系统（如 Solaris, Linux, Mac OS\r\nX）上通用的线程标准 。\r\n\r\nPthreads API 可以被实现为用户级库，也可以被实现为内核级库 。\r\n在早期的某些系统中，Pthreads\r\n可能是作为用户级库实现的（遵循“多对一”模型）。但在现代操作系统中（尤其是\r\nLinux），Pthreads\r\n通常是作为内核级库实现的，与“一对一”模型紧密配合，性能更高。\r\n\r\nLinux 线程\r\nLinux\r\n在内核层面实现线程的方式非常独特，它并没有严格区分“进程”和“线程”。相反,\r\nLinux 有这样一个统一的核心概念：任务 (Tasks)\r\n因此, 线程（或任务）的创建是通过 clone() 系统调用完成的。\r\nclone()\r\n系统调用非常灵活，它允许新创建的子任务选择性地共享其父任务的资源，例如地址空间（内存）。\r\n\r\n当调用 clone()\r\n时，如果设置了标志位要求共享地址空间、文件描述符等资源，那么创建出的新“任务”在行为上就等同于一个线程。\r\n如果调用 clone()\r\n时没有设置这些共享标志位（即复制所有资源），那么创建出的新“任务”在行为上就等同于一个进程（类似于\r\nfork() 的效果）。\r\n\r\n这种设计使得 Linux 能够非常高效地实现“一对一”线程模型\r\n，因为在内核看来，创建一个“线程”和一个“进程”的底层机制是统一的，只是共享的资源程度不同而已。\r\n\r\n在 Linux 系统上，Pthreads 是程序员在应用层使用的标准\r\nAPI，而内核提供的 clone() 系统调用和“任务”机制，则是实现该 API\r\n的底层基础。\r\n\r\n线程调度\r\n","categories":["system","OS"],"tags":["system"]},{"title":"Process","url":"/2025/09/30/system/OS/Process/Process/","content":"进程的基本概念 (Process\r\nConcept)\r\n什么是进程 (Process)\r\n一个进程是 “一个正在执行中的程序”\r\n。它不仅仅是代码，还包含了程序当前的活动状态 。\r\n一个进程在内存中通常包含以下几个部分 ：\r\n\r\n文本段 (Text Section)：存放程序代码 。\r\n数据段 (Data Section)：存放全局变量 。\r\n堆 (Heap)：用于动态分配的内存 。\r\n栈 (Stack)：存放函数参数、局部变量和返回地址 。\r\n程序计数器 (Program Counter)：指示下一条要执行的指令地址 。\r\n进程状态 (Process State)\r\n\r\n\r\n\r\nalt text\r\n\r\n进程状态 (Process State)\r\n一个进程在其生命周期中会经历多种状态的转换 ：\r\n\r\n新建 (New)：进程正在被创建 。\r\n就绪 (Ready)：进程已准备好，等待被分配给CPU运行 。\r\n运行 (Running)：进程的指令正在被处理器执行 。\r\n等待\r\n(Waiting/Blocked)：进程正在等待某个事件的发生，如 I/O\r\n操作完成 。\r\n终止 (Terminated)：进程已完成执行 。\r\n\r\n\r\n\r\nalt text\r\n\r\n进程控制块 (Process\r\nControl Block, PCB)\r\n进程控制块 (Process Control Block,\r\nPCB)：是操作系统进行进程切换和管理的基础, 操作系统为每一个进程都维护一个\r\nPCB，它包含了与该进程相关的所有重要信息 ，例如：\r\n\r\n进程状态 。\r\n程序计数器和 CPU 寄存器的值 。\r\nCPU 调度信息（如优先级） 。\r\n内存管理信息（如页表） 。\r\nI/O 状态信息（如已分配的设备） 。\r\n\r\n进程调度 (Process Scheduling)\r\n进程调度是操作系统管理多个进程以有效利用 CPU 的机制\r\n。\r\n调度队列\r\n调度队列 (Scheduling\r\nQueues)：操作系统使用队列来组织进程 。\r\n\r\n作业队列 (Job Queue)：系统中所有进程的集合 。\r\n就绪队列/CPU队列 (Ready Queue/CPU\r\nQueue)：所有在主内存中、准备好执行的进程的集合 。\r\n设备队列 (Device Queues)：等待某个 I/O\r\n设备的进程集合 。\r\n\r\n\r\n\r\nalt text\r\n\r\n上图展示了操作系统中用于管理进程的两种主要类型的队列：就绪队列\r\n(Ready Queue) 和 I/O 设备队列 (I/O Device\r\nQueues)。\r\n每个矩形框（如 PCB7, PCB2）代表一个进程控制块 (Process Control Block,\r\nPCB)，它是操作系统用来存储一个进程所有信息的数据结构。\r\n位于图顶部的“ready queue”就是就绪队列，也被称为 CPU\r\n队列 (The CPU\r\nqueue)。它包含所有已经准备就绪、可以立即在 CPU\r\n上运行的进程。这些进程正在等待操作系统调度程序（Scheduler）为它们分配\r\nCPU 时间。\r\n\r\nqueue header（队列头部）包含 head 和 tail\r\n两个指针，分别指向队列的第一个和最后一个进程的 PCB。\r\n在这个例子中，PCB7 和 PCB2 正在就绪队列中排队，等待被 CPU 执行。PCB7\r\n在 PCB2 的前面。\r\n\r\n而当一个进程需要执行 I/O\r\n操作时（例如从磁盘读取数据），它会进入等待状态，并被放入相应 I/O\r\n设备的等待队列中，直到 I/O 操作完成。\r\n图中也展示了多个独立的 I/O 设备队列，每个设备都有自己的队列。\r\n\r\n磁盘单元0 (disk unit 0)：它的队列中有三个进程 PCB3、PCB14 和\r\nPCB6，说明这三个进程都在等待从该磁盘设备完成 I/O 操作。\r\n终端单元0 (terminal unit 0)：PCB5 正在等待该终端设备的 I/O\r\n操作。\r\n磁带单元0和1 (mag tape unit\r\n0/1)：这两个设备的队列是空的，表示当前没有进程在等待它们。\r\n\r\n\r\n\r\nalt text\r\n\r\n上图则是一个 “排队图” (A\r\nqueueing-diagram)，它详细描绘了一个进程在操作系统中的生命周期和状态转换路径。\r\n矩形框（灰色）代表队列或导致状态变化的事件;\r\n圆形/椭圆形框（蓝色）代表系统资源（如 CPU, I/O）或事件的结果;\r\n箭头表示进程在不同状态和队列之间的流转方向。\r\n具体来看,\r\n一个进程从进入系统到最终退出的完整流程，以及在此期间可能发生的各种情况有：\r\n\r\n进入就绪队列 (Ready Queue)\r\n一个新创建的或者从等待状态恢复的进程首先会进入就绪队列。这里的进程已经准备好了一切，只等待被分配\r\nCPU。\r\n分配 CPU 并运行\r\n操作系统的调度程序会从就绪队列中选择一个进程，并将其调度到 CPU\r\n上运行。\r\n从 CPU 离开的几种可能情况\r\n\r\n情况一：发起 I/O 请求 (I/O request)\r\n\r\n如果正在运行的进程需要进行读写文件、访问网络等 I/O\r\n操作，它会发起一个 I/O 请求。\r\n随后，该进程会从 CPU 释放，并进入相应的 I/O 队列 (I/O queue)\r\n进行等待。\r\n当 I/O 操作完成后，进程会重新回到就绪队列的末尾，等待下一次 CPU\r\n调度。\r\n\r\n情况二：时间片用完 (Time slice expired)\r\n\r\n在分时操作系统中，每个进程只能在 CPU\r\n上运行一个固定的时间段，即“时间片”。\r\n当时间片用完后，操作系统会通过一个中断来剥夺该进程的 CPU\r\n使用权。\r\n该进程会直接回到就绪队列的末尾，等待下一轮调度。\r\n\r\n情况三：创建子进程 (Fork a child)\r\n\r\n进程在运行时可以调用 fork\r\n之类的系统调用来创建一个新的子进程。\r\n创建子进程后，父进程可能会等待子进程执行完毕，或者继续并发执行。图中箭头指向父进程回到就绪队列。\r\n\r\n情况四：等待中断 (Wait for an interrupt)\r\n\r\n进程可能需要主动等待某个特定的事件发生，例如等待另一个进程发来的信号。\r\n在这种情况下，进程会进入等待状态，直到所等待的中断发生 (interrupt\r\noccurs)。\r\n中断发生后，该进程会被唤醒并移回到就绪队列中。\r\n\r\n情况五：正常结束\r\n\r\n进程执行完所有任务后会正常终止，然后退出系统。图中从 CPU\r\n指向右侧外部的箭头就代表了这一路径。\r\n\r\n\r\n\r\n调度程序 (Schedulers)\r\n\r\n\r\nalt text\r\n\r\n从概念上来看, 操作系统中的调度程序负责管理进程的执行,\r\n可以有两种类型的调度程序：\r\n短期调度程序 (Short-term Scheduler): 也称为 CPU\r\n调度程序 (CPU scheduler) 。\r\n它的主要任务是从就绪队列 (ready\r\nqueue)中选择一个进程，并为它分配 CPU\r\n。它决定了就绪队列中的哪个进程可以“上CPU”运行。\r\n它的执行频率非常高，通常是毫秒级别，因为每次 CPU\r\n需要切换进程时都可能调用它 。\r\n由于执行得非常频繁，短期调度程序本身必须运行得非常快，否则会占用大量本该用于执行用户进程的时间\r\n。\r\n长期调度程序 (Long-term Scheduler): 也称为\r\n作业调度程序 (job scheduler) 。\r\n它的任务是从一个更大的进程池（例如硬盘上的所有待处理的“作业”）中，选择哪些进程应该被加载到内存中，并放入就绪队列\r\n。\r\n它控制着系统中的多道程序设计度 (degree of\r\nmultiprogramming)，即同时存在于内存中的进程数量 。\r\n一般来说, 它的执行频率非常低，可能几秒钟甚至几分钟才执行一次\r\n。由于不经常执行，它的速度也相对较慢 。\r\n值得注意的是，许多现代操作系统（如 UNIX 和\r\nWindows）实际上并不使用长期调度程序 。\r\n\r\n\r\nalt text\r\n\r\n此外, 有些系统还引入了中期调度程序 (Medium-term\r\nScheduler)，当内存不足或系统需要调整内存中的进程组合时，中期调度程序会选择一个进程（通常是处于等待状态或优先级较低的进程），将其从内存中暂时移除，并保存到硬盘等二级存储中。\r\n在未来的某个时刻，当内存条件允许或该进程被需要时，中期调度程序会将被换出的进程重新加载回内存的就绪队列中，使其可以继续执行\r\n\r\n在内存中,\r\n进程大致可以分为计算密集型（CPU-bound）和I/O密集型（I/O-bound）进程,\r\n前者主要进行大量CPU计算, 而后者则频繁进行I/O操作。\r\n操作系统的调度程序通常会优先选择 I/O\r\n密集型进程，因为它们在等待 I/O 操作完成时，CPU\r\n可以被其他进程使用，从而提高整体系统的吞吐量和响应时间\r\n。\r\n\r\n上下文切换 (Context Switch)\r\n\r\n\r\nalt text\r\n\r\n当 CPU\r\n从一个进程切换到另一个进程时，系统必须保存当前进程的状态（上下文）到其\r\nPCB 中，并加载新进程的上下文 。\r\n这个过程是纯粹的开销\r\n(overhead)，因为在切换期间系统没有执行任何有用的工作 。\r\n进程操作 (Operations on\r\nProcesses)\r\n这部分描述了进程的创建和终止过程。\r\n进程创建 (Process Creation)：\r\n一个进程（父进程）可以创建新的进程（子进程），从而形成一个进程树\r\n。\r\n\r\n\r\nalt text\r\n\r\n在 UNIX/Linux 系统中:\r\n\r\nfork()\r\n系统调用用于创建一个新的子进程，该子进程是父进程的一个副本 。\r\n\r\n在创建后, 父进程和子进程会从 fork() 调用返回,\r\n但返回值不同: 父进程收到子进程的 PID, 而子进程收到0\r\n。\r\n子进程继承了父进程的大部分属性（如环境变量、打开的文件描述符等），但有自己的独立地址空间\r\n。\r\n\r\nexec() 系统调用通常在 fork()\r\n之后被子进程调用，用于将新的程序加载到自己的内存空间中，以替代从父进程复制来的内容\r\n。\r\n父进程可以通过 wait()\r\n系统调用来阻塞等待子进程的完成\r\n\r\n进程终止 (Process\r\nTermination)\r\n当一个进程完成其最后一个语句的执行后，它会调用\r\nexit() 系统调用来请求操作系统删除它\r\n。其所有占用的资源（内存、文件等）都会被操作系统回收 。\r\n父进程也可以终止其子进程（例如，当子进程超出了资源限制时）。\r\n如果父进程终止，其子进程可能会被级联终止 (cascading\r\ntermination) ，或者在某些系统中成为孤儿进程 (orphaned)，并被 init\r\n进程（PID 为 1）所收养。\r\n进程间通信\r\n(Interprocess Communication, IPC)\r\n这部分探讨了进程之间如何协作和交换信息。\r\n协作进程 (Cooperating\r\nProcesses)：\r\n能够影响或被其他进程影响的进程称为协作进程 。\r\n协作的优势包括信息共享、加快计算速度、模块化和便利性 。\r\n生产者-消费者问题\r\n(Producer-Consumer Problem)\r\n生产者-消费者模型\r\n描述了两个或多个并发实体（线程/进程）通过共享缓冲区（bounded\r\nbuffer）协作完成任务的过程。\r\n\r\n生产者（Producer）：负责生产数据（例如消息、任务、商品）并放入缓冲区。\r\n消费者（Consumer）：从缓冲区取出数据进行处理或消费。\r\n缓冲区（Buffer）：是一个共享的、有界的存储空间，用来暂存生产者产生但消费者尚未取走的数据。\r\n\r\n这个模型有两个关键挑战：\r\n\r\n同步（Synchronization）问题:\r\n消费者不能在缓冲区为空时取数据,\r\n生产者也不能在缓冲区满时放数据。因此需要一种方式让它们“有序等待、协调运行”。\r\n互斥（Mutual Exclusion）问题:\r\n生产者和消费者不能同时访问缓冲区（否则会出现数据竞争）。因此需要互斥锁或信号量来保护共享资源。\r\n\r\nIPC 的两种模型\r\n\r\n\r\nalt text\r\n\r\n共享内存 (Shared\r\nMemory)：多个进程共享一块内存区域。进程通过直接读写这块共享内存来交换信息。\r\n消息传递 (Message\r\nPassing)：进程通过发送和接收消息进行通信，而无需共享变量\r\n。这种通信通常由内核提供的 send() 和 receive() 操作来完成 。\r\n消息传递的实现\r\n直接通信 (Direct\r\nCommunication)：进程必须明确地命名对方来进行通信，通信双方必须明确知道对方的身份（进程名或PID），通信链路由操作系统自动建立。\r\n- send(P, message) → 向进程 P 发送消息\r\n- receive(Q, message) → 从进程 Q 接收消息\r\n间接通信 (Indirect Communication)：消息被发送到 邮箱\r\n(mailbox) 或 端口\r\n(port)，进程通过共享同一个邮箱来进行通信 。\r\n同步与异步 (Synchronization)：通信可以是 阻塞的\r\n(blocking/synchronous)，即发送方会等待消息被接收；也可以是 非阻塞的\r\n(non-blocking/asynchronous)，即发送方发送消息后立即继续执行 。\r\n客户端-服务器系统中的通信\r\n这部分介绍了在网络环境中实现进程通信的几种常用技术。\r\n套接字 (Sockets)：\r\n套接字是通信的一个端点，它由一个 IP 地址和一个端口号组合而成\r\n。两个进程间的网络通信就是通过一对套接字进行的 。\r\n远程过程调用 (Remote Procedure Calls, RPC)：\r\nRPC\r\n是一种允许一个进程调用网络中另一台计算机上进程的过程（或函数）的机制，使得分布式编程看起来像本地调用一样简单\r\n。\r\n远程方法调用 (Remote Method Invocation, RMI)：\r\nRMI 是 Java 中类似 RPC 的机制，它允许一个 Java\r\n程序调用远程机器上另一个 Java 对象的\r\n方法 。\r\n","categories":["system","OS"],"tags":["system"]},{"title":"Vim","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/Vim/","content":"\r\n","categories":["system","linux"],"tags":["system"]},{"title":"gcc","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/gcc/","content":"GCC 编译的四个阶段\r\n一个 C 语言源文件要变成可执行文件，需要经过预处理\r\n(Preprocessing)、编译\r\n(Compilation)、汇编 (Assembly) 和 链接\r\n(Linking) 这四个核心步骤。\r\n当你执行一个简单的命令 gcc hello.c -o hello 时，GCC\r\n实际上在后台为你自动完成了所有四个步骤, 分别是:\r\n第一步：预处理 (Preprocessing):\r\n这个阶段处理源代码中以 #\r\n开头的指令。它不关心代码的语法，只是对文本进行简单的替换和处理。\r\n\r\n输入文件: C 源文件，例如 hello.c\r\n输出文件: 经过预处理的 C 文件，通常以 .i 为后缀，例如\r\nhello.i\r\nGCC 命令: gcc -E hello.c -o hello.i\r\n\r\n因为这里只展示预处理, -E 选项告诉 GCC\r\n在预处理完成后就停止，不要进行后续步骤。\r\n-o 选项指定输出文件的名称, 这里是 hello.i\r\n\r\n主要工作内容：\r\n\r\n展开宏定义: 将所有 #define 定义的宏进行文本替换。\r\n处理条件编译: 根据 #if, #ifdef, #else, #endif\r\n等指令，选择性地保留或移除代码段。\r\n包含头文件: 将 #include\r\n指定的头文件内容原封不动地插入到源文件中。\r\n删除注释和多余空白: 移除代码中所有的注释 (// … 和 /* …\r\n*/)、不必要的空行和空白字符。\r\n\r\n\r\n经过这个阶段，hello.i\r\n文件会变成一个不包含任何宏、头文件引用或注释的“纯净”C代码文件。\r\n第二步：编译 (Compilation)\r\n这是整个编译过程中最核心的阶段，它将预处理后的 C\r\n代码翻译成特定于目标平台的汇编代码。\r\n\r\n输入文件: 预处理后的文件，例如 hello.i\r\n输出文件: 汇编代码文件，通常以 .s 为后缀，例如\r\nhello.s\r\nGCC 命令: gcc -S hello.i -o hello.s\r\n\r\n-S 选项告诉 GCC 在生成汇编代码后就停止。\r\n\r\n主要工作内容：\r\n\r\n词法分析:\r\n将源代码分解成一个个独立的“记号”(tokens)，如关键字、标识符、操作符等。\r\n语法分析: 根据 C\r\n语言的语法规则，将记号组织成一棵“语法树”，并检查是否存在语法错误（例如，括号不匹配、缺少分号等）。\r\n语义分析:\r\n检查代码的语义是否正确（例如，类型是否匹配、变量是否已声明）。\r\n代码优化:\r\n对生成的中间代码进行优化，以提高程序的运行速度和减小体积。\r\n生成汇编代码: 将优化后的代码转换成目标平台的汇编语言。\r\n\r\n\r\n这个阶段涉及复杂的分析和优化过程，通常是整个流程中消耗时间和系统资源最多的部分。\r\n第三步 ：汇编 (Assembly):\r\n汇编阶段将人类可读的汇编代码转换成机器可以执行的二进制指令。\r\n\r\n输入文件: 汇编代码文件，例如 hello.s\r\n输出文件: 可重定位目标文件 (Relocatable Object File)，在 Linux/macOS\r\n中通常以 .o 为后缀，在 Windows 中为 .obj，例如\r\nhello.o。\r\nGCC 命令: gcc -c hello.s -o hello.o\r\n\r\n-c 选项告诉 GCC 在生成目标文件后就停止。\r\n由于汇编过程也包含了预处理和编译两个阶段，所以 -c\r\n选项也会触发这两个阶段的执行, 也就是可以 gcc -c hello.c -o hello.o\r\n来直接生成目标文件。\r\n\r\n主要工作内容：\r\n\r\n指令翻译: 将每一条汇编指令（如 mov, add,\r\njmp）翻译成其对应的二进制机器码。\r\n生成目标文件:\r\n将机器码以及符号表、重定位信息等打包成一个特定格式的目标文件（在 Linux\r\n中通常是 ELF\r\n格式）。此时，文件中的代码和数据地址都是相对的，而不是最终的绝对内存地址。\r\n\r\n\r\n第四步：链接 (Linking):\r\n链接是创建可执行文件的最后一步。它将多个目标文件以及程序所需的库文件（如标准库）的二进制代码(.o\r\n文件)组合在一起。\r\n\r\n输入文件: 一个或多个目标文件 (.o) 和所需的库文件。\r\n输出文件: 可执行文件，在 Linux/macOS 中默认为\r\na.out，也可以通过 -o 指定名称（如\r\nhello）。\r\nGCC 命令: gcc hello.o -o hello\r\n\r\n不带 -E, -S, -c 等选项时，GCC\r\n默认执行所有四个步骤，并最终进行链接。\r\n\r\n主要工作内容：\r\n\r\n合并段: 将所有输入目标文件中的相同类型的段（如代码段 .text、数据段\r\n.data）合并到最终可执行文件中的一个大段中。\r\n符号解析与地址回填 (重定位):\r\n\r\n解析: 找到代码中引用的函数和变量（例如 printf\r\n函数）在其他目标文件或库文件中的确切位置。\r\n回填:\r\n在汇编阶段，函数调用和变量访问的地址是未知的。链接器会计算出它们在虚拟内存中的最终地址，并修改代码中的占位符，使其指向正确的内存地址。这个过程就是图片中提到的地址回填。\r\n\r\n\r\n\r\ngcc编译常用参数\r\n当头文件和源码不在一个目录下时，需要指定头文件的搜索路径 -\r\n-I 选项:\r\n用于指定头文件的搜索路径。可以多次使用这个选项来添加多个路径。 -\r\n例如：gcc -I /path/to/headers -o hello hello.c - 这会告诉 GCC 在编译\r\nhello.c 时，先去 /path/to/headers 目录下查找头文件。\r\n\r\n-c 只做预处理，编译，汇编。得到二进制文件\r\n-g 编译时添加调试文件，用于gdb调试\r\n-Wall 显示所有警告信息\r\n-D 向程序中“动态”注册宏定义\r\n-l 指定动态库库名\r\n-L 指定动态库路径\r\n\r\n静态库和动态库\r\n静态库在文件中静态展开, 动态库在运行时才被加载到内存中\r\n前者在编译时就被链接到可执行文件中, 因此内存占用大,\r\n但是速度快; 后者在运行时才被链接到可执行文件中,\r\n因此内存占用小, 但是速度较慢\r\n静态库制作及使用\r\n静态库名字以lib开头，以.a结尾 例如：libmylib.a\r\n静态库生成指令: ar rcs [lib名称.a] [用于生成库的.o文件] ar rcs\r\nlibmylib.a file1.o file2.o 制作静态库的步骤: 1. 编写静态库的源文件 2.\r\n编译源文件生成.o文件(二进制指令), 例如: gcc -c add.c -o add.o 3.\r\n使用ar命令将.o文件打包成静态库\r\n静态库的使用：gcc test.c libmylib.a -o a.out,\r\n如果静态库和可执行文件不在同一个目录下, 则需要指定静态库的路径, 例如:\r\ngcc test.c ./lib/libmylib.a -o a.out\r\n还要注意的一点是,\r\n静态库在引入使用时需要配套的头文件,\r\n也就是代码最上方的#include 因为头文件是给编译器看的,\r\n编译器需要根据头文件中的函数声明和变量定义来进行编译;\r\n而静态库中的.o文件是给链接器看的,\r\n链接器需要根据.o文件中的符号表来进行链接;\r\n如果没有头文件:\r\n编译器会因为找不到函数的声明而报错，提示“函数未定义”或“隐式声明”(undeclared/implicit\r\nfunction)，导致编译失败。编译器根本不知道这个函数的存在，也就无法生成正确的目标文件\r\n(.o)。\r\n\r\n当你从第三方获取一个库时，通常会得到 .a (或 .lib) 文件和一系列的 .h\r\n文件，这两部分都必须正确配置到你的项目中才能成功使用。\r\n\r\n动态库制作\r\n制作动态库的步骤\r\n\r\n编译生成位置无关的.o文件 gcc -c add.c -o add.o\r\n-fPIC\r\n使用这个参数过后，生成的函数就和位置无关，挂上@plt标识，等待动态绑定.\r\n这里的-fPIC是Position Independent Code的缩写, 表示生成位置无关的代码,\r\n可以被加载到任意内存地址执行.\r\n使用 gcc -shared制作动态库 gcc -shared -o [lib库名.so]\r\n[用于生成库的.o文件]\r\n链接可执行程序, 同时指定所使用的动态库。 gcc test.c -o a.out -l\r\nmymath -L ./lib -I /path/to/headers -Wl,-rpath,‘$ORIGIN/lib’\r\n\r\n\r\n-l:指定库名\r\n-L:指定库路径, 只在链接时使用,\r\n运行时需要通过-Wl,-rpath,’$ORIGIN/lib’指定动态库的搜索路径\r\n-I:可能会需要指定头文件的搜索路径\r\n-Wl,-rpath,‘$ORIGIN/lib’:指定动态库的搜索路径, 这里的ORIGIN表示可执行文件所在的目录 − 加上 − Wl, −rpath,′ORIGIN/lib’在可执行文件中直接指定动态库的搜索路径.\r\n\r\n\r\n运行可执行程序./a.out 注意 &gt; 运行时,\r\n动态库需要在系统的库搜索路径中, 如果不加-Wl,-rpath,‘$ORIGIN/lib’,\r\n则需要通过设置LD_LIBRARY_PATH环境变量来指定动态库的搜索路径.\r\n或者移动自制的动态库到系统的库搜索路径中.\r\n\r\n静态库和动态库的函数地址解析\r\n","categories":["system","linux"],"tags":["system"]},{"title":"GDB","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/gdb/","content":"使用gdb之前，要求对文件进行编译时增加-g参数，加了这个参数过后生成的编译文件会大一些，这是因为增加了gdb调试内容\r\n基础指令：\r\n-g：使用该参数编译可以执行文件，得到调试表。\r\ngdb ./a.out: 开始调试\r\nlist/l： l 1 列出源码, 因为分页显示, 后续直接l即可\r\nb： b 20 在20行位置设置断点。\r\nrun/r: 运行程序\r\nn/next: 下一条指令（会越过函数）\r\ns/step: 单步执行下一条指令（会进入函数）\r\np/print：p i 查看变量的值。\r\ncontinue：继续执行断点后续指令, 跳转到下一个断点。\r\nfinish：结束当前函数调用。\r\nquit：退出gdb当前调试。\r\n其他指令：\r\nrun：若报错段错误,\r\n则不需要设置断点进入gdb后直接使用run查找段错误出现位置。\r\nset args： 如果main有命令行参数, 设置main函数命令行参数 （在\r\nstart、run 之前） - 也可以通过 run 字串1 字串2 …:\r\n设置main函数命令行参数\r\ninfo b: 查看断点信息表\r\nb 20 if i = 5： 设置条件断点。\r\nptype：查看变量类型。\r\nbt：列出当前程序正存活着的栈帧。\r\nframe： 根据栈帧编号，切换栈帧。\r\ndisplay：设置跟踪变量\r\nundisplay：取消设置跟踪变量。使用跟踪变量的编号。\r\nlayout: 用于切换 TUI（Text User\r\nInterface）模式下的窗口布局的工具，让你可以更直观地查看源代码、汇编代码和寄存器信息\r\n- layout src：显示源代码窗口。 - layout asm：显示汇编代码窗口。 - layout\r\nregs：显示寄存器窗口，通常与源代码或汇编一起显示。 - layout\r\nsplit：同时显示源代码和汇编代码。\r\n","categories":["system","linux"],"tags":["system"]},{"title":"Makefile","url":"/2025/09/24/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/makefile/","content":"makefile： 用于管理项目。\r\n文件命名：只能是 makefile 或者 Makefile\r\n配置完成后直接使用 make 命令执行\r\n1 个规则：\r\n    目标：依赖条件\r\n    （一个tab缩进）命令\r\n要求: 目标的时间必须晚于依赖条件的时间，否则，更新目标\r\n依赖条件如果不存在，找寻新的规则去产生依赖条件。\r\nALL：指定 makefile\r\n的终极目标。(因为makefile默认第一个目标文件为终极目标,\r\n防止将中间文件放在第一个造成执行中断)\r\n2 个函数：\r\n    src = $(wildcard ./*.c): 匹配当前工作目录下的所有.c 文件。将文件名组成列表，赋值给变量 src (例如src = add.c sub.c div1.c)\r\n\r\n    obj = $(patsubst %.c, %.o, $(src)): 将参数3($(src))中，包含参数1(%.c)的部分，替换为参数2(%.o)。 obj = add.o sub.o div1.o\r\n\r\n在脚本语言中对一个对象使用$表示取其值\r\n\r\nclean:  (没有依赖)\r\n    -rm -rf $(obj) a.out    \r\n上述脚本可以实现调用make clean即可清除.o文件\r\n“-”：作用是，删除不存在文件时，不报错。顺序执行结束。\r\n3 个自动变量：\r\n$@:\r\n在规则的命令中，表示规则中的目标。\r\n$^:\r\n在规则的命令中，表示所有依赖条件。\r\n$&lt;:\r\n在规则的命令中，表示第一个依赖条件。如果将该变量应用在模式规则中，它可将依赖条件列表中的依赖依次取出，套用模式规则。\r\n也就是上面三者用在命令中, 代指命令上一行的目标和依赖\r\n模式规则：\r\n\r\n    %.o:%.c\r\n       gcc -c $&lt; -o %@\r\n  \r\n含义是对于所有目标为.o文件的对象, 根据.c文件来执行gcc -c (%.c) -o (%.o)\r\n\r\n静态模式规则：\r\n\r\n    $(obj):%.o:%.c\r\n       gcc -c $&lt; -o %@  \r\n\r\n只对obj所指的对象执行这条命令\r\n\r\n伪目标：\r\n\r\n    .PHONY: clean ALL\r\n防止文件中出现同名clean和ALL的文件阻碍make\r\n\r\n参数：\r\n    -n：模拟执行make、make clean 命令。\r\n\r\n    -f：指定文件执行 make 命令。\r\nmakefile实现增量执行, 其检测原理：\r\n修改文件后，文件的修改时间发生变化，会出现目标文件的时间早于作为依赖材料的时间，出现这种情况的文件会重新编译。\r\n修改sub.c后，sub.o的时间就早于sub.c\r\n，a.out的时间也早于sub.o的时间了，于是重新编译这俩文件了。\r\n还有一点, 编译时的参数，-g,-Wall这些，也可以放在makefile里面.\r\n一份最终的makefile示例如下: src = $(wildcard *.c) # 搜索当前目录下所有 .c 文件obj = $(patsubst %.c, %.o, $(src)) # 将所有 .c 文件转换为对应的 .o 文件名myArgs = -Wall -g # 编译参数：显示所有警告并生成调试信息ALL: a.out # 默认目标$(obj): %.o: %.c    gcc -c $&lt; -o $@ $(myArgs) # 编译每个 .c 文件为 .o 文件并加入编译参数a.out: $(obj)    gcc $^ -o $@ $(myArgs) # 链接所有 .o 文件生成最终可执行文件 a.outclean:    rm -rf $(obj) a.out # 清理所有生成的文件.PHONY: clean ALL # 声明伪目标，避免与同名文件冲突\r\nexport\r\nexport 是 GNU Make\r\n中一个非常重要的指令，它的核心作用是控制变量如何从一个\r\nMakefile 传递到它的子 Make 进程中。\r\n为什么需要 export？\r\n在大型项目中，我们通常会将代码和 Makefile\r\n分散在不同的子目录中。顶层的 Makefile 负责调用子目录中的\r\nMakefile 来完成局部的编译任务。这种通过一个 make 进程调用另一个\r\nmake 进程的方式，被称为递归 Make (Recursive Make) 或子\r\nMake (Sub-make)。\r\n这时就出现了一个问题：默认情况下，父 Makefile\r\n中定义的变量，在子 Make\r\n进程中是不可见的。export 指令就是为了解决这个问题而存在的。\r\nexport 的作用与 Shell 脚本中的 export 命令非常相似。它将一个 Make\r\n变量“导出”为一个环境变量，这个环境变量对 make 启动的所有子进程（包括\r\nShell 命令和子 Make 进程）都是可见的。\r\n当顶层 make 调用子目录的 make 时, make 会为这个子 make\r\n命令创建一个新的进程。在创建这个子进程之前，make 会将所有通过\r\nexport 指令导出的变量设置到该子进程的环境中。\r\n子 make 进程启动后，会从它的环境中读取这些变量，并将它们当作自己在\r\nMakefile 中定义的变量来使用。\r\n简而言之：export 是父 Makefile 向子 Makefile\r\n传递变量的桥梁。\r\nexport 的使用示例\r\n假设我们有一个简单的项目结构如下：\r\n项目结构:project/├── Makefile          # 顶层 Makefile└── subdir/    ├── main.c    └── Makefile      # 子 Makefile\r\n不使用 export 的顶层 Makefile 可能如下所示：\r\n# 顶层 MakefileCC = gccCFLAGS = -Wall -gall:\t$(MAKE) -C subdir\r\n子 Makefile 可能如下所示：\r\n# 子 Makefileall: mainmain: main.c\t$(CC) $(CFLAGS) -o main main.cclean:\trm -f main\r\n在这个例子中，顶层 Makefile 定义了编译器 (GCC)和编译选项\r\n(CFLAGS)，但是子 Makefile 并不知道这些变量，因为它们没有被传递过去。\r\n如果我们想让子 Makefile 使用顶层 Makefile 中定义的变量，我们可以使用\r\nexport 指令：\r\n# 顶层 Makefileexport CC = gccexport CFLAGS = -Wall -gall:\t$(MAKE) -C subdir\r\n现在，当顶层 Makefile 调用子 Makefile 时，子 Makefile 可以访问 CC 和\r\nCFLAGS 变量，并使用它们来编译代码。\r\n不同语法形式\r\n\r\n先定义，后导出: VAR = valueexport VAR 这种方式最清晰，易于阅读和维护。\r\n定义时直接导出: export VAR = value\r\n全部导出: export 如果 export 后面不跟任何变量名，它会导出当前\r\nMakefile\r\n中定义的所有变量。这通常被认为是不良实践，因为它可能会意外地将一些不希望传递的内部变量传递给子\r\nMake，导致难以调试的错误。明确地导出需要的变量是更好的选择。\r\n\r\n与 export 相对的是 unexport，它用于取消一个变量的导出。\r\n如果一个变量是通过环境传入 make 的（例如，你在 shell 中 export\r\nCFLAGS=“-O3”），make 默认会把它再次 export 给子 Make。如果你不希望某个子\r\nMake 继承这个环境变量，就可以使用 unexport。\r\n","categories":["system","linux"],"tags":["system"]},{"title":"基本命令与认识Linux","url":"/2025/09/21/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%E4%B8%8E%E8%AE%A4%E8%AF%86Linux/","content":"Linux命令基础习惯\r\ndate 显示系统当前时间, 本质是通过shell解释器调用 /bin/date.exe cat\r\n/etc/shells 查看当前可使用的shell echo $SHELL 查看当前使用的shell,\r\necho是回声命令, 用于将参数输出到标准输出\r\n键盘快捷键: Ctrl+A 将光标移动到行首 Ctrl+E 将光标移动到行尾 Ctrl+L\r\n清屏 Ctrl+U 删除整行 方向键 移动光标\r\n注意BACKSPACE删除的是光标前一个字符, 而DELETE删除的是光标后一个字符\r\n类Unix系统目录\r\npwd 查看当前所在目录, 同时当前目录也会显示在当前系统环境和$符号之间\r\nLinux系统目录常见项： - bin：存放二进制可执行文件 -\r\nboot：存放开机启动程序 - dev：存放设备文件,\r\n字符设备如键盘、块设备如磁盘(注意WSL没有, 它并不直接访问物理硬件设备) -\r\nhome：存放普通用户 - etc：用户信息和系统配置文件 passwd、group -\r\nlib：库文件：libc.so.6 - root：管理员宿主目录（家目录） - usr：(unix\r\nsoftware resource)用户资源管理目录, 可以是第三方软件\r\n目录和文件操作\r\npwd 查看当前所在目录 cd – 返回上一个目录 cd ~ 返回用户家目录 cd /\r\n返回根目录\r\n相对路径： - . 当前目录 - .. 上一级目录 绝对路径: / 根目录\r\nls 列出当前文件夹下目录项(ls\r\ndirname显示dirname下目录项) ls -R 递归列出所有子目录下的文件 ls -Rl\r\n递归列出并展示详细信息 ls -a 显示所有文件, 包括隐藏文件 ls -l\r\n显示目录项详细信息  如上图所示,\r\n详细信息依次代表文件权限, 硬链接计数, 所有者 所属组, 大小(单位字节),\r\n时间, 文件名/文件夹名\r\n其中文件权限字符串如上述图所示共有十位, 如-rw-r–r–(序号1234567890),\r\n其中: 1代表文件类型, 如-代表普通文件, d代表目录\r\n234代表所有者读-写-执行权限, 如rw-代表所有者有读写权限,\r\n无执行权限 567代表同组用户读写执行权限 890代表其他人读写执行权限\r\nLinux系统文件类型： 7种 - 普通文件：- - 目录文件：d - 字符设备文件：c\r\n- 块设备文件：b - 软连接：l - 管道文件：p - 套接字：s\r\nwhich instruct 查看instruct命令所在系统 $PATH 环境变量中的位置 mkdir\r\ndirname 新建目录 touch filename 创建名为filename的空文件 rm filename\r\n删除文件 rm dirname -r 递归删除目录 mv filename dirname\r\n移动文件filename到dirname目录下 mv dirname1 dirname2\r\n移动目录dirname1到dirname2目录下 cp filename dirname\r\n复制文件到目录dirname下 cp dirname1 dirname2\r\n复制目录dirname1到dirname2目录下 cp -r dirname1 dirname2\r\n递归复制目录dirname1到dirname2目录下 cp -a dirname1 dirname2\r\n递归完全复制目录dirname1到dirname2目录下, 保留相同的文件属性, 包括时间,\r\n权限, 软硬链接等\r\ncat filename 查看文件内容 tac filename 逆转查看文件内容 cat\r\n读取终端，就是回显echo vim filename 编辑文件filename(使用vim编辑器)\r\nmore filename 分页查看文件内容(空格翻页，回车一行, q退出) less\r\nfilename 和上面more类似\r\nhead -n filename 查看文件前n行 tail -n filename 查看文件后n行\r\ntree 查看当前目录结构树 tree dirname 查看dirname目录结构树\r\n软链接和硬链接\r\nln -s file file.s 创建一个软链接(软链接就像windows下的快捷方式,\r\n在相同的目录下创建另一个可以访问到file的文件) -\r\n如果是用相对路径创建软连接, 则软连接指向的是file文件的相对路径,\r\n这意味着如果file文件移动了, 软连接就会失效 - 如果是用绝对路径创建软连接,\r\n则软连接指向的是file文件的绝对路径, 这意味着无论file文件移动到哪里,\r\n软连接都不会失效\r\nln file file.h\r\n创建一个硬链接(硬链接就像windows下的复制,\r\n在相同的目录下创建另一个可以访问到file的文件) -\r\n创建硬链接后，文件的硬链接计数+1 - 硬链接特点是修改文件内容,\r\n硬链接文件的内容也会改变, 因为它们指向的是同一个 inode -\r\n删除一个硬链接时，文件的硬链接计数-1，当这个计数减为0时，才会删除这个文件\r\n文件名与 inode\r\n在 Linux 文件系统中，一个文件由两部分组成：\r\n文件名 (Filename)：我们用来识别和访问文件的名称。\r\ninode\r\n(索引节点)：一个存储文件元数据（metadata）的数据结构，包括文件大小、所有者、权限、创建时间以及最重要的——指向磁盘上存储文件真实数据的块的指针。\r\n可以这样理解：文件名是给人看的标签，而 inode\r\n才是文件的“身份证”。一个文件名必定指向一个 inode，通过 inode\r\n才能找到文件的实际内容。\r\n硬链接的本质是给一个已存在的 inode\r\n分配一个新的文件名。换句话说，它创建了一个指向同一个 inode\r\n的新指针。\r\n当你创建一个硬链接时，你并没有复制文件的内容，只是增加了一个引用该文件内容的方式。硬链接和源文件拥有完全相同的\r\ninode 号\r\n而软链接（也叫符号链接）则完全不同。它是一个独立的新文件，拥有自己的\r\ninode。这个文件的内容很特殊，它存储的是另一个文件或目录的路径。它就像\r\nWindows 系统中的“快捷方式”。\r\n用户和用户组\r\nwhoami 查看当前用户\r\nchmod 修改权限操作, 主要有两种方法: 第一种，文字设定法 chmod [who]\r\n[+|-|=] [mode] filename\r\n操作对象who可以是下述字母中的任一个或者它们的组合 u\r\n表示”用户(user)”，即文件或目录的所有者 g\r\n表示”同组(group)用户”，即与文件所有者有相同组ID的所有用户 o\r\n表示”其他(others)用户” a 表示”所有(all)用户”，它是系统默认值\r\n操作符号可以是： + 添加某个权限 - 取消某个权限 =\r\n赋予给定权限并取消其他所有权限（如果有的话） 例如, chmod u+rwx filename\r\n给文件filename的所有者添加读写执行权限\r\n第二种，数字设定法 chmod 操作码 filename\r\n(直接用操作码修改文件权限)\r\n例如, 对于file的权限 -rw- rw- r– 421 421 421\r\n三个组的权限都用二进制编号，比如要设置当前用户对文件的读写和执行权限，则当前用户的操作权限为4（读）+\r\n2（写）+ 1（执行） = 7. 用户组和其他用户的权限设置也是一样的\r\n对于file的当前权限-rw-rw-r–, 我们设置如下： 所有者 rwx = 7\r\n所有者所在组 rw = 6 其他用户 r = 4 操作码就是764, 即chmod 764\r\nfilename\r\nsudo adduser newusername 添加新用户 sudo chown username filename\r\n修改文件所有者 su username 切换当前用户为username sudo addgroup\r\ngroupname 添加新的用户组 sudo chgrp groupname filename\r\n修改文件所属用户组 sudo chown username:groupname filename\r\n同时修改文件所属用户和用户组 sudo deluser username 删除用户 sudo\r\ndelgroup groupname 删除用户组\r\nsudo su 切换root用户 sudo passwd username 设置用户密码\r\nfind 命令\r\nfind命令：找文件, 表达式为find [path] [option] action - -maxdepth\r\n指定搜索深度。应作为第一个参数出现。 - 例如, find ./ -maxdepth 1 -name\r\n“file.jpg”,\r\n查找当前目录下的所有后缀为.jpg且文件名包含file的文件 - -type\r\n按文件类型搜索 d/p/s/c/b/l/ f:普通文件 - 例如, find / -type f\r\n查找根目录下的所有普通文件 - -name 按文件名搜索 - 例如, find / -name\r\n“*.jpg” 查找根目录下的所有后缀为.jpg的文件 - -size 按文件大小搜索,\r\n单位：k、M、G - 例如, find /home/ziyipei -size +20M -size -50M -\r\n这里要注意，两个size一个都不能少，还有就是文件大小单位对大小写敏感 -\r\n-user 按文件所有者搜索 - -group 按文件所属用户组搜索 - -perm\r\n按文件权限搜索 - -mtime 按文件修改时间搜索,\r\n指的是文件内容最后一次修改的时间(modification), 单位：天(-n\r\n表示n天内修改的文件, +n 表示n天前修改的文件) - 例如, find /home/ziyipei\r\n-mtime -10 查找/home/ziyipei目录下最近10天内修改的文件 - -atime\r\n按文件访问时间搜索, 指的是文件最后一次被访问的时间,\r\n单位：天 - 如果使用-amin则单位为分钟, -amin -10\r\n表示最近10分钟内访问的文件 - -ctime\r\n按文件状态改变时间搜索,\r\n指的是文件元数据最后一次改变的时间(change), 单位：天 - -exec\r\n将find搜索的结果集执行某一指定命令。 - find /usr/ -name ‘tmp’\r\n-exec ls -ld {} ; - 这里的{}表示find搜索到的结果, ;表示命令结束,\r\n一般修改的地方就是-exec和;之间的命令, 其余的不变 - -ok: 以交互式的方式\r\n将find搜索的结果集执行某一指定命令\r\n-grep和xargs\r\ngrep命令：在文件中搜索指定的字符串, 默认是在当前目录下搜索,\r\n也可以指定目录或者文件搜索 - -r 递归搜索 - -i 忽略大小写 - -n\r\n显示匹配行的行号 例如, grep -r ‘copy’ ./ -n,\r\n递归查找当前目录下的所有文件中包含copy的行, 并显示行号 grep -r ‘copy’\r\n./README.md -n, 查找README.md文件中包含copy的行, 并显示行号\r\nps监控后台进程工作情况，默认只显示当前可以和用户交互的进程 ps aux,\r\n显示所有进程的详细信息,\r\n包括进程ID、用户、CPU占用率、内存占用率、启动时间、命令等(其中a表示所有进程,\r\nu表示用户, x表示显示所有进程) ps aux | grep ‘root’\r\n将进程结果集通过管道传递给grep命令,\r\n查找包含root的进程(注意使用grep搜索进程，有一条结果是搜索进程本身)\r\nxargs：用于将前一个命令的输出作为后一个命令的参数(不加-)\r\n可以和find结合, 将find搜索的结果集执行某一指定命令: find /usr/ -name\r\n‘tmp’ | xargs ls -ld , 这里的ls -l\r\n表示对find搜索到的每个文件执行ls -l命令 可以等价于find … -exec ls -l {}\r\n; 不同点在于当结果集合很大的时候，xargs会对结果进行分段处理,\r\n所以性能好些.\r\n但xargs也有缺陷，xargs默认用空格来分割结果集，当文件名有空格的时候，会因为文件名被切割失效\r\n所以当文件名中包含空格时，我们可以使用以下方法来避免这个问题： - 使用 -0\r\n选项来使得xargs指定文件名的结束符为 null 字符 - 使用 find 命令的 -print0\r\n选项来输出 null 字符结尾的文件名 - 例如, find /usr/ -name ‘tmp’\r\n-print0 | xargs -0 ls -l -\r\n第一个-print0指定结果集分隔为null，第二个-0指定xargs分隔为null\r\n创建名字带空格的文件方法: 第一个方法，文件名加引号\r\n第二个方法，转义空格为’ ’\r\n软件包安装\r\n下面只介绍利用互联网安装软件包的方法, 使用安装包进行软件安装先略过\r\nsudo apt install softname 一般的安装软件, 也可以使用别的包管理工具,\r\n如yum, dnf等 sudo apt update 更新软件列表 sudo apt remove softname\r\n卸载软件\r\n压缩和打包\r\n压缩命令有两个: gzip和bzip2. 两者都需要配合tar打包命令使用,\r\n而且这两个压缩的缺陷都是只能对单个文件进行压缩，一来不能压目录，二来不能打包\r\n第一种压缩方式：gzip tar zcvf 要生成的压缩包名 压缩材料\r\n(这里压缩包名一般以.tar.gz结尾) - 例如, tar zcvf test.tar.gz test.txt,\r\n压缩test.txt文件, 生成test.tar.gz压缩包\r\n上述命令实际上执行了两步，一个是gzip进行压缩: gzip filename\r\n(解压是gunzip zipfilename) 另一个是使用tar打包, 一般我们直接使用tar zcvf\r\n来打包压缩, 不需要先压缩再打包\r\n所以tar zcvf 是两条指令的结合版本. 对zcvf进行解释： z:zip，压缩\r\nc:create，创建\r\nv:vision，显示压缩过程，可以去掉，直接用zcf，但这样不显示压缩过程\r\nf:file，文件\r\nfile filename 查看文件来源\r\n第二种压缩方式：bzip2 tar jcvf 要生成的压缩包名 压缩材料\r\n(这里压缩包名一般以.tar.bz2结尾) - 例如, tar jcvf test.tar.bz2 test.txt,\r\n压缩test.txt文件, 生成test.tar.bz2压缩包\r\n上述命令实际上执行了两步，一个是bzip2进行压缩: bzip2 filename\r\n(解压是bunzip2 zipfilename) 另一个是使用tar打包\r\n可以看出两者的区别只在于压缩命令不同, gzip用的是z, bzip2用的是j,\r\n其余的包括生成文件的后缀也一样\r\n解压： 将压缩命令中的c –&gt; x tar zxvf 压缩材料 使用gzip解压 tar\r\njxvf 压缩材料 使用bzip2解压\r\n此外, 还可以通过Linux和Windows通用的rar和zip压缩, 但需要先安装: sudo\r\napt install rar zip\r\nrar a -r newdir.rar dir, 压缩dir目录, 生成newdir.rar压缩包(a表示添加,\r\n-r表示递归压缩子目录) unrar x newdir.rar 解压rar文件 zip -r newdir.zip\r\ndir, 压缩dir目录, 生成newdir.zip压缩包(-r表示递归压缩子目录) unzip\r\nnewdir.zip 解压zip文件\r\nsudo aptitude show softname 查看软件安装信息\r\n其他命令\r\nenv 查看环境变量 env | grep ‘PATH’ 和管道,\r\ngrep结合查看环境变量中PATH的值 jobs 查看操作系统当前运行了哪些用户作业\r\nkill 杀死进程, 例如 kill -9 1234, 这里的-9表示强制杀死进程,\r\n1234表示进程ID\r\ntop 文字版任务管理器 ifconfig 查看网卡信息 man 系统参考手册 man n\r\nname 在系统手册第n章查看name, 主要是以下几章: - 第一章是基本命令 -\r\n第二章是系统调用 - 第三章是库函数 - 第五章是文件格式和约定\r\nalias 给命令起别名, 例如 alias ll=‘ls -l’,\r\n这样就可以使用ll命令来代替ls -l\r\n","categories":["system","linux"],"tags":["system"]},{"title":"文件和系统调用","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E6%96%87%E4%BB%B6%E5%92%8C%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"系统调用简介和实现\r\n什么是系统调用(system call)\r\n系统调用，顾名思义，说的是操作系统提供给用户程序调用的一组特殊接口，用户程序可以通过这个特殊接口来获得操作系统内核提供的服务\r\n\r\n\r\nalt text\r\n\r\n系统调用的实现\r\n系统调用是属于操作系统内核的一部分，必须以某种方式提供给进程让它们去调用，相应的操作系统也有不同的运行级别–用户态和内核态，内核态可以毫无限制的访问各种资源，而用户态下的用户进程的各种操作都有限制，显然,\r\n属于内核的系统调用是运行在内核态下，那么如何切换到内核态呢？\r\n答案是软件中断(trap)，操作系统一般是通过软件中断从用户态切换到内核态\r\n系统调用和库函数的区别\r\n系统调用是操作系统内核提供的接口，用户程序通过这些接口来请求内核提供的服务，而库函数是编程语言提供的一组预定义函数，这些函数封装了一些常用的操作，简化了编程工作\r\n库函数主要由两类函数组成： 1. 不需要调用系统调用\r\n不需要切换到内核空间即可完成函数全部功能，如strcpy、bzero等字符串操作函数\r\n\r\n需要调用系统调用\r\n需要切换到内核空间，这类函数通过封装系统调用去实现相应的功能，如print、fread等\r\n\r\n错误处理函数\r\nerrno 是一个在 C 语言及其派生语言（如\r\nC++）的标准库中使用的全局变量或宏，用于存储操作系统或库函数在执行过程中遇到的最近一次错误代码(类型为int),\r\n不同的错误码表示不同的含义。 #include &lt;stdio.h&gt;#include &lt;errno.h&gt;  // 也可以#include &lt;cerrno&gt; (C++)void example_perror() {    FILE *fp;    fp = fopen(\"non_existent_file.txt\", \"r\");    if (fp == NULL) {        // 仅需传入一个自定义前缀字符串        perror(\"文件读取失败\");                // 预期输出可能类似于: 文件读取失败: No such file or directory    } else {        fclose(fp);    }}\r\n虚拟地址空间\r\n 如图是一张 Linux\r\n进程地址空间布局图, 核心划分是内核区与用户区: | 区域 | 地址范围\r\n| 作用与特性 | |————————|————|————————————————————————————————————–| |\r\n内核区 (Kernel Space) | 3G 到 4G | 存放 Linux\r\n内核的代码和数据。它是受保护的，用于运行内核程序，如内存管理、进程管理、设备驱动和\r\nVFS（虚拟文件系统）。用户程序不能直接读写这块区域，否则会触发段错误。 |\r\n| 用户区 (User Space) | 0 到 3G | 存放用户程序的代码和数据。这是\r\nint main(…)\r\n函数及其代码、数据、堆栈等执行的地方。用户程序的大部分操作都在这个区域内进行。\r\n|\r\n下面我们再介绍用户区内存段（ELF 文件加载区）:\r\n用户区从底部（低地址 0）向上依次排列着由 ELF（Executable and Linkable\r\nFormat，可执行文件格式）文件加载而来的各个数据段：\r\n\r\n代码和数据段 (Code &amp; Data)\r\n这三个段通常是静态分配的，它们的大小在程序编译时就已经确定：\r\n\r\n\r\n.text\r\n(代码段)：存放程序的机器指令（二进制机器指令）。该区域是只读的，以防止程序意外修改自己的代码。\r\n\r\n图中标注：受保护的地址\r\n(0∼4K)，这是为了捕获对空指针的解引用操作，防止低地址被使用。\r\n\r\n.rodata / .data\r\n(已初始化全局变量)：存放程序中已初始化的全局变量和静态变量。\r\n.bss\r\n(未初始化全局变量)：存放程序中未初始化的全局变量和静态变量。在程序加载时，这些变量会被清零处理。\r\n\r\n这几个段共同构成了程序的基本静态结构，其中代码段的只读保护是程序安全的重要保障。\r\n\r\n堆空间 (Heap): 用于程序的动态内存分配（如 C 语言中的 malloc 或 C++\r\n中的 new）。\r\n\r\n它从低地址向高地址（图中的向上箭头）增长，其大小在程序运行时动态变化。并且堆空间通常是用户区中最大的一块区域。\r\n\r\n共享库/动态库 (Shared Libraries/Dynamic Libraries):\r\n存放程序运行时需要链接的共享库文件（如 libc.so - C\r\n标准库）。\r\n\r\n多个进程可以共享同一份库的代码和数据，从而节省物理内存。共享库通过系统调用（如\r\nexecve）或动态加载器，将 C 标准库、Linux 系统 I/O\r\n函数等加载到这里，供用户代码调用。\r\n\r\n而静态库的代码则直接链接到程序的代码段中, 存储在.text 段内。\r\n\r\n\r\n栈空间 (Stack):\r\n用于存放函数调用时的局部变量、函数参数、返回地址等。\r\n\r\n它从高地址向低地址（图中的向下箭头）增长。栈空间相对较小，一旦耗尽会导致栈溢出（Stack\r\nOverflow）。\r\n\r\n堆和栈的对向增长（一个向上，一个向下）机制可以有效地利用中间的虚拟地址空间，并在它们相遇之前，为程序提供了最大的灵活性。\r\n\r\n\r\n命令行参数和环境变量: 位于用户区最高端，存放着程序启动时传递给 main\r\n函数的参数（如 argc,argv[…]）和系统的环境变量（env）。\r\n\r\n文件描述符\r\n 如图展示了 Linux\r\n进程如何通过文件描述符 (File Descriptor, FD) 机制来管理和访问文件及 I/O\r\n资源。\r\n文件描述符的本质是一个非负整数（通常是 0 到 1023\r\n之间），它在进程的上下文中，是用来唯一标识一个打开的文件、套接字（socket）\r\n或其他 I/O 资源(本质上它们都是文件)的索引。\r\n右图的文件描述符表存储在PCB中, PCB(process control\r\nblock)是每个 Linux\r\n进程都有的进程控制块，它位于内核区(Linux kernel)内,\r\n包含了一个指向该进程文件描述符表的指针。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n文件描述符 (FD)\r\n名称\r\n对应 I/O 资源\r\n默认用途\r\n\r\n\r\n\r\n\r\n0\r\nSTDIN_FILENO\r\n标准输入\r\n默认为只读模式，通常指向键盘输入或文件重定向。\r\n\r\n\r\n1\r\nSTDOUT_FILENO\r\n标准输出\r\n默认为只写模式，通常指向终端显示或文件重定向。\r\n\r\n\r\n2\r\nSTDERR_FILENO\r\n标准错误\r\n默认为只写模式，用于输出程序的错误和诊断信息。\r\n\r\n\r\n3 及以上\r\n正常文件 I/O\r\n文件、套接字、管道等\r\n用于进程通过 open()、socket() 等系统调用打开的资源。\r\n\r\n\r\n\r\n如图所示, FD 0、FD 1、FD 2 是所有进程默认打开的三个标准流.\r\n而当程序调用 open() 或 socket() 等系统调用(进入内核态)打开一个新的 I/O\r\n资源时，内核会在PCB中查找该进程的文件描述符表。它会从 3\r\n开始，寻找最小且当前未被占用的整数作为新的文件描述符分配给该资源。\r\n简而言之，用户进程不直接操作文件，而是操作文件描述符，由内核负责将这个数字与实际的\r\nI/O 资源关联起来\r\n常用文件IO函数\r\nopen函数\r\n#include &lt;sys/types.h&gt;#include &lt;sys.stat.h&gt;#include &lt;fcntl.h&gt;int open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);参数：    pathname：文件的路径及文件名    flags：打开文件的行为标识(只读、只写、可读可写)    mode：这个参数只有在文件不存在时有效,指新建文件时指定文件的权限(数字指定, 如 0644代表rw-r--r--)返回值：      成功：返回打开的文件描述符      失败：-1\r\n其中flags参数常用的取值有： 必选项 (Access Modes) |\r\n取值 (Flag) | 含义 (Meaning) | |————-|———————–| | O_RDONLY |\r\n以只读的方式打开 | | O_WRONLY | 以只写的方式打开 | | O_RDWR |\r\n以可读、可写的方式打开 |\r\n可选项 (Creation/Status Flags):\r\n可以和必选项按位或（使用 | 运算符）起来使用。 | 取值\r\n(Flag) | 含义 (Meaning) | |————-|———————–| | O_CREAT |\r\n文件不存在则创建文件，使用此选项时需使用 mode 说明文件的权限 | | O_EXCL\r\n| 如果同时指定了 O_CREAT，且文件已经存在，则出错 | | O_TRUNC |\r\n如果文件存在，则清空文件内容 | | O_APPEND | 写文件时，数据添加到文件末尾\r\n| | O_NONBLOCK | 对于设备文件，以 O_NONBLOCK 方式打开可以做非阻塞 I/O\r\n|\r\n// 打开和关闭文件int main(void){    int fd = -1;    // 1. 以只读的方式打开一个文件，如果文件不存在就报错    fd = open(\"txt\", O_RDONLY);     // 2. 以只写的方式打开一个文件，如果文件存在就直接打开，如果文件不存在就新建一个文件    /fd = open(\"txt\", O_WRONLY | O_CREAT, 0644);     // 3. 以只写的方式打开一个文件，如果文件存在就报错，如果文件不存在就新建一个文件    fd = open(\"txt\", O_WRONLY | O_CREAT | O_EXCL, 0644);     // 4. 以读写的方式打开一个文件，如果文件存在就打开，如果文件不存在就新建一个文件    fd = open(\"txt\", O_RDWR | O_CREAT, 0644);     // 5. O_TRUNC 清空文件内容    // 如果文件不存在就新建一个文件，如果文件存在就打开之后清空    fd = open(\"txt\", O_WRONLY | O_TRUNC | O_CREAT, 0644);     // 6. O_APPEND 追加的方式    // 以只写和追加的方式打开一个文件，如果文件不存在会报错    fd = open(\"txt\", O_WRONLY | O_APPEND);     close(fd);    return 0;}\r\nclose函数\r\n#include &lt;unistd.h&gt;int close(int fd);功能：    关闭已打开的文件参数：    fd：文件描述符，open()的返回值返回值：    成功：0    失败：-1，并设置errno\r\nwrite函数\r\n#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);功能：    把指定数目的数据写到文件(fd), 注意 write() 函数会覆盖从当前文件偏移量开始的现有数据(与 lseek() 函数结合使用时尤为重要)。参数：    fd：文件描述符    buf：数据首地址    count：写入数据的长度(字节)返回值：    成功：实际写入数据的字节个数    失败：-1\r\n示例代码: // 写文件int main(void){    int fd = -1;    int ret = -1;  // write的返回值        char *str = \"hello itcast\";        // 1. 以只写的方式打开一个文件, 如果文件不存在就新建一个文件    fd = open(\"txt\", O_WRONLY | O_CREAT, 0644);    if (-1 == fd)    {        perror(\"open\");        return 1;    }        printf(\"fd = %d\\n\", fd);        // 2. 写文件    ret = write(fd, str, strlen(str));    if (-1 == ret)    {        perror(\"write\");        return 1;    }        printf(\"write len: %d\\n\", ret);        // 3. 关闭文件    close(fd);        return 0;}\r\nread函数\r\n#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);功能：    把指定数目的数据读到内存(缓冲区)参数：    fd：文件描述符    buf：内存首地址, 用于存储读取到的数据    count：读取的字节个数返回值：    成功：实际读取到的字节个数    失败：-1\r\n示例代码: #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;     // 包含 read, close 函数#include &lt;fcntl.h&gt;      // 包含 O_RDONLY, O_CREAT 等宏#include &lt;errno.h&gt;      // 包含 errno 定义#define BUF_SIZE 100    // 定义读取缓冲区的大小int main(void){    int fd = -1;    ssize_t ret = -1;       // 使用 ssize_t 类型存储 read/write 返回值    char buffer[BUF_SIZE] = {0}; // 用于存储读取到的数据，并初始化为 0    // 1. 以只读的方式打开一个文件    fd = open(\"data.txt\", O_RDONLY);     if (-1 == fd)    {        perror(\"open:\");        return 1; // 退出程序并返回错误码    }    printf(\"成功打开文件，文件描述符 (FD) 为: %d\\n\", fd);        // 2. 读取文件    // 从 fd 对应文件中读取最多 BUF_SIZE-1 个字节到 buffer 中    ret = read(fd, buffer, BUF_SIZE - 1); // 留出 1 字节用于添加字符串结束符 '\\0'    if (-1 == ret)    {        perror(\"read:\");        // read 失败后，必须关闭文件，否则会造成资源泄露。        close(fd);         return 1;    }        // 3. 处理读取结果        // 步骤说明：将读取到的字节数 ret 对应的位置设为字符串结束符 '\\0'，    // 以便将读取到的数据作为一个C字符串打印出来，确保打印的准确性。    buffer[ret] = '\\0';         printf(\"读取到的字节长度 (ret): %zd\\n\", ret);    printf(\"文件内容:\\n%s\\n\", buffer);        // 4. 关闭文件    close(fd);        return 0;}\r\nlseek函数\r\n#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;typedef long off_t;  // 32位系统中off_t是long类型, 64位系统中是long long类型, long是4字节, long long是8字节off_t lseek(int fd, off_t offset, int whence);功能:    改变文件的偏移量, 实现文件的随机访问(这很重要, lseek()本身不进行读写操作，它唯一的作用是修改内核记录的文件偏移量)参数:    fd: 文件描述符    offset: 根据 whence 来移动的位数(偏移量), 可以是正数, 也可以是负数,        如果正数, 则相对于 whence 往右移动, 如果是负数, 则相对于 whence 往左移动。    whence: 其取值如下:        SEEK_SET: 从文件开头移动 offset 个字节        SEEK_CUR: 从当前位置移动 offset 个字节        SEEK_END: 从文件末尾移动 offset 个字节返回值:    若 lseek 成功执行, 返回新的偏移量(绝对偏移量, 即从文件开头算起的字节数)    如果失败, 返回 -1\r\n\r\n如果 lseek() 将文件偏移量设置到当前文件末尾之后（例如文件长 10\r\n字节，你 lseek 到 100），然后执行 write 操作，文件尺寸会增大到 101\r\n字节。中间跳过的 90 个字节是未初始化的，通常被称为“文件空洞”（File\r\nHole）。\r\n\r\n示例代码: #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;void lseek_example() {    int fd;    char buffer[20] = {0};    ssize_t ret;    // 我们假设已经有一个名为 sample.txt 的文件，内容为: 0123456789    fd = open(\"sample.txt\", O_RDWR);    if (fd == -1) {        perror(\"open sample.txt\");        return;    }        // 1. 使用 SEEK_SET     // 步骤说明：SEEK_SET 表示从文件起始位置 (0) 开始计算偏移量。    off_t new_offset = lseek(fd, 4, SEEK_SET);    if (new_offset == -1) {        perror(\"lseek SEEK_SET failed\");    } else {        printf(\"1. SEEK_SET: 成功将偏移量设置为: %ld\\n\", new_offset); // 输出 4            // 从当前位置 (4) 读取 3 个字节        ret = read(fd, buffer, 3);         buffer[ret] = '\\0';        printf(\"   读取内容: %s (从 '4' 开始读 3 个)\\n\", buffer); // 输出 456    }    // 此时文件偏移量位于 4 + 3 = 7 处        // 2. 使用 SEEK_CUR    // 步骤说明：SEEK_CUR 表示从当前偏移量 (7) 开始计算偏移量。    new_offset = lseek(fd, 2, SEEK_CUR);    if (new_offset == -1) {        perror(\"lseek SEEK_CUR failed\");    } else {        printf(\"2. SEEK_CUR: 成功将偏移量移动到: %ld\\n\", new_offset); // lseek 成功后，它返回的是新的绝对偏移量, 因此输出 9            // 从当前位置 (9) 写入数据 'A'        ret = write(fd, \"A\", 1);         printf(\"  写入内容: A\\n\"); // sample.txt 变为 012345678A    }    // 此时文件偏移量位于 9 + 1 = 10 处    // 3. 使用 SEEK_END    // 步骤说明：SEEK_END 表示从文件末尾开始计算偏移量。    new_offset = lseek(fd, 0, SEEK_END);  // 0 表示不移动，即只是定位到文件末尾。    if (new_offset == -1) {        perror(\"lseek SEEK_END failed\");    } else {        printf(\"3. SEEK_END: 成功将偏移量移动到文件末尾: %ld\\n\", new_offset); // 输出 10            // 从文件末尾写入数据 'Z'，这将增大文件尺寸        ret = write(fd, \"Z\", 1);        printf(\"在文件末尾追加内容: Z\\n\"); // sample.txt 变为012345678AZ    }    // 此时文件偏移量位于 10 + 1 = 11 处    close(fd);    printf(\"--- 文件操作完成 ---\\n\");    // 实际文件内容现在为 012345678AZ}\r\n文件描述符复制\r\n在 Linux/Unix 系统编程中，dup() 和 dup2()\r\n是两个重要的系统调用，用于复制（或称为重定向）文件描述符。\r\ndup函数\r\n#include &lt;unistd.h&gt;int dup(int oldfd);功能:    用于根据旧的文件描述符复制出一个新的文件描述符, 原始的文件描述符 oldfd 和新的文件描述符都将指向同一个文件参数:    oldfd: 需要复制的文件描述符返回值:    成功: 返回新的文件描述符    失败: -1\r\nint main(void){     int fd = -1;    int newfd = -1;    // 1. 打开文件    fd = open(\"txt\", O_RDWR | O_CREAT, 0644);    if (-1 == fd)    {         perror(\"open\");         return 1;     }     printf(\"fd = %d\\n\", fd);     // 文件描述符复制     newfd = dup(fd);     if (-1 == newfd)     {         perror(\"dup\");        return 1;     }     printf(\"newfd = %d\\n\", newfd);     // 2. 操作     write(fd, \"ABCDEFG\", 7);     write(newfd, \"1234567\", 7);     // 3. 关闭文件描述符     close(fd);     close(newfd);     return 0;}\r\n由于 newfd 和 fd 指向同一个文件,\r\n共享同一文件偏移量，因此这次写入操作将从上一次写入结束的位置开始。也就是说，1234567\r\n会紧接着 ABCDEFG 写入文件，文件内容最终是 ABCDEFG1234567\r\ndup2函数\r\n#include &lt;unistd.h&gt;int dup2(int oldfd, int newfd);功能:    将 oldfd 复制到 newfd, 并且newfd 的值可以人为指定. 如果 newfd 已经被打开, 则先调用 close() 关闭此描述符，断开它与原文件的关联，然后再使用这个合法的数字作为新的文件描述符。参数:    oldfd: 需要复制的文件描述符    newfd: 目标文件描述符, 这个描述符的值可以指定。返回值:    成功: 返回新的文件描述符    失败: -1\r\ndup2() 最常见的用途是将标准 I/O 流（FD 0、1、2）重定向到文件。\r\nint file_fd = open(\"output.log\", O_WRONLY | O_CREAT | O_TRUNC, 0644); if (file_fd == -1) { /* 错误处理 */ }// 步骤说明：使用 dup2 将 标准输出 (FD 1) 替换为 file_fd 指向的文件。// 1. 如果 FD 1 已经打开（通常是终端），dup2 会先关闭它, 意味着无法通过FD 1 连接到终端。// 2. 然后，它使 FD 1 指向和 file_fd 相同的资源。dup2(file_fd, 1); // 现在，所有原本写入标准输出 (原先的FD 1) 的数据，都会被写入 output.log 文件中。printf(\"这条信息现在写入了 output.log 文件中。\\n\"); close(file_fd); // 关闭原始的文件描述符，但 FD 1 作为新的log文件描述符仍然有效 ### fcntl函数 #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* arg */);功能:    改变已打开的文件的性质，fcntl 针对文件描述符提供控制功能参数:    fd: 文件描述符    cmd: 控制命令        F_DUPFD: 复制文件描述符，类似于 dup()        F_GETFD: 获取文件描述符标志        F_SETFD: 设置文件描述符标志        F_GETFL: 获取文件状态标志和访问模式        F_SETFL: 设置文件状态标志返回值:    成功: 返回值取决于具体的 cmd    失败: -1\r\n目录相关操作\r\n","categories":["system","linux"],"tags":["system"]},{"title":"虚拟内存","url":"/2025/10/01/system/computer-architecture/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","content":"虚拟地址空间\r\n虚拟内存 (Virtual Memory)\r\n是现代操作系统中的一个重要概念。它通过将程序使用的地址空间虚拟化，使得每个进程都拥有一个独立的、连续的地址空间，从而实现了内存保护、内存共享和更高效的内存利用。\r\n目前,\r\n一个进程的虚拟地址空间通常被划分为以下几个部分:\r\n+-------------------+  (高地址)|      内核空间     |  &lt;- 内核专用地址空间, 用户态进程无法访问+-------------------+ |       栈 (Stack)  |  &lt;- 向下增长 (Grows Down)|        ...        || (未使用的虚拟内存) ||        ...        |+===================+  &lt;- 当前的 \"分断\" (Program Break)  &lt;-- 堆的顶部|       堆 (Heap)   |  &lt;- 向上增长 (Grows Up)|        ...        || (未使用的虚拟内存) ||        ...        |+-------------------+|    全局/静态数据  |  &lt;- 固定大小+-------------------+|       代码段      |  &lt;- 固定大小+-------------------+  (低地址) 也就是说,\r\n在进程的虚拟地址空间中不仅有用户代码和数据,\r\n还有操作系统内核的代码和数据。但用户态进程只能访问属于自己的那部分地址空间（代码段、数据段、堆和栈），无法访问内核空间。\r\n对于内核空间, 其基本组成分为两部分: - 全局共享区\r\n(Shared &amp; Static Area) -\r\n这部分内存在所有进程的虚拟地址空间中都是一样的，并且它们指向相同的物理内存。\r\n- 内核代码 (.text)：\r\n操作系统本身的代码，如系统调用处理函数、switch()\r\n函数、调度器、驱动程序等。 - 内核全局数据 (.data, .bss)： - 进程列表\r\n(Process List)： 一个全局的链表或数组，串联了所有的 PCB。 - PCB\r\n结构体本身： PCB（如 Linux 的\r\ntask_struct）本身通常也存储在这里（或者在内核动态分配的内存中）。 -\r\n其他全局数据（如物理内存管理信息、文件表等）。\r\n\r\n进程专属区 (Per-Process Area)\r\n\r\n这部分在虚拟地址空间中可能处于特定范围，但每个进程的这部分虚拟地址，都指向完全不同的物理内存。\r\n主要是内核栈 (Kernel Stack)：\r\n\r\n进程 A 的内核栈 (K-Stack A)\r\n进程 B 的内核栈 (K-Stack B)\r\n…等等。\r\n\r\nOS 在创建进程 A 时，会从物理内存中分配一块作为 A 的内核栈;\r\n在创建进程 B 时，会从物理内存中分配另一块作为 B 的内核栈。\r\n\r\n\r\n其基本结构如下所示：\r\n+-------------------+  (高地址)|      内核空间       |  &lt;- 内核专用地址空间, 用户态进程无法访问|  +---------------+ ||  |  进程 A 内核栈 | |  &lt;- 进程 A 的内核栈 (K-Stack A)|  +---------------+ ||  +---------------+ ||  |  进程 B 内核栈 | |  &lt;- 进程 B 的内核栈 (K-Stack B)|  +---------------+ ||       ...          ||     进程列表       |  &lt;- 全局的 PCB 列表|    内核代码和数据   |  &lt;- 全局共享的内核代码和数据+-------------------+\r\n虚拟地址空间的由来\r\n早期的计算机系统中,\r\n操作系统加载在物理内存的低地址，唯一的运行程序（进程）加载在它之后.\r\n这种设计存在几个严重的问题: 1. 内存保护缺失:\r\n如果程序有bug, 它可能会意外地覆盖操作系统的代码或数据, 导致系统崩溃. 2.\r\n内存利用率低:\r\n程序必须完全装入内存才能运行, 这限制了程序的大小和数量.\r\n3. 只有一个程序能运行, 无法实现多任务.\r\n后来,\r\n为了提高昂贵硬件的利用率（Efficiency）和满足用户对交互性（Interactivity）的需求，系统发展出了多道程序和时分共享。\r\n- 多道程序设计 (Multiprogramming): 允许多个程序同时驻留在物理内存中,\r\n操作系统负责调度它们的执行. - 时分共享 (Time-Sharing):\r\n通过快速切换程序的执行, 给用户一种“同时运行多个程序”的感觉.\r\n但是这样还是没有解决问题：当多个进程共享物理内存时，保护（Protection）成了关键问题。必须防止一个进程读取或修改另一个进程（或操作系统）的内存。\r\n为了解决上述保护和易用性问题，操作系统引入了“地址空间”这一抽象,\r\n每个进程都拥有自己独立的虚拟地址空间 (Virtual Address\r\nSpace)。这一设计有三大目标: -\r\n透明（Transparency）：程序不应感知到内存被虚拟化了。它应该感觉自己独占了内存。\r\n-\r\n效率（Efficiency）：虚拟化（尤其是地址转换）必须在时间（速度快）和空间（额外开销小）上都高效。\r\n-\r\n保护（Protection）：必须确保进程之间隔离（Isolation）。任何进程都不能访问其自身地址空间之外的内存。\r\n初版地址转换\r\n在引入虚拟地址空间后，操作系统需要一种机制将虚拟地址\r\n(Virtual Address) 转换为物理地址 (Physical\r\nAddress)。也就是说,\r\n操作系统需要为每个进程提供一个私有的、从0开始的地址空间（Address\r\nSpace）抽象。但在物理上，多个进程的地址空间必须“塞”进同一个物理内存中。\r\n本章提出的解决策略是：基于硬件的地址转换（Hardware-based\r\nAddress Translation）。\r\n核心思想：不再让进程直接访问物理内存。相反，进程生成的所有地址（称为虚拟地址）都必须经过一个硬件单元的“翻译”，将其转换为实际的物理地址。这个硬件单元通常集成在\r\nCPU 内部，称为内存管理单元 (Memory Management\r\nUnit, MMU)。 -\r\n硬件（MMU）：负责每一次内存访问的快速翻译。（实现高效）\r\n- 操作系统（OS）：负责设置硬件，管理内存分配与回收。（实现控制）\r\n动态重定位（基址+界限）是地址转换的初级版本。它在MMU中使用两个寄存器:\r\n- 基址寄存器（Base Register）： -\r\n功能：存储该进程地址空间在物理内存中的起始地址（例如\r\n32KB）。 -\r\n作用：解决重定位（Relocation）问题。它在运行时动态地将虚拟地址“偏移”到正确的物理位置。\r\n- 界限寄存器（Bound / Limit Register）： -\r\n功能：存储该进程地址空间的大小（例如 16KB）。 -\r\n作用：解决保护（Protection）问题。它划定了进程可以访问的合法虚拟地址范围。\r\n地址转换的详细步骤\r\n当一个进程在用户模式下运行时，它产生的每一个内存访问（无论是取指令、读数据还是写数据）都会被硬件（MMU）自动按以下步骤处理：\r\n&gt; 前提：OS在切换到该进程时，已提前将该进程的\r\nbase（例如 32KB）和 bound（例如\r\n16KB）值加载到MMU的寄存器中。\r\n进程发出一个虚拟地址（VA），例如 VA = 15KB：\r\n第1步：硬件进行保护检查（界限检查）,\r\n主要是检查 VA 是否在合法范围内。 - if (VA &lt; 0 OR VA &gt;= bound) -\r\n解释：检查该虚拟地址是否小于0（非法），或者是否大于等于地址空间的大小（bound）。示例：检查\r\n15KB 是否 &gt;= 16KB？否。检查通过。 - 如果失败（例如 VA = 17KB）：17KB\r\n&gt;=\r\n16KB，检查失败。硬件会立即停止该指令，触发一个异常（Exception），并将控制权交给操作系统（进入内核模式）。OS的“越界”异常处理程序会接管，通常的反应是终止这个行为不端的进程（这就是“段错误”的来源之一）。\r\n第2步：硬件进行地址转换（基址重定位）\r\n- 如果保护检查通过，硬件（MMU）使用基址寄存器计算物理地址（PA）。 -\r\nPhysicalAddress = VirtualAddress + base -\r\n解释：通过将虚拟地址与基址相加，将其重定位到物理内存中的正确位置。示例：PA\r\n= 15KB + 32KB = 47KB。\r\n第3步：访问物理内存 - 硬件（MMU）将计算出的物理地址 47KB\r\n发送到内存总线，进行数据读取或写入。 -\r\n关键点：这整个“检查-转换”过程完全由硬件在每一次内存访问中自动完成，速度极快（只有一个加法和一次比较），对进程完全透明。\r\n硬件与操作系统的职责划分\r\n要让这个机制工作，硬件和操作系统必须紧密配合。\r\n\r\n硬件（CPU/MMU）的职责\r\n\r\n两种CPU模式：用户模式（运行进程，受限制）和内核模式（运行OS，有特权）。\r\n基址和界限寄存器：提供这两个MMU寄存器。\r\n特权指令：提供只能在内核模式下运行的指令，用于修改 base 和 bound\r\n寄存器。这是为了保护。如果用户进程能随意修改 base\r\n寄存器，它就能访问任意物理内存，整个保护机制就失效了。\r\n异常机制：当发生保护违例（如越界）或特权违例（如用户模式试图修改\r\nbase）时，CPU必须能触发异常，将控制权交给OS。\r\n\r\n操作系统（OS）的职责\r\n\r\n进程创建时：OS必须在物理内存中查找一个连续的、足够大的空闲块（通过管理一个空闲列表\r\nFree List），来存放新进程的地址空间。\r\n\r\n这个块的起始地址将作为该进程的 base 值，块的大小将作为 bound\r\n值。\r\n空闲列表是 OS\r\n维护的一个数据结构，记录了哪些物理内存块是空闲的，哪些是已分配的。\r\n\r\n进程终止时：OS必须回收该进程占用的物理内存块，并将其放回空闲列表，以备将来使用。\r\n上下文切换时（至关重要）：\r\n\r\n保存（切换出）：当停止进程A时，OS（在内核模式下）必须读取\r\nbase 和 bound\r\n寄存器的当前值，并将它们保存到进程A的进程控制块（PCB）中。\r\n恢复（切换入）：当启动进程B时，OS（在内核模式下）必须从进程B的PCB中取出它之前保存的\r\nbase 和 bound\r\n值，并使用特权指令将它们加载到MMU的硬件寄存器中。\r\n\r\n异常处理时：\r\n\r\nOS在启动时就必须告诉硬件，当异常发生时，应该跳转到哪里去执行OS的异常处理程序（Handler）。\r\n当硬件触发异常（如越界访问），OS的异常处理程序被激活，负责决定如何响应（通常是终止犯错的进程）。\r\n\r\n\r\n\r\n总之,\r\n本章介绍的动态重定位（基址+界限）机制是实现虚拟内存的伟大开端。\r\n优点： - 高效：硬件执行转换，开销极小。 -\r\n保护：bound 寄存器提供了强大的进程隔离和OS保护。 -\r\n透明：进程完全不知道自己的地址被转换了。\r\n致命缺陷： -\r\n空间效率低下：该机制假设地址空间是连续存放的,\r\n但实际情况往往不是这样。这会导致严重的内部碎片问题: -\r\n外部碎片（External\r\nFragmentation）：随着进程的创建和终止，物理内存会变得支离破碎，难以找到足够大的连续块来满足新进程的需求。\r\n- 内部碎片（Internal\r\nFragmentation）：已分配的内存块中，未被使用的部分也会浪费掉。因为\r\nbase 和 bound\r\n机制要求为整个地址空间（从0到bound）分配一块连续的物理内存，所以那块未使用的“栈堆之间”的巨大空洞，也必须占用宝贵的物理内存。这造成了极大的浪费。\r\n这个“内部碎片”问题，就是下一章（分段）试图解决的核心问题。\r\n分段\r\n上一章遗留的问题是,\r\n如何高效地支持一个稀疏的地址空间，而不为这些未使用空间分配宝贵的物理内存？\r\n这一章提出的解决方案是泛化（Generalize）基址/界限机制。\r\n- 旧方法：使用一个 base/bound 对来管理整个地址空间。 -\r\n新方法（分段）：鉴于内存的使用是按照逻辑段（如代码段、数据段、堆段、栈段）划分的,\r\n我们可以为每个逻辑段分别维护一对 base/bound 寄存器。\r\n分段 (Segmentation)\r\n是对动态重定位（基址+界限）机制的改进。它将进程的地址空间划分为多个逻辑段\r\n(Segment)，每个段都有自己的基址和界限。这样,\r\n只有被使用的段才需要分配物理内存,\r\n未使用的段则不占用任何物理内存, 从而大大减少了内部碎片。\r\n一个典型的进程有3个逻辑段：代码段（Code）、堆段（Heap）和栈段（Stack）。\r\n通过分段，操作系统现在可以将这三个段放置到物理内存中三个不同的、非连续的位置。栈和堆之间那块巨大的“未使用”空洞，根本不需要占用任何物理内存。这就完美地解决了内部碎片问题。\r\n硬件机制：分段下的地址转换\r\n要支持分段，硬件（MMU）必须变得更复杂。它不再是只有一对 base/bound\r\n寄存器，而是在MMU中内置了多对 base/bound\r\n寄存器（例如，一个用于代码，一个用于堆，一个用于栈）。\r\n当进程发出一个虚拟地址时，硬件（MMU）如何知道这个地址属于哪个段（是代码、堆还是栈）？在该段内的偏移量（Offset）是多少？\r\n本章介绍了一种显式（Explicit）的方法：使用虚拟地址的最高几位来标识段。\r\n虚拟地址的结构：硬件将虚拟地址（VA）在内部“解析”为两部分： VA = [\r\n段标识符 (Segment Identifier) |\r\n段内偏移量 (Offset) ]\r\n假设14位虚拟地址空间, 我们使用最高2位作为“段标识符”：00 -&gt; 代码段,\r\n01 -&gt; 堆段, 10 -&gt; (未使用), 11 -&gt; 栈段;\r\n剩下的12位作为“段内偏移量”。\r\n假设MMU中存储着下列值：\r\n\r\n\r\n\r\n段类型\r\n基址 (Base)\r\n界限 (Bound)\r\n\r\n\r\n\r\n\r\n代码段\r\n0KB\r\n8KB\r\n\r\n\r\n堆段\r\n34KB\r\n2KB\r\n\r\n\r\n栈段\r\n64KB\r\n4KB\r\n\r\n\r\n\r\n当进程发出一个虚拟地址时，硬件（MMU）按以下步骤进行处理： &gt;\r\n前提：OS在切换到该进程时，已提前将该进程的各段 base 和\r\nbound 值加载到MMU的寄存器中。\r\n当进程发出虚拟地址 VA = 4200 (二进制 01 0000 0110 1000) 时：\r\n第1步：硬件提取段标识符 - 硬件查看最高2位，发现是\r\n01。 - 硬件立即知道这个地址属于堆段。它将使用堆的 base 和 bound\r\n寄存器。\r\n第2步：硬件提取偏移量 - 硬件查看剩下的12位，0000\r\n0110 1000。 - 这是十进制的\r\n104。所以这个地址是“堆段内的第104个字节”(本书使用字节寻址)。\r\n第3步：硬件进行保护检查（界限检查） - 硬件将 Offset\r\n(104) 与堆的 bound 寄存器（2KB，即 2048）进行比较。 - if (Offset &gt;=\r\nbound), 104 &lt; 2048。检查通过。 - 如果失败（例如，访问 VA =\r\n7KB，其偏移量会超过 2KB），硬件会立即触发异常（即段错误\r\n/ Segmentation Fault），操作系统将介入并终止该进程。\r\n第4步：硬件进行地址转换（基址重定位） -\r\n如果保护检查通过，硬件将 Offset 与堆的 base\r\n寄存器相加。 - PhysicalAddress = Offset + base, 这里 PA = 104 + 34KB (即\r\n34816) = 34920。\r\n第5步：访问物理内存 - MMU将计算出的物理地址 34920\r\n发送到内存总线。\r\n分段机制的扩展与特性\r\n\r\n特殊情况：栈的处理\r\n\r\n栈是反向增长的（即从高地址向低地址增长）,\r\n这需要额外的硬件支持。硬件为每个段增加一个“增长方向”位（例如，1代表向上增长，0代表反向增长）。\r\n当硬件识别到这是一个栈段（例如 VA 高位为\r\n11）时，它会启用一套不同的翻译逻辑： - Offset\r\n会被计算为负值（例如，从段的最大可能大小中减去）。 -\r\nPhysicalAddress = base + NegativeOffset - bound\r\n检查也会相应调整（例如，检查负偏移量的绝对值是否超过了段大小）。\r\n例如, 当进程发出 VA = 1100 0000 0000 1000 (即 12KB) 时: - 段标识符 =\r\n11 -&gt; 栈段 - 偏移量 = 0000 0000 1000 = 8 - 保护检查: 8 &lt; 4KB\r\n(bound) 通过 - 地址转换: PA = base + (-8) = 64KB - 8 = 65528 -\r\n访问物理内存地址 65528。\r\n这种设计允许栈从高地址向低地址增长，同时仍然利用分段的保护和重定位机制。\r\n\r\n新增优势：支持共享\r\n\r\n分段机制带来一个巨大的额外好处：内存共享。如果代码段是只读的，那么让多个进程共享同一块物理内存中的代码是完全安全的。\r\n硬件支持：为每个段增加保护位（Protection Bits），例如\r\nRead、Write、Execute。 - 代码段的保护位设置为 R-X（只读、可执行）。 -\r\n堆段的保护位设置为 RW-（可读、可写）。 - 栈段的保护位设置为\r\nRW-（可读、可写）。\r\n举例说明：假设有3个进程 P1、P2、P3，它们都运行同一个程序（例如 printf\r\n函数）。每个进程都有自己的堆和栈段，但它们的代码段是相同的。 -\r\n物理内存中，OS将一个共享库（例如 printf）的代码加载到物理内存A处一次。 -\r\n当进程1、2、3运行时，OS只需将它们各自的代码段 base\r\n寄存器都设置为指向物理地址A，并将保护位设为\r\nR-X（只读、可执行）。\r\n结果：内存被极大节省，而进程间的隔离性（因为它们都不能写这块内存）仍然保持。\r\n操作系统（OS）的职责与新问题\r\n分段机制虽然解决了内部碎片，但也给OS带来了新的、更严峻的挑战。 -\r\n上下文切换：OS的工作量变大了。在切换进程时，它现在必须保存和恢复所有的段寄存器（Code\r\nbase/bound、Heap base/bound、Stack\r\nbase/bound）到各自的PCB中。 -\r\n空闲空间管理：这是分段引入的致命缺陷。\r\n新的致命缺陷：外部碎片 -\r\n内部碎片（已解决）：发生在已分配的内存块内部的未使用空间（如栈堆之间的空洞）。\r\n-\r\n外部碎片（新问题）：发生在已分配的内存块之间的未使用空间。\r\n-\r\n问题根源：分段机制导致OS在物理内存中分配大小不等（Variable-sized）的块（代码段2KB，堆段500KB，栈段8KB…）。\r\n-\r\n当进程运行、终止、再运行…物理内存会被这些大小不一的段“切割”得支离破碎。最终，空闲内存变成了许多不连续的小“洞”（Holes）。\r\n后果是，系统可能总共有 24KB 的空闲内存，但这 24KB 是由三个分散的 8KB\r\n小洞组成的。此时，一个新进程请求一个 20KB\r\n的堆段，分配将会失败！尽管总空闲空间足够，但没有连续的 20KB 空间。\r\n解决方案（都不理想）： -\r\n内存紧凑（Compaction）：OS暂停所有进程，将所有已分配的段“搬家”到物理内存的一端，从而将所有小洞合并成一个大的连续空闲块。这个过程极其缓慢，会导致系统卡顿。\r\n- 复杂的空闲列表算法：使用如 Best-fit\r\n(最优匹配)、First-fit (首次匹配)\r\n等算法来试图减少碎片的产生，但无法根除这个问题。\r\n总之,\r\n虚拟地址空间的分段技术完美解决了“基址+界限”的内部碎片问题,\r\n能够高效支持稀疏地址空间,\r\n且提供了一个逻辑上自然的内存视图（代码、堆、栈）。\r\n但是,\r\n分段机制由于分配的可变大小的块，引入了难以解决的外部碎片问题。这个“外部碎片”问题，就是推动操作系统设计者发明下一代内存管理技术——分页（Paging）的根本原因。\r\n空闲空间管理\r\n在上一章的结尾，我们遇到了“外部碎片”这个难题，即如何管理大小不等的内存块。本章就专门深入探讨这个问题。\r\n本章讨论的策略和机制是通用的，它们既适用于用户空间, 如C语言中的\r\nmalloc() 和 free() 库，用于管理进程堆（Heap）上的空闲空间;\r\n也适用于内核空间：操作系统在实现分段时，用于管理物理内存的空闲空间。\r\n底层三大机制\r\n在讨论具体策略（如“最优匹配”）之前，本章先介绍了几乎所有分配程序都必须实现的3个底层机制。\r\n\r\n分割（Splitting）与 合并（Coalescing）\r\n\r\n分割（Splitting）：当一个100字节的请求到来，而空闲列表中只有一个1000字节的大空闲块。分配程序需要将这个1000字节的块分割成两块：一块100字节（返回给用户），另一块900字节（保留在空闲列表中）。以避免浪费，满足小请求。\r\n合并（Coalescing）：当用户 free()\r\n一块内存时，这块新释放的内存恰好与空闲列表中的另一块（或两块）空闲内存在物理上相邻。分配程序必须检测到这种相邻关系，并将它们合并成一个更大的连续空闲块。这是对抗外部碎片的核心武器。它能将被割裂的小块重新组合成大块，提高未来大请求的成功率。\r\n\r\n追踪已分配空间的大小\r\n\r\n问题：free(ptr) 接口没有 size 参数。那么 free\r\n库函数是如何知道要释放的这块内存到底有多大呢？\r\n机制：头块（Header Block）。\r\n当用户调用 malloc(20) 时，库实际上会分配大于20字节的空间（例如 20 +\r\n8 字节）。它在返回的指针 ptr\r\n之前的那8个字节（即头块）中，秘密存储了管理信息。\r\n头块内容有:\r\n\r\nsize：这块内存的实际大小（例如 20）。\r\nmagic：一个“魔数”，用于完整性检查（例如，检查用户是否传了一个无效指针给\r\nfree）。\r\n\r\nfree(ptr) 的工作流：\r\n\r\n通过指针运算 hptr = ptr - sizeof(header_t)\r\n找到头块。\r\n检查 hptr-&gt;magic 是否正确。\r\n读取 hptr-&gt;size，从而知道要释放的内存块大小。\r\n将这个大小为 size 的块放回空闲列表（并尝试进行合并）。\r\n\r\n\r\n嵌入空闲列表（Embedding the Free List）\r\n\r\n问题：空闲列表本身（即那些记录“哪里空闲、有多大”的节点）需要空间来存储。但是我们无法\r\nmalloc 一块内存来存放空闲列表节点，因为 malloc\r\n本身需要使用空闲列表来查询空闲空间。这是一个“鸡与蛋”的问题。\r\n机制：利用空闲空间本身来存储空闲列表的节点数据。一块内存，要么被用户使用，要么是空闲的。当它空闲时，它的内部空间是无用的。分配程序就利用这块无用的空间来存储空闲列表的节点数据。\r\n具体实现：定义一个 node_t 结构体，包含 size（块大小）和\r\nnext（指向下一个空闲块的指针）。\r\n\r\n当一块内存被 free()\r\n时，分配程序在这块内存的起始位置写入 node_t\r\n数据，包含这块内存的大小和指向下一个空闲块的指针。然后将这块内存插入到空闲列表中。\r\n当一块内存被 malloc() 分配出去时，这块内存的 node_t\r\n数据会被覆盖（因为现在归用户使用），同时它会从空闲列表中移除。\r\n``` free_list_head → [0x1000 | size=100 | next=0x2000 | 空闲块数据…\r\n] ↓ [0x2000 | size=4088 | next=NULL | 空闲块数据… ]\r\n\r\n\r\n\r\n基本策略\r\n这里介绍了四种经典策略：\r\n最优匹配（Best Fit）\r\n\r\n策略：遍历整个空闲列表，找到所有能满足请求的块（size\r\n&gt;= request），然后选择其中尺寸最小的那一块。\r\n理念：尽量不“浪费”大块内存。为15字节的请求分配一个16字节的块，只留下1字节的碎片，这看起来很“优”。\r\n缺点：\r\n\r\n慢：每次分配都需要遍历整个列表。\r\n产生大量小碎片：容易在列表中留下许多几乎无法使用的小碎片（如1字节、2字节），加剧外部碎片。\r\n\r\n\r\n最差匹配（Worst Fit） -\r\n策略：遍历整个空闲列表，找到尺寸最大的那一块进行分割。\r\n- 理念：留下来的剩余部分（Largest -\r\nrequest）仍然会是一个比较大的块，也许对未来有用。 - 缺点： -\r\n慢：同样需要遍历整个列表。 -\r\n性能差：研究和实践表明，这种策略会很快地“摧毁”所有的大块内存，导致外部碎片问题更严重。\r\n首次匹配（First Fit） -\r\n策略：从列表头部开始遍历，找到第一个能满足请求的空闲块，立即分割并返回。\r\n- 优点：快。不需要遍历整个列表，分配速度很快。 -\r\n缺点：容易导致列表头部堆积大量小碎片，使得后续的小请求很快，但大请求总是要遍历很久才能找到合适的块。\r\n- 改进：如果列表按地址排序，可以使合并操作非常高效。\r\n下次匹配（Next Fit） -\r\n策略：像首次匹配一样，但它维护一个“漫游指针”\r\ncurrent_ptr，记录上次查找结束的位置。下次分配时，从\r\ncurrent_ptr 开始查找。 -\r\n理念：让查找“均匀”地分布在整个列表中，而不是总从头部开始，避免了首次匹配中头部碎片堆积的问题。\r\n- 优点：速度和首次匹配一样快（摊销后），且列表碎片的分布更均匀。\r\n高级方法\r\n除了上述基本策略，现代内存分配器还采用了一些更复杂的技术来提高效率和减少碎片。\r\n- 分离空闲列表（Segregated Free\r\nLists）：将空闲块按大小分类，维护多个空闲列表（如小块列表、大块列表）。这样，分配请求时只需查找对应大小类别的列表，减少查找时间。\r\n- 位图分配（Bitmap\r\nAllocation）：使用位图来表示内存块的使用情况。每个位对应一个固定大小的内存块，1表示已分配，0表示空闲。适用于管理大量小块内存。\r\n- 伙伴系统（Buddy\r\nSystem）：将内存划分为大小为2的幂次方的块。分配时，找到最小的满足请求的块，并在释放时尝试与相邻的“伙伴”块合并，减少碎片。\r\n其实,\r\n不存在一个“完美”的分配程序。一个好的分配程序必须根据具体的工作负载（Workload）来设计和调整，在速度、空间效率和可扩展性（尤其是在多核处理器上）之间做出明智的折中（Trade-off）。\r\n分页\r\n分页是当下操作系统中最广泛使用的内存管理技术。它彻底解决了分段机制中的“外部碎片”问题，通过牺牲逻辑上的直观性（分段）来换取无可比拟的管理便利性（分页）。\r\n分页的思想：将空间分割成固定大小（Fixed-sized）的单元。\r\n我们将虚拟地址空间（Address\r\nSpace）分割成固定大小的单元，称为页（Page）（或虚拟页，Virtual\r\nPage, VP）。 - 页的大小通常是\r\n4KB（4096字节），但也有更大（如\r\n2MB、1GB）的页，具体取决于硬件支持。\r\n我们将物理内存（Physical\r\nMemory）也分割成同样大小的单元，称为页帧（Frame）（或物理页帧,\r\nPhysical Page Frame, PFN）。\r\n实现虚拟内存的核心任务，就是管理如何将进程的“页”映射（Map）到内存中的“页帧”。\r\n分页的优点: -\r\n灵活性（Flexibility）：操作系统不再关心堆和栈如何增长或使用。任何一个虚拟页都可以被放置到任何一个空闲的物理页帧中。\r\n- 空闲空间管理极其简单： -\r\n分段：OS需要搜索一个复杂的列表（Best-fit,\r\nFirst-fit…）来找到一个足够大且连续的空闲块。 -\r\n分页：OS只需要维护一个简单的空闲页帧列表（Free-frame\r\nList）。当一个进程需要4个页时，OS只需从这个列表中取出任意4个页帧即可，它们不需要是连续的。这就彻底消除了外部碎片。\r\n地址转换机制\r\n这是本章的机制核心, 分页机制下的地址转换与分段完全不同。 -\r\n分段地址：[ 段标识符 | 偏移量 ] - 分页地址：[ 虚拟页号\r\n(VPN) | 偏移量 (Offset) ]\r\n\r\n虚拟地址的解析\r\n\r\n硬件（MMU）将一个虚拟地址（VA）按固定边界（由页大小决定）拆分为两部分：\r\n\r\n虚拟页号\r\n(VPN)：高位部分。用于在“页表”中进行查找。\r\n偏移量\r\n(Offset)：低位部分。用于在找到的物理页帧中定位具体的字节。\r\n\r\n示例：64字节地址空间（虚拟地址需要6位）, 16字节页大小（24），因此需要4位作为偏移量。剩下的\r\n6 − 4 = 2 位，就是虚拟页号 (VPN)。\r\n\r\n虚拟地址 21（二进制 010101）：01 (VPN)表示这是虚拟页1, 0101\r\n(Offset)表示这是该页中的第5个字节（从0开始）。\r\n\r\n\r\n页表 (Page Table)\r\n\r\n定义：页表是操作系统为每个进程维护的一个核心数据结构。\r\n功能：它存储了从虚拟页号 (VPN) 到物理页帧号 (PFN) 的映射关系。\r\n定位: OS在切换进程时会将该进程的页表地址加载到MMU中,\r\n起始地址存储在一个专用寄存器中，称为页表基址寄存器（Page\r\nTable Base Register, PTBR）。\r\n\r\n类似于分段中的 base 寄存器，但这里存储的是页表的起始地址。\r\n\r\n最简单的形式（线性页表）：就是一个数组，VPN用作访问该数组的索引。\r\n\r\n示例： | VPN | PFN | |—–|—–| | 0 | 5 | | 1 | 2 | | 2 | 8 | | 3 | 1\r\n|\r\n\r\n\r\n\r\n当进程访问虚拟地址 21（010101）时：\r\n第1步：硬件拆分地址 - 硬件从 VA=21 中提取\r\nVPN = 01 (即1) 和 Offset = 0101\r\n(即5)。\r\n第2步：硬件查找页表（核心） - 硬件访问该进程的页表,\r\n它以 VPN=1 作为索引，查表得到 页表[1] 的内容，即 PFN = 7（二进制\r\n111）。\r\n第3步：硬件构建物理地址（PA） - 硬件将查到的\r\nPFN（111）和原始的 Offset（0101）重新组合（拼接）起来。 - PA = [ PFN |\r\nOffset ], 例如 PA = [ 111 | 0101 ] = 1110101（二进制），即十进制的 117。\r\n-\r\n关键：偏移量（Offset）永远不会被翻译，它只在虚拟页和物理页帧中指明同一个相对位置(因为页和页帧大小相同)。\r\n第4步：访问物理内存 - 硬件（MMU）将计算出的物理地址 117\r\n发送到内存总线，完成数据访问。\r\n页表项（PTE）的内部结构\r\n页表中的每个条目称为页表项（Page Table Entry,\r\nPTE）。页表项内部除了“物理页帧号（PFN）”之外，还包含一些关键的控制位（Control\r\nBits）：\r\n有效位 (Valid Bit)： -\r\n功能：指示该PTE是否有效（即该虚拟页是否被映射）。 -\r\n作用：这是实现稀疏地址空间的关键。对于栈和堆之间的巨大空洞，OS只需将这些页对应的PTE标记为“无效”。如果进程试图访问它们，硬件会立即触发异常（段错误）。OS不需要为这些无效页分配任何物理页帧。\r\n保护位 (Protection Bits)： -\r\n功能：标记该页是可读（R）、可写（W）还是可执行（X）。 -\r\n作用：提供权限保护。如果进程试图写入一个被标记为“只读”的页（如代码段），硬件会触发异常。\r\n存在位 (Present Bit)： -\r\n功能：标记该页是在物理内存中，还是在磁盘上（即被“换出”了）。\r\n-\r\n作用：这是实现交换（Swapping）的基础。如果硬件发现该位为0（不在内存），它会触发一个缺页异常（Page\r\nFault），让OS去磁盘上把数据取回内存。\r\n脏位 (Dirty Bit)： -\r\n功能：硬件在写入一个页时，会自动设置该位。 -\r\n作用：优化。当OS决定将一个页换出到磁盘时，它会检查脏位。如果脏位为0（表示该页从未被修改过），OS就不必将其写回磁盘（因为磁盘上的版本已经是最新的）而是直接丢弃该页,\r\n从而节省了I/O时间。\r\n访问位 (Accessed Bit /\r\nReference Bit)： -\r\n功能：硬件在读取或写入一个页时，会自动设置该位。 -\r\n作用：用于页面替换算法。OS可以定期检查此位，以了解哪些页最近被频繁使用（保留在内存中），哪些页无人问津（可以换出到磁盘）。\r\n分页带来的两个新问题\r\n分页机制虽然在概念上完美地解决了碎片问题，但在工程实现上带来了两个全新的、巨大的挑战：页表可能非常大（空间开销）且访问页表可能非常慢（时间开销）。\r\n问题一：页表太大（空间开销） -\r\n问题：由于页表需要为每一个虚拟页都存储一个条目，它的大小与虚拟地址空间的大小成正比，与页大小成反比,\r\n而与进程实际使用的内存无关。 - 计算：一个32位地址空间（4GB）, 4KB（212）的页大小。地址被分为 20位 VPN\r\n和 12位 Offset。 - 页表需要有 220（约100万）个页表项\r\n(PTE)。假设每个PTE为4字节（用于存储PFN和各种标志位）。 -\r\n页表所占空间：100万 * 4字节 = 4MB。 - 结论：每个进程都需要一个 4MB\r\n大小的页表！如果有100个进程在运行，仅页表本身就会消耗 400MB\r\n物理内存。这在当时（甚至现在）都是难以接受的巨大开销。 -\r\n存储：因为页表如此巨大，它不能被存在CPU的快速寄存器上（不像分段的几个\r\nbase/bound\r\n寄存器），它必须被存储在主内存（RAM）中。\r\n问题二：分页太慢（时间开销） -\r\n问题：由于页表存储在内存中，硬件在进行地址转换时，引发了“鸡生蛋，蛋生鸡”的悖论。\r\n- 访问流程：假设程序要执行\r\nmovl 21, %eax（从虚拟地址21加载数据）。 - 硬件需要知道\r\nVA=21 对应的物理地址。为此，硬件需要去查页表，以 VPN=1 为索引，找到\r\nPTE[1]。 -\r\n但页表本身也在内存中！因此，硬件必须先发起一次内存访问，从内存中读取\r\nPTE[1] 的内容（PFN=7）。 - 然后，硬件才能计算出真正的物理地址 PA=117。 -\r\n最后，硬件再发起第二次内存访问，从 PA=117 处读取真正的数据。 -\r\n结论：每一次虚拟内存访问（无论是取指令还是读写数据），现在都变成了两次物理内存访问。第一次：访问页表（PTE）。第二次：访问真实数据。\r\n-\r\n后果：这会使系统的内存性能下降一倍（减慢50%），这是毁灭性的性能灾难。\r\n总之, 分页的胜利： - 彻底解决了外部碎片（通过固定大小的单元）。 -\r\n极度灵活（任何VP可以到任何PFN）。 -\r\n通过“有效位”完美支持了稀疏地址空间（解决了内部碎片）。\r\n分页的挑战： -\r\n空间问题：线性页表（作为数组）太大，浪费内存。 -\r\n时间问题：访问页表需要额外的内存访问，导致性能减半。\r\n本章成功地用“分页”取代了“分段”，成为了现代虚拟内存的基石。但它也留下了两个亟待解决的工程难题（页表太大、太慢）。接下来的两章（TLB\r\n和 多级页表）将专门用于解决这两个问题。\r\n分页：快速地址转换（TLB）\r\n在上一章中，我们建立了一个看似完美的虚拟内存机制——分页（Paging）。它通过将内存划分为固定大小的“页”和“页帧”，彻底解决了外部碎片问题，并能完美支持稀疏地址空间。\r\n然而，结尾也揭示了一个灾难性的性能问题：由于页表（Page\r\nTable）存储在主内存（RAM）中，导致每一次内存访问（如 movl 21,\r\n%eax）都变成了两次内存访问： - 第一次访问：访问内存中的页表，以查找 VPN\r\n-&gt; PFN 的映射。 -\r\n第二次访问：访问内存中的实际数据（在计算出的物理地址处）。\r\n这会使系统的内存性能直接减半。本章的核心就是解决这个性能灾难。\r\n解决方案思路\r\n既然我们无法避免在概念上需要“查找页表”，我们该如何才能避免实际上去访问缓慢的主内存来进行查找？\r\n解决方案来自计算机科学中最强大的技术之一：缓存（Caching）。\r\n-\r\n核心思想：我们增加一个小型的、极快的、基于硬件的缓存，专门用于缓存最近使用过的地址转换（VPN\r\n-&gt; PFN）。 -\r\n名称：这个特殊的缓存被称为地址转换旁路缓冲（Translation-Lookaside\r\nBuffer），简称 TLB。\r\nTLB的成功依赖于程序的局部性（Locality）原理： -\r\n时间局部性（Temporal\r\nLocality）：如果一个程序刚刚访问了某个页（例如，循环中的指令），它很可能马上会再次访问它。\r\n- 空间局部性（Spatial Locality）：如果一个程序刚刚访问了某个页（例如\r\na[0]），它很可能马上会访问同一个页中的邻近数据（例如\r\na[1]、a[2]）。\r\n因此，只要我们将第一次查找的结果缓存到TLB中，后续的（大概率会发生的）访问就可以直接从TLB中获取，而无需访问主内存中的页表。\r\nTLB的基本算法\r\nTLB被集成在CPU的内存管理单元（MMU）中。现在，硬件的地址转换流程变得更加复杂：\r\n\r\nCPU生成一个虚拟地址（VA）要访问内存。\r\n硬件（MMU）将其拆分为 [ VPN |\r\nOffset ]。\r\n（关键步骤） 硬件首先拿着 VPN 去查询\r\nTLB。TLB是一个全相联的硬件缓存，它会并行地（非常快地）检查自己是否存有该\r\nVPN 的映射。接下来是两种可能：\r\n\r\n情况一：TLB 命中 (TLB Hit), 即TLB中存在该 VPN\r\n的有效映射条目。这是最理想、最常见的情况。\r\n\r\n硬件立即从TLB条目中获取 PFN（物理页帧号）。\r\n硬件检查保护位（例如，是否允许写入）。\r\n硬件将 PFN 和原始的 Offset 拼接成物理地址（PA）。\r\n硬件访问主内存（RAM）。\r\n性能：总共只需要一次内存访问（用于获取真实数据）。TLB的查找几乎不花时间（集成在CPU时钟周期内）。性能问题解决了！\r\n\r\n\r\n情况二：TLB 未命中 (TLB Miss), 即TLB中没有该 VPN\r\n的映射。这是我们不希望看到的慢速路径。硬件操作：\r\n\r\n系统暂停当前指令的执行。\r\n系统现在必须执行上一章中那个缓慢的、原始的操作：\r\n\r\n硬件（或OS）访问页表基址寄存器（PTBR），找到页表的位置。\r\n硬件（或OS）计算出PTE的地址（PTEAddr = PTBR + (VPN\r\n* sizeof(PTE))）。\r\n（第一次内存访问） 硬件（或OS）访问主内存，读取该\r\nPTE。\r\n硬件（或OS）从 PTE 中提取出 PFN 和保护位。\r\n（关键步骤） 硬件（或OS）将这个 [VPN -&gt; PFN]\r\n的映射更新（插入）到TLB中。如果TLB已满，将根据替换策略踢出一个旧条目。\r\n\r\n\r\n接着硬件重新启动导致未命中的那条指令。\r\n\r\n这一次，指令会从步骤1重新开始，但必定会 TLB\r\n命中（因为我们刚把映射放进去了）。\r\n（第二次内存访问） 硬件访问主内存，获取真实数据。\r\n性能：总共需要两次内存访问（一次查PTE，一次查数据），外加处理未命中的额外开销。这非常非常慢，但我们希望它很少发生。\r\n\r\n\r\n谁来处理TLB未命中\r\nTLB未命中的处理方式取决于具体的CPU架构：\r\n硬件管理的TLB（例如：x86 - CISC） -\r\n机制：硬件全权负责。硬件中固化了“遍历页表”的逻辑。 -\r\n要求：硬件必须知道页表在内存中的确切位置（通过 CR3 等寄存器, CR3 是 PTBR\r\n在 x86 CPU\r\n上的具体名字）以及页表的刚性数据结构（例如x86的固定多级页表）。 -\r\n优点：速度非常快。TLB未命中完全由硬件处理，对OS透明，开销较小。 -\r\n缺点：缺乏灵活性。操作系统必须使用硬件规定的页表格式。如果OS想尝试新的页表结构（如倒排页表），硬件不支持，就无法实现。\r\n软件管理的TLB（例如：MIPS, SPARC - RISC） -\r\n机制：硬件不参与查找，只负责“上报问题”。 - 流程： - 硬件在TLB中查找\r\nVPN。 - TLB未命中！ -\r\n硬件立即停止，并触发一个特殊的异常（Trap），切换到内核模式，跳转到OS预设好的“TLB未命中处理程序”。\r\n-\r\n操作系统的代码开始运行。它在自己的数据结构（可以是数组、哈希表、树…）中查找\r\nVPN 对应的 PFN。 - OS找到后，使用一条特权指令（如\r\nTLB_Insert）手动将映射写入TLB。 -\r\nOS执行“从陷阱返回（return-from-trap）”指令。 -\r\n硬件重新启动那条导致未命中的指令（这一次，它会TLB命中）。\r\n优点：极度灵活。OS可以使用任何它喜欢的数据结构来作为页表，硬件根本不关心。\r\n缺点：处理未命中的开销更大（因为涉及到了OS的上下文切换和软件执行），但如果未命中率足够低，这种灵活性是值得的。\r\nTLB的内容与上下文切换\r\nTLB的条目（Entry）不仅仅是 [VPN | PFN]，它还包含其他关键位：\r\n\r\nValid bit：这个TLB条目是否有效？\r\n\r\n这与PTE的Valid bit不同, TLB的Valid\r\nbit表示该TLB条目是否包含有效的映射, 而PTE的Valid\r\nbit表示该虚拟页是否被映射。\r\n\r\nProtection bits：保护位（R/W/X）。\r\nDirty bit / Accessed bit：脏位和访问位。\r\n\r\n上下文切换的挑战\r\n问题：TLB缓存了进程A的映射（例如 VPN 10 -&gt; PFN\r\n100）。当OS切换到进程B时，进程B也可能访问它自己的 VPN\r\n10，但它的映射应该是 VPN 10 -&gt; PFN\r\n170。如果进程B使用了进程A的旧TLB条目，它将访问到错误的内存！\r\n关键问题：进程切换时如何管理TLB的内容？\r\n解决方案 1：清空TLB (Flush TLB) -\r\n机制：在每次上下文切换时，OS执行一条特权指令，将TLB中所有条目的\r\nValid bit 设为0，即清空整个TLB。 -\r\n优点：简单、绝对安全。 -\r\n缺点：代价高昂。新换上的进程B开始运行时，它的TLB是“冷”的，它访问的每一个新页都会导致一次TLB未命中，直到它的“工作集”被重新缓存进TLB。\r\n解决方案 2：地址空间标识符 (ASID) -\r\n机制：硬件为TLB条目增加一个额外的字段：ASID（Address Space\r\nIdentifier）。ASID是一个（通常为8位的）ID，用于唯一标识当前正在运行的进程。\r\n- TLB条目变为：[ ASID | VPN | PFN | … ] - 上下文切换时的操作： -\r\nOS上下文切换时，不再需要清空TLB。OS只是告诉MMU：“现在请使用 ASID =\r\n2”（进程B的ID）。 - 硬件查找时的操作：硬件在查找TLB时，现在会匹配两者：\r\nTLB.ASID == Current_ASID 并且 TLB.VPN == VA.VPN\r\n\r\n优点：效率极高。进程B的旧映射（如果还在TLB中）可以被立即重用，避免了“冷启动”的开销。TLB现在可以同时持有多个进程的映射。\r\n\r\nTLB替换策略\r\n和一般的缓存一样，TLB是有限的（例如64项）。当发生TLB未命中，且TLB已满时，必须替换（Evict）一个旧条目。替换哪一个？\r\n&gt; 目标/benchmark：选择一个“未来最不可能被使用”的条目。 策略： -\r\n最近最少使用\r\n(LRU)：替换掉“最长时间没有被访问过”的条目。它在理论上利用局部性，效果很好，但在硬件中实现起来非常复杂。\r\n- 随机\r\n(Random)：随机选择一个条目并替换。实现起来极其简单（硬件只需要一个随机数生成器），并且巧妙地避免了一些“最坏情况”（例如，当程序循环访问65个页，而TLB只有64项时，LRU会每次都失败，而随机策略表现反而更好）。\r\n总之,\r\nTLB是让分页（Paging）机制变得可行的关键。没有TLB，分页带来的性能损失（每次访问都变两次）将是无法接受的。\r\nTLB是一个硬件缓存，它利用时间局部性和空间局部性，使得绝大多数（希望是\r\n&gt; 99%）的地址转换都极快（TLB Hit）。\r\n但TLB自身也引入了新的设计挑战： -\r\n未命中处理：由硬件还是软件负责？（CISC vs. RISC） -\r\n上下文切换：如何避免进程A的映射被进程B误用？（Flush vs. ASID） -\r\n替换策略：当TLB满了踢出谁？（LRU vs. Random）\r\nTLB覆盖范围（Coverage）：TLB的局限性在于它能“覆盖”的内存总量是\r\nTLB条目数 * 页大小。如果一个程序（如数据库）在短时间内随机访问大量内存（例如\r\n1000 * 4KB =\r\n4MB），超出了TLB的覆盖范围，就会频繁发生TLB未命中，性能急剧下降。这引出了后续章节对“大页（Large\r\nPages）”的需求。\r\n分页：缩小页表所占空间（多级页表）\r\n之前，我们引入了“分页”作为理想的虚拟内存方案。在第上一章中，我们通过“TLB”解决了分页带来的速度问题（即避免了每次内存访问都变成两次）。\r\n现在，本章将集中火力解决分页带来的第二个大问题：空间问题。也就是,\r\n如何让页表更小？\r\n简单的线性页表（Linear Page\r\nTable，即一个大数组）太大了。一个32位系统、4KB页大小，每个进程的页表都需要\r\n4MB。100个进程就需要 400MB\r\n内存仅仅用来存页表。这无法接受。我们该如何设计数据结构来缩小它？\r\n本章探讨了四种主要的解决方案，从简单到复杂。\r\n简单的解决方案：更大的页\r\n这是最直观的解决方案。\r\n思想：页表的大小 = (虚拟地址空间大小 / 页大小) *\r\nPTE大小。要缩小页表，最简单的方法就是增大分母（页大小）,\r\n这样页表项数就会减少。例如： - 32位地址空间, 4KB 页 ( 212 ) -&gt; 220 (约100万) 个PTE -&gt; 4MB\r\n页表。 - 32位地址空间, 16KB 页 ( 214 ) -&gt; 218 (约26万) 个PTE -&gt; 1MB 页表\r\n(缩小为1/4)。\r\n优点：立竿见影地缩小了页表。而且还会增加TLB的覆盖范围。一个TLB条目现在可以映射16KB内存，而不是4KB，这大大减少了TLB未命中（尤其对大型应用）。\r\n致命缺点：内部碎片（Internal Fragmentation）,\r\n这又回到了我们最初试图解决的问题！如果一个应用程序只需要3KB内存，操作系统为了它分配一个16KB的页帧，就净浪费了13KB。这在小程序或稀疏使用内存的应用中会造成巨大的物理内存浪费。\r\n结论：因为内部碎片的代价太高，大多数系统仍然坚持使用较小的页（如4KB或8KB）作为默认。\r\n混合方法：分页和分段\r\n这是一种“取两家之长”的杂合（Hybrid）设计。\r\n思想：我们为什么要因未使用的地址空间（如栈和堆之间的巨大空洞）而惩罚自己，去为它们分配页表项呢？\r\n\r\n线性页表的问题是：它必须为所有可能的VPN都保留一个PTE槽位，即使它们是无效的（Invalid）。\r\n分段的优点是：它只为实际使用的段（代码、堆、栈）分配资源。\r\n\r\n杂合机制：我们不为整个地址空间维护一个大页表。我们为每个逻辑段（Segment）维护一个单独的、小型的线性页表。例如，一个进程有3个段（代码、堆、栈），它就有3个页表。\r\nCPU的MMU中不再只有一个页表基址寄存器（PTBR），而是像分段一样，有多对\r\nbase/bound 寄存器（例如，CodeBase/Bound, HeapBase/Bound,\r\nStackBase/Bound）。\r\n关键区别：这里的 base\r\n寄存器指向的不再是段本身的物理地址，而是指向该段的页表的物理地址。bound\r\n寄存器则用于检查该段的页表有多大（即该段包含多少个有效的页）。\r\n地址转换流程 (TLB Miss的情况下)： - VA = [ SN | VPN | Offset ]\r\n(SN=段号, 如01=代码, 10=堆) - 硬件使用 SN (例如 10)\r\n来选择对应的寄存器对（HeapBase, HeapBound）。 - 硬件检查 VPN\r\n是否在界限内（VPN &lt; HeapBound）。如果越界，触发异常。 -\r\n硬件计算PTE的地址：PTEAddr = HeapBase + (VPN * sizeof(PTE))。 -\r\n（一次内存访问）硬件获取 PTE。 - 硬件从 PTE 中提取 PFN，并与 Offset\r\n组合成物理地址。\r\n优点：极大节省空间。栈和堆之间的巨大空洞完全不占用任何页表空间。\r\n缺点：不够灵活.\r\n它仍然依赖于分段的逻辑（代码/堆/栈），如果一个程序有一个巨大的、但稀疏使用的堆，这种方法仍然会浪费大量页表空间。\r\n外部碎片：页表本身（例如代码页表3项，堆页表500项）现在是大小不等的内存块。这又把我们努力解决的外部碎片问题带回来了！\r\n结论：虽然在某些旧系统（如Multics）上很优雅，但它不够通用，并且会重新引入外部碎片问题。\r\n核心解决方案：多级页表\r\n这是现代操作系统（如Linux, Windows, macOS,\r\nx86）实际采用的主流解决方案。\r\n思想：如果我们能找到一种方法，只为有效的PTE分配空间，同时又不使用大小可变的“分段”，那该多好？\r\n这就是多级页表机制：\r\n\r\n我们将那个巨大的、连续的“线性页表”本身也进行分页。即，我们将4MB的页表切分成1024个4KB的“页表页（Page\r\nof Page Table）”。\r\n我们引入一个新结构，叫做页目录（Page\r\nDirectory）。它是一个数组，大小刚好也是一页（4KB）。这个页目录有1024项，每一项（称为PDE）对应一个“页表页”。\r\n\r\n如果一个“页表页”中所有的PTE都是无效的（例如，对应栈和堆之间的空洞），那么对应的页目录项（PDE）就标记为无效（Invalid）。操作系统根本不会为这个无效的“页表页”分配物理内存。\r\n\r\n\r\n如图20.2所示，我们用一个4KB的页目录，加上两个4KB的“页表页”，总共只用了12KB，就管理了原本需要4MB的线性页表所管理的空间。\r\n下面是详细的多级地址转换 (两级为例): - 地址拆分（x86 32位）：VA\r\n(32位) 被硬件拆分为三部分（不再是两部分）： - [ PD Index (10位) | PT\r\nIndex (10位) | Offset (12位) ]\r\n\r\nTLB Miss 时的硬件流程：\r\n\r\n硬件从 PDBR（页目录基址寄存器，x86中是\r\nCR3）获取页目录的物理地址。\r\n硬件使用 PD Index（高10位）作为索引，计算 PDE 的地址：PDEAddr = PDBR\r\n+ (PD Index * sizeof(PDE))。\r\n（第一次内存访问） 硬件从内存中读取 PDE。\r\n\r\n硬件检查该 PDE 的有效位。\r\n如果无效，说明进程访问了未映射的巨大空洞，触发异常（SEGFAULT）。\r\n如果有效，PDE 会告诉硬件下一步该去哪里找。PDE 包含一个 PFN，这个 PFN\r\n指向的不是数据，而是下一级（L2）的“页表页”。\r\n\r\n硬件使用 PT Index（中间10位）作为索引，计算 PTE 的地址：PTEAddr =\r\n(PDE.PFN &lt;&lt; 12) + (PT Index * sizeof(PTE))。\r\n（第二次内存访问） 硬件从内存中读取这个 PTE。\r\n\r\n硬件检查该 PTE 的有效位和保护位。\r\nPTE 包含最终数据的物理页帧号（PFN）。\r\n\r\n硬件将这个 PFN 和 Offset（低12位）拼接成最终物理地址。\r\n（硬件此时将 [VPN -&gt; PFN] 存入TLB）。\r\n（硬件重新启动指令，此时会TLB命中）。\r\n（第三次内存访问） 硬件最终访问数据。\r\n\r\n\r\n优点：\r\n极度节省空间：页表空间是按需分配的，与进程实际使用的内存量成正比。完美支持稀疏地址空间。\r\n易于管理：页目录和“页表页”本身都是固定大小（一页），OS管理它们就像管理其他页一样简单，没有外部碎片。\r\n缺点：\r\n时间开销：TLB 未命中时的代价变高了 - 线性页表：1次额外内存访问。 -\r\n两级页表：2次额外内存访问（1次查PDE，1次查PTE）。 -\r\n（x86-64的四级页表：4次额外内存访问！）\r\n复杂性：硬件和OS的实现都更加复杂。\r\n这是一个经典的时间-空间折中（Time-Space\r\nTrade-off）。我们用更慢的TLB未命中处理换取了极大的空间节省。鉴于TLB命中率通常非常高（&gt;99%），这个折中是完全值得的。\r\n其他方案\r\n\r\n反向页表 (Inverted Page Table)\r\n\r\n这是一种完全不同的、以物理内存为中心的设计。\r\n机制：\r\n\r\n不再为每个进程维护一个页表。\r\n全局只有一个页表，这个页表的大小与物理内存中的页帧数成正比（而不是与虚拟地址空间大小成正比）。\r\nInvertedPageTable[PFN] -&gt; [ PID, VPN ]\r\n翻译：当一个进程（PID=5）访问 VPN=10\r\n时，硬件（或OS）必须搜索整个反向页表，查找是否存在一个条目，其内容是 [5,\r\n10]。\r\n\r\n搜索问题：线性搜索这个大表太慢了，所以通常会使用一个哈希表（Hash\r\nTable）来加速查找。\r\n优点：极度节省空间，页表总大小只与物理内存相关，与进程数量或虚拟空间大小无关。\r\n缺点：哈希表的实现非常复杂，且处理哈希冲突等问题会增加开销。\r\n\r\n将页表交换到磁盘\r\n\r\n思想：为什么我们假设页表（尤其是多级页表中那些不常用的“页表页”）必须一直待在物理内存中？\r\n\r\n这和我们对待普通数据页的方式是一样的：不常用的数据页可以被换出到磁盘。\r\n\r\n机制：OS可以将页表本身也视为内核虚拟内存的一部分。当物理内存紧张时，OS可以将不常用的“页表页”换出（Swap\r\nout）到磁盘上。\r\n后果：这会导致“地狱般”的TLB未命中。当硬件试图查找一个PTE，而它的PDE指向的“页表页”又不在内存中时…\r\n\r\nTLB Miss。\r\n硬件查找PDE（内存访问1）。\r\n硬件试图查找PTE，但发现PTE所在的“页表页”的“存在位”为0（缺页异常！）。\r\nOS介入，从磁盘读回“页表页”（I/O操作）。\r\nOS重新执行指令，TLB Miss。\r\n硬件查找PDE（内存访问2）。\r\n硬件查找PTE（内存访问3）。\r\n硬件查找数据（内存访问4）。\r\n\r\n结论：这是一种终极的空间节省方案，但代价是极高的复杂性和潜在的性能悬崖。\r\n\r\n\r\n总之, 本章解决了分页带来的空间问题。\r\n\r\n简单的（坏）方案：大页（引入内部碎片）和分段+分页（引入外部碎片）。\r\n核心的（好）方案：多级页表。它通过增加间接层（Indirection）（即页目录），实现了页表的按需分配，极大地节省了空间，代价是TLB未命中时需要更多的内存访问。\r\n\r\n这是现代操作系统设计中一个完美的时间-空间折中案例。\r\n超越物理内存: Swap 机制\r\n在前面的章节中，我们已经构建了一个高效、空间节省的分页系统（使用多级页表和TLB）。但是，这个系统仍然基于一个核心假设：所有进程的虚拟地址空间加起来，必须能完全装入物理内存（RAM）。\r\n然而，现实情况往往并非如此。现代应用程序（如浏览器、数据库、大数据处理）通常需要远远超过物理内存容量的内存空间。\r\n操作系统如何利用一个容量大但速度慢的设备（如硬盘），来透明地提供一个巨大的虚拟地址空间的假象？\r\n\r\n为什么需要这样做？ - 易用性（Ease of\r\nUse）：程序员不再需要担心“内存不够用”。他们可以按需分配巨大的数据结构，而无需手动编写“内存覆盖（memory\r\noverlays）”代码来管理数据在内存和磁盘间的移入移出。操作系统替他们完成了所有繁重的工作。\r\n-\r\n多道程序（Multiprogramming）：为了充分利用CPU，系统希望“同时”运行许多进程（例如100个）。但在早期的（或内存受限的）机器上，所有这些进程的内存总和远远超过了物理内存。通过只在内存中保留每个进程的“活动”部分，系统可以运行远超物理内存容量的进程总数。\r\n\r\n核心机制：交换（Swapping）\r\n为了实现这个假象，OS必须有能力将内存中“暂时不用”的页（Page）移出到慢速设备上，并在“需要时”再将它们移回。这个过程称为交换（Swapping）。为此，我们需要引入四个关键机制：\r\n机制一：交换空间 (Swap Space)\r\n交换空间是操作系统在硬盘（HDD或SSD）上预先分配的一块专用空间。\r\n它充当RAM的“溢出区”。当物理内存（页帧）满了，OS可以将一个“受害者”页帧的内容写入（Page\r\nOut）到交换空间中；当稍后需要这个页时，再从交换空间读回（Page In）。\r\nOS的职责：OS必须为每个被换出的页记录其在磁盘上的地址（Disk\r\nAddress）。\r\n\r\n特例：并非所有页都去交换空间。例如，程序的可执行代码页（Code\r\nPage），如果它们没有被修改过（是“干净的”），当内存紧张时，OS可以直接丢弃它们。因为如果将来再次需要，OS可以直接从磁盘上的原始二进制文件（例如\r\na.out）中重新读取，而无需占用宝贵的交换空间。\r\n\r\n机制二：存在位 (Present Bit)\r\n问题：当硬件（MMU）遍历页表时，它如何知道一个页是在RAM中（可以立即访问），还是在磁盘上（必须停止并通知OS）？\r\n机制：我们在页表项（PTE）中引入一个新的控制位，称为“存在位（Present\r\nBit）”。 - Present = 1：页在物理内存中。PFN\r\n字段有效。硬件（TLB未命中后）可以正常获取 PFN，更新TLB，然后重试指令。 -\r\nPresent = 0：页不在物理内存中（它在磁盘上）。PFN\r\n字段无效。硬件此时不能处理这个情况，它必须立即停止，并触发一个异常（Exception），将控制权交给OS。\r\n机制三：页错误 (Page Fault) (21.2节)\r\n当硬件访问一个PTE，发现其存在位（Present Bit）为 0\r\n时，触发的异常（Exception / Trap），就称为“页错误（Page Fault）”。\r\n在这里需要区分两个概念：\r\n\r\n段错误 (Segmentation\r\nFault)：是一个“真正的”错误。进程访问了一个无效（Invalid）的地址（PTE的\r\nValid Bit = 0），OS会杀死该进程。\r\n页错误 (Page\r\nFault)：不是一个错误！它是一个“合法的”事件。进程访问了一个有效的地址（Valid\r\nBit = 1），但该页只是“恰好”不存在（Present Bit =\r\n0）于内存中。OS的职责是去磁盘把它取回来。 &gt;\r\n它更应该被称为“页未命中（Page\r\nMiss）”，但由于它使用与“错误”相同的异常机制，因此被称为“页错误”。\r\n\r\n机制四：页错误处理程序 (Page-Fault\r\nHandler)\r\n这是OS中的一段特权代码，在“页错误”异常发生时被硬件自动调用。它的工作流程:\r\n\r\n定位磁盘地址：OS需要知道去磁盘的哪个位置取回这个页。它通常会利用PTE中原本用于PFN的位来存储该页的磁盘地址（反正\r\nPresent Bit = 0 时，PFN 字段是无用的）。\r\n寻找空闲帧：OS必须在物理内存中找到一个空闲的页帧（Free\r\nPage Frame）来存放即将读入的页。\r\n（如果内存已满）：如果没有空闲页帧，OS必须运行页交换策略（Page-Replacement\r\nPolicy）来选择一个“受害者”页（Victim Page）并将其换出（Page\r\nOut）。\r\n发起I/O请求：OS向磁盘控制器发起一个异步读（Disk\r\nRead）请求，告诉它“将磁盘地址X的数据读入物理页帧Y中”。\r\n\r\n阻塞进程：磁盘I/O极其缓慢（毫秒级别）。OS不会让CPU空等。它会将导致页错误的进程状态置为“阻塞（Blocked）”，并调度运行另一个“就绪（Ready）”的进程。\r\nI/O完成中断：几毫秒后，磁盘完成读取，并向CPU发送一个I/O中断（Interrupt）。\r\n\r\nOS（中断处理程序）被唤醒：OS（此时可能正在运行另一个进程）接收到中断，知道“页的读入已完成”。\r\n更新页表：OS找到导致页错误的那个进程（它还在阻塞中）的页表，更新其PTE：\r\n\r\nPresent Bit = 1\r\nPFN = Y （指向刚刚载入数据的那个页帧）\r\n\r\n唤醒进程：OS将被阻塞的进程状态改回“就绪（Ready）”。\r\n（稍后）重试指令：当调度器最终再次运行该进程时，该进程会重新执行那条导致页错误的指令。\r\n\r\n完整的内存访问流程\r\n结合第19、20、21章，一次内存访问的完整流程（如图21.2 - 硬件，图21.3 -\r\n软件）如下：\r\n（硬件） 硬件拆分 VA -&gt; [VPN | Offset]。\r\n（硬件） 硬件检查TLB。\r\nTLB 命中？\r\n是 (常见情况)：获取 PFN，组合 PA，访问内存。（访问结束）\r\n否 (TLB 未命中)：\r\n（硬件/OS） 访问多级页表（可能多次内存访问）以找到PTE。\r\n（硬件） 检查 PTE.Valid == 0？ -&gt; 是：段错误（Segmentation\r\nFault），陷阱（Trap）到OS，OS杀死进程。（访问结束）\r\n（硬件） 检查 PTE.Protection？ -&gt; 访问非法？ -&gt;\r\n保护错误（Protection Fault），陷阱到OS，OS杀死进程。（访问结束）\r\n（硬件） 检查 PTE.Present == 1？\r\n是 (仅TLB未命中)：硬件将 PTE\r\n内容（PFN）载入TLB，然后重试指令（此时会TLB命中）。（访问结束）\r\n否 (PTE.Present == 0)：\r\n（硬件） 触发 页错误（PAGE_FAULT）异常，陷阱到OS。\r\n（OS - 页错误处理程序）\r\nOS从PTE中找到该页的磁盘地址。\r\nOS寻找一个空闲页帧。\r\n（如果内存已满）\r\nOS运行替换算法，选择一个“受害者”页。如果该页是“脏的”（Dirty=1），OS必须先将其写回（Page\r\nOut）交换空间（又一次I/O）。\r\nOS发起磁盘读（Page In），将数据读入空闲页帧。\r\nOS阻塞当前进程，调度其他进程运行。\r\n…（时间流逝，发生I/O中断）…\r\nOS（中断处理程序）更新PTE（Present=1, PFN=…）。\r\nOS将该进程设为就绪。\r\nOS返回（RetryInstruction）。\r\n（硬件）\r\n指令被重试（回到第1步），此时会发生TLB未命中（第3步），但会在第3.4步中发现\r\nPresent=1，载入TLB，最终访问成功。\r\n优化：后台交换\r\n上述流程是一个“懒惰的（Lazy）”或“按需的（On-demand）”策略。它会等到内存100%用满，然后在发生页错误时才去寻找“受害者”页并将其换出。\r\n这使得页错误变得极其缓慢。进程不仅要等待“页入（Page\r\nIn）”的I/O，还可能要先等待“页出（Page Out）”的I/O。\r\n优化方案：主动（Proactive）地维护一个空闲页池。可以使用水位线（Watermarks）机制:\r\n- 低水位线\r\n(LW)：当空闲页帧的数量低于此线（例如低于1000个），OS就该警觉了。 -\r\n高水位线\r\n(HW)：OS的目标是释放内存，直到空闲页帧的数量高于此线（例如高于5000个）。\r\n还有一种机制是交换守护进程 (Swap Daemon):\r\n它是一个在OS中后台运行的特殊线程（如Linux的 kswapd）。\r\n它大部分时间在休眠。当空闲内存低于LW时，OS唤醒这个守护进程,\r\n于是守护进程开始运行替换策略，寻找“不常用”的页，并将它们（如果是脏页）提前写出（Page\r\nOut）到磁盘，直到空闲内存高于HW。\r\n守护进程再次休眠。\r\n优点：\r\n页错误变快：当一个真正的页错误发生时，大概率已经有空闲页帧可用。处理程序只需等待“页入”，而无需等待“页出”。\r\nI/O效率（集群）：守护进程可以一次性收集（Cluster）多个脏页（例如32个），然后将它们作为一个大的、连续的I/O操作写入磁盘。这比32次单独的、随机的I/O操作要快得多。\r\n总之, 本章引入了将页“换出”到磁盘（交换空间）的机制。\r\n\r\n核心硬件支持是PTE中的“存在位（Present Bit）”。\r\n核心OS支持是“页错误处理程序（Page-Fault Handler）”。\r\n\r\n当内存已满时，OS必须运行“页交换策略（Page-Replacement\r\nPolicy）”来换出（Evict）一个“受害者”页。\r\n这一切对进程是完全透明的，进程只看到一个巨大的地址空间，但代价是某些内存访问（页错误时）会变得极其缓慢。\r\n通过后台守护进程和水位线机制，OS可以主动管理内存，使页错误的开销降到最低。\r\n超越物理内存：替换策略\r\n我们已经学习了实现“超越物理内存”的机制（Mechanisms），即交换（Swapping）、存在位（Present\r\nBit）和页错误（Page Fault）。\r\n本章则专注于探讨一个至关重要的问题：当内存已满，一个新页需要被调入时，我们必须选择一个“受害者”页将其踢出（Evict）。我们如何选择这个受害者？这就是替换策略（Replacement\r\nPolicy）。\r\n鉴于页错误的高昂代价（毫秒级别的I/O），选择一个好的替换策略对于系统性能至关重要。我们的目标是最小化页错误率（Page\r\nFault Rate）。\r\n我们的 benchmark\r\n是：在一系列内存访问中，选择一个“未来最不可能被访问”的页作为受害者，从而最大限度地减少未来的页错误。\r\n简单（但有缺陷）的策略\r\n先入先出 (FIFO):\r\n最简单的策略。维护一个队列，替换掉“最早进入”内存的那个页（即在队列头部的页）。\r\n\r\n优点：实现非常简单。\r\n缺点：\r\n\r\n逻辑缺陷：一个页“进来得早”和它“是否重要”毫无关系。它可能会踢出一个刚刚被载入、且即将被频繁访问的核心页。\r\nBelady异常（Belady’s\r\nAnomaly）：在极少数情况下，增加物理内存（增加缓存大小）反而会导致未命中率上升！这是违反直觉的，也是一个致命缺陷。\r\n\r\n\r\n随机 (Random): 当需要替换时，随机选择一个受害者页将其踢出。\r\n\r\n优点：\r\n\r\n实现极其简单。\r\n无最坏情况：在某些特定工作负载（如循环访问）下，它甚至比FIFO和LRU表现得更好，因为它不会陷入某种策略性的“陷阱”。\r\n\r\n缺点：性能完全不可控，全凭运气。\r\n\r\n核心策略：利用历史 (LRU)\r\nFIFO和Random失败的根本原因在于它们忽视了程序的行为。\r\n局部性原理（Principle of\r\nLocality）：这是现代计算机系统（包括CPU缓存、TLB和本章的页面替换）的基石。\r\n- 时间局部性\r\n(Temporal)：最近被访问过的东西，很可能马上会再次被访问（例如循环中的代码）。\r\n- 空间局部性\r\n(Spatial)：被访问过的东西附近的数据，很可能马上会被访问（例如数组元素）。\r\n策略（LRU - Least Recently\r\nUsed）：替换掉“最近最少使用”的那个页（即在“最久远的过去”被访问的页）。\r\n- 理念：如果一个页很久都没被用过了，那么它在将来被使用的概率也很低。 -\r\n实现：可以使用一个链表或栈来维护页的访问顺序。每次访问一个页时，将其移动到链表/栈的顶部。当需要替换时，踢出链表/栈底部的页。\r\n- 优点： - 性能优秀：在大多数真实工作负载中，性能非常接近“最优策略”。 -\r\n没有Belady异常：LRU具有“栈特性”，增加内存只会让命中率更好（或持平）。\r\n- 栈特性(Stack Property)：对于任何给定的工作负载，假设有两种缓存大小 S1\r\n&lt; S2。如果一个页在大小为 S1 的缓存中命中，那么它在大小为 S2\r\n的缓存中也一定会命中。\r\n\r\n缺点：\r\n\r\n最坏情况：在“循环顺序”工作负载中，LRU的表现是最差的。例如，循环访问50个页，但只有49个页帧，LRU会每次访问都导致未命中（0%命中率），因为它总是踢出下一个即将被访问的页。\r\n实现成本极高。\r\n\r\n\r\n由于要实现“完美”的LRU，操作系统必须在每一次内存访问时（包括取指令、读、写）都知道访问了哪个页，然后更新一个数据结构（例如一个链表，将被访问的页移到表头）。\r\n这100%是无法接受的。在每次内存访问时都陷入OS或更新数据结构，会使系统慢到瘫痪。\r\n于是, 近似LRU (Approximate LRU)被提出:\r\n我们不需要找到绝对“最少最近使用”的页，我们只需要找到一个“比较久没用过”的页。\r\n\r\n硬件支持：使用位 (Use Bit)（也叫引用位，Reference\r\nBit）\r\n\r\nOS在PTE中增加一个“Use Bit”。\r\n硬件的职责：当一个页被（读或写）访问时，硬件自动将该页PTE中的 Use\r\nBit 设置为 1。\r\nOS的职责：OS负责在某个时刻将 Use Bit 清除为\r\n0。\r\n\r\n核心算法：时钟算法 (Clock Algorithm),\r\n这是实现近似LRU的最经典、最高效的算法。\r\n\r\nOS将所有的物理页帧组织成一个循环列表（像一个钟表）。\r\n一个“时钟指针（Clock Hand）”指向列表中的某一个页帧。\r\n当需要替换一个页时（发生页错误且内存已满），OS开始顺时针转动指针,\r\n检查指针指向的页P：\r\n\r\nUse Bit == 1? (最近被用过)\r\n\r\nOS的动作：OS给它“第二次机会”。\r\n将 Use Bit 清零 (置为 0)。\r\n指针前进到下一页 (P+1)，并重复检查新的指向的页。\r\n\r\nUse Bit == 0? (最近没被用过)\r\n\r\nOS的动作：找到受害者了！\r\n踢出（Evict）这个页P。\r\n指针前进到下一页 (P+1)，算法结束。\r\n\r\n\r\n\r\n\r\n时钟算法是一个优雅的折中。它通过 Use Bit\r\n快速地（最坏情况下O(N)）跳过“最近被用过”的页，并最终找到一个“比较久没用过”的页（Use\r\nBit 为 0 的页）来替换。\r\n还可以对策略进一步优化, 考虑脏页 (Dirty Pages) :\r\n从而计算“换出成本”。\r\n\r\n硬件支持：脏位 (Dirty Bit)（也叫修改位，Modified Bit）\r\n\r\n硬件在写入一个页时，自动将该页PTE中的 Dirty Bit 设置为 1。\r\n\r\n成本分析：\r\n\r\n踢出一个干净（Clean）的页（Dirty =\r\n0）：成本低。OS可以直接丢弃它（如果是代码页）或用新页覆盖它。\r\n踢出一个脏（Dirty）的页（Dirty =\r\n1）：成本极高。OS必须先将这个页写回磁盘（一次昂贵的I/O），然后才能用新页覆盖它。\r\n\r\n\r\n因此, 改进的时钟算法中, OS在扫描时，会优先寻找 (Use=0, Dirty=0)\r\n的页（未使用、干净）作为受害者。如果第一圈找不到，OS会继续扫描，在扫描过程中将\r\nUse=1 的页清零。\r\n第二圈时，它会寻找 (Use=0, Dirty=1)\r\n的页（未使用、但很脏）。如果找到，OS会启动一个后台写操作将其写回磁盘，但继续扫描，看能否找到更好的\r\n(0, 0) 页。从而尽可能避免踢出脏页。\r\n此外, 还有一些优化, 比如: - 预取\r\n(Prefetching)：OS“猜测”程序即将访问某些页，并提前将它们调入。例如，当检测到程序正在顺序访问\r\nP、P+1 时，OS可能会猜测它即将访问 P+2 并提前调入。 - 聚集/分组写入\r\n(Clustering)：OS（如 kswapd\r\n守护进程）不会在踢出一个脏页时马上写回磁盘。它会“收集”多个相邻的脏页，然后将它们一次性（作为一整个I/O操作）写入磁盘，这比多次小I/O要快得多。\r\n极端情况：抖动 (Thrashing)\r\n当内存被严重超额使用（Over-subscribed）时，即所有正在运行的进程的“活跃工作集”（它们真正需要的页）之和远远大于物理内存时，系统会陷入“抖动（Thrashing）”状态。\r\n表现： - 进程A运行，访问页A，踢出页B。 -\r\nOS切换到进程B，进程B访问页B，踢出页A。 -\r\nOS切换到进程A，进程A访问页A，踢出页C…\r\n使得CPU利用率急剧下降，磁盘I/O达到100%。系统所有的时间都花在了“换页”上，没有任何“有效工作”在推进。\r\n解决方案： - 准入控制 (Admission\r\nControl)：OS检测到抖动时，“暂停”一个或多个进程，释放它们的内存，直到剩下的进程可以“舒适地”运行。\r\n- 内存不足杀手 (OOM\r\nKiller)：更激进的方案（如Linux）。当系统检测到内存严重不足时，它会启动一个“杀手”进程，选择一个（通常是内存占用最大的）进程并将其杀死，以强行释放内存。\r\n内存操作 API\r\nmalloc 和 free\r\n的底层实现原理\r\nmalloc 和\r\nfree是C语言中用于动态内存分配和释放的函数。需要注意的是,\r\n它们不是系统调用, 而是C标准库提供的接口,\r\n底层实现通常会调用系统调用如 brk/sbrk 或\r\nmmap 来管理内存。\r\n这个实现是为了提高内存分配的效率和灵活性,\r\n避免每次分配内存都直接调用系统调用带来的开销。这个设计的核心目的只有一个：最小化昂贵的“系统调用”\r\n(System Calls)。\r\n系统调用 (System Call)： - 代价高昂：当程序执行一个系统调用（如\r\nbrk），它会触发一个“陷阱”(trap)。CPU 必须从用户态 (User\r\nMode) 切换到内核态 (Kernel Mode)。 -\r\n这个切换需要保存当前程序的所有寄存器状态，加载内核的状态，执行内核代码（内核需要检查权限、更新页表等），然后再切换回用户态。这个上下文切换的开销远大于一次普通的函数调用。\r\n库调用 (Library Call)： - 代价低廉：当程序调用\r\nmalloc()，它只是在用户态调用了 C\r\n运行时库（libc）中的一个普通函数。这就像调用你自己写的任何其他函数一样，只涉及一个函数栈帧的压入和弹出，速度极快。\r\n- 如果每次 malloc(16)\r\n这样的小请求都去执行一次系统调用，那么程序的性能将会惨不忍睹。\r\n为了解决这个问题，malloc\r\n库和操作系统内核实现了一种两级管理模型: - 内核\r\n(OS)：作为批发商。它只按“大块”（Page，通常是 4KB\r\n或更大）来管理物理内存和虚拟内存。 - malloc\r\n库：作为零售商。它在用户态运行，负责精细化的内存管理。\r\n在 Linux 进程的经典内存布局中，内存被分为几个段： +-------------------+  (高地址)|       栈 (Stack)  |  &lt;- 向下增长 (Grows Down)|        ...        || (未使用的虚拟内存) ||        ...        |+===================+  &lt;- 当前的 \"分断\" (Program Break)  &lt;-- 堆的*顶部*|                   ||   堆 (Heap)       |  &lt;- 向上增长 (Grows Up)+-------------------+  &lt;- 堆的*起始点* (紧挨着BSS的末尾)| BSS 段 (未初始化) |+-------------------+| Data 段 (已初始化) |+-------------------+| Text 段 (代码)    |+-------------------+  (低地址) - 堆\r\n(Heap)：就是动态分配内存（malloc 或 new）的地方。 - 分断\r\n(Break)：就是堆的顶部边界。\r\nbrk() 和 sbrk() 系统调用\r\nbrk() 和 sbrk() 是 malloc\r\n库用来向内核“进货”的系统调用。它们管理的是一个单一、连续的内存区域，即堆\r\n(Heap)。\r\n\r\nvoid* sbrk(intptr_t increment);\r\n\r\n功能：告诉内核：“请把我的分断点向上移动 increment\r\n字节”\r\n操作：内核收到请求后，会更新进程的虚拟地址空间，将堆的上限扩大。这并不会立即分配物理内存，而只是标记这块虚拟地址“合法”。当你第一次访问这块新地址时，才会触发“缺页中断”(Page\r\nFault)，由内核分配一个实际的物理内存页。\r\n这是一个昂贵的内核态操作。\r\n\r\nint brk(void* addr);\r\n\r\n功能：直接告诉内核：“请把我的‘分断’点设置到 addr 这个新地址” sbrk\r\n只是 brk 的一个简单封装。\r\n操作：内核会将堆的上限设置为 addr\r\n指定的位置，同样不会立即分配物理内存。\r\n这是一个昂贵的内核态操作。\r\n\r\n\r\nmalloc() 和 free() 库调用\r\nmalloc\r\n库在内部维护着一个“空闲内存池”（freelist）。当调用\r\nmalloc(size_t size) 时：\r\n\r\n第一步（零售）：malloc\r\n库首先检查自己内部的空闲内存池，看有没有大小合适的“空闲块”可以满足你的\r\nsize 请求。\r\n\r\n如果找到：它会把这个空闲块标记为“已使用”，可能会从块上分割出你请求的大小，然后把指向这块内存的指针返回给你。这个过程完全在用户态发生，没有系统调用，速度极快。\r\n如果没找到（或内存池为空）：malloc 发现自己的“库存”不够了。\r\n\r\n第二步（批发）：malloc\r\n库会决定向内核“进一大批货”。它不会只申请你想要的\r\nsize（比如32字节），而是会申请一个更大的块（例如\r\n128KB）。\r\n\r\nmalloc 库调用\r\nsbrk(131072)。这触发了一次系统调用，进入内核态，将堆的“分断”点向上移动了\r\n128KB。\r\n返回用户态后：malloc 库现在拥有了 128KB\r\n的新“原始”内存。它会从这块内存中取出你请求的 32\r\n字节，返回给你，然后把剩下的（128KB - 32字节）\r\n放入它自己的空闲内存池，以备未来的 malloc 请求使用。\r\n\r\n\r\n当调用 free(void* ptr) 时：\r\n\r\nfree 库函数接收到指针 ptr。\r\n它根据 ptr 找到相关的元数据（通常存储在 ptr\r\n指向的内存块之前），得知这个块的大小。\r\n它将这个内存块标记为“空闲”，并将其归还到 malloc\r\n库的空闲内存池中。\r\n\r\n这个过程完全在用户态发生，没有系统调用。这块内存并没有还给操作系统，它仍然属于你的进程，只是可以被你的下一个\r\nmalloc 请求“循环利用”。 &gt; 特殊情况：只有当 free\r\n发现一个非常大的空闲块，并且这个块正好位于堆的顶部（“分断”点旁边）时，malloc\r\n库才可能会决定调用 brk()\r\n并传入一个更低的地址，真正地将这块内存“退还”给操作系统。\r\nmmap/munmap 系统调用\r\n现代的 malloc 实现（如 glibc 的\r\nptmalloc）更加复杂，它们混合使用了两种系统调用：\r\n\r\nbrk/sbrk：用于相对较小的、连续的内存分配。\r\nmmap() /\r\nmunmap()：当程序请求一个非常大的内存块时（例如大于\r\n128KB），malloc\r\n库可能会决定不使用堆（brk），而是转而使用\r\nmmap() 系统调用。\r\n\r\nmmap()\r\n会在进程的虚拟地址空间中（独立于堆）映射一块新的、匿名的内存区域。\r\n当这块大内存被 free 时，库会直接调用\r\nmunmap()，这会立即、完整地将这块内存归还给操作系统，避免了“堆碎片”问题。\r\n\r\n\r\nnew 和 delete 的底层实现原理\r\nnew 和 delete 是 C++ 的操作符\r\n(Operators)。它们的核心职责是管理对象的生命周期 (Object\r\nLifetime)，而不仅仅是内存。\r\nnew 操作符：两步走\r\n当写下 MyClass* p = new MyClass(10); 这样一行代码时，new\r\n操作符在底层执行了两个截然不同的操作：\r\n第 1 步：内存分配 (调用 operator\r\nnew 函数) - new 操作符首先需要一块原始内存。它通过调用一个名为\r\noperator new 的全局函数来获取这块内存。 - operator new\r\n是一个可以被重载（overload）的函数。 -\r\n在默认情况下，C++ 标准库中的全局 ::operator new(size_t size)\r\n函数，其标准实现通常就是简单地调用 malloc(size)。 -\r\n也可以为特定类重载 operator new，从而实现自定义的内存分配策略,\r\n例如内存池 (Memory Pool)。\r\n\r\n步骤说明：\r\n\r\nnew MyClass(10); 启动。\r\n编译器计算 MyClass 需要多少字节（例如 sizeof(MyClass) 是 32\r\n字节）。\r\nnew 操作符调用 operator new(32) 函数。\r\n默认的 operator new(32) 函数内部调用 malloc(32)。\r\nmalloc 使用我们之前讨论的 brk 或 mmap 机制，返回一个 void*\r\n指针（例如 0x5000）\r\noperator new 函数将这个 void* 指针返回给 new 操作符。\r\n\r\n\r\n第 2 步：对象构造 (调用构造函数),\r\n这是 new 和 malloc 的根本区别。\r\n\r\nnew 操作符拿到了 operator new 返回的原始内存地址（0x5000）。\r\n它会在这块原始内存上调用 MyClass\r\n的构造函数，并将参数（10）传递过去。这个过程在技术上称为“定位\r\nnew” (Placement New)。\r\n步骤说明：\r\n\r\nnew 操作符在 0x5000 这个地址上执行 MyClass::MyClass(10)。\r\n构造函数运行，初始化对象的所有成员变量，设置虚函数表（vtable）指针等。\r\n此时，0x5000 处不再是一块“原始内存”，而是一个“活生生”的、类型为\r\nMyClass 的对象。\r\nnew 操作符最后返回这个地址，但类型是 MyClass*（即 p =\r\n0x5000;）。\r\n\r\n\r\ndelete 操作符：也是两步走\r\n当调用 delete p; 时，delete 操作符会逆向执行两个操作：\r\n第 1 步：对象析构 (调用析构函数),\r\n这是 delete 和 free 的根本区别。\r\n\r\ndelete 操作符首先会检查 p 是否为\r\nnullptr（如果是，则什么也不做）。\r\n如果 p 不是 nullptr，它会调用 p\r\n指向对象的析构函数（p-&gt;~MyClass()）。\r\n步骤说明：\r\n\r\ndelete p; 启动（假设 p 是 0x5000）。\r\ndelete 操作符调用 MyClass::~MyClass()（p 的析构函数）。\r\n析构函数运行，释放该对象在构造时可能申请的任何内部资源（例如，如果\r\nMyClass 内部有一个指针，它可能会在析构函数中 delete 那个指针）\r\n析构函数完成后，0x5000\r\n处的对象“死亡”了，它又变回了一块“原始内存”。\r\n\r\n\r\n第 2 步：内存释放 (调用 operator\r\ndelete 函数) - 在对象“死亡”后，delete\r\n操作符必须归还这块原始内存。 - 它通过调用一个名为 operator delete\r\n的全局函数来实现。 - 和 operator new 对应，默认的全局 ::operator\r\ndelete(void* p) 函数，其标准实现通常就是简单地调用\r\nfree(p)。 - 步骤说明： 1. delete 操作符调用 operator\r\ndelete(0x5000)。 2. 默认的 operator delete(0x5000) 函数内部调用\r\nfree(0x5000)。 3. free 函数将这块内存归还给 malloc\r\n的空闲池，或者通过 munmap\r\n归还给操作系统（如果是大块内存）。\r\n数组的特殊情况：new[] 和\r\ndelete[]\r\n这就是为什么 new[] 必须配对 delete[]，new 必须配对 delete。\r\n\r\nMyClass* arr = new MyClass[10]; (new[])\r\n\r\n分配：调用 operator\r\nnew[]。这个函数不仅会申请 10 * sizeof(MyClass)\r\n的内存。它几乎总是会多申请几个字节（例如 4 或 8\r\n字节），用来存储数组的长度\r\n10。这个元数据（“cookie”）通常放在返回的指针地址之前。\r\n\r\n例如, 如果 sizeof(MyClass) 是 32 字节, 那么 operator new[] 会调用\r\nmalloc(10 * 32 + 8)（假设 8 字节用于存储长度）, 假设获取到的内存地址是\r\n0x6000 到 0x60C0, 那么它会在 0x6000 处存储整数\r\n10（数组长度），然后返回给用户的指针是 0x6008。\r\n\r\n构造：new[]\r\n操作符会进入一个循环，在分配好的内存上（跳过”cookie”）连续调用\r\n10 次 MyClass 的默认构造函数 (MyClass::MyClass())。\r\n\r\n\r\ndelete[] arr; (delete[]) -\r\n析构：delete[]\r\n操作符会首先去读取那个“cookie”（例如，在 arr\r\n指针之前的几个字节），发现数组长度是 10。然后，它会进入一个循环，从\r\narr[9] 到 arr[0] 反向调用 10\r\n次析构函数（~MyClass()）。\r\n\r\n释放：在所有对象都被析构后，它会调用 operator\r\ndelete[] 来释放整个内存块（包括存储”cookie”的那几个字节）。\r\n\r\n为什么混用是灾难？假设 delete arr; (用在 new[]\r\n分配的内存上):\r\ndelete\r\n不会去查找”cookie”。它只会调用一次析构函数（即\r\narr[0].~MyClass()）。其他 9\r\n个对象永远不会被析构，导致严重的资源泄漏。\r\n它调用 operator delete(arr)，而不是 operator\r\ndelete[]。这可能会导致堆损坏，因为 operator delete\r\n没有正确处理”cookie”所占用的空间。\r\n分段和分页\r\n操作系统通过分段 (Segmentation) 和\r\n分页 (Paging)\r\n两种机制来管理内存。它们都用于解决同一个核心问题：如何将程序看到的“虚拟地址”安全、高效地转换为“物理地址”（即\r\nRAM 上的真实地址）。\r\n分段 (Segmentation)\r\n分段是一种面向程序员和逻辑结构的管理方式。它认为一个程序天然就由几个逻辑部分组成，比如代码段\r\n(Code Segment), 数据段 (Data\r\nSegment),和堆栈段 (Stack Segment)\r\n等。每个段都有自己的基地址 (Base) 和\r\n界限\r\n(Limit)，操作系统通过这些信息来进行地址转换和保护。 &gt;\r\n比喻：把内存想象成一本书，书被分成了若干“章”（段）。\r\n分段的工作方式:\r\n\r\n块大小：可变的 (Variable-sized),\r\n每个段的大小根据程序的需要动态变化\r\n地址形式：一个虚拟地址由两部分组成：（段号，段内偏移量）,\r\n假设数据段是段号 2，基地址是 0x2000，界限是 0x1000（4KB），那么虚拟地址\r\n(2, 0x0500) 实际对应的物理地址是 0x2000 + 0x0500 = 0x2500。\r\n管理机制 (段表 Segment Table)：\r\n\r\n操作系统为每个进程维护一个段表，记录每个段的基地址和界限。\r\n当程序访问一个虚拟地址时，硬件会查找段表，找到对应段的基地址和界限，然后进行地址转换和边界检查。\r\n例如, 一个段表可能是这样的: 段号 | 基地址  | 界限------------------------ 0   | 0x0000  | 0x1FFF  (代码段) 1   | 0x2000  | 0x2FFF  (数据段) 2   | 0x3000  | 0x3FFF  (堆栈段)\r\n\r\n寻址过程：\r\n\r\n程序生成一个虚拟地址 (段号, 偏移量)。\r\n硬件查找段表，获取该段的基地址和界限。\r\n检查偏移量是否在界限内。\r\n如果合法，计算物理地址 = 基地址 + 偏移量。\r\n如果越界，触发异常 (段错误, Segmentation Fault),\r\n表示访问了非法内存。\r\n\r\n\r\n优点： - 逻辑清晰：与程序结构一致，易于理解。 -\r\n保护简单：可以轻松地给整个“代码段”设置“只读”权限，给“数据段”设置“读写”权限。\r\n致命缺点：外部碎片 (External Fragmentation)\r\n由于段的大小是可变的，随着程序的运行，内存中会出现许多不连续的小空闲块，这些小块可能无法满足新的内存分配请求，导致内存利用率低下。\r\n分页 (Paging)\r\n分页是一种面向硬件和固定大小块的管理方式。它将内存划分为固定大小的块，称为页\r\n(Page)，通常是 4KB 或\r\n8KB。程序的虚拟地址空间也被划分为同样大小的页。分页通过页表\r\n(Page Table) 来实现虚拟地址到物理地址的映射。 &gt;\r\n比喻：把内存想象成一本书，书被分成了若干“页”。\r\n分页的工作方式: - 块大小：固定的 (Fixed-sized),\r\n每页的大小是预定义的（例如 4KB）。 -\r\n地址形式：一个虚拟地址被划分为两部分：（页号，页内偏移量）,\r\n假设页大小是 4KB (0x1000)，那么虚拟地址 0x2500 可以分解为页号 2 (0x2000\r\n/ 0x1000) 和页内偏移量 0x0500 (0x2500 % 0x1000)。 - 管理机制 (页表 Page\r\nTable)： -\r\n操作系统为每个进程维护一个页表，记录每个虚拟页号对应的物理页框号。\r\n-\r\n当程序访问一个虚拟地址时，硬件会查找页表，找到对应的物理页框，然后进行地址转换。\r\n- 例如, 一个页表可能是这样的: 虚拟页号 | 物理页框号------------------------   0     |    5   1     |    3   2     |    8 - 寻址过程： 1.\r\n程序生成一个虚拟地址 (页号, 偏移量)。 2.\r\n硬件查找页表，获取该虚拟页号对应的物理页框号。 3. 计算物理地址 =\r\n(物理页框号 * 页大小) + 偏移量。 4.\r\n如果虚拟页号不存在于页表中，触发异常 (缺页中断, Page\r\nFault), 由操作系统处理。 优点： -\r\n无外部碎片：由于页的大小是固定的，内存中不会出现无法利用的小空闲块。 -\r\n灵活性高：可以轻松地将虚拟页映射到任意物理页框，实现内存的高效利用。\r\n缺点： -\r\n内存开销：页表需要占用额外的内存空间，尤其是对于大地址空间的程序。 -\r\n地址转换开销：每次内存访问都需要查找页表，可能会影响性能。为了解决这个问题，现代\r\nCPU 引入了快表 (TLB, Translation Lookaside Buffer)\r\n来缓存最近使用的页表项，加速地址转换过程。\r\n缺页中断 (Page\r\nFault)和段错误 (Segmentation Fault)\r\n缺页中断和段错误是两种不同的内存访问异常,\r\n可以将它们理解为“事件”和“判决”的关系：\r\n\r\n当进程试图访问一个内存地址时, 硬件 (MMU)负责检查“页表”(Page Table)\r\n来翻译这个地址。\r\n假如MMU\r\n在页表中发现这个地址有问题（例如，权限不对，或者根本不在物理内存中）。硬件立即停下，并触发一个缺页错误\r\n(Page Fault) 异常。\r\n内核 (OS)接管这个异常，开始处理:\r\n\r\n情况A (合法的，“好”的 Page\r\nFault)：内核发现这个页只是被“换出”到磁盘了（Swap）。因此内核从磁盘读回数据到\r\nRAM，更新页表，然后重新启动刚才失败的指令。程序继续运行，毫不知情。\r\n\r\n换出磁盘的页通常是因为内存不足，操作系统需要腾出空间给其他进程使用。\r\n\r\n情况B (非法的，“坏”的 Page\r\nFault)：内核发现这个地址是完全非法的（例如 NULL\r\n指针，或一个野指针）。它向该进程发送一个 SIGSEGV 信号。\r\n\r\n当进程收到 SIGSEGV\r\n信号，默认动作是终止，并向控制台打印消息：“Segmentation fault”。\r\n\r\n\r\n\r\n所以，“段错误”是“非法缺页错误”导致的一种后果,\r\n指的是程序试图访问一个它不被允许访问的内存区域。不过尽管名字里有“段”(Segment)二字,\r\n但现代操作系统中的段错误实际上是由分页机制引起的,\r\n只不过由于历史原因, 这个术语沿用下来。\r\n现代系统（如 Linux,\r\nWindows）如何运作\r\n现代 64 位系统（x86-64,\r\nARM）压倒性地以“分页”为核心。不过硬件（x86-64\r\n架构）为了向后兼容，仍然保留了“分段”机制。\r\n具体做法：Linux 和 Windows 等现代 OS 采取了一种“扁平化\r\n(Flat)”策略来“绕过”分段。\r\n\r\n操作系统在启动时，会设置一个（或几个）“段”。\r\n它将这个段的基地址 (Base) 设为 0, 界限 (Limit)\r\n设为最大可能值（例如，整个 64 位地址空间）。\r\n结果是 物理地址 = Base + 偏移量 变成了 物理地址 = 0 + 偏移量; 偏移量\r\n&lt; Limit 这个检查永远为真。\r\n分段机制在功能上被“禁用”了。所有的地址翻译、内存保护、安全检查工作，全部交由更高效、更灵活的“分页”机制来完成。\r\n\r\n不过，分段机制仍然存在于硬件中，并且在某些特殊情况下（如内核态代码）可能会被使用，但对于大多数用户态程序来说，分页才是主角。\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"进程间通信","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/","content":"Linux操作系统支持的进程间通信（IPC）机制主要包括以下几种： \r\n","categories":["system","linux"],"tags":["system"]},{"title":"进程","url":"/2025/09/25/system/linux/Linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/%E8%BF%9B%E7%A8%8B/","content":"进程和程序 (Process and\r\nProgram)\r\n程序(Program)是一组指令的集合，通常存储在磁盘等静态存储介质上。它本身是静态的、被动的，不占用系统的运行资源（如CPU时间、内存等）。\r\n进程(Process)是程序的一次执行实例。当程序被加载到内存中并开始执行时，就创建了一个进程。它是动态的、活动的，是操作系统资源分配（如内存、文件句柄）和CPU调度的基本单位(更精确的说法是将线程视为独立调度单位)。\r\n进程的状态 (Process States)\r\n在三态模型中，进程状态分为三个基本状态，即：运行态、就绪态、阻塞态；\r\n在五态模型中，进程状态分为五个基本状态，即：新建态、终止态、运行态、就绪态、阻塞态；\r\nps 命令\r\nps (Process Status)\r\n命令用于显示当前系统的进程快照，即执行命令那一刻的进程信息。通常使用ps aux来显示所有用户的(a)、包含完整格式的、包括无终端进程(x)在内的所有进程的详细状态(u)。\r\ntop 命令\r\ntop\r\n命令用于动态显示系统中各个进程的资源占用情况，默认每隔几秒刷新一次。它提供了一个实时的视图，可以看到\r\nCPU 和内存的使用情况，以及各个进程的状态。\r\nkill 命令\r\nkill 命令用于向进程发送终止进程的信号（Signal）,\r\n常见的流程为:\r\n\r\n使用 ps 或 top 找到目标进程的ID（PID）。\r\n执行 kill 。\r\n如果进程没有响应，可以执行 kill -9  强制终止。\r\n\r\n进程号和相关函数\r\n(Process IDs and Related Functions)\r\n在操作系统内部，每个进程都有唯一的标识符和关联信息。在编程中，我们可以通过特定的函数来获取这些信息。\r\n\r\n进程ID (PID)：每个进程都有一个唯一的非负整数标识符。\r\n父进程ID (PPID)：标识创建当前进程的那个进程。所有进程（除了初始的\r\ninit 进程）都是由其他进程创建的。\r\n进程组ID\r\n(PGID)：进程组是一个或多个进程的集合。通常，同一个作业（Job）中的所有进程属于同一个进程组。\r\n\r\n在C语言等编程环境中，可以通过以下标准函数获取这些ID：\r\ngetpid(): 获取当前进程的ID。\r\n原型：pid_t getpid(void);\r\n说明：该函数不接受参数，并返回调用它的进程的PID。pid_t\r\n通常是一个整数类型。\r\ngetppid(): 获取当前进程的父进程的ID。\r\n原型：pid_t getppid(void);\r\n说明：返回创建当前进程的那个父进程的PID。\r\ngetpgid():\r\n获取指定进程的进程组ID。\r\n原型：pid_t getpgid(pid_t pid);\r\n说明：如果参数 pid 为0，则返回当前进程的进程组ID。否则，返回PID为 pid\r\n的进程的进程组ID。\r\n进程的创建 (Process Creation)\r\n在 Linux/Unix-like 操作系统中，创建一个新进程的主要方式是通过\r\nfork() 系统调用。\r\nfork()\r\n的工作机制非常独特：它会创建一个与调用它的进程（称为父进程）几乎一模一样的新进程（称为子进程）。这个子进程是父进程的一个副本，它从\r\nfork() 调用返回之后开始执行。\r\n#include &lt;unistd.h&gt;pid_t fork(void);功能:    从一个已存在的进程中创建一个新进程(子进程), 该子进程是调用进程(父进程)的一个副本参数:     无返回值:    成功时, 在父进程中返回子进程的 PID, 在子进程中返回 0    失败时, 返回 -1, 并设置 errno\r\n#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int main(void){    //创建子进程    fork();    printf(\"hello world\\n\");    return 0;}\r\n上述代码编译执行后会输出两次 “hello world”，原因在于当父进程调用\r\nfork() 时，操作系统会创建一个几乎与父进程完全相同的子进程,\r\n这两个进程（父进程和子进程）在创建完毕后都会从 fork()\r\n调用处返回, 继续执行 fork()\r\n下一行的后续代码，因此 printf(“hello world”);\r\n这行代码会被父子进程执行两次。\r\n循环创建进程\r\n(Creating Processes in a Loop)\r\n当 fork() 被放置在循环中时, 会创建多个子进程,\r\n每个子进程又会继续执行循环体内的代码,\r\n这可能会导致指数级增长的进程数量。\r\nfor (int i = 0; i &lt; 3; i++) {    fork();    // ...}\r\n如上, 原始进程 P0 调用 fork()，创建子进程 C1。现在有两个进程：P0 和\r\nC1, 在第2次循环 (i=1)中P0 和 C1 都会 继续执行循环产生共计四个进程,\r\n接着又会产生更多进程……\r\n也就是说, 在循环中直接调用 fork()\r\n会导致进程数量呈指数级增长。如果不加控制，这种代码会迅速耗尽系统资源，形成所谓的“fork\r\n炸弹”（Fork Bomb），可能导致系统崩溃。因此，在实际应用中，通常会结合 if\r\n判断 fork() 的返回值，确保只有父进程（或特定进程）继续创建新的子进程。\r\nfor (int i = 0; i &lt; 3; i++) {    pid_t pid = fork();    if (pid &gt; 0) {        // 父进程继续创建子进程        continue;    } else if (pid == 0) {        // 子进程跳出循环，避免继续创建子进程        break;    } else {        // 处理 fork() 失败的情况        perror(\"fork failed\");        exit(1);    }}\r\n父子进程关系\r\n(Parent-Child Process Relationship)\r\n通过 fork()\r\n创建的进程之间形成了明确的父子关系，这种关系是进程管理的基础。子进程在创建时会继承父进程的大部分资源和属性，包括：\r\n\r\n进程地址空间的副本（下文详述）。\r\n打开的文件描述符（File Descriptors）(因此也共享文件偏移量)。\r\n环境变量。\r\n当前工作目录。\r\n用户ID (UID) 和组ID (GID)。\r\n\r\n另一方面,\r\n虽然子进程是父进程的副本，但它们是两个独立的进程，拥有自己独特的属性：\r\n\r\n进程ID (PID)：子进程有自己唯一的 PID。\r\n父进程ID (PPID)：子进程的 PPID 是其父进程的 PID。\r\n资源统计：CPU时间、内存使用等资源消耗是独立计算的。\r\n\r\n父进程的责任：父进程通常需要负责“回收”子进程的资源。当子进程结束后，它会变成一个僵尸进程\r\n(Zombie Process)，直到父进程通过 wait() 或\r\nwaitpid()\r\n系统调用获取其退出状态后，子进程才会彻底消失。如果父进程不执行此操作，僵尸进程会一直占用系统资源。\r\n父子进程地址空间\r\n(Parent-Child Address Space)\r\n进程地址空间是指进程可以访问的内存区域，包括代码段、数据段、堆和栈。父子进程的地址空间遵循以下几个原则：\r\n独立性原则：fork()\r\n之后，父进程和子进程拥有各自独立的地址空间。任何一方对其地址空间中的数据（如变量）进行修改，都不会影响到另一方。\r\n读时共享, 写时复制 (Copy-on-Write,\r\nCOW):\r\n虽然逻辑上地址空间是独立的，但操作系统为了提高效率，并不会在 fork()\r\n时立即完整地复制父进程的所有物理内存页给子进程。\r\n相反, 当 fork()\r\n创建子进程时，子进程的虚拟地址空间与父进程相同，并且它们共享相同的物理内存页。这些内存页被内核标记为“只读”。\r\n当父进程或子进程尝试写入某个共享的内存页时，会触发一个缺页异常\r\n(Page\r\nFault)。内核捕获到这个异常，此时才会为写入方复制一份该内存页的副本，并将该副本映射到其地址空间，然后执行写入操作。\r\n这些原则使得 fork()\r\n的创建速度非常快，因为它避免了大量不必要的内存复制;\r\n同时还兼具智能性：如果子进程创建后立即调用 exec()\r\n系列函数来执行一个新程序（这是一种非常常见的模式），那么之前的地址空间会被完全替换。COW\r\n机制避免了在这种情况下进行无用的内存复制，极大地提升了系统性能。\r\nCOW机制的示例// 父子进程地址空间int main(void){    int var = 88;    pid_t pid = -1;    // 创建一个子进程    pid = fork();    if (-1 == pid)    {        perror(\"fork\");        return 1;    }    if (0 == pid)    {        // 子进程        sleep(1);        printf(\"子进程睡醒之后 var = %d\\n\", var); //88    }    else    {        // 父进程        printf(\"父进程之前 var = %d\\n\", var); //88        var++;        printf(\"父进程之后 var = %d\\n\", var); //89    }    return 0;}\r\n可以看到, 在 fork() 之前，父子进程共享变量 var 的内存页; 父进程执行\r\nvar++; 将其私有 var 从 88 改为 89。此时，COW\r\n触发，内核为父进程分配了一个新的内存页来存放父进程的 var=89, 而子进程的\r\nvar 仍然指向原来的内存页，值仍为 88。父子进程各自拥有独立的 var\r\n变量，互不影响。\r\n进程的终止 (Process\r\nTermination)\r\n进程终止是指一个进程完成其任务并退出运行的过程。进程可以通过多种方式终止，包括正常退出和异常终止。\r\n进程的正常退出通常是通过调用 exit() 函数或者 _exit()\r\n函数来实现的。\r\n#include &lt;stdlib.h&gt;void exit(int status);#include &lt;unistd.h&gt;void _exit(int status);功能:    终止调用进程, 并将状态码 status 返回给父进程参数:    status: 进程的退出状态码, 一般传入0表示正常退出\r\n这两者的主要区别在于，exit() 是一个C 标准库 libc\r\n中的库函数,\r\n会执行标准I/O缓冲区的清理工作（如刷新缓冲区、关闭文件等），而\r\n**_exit()** 是一个系统调用，由内核直接处理,\r\n直接终止进程，不进行任何清理操作。\r\n因此, exit()主要用于进程的正常退出, 清理资源; 而 _exit()\r\n通常用于在子进程中调用，以确保子进程终止时不会影响父进程的资源状态。\r\n等待子进程退出的函数\r\n当一个子进程结束其生命周期时，它的父进程有责任去“回收”它。这个回收过程主要有两个目的：\r\n获取子进程的退出状态：父进程可以了解到子进程是正常结束的，还是因为某个错误或信号而异常终止的，以及它的返回值是什么。\r\n清理子进程的资源：通过执行等待函数，父进程通知内核它已经知晓子进程的状态，内核此时可以彻底释放子进程在进程表中占用的条目和其他资源。\r\n如果父进程不执行这个回收操作，那么已经终止的子进程将变成一个僵尸进程，持续占用系统资源。因此，使用\r\nwait() 或 waitpid() 函数是健壮的并发程序设计中必不可少的一环。\r\nwait() 函数\r\nwait 函数是的最基本的方法 #include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;pid_t wait(int *wstatus);功能:    阻塞父进程(调用进程), 直到其任意一个子进程终止参数:    wstatus: 一个指向int类型的指针, 是传出参数, 用于存储子进程的退出状态信息. 如果不关心子进程的退出状态, 可以传入 NULL. 我们可以使用一组宏来解析这个状态值：        WIFEXITED(wstatus)：如果子进程是正常退出的，则返回真。        WEXITSTATUS(wstatus)：如果 WIFEXITED 为真，这个宏会返回子进程的退出码（即 main 函数的 return 值或 exit() 的参数）。        WIFSIGNALED(wstatus)：如果子进程是因信号而异常终止的，则返回真。        WTERMSIG(wstatus)：如果 WIFSIGNALED 为真，这个宏会返回导致子进程终止的信号编号。返回值:    成功时, 返回终止的子进程的 PID    失败时, 返回 -1, 并设置 errno\r\nwaitpid() 函数\r\nwaitpid 函数是 wait\r\n函数的一个更强大、更灵活的版本。它可以等待指定的子进程，并且可以选择非阻塞的方式进行等待。\r\n#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;pid_t waitpid(pid_t pid, int *wstatus, int options);功能:    等待指定的子进程终止, 或者在非阻塞模式下检查子进程的状态参数:    pid: 指定要等待的子进程的 PID。它有几种特殊的取值:        pid &gt; 0: 等待 PID 等于 pid 的子进程。        pid == 0: 等待与调用进程在同一进程组中的任意子进程。        pid &lt; -1: 等待进程组 ID 等于 -pid 的任意子进程。        pid == -1: 等同于 wait()，等待任意子进程。    wstatus: 一个指向 int 类型的指针, 用于存储子进程的退出状态信息. 如果不关心子进程的退出状态, 可以传入 NULL.    options: 控制 waitpid 行为的选项, 常用的选项包括:        WNOHANG: 非阻塞模式, 如果当前没有子进程终止, 则立即返回0, 而不是阻塞等待.        WUNTRACED: 如果子进程被停止(如接收到 SIGSTOP 信号), 也会返回其状态.返回值:    成功时, 返回终止的子进程的 PID. 如果使用 WNOHANG 选项且没有子进程终止, 则返回 0    失败时, 返回 -1, 并设置 errno\r\n僵尸进程 &amp;\r\n孤儿进程 (Zombie Process &amp; Orphan Process)\r\n这两个概念是理解进程生命周期管理的关键。\r\n僵尸进程 (Zombie Process)\r\n\r\n定义：一个已经执行完毕、终止运行，但其父进程尚未通过\r\nwait() 或 waitpid() 回收它的进程。\r\n产生原因：子进程先于父进程结束,\r\n子进程结束后，其在内核进程表中的条目（包含PID、退出状态等信息）需要被保留，直到父进程读取这些信息。\r\n状态：在 ps 或 top 命令中，状态通常显示为 Z\r\n(Zombie)。\r\n危害：僵尸进程本身不占用CPU或内存，但它会占用进程表中的一个位置(PID)。如果系统中存在大量僵尸进程，可能会耗尽可用的PID资源，导致无法创建新进程。\r\n解决方法：父进程必须调用 wait 或\r\nwaitpid\r\n来回收子进程。如果父进程异常退出，其子僵尸进程会被 init\r\n进程（PID为1）接管并自动回收。\r\n\r\n孤儿进程 (Orphan Process)\r\n\r\n定义：一个父进程已经终止，但它自身还在运行的子进程。\r\n产生原因：父进程先于子进程结束。\r\n生命周期：当一个进程变成孤儿进程后，为了确保它最终能被回收，操作系统会将其过继给\r\ninit 进程(在现代系统中可能是\r\nsystemd)，其PPID变为1。\r\n“领养”过程：init\r\n进程会自动成为所有孤儿进程的新的父进程。init\r\n进程有一个循环，会定期调用 wait\r\n来回收它所有已终止的子进程（包括它领养的这些孤儿进程）。\r\n结论：孤儿进程不会对系统造成危害，因为它们会被\r\ninit 进程妥善管理和回收，不会变成僵尸进程。\r\n\r\n进程替换 (Process\r\nReplacement)\r\n在 Unix/Linux\r\n系统中，进程替换是指一个进程通过调用进程替换函数来加载并执行一个新的程序，从而替换掉当前进程的地址空间、代码和数据,\r\n同时保留其原有的进程ID和其他系统资源（如文件描述符、信号处理程序等），从而实现了进程的动态更新。\r\n常用的进程替换函数是 exec 函数族. 在替换后,\r\n以下几个关键点需要注意:\r\n\r\n进程 ID 不变： 这是 exec 与 fork 的最大区别。fork\r\n创建一个新进程，exec 是在当前进程上加载新程序。\r\n地址空间替换：\r\n当前进程的整个用户区地址空间（包括\r\n.text、.data、堆、栈等）都会被新的程序代码和数据覆盖和替换。\r\n成功不返回： 如果 exec\r\n函数调用成功，新的程序将从其自己的 main() 函数开始执行，exec\r\n函数永远不会返回。只有在 exec 调用失败时，它才会返回 −1。\r\n文件描述符保留：\r\n默认情况下，所有打开的文件描述符（包括标准输入\r\nFD 0、标准输出 FD 1 等）都会被新程序继承。\r\n\r\nexec\r\n族函数有六个主要成员（execl、execlp、execle、execv、execvp、execvpe），它们的区别主要在于如何传递参数和如何查找程序：\r\n| 函数名 | 参数传递方式 | 环境变量传递 | 程序查找方式 |\r\n|——–|—————-|———–|——————-| | execl | 可变参数列表(l) | 使用当前环境变量 |\r\n需要提供完整路径 | | execlp | 可变参数列表(l) | 使用当前环境变量 | 使用\r\nPATH 环境变量查找程序(p) | | execle | 可变参数列表(l) |\r\n需要提供环境变量(e) | 需要提供完整路径 | | execv | 参数数组(v) |\r\n使用当前环境变量 | 需要提供完整路径 | | execvp | 参数数组(v) |\r\n使用当前环境变量 | 使用 PATH 环境变量查找程序(p) | | execvpe|\r\n参数数组(v) | 需要提供环境变量(e) | 使用 PATH 环境变量查找程序(p) |\r\nexeclp() 函数\r\n该函数通常用来调用系统的可执行程序，如：cat、ls、date #include &lt;unistd.h&gt;int execlp(const  char *file，const  char *arg，...)功能:    用于在当前进程中执行一个新的程序, 替换当前进程的地址空间参数:    file: 要执行的程序的文件名, 如果不包含路径, 则会在 PATH 环境变量指定的目录中查找    arg: 可变参数列表, 代表传递给新程序的参数. 第一个参数是程序的名称, 后面的参数是传递给程序的命令行参数. 最后一个参数必须是 NULL, 以标识参数列表的结束.返回值:    成功时, 不返回, 因为当前进程的地址空间被新程序替换    失败时, 返回 -1, 并设置 errno\r\n#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;int main(void){    pid_t pid = fork();    if(pid &lt; 0)    {        //fork失败        perror(\"fork\");        exit(1);    }    else if(pid == 0)    {        //子进程        execlp(\"ls\",\"ls\",\"-l\",\"-h\",NULL); // 第一个是新进程的文件名, 第二个是传递给新进程的argv[0], 后面是参数列表, 最后一个必须是NULL        // 因为执行ls时第一个参数也是ls, 所以这里共传递两个\"ls\"        perror(\"execlp error\");  //如果execlp成功，下面的不执行        exit(1);    }    else if(pid &gt; 0)    {    //父进程    sleep(1);    printf(\"我是父进程:%d\\n\",getpid());    wait(NULL); //等待子进程退出    }    return 0;} 需要注意的是, exec 函数族中的任何一个函数（如 execlp,\r\nexecl 等）执行成功，它将永远不会返回到调用它的原函数或原程序。\r\n这是因为 exec 的本质是进程替换（Process\r\nReplacement），而不是函数调用或程序跳转。一旦 exec\r\n函数成功后，当前进程的地址空间已经被新程序完全替换，这个进程的PC地址被设置为新进程的的\r\nmain() 函数。因此，任何在 exec 调用之后的代码都不会被执行，除非 exec\r\n调用失败。\r\n不过, 原先的父进程通常仍然需要 wait（或 waitpid）\r\n来等待子进程结束并回收资源。因为父子关系仍然存在，新程序执行完毕后，它也会调用\r\nexit() 或 return，导致子进程终止, 进而影响父进程。\r\nexecl() 函数\r\n#include &lt;unistd.h&gt;int execl(const char *path, const char *arg, ...);功能:    用于在当前进程中执行一个新的程序, 替换当前进程的地址空间参数:    path: 要执行的程序的完整路径, 通常用来执行自己当前目录下的可执行文件    arg: 可变参数列表, 代表传递给新程序的参数. 第一个参数是程序的名称, 后面的参数是传递给程序的命令行参数. 最后一个参数必须是 NULL, 以标识参数列表的结束.返回值:    成功时, 不返回, 因为当前进程的地址空间被新程序替换    失败时, 返回 -1, 并设置 errno\r\n#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;int main(void){    pid_t pid = fork();    if(pid &lt; 0)    {        //fork失败        perror(\"fork\");        exit(1);    }    else if(pid == 0)    {        //子进程        execl(\"./wait\",\"wait\",NULL);        perror(\"execlp error\");  //如果execl成功，下面的不执行        exit(1);    }    else if(pid &gt; 0)    {        //父进程        sleep(1);        printf(\"我是父进程:%d\\n\",getpid());        wait(NULL); //等待子进程退出    }    return 0;}\r\nfork 和 exec 的协作\r\n在 Linux 中，启动一个新的程序(例如在 Shell 中调用\r\nls.exe)通常是一个两步过程，它们必须配合使用：\r\n\r\nfork()： 父进程(这里的shell)调用 fork，创建一个子进程。\r\nexec()： 子进程调用 exec 族函数，将自己替换成新的程序(如 ls)。\r\n父进程等待： 父进程通常会调用 wait() 等待子进程执行完毕并退出。\r\n\r\n这种 fork + exec 模式是 Linux/Unix\r\n操作系统构建命令行环境和启动新应用的基石。\r\n","categories":["system","linux"],"tags":["system"]},{"title":"Alpha对冲","url":"/2025/10/16/misc/Quant/Strategy/Alpha%E5%AF%B9%E5%86%B2/","content":"这是一个在机构投资者和对冲基金中广泛使用的市场中性策略，其目标是剥离市场的系统性风险（Beta），从而获取纯粹的、由选股能力带来的超额收益（Alpha）。\r\n策略原理\r\nAlpha (α) 与 Beta\r\n(β)：解构投资收益的来源\r\n在金融学中，投资收益通常可以分解为两部分：\r\n\r\nBeta\r\n(β)：代表市场收益和风险，反映了投资组合相对于市场整体的波动性。高\r\nBeta\r\n值意味着投资组合对市场变动的敏感度较高，可能带来更高的收益，但也伴随更大的风险。\r\nAlpha\r\n(α)：代表超额收益，反映了投资组合在剔除市场风险后所获得的额外回报。正\r\nAlpha\r\n值意味着投资经理的选股能力强，带来了独立于市场涨跌的超额收益。\r\n\r\n通过对 Alpha 和 Beta\r\n的分析，投资者可以更好地理解其投资组合的表现，并制定相应的对冲策略。\r\n如何实现Alpha对冲？\r\n策略的核心思想是通过同时持有多头和空头头寸，来剥离市场的系统性风险（Beta），从而专注于获取选股带来的超额收益（Alpha）。\r\n\r\n构建Alpha组合：首先，通过你的选股模型（在这个策略里是低EV/EBITDA因子），精心挑选出一篮子你认为会跑赢市场的股票，并买入它们（做多）。这个组合同时包含了你期望的Alpha和你不想要的Beta。\r\n对冲Beta风险：同时，在股指期货市场上，做空与你股票组合市值相当的股指期货合约。股指期货的涨跌与整个市场高度相关。\r\n\r\n此时,\r\n当市场上涨时，你的股票组合（大概率）会上涨，获得Beta收益；但你做空的股指期货会亏损,\r\n两者相互抵消。\r\n当市场下跌时，你的股票组合（大概率）会下跌，产生Beta亏损；但你做空的股指期货会盈利。\r\n最终结果是,\r\n通过期货的做空头寸，市场涨跌带来的Beta收益和亏损被相互抵消了。最后剩下的，就是你的选股组合跑赢市场基准的那一部分——纯粹的Alpha收益。\r\n策略实现\r\n本策略将上述原理转化为了一个清晰、可执行的月度调仓计划。\r\n第一步：Alpha因子选择与组合构建\r\n\r\n选股池: 沪深300指数的成份股。\r\nAlpha因子: EV/EBITDA (企业价值/息税折旧摊销前利润)。\r\n\r\n这是一个常用的价值因子，类似于市盈率(P/E)。它衡量的是一家公司的企业价值（市值+净负债）是其核心盈利能力的多少倍。EV/EBITDA值越低，通常意味着该公司可能被市场低估。\r\n\r\n策略假设:\r\n选取EV/EBITDA值最低的一批股票，可以构建一个跑赢沪深300指数的Alpha组合。\r\n组合构建:\r\n每月选取30只EV/EBITDA值最低且大于零的股票，并对它们进行等权重资金分配。\r\n\r\n第二步：Beta对冲工具选择\r\n\r\n对冲工具: 沪深300股指期货\r\n(CFFEX.IF)。因为股票池来自沪深300，所以用对应的股指期货来对冲，相关性最高，对冲效果最好。\r\n\r\n第三步：调仓与执行\r\n\r\n每月调仓一次，卖出不再符合条件的旧股票，买入新选出的股票，并同时调整股指期货的空头头寸，使其名义价值与股票组合的总市值保持大致相等。\r\n\r\n策略代码\r\n# coding=utf-8from __future__ import print_function, absolute_import, unicode_literalsfrom gm.api import *'''本策略每隔1个月定时触发计算SHSE.000300成份股的过去一天EV/EBITDA值并选取30只EV/EBITDA值最小且大于零的股票对不在股票池的股票平仓并等权配置股票池的标的并用相应的CFFEX.IF对应的真实合约等额对冲回测数据为:SHSE.000300和他们的成份股和CFFEX.IF对应的真实合约回测时间为:2017-07-01 08:00:00到2017-10-01 16:00:00注意：本策略仅供参考，实际使用中要考虑到期货和股票处于两个不同的账户，需要人为的保证两个账户的资金相同。'''def init(context):    # 每月第一个交易日09:40:00的定时执行algo任务（仿真和实盘时不支持该频率）    schedule(schedule_func=algo, date_rule='1m', time_rule='09:40:00')    # 设置开仓在股票和期货的资金百分比(期货在后面自动进行杠杆相关的调整)    context.percentage_stock = 0.4    context.percentage_futures = 0.4def algo(context):    # 获取当前时刻    now = context.now    # 获取上一个交易日    last_day = get_previous_trading_date(exchange='SHSE', date=now)    # 获取沪深300成份股的股票代码    stock300 = get_history_constituents(index='SHSE.000300', start_date=last_day,                                                end_date=last_day)[0]['constituents'].keys()    # 获取上一个工作日的CFFEX.IF对应的合约    index_futures = get_continuous_contracts(csymbol='CFFEX.IF', start_date=last_day, end_date=last_day)[-1]['symbol']    # 获取当天有交易的股票    not_suspended_info = get_history_instruments(symbols=stock300, start_date=now, end_date=now)    not_suspended_symbols = [item['symbol'] for item in not_suspended_info if not item['is_suspended']]    # 获取成份股EV/EBITDA大于0并为最小的30个    fin = get_fundamentals(table='trading_derivative_indicator', symbols=not_suspended_symbols,                           start_date=now, end_date=now, fields='EVEBITDA',                           filter='EVEBITDA&gt;0', order_by='EVEBITDA', limit=30, df=True)    fin.index = fin.symbol    # 获取当前仓位    positions = context.account().positions()    # 平不在标的池或不为当前股指期货主力合约对应真实合约的标的    for position in positions:        symbol = position['symbol']        sec_type = get_instrumentinfos(symbols=symbol)[0]['sec_type']        # 若类型为期货且不在标的池则平仓        if sec_type == SEC_TYPE_FUTURE and symbol != index_futures:            order_target_percent(symbol=symbol, percent=0, order_type=OrderType_Market,                                 position_side=PositionSide_Short)            print('市价单平不在标的池的', symbol)        elif symbol not in fin.index:            order_target_percent(symbol=symbol, percent=0, order_type=OrderType_Market,                                 position_side=PositionSide_Long)            print('市价单平不在标的池的', symbol)    # 获取股票的权重    percent = context.percentage_stock / len(fin.index)    # 买在标的池中的股票    for symbol in fin.index:        order_target_percent(symbol=symbol, percent=percent, order_type=OrderType_Market,                             position_side=PositionSide_Long)        print(symbol, '以市价单调多仓到仓位', percent)    # 获取股指期货的保证金比率    ratio = get_history_instruments(symbols=index_futures, start_date=last_day, end_date=last_day)[0]['margin_ratio']    # 更新股指期货的权重    percent = context.percentage_futures * ratio    # 买入股指期货对冲    # 注意：股指期货的percent参数是按照期货的保证金来算比例，不是按照合约价值， 比如说0.1就是用0.1的仓位的资金全部买入期货。    order_target_percent(symbol=index_futures, percent=percent, order_type=OrderType_Market,                         position_side=PositionSide_Short)    print(index_futures, '以市价单调空仓到仓位', percent)if __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2017-07-01 08:00:00',        backtest_end_time='2017-10-01 16:00:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=10000000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"Dual Thrust 策略","url":"/2025/10/16/misc/Quant/Strategy/Dual%20Thrust/","content":"Dual Thrust 策略（双向推力策略）由 Michael Chalek 于 20 世纪 80\r\n年代提出，是一种旨在捕捉日内突破的趋势跟踪系统。它利用前一个交易周期（通常是前一日）的价格波动信息来确定当前交易日的开仓区间。\r\n该策略的关键在于建立一个动态的交易区间，包含一个上限（阻力线）和一个下限（支撑线）。\r\n\r\n突破上限（阻力线）：被视为强烈的向上动能，产生做多信号。\r\n跌破下限（支撑线）：被视为强烈的向下动能，产生做空信号。\r\n\r\n区间边界的计算（策略核心）\r\n上下限的设定是 Dual Thrust\r\n策略的核心，它决定了突破的敏感度。它结合了前一个交易周期的最高价、最低价和收盘价，以确定一个有效的波动幅度。\r\n\r\nHH: N 日内的最高价的最高值 (Highest High)。\r\nHC: N 日内的收盘价的最高值 (Highest Close)。\r\nLC: N 日内的收盘价的最低值 (Lowest Close)。\r\nLL: N 日内的最低价的最低值 (Lowest Low)。\r\n\r\n波动范围的计算遵循以下公式: \r\n这个公式试图捕捉过去 N 天内市场的最大价格运动幅度。\r\nHH - LC 代表了“最大上涨力量”（从最低收盘价到最高价的距离）。 HC - LL\r\n代表了“最大下跌力量”（从最高收盘价到最低价的距离）。\r\n取这两者中的较大值，可以更稳健地代表近期的市场波动性。\r\n设定上下轨 (Trigger Lines):\r\n\r\n上轨 (买入触发线): \r\n下轨 (卖出触发线): \r\n\r\n这里的 K1 和 K2\r\n是敏感度系数。它们控制了交易区间的宽度。K\r\n值越小，区间越窄，交易信号越频繁，但也越容易被市场噪音触发。K\r\n值越大，区间越宽，信号更少，但一旦触发，可能代表着更强的趋势。\r\n一个有趣的应用是，当交易者对后市的上涨和下跌预期不对称时，可以设置不同的\r\nK1 和 K2。例如，如果认为上涨趋势更容易形成，可以设置一个较小的 K1\r\n和一个较大的 K2。\r\n策略逻辑\r\n策略的日内执行逻辑是一个清晰的“停止-反转”(Stop-And-Reverse)系统。\r\n每日开盘前:\r\n\r\n第一步: 设置好核心参数 N, K1, K2。\r\n第二步: 获取过去 N 天的日线数据。\r\n第三步: 根据公式计算出当日的 Range 值。\r\n\r\n当日开盘后:\r\n\r\n第四步: 获取当日的开盘价 Open。\r\n第五步: 计算出当日的上轨 BuyLine 和下轨\r\nSellLine。这两条线在当天是固定不变的。\r\n\r\n盘中持续监控:\r\n\r\n第六步: 监控实时价格。\r\n做多信号: 当价格向上突破 BuyLine 时：\r\n\r\n如果当前持有空仓，则先平掉空仓，再开立多仓。\r\n如果当前无持仓，则直接开立多仓。\r\n如果当前已持有多仓，则无操作。\r\n\r\n做空信号: 当价格向下突破 SellLine 时：\r\n\r\n如果当前持有多仓，则先平掉多仓，再开立空仓。\r\n如果当前无持仓，则直接开立空仓。\r\n如果当前已持有空仓，则无操作。\r\n\r\n\r\n策略代码\r\n下面的代码示例展示了如何实现 Dual Thrust 交易策略：\r\n# coding=utf-8from __future__ import print_function, absolute_importfrom gm.api import *\"\"\"Dual Thrust是一个趋势跟踪系统计算前N天的最高价－收盘价和收盘价－最低价。然后取这2N个价差的最大值，乘以k值。把结果称为触发值。在今天的开盘，记录开盘价，然后在价格超过上轨（开盘＋触发值）时马上买入，或者价格低于下轨（开盘－触发值）时马上卖空。没有明确止损。这个系统是反转系统，也就是说，如果在价格超过（开盘＋触发值）时手头有空单，则平空开多。同理，如果在价格低于（开盘－触发值）时手上有多单，则平多开空。选用了SHFE的rb2010 在2020-02-07 15:00:00 到 2020-04-15 15:00:00' 进行回测。注意： 1：为回测方便，本策略使用了on_bar的一分钟来计算，实盘中可能需要使用on_tick。2：实盘中，如果在收盘的那一根bar或tick触发交易信号，需要自行处理，实盘可能不会成交\"\"\"# 策略中必须有init方法def init(context):    # 设置要进行回测的合约（可以在掘金终端的仿真交易中查询标的代码）    context.symbol = 'SHFE.rb2010'  # 订阅&amp;交易标的, 此处订阅的是上期所的螺纹钢 2010    # 设置参数    context.N = 5    context.k1 = 0.2    context.k2 = 0.2    # 获取当前时间    time = context.now.strftime('%H:%M:%S')    # 如果策略执行时间点是交易时间段，则直接执行algo定义buy_line和sell_line，以防直接进入on_bar()导致context.buy_line和context.sell_line未定义    if '09:00:00' &lt; time &lt; '15:00:00' or '21:00:00' &lt; time &lt; '23:00:00':        algo(context)    # 如果是交易时间段，等到开盘时间确保进入algo()    schedule(schedule_func = algo, date_rule = '1d', time_rule = '09:00:00')    schedule(schedule_func = algo, date_rule = '1d', time_rule = '21:00:00')    # 只需要最新价，所以只需要订阅一个, 如果用tick，次数太多，用一分钟线代替    subscribe(symbols=context.symbol, frequency='60s', count = 1)def algo(context):    # 取历史数据    data = history_n(symbol=context.symbol, frequency='1d', end_time=context.now,                     fields='symbol,open,high,low,close', count=context.N + 1, df=True)    # 取开盘价    # 回测模式下，开盘价可以直接用history_n取到    if context.mode == 2:        # 获取当天的开盘价        current_open = data['open'].loc[context.N]        # 去掉当天的实时数据        data.drop(context.N, inplace = True)    # 如果是实时模式，开盘价需要用current取到    else:        # 获取当天的开盘价        current_open = current(context.symbol)[0]['open']    # 计算Dual Thrust 的上下轨    HH = data['high'].max()    HC = data['close'].max()    LC = data['close'].min()    LL = data['low'].min()    range = max(HH - LC, HC - LL)    context.buy_line = current_open + range * context.k1  # 上轨    context.sell_line = current_open - range * context.k2  # 下轨def on_bar(context, bars):    # 取出订阅的这一分钟的bar    bar = bars[0]    # 取出买卖线    buy_line =  context.buy_line    sell_line = context.sell_line    # 获取现有持仓    position_long = context.account().position(symbol=context.symbol, side=PositionSide_Long)    position_short = context.account().position(symbol=context.symbol, side=PositionSide_Short)    # 交易逻辑部分    # 如果超过range的上界    if bar.close &gt; buy_line:        if position_long:  # 已经持有多仓，直接返回            return        elif position_short:  # 已经持有空仓，平仓再做多。            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy,                         order_type=OrderType_Market, position_effect=PositionEffect_Close)            print('市价单平空仓', context.symbol)            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('市价单开多仓', context.symbol)        else:  # 没有持仓时，市价开多。            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('市价单开多仓', context.symbol)    # 如果低于range的下界    elif bar.close &lt; sell_line:        if position_long:  # 已经持有多仓， 平多再开空。            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell,                         order_type=OrderType_Market, position_effect=PositionEffect_Close)            print('市价单平多仓', context.symbol)            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('市价单开空仓', context.symbol)        elif position_short:  # 已经持有空仓，直接返回。            return        else:  # 没有持仓，直接开空            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('市价单开空仓', context.symbol)if __name__ == '__main__':    '''        strategy_id策略ID,由系统生成        filename文件名,请与本文件名保持一致        mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST        token绑定计算机的ID,可在系统设置-密钥管理中生成        backtest_start_time回测开始时间        backtest_end_time回测结束时间        backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST        backtest_initial_cash回测初始资金        backtest_commission_ratio回测佣金比例        backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2020-02-07 15:00:00',        backtest_end_time='2020-04-15 15:00:00',        backtest_initial_cash= 30000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"做市商策略","url":"/2025/10/16/misc/Quant/Strategy/%E5%81%9A%E5%B8%82%E5%95%86%E7%AD%96%E7%95%A5/","content":"做市商策略 (Market Maker\r\nStrategy)是一个典型的高频交易策略，其核心目标不是预测市场的长期方向，而是通过为市场提供流动性，从买卖价差（Bid-Ask\r\nSpread）中赚取微小但频繁的利润。\r\n\r\n核心职能:\r\n一个健康的金融市场需要随时都有人愿意买，也随时有人愿意卖。做市商就是这样的参与者，他们主动、持续地向市场报出自己的买入价（Bid）和卖出价（Ask）。\r\n盈利模式:\r\n做市商的利润来源，正是其报出的卖出价与买入价之间的差额，即买卖价差\r\n(Bid-Ask\r\nSpread)。假如做市商以6344的价格卖出的同时，希望能以6333的价格买入，如果双边都成交，他就赚取了11个点的价差。这是一个积少成多的过程。\r\n\r\n核心风险：库存风险与逆向选择\r\n做市商并非稳赚不赔，它面临着巨大的风险，其中最核心的是：\r\n库存风险 (Inventory Risk):\r\n\r\n场景:\r\n当市场出现单边下跌行情时，做市商的买单会不断被“聪明”的交易者成交，导致做市商积累了大量亏损的多头头寸（库存）。\r\n场景:\r\n当市场单边上涨时，做市商的卖单会不断被成交，导致其积累大量亏损的空头头寸。\r\n本质:\r\n做市商的目标是维持一个中性的、零风险的库存。一旦库存失衡，做市商就从一个流动性提供者，被迫变成了一个承担方向性风险的投机者。\r\n\r\n逆向选择 (Adverse Selection):\r\n\r\n场景:\r\n拥有信息优势或速度优势的交易者，总是在对做市商最不利的时候来与你交易。例如，当他们知道价格即将上涨时，他们会迅速吃掉你的卖单。\r\n本质:\r\n做市商永远在和比自己“更快”或“更聪明”的对手方博弈，这要求做市商必须拥有极低延迟的交易系统和复杂的报价模型来保护自己。\r\n\r\n策略逻辑\r\n我们来介绍一个最简化、最基础的被动做市商模型，它的逻辑非常纯粹：\r\n第一步：数据源:\r\n订阅Tick级别的数据。这是最高频率的数据，包含了每一次最优买卖价（盘口）的变动。做市商策略必须工作在这样的高频数据上。\r\n第二步：定义交易行为\r\n\r\n开多仓: 在当前的买一价 (Best Bid Price) 挂一个限价买单。\r\n开空仓: 在当前的卖一价 (Best Ask Price) 挂一个限价卖单。\r\n平多仓: 在当前的卖一价 (Best Ask Price) 挂一个限价卖单。\r\n平空仓: 在当前的买一价 (Best Bid Price) 挂一个限价买单。\r\n\r\n第三步：执行循环\r\n策略的目标是始终尝试在市场上同时持有一个多头仓位和一个空头仓位（或者说，始终挂着一个买单和一个卖单）。\r\n\r\n如果没有多仓，就去挂买单。如果有了多仓，就去挂卖单尝试平仓。\r\n如果没有空仓，就去挂卖单。如果有了空仓，就去挂买单尝试平仓。\r\n只要买单成交后，对应的平仓卖单也能成交，一个完整的“低买高卖”循环就完成了，策略赚取了一个买卖价差。\r\n\r\n策略代码\r\n下面是一个非常简化的代码示例，展示了做市商策略的核心逻辑：\r\n# coding=utf-8from __future__ import print_function, absolute_import, unicode_literalsfrom gm.api import *'''本策略通过不断对CZCE.CF801进行:买(卖)一价现价单开多(空)仓和卖(买)一价平多(空)仓来做市, 并以此赚取差价回测数据为:CZCE.CF801的tick数据回测时间为:2017-09-29 11:25:00到2017-09-29 11:30:00需要特别注意的是:本平台对于回测对限价单固定完全成交, 本例子仅供参考.目前只支持最近三个月的tick数据，回测时间和标的需要修改'''def init(context):   # context 是框架提供的对象, 它在策略初始化时由 gm.api 自动传入 init 函数。可以把它理解为“全局变量对象”，策略运行期间的各种信息都可以放在里面。    # 订阅CZCE.CF801的tick数据    context.symbol = 'CZCE.CF801'  # symbol为订阅的交易标的    subscribe(symbols=context.symbol, frequency='tick') # subscribe函数用于订阅行情数据, symbols为订阅的标的, frequency为数据频率, 此时订阅的是tick数据    # Tick = 最小价格变动数据, 每当市场上有新的成交或者盘口变化，就会产生一个 tick 数据。(盘口”是指市场上当前的买卖挂单情况，也就是 买卖双方的报价和数量信息)def on_tick(context, tick):  # on_tick函数是策略的核心函数, 每当有新的tick数据到达时, 框架会自动调用这个函数, 并把最新的tick数据传入tick参数    # 获取最新的盘口数据    quotes = tick['quotes'][0]   # tick结构见下文, 通过调用这一行代码可以获取当前的盘口快照(买一到买五, 卖一到卖五的价格和手数)    # 获取持有的多仓, context.account() 返回 当前策略绑定的交易账户对象, position() 方法用于查询持仓, side=PositionSide_Long 表示查询多仓    position_long = context.account().position(symbol=context.symbol, side=PositionSide_Long)    # 获取持有的空仓    position_short = context.account().position(symbol=context.symbol, side=PositionSide_Short)    # 没有仓位则双向开限价单    # 若有仓位则限价单平仓    if not position_long:        # 获取买一价        price = quotes['bid_p']        print('买一价为: ', price)        # 下单买入1手多仓, order_target_volume函数用于下单, symbol为交易标的, volume为目标持仓量(调整仓位到目标手数), price为限价单价格, order_type为订单类型(限价单或市价单), position_side为持仓方向(多仓或空仓)        order_target_volume(symbol=context.symbol, volume=1, price=price, order_type=OrderType_Limit,                            position_side=PositionSide_Long)        print('CZCE.CF801开限价单多仓1手')    else:        # 获取卖一价        price = quotes['ask_p']        print('卖一价为: ', price)        # 下一个卖单就可以把多仓平掉        order_target_volume(symbol=context.symbol, volume=0, price=price, order_type=OrderType_Limit,                            position_side=PositionSide_Long)        print('CZCE.CF801平限价单多仓1手')    if not position_short:        # 获取卖一价        price = quotes['ask_p']        print('卖一价为: ', price)        order_target_volume(symbol=context.symbol, volume=1, price=price, order_type=OrderType_Limit,                            position_side=PositionSide_Short)        print('CZCE.CF801卖一价开限价单空仓')    else:        # 获取买一价        price = quotes['bid_p']        print('买一价为: ', price)        order_target_volume(symbol=context.symbol, volume=0, price=price, order_type=OrderType_Limit,                            position_side=PositionSide_Short)        print('CZCE.CF801买一价平限价单空仓')if __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    backtest_transaction_ratio回测成交比例    '''    # 启动策略的回测或实盘运行, 启动后框架会自动调用 init(context) 初始化策略, 在每个回测时间点调用 on_tick 或 on_bar记录账户资金变化、持仓、盈亏等, 最终输出回测报告    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2017-09-29 11:25:00',        backtest_end_time='2017-09-29 11:30:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=500000,        backtest_commission_ratio=0.00006,        backtest_slippage_ratio=0.0001,        backtest_transaction_ratio=0.5)\r\n部分代码解释:\r\n\r\ntick 是一个字典（dict）, 通常包含以下主要字段: tick = {    \"symbol\": \"CZCE.CF801\",  # 合约代码    \"time\": \"2025-10-17 13:30:01.123\",  # tick 时间    \"last\": 1234.5,  # 最新成交价    \"volume\": 100,    # 最新成交量（通常是单笔成交量）    \"quotes\": [       # 当前盘口快照        {            \"bid\": [1234.0, 1233.5, 1233.0, ...],  # 买一到买五价格            \"bid_volume\": [10, 15, 20, ...],      # 买一到买五手数            \"ask\": [1235.0, 1235.5, 1236.0, ...],# 卖一到卖五价格            \"ask_volume\": [5, 10, 8, ...]        # 卖一到卖五手数        }    ]}\r\n\r\n需要注意的是，本演示策略只是用作示例，在现实中，以买一和卖一挂单不一定会成交，实际收益率也达不到示例水平。做市商策略对交易系统的延迟要求极高，且需要非常复杂的风险控制和资金管理逻辑，建议有一定量化交易经验的用户再进行尝试。\r\n","categories":["misc"],"tags":["misc"]},{"title":"双均线策略","url":"/2025/10/16/misc/Quant/Strategy/%E5%8F%8C%E5%9D%87%E7%BA%BF%E7%AD%96%E7%95%A5/","content":"均线的“前世今生”\r\n移动平均线（Moving Average,\r\nMA），一个进行形态分析时总也绕不过去的指标。\r\n均线最早由美国投资专家Joseph\r\nE.Granville(格兰威尔)于20世纪中期提出，现在仍然广泛为人们使用，成为判断买卖信号的一大重要指标。从统计角度来说，均线就是历史价格的平均值，可以代表过去N日股价的平均走势。\r\n\r\n一般来说, 均线最常使用的是收盘价,\r\n但也可以使用开盘价、最高价、最低价等价格来计算均线。\r\n\r\n1962年7月，Joseph\r\nE.Granville在他的书中提出了著名的Granville八大买卖法则。只利用股价和均线即可进行择时，方法简单有效，一经提出，迅速受到市场追捧。尤其是其中的金叉和死叉信号，更是沿用至今。\r\nGranville\r\n八大法则其中有四条是用于判断买进时机，另外四条是用于判断卖出时机。买进和卖出法则一一对应，分布在高点的左右两侧（除买4和卖4以外）。法则内容如下所示：\r\n买1：均线整体上行，股价由下至上上穿均线，此为黄金交叉，形成第一个买点。\r\n买2：股价出现下跌迹象，但尚未跌破均线，此时均线变成支撑线，形成第二个买点。\r\n买3：股价仍处于均线上方，但呈现急剧下跌趋势。当跌破均线时，出现第三个买点。\r\n买4：（右侧）股价和均线都处于下降通道，且股价处于均线下方，严重远离均线，出现第四个买点。\r\n卖1：均线由上升状态变为缓慢下降的状态，股价也开始下降。当股价跌破均线时，此为死亡交叉，形成第一个卖点。\r\n卖2：股价仍处于均线之下，但股价开始呈现上涨趋势，当股价无限接近均线但尚未突破时，此时均线变成阻力线，形成第二个卖点。\r\n卖3：股价终于突破均线，处于均线上方。但持续时间不长，股价开始下跌，直至再一次跌破均线，此为第三个卖点。\r\n卖4：（左侧）股价和均线都在上涨，股价上涨的速度远快于均线上涨的速度。当股价严重偏离均线时，出现第四个卖点。\r\n &gt;\r\n图中的买3和卖3描述相反\r\n均线理论为什么有效？\r\nShiller（1981）在研究中发现，资产的长期价格呈现均值回复的特征，即从长期来看，资产的价格会回归均值。这也是均线理论被广泛应用的前提。\r\n均线理论的缺陷\r\n均线归根到底是一种平均值，平均值在应用过程中存在最大的问题就是其滞后性。当出现买入卖出信号时，最佳时机早已过去。举例来说，如果A股票最新价格出现了较大的涨幅，股价和均线都上涨，但均线的速度慢于股价上涨速度。此时，从形态上来看，金叉出现，为买入信号。次日，股价回调，股价下降的速度快于均线下降的速度，形成死叉，为卖点。这样一买一卖不仅没有盈利，反而出现亏损。\r\n均线理论的改进\r\n针对均线的缺点，市场上提出了各种各样的改进方法。\r\n1.对均线的计算方法进行改正。\r\n加权移动平均线是在移动平均线的基础上按照时间进行加权。越靠近当前日期的价格对未来价格的影响越大，赋予更大的权重；越远离当前日期价格，赋予越小的权重。\r\n例如, 5日加权移动平均线的计算公式为：\r\n\r\n其中，P1、P2、P3、P4、P5分别为第1天、第2天、第3天、第4天和第5天的收盘价。\r\n指数平滑移动平均线（Exponential Moving Average,\r\nEMA）是对加权移动平均线的进一步改进。它通过指数衰减的方式赋予最近的价格更大的权重，从而使得均线对最新价格变化更加敏感。\r\nEMA的计算公式为： EMAt = (Pt ⋅ α) + (EMAt − 1 ⋅ (1 − α))\r\n其中，Pt\r\n是当前价格，EMAt − 1\r\n是前一时期的EMA值，α\r\n是平滑系数，通常计算为 ，其中N是选定的时间周期。\r\n2.调整均线周期\r\n利用不同周期均线得到的结果也不同。许多有经验的投资者发现，在不同的市场中，有些均线的效果显著优于其他周期均线。有些长线投资者还会将股价替换成短周期均线进行趋势判断。\r\n通用双均线（DMA）交易策略代码示例\r\n下面的代码示例展示了如何实现通用双均线（DMA）交易策略：\r\n标的：任意金融产品（例如股票、期货等）。\r\n周期：1分钟 K线数据（或其他您选择的周期）。\r\n参数：短周期均线（Short MA）设置为 20，长周期均线（Long MA）设置为\r\n60。\r\n\r\n交易信号：\r\n\r\n做多信号：短期均线由下向上穿越长期均线（金叉）。\r\n做空信号：短期均线由上向下穿越长期均线（死叉）。\r\n持仓管理：每次开仓前，先平掉所有现有仓位（反向开仓）。\r\n\r\n\r\n# coding=utf-8from __future__ import print_function, absolute_importfrom gm.api import *  # 引入掘进量化交易APIimport talib'''本策略以SHFE.rb2101为交易标的，根据其一分钟(即60s频度）bar数据建立双均线模型，短周期为20，长周期为60，当短期均线由上向下穿越长期均线时做空，当短期均线由下向上穿越长期均线时做多,每次开仓前先平掉所持仓位，再开仓。注：为了适用于仿真和实盘，在策略中增加了一个“先判断是否平仓成功再开仓”的判断逻辑，以避免出现未平仓成功，可用资金不足的情况。回测数据为:SHFE.rb2101的60s频度bar数据回测时间为:2020-04-01 09:00:00到2020-05-31 15:00:00'''def init(context):    context.short = 20                                             # 短周期均线    context.long = 60                                              # 长周期均线    context.symbol = 'SHFE.rb2101'                                 # 订阅交易标的    context.period = context.long + 1                              # 订阅数据滑窗长度    context.open_long = False                                      # 开多单标记    context.open_short = False                                     # 开空单标记    subscribe(context.symbol, '60s', count=context.period)         # 订阅行情def on_bar(context, bars):    # 获取通过subscribe订阅的数据    prices = context.data(context.symbol, '60s', context.period, fields='close')    # 利用talib库计算长短周期均线    short_avg = talib.SMA(prices.values.reshape(context.period), context.short)    long_avg = talib.SMA(prices.values.reshape(context.period), context.long)    # 查询持仓    position_long = context.account().position(symbol=context.symbol, side=1)    position_short = context.account().position(symbol=context.symbol, side=2)    # 短均线下穿长均线，做空(即当前时间点短均线处于长均线下方，前一时间点短均线处于长均线上方)    if long_avg[-2] &lt; short_avg[-2] and long_avg[-1] &gt;= short_avg[-1]:        # 无多仓情况下，直接开空        if not position_long:            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell, position_effect=PositionEffect_Open,                        order_type=OrderType_Market)            print(context.symbol, '以市价单调空仓到仓位')        # 有多仓情况下，先平多，再开空(开空命令放在on_order_status里面)        else:            context.open_short = True            # 以市价平多仓            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell, position_effect=PositionEffect_Close,                         order_type=OrderType_Market)            print(context.symbol, '以市价单平多仓')    # 短均线上穿长均线，做多（即当前时间点短均线处于长均线上方，前一时间点短均线处于长均线下方）    if short_avg[-2] &lt; long_avg[-2] and short_avg[-1] &gt;= long_avg[-1]:        # 无空仓情况下，直接开多        if not position_short:            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy, position_effect=PositionEffect_Open,                         order_type=OrderType_Market)            print(context.symbol, '以市价单调多仓到仓位')        # 有空仓的情况下，先平空，再开多(开多命令放在on_order_status里面)        else:            context.open_long = True            # 以市价平空仓            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy,                        position_effect=PositionEffect_Close, order_type=OrderType_Market)            print(context.symbol, '以市价单平空仓')def on_order_status(context, order):    # 查看下单后的委托状态    status = order['status']    # 成交命令的方向    side = order['side']    # 交易类型    effect = order['position_effect']    # 当平仓委托全成后，再开仓    if status == 3:        # 以市价开空仓，需等到平仓成功无仓位后再开仓        # 如果无多仓且side=2（说明平多仓成功），开空仓        if effect == 2 and side == 2 and context.open_short:            context.open_short = False            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Sell, position_effect=PositionEffect_Open,                         order_type=OrderType_Market)            print(context.symbol, '以市价单调空仓到仓位')        # 以市价开多仓,需等到平仓成功无仓位后再开仓        # 如果无空仓且side=1（说明平空仓成功），开多仓        if effect == 2 and side == 1 and context.open_long:            context.open_long = False            order_volume(symbol=context.symbol, volume=1, side=OrderSide_Buy, position_effect=PositionEffect_Open,                         order_type=OrderType_Market)            print(context.symbol, '以市价单调多仓到仓位')if __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2020-04-01 09:00:00',        backtest_end_time='2020-05-31 15:00:00',        backtest_adjust=ADJUST_NONE,        backtest_initial_cash=10000000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"R-Breaker 策略","url":"/2025/10/16/misc/Quant/Strategy/R-Breaker/","content":"R-Breaker是一种日内回转交易策略，属于短线交易。日内回转交易是指当天买入或卖出标的后于当日再卖出或买入标的。日内回转交易通过标的短期波动盈利，低买高卖，时间短、投机性强，适合短线投资者。\r\n它的核心是一种双模式切换的交易思想。它不像单纯的趋势策略那样一条路走到黑，也不像单纯的反转策略那样总是在逆势抄底摸顶。它会根据当前是否持仓，来决定自己扮演“追随者”还是“逆行者”的角色。\r\n\r\n空仓时 →\r\n趋势跟踪模式：当账户没有任何仓位时，策略表现得像一个突破策略\r\n(Breakout\r\nStrategy)。它认为，如果价格能够强力突破根据昨日波动计算出的关键阻力/支撑位，那么日内很可能会形成一轮值得追随的趋势。\r\n持仓时 →\r\n反转交易模式：一旦持有了仓位，策略的“性格”就会立刻改变。它变得警惕起来，不再追涨杀跌，而是开始寻找趋势衰竭的迹象。如果价格在创出日内新高/新低后显现出疲态并回落到某个关键点位，策略会果断地认为趋势即将反转，从而进行反手操作。\r\n\r\n六大关键价位\r\n策略的灵魂在于根据前一交易日的数据，计算出六个固定的价格水平。这六个价位构成了当天所有交易决策的“地图”和“标尺”。\r\n不过在进行进一步的计算关键价位之前,\r\n我们还要先进行基础计算确定枢轴点:\r\n枢轴点 (Pivot Point): P = (前一日最高价 H +\r\n前一日最低价 L + 前一日收盘价 C) / 3\r\n它代表了前一交易日市场多空双方力量的均衡点或价值中枢,\r\n它是所有其他价位计算的基础。\r\n下面介绍六大价位 (从高到低):\r\n\r\n突破买入价 (Breakout Buy): bBreak = H + 2 * (P - L)\r\n\r\n这个价格显著高于前一日的最高价 H。价差 2 * (P - L)\r\n衡量了从最低点到中心点的两倍距离，可以理解为前一日多头力量的一种体现。只有当今日价格极度强势，远超昨日高点时，才触发趋势性买入。\r\n\r\n观察卖出价 (Setup Sell): sSetup = P + (H - L)\r\n\r\n逻辑解析: H - L 是前一日的波幅 (Range)。这个价位等于 中心价位 +\r\n一个完整的波幅，它同样高于前一日的最高价\r\nH。当价格达到这里时，意味着上涨趋势可能已接近潜在的衰竭点，需要开始“观察”是否有反转迹象。\r\n\r\n反转卖出价 (Enter Sell): sEnter = 2 * P - L\r\n\r\n逻辑解析:\r\n这个价位是多头持仓的反转止损线。它的位置相对灵活，但通常介于观察卖出价和枢轴点之间。\r\n\r\n反转买入价 (Enter Buy): bEnter = 2 * P - H\r\n\r\n逻辑解析: 与反转卖出价对称，是空头持仓的反转止损线。\r\n\r\n观察买入价 (Setup Buy): bSetup = P - (H - L)\r\n\r\n逻辑解析: 与观察卖出价对称，等于 中心价位 -\r\n一个完整的波幅。当价格跌至此处，意味着下跌趋势可能接近潜在的衰竭点，需要“观察”反弹。\r\n\r\n突破卖出价 (Breakout Sell): sBreak = L - 2 * (H - P)\r\n\r\n逻辑解析: 与突破买入价对称。价差 2 * (H - P)\r\n衡量了从中心点到最高点的两倍距离，代表前一日空头力量。只有当价格极度弱势时，才触发趋势性卖出。\r\n\r\n\r\n\r\n背后逻辑解析\r\n首先看一下这6个价格与前一日价格之间的关系。\r\n反转卖出价和反转买入价\r\n根据公式推导，发现这两个价格和前一日最高最低价没有确定的大小关系。\r\n观察卖出价和观察买入价。 用观察卖出价 -\r\n前一交易日最高价发现，(H+P-L)-H = P - L\r\n&gt;0,说明观察卖出价&gt;前一交易日最高价；同理可证，观察买入价&lt;前一交易日最低价。\r\n突破买入价和突破卖出价\r\n突破买入价&gt;观察卖出价&gt;前一交易日最高价，可以说明突破买入价&gt;&gt;前一交易日最高价。做差后可以发现，突破买入价\r\n- 前一交易日最高价 = 2[(C-L)+(H-L)]/3。\r\n用K线形态表示：\r\n前一交易日K线越长，下影线越长，突破买入价越高。\r\n前一交易日K线越长，上影线越长，突破卖入价越高。\r\n这样一来就可以解释R Breaker背后的逻辑了。\r\n当今日的价格突破前一交易日的最高点，形态上来看会是上涨趋势，具备一定的开多仓条件，但还不够。若前一交易日的下影线越长，说明多空方博弈激烈，多方力量强大。因此可以设置更高的突破买入价，一旦突破说明多方力量稳稳地占据了上风，那么就有理由相信未来会继续上涨。同理可解释突破卖出价背后的逻辑。\r\n持有多仓时，若标的价格持续走高，则在当天收盘之前平仓获利离场。若价格不升反降，跌破观察卖出价时，此时价格仍处于前一交易日最高价之上，继续观望。若继续下跌，直到跌破反转卖出价时，平仓止损。\r\n持有空仓时，若标的价格持续走低，则在当天收盘之前平仓获利离场。若价格不降反升，升至观察买入价时，此时价格仍处于前一交易日最低价之下，继续观望。若继续上涨，直到升至反转买入价时，平仓止损。\r\n策略步骤\r\n结合这六个价位，我们可以梳理出 R-Breaker\r\n在一个交易日内的完整决策流程。\r\n每日开盘前:\r\n\r\n获取前一交易日的 H, L, C 数据, 计算出枢轴点 P\r\n以及上述六个关键价位。这些价位在当天盘中是固定不变的。\r\n\r\n盘中 - 空仓状态:\r\n\r\n做多信号: 如果实时价格向上突破 突破买入价\r\n(bBreak)，则立即开仓做多。\r\n做空信号: 如果实时价格向下突破 突破卖出价\r\n(sBreak)，则立即开仓做空。\r\n\r\n盘中 - 持有多仓状态:\r\n\r\n反转条件 (两步):\r\n\r\n“预备”阶段: 盘中的日内最高价必须曾经触及或超过\r\n观察卖出价\r\n(sSetup)。这个条件达成后，策略就进入了“反转预警”状态。\r\n“触发”阶段:\r\n在“预备”条件满足后，如果价格从高位回落，并且向下跌破了\r\n反转卖出价 (sEnter)。\r\n\r\n执行动作:\r\n立即平掉所有多仓，并反手开立空仓。\r\n\r\n盘中 - 持有空仓状态:\r\n\r\n反转条件 (两步):\r\n\r\n“预备”阶段: 盘中的日内最低价必须曾经触及或低于\r\n观察买入价 (bSetup)。\r\n“触发”阶段:\r\n在“预备”条件满足后，如果价格从低位反弹，并且向上突破了\r\n反转买入价 (bEnter)。\r\n\r\n执行动作:\r\n立即平掉所有空仓，并反手开立多仓。\r\n\r\n每日收盘前:\r\n\r\n无论当前持有什么仓位，也无论盈亏，在收盘前几分钟强制平掉所有仓位，确保不持仓隔夜。这是日内交易的铁律。\r\n\r\n策略代码详解\r\n下面的代码示例展示了如何实现 R-Breaker 交易策略：\r\n# coding=utf-8from __future__ import print_function, absolute_importimport pandas as pdfrom gm.api import *from datetime import datetime, timedelta\"\"\"R-Breaker是一种短线日内交易策略根据前一个交易日的收盘价、最高价和最低价数据通过一定方式计算出六个价位，从大到小依次为：突破买入价、观察卖出价、反转卖出价、反转买入、观察买入价、突破卖出价。以此来形成当前交易日盘中交易的触发条件。追踪盘中价格走势，实时判断触发条件。具体条件如下：突破在空仓条件下，如果盘中价格超过突破买入价，则采取趋势策略，即在该点位开仓做多。在空仓条件下，如果盘中价格跌破突破卖出价，则采取趋势策略，即在该点位开仓做空。反转持多单，当日内最高价超过观察卖出价后，盘中价格出现回落，且进一步跌破反转卖出价构成的支撑线时，采取反转策略，即在该点位反手做空。持空单，当日内最低价低于观察买入价后，盘中价格出现反弹，且进一步超过反转买入价构成的阻力线时，采取反转策略，即在该点位反手做多。设定止损条件。当亏损达到设定值后，平仓。注意： 1：为回测方便，本策略使用了on_bar的一分钟来计算，实盘中可能需要使用on_tick。2：实盘中，如果在收盘的那一根bar或tick触发交易信号，需要自行处理，实盘可能不会成交。3：本策略使用在15点收盘时全平的方式来处理不持有隔夜单的情况，实际使用中15点是无法平仓的。\"\"\"def init(context):    # 设置交易品种    context.symbol = 'SHFE.ag'    # 设置止损点数    context.stopLossPrice = 50    # 获取前一交易日的主力合约    startDate = get_previous_trading_date(exchange='SHFE', date=context.now.date())    continuous_contract = get_continuous_contracts(context.symbol, startDate, startDate)    context.mainContract = continuous_contract[0]['symbol']    # 获取当前时间    time = context.now.strftime('%H:%M:%S')    # 如果当前时间是非交易时间段，则直接执行algo,以防直接进入on_bar()导致context.bBreak等未定义    if '09:00:00' &lt; time &lt; '15:00:00' or '21:00:00' &lt; time &lt; '23:00:00':        algo(context)    # 如果是交易时间段，等到开盘时间确保进入algo()    schedule(schedule_func = algo, date_rule = '1d', time_rule = '09:00:00')    schedule(schedule_func = algo, date_rule = '1d', time_rule = '21:00:00')    # 订阅行情    subscribe(continuous_contract[0]['symbol'], frequency='60s', count=1)def algo(context):    # 检查主力和约，发生变化则更换订阅    # 由于主力合约在盘后才公布，为了防止未来函数，选择上一交易日的主力合约。    startDate = get_previous_trading_date(exchange='SHFE', date=context.now.date())    contractInfo = get_continuous_contracts(context.symbol, startDate, startDate)    if context.mainContract != contractInfo[0]['symbol']:        context.mainContract = contractInfo[0]['symbol']        subscribe(context.mainContract, frequency='60s', count=1, unsubscribe_previous=True)    # 获取历史数据    data = history_n(symbol=context.mainContract, frequency='1d',                         end_time=context.now, fields='high,low,open,symbol,close', count=2, df=True)    high = data['high'].iloc[0]  # 前一日的最高价    low = data['low'].iloc[0]  # 前一日的最低价    close = data['close'].iloc[0]  # 前一日的收盘价    pivot = (high + low + close) / 3  # 枢轴点    context.bBreak = high + 2 * (pivot - low)  # 突破买入价    context.sSetup = pivot + (high - low)  # 观察卖出价    context.sEnter = 2 * pivot - low  # 反转卖出价    context.bEnter = 2 * pivot - high  # 反转买入价    context.bSetup = pivot - (high - low)  # 观察买入价    context.sBreak = low - 2 * (high - pivot)  # 突破卖出价    context.data = datadef on_bar(context, bars):    # 获取止损价    STOP_LOSS_PRICE = context.stopLossPrice    # 设置参数    bBreak = context.bBreak    sSetup = context.sSetup    sEnter = context.sEnter    bEnter = context.bEnter    bSetup = context.bSetup    sBreak = context.sBreak    data = context.data    # 获取现有持仓    position_long = context.account().position(symbol=context.mainContract, side=PositionSide_Long)    position_short = context.account().position(symbol=context.mainContract, side=PositionSide_Short)    # 突破策略:    if not position_long and not position_short:  # 空仓条件下        if bars[0].close &gt; bBreak:            # 在空仓的情况下，如果盘中价格超过突破买入价，则采取趋势策略，即在该点位开仓做多            order_volume(symbol=context.mainContract, volume=10, side=OrderSide_Buy,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)  # 做多            print(\"空仓,盘中价格超过突破买入价: 开仓做多\")            context.open_position_price = bars[0].close        elif bars[0].close &lt; sBreak:            # 在空仓的情况下，如果盘中价格跌破突破卖出价，则采取趋势策略，即在该点位开仓做空            order_volume(symbol=context.mainContract, volume=10, side=OrderSide_Sell,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)  # 做空            print(\"空仓,盘中价格跌破突破卖出价: 开仓做空\")            context.open_position_price = bars[0].close    # 设置止损条件    else:  # 有持仓时        # 开仓价与当前行情价之差大于止损点则止损        if (position_long and context.open_position_price - bars[0].close &gt;= STOP_LOSS_PRICE) or \\                (position_short and bars[0].close - context.open_position_price &gt;= STOP_LOSS_PRICE):            print('达到止损点，全部平仓')            order_close_all()  # 平仓        # 反转策略:        if position_long:  # 多仓条件下            if data.high.iloc[1] &gt; sSetup and bars[0].close &lt; sEnter:                # 多头持仓,当日内最高价超过观察卖出价后，                # 盘中价格出现回落，且进一步跌破反转卖出价构成的支撑线时，                # 采取反转策略，即在该点位反手做空                order_close_all()  # 平仓                order_volume(symbol=context.mainContract, volume=10, side=OrderSide_Sell,                             order_type=OrderType_Market, position_effect=PositionEffect_Open)  # 做空                print(\"多头持仓,当日内最高价超过观察卖出价后跌破反转卖出价: 反手做空\")                context.open_position_price = bars[0].close        elif position_short:  # 空头持仓            if data.low.iloc[1] &lt; bSetup and bars[0].close &gt; bEnter:                # 空头持仓，当日内最低价低于观察买入价后，                # 盘中价格出现反弹，且进一步超过反转买入价构成的阻力线时，                # 采取反转策略，即在该点位反手做多                order_close_all()  # 平仓                order_volume(symbol=context.mainContract, volume=10, side=OrderSide_Buy,                             order_type=OrderType_Market, position_effect=PositionEffect_Open)  # 做多                print(\"空头持仓,当日最低价低于观察买入价后超过反转买入价: 反手做多\")                context.open_position_price = bars[0].close    if context.now.hour == 14 and context.now.minute == 59:        order_close_all()        print('全部平仓')if __name__ == '__main__':    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2019-10-1 15:00:00',        backtest_end_time='2020-04-16 15:00:00',        backtest_initial_cash=1000000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"日内回转策略","url":"/2025/10/16/misc/Quant/Strategy/%E6%97%A5%E5%86%85%E5%9B%9E%E8%BD%AC%E7%AD%96%E7%95%A5/","content":"这个策略针对于A股等某些不支持T+0交易的市场，核心是在A股“T+1”的交易规则限制下，通过巧妙的仓位管理，实现变相的“T+0”交易，从而捕捉日内的短线波动利润。\r\nMACD指标：交易信号的来源\r\nMACD（Moving Average Convergence Divergence）, 即异同移动平均线,\r\n是一个经典的趋势判断指标，它的核心思想是通过比较短期趋势与长期趋势的“距离”和“变化”，来判断市场的趋势强弱和反转信号。它由三部分组成：\r\n\r\nDIF线 (差离值):\r\n短期（如12日）EMA与长期（如26日）EMA的差值，EMA(12) − EMA(26),\r\n反映了短期趋势的变化速度。\r\n\r\nEMA (Exponential Moving Average)\r\n指数移动平均线，是一种加权的移动平均线，较新的数据权重更大，更能反映近期价格变化。\r\n如果 DIF &gt; 0，说明短期均线在长期均线之上 → 市场偏多。\r\n如果 DIF &lt; 0，说明短期均线在长期均线之下 → 市场偏空。\r\n\r\nDEA线 (讯号线): DIF线的9日EMA，EMA(DIF, 9),\r\n是DIF的平滑线，用于确认趋势。\r\n\r\n如果 DIF 从下往上突破 DEA → 金叉（买入信号）\r\n如果 DIF 从上往下跌破 DEA → 死叉（卖出信号）\r\n\r\nMACD柱 (Histogram): (DIF - DEA) ×\r\n2，直观地表示了短期趋势与长期趋势的分离和聚合程度,\r\n可以揭示趋势的强弱。\r\n\r\n柱体越长 → 两者分离越大 → 趋势越强。\r\n柱体缩短 → 两者靠近 → 趋势减弱，可能反转。\r\n\r\n\r\n总之, DIF 看趋势，DEA 看确认，MACD柱 看强弱。\r\n","categories":["misc"],"tags":["misc"]},{"title":"海龟交易法和唐奇安通道","url":"/2025/10/16/misc/Quant/Strategy/%E6%B5%B7%E9%BE%9F%E4%BA%A4%E6%98%93%E6%B3%95/","content":"\r\n海龟交易法的传奇起源于这样一个问题：交易员是天生的还是后天培养的？\r\n传奇交易员理查德·丹尼斯 (Richard Dennis)\r\n相信，成功的交易员可以像海龟一样被“培育”出来。他认为，只要有一套明确、量化的规则，并严格遵守，普通人也能成为顶尖的交易员。这个实验的产物——海龟交易系统，证明了他的观点，并成为了量化交易领域的传世经典。\r\n\r\n海龟交易法则的本质是一个趋势跟踪 (Trend Following)\r\n策略。它基于一个哲学信念：市场价格倾向于在一段时间内向某个方向持续运动，形成趋势。该策略的目标就是尽早识别出新趋势的苗头，建立头寸，并尽可能地持有，直到有明确的信号表明趋势已经结束。\r\n它的“完整性”和“机械化”体现在它为一笔交易的全生命周期都提供了清晰的、不带感情色彩的规则：\r\n\r\n买卖什么？ (市场)\r\n买卖多少？ (头寸规模)\r\n何时买卖？ (入市信号)\r\n何时止损？ (风险控制)\r\n何时止盈？ (退出信号)\r\n\r\n策略的五大支柱\r\n我们可以将海龟交易法则拆解为五个环环相扣的核心组成部分。\r\n头寸规模：买卖多少？\r\n(风险管理的核心)\r\n这是海龟交易法则最核心、最天才的部分。它不问“这个信号能赚多少钱？”，而是先问“如果这个信号错了，我会亏多少钱？”。这一切都围绕着一个核心概念——波动性\r\n(Volatility)。\r\n\r\n定义波动性 N (Average True Range - ATR):\r\n策略首先需要量化市场的日常波动幅度。这通过计算平均真实波幅\r\n(ATR) 来实现。\r\n\r\n真实波幅 (True Range, TR) 的计算如下，取三者中的最大值：\r\n\r\n当日最高价 - 当日最低价\r\n当日最高价 - 上一交易日收盘价 |\r\n当日最低价 - 上一交易日收盘价 |\r\n\r\n平均真实波幅 (N 或 ATR) 则是过去 n 天 TR 值的简单移动平均值。\r\n\r\n计算 N\r\n的目的是为了让所有的交易决策都基于市场的真实波动性，而不是主观臆断。\r\n\r\n\r\n定义头寸单位 (Unit):\r\n海龟法则不以固定的“手数”来下单，而是以一个标准化的“单位”(Unit)来下单。一个\r\nUnit 的设计原则是：当价格向不利方向变动 1N 时，账户总资金的损失恰好是\r\n1%。\r\n\r\n价值波动量 (Dollar Volatility, DV)：首先计算 1N\r\n的波动对应多少现金价值。\r\n\r\nDV = N × 合约每点价值\r\n\r\n计算单位\r\n(Unit)：用总资产的1%除以价值波动量，得到每次应该交易的合约数量。\r\n\r\n总资产总资产合约每点价值\r\n\r\n这是风险标准化的关键。通过这个公式，无论是在波动剧烈的原油市场还是在波动平缓的玉米市场，一个\r\nUnit 所承担的风险都是完全一致的，即总资产的1%。\r\n\r\n入市信号：何时买入/卖出？\r\n海龟法则使用唐奇安通道 (Donchian Channel)\r\n来识别趋势的突破。唐奇安通道由过去 n\r\n天的最高价（上轨）和最低价（下轨）构成。\r\n系统一 (System 1)：短期系统\r\n\r\n入市信号：当价格向上突破过去 20日 的最高价时，买入一个\r\nUnit。当价格向下突破过去 20日 的最低价时，卖出一个 Unit。\r\n\r\n系统二 (System 2)：中长期系统\r\n\r\n入市信号：当价格向上突破过去 55日 的最高价时，买入一个\r\nUnit。当价格向下突破过去 55日 的最低价时，卖出一个 Unit。\r\n\r\n突破前期高点或低点被认为是市场原有均衡被打破的标志，可能预示着一轮新趋势的开启。\r\n加仓：如何扩大优势？\r\n海龟法则采用金字塔式加仓\r\n(Pyramiding)，在盈利的头寸上追加投资，让利润奔跑。\r\n加仓规则：在建立第一个 Unit\r\n的头寸后，如果市场价格继续沿着盈利方向移动\r\n1/2N，则加仓一个 Unit。\r\n虽然这种加仓方式比较激进，但它是基于波动性的，只有当趋势得到确认（价格持续朝有利方向移动）时才增加风险暴露。\r\n止损：何时承认错误？\r\n严格的止损是系统的安全带。\r\n止损规则：任何一笔交易的初始止损位都设置在距离入场价\r\n2N 的位置。\r\n风险上限：由于初始头寸是一个 Unit（代表1%的风险），而止损位在\r\n2N，这意味着任何一笔初始交易的最大亏损被严格限制在总资产的\r\n2%。\r\n动态调整：每加仓一次（增加 1/2N\r\n的盈利），整个头寸（包括之前的所有头寸）的止损位也随之提高\r\n1/2N。\r\n这种移动止损机制不仅能保护初始资本，还能逐步锁定浮动盈利。\r\n止盈退出：何时兑现利润？\r\n这是海龟法则中最反人性的部分。它没有固定的盈利目标，而是让趋势决定何时离场。\r\n系统一 (System 1) 退出：\r\n\r\n多头头寸：当价格跌破过去 10日 的最低价时离场。\r\n空头头寸：当价格涨破过去 10日 的最高价时离场。\r\n\r\n系统二 (System 2) 退出：\r\n\r\n多头头寸：当价格跌破过去 20日 的最低价时离场。\r\n空头头寸：当价格涨破过去 20日 的最高价时离场。\r\n\r\n这种退出机制的哲学是“给趋势足够的呼吸空间”。它允许价格在趋势中有较大幅度的回调而不被震荡出局，目标是完整地抓住一段大趋势，即使这意味着会回吐一部分浮动盈利。\r\n代码示例\r\n下面的代码示例展示了如何实现一个简单的海龟交易策略：\r\n# coding=utf-8from __future__ import print_function, absolute_import, unicode_literalsimport numpy as npimport pandas as pdfrom gm.api import *'''以短期为例：20日线第一步：获取历史数据，计算唐奇安通道和ATR第二步：当突破唐奇安通道时，开仓。第三步：计算加仓和止损信号。'''def init(context):    # 设置计算唐奇安通道的参数    context.n = 20    # 设置合约标的    context.symbol = 'DCE.i2012'    # 设置交易最大资金比率    context.ratio = 0.8    # 订阅数据    subscribe(symbols=context.symbol, frequency='60s', count=2)    # 获取当前时间    time = context.now.strftime('%H:%M:%S')    # 如果策略执行时间点是交易时间段，则直接执行algo定义atr等参数，以防直接进入on_bar()导致atr等未定义    if '09:00:00' &lt; time &lt; '15:00:00' or '21:00:00' &lt; time &lt; '23:00:00':        algo(context)    # 如果是交易时间段，等到开盘时间确保进入algo()    schedule(schedule_func=algo, date_rule='1d', time_rule='09:00:00')    schedule(schedule_func=algo, date_rule='1d', time_rule='21:00:00')def algo(context):    # 计算通道的数据:当日最低、最高、上一交易日收盘    # 注：由于talib库计算ATR的结果与公式求得的结果不符，所以这里利用公式计算ATR    # 如果是回测模式,当天的数据直接用history取到    if context.mode == 2:        data = history_n(symbol=context.symbol, frequency='1d', count=context.n+1, end_time=context.now, fields='close,high,low,bob', df=True) # 计算ATR        tr_list = []        for i in range(0, len(data)-1):            tr = max((data['high'].iloc[i] - data['low'].iloc[i]), data['close'].shift(-1).iloc[i] - data['high'].iloc[i],                     data['close'].shift(-1).iloc[i] - data['low'].iloc[i])            tr_list.append(tr)        context.atr = int(np.floor(np.mean(tr_list)))        context.atr_half = int(np.floor(0.5 * context.atr))        # 计算唐奇安通道        context.don_open = np.max(data['high'].values[-context.n:])        context.don_close = np.min(data['low'].values[-context.n:])    # 如果是实时模式，当天的数据需要用current取到    if context.mode == 1:        data = history_n(symbol=context.symbol, frequency='1d', count=context.n, end_time=context.now, fields='close,high,low',                         df=True)  # 计算ATR        current_data = current(symbols=context.symbol)   # 最新一个交易日的最高、最低        tr_list = []        for i in range(1, len(data)):            tr = max((data['high'].iloc[i] - data['low'].iloc[i]),                     data['close'].shift(-1).iloc[i] - data['high'].iloc[i],                     data['close'].shift(-1).iloc[i] - data['low'].iloc[i])            tr_list.append(tr)        # 把最新一期tr加入列表中        tr_new = max((current_data[0]['high'] - current_data[0]['low']),                     data['close'].iloc[-1] - current_data[0]['high'],                     data['close'].iloc[-1] - current_data[0]['low'])        tr_list.append(tr_new)        context.atr = int(np.floor(np.mean(tr_list)))        context.atr_half = int(np.floor(0.5 * context.atr))        # 计算唐奇安通道        context.don_open = np.max(data['high'].values[-context.n:])        context.don_close = np.min(data['low'].values[-context.n:])    # 计算加仓点和止损点    context.long_add_point = context.don_open + context.atr_half    context.long_stop_loss = context.don_open - context.atr_half    context.short_add_point = context.don_close - context.atr_half    context.short_stop_loss = context.don_close + context.atr_halfdef on_bar(context, bars):    # 提取数据    symbol = bars[0]['symbol']    recent_data = context.data(symbol=context.symbol, frequency='60s', count=2, fields='close,high,low')    close = recent_data['close'].values[-1]    # 账户仓位情况    position_long = context.account().position(symbol=symbol, side=PositionSide_Long)    position_short = context.account().position(symbol=symbol, side=PositionSide_Short)    # 当无持仓时    if not position_long and not position_short:        # 如果向上突破唐奇安通道，则开多        if close &gt; context.don_open:            order_volume(symbol=symbol, side=OrderSide_Buy, volume=context.atr, order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('开多仓atr')        # 如果向下突破唐奇安通道，则开空        if close &lt; context.don_close:            order_volume(symbol=symbol, side=OrderSide_Sell, volume=context.atr, order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('开空仓atr')    # 有持仓时    # 持多仓，继续突破（加仓）    if position_long:        # 当突破1/2atr时加仓        if close &gt; context.long_add_point:            order_volume(symbol=symbol, volume=context.atr_half, side=OrderSide_Buy, order_type=OrderType_Market,position_effect=PositionEffect_Open)            print('继续加仓0.5atr')            context.long_add_point += context.atr_half            context.long_stop_loss += context.atr_half        # 持多仓，止损位计算        if close &lt; context.long_stop_loss:            volume_hold = position_long['volume']            if volume_hold &gt;= context.atr_half:                order_volume(symbol=symbol, volume=context.atr_half, side=OrderSide_Sell, order_type=OrderType_Market, position_effect=PositionEffect_Close)            else:                order_volume(symbol=symbol, volume=volume_hold, side=OrderSide_Sell, order_type=OrderType_Market,position_effect=PositionEffect_Close)            print('平多仓0.5atr')            context.long_add_point -= context.atr_half            context.long_stop_loss -= context.atr_half    # 持空仓，继续突破（加仓）    if position_short:        # 当跌破加仓点时加仓        if close &lt; context.short_add_point:            order_volume(symbol = symbol, volume=context.atr_half, side=OrderSide_Sell, order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('继续加仓0.5atr')            context.short_add_point -= context.atr_half            context.short_stop_loss -= context.atr_half        # 持多仓，止损位计算        if close &gt; context.short_stop_loss:            volume_hold = position_short['volume']            if volume_hold &gt;= context.atr_half:                order_volume(symbol=symbol, volume=context.atr_half, side=OrderSide_Buy, order_type=OrderType_Market, position_effect=PositionEffect_Close)            else:                order_volume(symbol=symbol, volume=volume_hold, side=OrderSide_Buy, order_type=OrderType_Market,position_effect=PositionEffect_Close)            print('平空仓0.5atr')            context.short_add_point += context.atr_half            context.short_stop_loss += context.atr_halfif __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token',        backtest_start_time='2020-02-15 09:15:00',        backtest_end_time='2020-09-01 15:00:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=1000000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"网格交易","url":"/2025/10/16/misc/Quant/Strategy/%E7%BD%91%E6%A0%BC%E4%BA%A4%E6%98%93/","content":"网格交易法 (Grid Trading)\r\n是一种在震荡行情中表现出色的“自动化高抛低吸”策略，其核心思想与追涨杀跌的趋势策略完全相反，非常考验交易者对市场波动区间的判断。\r\n它的哲学非常直观：它不预测市场的未来方向，而是假设价格将在一个特定的区间内来回波动。\r\n\r\n策略行为:\r\n交易者预先设定一个价格区间（由压力位和支撑位定义），并在这个区间内密布多个预设的价格线（网格线）。\r\n\r\n当价格下跌并触及下方的某个节点时，就买入一份头寸。\r\n当价格上涨并触及上方的某个节点时，就卖出一份头寸。\r\n\r\n盈利模式:\r\n策略的利润来自于在低价节点买入、在高价节点卖出这一过程的不断重复。每一次成功的“一买一卖”循环，就锁定了一份由网格间距决定的利润。\r\n左侧交易:\r\n这是一种典型的左侧交易。它在价格下跌、看似“危险”时买入；在价格上涨、看似“乐观”时卖出。它总是在“逆”着短期的小趋势操作，赌的是价格会回归到区间的中心。\r\n\r\n风险与适用场景\r\n最大优势: 在横盘震荡市 (Ranging Market)\r\n中，网格交易法如同永动机一般，能够持续不断地从价格的无序波动中榨取利润。\r\n最大风险: 其“阿喀琉斯之踵”是强烈的单边趋势行情\r\n(Trending Market)。\r\n\r\n在持续的单边下跌中，策略会不断地在更低的价格买入、买入、再买入，导致积累大量浮动亏损的多头头寸，俗称“接飞刀”。\r\n在持续的单边上涨中，策略会不断地卖出、卖出、再卖出，最终可能耗尽持仓并开始建立亏损的空头头寸，导致“踏空”并转为逆势做空。\r\n\r\n因此，成功运用网格交易的关键在于正确判断当前市场处于震荡状态，并设定一个合理的波动区间。\r\n策略逻辑\r\n网格交易策略的实现可以分为以下几个步骤：\r\n第一步：设定网格\r\n\r\n价格中枢:\r\n策略以前一交易日的收盘价作为当天网格的中心基准。这个中枢价在当天是固定不变的。\r\n\r\n也可以用其他方法确定中枢价，比如前一日的最高价和最低价的均值，或者更复杂的技术指标。\r\n\r\n网格线: 在中枢价的基础上，按固定的百分比（如 ±1%,\r\n±2%,\r\n±3%）向上和向下扩展，形成一系列的网格线。这构成了一个等比例的网格系统。\r\n\r\n也可以用固定的点数间隔（如每隔10点）来设定网格线，具体取决于标的的价格水平和波动性,\r\n甚至可以用ATR等波动率指标来动态调整网格间距。\r\n\r\n网格区域: 相邻的两条网格线之间形成一个“区域”或“格子”。\r\n\r\n第二步：交易规则\r\n\r\n核心原则:\r\n当价格从一个网格区域移动到另一个相邻的网格区域时，触发一次交易。\r\n向上移动 (例如，从区域3进入区域4): 卖出 m\r\n手合约。如果原先持有多仓，则为平仓；如果原先为空仓或空头，则为开/加空仓。\r\n向下移动 (例如，从区域4进入区域3): 买入 m\r\n手合约。如果原先持有空仓，则为平仓；如果原先为空仓或多头，则为开/加多仓。\r\n\r\n举例分析\r\n在行情震荡上涨时: \r\n假设格子之间的差为1元钱，每变化一个格子相应的买入或卖出1手，则通过网格交易当前账户的净收益为6元，持空仓4手，持仓均价为12.5元。\r\n行情震荡下跌时： \r\n同理可知，净收益为8元，持4手多仓，平均成本为7.5元。\r\n可以看到，无论行情上涨还是下跌，已平仓的部分均为正收益，未平仓的部分需要等下一个信号出现再触发交易。\r\n即使网格交易能够获得较为稳定的收益，但也存在一定的风险。如果行情呈现大涨或大跌趋势，会导致不断开仓，增加风险敞口。这也是为什么网格交易更适用震荡行情，不合适趋势性行情。\r\n代码示例\r\n下面的代码示例展示了如何实现一个简单的网格交易策略：\r\n# coding=utf-8from __future__ import print_function, absolute_import, unicode_literalsimport numpy as npimport pandas as pdfrom gm.api import *'''本策略标的为：SHFE.rb1901价格中枢设定为：前一交易日的收盘价从阻力位到压力位分别为：1.03 * open、1.02 * open、1.01 * open、open、0.99 * open、0.98 * open、0.97 * open每变动一个网格，交易量变化100个单位回测数据为:SHFE.rb1901的1min数据回测时间为:2017-07-01 08:00:00到2017-10-01 16:00:00'''def init(context):    # 策略标的为SHFE.rb1901    context.symbol = 'SHFE.rb1901'    # 订阅SHFE.rb1901, bar频率为1min    subscribe(symbols = context.symbol, frequency='60s')    # 设置每变动一格，增减的数量(下单的手数)    context.volume = 1    # 储存前一个网格所处区间，用来和最新网格所处区间作比较    context.last_grid = 0    # 以前一日的收盘价为中枢价格, history_n函数用于获取历史数据, 第[0]条返回形式为[{'open': 3500, 'high': 3520, 'low': 3480, 'close': 3510, 'volume': 1000}], 取close字段即为收盘价    context.center = history_n(symbol= context.symbol,frequency='1d',end_time=context.now,count = 1,fields = 'close')[0]['close']    # 记录上一次交易时网格范围的变化情况（例如从4区到5区，记为4,5）    context.grid_change_last = [0,0]# bar 是一种 K 线数据，也就是把一段时间内的市场行情汇总成一条数据，而不是每笔成交的 tick。它反映了某个时间周期内的开盘、收盘、最高、最低价格和成交量。可以是 1分钟/5分钟/1小时/1天的 K 线def on_bar(context, bars): # on_bar函数是策略的核心函数, 每当有新的bar数据到达时, 框架会自动调用这个函数, 并把最新的bar数据传入bars参数    # 获取最新的bar数据, bars是一个列表, 每个元素是一个Bar对象, 代表一个标的的bar数据. 这里我们只订阅了一个标的, 所以取第一个元素    bar = bars[0]    # 获取多仓仓位    position_long = context.account().position(symbol=context.symbol, side=PositionSide_Long)    # 获取空仓仓位    position_short = context.account().position(symbol=context.symbol, side=PositionSide_Short)    # 设置网格, 以开盘价为中枢价格, 计算网格线得到实际的网格线价格    context.band = np.array([0.97, 0.98, 0.99, 1, 1.01, 1.02, 1.03]) * context.center    # 计算当前价格所处的网格区间, pd.cut函数用于将数据分割成不同的区间(把连续数值分箱（bin）), labels参数用于给每个区间命名, 这里我们用1-6表示6个区间    grid = pd.cut([bar.close], context.band, labels=[1, 2, 3, 4, 5, 6])[0]    # pd.cut 的返回值是一个 Pandas Series 对象，长度和 x 一致. 由于 x=[bar.close] 只有一个元素，所以用 [0] 取出标签值    # 如果价格超出网格设置范围，则提示调节网格宽度和数量. 当价格低于最小网格或高于最大网格时，pd.cut 会返回 NaN    if np.isnan(grid):        print('价格波动超过网格范围，可适当调节网格宽度和数量')    # 如果新的价格所处网格区间和前一个价格所处的网格区间不同，说明触碰到了网格线，需要进行交易    # 如果新网格大于前一天的网格，做空或平多    if context.last_grid &lt; grid:        # 记录新旧格子范围（按照大小排序）        grid_change_new = [context.last_grid,grid]        # 几种例外：        # 当last_grid = 0 时是初始阶段，不构成信号        # 如果此时grid = 3，说明当前价格仅在开盘价之下的3区域中，没有突破网格线        # 如果此时grid = 4，说明当前价格仅在开盘价之上的4区域中，没有突破网格线        if context.last_grid == 0:            context.last_grid = grid            return        if context.last_grid != 0:            # 如果前一次开仓是4-5，这一次是5-4，算是没有突破，不成交            if grid_change_new != context.grid_change_last:                # 更新前一次的数据                context.last_grid = grid                context.grid_change_last = grid_change_new                # 如果有多仓，平多                if position_long:                    # 下一单, 平多                    order_volume(symbol=context.symbol, volume=context.volume, side=OrderSide_Sell, order_type=OrderType_Market,                                 position_effect=PositionEffect_Close)                    print('以市价单平多仓{}手'.format(context.volume))                # 否则，做空                if not position_long:                    order_volume(symbol=context.symbol, volume=context.volume, side=OrderSide_Sell, order_type=OrderType_Market,                                 position_effect=PositionEffect_Open)                    print('以市价单开空{}手'.format(context.volume))    # 如果新网格小于前一天的网格，做多或平空    if context.last_grid &gt; grid:        # 记录新旧格子范围（按照大小排序）        grid_change_new = [grid,context.last_grid]        # 几种例外：        # 当last_grid = 0 时是初始阶段，不构成信号        # 如果此时grid = 3，说明当前价格仅在开盘价之下的3区域中，没有突破网格线        # 如果此时grid = 4，说明当前价格仅在开盘价之上的4区域中，没有突破网格线        if context.last_grid == 0:            context.last_grid = grid            return        if context.last_grid != 0:            # 如果前一次开仓是4-5，这一次是5-4，算是没有突破，不成交            if grid_change_new != context.grid_change_last:                # 更新前一次的数据                context.last_grid = grid                context.grid_change_last = grid_change_new                # 如果有空仓，平空                if position_short:                    order_volume(symbol=context.symbol, volume=context.volume, side=OrderSide_Buy,                                 order_type=OrderType_Market,                                 position_effect=PositionEffect_Close)                    print('以市价单平空仓{}手'.format(context.volume))                # 否则，做多                if not position_short:                    order_volume(symbol=context.symbol, volume=context.volume, side=OrderSide_Buy,                                 order_type=OrderType_Market,                                 position_effect=PositionEffect_Open)                    print('以市价单开多{}手'.format(context.volume))    # 设计一个止损条件：当持仓量达到10手，全部平仓    if position_short == 10 or position_long == 10:        order_close_all()        print('触发止损，全部平仓')if __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2018-07-01 08:00:00',        backtest_end_time='2018-10-01 16:00:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=100000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n获取数据的bar格式可能如下: bar = {    'symbol': 'SHFE.rb1901',    'datetime': '2025-10-17 13:30:00',    'open': 3500,    'high': 3520,    'low': 3490,    'close': 3510,    'volume': 120}\r\n策略难点：\r\n\r\n怎样记录价格是否突破网格线？\r\n\r\n解决方法：有些人可能会想到用当前价格与网格线对应的价格进行比较，但这样操作比较麻烦，步骤繁琐。这里采用区域判断方式。根据网格线划分网格区域为1、2、3、4、5、6.利用pandas库提供的cut函数，将当前价格所处的网格区域表示出来。当网格区域发生变化，说明价格突破了一个网格线。\r\n\r\n如何避免出现4区-5区开仓一次,5区-4区又平仓一次这种“假突破”？\r\n\r\n解决方法：4-5开仓一次和5-4平仓一次实际上突破的是一根线，此时的形态是价格沿着这根线上下波动。只有第一次穿过这条线时才是真正的交易信号，其他的并没有形成突破。因此我们需要一个变量储存每一次交易时网格区域的变化形态(按照从大到小的顺序)，比如5-4可以记为[4,5],4-5记为[4,5]。当新的记录=旧的记录时，信号失效。\r\n\r\n\r\n","categories":["misc"],"tags":["misc"]},{"title":"布林线均值回归策略","url":"/2025/10/16/misc/Quant/Strategy/%E5%B8%83%E6%9E%97%E7%BA%BF%E5%9D%87%E5%80%BC%E5%9B%9E%E5%BD%92%E7%AD%96%E7%95%A5/","content":"布林线均值回归策略是一种结合了趋势跟踪和均值回归两种不同交易理念的混合型策略,\r\n不过主要是后者。它利用布林带（Bollinger\r\nBands）来识别价格的极端状态，同时结合均线（Moving\r\nAverages）来确认市场的整体趋势方向。\r\n布林带\r\n(Bollinger Bands, BOLL) - 衡量价格的“常态”与“极端”\r\n布林带由三条线组成，它在移动平均线的基础上引入了标准差\r\n(Standard Deviation)\r\n的概念，从而创造了一个动态的、能够自我适应市场波动性的价格通道。\r\n\r\n中轨线 (Middle Band): N日的简单移动平均线 (SMA)。\r\n\r\n代表了市场在过去 N\r\n个周期内的平均成本或价值中枢，是趋势的基本方向。\r\n\r\n上轨线 (Upper Band): 中轨线 + K × N日标准差\r\n下轨线 (Lower Band): 中轨线 - K × N日标准差\r\n\r\n标准差是衡量数据离散程度的统计量。在这里，它衡量了过去 N\r\n个周期内价格相对于中轨线的波动幅度。\r\nK\r\n是一个倍数参数（通常取2）。根据正态分布理论，大约95%的数据点会落在距离均值两个标准差的范围内。因此，上轨线和下轨线共同构建了一个动态的通道，这个通道定义了价格波动的“常态区间”。\r\n当市场波动加剧时，标准差会变大，通道随之变宽；当市场进入盘整，波动减小时，标准差会变小，通道随之收窄。这种自适应性是布林带指标的核心优势。\r\n\r\n\r\n均值回归 (Mean\r\nReversion) - 策略的哲学基础\r\n均值回归策略基于一个金融学中的普遍现象：资产价格，即使在短期内可能因为市场情绪或随机事件而大幅偏离其内在价值，但从长期来看，总有一种力量会将其拉回到价值中枢。\r\n布林带与均值回归的结合在于:\r\n\r\n策略将布林带的中轨线视为价格的“均值”或“价值中枢”。\r\n将上轨线和下轨线视为价格波动的“极端”边界。\r\n\r\n核心假设:\r\n当价格触摸甚至突破了上下轨时，意味着价格相对于其近期均值已经过度延伸\r\n(Overextended)，市场大概率出现了超买（突破上轨）或超卖（突破下轨）的情况。这种极端状态是不可持续的，价格在不久的将来有很高的概率会向中轨线回归。\r\n策略逻辑\r\n本策略的交易逻辑是均值回归思想最直接的应用：\r\n第一步：计算指标\r\n\r\n根据设定的周期 N 和标准差倍数\r\nK，计算出当前布林带的中轨、上轨和下轨。\r\n\r\n第二步：定义交易信号\r\n\r\n卖出信号 (做空或平多仓):\r\n当股价从通道内部向上穿越布林带上轨时触发。这被解释为市场超买，是价格即将回调的信号。\r\n买入信号 (做多或平空仓):\r\n当股价从通道内部向下穿越布林带下轨时触发。这被解释为市场超卖，是价格即将反弹的信号。\r\n\r\n第三步：仓位管理\r\n\r\n策略采用了一种简单的“买入持有，直至卖出信号出现”的模式。\r\n\r\n当收到买入信号且当前无持仓时，买入固定数量的股票。\r\n当收到卖出信号且当前有持仓时，卖出所有股票。\r\n\r\n\r\n示例代码\r\n# coding=utf-8from __future__ import print_function, absolute_importfrom gm.api import *\"\"\"本策略采用布林线进行均值回归交易。当价格触及布林线上轨的时候进行卖出，当触及下轨的时候，进行买入。使用600004在 2009-09-17 13:00:00 到 2020-03-21 15:00:00 进行了回测。注意： 1：实盘中，如果在收盘的那一根bar或tick触发交易信号，需要自行处理，实盘可能不会成交。\"\"\"# 策略中必须有init方法def init(context):    # 设置布林线的三个参数    context.maPeriod = 26  # 计算BOLL布林线中轨的参数    context.stdPeriod = 26  # 计算BOLL 标准差的参数    context.stdRange = 1  # 计算BOLL 上下轨和中轨距离的参数    # 设置要进行回测的合约    context.symbol = 'SHSE.600004'  # 订阅&amp;交易标的, 此处订阅的是600004    context.period = max(context.maPeriod, context.stdPeriod, context.stdRange) + 1  # 订阅数据滑窗长度    # 订阅行情     subscribe(symbols= context.symbol, frequency='1d', count=context.period)def on_bar(context, bars):    # 获取数据滑窗，只要在init里面有订阅，在这里就可以取的到，返回值是pandas.DataFrame    data = context.data(symbol=context.symbol, frequency='1d', count=context.period, fields='close')    # 计算boll的上下界    bollUpper = data['close'].rolling(context.maPeriod).mean() \\                + context.stdRange * data['close'].rolling(context.stdPeriod).std()    bollBottom = data['close'].rolling(context.maPeriod).mean() \\                 - context.stdRange * data['close'].rolling(context.stdPeriod).std()    # 获取现有持仓    pos = context.account().position(symbol=context.symbol, side=PositionSide_Long)    # 交易逻辑与下单    # 当有持仓，且股价穿过BOLL上界的时候卖出股票。    if data.close.values[-1] &gt; bollUpper.values[-1] and data.close.values[-2] &lt; bollUpper.values[-2]:        if pos:  # 有持仓就市价卖出股票。            order_volume(symbol=context.symbol, volume=100, side=OrderSide_Sell,                         order_type=OrderType_Market, position_effect=PositionEffect_Close)            print('以市价单卖出一手')    # 当没有持仓，且股价穿过BOLL下界的时候买出股票。    elif data.close.values[-1] &lt; bollBottom.values[-1] and data.close.values[-2] &gt; bollBottom.values[-2]:        if not pos:  # 没有持仓就买入一百股。            order_volume(symbol=context.symbol, volume=100, side=OrderSide_Buy,                         order_type=OrderType_Market, position_effect=PositionEffect_Open)            print('以市价单买入一手')if __name__ == '__main__':    '''        strategy_id策略ID,由系统生成        filename文件名,请与本文件名保持一致        mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST        token绑定计算机的ID,可在系统设置-密钥管理中生成        backtest_start_time回测开始时间        backtest_end_time回测结束时间        backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST        backtest_initial_cash回测初始资金        backtest_commission_ratio回测佣金比例        backtest_slippage_ratio回测滑点比例        '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token_id',        backtest_start_time='2009-09-17 13:00:00',        backtest_end_time='2020-03-21 15:00:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=1000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"跨品种套利 (Cross-Variety Arbitrage)","url":"/2025/10/16/misc/Quant/Strategy/%E8%B7%A8%E5%93%81%E7%A7%8D%E5%A5%97%E5%88%A9%20(Cross-Variety%20Arbitrage)/","content":"跨品种套利 (Cross-Variety Arbitrage)\r\n是一种利用相关品种之间的价格差异进行交易以获取利润的策略。它基于这样一个假设：在有效市场中，相关品种的价格关系应该是稳定且可预测的。当这种关系出现偏离时，套利者可以通过买入和卖出相关品种来获取利润。\r\n它属于统计套利 (Statistical Arbitrage)\r\n的范畴，其核心是一种均值回归 (Mean Reversion)\r\n的信念，但它交易的不是单一资产的价格，而是两种相关资产之间的价差\r\n(Spread)。\r\n前提：经济关联性\r\n策略成功的基石是选择的两个品种之间必须有强烈的、稳定的经济关联。例如：\r\n\r\n焦炭(j) vs. 焦煤(jm) :\r\n焦煤是生产焦炭的原材料。它们的成本和需求端紧密相连，因此价格走势高度相关。\r\n玉米(c) vs. 淀粉(cs): 玉米是生产淀粉的原材料。\r\n大豆 vs. 豆粕: 大豆是生产豆粕的原材料。\r\n\r\n这种内在的经济联系，使得它们的价差在长期来看，会像一根“橡皮筋”，围绕一个均衡水平（均值）上下波动。\r\n套利机会的产生\r\n由于短期市场情绪、供需冲击或流动性问题，这根“橡皮筋”有时会被过度拉伸（价差过大）或过度压缩（价差过小）。\r\n套利策略的目标，就是在“橡皮筋”被拉伸到极限时，做空价差（卖出高价的，买入低价的），赌它会收缩；在被压缩到极限时，做多价差（买入低价的，卖出高价的），赌它会扩张。\r\n如何验证相关性存在\r\n最常用的方法是利用EG两步法对两个序列做协整检验，判断两个序列是否平稳。只有单整阶数相同，二者才有可能存在一定的关系。\r\n\r\n平稳性 (Stationarity):\r\n一个时间序列如果是平稳的，意味着它的均值和方差不随时间改变。它的走势图看起来像是在一条水平线上下随机波动。\r\n协整的直观理解:\r\n两个单独看起来“不平稳”（像随机游走，没有回归均值的趋势）的资产价格，如果它们是协整的，就意味着它们之间存在一个神奇的长期均衡关系,\r\n此时他们的价差（Spread）是平稳的\r\n\r\n策略逻辑\r\n第一步：定义价差和统计通道\r\n\r\n价差 (Spread): Spread = Price(DCE.j1901) -\r\nPrice(DCE.jm1901)。\r\n历史数据窗口:\r\n使用过去30个交易日的数据作为计算统计量的基础。\r\n通道中轨 (均衡值): 过去30日价差的均值\r\nmean。\r\n开仓边界 (触发线): 在中轨的上下方各设置一个边界，宽度为 0.75 *\r\n标准差。\r\n\r\n上轨: Up_Open = mean + 0.75 * std\r\n下轨: Down_Open = mean - 0.75 * std\r\n\r\n止损边界 (风控线): 在中轨的上下方设置更宽的边界，宽度为 2.0 *\r\n标准差。\r\n\r\n上轨止损: Up_Stop = mean + 2.0 * std\r\n下轨止损: Down_Stop = mean - 2.0 * std\r\n\r\n\r\n第二步：开仓逻辑\r\n\r\n做空价差: 如果当前实时价差向上突破了上轨开仓线\r\n(Up_Open)，意味着价差异常偏高。执行操作：卖出焦炭(j)，买入焦煤(jm)。\r\n做多价差: 如果当前实时价差向下突破了下轨开仓线\r\n(Down_Open)，意味着价差异常偏低。执行操作：买入焦炭(j)，卖出焦煤(jm)。\r\n\r\n第三步：平仓逻辑\r\n\r\n止盈平仓:\r\n无论持有多头还是空头价差头寸，当价差回归到中轨线（均值）时，认为套利目标达成，平掉所有头寸，锁定利润。\r\n止损平仓:\r\n\r\n如果持有多头价差头寸，但价差没有回归，反而继续下跌并跌破了下轨止损线\r\n(Down_Stop)，立即平仓，防止亏损扩大。\r\n如果持有空头价差头寸，但价差没有回归，反而继续上涨并涨破了上轨止损线\r\n(Up_Stop)，立即平仓。\r\n\r\n\r\n代码示例\r\n下面的代码示例展示了如何实现一个简单的跨品种套利策略：\r\n# coding=utf-8from __future__ import print_function, absolute_import, unicode_literalsfrom gm.api import *import numpy as npdef init(context):    # 选择的两个合约    context.symbol = ['DCE.j1901', 'DCE.jm1901']    # 订阅历史数据    subscribe(symbols=context.symbol,frequency='1d',count=11,wait_group=True)def on_bar(context, bars):    # 数据提取    j_close = context.data(symbol=context.symbol[0],frequency='1d',fields='close',count=31).values    jm_close = context.data(symbol=context.symbol[1],frequency='1d',fields='close',count=31).values    # 提取最新价差    new_price = j_close[-1] - jm_close[-1]    # 计算历史价差,上下限，止损点    spread_history = j_close[:-2] -  jm_close[:-2]    context.spread_history_mean = np.mean(spread_history)    context.spread_history_std = np.std(spread_history)    context.up = context.spread_history_mean + 0.75 * context.spread_history_std    context.down = context.spread_history_mean - 0.75 * context.spread_history_std    context.up_stoppoint = context.spread_history_mean + 2 * context.spread_history_std    context.down_stoppoint = context.spread_history_mean - 2 * context.spread_history_std    # 查持仓    position_jm_long = context.account().position(symbol=context.symbol[0],side=1)    position_jm_short = context.account().position(symbol=context.symbol[0],side=2)    # 设计买卖信号    # 设计开仓信号    if not position_jm_short and not position_jm_long:        if new_price &gt; context.up:            print('做空价差组合')            order_volume(symbol=context.symbol[0],side=OrderSide_Sell,volume=1,order_type=OrderType_Market,position_effect=1)            order_volume(symbol=context.symbol[1], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Open)        if new_price &lt; context.down:            print('做多价差组合')            order_volume(symbol=context.symbol[0], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Open)            order_volume(symbol=context.symbol[1], side=OrderSide_Sell, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Open)    # 设计平仓信号    # 持jm多仓时    if position_jm_long:        if new_price &gt;= context.spread_history_mean:            # 价差回归到均值水平时，平仓            print('价差回归到均衡水平，平仓')            order_volume(symbol=context.symbol[0], side=OrderSide_Sell, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)            order_volume(symbol=context.symbol[1], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)        if new_price &lt; context.down_stoppoint:            # 价差达到止损位，平仓止损            print('价差超过止损点，平仓止损')            order_volume(symbol=context.symbol[0], side=OrderSide_Sell, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)            order_volume(symbol=context.symbol[1], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)    # 持jm空仓时    if position_jm_short:        if new_price &lt;= context.spread_history_mean:            # 价差回归到均值水平时，平仓            print('价差回归到均衡水平，平仓')            order_volume(symbol=context.symbol[0], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)            order_volume(symbol=context.symbol[1], side=OrderSide_Sell, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)        if new_price &gt; context.up_stoppoint:            # 价差达到止损位，平仓止损            print('价差超过止损点，平仓止损')            order_volume(symbol=context.symbol[0], side=OrderSide_Buy, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)            order_volume(symbol=context.symbol[1], side=OrderSide_Sell, volume=1, order_type=OrderType_Market, position_effect=PositionEffect_Close)if __name__ == '__main__':    '''    strategy_id策略ID,由系统生成    filename文件名,请与本文件名保持一致    mode实时模式:MODE_LIVE回测模式:MODE_BACKTEST    token绑定计算机的ID,可在系统设置-密钥管理中生成    backtest_start_time回测开始时间    backtest_end_time回测结束时间    backtest_adjust股票复权方式不复权:ADJUST_NONE前复权:ADJUST_PREV后复权:ADJUST_POST    backtest_initial_cash回测初始资金    backtest_commission_ratio回测佣金比例    backtest_slippage_ratio回测滑点比例    '''    run(strategy_id='strategy_id',        filename='main.py',        mode=MODE_BACKTEST,        token='token',        backtest_start_time='2018-02-01 08:00:00',        backtest_end_time='2018-12-31 16:00:00',        backtest_adjust=ADJUST_PREV,        backtest_initial_cash=2000000,        backtest_commission_ratio=0.0001,        backtest_slippage_ratio=0.0001)\r\n","categories":["misc"],"tags":["misc"]},{"title":"OSI model","url":"/2025/09/01/web/Computer%20Network/OSI/2.%20OSI/","content":"OSI 模型（Open Systems Interconnection\r\nmodel，开放式系统互联模型）是一个由国际标准化组织（ISO）提出的概念模型，旨在为不同计算机网络之间的通信提供一个标准的参考框架。它将复杂的通信过程划分为七个独立的、功能明确的层次（Layer）。\r\n这个模型的核心思想是\r\n“分层”。每一层都负责特定的网络功能，并为其上一层提供服务，同时使用其下一层提供的服务。这种分层结构使得网络协议的设计和排错变得更加简单和模块化。\r\nOSI\r\n模型从上到下分为七个层次，每一层都有其独特的功能。数据在发送端从顶层（应用层）向下逐层封装，在接收端则从底层（物理层）向上逐层解封装。\r\n第一层：物理层 (Physical\r\nLayer)\r\n物理层是 OSI\r\n模型的最底层，它负责传输原始的比特流（Bits）。\r\n这一层处理的是最基础的物理媒介。它规定了网线、光纤、无线电波等传输介质的电气和物理特性,\r\n如电压、接口类型、线缆规范、传输速率等。它的任务就是将上层传递下来的数字信号（0\r\n和\r\n1）转换成电信号、光信号或无线电信号，并在物理介质上传输。\r\n更详细来说, 物理层的目的是在物理传输介质上，实现原始比特流（raw bit\r\nstream）的透明传输\r\n\r\n“物理”的含义：这一层关注的是构成网络的实体部分，例如线缆、连接器、电压、光信号等，这些都是看得见、摸得着的物理设备和标准。\r\n“比特流”的含义：物理层不关心数据的内容、格式或意义。在它看来，所有数据都是一串由\r\n0 和 1 组成的二进制序列。它的工作就是确保发送方发送的 0101\r\n序列，接收方接收到的也是 0101 序列。\r\n“透明传输”的含义：这意味着物理层对上层（数据链路层）屏蔽了所有物理细节。数据链路层不需要关心数据是通过光纤、铜缆还是无线电波传输的，也不需要关心电压是多少、接口是什么形状。物理层为上层提供了一个统一、透明的比特流传输通道。\r\n\r\n物理层的四大核心功能\r\n物理层的功能主要围绕着如何可靠地传输比特流来展开，具体可以分为以下四个方面：\r\n\r\n定义电气和物理特性\r\n\r\n这是物理层最基础的职责，它定义了所有与传输介质和接口相关的物理和电气规范。\r\n机械特性：定义了网络接口（如网线接口）的物理形状、尺寸、引脚数量和排列方式。\r\n\r\n这一步是为了确保不同制造商生产的设备可以物理上相互连接。例如，我们常见的\r\nRJ45\r\n网线接口就是一个标准化的机械特性，保证任何一根标准的网线都能插入任何一个标准的网络端口。\r\n\r\n电气特性：定义了在线缆的各个引脚上传输信号时的电压范围、阻抗匹配、传输速率等。\r\n\r\n规定信号的标准，以确保接收方能正确解读。例如，规定 +5V 代表比特\r\n1，0V 代表比特 0。如果电压标准不统一，就会导致信号的误判。\r\n\r\n功能特性：指明接口的各条信号线（引脚）的功能。\r\n\r\n这就像定义插座上哪个孔是火线，哪个是零线。例如，在网线中，规定哪几根线用于发送数据（TX），哪几根用于接收数据（RX）。\r\n\r\n规程特性：定义了利用信号线进行比特流传输的一系列操作流程和时序关系。\r\n\r\n这是对信号传输过程的规定，确保数据传输的同步和协调。例如，规定了建立连接、传输数据、断开连接时，信号变化的先后顺序。\r\n\r\n\r\n比特流的编码与表示\r\n\r\n计算机内部的数据是二进制的 0 和\r\n1，物理层需要将这些抽象的比特转换成可以在物理介质上传输的物理信号（如电信号或光信号）,\r\n这个过程称为编码 (Encoding)。\r\n直接用高低电平代表 1 和 0 的方式（称为不归零编码\r\nNRZ）在长距离传输时容易出现时钟同步问题。因此，物理层采用更复杂的编码方式，如曼彻斯特编码\r\n(Manchester Encoding)。\r\n\r\n数据传输速率（比特率）\r\n\r\n物理层规定了数据在信道上的传输速率，即每秒可以传输多少个比特（bits\r\nper second, bps）。\r\n传输速率受到物理介质、编码方式和信道带宽等多种因素的限制。物理层标准会明确定义一个网络所能支持的速率，例如\r\n10 Mbps、100 Mbps、1 Gbps。\r\n物理层还必须确保发送方和接收方以相同的速率工作，这称为比特同步 (Bit\r\nSynchronization)。如果发送方以 100 Mbps 的速率发送，而接收方以 10 Mbps\r\n的速率接收，数据就会丢失或出错。\r\n\r\n传输模式\r\n\r\n物理层定义了数据在两个设备之间传输的方向。\r\n\r\n单工\r\n(Simplex)：数据只能在一个方向上传输。例如无线电广播、电视广播。你只能接收信号，不能发送信号给电视台。\r\n半双工\r\n(Half-Duplex)：数据可以在两个方向上传输，但在同一时刻只能有一个方向在进行。例如对讲机。一方说话时，另一方只能听，不能同时说话。\r\n全双工\r\n(Full-Duplex)：数据可以同时在两个方向上传输。例如电话通话。通话双方可以同时说话和倾听。\r\n\r\n物理层的常见设备和介质\r\n物理层是唯一一层涉及具体物理设备的层次。常见的传输介质有同轴电缆\r\n(Coaxial Cable), 光纤 (Fiber Optic Cable)以及无线电波 (Radio Waves, 用于\r\nWi-Fi)等\r\n常见的物理层设备有中继器\r\n(Repeater):对衰减的信号进行再生和放大，然后转发出去，从而延长网络的传输距离;\r\n集线器 (Hub)：它将从一个端口接收到的信号放大后，广播到所有其他端口等\r\n第二层：数据链路层 (Data Link\r\nLayer)\r\n数据链路层位于物理层之上、网络层之下，扮演着一个至关重要的“承上启下”的角色。如果说物理层负责在一段物理介质上透明地传输比特流，那么数据链路层的核心任务就是：在同一个物理网络（即一个局域网或广播域）内的相邻节点之间，提供可靠的数据传输。\r\n\r\n从“比特”到“帧”：数据链路层接收来自网络层的数据包（Packet），并将其封装成一种称为“帧”\r\n(Frame)\r\n的结构化数据单元。帧是数据链路层传输的基本单位。这个过程好比将一堆零散的货物（比特流）打包成一个个贴好标签、有明确边界的箱子（帧），便于管理和运输。\r\n节点到节点\r\n(Node-to-Node)：它负责的是点对点或相邻节点之间的通信。例如，从你的电脑到你的路由器，或者从你的路由器到互联网服务提供商（ISP）的下一个设备。它不关心数据的最终目的地，只关心如何将数据可靠地送到链路上的下一个节点。\r\n提供服务给网络层：它向其上层（网络层）隐藏了物理层的复杂细节。网络层只需要将数据包交给数据链路层，并指定下一个节点的地址(MAC)，数据链路层就会负责将其变成帧，并通过物理层可靠地发送出去。\r\n\r\nMAC\r\nMAC 地址（Media Access Control\r\nAddress），中文全称为“媒体访问控制地址”，也被称为物理地址（Physical\r\nAddress）或硬件地址（Hardware Address）。\r\n可以把它想象成网络设备的“身份证号码”。理论上，每一块出厂的网络接口卡（NIC，无论是你的电脑网卡、手机\r\nWi-Fi 芯片，还是路由器的端口）都有一个全球唯一的 MAC\r\n地址。这个地址在设备生产时就被固化（烧录）在硬件中。\r\nMAC 地址具有全球唯一性，一个标准的 MAC 地址长度为 48 位（6\r\n个字节）。用 12 个十六进制数 来表示，例如：00:1A:2B:3C:4D:5E。\r\n一个 MAC 地址由两部分组成：前 24 位称作组织唯一标识符（OUI,\r\nOrganizationally Unique Identifier）。这是由 IEEE\r\n分配给硬件制造商的。通过查询\r\nOUI，你可以知道这个网络设备是由哪家公司生产的。例如，00:1A:2B\r\n可能就代表苹果公司（Apple Inc.）。\r\n而后 24 位是网络接口标识符（NIC\r\nSpecific）。这部分由制造商自行分配，确保其生产的每一个设备都有一个独一无二的编号。\r\nMAC 地址工作在 OSI 模型的第二层——数据链路层 (Data Link\r\nLayer)。它的核心功能是在同一个局域网（LAN）内部进行设备寻址和数据传输。\r\n五大核心功能\r\n为了实现节点间的可靠传输，数据链路层需要执行以下几个关键功能:\r\n\r\n封装成帧 (Framing)\r\n\r\n这是数据链路层的首要任务。它将来自网络层的 IP\r\n数据包，在前后分别添加头部 (Header) 和尾部\r\n(Trailer)，构成一个完整的帧。\r\n\r\n添加头部：头部通常包含源 MAC\r\n地址和目的 MAC\r\n地址，以及一些控制信息。这就像在包裹上贴上寄件人和收件人的本地地址。\r\n添加尾部：尾部通常包含差错校验码 (Frame Check\r\nSequence, FCS)，例如循环冗余校验（CRC）码。\r\n帧定界 (Frame\r\nDelimiting)：为了让接收方知道一个帧从哪里开始、到哪里结束，数据链路层会使用特殊的比特模式作为帧的起始和结束标记。\r\n\r\n\r\n物理寻址 (Physical Addressing)\r\n\r\n数据链路层使用 MAC\r\n地址来标识网络中的每一个设备（如网卡）。当一个设备要向同一局域网内的另一个设备发送数据时，它会在帧的头部填入自己的源\r\nMAC 地址和对方的目的 MAC 地址。网络中的设备（如交换机）会根据这个目的\r\nMAC 地址来决定将帧转发到哪个端口。这好比邮递员根据门牌号（MAC\r\n地址）来投递信件。\r\n\r\n流量控制 (Flow Control)\r\n\r\n流量控制是为了防止发送速度过快的发送方淹没接收速度较慢的接收方，导致数据丢失。\r\n如果接收方的缓冲区已满，无法再处理更多的数据，它会通过数据链路层协议向发送方发送一个“暂停”信号。发送方收到信号后会暂停发送，直到接收方通知它可以继续发送。这确保了数据的平稳传输，避免了因接收方处理能力不足而造成的“数据溢出”。\r\n\r\n差错控制 (Error Control)\r\n\r\n由于物理线路上的噪声或其他干扰，比特流在传输过程中可能会出错（例如 1\r\n变成 0）。差错控制就是为了检测并可能纠正这些错误。\r\n一般的步骤如下：\r\n\r\n差错检测 (Error\r\nDetection)：发送方在生成帧时，会根据帧的数据内容计算出一个校验码\r\n(FCS/CRC) 并附加在帧的尾部。\r\n接收方收到帧后，会用同样的算法对接收到的数据进行计算，得出一个新的校验码。\r\n校验码比较：接收方将新计算的校验码与帧中包含的校验码进行比较。\r\n错误检测：如果两个校验码一致，说明数据在传输过程中没有出错，接收方就接受该帧。\r\n差错纠正 (Error\r\nCorrection)：一些更高级的数据链路层协议（如在无线通信中）不仅能检测错误，还能通过重传机制来纠正错误。例如，如果接收方检测到错误，它可以请求发送方重新发送损坏的帧。\r\n\r\n\r\n介质访问控制 (Media Access Control)\r\n\r\n介质访问控制决定了在同一时刻哪个设备可以使用这个共享介质来发送数据,\r\n这是为了解决“信道争用”和“冲突”的问题。如果两个设备同时在共享介质上发送数据，它们的信号会相互干扰，导致数据损坏，这就是冲突\r\n(Collision)。\r\n常见的控制方式是CSMA/CD (Carrier Sense Multiple Access with Collision\r\nDetection),\r\n即载波侦听多路访问/冲突检测，主要用于有线以太网。其主要策略有三点:\r\n\r\n先听后发：发送前先侦听信道是否空闲。\r\n边发边听：发送数据的同时继续侦听，以检测是否发生冲突。\r\n冲突后退：一旦检测到冲突，立即停止发送，并等待一个随机时间后重试。\r\n\r\n数据链路层的常见设备\r\n数据链路层最重要的设备就是交换机 (Switch),\r\n称得上是现代局域网的核心设备。\r\n我们可以把交换机看做升级版的Hub. 它内部维护着一张 MAC\r\n地址表，记录了每个 MAC 地址所连接的端口。\r\n当交换机从一个端口收到一个帧时，它会检查帧头部的目的 MAC\r\n地址。然后，它会在 MAC\r\n地址表中查找这个地址，并只将该帧从对应的端口精确地转发出去，而不是像集线器那样广播到所有端口。\r\n因此,\r\n交换机能够隔离冲突域，每个端口都是一个独立的冲突域，从而极大地提高了网络效率和性能。\r\n第三层：网络层 (Network Layer)\r\n网络层位于数据链路层之上、传输层之下。如果说数据链路层负责的是局域网内部相邻节点之间的通信，那么网络层的核心任务就是：实现数据在不同网络之间的路由和转发，为数据从源主机到目的主机提供一条端到端的路径。\r\n\r\n全局视野：网络层是第一个具有全局网络视野的层次。它不再局限于单个局域网，而是要负责数据在整个互联网（由无数个局域网组成）中的传输路径。\r\n从“帧”到“包”：网络层处理的基本数据单元是“包”\r\n(Packet) 或“数据报”\r\n(Datagram)。它接收来自上层（传输层）的数据段（Segment），并为其添加一个网络层头部（Header），其中包含了关键的逻辑地址信息，从而构成了数据包。\r\n逻辑寻址 (Logical\r\nAddressing)：网络层引入了一套与物理地址（MAC\r\n地址）完全不同的地址体系——逻辑地址，最典型的就是我们熟知的\r\nIP 地址 (Internet Protocol\r\nAddress)。IP\r\n地址为网络中的每台主机提供了一个全局唯一的、分等级的地址。\r\n路由\r\n(Routing)：这是网络层的核心功能。它负责根据目的主机的 IP\r\n地址，通过特定的算法（路由协议）计算出一条从源到目的地的最佳路径，并指示数据包如何穿越一系列相互连接的网络。\r\n\r\n四大核心功能\r\n\r\n逻辑寻址 (Logical Addressing)\r\n\r\n为了在庞大的互联网中唯一地标识每一台主机，网络层定义了逻辑地址,\r\n即IP地址。\r\n目前主要使用 IPv4 (32位地址，如 192.168.1.1) 和 IPv6 (128位地址)。IP\r\n地址由两部分组成：\r\n\r\n网络部分 (Network ID)：标识主机所在的特定网络。\r\n\r\n\r\n因此，在不连接任何网络时，设备没有一个可以用来与外部通信的有效 IP\r\n地址。\r\n\r\n\r\n主机部分 (Host ID)：标识该网络中的特定主机。\r\n\r\n当一台主机要向另一台主机发送数据时，它必须知道对方的 IP\r\n地址。网络层会在数据包的头部封装上源 IP\r\n地址和目的 IP 地址。这个目的 IP\r\n地址就是数据包在整个旅程中的最终导航目标。\r\n\r\nMAC 地址是设备的固有属性，而一个能让设备与外界通信的 IP\r\n地址，则是设备加入网络后获得的临时身份\r\n\r\n\r\n路由 (Routing)\r\n\r\n路由是网络层最复杂也最重要的功能，即为数据包选择最佳的传输路径。\r\n路由器\r\n(Router)：执行路由功能的关键设备。路由器连接着两个或多个不同的网络，其内部维护着一张路由表\r\n(Routing Table)。\r\n路由表：这张表记录了“要去往某个目的网络，应该从哪个接口出去，并将数据包交给下一个路由器”。路由表可以由管理员静态配置\r\n(Static Routing)，也可以通过路由协议动态学习 (Dynamic Routing)。\r\n步骤说明（数据包的旅程）：\r\n\r\n源主机创建一个数据包，包含源/目的 IP 地址。\r\n数据包被发送到本地网络的默认网关（通常是一个路由器）。\r\n路由器收到数据包后，会查看其头部的目的 IP 地址。\r\n路由器在其路由表中查找与该目的 IP 地址最匹配的条目。\r\n根据路由表中的指示，路由器将数据包从正确的接口转发给下一个路由器。\r\n\r\n这个过程（查找路由表 -&gt;\r\n转发）在路径上的每一个路由器上重复进行，直到数据包最终到达包含目的主机的那个局域网。这个过程被称为“逐跳转发”\r\n(Hop-by-Hop Forwarding)。\r\n\r\n数据包转发与分片 (Forwarding &amp; Fragmentation)\r\n\r\n转发\r\n(Forwarding)：这是路由器根据路由表做出的具体动作，即将数据包从输入端口移送到正确的输出端口。\r\n分片\r\n(Fragmentation)：数据链路层对可传输的帧大小有一个上限，称为最大传输单元\r\n(Maximum Transmission Unit, MTU)。例如，以太网的 MTU 通常是 1500\r\n字节。如果要传输的网络层数据包大于 MTU，网络层就需要将这个大数据包分片\r\n(Fragment) 成多个较小的数据包，以便它们能够装入数据链路层的帧中。\r\n步骤说明：\r\n\r\n当路由器准备转发一个数据包时，它会检查出口网络的 MTU。\r\n如果数据包的大小超过了\r\nMTU，路由器就会将其分割成多个更小的分片。\r\n每个分片都会被加上自己的网络层头部，并被独立地进行路由和转发。\r\n这些分片最终会在目的主机的网络层被重新组装成原始的数据包。\r\n\r\n\r\n拥塞控制与服务质量 (Congestion Control &amp; QoS)\r\n\r\n\r\n拥塞控制 (Congestion\r\nControl)：当网络中的数据包数量过多，超出路由器处理能力时，就会发生网络拥塞。网络层协议可以包含一些机制来检测和缓解拥塞，例如通知源主机降低发送速率。\r\n服务质量 (Quality of Service,\r\nQoS)：网络层可以为不同类型的数据包提供不同的服务优先级。例如，可以优先处理对延迟敏感的实时视频流数据，而不是普通的网页浏览数据。\r\n\r\n关键协议和设备\r\n路由器\r\n(Router)：网络层的标志性设备。它的主要工作是连接不同的网络（如连接你的家庭局域网和互联网），并根据\r\nIP\r\n地址执行路由和转发。路由器能够隔离广播域，即一个网络中的广播消息不会被路由器转发到另一个网络，这对于大型网络的性能和安全至关重要。\r\nIP (Internet\r\nProtocol)：网际协议，是网络层的基石。它定义了数据包的格式（IP\r\n头部）和地址方案，是目前互联网上使用最广泛的协议。它是一个无连接\r\n(Connectionless) 的、不可靠 (Unreliable)\r\n的协议，即它只负责尽力而为地转发数据包，不保证数据包一定能到达，也不保证按序到达。可靠性由上层（传输层）的\r\nTCP 协议来保证。\r\nARP (Address Resolution Protocol)：地址解析协议。它负责将一个已知的\r\nIP 地址解析为对应的 MAC 地址。虽然 ARP\r\n协议在功能上连接了网络层和数据链路层，但通常被认为是网络层协议。\r\n路由协议 (Routing\r\nProtocols)：用于在路由器之间交换路由信息，动态地构建和维护路由表。常见的有\r\nRIP, OSPF, BGP 等。\r\n第四层：传输层 (Transport\r\nLayer)\r\n传输层位于网络层之上、会话层之下，是网络协议栈中承上启下的关键一层。它在面向通信的底层（网络层及以下）和面向应用的上层之间架起了一座关键的桥梁。如果说网络层提供了主机到主机\r\n(Host-to-Host)\r\n的通信，那么传输层的核心任务就是：为运行在不同主机上的应用程序之间，提供端到端\r\n(End-to-End) 的逻辑通信服务。\r\n\r\n端到端\r\n(End-to-End)：这是传输层与网络层的根本区别。网络层只关心如何将数据包送到正确的主机IP地址，但它并不知道这个数据包具体应该由这台主机上的哪个应用程序（例如浏览器、QQ还是邮件客户端）来处理。传输层则负责将数据准确地送达到指定应用程序的“门口”。\r\n进程到进程\r\n(Process-to-Process)：传输层的通信是应用程序进程之间的通信。它确保了源主机上一个应用程序发送的数据，能够被目的主机上正确的应用程序接收。\r\n逻辑通信 (Logical\r\nCommunication)：传输层为应用程序之间建立了一条“逻辑”上的连接通道。应用程序可以认为它们之间有一条直接的、专用的通道在通信，而无需关心底层复杂的路由、转发等网络细节。\r\n\r\n五大核心功能\r\n\r\n端口寻址 (Port Addressing)\r\n\r\n为了区分一台主机上同时运行的多个网络应用程序，传输层引入了端口号\r\n(Port Number) 的概念。这是一个 16 位的数字（范围从 0 到\r\n65535），用于标识一个特定的应用程序进程。其主要分为下面三类:\r\n\r\n知名端口 (Well-known Ports)：0 -\r\n1023，分配给特定的、标准的服务。例如，HTTP 服务的端口是 80，HTTPS 是\r\n443，FTP 是 21。\r\n注册端口 (Registered Ports)：1024 - 49151。这是 IANA (Internet\r\nAssigned Numbers Authority) 分配的端口号，用于注册非标准服务。\r\n动态/私有端口 (Dynamic/Private Ports)：49152 -\r\n65535，客户端程序通常会随机使用这个范围的端口。\r\n\r\n当传输层接收到来自上层应用的数据时，会为其封装上源端口号和目的端口号。目的主机上的传输层在收到数据后，会根据目的端口号，将数据递交给绑定在该端口上的应用程序。这个\r\n(IP地址, 端口号) 的组合，称为套接字\r\n(Socket)，它唯一地标识了网络中的一个通信端点(如162.105.146.10:80)。\r\n\r\n分段与重组 (Segmentation and Reassembly)\r\n\r\n来自上层应用的数据通常很大，不适合一次性在网络中传输。传输层负责将这些大数据块分割成更小的、易于管理和传输的数据段\r\n(Segment)。\r\n\r\n分段\r\n(Segmentation)：在发送端，传输层将应用层数据流切割成大小合适的数据段，并为每个数据段添加传输层头部（包含端口号、序列号等信息）。\r\n重组 (Reassembly)：在接收端，传输层根据数据段头部的序列号\r\n(Sequence\r\nNumber)，将接收到的多个数据段按照正确的顺序重新组合起来，恢复成原始的应用层数据流，再递交给上层应用。\r\n\r\n\r\n连接控制 (Connection Control)\r\n\r\n传输层可以提供两种不同模式的连接服务：面向连接和无连接。\r\n面向连接\r\n(Connection-Oriented)：在数据传输之前，必须先在发送方和接收方之间建立一个专用的逻辑连接。传输结束后，再将连接释放。这种方式可靠性高。代表协议为TCP\r\n(Transmission Control Protocol)。\r\n而建立连接的过程, 最著名的就是 TCP 的三次握手 (Three-Way\r\nHandshake)。具体为:\r\n\r\nSYN：客户端向服务器发送一个 SYN (Synchronize)\r\n包，请求建立连接。\r\nSYN-ACK：服务器收到请求后，回复一个 SYN-ACK\r\n(Synchronize-Acknowledge) 包，表示同意建立连接。\r\nACK：客户端收到服务器的同意后，再发送一个 ACK (Acknowledge)\r\n包进行确认。至此，连接建立成功。\r\n\r\n无连接\r\n(Connectionless)：发送数据之前不需要建立连接。发送方直接将数据段发送出去，每个数据段都是独立传输的，相互之间没有关联。这种方式简单、高效，但不可靠。代表协议为UDP\r\n(User Datagram Protocol)。\r\n\r\n流量控制 (Flow Control)\r\n\r\n与数据链路层类似，传输层也提供流量控制，但它是一个端到端的流量控制。目的是防止发送方发送数据的速度过快，导致接收方的缓冲区溢出。\r\n步骤说明 (以 TCP 为例)：TCP 使用滑动窗口 (Sliding Window)\r\n机制来实现流量控制。接收端在确认报文中会告诉发送端自己当前还有多少可用的缓冲区空间（即接收窗口大小）;\r\n发送方根据接收端反馈的窗口大小，来动态调整自己的发送速率。如果接收窗口为\r\n0，发送方就会暂停发送，直到窗口更新。\r\n\r\n差错控制 (Error Control)\r\n\r\n网络层的 IP\r\n协议是不可靠的，数据包在传输中可能丢失、损坏或失序。传输层（特指\r\nTCP）负责提供端到端的差错控制，以确保数据的可靠性。\r\n其机制主要通过序列号 (Sequence Number)、确认号 (Acknowledgment\r\nNumber) 和校验和 (Checksum) 来实现。步骤说明如下：\r\n\r\n差错检测：发送方和接收方都会计算数据段的校验和，以检测数据在传输过程中是否损坏。\r\n确认与重传：发送方为每个发出的数据段启动一个计时器;\r\n接收方每收到一个正确的数据段，就会发送一个确认 (ACK) 消息;\r\n如果发送方在计时器超时之前收到了 ACK，就知道该数据段已成功送达;\r\n如果计时器超时仍未收到 ACK（可能数据段丢失或 ACK\r\n丢失），发送方会重新发送 (Retransmit) 该数据段。\r\n确保有序：通过序列号，接收端可以检测出失序的数据段，并对其进行重新排序，保证交给应用层的数据是正确的顺序。\r\n\r\n第五层：会话层 (Session Layer)\r\n会话层位于传输层之上、表示层之下。它的核心任务是：负责建立、管理和终止不同主机上应用程序之间的会-话（Session），并提供对话控制和同步功能。\r\n\r\n超越连接，关注“会话”：传输层（如 TCP）负责建立和维护一条可靠的连接\r\n(Connection)，但它不关心这条连接上进行的是什么样的交互。会话层则更进一步，它管理的是两个应用程序之间一次完整的交互过程，这个过程就被称为“会-话”。会话层就像一个会议主持人或对话管理者。它确保通信双方能够有序地进行对话，决定何时开始、谁先发言、如何交替、以及何时结束\r\n\r\n在现代的 TCP/IP\r\n模型中，会话层的功能往往被简化，并直接整合到了应用层协议（如\r\nHTTP）中。因此，它是一个在理论上很重要，但在实践中不那么独立的层次。\r\n三大核心功能\r\n\r\n会话管理 (Session Management)\r\n\r\n这是会话层最基本的功能，即负责在两个应用程序进程之间建立、维护和终止会话。\r\n\r\n建立会话\r\n(Establishment)：当一个应用程序想要与另一个远程应用程序开始一次交互时，会话层会负责建立起一个会话通道。这不仅仅是建立一个传输连接，还可能包括用户认证、权限检查、协商交互参数等步骤。例如，在进行远程登录时，会话层会启动这个过程，验证用户名和密码，成功后才正式建立一个可供交互的会话。\r\n维护会话\r\n(Maintenance)：在会话期间，会话层负责保持通信的稳定。即使底层的传输连接（如\r\nTCP\r\n连接）因网络问题瞬时中断，会话层也可以尝试自动重新连接，从而对上层应用保持会话的连续性，做到对底层问题透明。\r\n终止会话\r\n(Termination)：当交互完成后，会话层负责“优雅地”关闭会话。它会确保所有正在进行的操作都已完成，数据都已同步，然后才释放相关资源。这避免了因突然中断连接而导致的数据不一致问题。\r\n\r\n\r\n对话控制 (Dialog Control)\r\n\r\n对话控制决定了两个应用程序之间的数据交换方式，即由哪一方在何时发送数据。\r\n会话层通过引入“令牌”\r\n(Token)的概念来管理对话。只有持有令牌的一方才能执行某个关键操作（如发送数据）。\r\n三种对话模式： - 单工\r\n(Simplex)：数据只能从一方流向另一方，类似于广播。 - 半双工\r\n(Half-Duplex)：双方都可以发送数据，但不能同时进行。一方发送时，另一方必须接收。会话层通过令牌传递来控制发言权。\r\n- 全双工\r\n(Full-Duplex)：双方可以随时同时发送和接收数据。在这种模式下，对话控制的作用较小。\r\n\r\n同步 (Synchronization)\r\n\r\n同步是会话层一个非常重要的功能，尤其是在传输大量数据时。它允许在数据流中插入“同步点”\r\n(Synchronization Points)或“检查点” (Checkpoints)。\r\n如果在数据传输过程中发生错误或中断（例如，一个包含 1000\r\n页的文档在传输到第 800\r\n页时网络中断了），同步功能可以使通信恢复到最后一个已确认的同步点，而无需从头开始重新传输所有数据。\r\n步骤说明：\r\n\r\n发送方在数据流中设置同步点（例如，每传输 100\r\n页设置一个）。\r\n接收方每成功接收到一个同步点的数据，就会向发送方发送一个确认。\r\n如果传输中断，双方会协商从最后一个被成功确认的同步点开始，继续传输剩余的数据（从第\r\n701 页开始，而不是第 1 页）。\r\n\r\n这对于大型文件传输、数据库事务等长时间的交互至关重要，极大地提高了传输效率和可靠性。\r\n\r\n我们之前经历的 SQL Session\r\n便属于会话：当你连接到一个数据库时，你就建立了一个 SQL\r\n会话。在这个会话中，你可以执行多个查询和事务。数据库系统会管理这个会话的状态、权限和事务的完整性，这正是会话层功能的体现。\r\n\r\n第六层：表示层 (Presentation\r\nLayer)\r\n表示层位于会话层之上、应用层之下，是处理数据“表示”问题的一个特殊层次。它的核心任务是：确保一个系统的应用层所发送的信息可以被另一个系统的应用层识别和理解。\r\n\r\n网络的“通用翻译官”：表示层的主要作用是解决不同系统之间数据表示方式的差异问题。因为不同的计算机体系结构、操作系统和编程语言可能会使用不同的内部数据格式。表示层负责将数据从发送方的“本地格式”转换为一种标准的、与平台无关的“网络通用格式”，然后在接收端再将这种通用格式转换回接收方的“本地格式”。\r\n关注数据的语法和语义：与下层只关心如何传输数据不同，表示层开始关心数据本身的语法（格式）和语义（含义）。它确保数据在传输过程中不会因为格式问题而导致意义的扭曲。\r\n服务提供者：它为上层（应用层）提供服务，使得应用层开发者可以专注于应用程序的逻辑，而不用担心数据的编码、加密或压缩等底层细节。\r\n\r\n在现代的 TCP/IP\r\n模型中，表示层的功能通常也和会话层一样，被整合到了应用层协议中。例如，HTTP\r\n协议自身会定义内容类型（Content-Type），浏览器则根据这个类型来决定如何解析和显示数据（如\r\nHTML、JSON、JPEG 等），这实际上就是表示层在发挥作用。\r\n三大核心功能\r\n\r\n数据格式化与转换 (Data Formatting and Translation)\r\n\r\n这是表示层最核心的功能。它负责在不同系统的数据格式之间进行转换，确保通信双方对数据有相同的理解。其基本步骤如下:\r\n\r\n发送端：表示层获取来自应用层的数据（通常是发送方的内部格式），并将其转换（编码）成一种标准的、通用的网络数据格式（如\r\nASN.1 - Abstract Syntax Notation One）。\r\n传输：这些标准格式的数据通过网络传输到接收端。\r\n接收端：表示层接收到标准格式的数据，并将其转换（解码）成接收端应用层能够理解的内部格式。\r\n\r\n通过这个“编码-传输-解码”的过程，表示层屏蔽了不同系统间的格式差异，实现了异构系统之间的透明通信。\r\n\r\n数据加密与解密 (Data Encryption and Decryption)\r\n\r\n为了保证通信的安全性，表示层还负责对数据进行加密和解密，以防止数据在传输过程中被窃听或篡改。步骤说明：\r\n\r\n发送端：在数据发送到网络之前，表示层使用一个加密算法和一个密钥\r\n(Key) 将原始的、可读的数据（明文）转换成不可读的密文。\r\n接收端：接收到密文后，表示层使用一个解密算法和相应的密钥将密文恢复成原始的明文数据，然后再递交给应用层。\r\n\r\n常见协议：SSL (Secure Sockets Layer) 或其后继者 TLS (Transport Layer\r\nSecurity) 协议通常被认为跨越了表示层和会话层。当你通过 HTTPS\r\n访问网站时，你的浏览器和服务器之间的数据就是由 TLS\r\n协议进行加密的，这正是表示层功能的体现。\r\n\r\n数据压缩与解压缩 (Data Compression and Decompression)\r\n\r\n为了减少网络传输的数据量，提高传输效率和节省带宽，表示层可以对数据进行压缩。步骤说明：\r\n\r\n发送端：表示层使用一种压缩算法（如 Lempel-Ziv\r\n算法）来减少数据的比特数。\r\n接收端：在将数据交给应用层之前，表示层使用相应的解压缩算法将数据恢复到其原始形式。\r\n\r\n这对于传输大型文件、图片、视频等多媒体数据尤其有效。常见的压缩格式如\r\nGZIP, JPEG, MPEG 等都体现了这一功能。\r\n第七层：应用层 (Application\r\nLayer)\r\n应用层是 OSI\r\n模型的最顶层，也是距离最终用户最近的一层。它的核心任务是：直接为用户的应用程序提供网络通信服务，并作为用户与网络之间的接口。\r\n\r\n用户的网络门户：当你使用任何需要联网的软件时，无论是浏览器、电子邮件客户端、游戏还是文件共享程序，你都是在与应用层进行直接交互。应用层负责将你的操作（如点击一个链接、发送一封邮件）转换成网络协议可以理解的请求，并发起通信过程。\r\n协议的集合：应用层本身并不是一个单一的程序，而是一个包含了众多协议的集合。每个协议都是为了实现某种特定的应用功能而设计的。例如，浏览网页用\r\nHTTP 协议，收发邮件用 SMTP 和 POP3 协议。\r\n封装的终点与起点：在发送数据时，应用层是数据封装过程的起点。应用程序产生的数据在这里被首次处理，并加上应用层协议的控制信息，然后向下传递给表示层。在接收数据时，应用层是数据解封装过程的终点。从下层传递上来的数据在这里被最终解析，并呈现给用户或应用程序。\r\n\r\n主要功能与常见协议\r\n与下层处理具体的数据传输细节不同，应用层的功能更加抽象和多样化，主要围绕着为应用程序提供服务展开。\r\n也就是说,\r\n提供用户接口与服务是应用层最根本的功能。它定义了应用程序如何访问网络以及如何使用网络服务。\r\n应用层协议规定了请求和响应的格式、命令和参数。例如，HTTP 协议定义了\r\nGET、POST 等请求方法，以及 200 OK、404 Not Found\r\n等状态码。应用程序（如浏览器）必须按照这些规定来创建请求和解析响应。\r\n同时, 应用层包含了我们日常使用互联网时接触到的大部分协议：\r\n\r\nHTTP (Hypertext Transfer Protocol) / HTTPS (HTTP Secure)\r\n\r\n超文本传输协议，是构建万维网（World Wide Web）的基础。用于从 Web\r\n服务器请求网页和数据，并在浏览器上显示。HTTPS\r\n是其加密版本，提供了更安全的连接。\r\n端口：80 (HTTP), 443 (HTTPS)。\r\n\r\nFTP (File Transfer Protocol)\r\n\r\n文件传输协议，用于在客户端和服务器之间上传和下载文件。\r\n端口：20 (数据), 21 (控制)。\r\n\r\nDNS (Domain Name System)\r\n\r\n域名系统，是互联网的“电话簿”。负责将人类易于记忆的域名（如\r\nwww.google.com）解析成机器能够识别的 IP 地址（如\r\n142.251.1.101）。\r\n端口：53。\r\n\r\nTelnet / SSH (Secure Shell)\r\n\r\n用于远程登录和管理服务器。Telnet 以明文传输数据，非常不安全。SSH\r\n是其加密的替代品，提供了安全的远程命令行访问。\r\n端口：23 (Telnet), 22 (SSH)。\r\n\r\nDHCP (Dynamic Host Configuration Protocol)\r\n\r\n动态主机配置协议，用于网络中的设备自动获取 IP\r\n地址、子网掩码、默认网关等网络配置信息。\r\n\r\n\r\n总的来说, 应用层是整个 OSI\r\n模型的最终目的，它将底层的、复杂的数据传输能力，转化为丰富多彩、功能各异的应用程序和服务，直接呈现给最终用户。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"介质访问控制(Media Access Control, MAC)","url":"/2025/09/26/web/Computer%20Network/%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/5.%20%E4%BB%8B%E8%B4%A8%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/","content":"我们之前讨论的可靠传输、流量控制等，大多是针对点对点\r\n(Point-to-Point)\r\n链路的，即链路上只有两个节点。但在很多网络中，多个节点需要共享同一条通信信道，这种信道被称为广播信道\r\n(Broadcast Channel)。\r\n例如早期的总线型以太网（所有计算机共享一根同轴电缆），现在的无线局域网\r\nWi-Fi（所有设备共享同一频段的空口）。\r\n在广播信道上，如果两个或两个以上的节点同时发送数据，它们的信号就会在信道中混合、相互干扰，导致所有数据都变得无法识别，这种现象称为冲突\r\n(Collision)。\r\n介质访问控制 (MAC)\r\n的任务就是制定一套规则，来协调各个节点对共享介质的访问，决定“下一个谁可以发送数据”，从而尽可能地避免或解决冲突问题。MAC协议通常被认为是数据链路层的一个子层（MAC子层）。\r\nMAC协议主要分为三大类：信道划分、随机访问和轮询访问。其中前者是静态分配，后两者是动态分配。\r\n信道划分介质访问控制\r\n(Channel Partitioning)\r\n这类协议的核心思想是“资源预留”。它将共享的信道资源（如时间、频率）从物理上分割成多个互不干扰的子信道，然后为每个节点分配一个专用的子信道。\r\n优点：一旦分配，节点就可以在自己的子信道上自由通信，绝不会发生冲突。网络负载高时，性能稳定且有保障。\r\n缺点：效率低下，资源浪费。如果一个节点被分配了子信道，但它大部分时间都没有数据要发送，那么这个子信道的容量就被白白浪费了。这对于流量具有突发性的计算机网络来说，尤其不划算。\r\n其主要是通过复用技术来实现的，所谓复用，就是将多个信号合并在一起传输，然后在接收端再将它们分离开来。\r\n\r\n\r\nalt text\r\n\r\n频分多路复用\r\n(FDMA - Frequency Division Multiple Access)\r\n核心思想是按频率划分信道。类似于不同的广播电台使用不同的频率播出节目，互不干扰。\r\n\r\n\r\nalt text\r\n\r\n如图所示，频分多路复用将总带宽划分为多个频段\r\n(Channel)，每个节点被分配到一个独立的频段进行通信。同一时刻不同节点使用不同的频段，因此不会发生冲突。\r\n时分多路复用\r\n(TDMA - Time Division Multiple Access)\r\n时分多路复用按时间划分信道。将时间划分为一个个时隙，每个节点被分配到固定的时隙才能发送数据，这样的时隙称作\r\nTDM\r\n帧。如图，每个用户在自己的时隙内发送数据，不同用户的时隙互不重叠，因此不会发生冲突。\r\n\r\n\r\nalt text\r\n\r\n波分多路复用\r\n(WDM - Wavelength Division Multiplexing)\r\n波分多路复用实际上就是光纤网络中的频分复用，按光的波长来划分信道。\r\n码分多路复用\r\n(CDMA - Code Division Multiple Access)\r\n码分多路复用按码片序列划分信道。每个节点被分配一个唯一且相互正交的码片序列\r\n(Chipping Sequence)，用来对数据进行编码。\r\n所有节点可以在同一时间、同一频率发送数据，但由于使用了不同的码片序列，因此不会发生冲突。接收方利用相同的码片序列，可以从混合的信号中分离出自己想要的数据。\r\n\r\nCDMA 的技术基石是正交性 (Orthogonality)：\r\n- 任何码片序列 S\r\n与其自身的规格化内积结果为 +1；\r\n- 两个不同用户的码片序列 S 和\r\nT，其规格化内积结果为 0；\r\n- 任何码片序列 S\r\n与其反码的规格化内积结果为 −1。\r\n\r\n例如，A 节点被分配了码片序列 S = (−1, −1, −1, 1, 1, −1, 1, 1)，这里的\r\n−1 和 1 分别表示二进制的 0 和 1。\r\n这意味着，A 节点如果发送比特 1\r\n就是发送该用户原始的码片序列 S；发送比特 0 就是发送该用户码片序列的反码（所有 +1 变 −1，−1 变\r\n+1）。\r\nB 节点也要传输信息，分配码片 T = (−1, 1, −1, −1, 1, −1, 1, 1)（此码片与\r\nS 正交）。\r\n假设 A 发送比特 1，B 发送比特 0，则它们同时在信道中发送的信号为：\r\nS + (−T) = (−1, −1, −1, 1, 1, −1, 1, 1) + (1, −1, 1, 1, −1, 1, −1, −1) = (0, −2, 0, 2, 0, 0, 0, 0)，\r\n接收端 C 节点接收到了这个混合信号 (0, −2, 0, 2, 0, 0, 0, 0)。\r\nC 节点现在可以利用码片序列从混合信号中分离出它想听的信号：\r\n解码 A 站的信号：\r\nC 站用 A 站的码片 S\r\n与混合信号进行内积运算。\r\n解码结果：\r\n\r\n根据规则：S ⋅ S = 1，而 。\r\n解码结果：\r\n1 + 0 = 1\r\n结论：结果为正，代表站点 A 发送了比特 1。\r\n解码 B 站的信号：\r\nC 站用 B 站的码片 T\r\n与同一个混合信号进行内积运算。\r\n解码结果：\r\n\r\n根据规则：S ⋅ T = 0，而 。\r\n解码结果：\r\n0 + (−1) = −1\r\n结论：结果为负，代表站点 B 发送了比特 0。\r\n\r\n如果结果为零，说明该站点没有发送任何数据。\r\n\r\n这种技术实际上就是扩频通信 (Spread Spectrum\r\nCommunication)\r\n的基础。它通过将原始信号扩展到一个更宽的频带上进行传输，从而提高抗干扰能力和安全性。\r\n甚至即使码片序列中的少数几位因为干扰而出错，经过整个序列的“民主投票”（内积运算），最终的结果仍然能非常可靠地判断出原始比特是1还是0\r\n随机访问介质访问控制 (Random\r\nAccess)\r\n这类协议的核心思想是“先到先得”。节点在任何时候，只要有数据要发送，就可以立即尝试在信道上发送数据。如果发生冲突，节点会通过某种机制来检测到冲突，并在稍后重新尝试发送,\r\n因此, 协议的核心是如何处理不可避免的冲突 (Collision) 问题。\r\nALOHA 协议\r\nALOHA\r\n协议是最早的随机访问协议，思想极其简单，也因此效率很低。它是后续更复杂协议的思想源头。\r\n纯 ALOHA (Pure ALOHA): “想发就发，完全随性”,\r\n任何节点只要有数据要发送，就可以立即发送。\r\n发送后，节点会监听信道，等待一个确认\r\n(ACK)。如果在规定时间内没有收到ACK，就认为发生了冲突。发生冲突后，节点会等待一个随机的时间，然后重新发送。\r\n假设发送一帧需要时间 TD。如果 A 站在\r\nt0\r\n时刻开始发送，那么任何其他站只要在区间 [t0 − TD, t0 + TD]\r\n内开始发送数据，都会与 A 站发生冲突。也就是说，冲突窗口的长度为 2TD，范围非常大，因此纯\r\nALOHA 的信道利用率较低。\r\n分隙 ALOHA (Slotted ALOHA): “统一行动，只在整点发”,\r\n将时间划分为一个个等长的时隙 (Slot)，每个时隙的长度刚好够发送一帧。\r\n节点不再是随时可以发送，而是必须等到下一个时隙的开始时刻才能发送。如果多个节点在同一个时隙内发送，仍然会发生冲突。\r\n此时冲突只可能发生在多个节点选择同一个时隙发送的情况下。冲突窗口从\r\n2TD 缩小到\r\nTD，信道利用率有所提升。\r\nCSMA 协议 (载波侦听多路访问)\r\nCSMA 协议是对ALOHA协议的重大改进，引入了载波侦听 (Carrier Sense)\r\n的机制。核心思想: “先听再说 (Listen Before Talk)”.\r\n一个节点在发送数据之前，会先侦听信道，检查信道是否空闲。如果信道空闲，则发送数据;\r\n如果信道正忙，节点会等待，直到信道变为空闲。\r\n尽管这样, 冲突仍然可能发生, 因为信号在信道上传播需要时间（传播时延\r\nTP）。可能A站在侦听到信道空闲后立即发送，但其信号还没传播到B站，此时B站也可能侦听到信道空闲并开始发送，从而导致冲突。\r\n根据“监听到信道忙后怎么办”，CSMA又分为三种：\r\n\r\n1-坚持 CSMA:\r\n监听到信道忙，就持续监听，一旦空闲立即发送。缺点是如果多个节点都在等待，信道一空闲它们会同时发送，导致冲突概率大。\r\n非坚持 CSMA:\r\n监听到信道忙，就放弃监听，等待一个随机时间后再回来重新尝试。缺点是可能导致信道空闲了也没人立即使用，利用率降低。\r\np-坚持 CSMA: 只适用于时分复用信道. 监听到信道空闲，以概率\r\np 发送，以概率 1−p\r\n推迟到下一个时隙。这是前两者的折中。若监听到信道忙，则持续监听(监听到下一个信道)。\r\n\r\nCSMA/CD 协议\r\n(载波侦听多路访问/冲突检测)\r\nCSMA/CD 协议是在 CSMA 的基础上，增加了冲突检测 (Collision Detection)\r\n的机制。核心思想: “边说边听，冲突即停 (Talk and Listen Simultaneously,\r\nStop on Collision)”. 这是有线以太网 (Ethernet)\r\n采用的经典协议.\r\n它继承了CSMA的“先听再说”。最重要的改进是，节点在发送数据的同时，会持续不断地监听信道。如果在发送过程中，节点监听到信道上的信号与自己发送的信号不一致，就说明发生了冲突。\r\n当冲突发生时, 立即停止发送数据(等待一段时间后重新发送),\r\n并发送一个简短的冲突增强信号 (Jam\r\nSignal)，以确保网络上所有节点都知道发生了冲突，并丢弃已收到的不完整数据。接着执行二进制指数退避算法\r\n(Binary Exponential Backoff)：\r\n\r\n定义 k 为当前帧的重传次数。第一次冲突后，准备进行第1次重传，此时\r\nk=1。如果再次冲突，准备进行第2次重传，此时 k=2，以此类推。\r\n在进行第 k 次重传时，从整数集合 [0, 1, …, 2^k - 1]\r\n中随机选择一个数，记为 r。同时, 为了防止等待时间的上限变得过长，算法对 k\r\n的值进行了限制, 一般\r\nk=min(重传次数,10)。这意味着当重传次数小于等于10时，k 就等于重传次数;\r\n当重传次数超过10次后，k\r\n的值不再增长，始终保持为10。因此，随机数的最大选择范围就是 [0,\r\n1023]。\r\n等待 r 个争用期 (Contention Period)\r\n后，重新尝试发送数据。(也就是说所有的退避等待时间都是争用期的整数倍)。\r\n如果重传次数超过了一个预设的最大值\r\n(通常是16次)，就放弃发送该帧，并向上层报告一个错误。\r\n\r\n优点:\r\n能在冲突发生的第一时间就检测到并停止发送，极大地减少了因冲突而浪费的信道时间和带宽。同时确保冲突的站点在不同的时间点重新尝试发送,避免再次冲突。\r\n争用期 (Contention Period)\r\nCSMA/CD协议中的冲突检测不是瞬时的。根本原因在于电磁波的传播速率是有限的。\r\n\r\n\r\nalt text\r\n\r\n上图展示了两个节点发送信息时出现冲突的情况: - t = 0:\r\n站点A（最左端）侦听信道空闲，开始发送数据。 - t = τ - δ:\r\nA的信号即将到达最右端的站点B。就在这一瞬间，B也侦听到信道空闲并决定发送数据。（τ\r\n是信号从A到B的单程最大传播时延，δ\r\n是一个极小的时间）。这是可能发生冲突的最晚时刻。 - t = τ - δ/2:\r\n冲突发生, B发出的信号与A发出的信号在B站附近立刻相撞。 - t = τ:\r\nA的信号传播了整整一个 τ 的时间，终于到达了B, 同一时刻,\r\nB检测到了冲突，并立即停止发送。 - t = 2τ - δ:\r\n冲突的信号从B站附近一路传回，最终在 t = 2τ - δ\r\n(2倍的冲突发生时间)时刻到达A站。此时，A站才终于检测到自己之前发送的数据发生了冲突。\r\n因此, 取极限δ-&gt;0,\r\n从A开始发送，到A能确信自己的发送是否成功（即是否检测到冲突），最多需要经过两倍的端到端传播时延\r\n(2τ)。而争用期 (Contention\r\nPeriod)，也称为冲突窗口或碰撞窗口，就是指这个最长时间 2τ。\r\n它的物理意义是：在以太网中，一个站点发送数据后，最多经过时间\r\n2τ，就可以确定自己是否成功“占领”了信道。\r\n如果在争用期（2τ）内没有检测到冲突，那么之后就绝不可能再发生冲突了（因为此时第一个比特已经传播到了网络中的所有角落，所有其他站点都已经能侦听到信道为“忙碌”状态）。\r\n例如,\r\n在10Mb/s的以太网标准中，经过精确计算和一定的工程冗余，这个争用期被规定为\r\n51.2μs\r\n最短帧长 (Minimum Frame\r\nLength)\r\n现在，一个关键问题出现了：站点A必须确保在 t = 2τ\r\n这个最晚的冲突信号返回之前，自己仍然在发送数据。否则，如果它已经发送完毕并“认为”传输成功，它就永远不会知道其实自己的帧已经在半路被毁了(认为传输成功后就不再监听信号)。\r\n这就引出了一个必须满足的不等式：帧的发送时延 (TD) ≥ 争用期\r\n(2τ)\r\n我们将这个不等式展开：\r\n最短帧长数据传输速率 即, 最短帧长≥争用期×数据传输速率\r\n根据上述公式, 计算以太网规定最短帧长得到了64字节 (512 bits):\r\n这个长度确保了即使发生最极端的“末端碰撞”，发送方也能在发送完成前及时检测到冲突，从而执行退避算法进行重传。\r\n同时,\r\n任何小于64字节的帧都被认为是无效帧，也称为“冲突碎片”\r\n(Runt\r\nFrame)。网络设备（如交换机、网卡）收到这种帧会直接将其丢弃，因为它们知道这必然是冲突后异常中止发送的残留物。\r\n\r\n如果上层（如IP层）交下来的数据包本身很小，不足以构成一个64字节的帧（例如，只有一个ACK确认信息），那么数据链路层必须在数据字段后面填充一些额外的字节，以凑够64字节的最小长度，然后才能发送。\r\n\r\nCSMA/CA 协议\r\n(载波侦听多路访问/冲突避免)\r\nCSMA/CA 协议是在 CSMA 的基础上，增加了冲突避免\r\n(Collision Avoidance) 的机制。核心思想: “先听再说，冲突前预防 (Listen\r\nBefore Talk, Prevent Collision)”. 这是无线局域网\r\n(Wi-Fi) 采用的经典协议.\r\n\r\n无法实现冲突检测主要是因为无线信号的传播特性。无线信号在空气中传播时，信号强度会随着距离的增加而迅速衰减,\r\n同时无线设备通常功率较低。因此,\r\n无线设备在发送数据时难以监听到信道上的其他信号,\r\n也就无法检测到冲突。当然, 还有下面要介绍的隐藏站问题。\r\n\r\n这套机制主要由以下几个部分组成：\r\n核心策略一：确认与重传 (ARQ)\r\n由于无线信道的通信质量远不如有线信道，数据帧更容易丢失或损坏。为了保证可靠传输，802.11标准规定，所有单播的数据帧都必须得到接收方的确认\r\n(ACK)。\r\n\r\n802.11标准，也就是我们常说的 Wi-Fi 协议族，是由\r\nIEEE（电气电子工程师学会）在 1997 年制定的无线局域网通信协议标准\r\n\r\n因此发送方每发送一个数据帧，就会启动一个计时器并等待接收方回复ACK帧。如果在规定时间内收到了ACK，说明传输成功。如果超时仍未收到ACK，发送方就认为该帧已丢失或损坏（即发生了冲突），并会立即进行重传。这是一种停止-等待式的可靠传输机制。\r\n核心策略二：帧间间隔 (IFS) - 协调信道访问优先级\r\n为了避免多个站点在信道刚一空闲时就“蜂拥而上”导致冲突，CSMA/CA规定，所有站点在发送前都必须先侦听信道。当侦听到信道从忙碌变为空闲后，不能立即发送，而是必须再等待一段被称为帧间间隔\r\n(InterFrame Space, IFS) 的时间。\r\nIFS的长短决定了访问的优先级。等待时间越短，优先级越高。主要有三种IFS：\r\n- SIFS (短帧间间隔 - Short IFS):\r\n时间最短，优先级最高。用于处理需要立即响应的、最高优先级的操作，例如发送\r\nACK 确认帧, 回复 CTS (清除发送) 帧,\r\n响应接入点(AP)的轮询等。这保证了像ACK这样的重要控制帧不会因为要和其他数据帧竞争而被延迟。\r\n- PIFS (点协调功能帧间间隔 - PCF IFS):\r\n时间中等，优先级较高。在PCF（点协调功能，一种集中控制模式）下，供AP（无线路由器）优先抢占信道使用。\r\n- DIFS (分布式协调功能帧间间隔 - DCF IFS):\r\n时间最长，优先级最低。这是最常用的一种间隔。任何一个站点如果想要发送一个新的数据帧或管理帧，当它检测到信道空闲后，必须至少等待一个DIFS的时长\r\n核心策略三：退避倒计时\r\n这是CSMA/CA避免冲突的精髓所在。当一个站点有数据要发送，并且已经等待了一个DIFS后，它并不能立刻发送，而是要进入一个随机退避阶段(除非是第一个发送帧且信道空闲)。\r\n启动时机： - 在发送一个新的数据帧之前（在DIFS后）检测到信道忙。 -\r\n在每一次重传之前。 - 在每一次成功发送后，准备发送下一个新帧之前。\r\n退避时间计算：\r\n类似CSMA/CD协议, 但不同的是, 站点在进行第 k 次重传时，从整数集合 [0,\r\n1, …, 2^{k+2} - 1] 的范围内随机选择一个数，作为自己的退避计时器的值,\r\n这样做扩大了随机选择的范围, 从而进一步降低冲突概率。不过,\r\nk的最大值被限制在了6, 因此最大范围是 [0, 255]。\r\n退避倒计时过程： - 站点选择了随机的退避值后，开始倒计时。 -\r\n倒计时器只在信道保持空闲时才会递减。 -\r\n如果在倒计时过程中，信道被其他站点占用变为忙碌，则计时器暂停,\r\n直到信道再次变为空闲，并经过一个DIFS后，计时器才继续从暂停处开始倒数。 -\r\n当且仅当计时器倒数到0时，站点才能真正发送它的数据帧。\r\n这个“暂停-继续”的机制极大地降低了冲突概率。即使多个站点在同一个DIFS后启动了退避，它们大概率会选择不同的随机值，因此倒计时到0的时刻也不同，从而实现了“错峰出行”。\r\n总之, CSMA/CA 算法的过程如下：\r\n1）若站点最初有数据要发送（而非发送不成功后再进行重传），且检测到信道空闲，那么在等待时间\r\nDIFS 后，就发送整个数据帧。\r\n2）否则，站点执行 CSMA/CA\r\n退避算法。选取一个随机退避时间。一旦检测到信道空闲，退避计时器就保持不变。只要信道空闲，退避计时器就继续倒计时。\r\n3）退避计时器减为 0\r\n后（即等待时间已被足够的时间），站点就发送整个数据帧。\r\n4）若接收方正确接收到该数据帧（即帧的校验和正确），则发送一个确认帧\r\nACK。否则，发送方在超时时间后重传该数据帧。\r\n5）若发送方没有接收到\r\nACK，就认为该数据帧丢失，进入重传过程。重传过程包括退避算法（即 CSMA/CA\r\n退避算法）。重传过程重复一定次数。若连续多次发送失败，则 CSMA\r\n协议中断该数据帧的发送，改经过上层协议的其他方式来发送。\r\n隐藏站问题 (Hidden Terminal\r\nProblem)\r\n隐藏站问题描述的是这样一种情况: 三个站点分布为A–B–C,\r\n显然A和C都能和B通信，但A和C距离较远,\r\n之间互相听不到。如果A和C在某时刻检测到信道空闲而同时向B发送数据，就会在B处发生冲突,\r\n这里假如A是发送站, B是接收站, 那C对于A来说就是隐藏站.\r\n为了解决“隐藏站”问题，802.11标准提出了信道预约机制和虚拟载波监听机制。\r\n发送方在发送数据前(已经监听信道空闲并等待了DIFS)，先向目的站发送一个\r\nRTS (请求发送 - Request to Send)\r\n帧，告诉接收方自己有数据要发送，并请求许可。接收方收到RTS后，如果信道空闲且准备好接收，在等待SIFS后就广播回复一个\r\nCTS (清除发送 - Clear to Send) 帧，表示允许发送。\r\nCTS帧中包含了一个持续时间字段，指示发送方和其他所有听到CTS的站点，自己将占用信道多长时间。这样,\r\n其他站点(包括隐藏站)在听到CTS后, 都会知道信道即将被占用,\r\n并且知道要等待多长时间才可以再次尝试发送, 从而避免了冲突。\r\nA站在收到CTS后, 等待SIFS后就发送数据帧。B站在正确接收到数据帧后,\r\n也等待SIFS后发送ACK确认帧, 从而成功完成了一次可靠的数据传输。\r\n而在RTS和CTS帧中(甚至传输的数据帧也可以携带),\r\n都附带了本次通信所要占据信道的时间,\r\n所谓虚拟载波监听指的就是其他节点虽然不一定是这些帧的目的站,\r\n但是可以监听并解析这些帧(MAC帧头中的 Duration\r\n字段)，这些帧中包含了本次通信预计要持续的时间。节点于是根据这个时间设置一个“网络分配向量(NAV)”，在NAV计时器归零前，即使物理信道空闲，节点也会认为信道是“虚拟”忙碌的，从而保持静默。\r\n轮询访问 (Polling Access)\r\n轮询访问是一种受控的访问方式，其核心思想可以概括为“依次点名，授权发言”。\r\n在这种机制下，网络中的节点不能随心所欲地发送数据。它们必须等待“授权”。这个授权的过程，就是由一个主节点或一种特殊规则，按照一定的顺序（通常是循环的）去“轮询”或“询问”每一个节点是否需要发送数据。\r\n这种方式完全避免了随机访问中可能发生的冲突，因为在任何时刻，只有一个节点被授权使用信道。它比信道划分更灵活，因为信道是按需分配，而不是永久预留。\r\n轮询可以由一个中心站来完成。但更常见的一种分布式是令牌传递协议，它通过传递“令牌”这个“发言权”信令，来模拟一个去中心化的轮询过程,\r\n基本步骤如下:\r\n\r\n步骤 A - 等待令牌:\r\n一个节点（例如A）如果有数据要发送，它必须进入监听状态，等待从其上游节点传来的令牌。\r\n步骤 B - 捕获令牌与发送数据: 当A接收到“空闲”令牌后，它会：\r\n\r\n将令牌的状态从“空闲”改为“忙碌”。\r\n将自己的数据帧附加在“忙碌”令牌之后，发送到环路中。\r\n\r\n步骤 C - 沿环传递与接收:\r\n载有数据的帧沿着环路向下游传递。环路上的每个节点都会接收并检查该帧的目的地址。\r\n\r\n如果不是发给自己的，就简单地将该帧转发给下游节点。\r\n如果目的地址是自己（例如节点C），C就会复制一份数据帧的内容。\r\n\r\n步骤 D - 释放令牌:\r\n数据帧会继续传递，直到它绕环一周后，返回到最初的发送方A。\r\n\r\nA接收到自己发出的帧后，确认它已被成功环回（可以检查帧中的状态位了解接收情况）。\r\nA将该数据帧从环路中移除,\r\n并重新生成一个新的“空闲”令牌，并将其发送给自己的下游节点。\r\n\r\n\r\n\r\n如果一个节点收到“空闲”令牌，但它自己没有数据要发送，它会立即将这个“空闲”令牌转发给下游节点。\r\n\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"中低频交易","url":"/2025/10/16/misc/Quant/Overview/%E4%B8%AD%E4%BD%8E%E9%A2%91%E4%BA%A4%E6%98%93/","content":"量化交易根据交易频率的不同，可以分为高频交易（HFT）、中频交易和低频交易三大类。而中低频交易通常指的是持仓时间从几分钟到几天的交易策略。这类策略相较于高频交易，交易频率较低，但仍然需要一定的市场敏感度和快速反应能力。\r\n要建立一个清晰的框架，最好的方式是从策略的“思想根源”或“Alpha来源”进行分类。也就是说，我们根据“策略为什么能赚钱”的根本逻辑来进行划分。\r\n在这个框架下，中低频量化策略主要可以分为以下五大类别，每个类别下又包含多种具体的策略。\r\n\r\n基于市场数据规律的策略 (Market Data-Driven)\r\n\r\n核心假设：市场的历史价格和成交量数据中蕴含着可以预测未来价格走势的模式。这是最经典的量化思想。\r\n\r\n基于基本面数据的策略 (Fundamental\r\nData-Driven)\r\n\r\n核心假设：公司的财务状况、行业地位、宏观经济等基本面信息是决定其长期价值和未来收益的核心驱动力。\r\n\r\n事件驱动策略 (Event-Driven)\r\n\r\n核心假设：特定的、公开的公司或宏观事件会系统性地影响资产价格，通过在事件前后布局可以获利。例如并购重组、财报发布等事件。\r\n\r\n套利策略 (Arbitrage-Based)\r\n\r\n核心假设：市场在短期内可能无效，导致同一资产或高度相关资产之间出现定价错误，这些价差是低风险的盈利机会。\r\n\r\n新兴与复合策略 (Emerging &amp; Hybrid)\r\n\r\n核心假设：通过更先进的算法（如机器学习）或更独特的数据源（如另类数据）可以发掘传统方法无法找到的盈利模式。\r\n\r\n\r\n现在我们来详细展开每个主干下的具体策略。\r\n基于市场数据规律的策略\r\n这类策略主要分析价和量，它们构成了量化世界里的“阴”和“阳”，逻辑上完全对立，分别适用于不同市场环境。\r\n\r\n趋势跟踪策略 (Trend Following)\r\n\r\n盈利逻辑：捕捉并顺应市场的单边走势（牛市或熊市）。\r\n核心思想：资产价格的动量会持续一段时间，“强者恒强，弱者恒弱”。\r\n常用技术：双均线系统、唐奇安通道、布林带突破、MACD等。\r\n持仓周期：中长，通常为数周至数月。\r\n适用环境：趋势市。在市场方向明确时表现优异。\r\n致命弱点：震荡市。会被市场反复“来回打脸”，造成持续的小额亏损。\r\n\r\n均值回归策略 (Mean Reversion)\r\n\r\n盈利逻辑：捕捉市场在震荡区间内的来回波动。\r\n核心思想：价格会围绕其长期均值波动，“涨多必跌，跌多必涨”。\r\n常用技术：布林带、相对强弱指数(RSI)、振荡器指标(KDJ,\r\nCCI)、Z-Score检验等。\r\n持仓周期：中短，通常为数小时至数天。\r\n适用环境：震荡市。在没有明确方向的市场中表现优异。\r\n致命弱点：趋势市。逆势交易可能导致巨大亏损，是趋势跟踪策略的“死对头”。\r\n\r\n\r\n基于基本面数据的策略\r\n这类策略侧重于公司的内在价值和长期成长性，是传统价值投资的系统化和数量化。\r\n\r\n多因子模型 (Multi-Factor Models)\r\n\r\n盈利逻辑：寻找并组合多种能稳定预测股票未来收益的“因子”，构建超越市场基准的投资组合。\r\n核心思想：股票的长期回报由其内在的多种特征（因子）共同决定。\r\n经典因子：\r\n\r\n价值因子(Value)：如低市盈率(P/E)、低市净率(P/B)。\r\n规模因子(Size)：小市值公司通常有更高成长性。\r\n动量因子(Momentum)：过去表现好的股票未来可能继续表现好（与趋势跟踪思想相通）。\r\n质量因子(Quality)：如高净资产收益率(ROE)、低负债率。\r\n低波因子(Low Volatility)：低风险的股票长期回报更稳健。\r\n成长因子(Growth)：如高营收增长率、高利润增长率。\r\n\r\n操作流程：因子挖掘 -&gt; 因子打分 -&gt; 构建投资组合 -&gt;\r\n定期调仓。\r\n持仓周期：长，通常为每月或每季度调仓一次。\r\n\r\n\r\n事件驱动策略\r\n这类策略利用特定事件对资产价格的影响，通常具有较强的时效性和针对性。它们的收益来源与大盘涨跌相关性较低。\r\n\r\n公司公告类：\r\n\r\n财报超预期：在财报公布后，买入业绩超预期的公司。\r\n高送转/分红：在预案公告日买入，在除权除息日前卖出。\r\n\r\n公司行为类：\r\n\r\n并购套利 (Merger\r\nArbitrage)：A公司宣布收购B公司后，买入B公司股票，赚取其市价与最终收购价之间的差价。\r\n定向增发：分析增发价格、对象和目的，判断其对股价的短期影响。\r\n\r\n市场行为类：\r\n\r\n指数成分股调整：提前买入即将被纳入重要指数（如沪深300）的股票，因为被动型基金届时必须建仓。\r\n\r\n\r\n套利策略\r\n这类策略追求的是确定性更高、风险更低的收益。\r\n\r\n统计套利 (Statistical Arbitrage)\r\n\r\n盈利逻辑：利用资产之间被统计规律验证过的稳定关系，当这种关系暂时被打破时进行套利。\r\n核心思想：它并非无风险，而是基于高概率会修复的价差。\r\n经典代表：配对交易 (Pairs\r\nTrading)。找到两只高度相关的股票（如可口可乐与百事可乐），在它们价差扩大时，做空价格偏高的、做多价格偏低的，等待价差收敛。\r\n\r\n期现套利 (Cash-Futures Arbitrage)\r\n\r\n盈利逻辑：利用股指期货价格与现货指数价格之间的价差（基差）进行套利。\r\n操作：当基差为正且过大时，卖出股指期货，同时买入一篮子现货股票；当基差为负且过大时，反向操作。\r\n\r\n跨期/跨品种套利\r\n：利用同一资产不同交割月份或不同但相关资产之间的价差进行套利。\r\n\r\n新兴与复合策略\r\n这类策略结合了多种先进技术和数据源，力求在竞争激烈的市场中寻找新的Alpha来源。它代表了量化交易的前沿方向。\r\n\r\n机器学习策略 (Machine Learning Strategies)\r\n\r\n盈利逻辑：利用复杂的机器学习算法（如梯度提升树、神经网络）从海量数据中自主学习并发现非线性的预测模式。\r\n应用：可以用于改进传统因子模型（发现新因子）、进行择时（判断市场状态），或直接输出买卖信号。\r\n\r\n另类数据策略 (Alternative Data Strategies)\r\n\r\n盈利逻辑：利用传统财务和行情数据之外的信息源，获取领先于市场的信息优势。\r\n数据源示例：\r\n\r\n卫星图像：分析工厂、港口、商场停车场的活跃度来预测经济或公司业绩。\r\n网络舆情：分析社交媒体对某公司或产品的情绪。\r\n供应链数据：通过核心企业的订单数据预测上下游公司的业绩。\r\n招聘数据：通过分析公司的招聘岗位和数量判断其扩张意图。\r\n\r\n\r\n\r\n","categories":["misc"],"tags":["misc"]},{"title":"应用层","url":"/2025/10/22/web/Computer%20Network/%E5%BA%94%E7%94%A8%E5%B1%82/%E5%BA%94%E7%94%A8%E5%B1%82/","content":"应用层是 OSI 参考模型的最高层 (第 7 层)，也是 TCP/IP\r\n体系结构事实上的顶层。它是离用户最近的一层。\r\n它的根本目标是通过应用进程之间的交互来实现特定的网络应用。我们平时使用的各种网络功能，如网页浏览、文件下载、电子邮件、在线游戏等，都是在应用层实现的。可以说，设计和建立计算机网络的最终目的，就是为了运行应用层上的各种应用程序，满足用户的需求\r\n同时, 应用层开发也具有很高的便利性.\r\n网络应用程序只运行在端系统（用户的计算机、服务器等）上,\r\n传输层已经为应用进程提供了端到端的逻辑通信服务（TCP 或\r\nUDP）。开发者无需关心底层网络核心的复杂细节，如路由器的选择、数据包的转发等。\r\n客户/服务器方式和对等方式\r\n在开发一个新的网络应用时，首先要考虑的问题是：这个应用的程序如何在不同的端系统上组织？它们之间是什么关系？目前主要有两种流行的体系结构。\r\n客户/服务器方式 (Client/Server,\r\nC/S)\r\n这是最传统、最成熟的网络应用模型。它将应用程序分为两个部分：客户端和服务器。客户端是向服务器请求服务的应用程序，而服务器是提供服务的应用程序。客户端和服务器之间通过网络进行通信。\r\n服务器 (Server)：指运行服务器程序的应用进程。\r\n\r\n它是服务的提供方,\r\n通常持续运行，被动地等待客户的请求。\r\n具有固定的 IP\r\n地址和熟知的传输层端口号（如 Web 服务器的 80\r\n端口）。\r\n\r\n客户 (Client)：指运行客户程序的应用进程。\r\n\r\n它是服务的请求方,\r\n主动向服务器发起请求。\r\n客户端计算机的 IP\r\n地址通常是动态的，使用的端口号也是临时的。\r\n\r\n模型特点:\r\n\r\n服务集中型：\r\n应用服务集中在少数（通常性能强大）的服务器计算机上。\r\n不对等关系：\r\n客户和服务器的角色固定，功能不同。\r\n\r\n优点： - 易于管理和维护（服务集中）。 - 安全性相对容易控制。\r\n缺点： - 可扩展性问题：\r\n当客户数量激增时，单一服务器容易成为性能瓶颈 。 - 成本较高：\r\n需要购买和维护高性能的服务器硬件及带宽。 - 单点故障：\r\n如果服务器宕机，整个服务就会中断。\r\n解决方案 (针对缺点)： 使用服务器集群 (Server\r\nCluster) 或服务器场 (Server Farm)\r\n来构建一个强大的“虚拟服务器”，以提高处理能力和可靠性 。\r\n典型应用： 万维网 (WWW)、文件传送 (FTP)、电子邮件\r\n(Email)、数据库访问等。\r\n对等方式 (Peer-to-Peer, P2P)\r\n这是一种相对较新的、与 C/S\r\n模型截然不同的结构。其核心概念是对等关系。\r\nP2P没有固定的客户和服务器角色,\r\n网络边缘端系统上的应用进程互称对等方(Peer)。每个对等方既是服务的请求者，又是服务的提供者,\r\n对等方之间直接通信。\r\n模型特点： - 服务分散型：\r\n服务能力分布在大量对等方的计算机上，这些计算机通常是个人拥有并控制的 。\r\n- 对等关系： 所有参与者的角色和功能相似。\r\n优点： - 高度可扩展性：\r\n每增加一个对等方，不仅增加了服务需求，同时也增加了服务提供能力。系统性能不会因规模增大而降低（甚至可能提高）。\r\n- 成本低廉： 通常不需要庞大的服务器设施和带宽投入 。 -\r\n鲁棒性 (Robustness)：\r\n不存在单点故障，部分对等方离线不影响整个系统的运行。\r\n缺点： - 管理复杂：资源分散，难以集中管理和控制。 -\r\n安全性问题：内容来源多样，可能存在安全风险或版权问题。\r\n-\r\n性能不稳定：对等方的在线时间和带宽不稳定，可能影响服务质量。\r\n典型应用： P2P文件共享 (如 BitTorrent)、即时通信\r\n(部分功能)、P2P 流媒体 (如某些直播)、分布式存储 。\r\n此外, 目前还演进出了混合模式：许多现代应用会混合使用\r\nC/S 和 P2P 模式 。例如，用户登录和好友列表可能依赖中心服务器\r\n(C/S)，而文件传输或音视频通话则采用 P2P 直接连接。\r\n动态主机配置协议 (DHCP)\r\n任何一台主机想要接入 TCP/IP\r\n网络（如因特网）并与其他主机正常通信，都必须首先配置好一系列关键的网络参数。这些参数就像主机的“网络身份证”和“导航地图”，主要包括\r\n：\r\n\r\nIP 地址 (IP Address)：\r\n主机在网络中的唯一标识符，就像门牌号。\r\n子网掩码 (Subnet Mask)： 用于区分 IP\r\n地址中的网络部分和主机部分，帮助主机判断通信目标是在本地子网还是需要通过路由器转发。\r\n默认网关的 IP 地址 (Default Gateway IP\r\nAddress)：\r\n当主机需要与本地子网之外的主机通信时，数据包需要发送给这个“网关”（通常是路由器）进行转发。\r\n域名服务器 (DNS) 的 IP 地址 (DNS Server IP\r\nAddress)： 主机需要通过 DNS 服务器将易于记忆的域名（如\r\nwww.google.com）解析成 IP 地址才能进行访问。\r\n\r\n在早期或小型网络中，这些参数可以通过操作系统提供的工具（图形界面或命令行）手动配置在每台主机上。主机会将这些配置保存在一个文件中，并在每次启动时读取使用。\r\n但是随着网络规模的扩大和移动设备的普及，手工配置网络参数暴露出诸多不便和问题\r\n：\r\n\r\n工作量巨大且易出错\r\n(对于管理员)：想象一下在一个拥有数百甚至数千台主机的企业或校园网络中，网络管理员需要为每一台机器逐一手动输入上述所有参数。这不仅是一项极其繁琐、耗时的工作，而且非常容易出错（例如输错\r\nIP 地址、掩码或网关），导致主机无法正常联网 。\r\n不方便且易出错\r\n(对于用户)：对于经常需要在不同网络环境（如家中、办公室、咖啡馆）中使用笔记本电脑的用户来说，每次更换地点都需要重新手动修改网络配置，这非常不方便\r\n。用户可能不清楚每个网络环境的具体参数，或者在配置过程中出错。\r\n\r\n动态主机配置协议的作用\r\n为了解决手工配置带来的种种问题，动态主机配置协议\r\n(Dynamic Host Configuration Protocol, DHCP) 应运而生。\r\nDHCP\r\n允许网络中的主机自动获取所需的网络配置参数，而无需人工干预。\r\n实现方式是, 网络管理员先在网络中部署一台 DHCP\r\n服务器。\r\n\r\n在 DHCP\r\n服务器上集中配置好可供分配的网络参数范围（如\r\nIP 地址池、子网掩码、默认网关地址、DNS 服务器地址等）。\r\n网络中的客户端主机（如\r\nPC、笔记本电脑、手机）在开机或接入网络时，会自动运行 DHCP\r\n客户端程序。\r\nDHCP 客户端会自动向网络中的 DHCP\r\n服务器请求配置参数 。\r\nDHCP\r\n服务器收到请求后，会从预设的配置中分配一套参数给客户端\r\n。\r\n\r\n最终, 主机可以实现“即插即联网” (Plug-and-Play\r\nNetworking)，极大地简化了网络管理和用户操作。这种自动化的方式解决了大规模网络和移动设备场景下网络参数配置的复杂性和易错性问题，是现代网络不可或缺的基础服务之一。\r\nDHCP 的工作流程\r\nDHCP 采用客户/服务器 (C/S) 模式工作 。用户主机上运行 DHCP\r\n客户进程，网络中至少有一台服务器运行 DHCP 服务器进程。在理解 DHCP\r\n的工作流程前，我们需要先理解 DHCP\r\n报文如何在网络中传输：\r\n\r\n应用层协议： DHCP 本身是就一个应用层协议。\r\n传输层： 它使用 UDP 作为传输层协议 。\r\n\r\nDHCP 服务器监听 UDP 的熟知端口号\r\n67 。\r\nDHCP 客户使用 UDP 的熟知端口号 68\r\n。\r\n\r\n封装过程：\r\n\r\nDHCP 报文（如 DHCP 发现报文）首先被封装成 UDP 用户数据报，包含源端口\r\n68 和目的端口 67 。\r\nUDP 用户数据报再被封装成 IP 数据报 。\r\nIP\r\n数据报最后根据网络接口类型（如以太网）封装成相应的数据链路层帧进行传输\r\n\r\n\r\n\r\nDHCP 的核心交互过程通常被称为\r\nDORA，代表四个主要报文：Discover,\r\nOffer, Request,\r\nAcknowledge。此外还包括租约的更新和释放过程。\r\n 场景假设：\r\n网络中有一台新主机（DHCP 客户）需要获取网络配置，同时有两台 DHCP\r\n服务器（服务器1 和 服务器2）可以提供服务。\r\n步骤 1：发现服务器 (DHCP DISCOVER)\r\n- 客户广播\r\n\r\n主机启动 DHCP 客户端后，它不知道网络中有哪些 DHCP\r\n服务器，也不知道它们的地址。因此，它会广播发送一个\r\nDHCP 发现报文 (DHCP DISCOVER) 。\r\n封装细节：\r\n\r\nUDP：源端口 68，目的端口 67 。\r\nIP：源 IP 地址为 0.0.0.0 (因为客户还没有\r\nIP)，目的 IP 地址为广播地址 255.255.255.255 。\r\nDHCP 报文内部：包含一个事务 ID (Transaction ID) 和客户的 MAC\r\n地址 。\r\n\r\n结果：网络中所有主机都会收到这个广播包，但只有\r\nDHCP 服务器会处理它。\r\n\r\n步骤 2：提供租约 (DHCP OFFER) -\r\n服务器响应\r\n\r\n收到 DISCOVER 报文的 DHCP\r\n服务器（假设服务器1和服务器2都收到了）会各自准备一个配置方案。\r\n服务器内部操作：查找数据库，看是否有为该 MAC\r\n地址预留的配置。如果没有，则从 IP\r\n地址池中挑选一个可用的 IP 地址 。\r\n\r\n服务器在提供 IP 地址前，会先使用 ARP 检查该 IP\r\n是否已被网络中其他主机占用 。\r\n\r\n发送报文： 每个服务器都发送一个 DHCP 提供报文\r\n(DHCP OFFER) 。\r\n封装细节：\r\n\r\nIP：源 IP 地址为服务器自身的 IP，目的 IP\r\n地址仍然是广播地址 255.255.255.255\r\n(因为客户此时可能还无法接收单播) 。\r\nDHCP 报文内部：包含提供的 IP\r\n地址、子网掩码、地址租期\r\n(Lease Time)、默认网关 IP、DNS 服务器\r\nIP 等配置信息，以及与 DISCOVER 报文匹配的事务\r\nID 。\r\n\r\n客户动作： 客户可能会收到多个 DHCPOFFER\r\n报文（来自服务器1和服务器2）。它会根据事务 ID\r\n确认是自己请求的响应，然后从中选择一个（通常选择最先到达的那个）。\r\n\r\n步骤 3：请求租约 (DHCP REQUEST) -\r\n客户广播\r\n\r\n客户选择好一个 OFFER 后（假设选择了服务器1的\r\nOFFER），需要向所有服务器确认这个选择，并正式请求使用该租约。它会广播发送一个\r\nDHCP 请求报文 (DHCP REQUEST) 。\r\n封装细节：\r\n\r\nIP：源 IP 地址仍为 0.0.0.0\r\n(因为租约尚未最终确认)，目的 IP 地址为广播地址\r\n255.255.255.255 。\r\nDHCP 报文内部：包含事务 ID、客户 MAC 地址、接收到的租约中的 IP\r\n地址、提供此租约的 DHCP 服务器的 IP 地址\r\n(明确告知选择了谁) 等信息 。\r\n\r\n结果：所有 DHCP 服务器都会收到这个 REQUEST。\r\n\r\n被选中的服务器（服务器1）知道客户接受了它的 OFFER。\r\n未被选中的服务器（服务器2）知道客户拒绝了它的\r\nOFFER，可以收回之前预留的 IP 地址。\r\n\r\n\r\n步骤 4：确认租约 (DHCP ACK) -\r\n服务器响应\r\n\r\n被选中的 DHCP 服务器（服务器1）发送 DHCP 确认报文 (DHCP\r\nACK) 来最终确认租约 。\r\n封装细节：\r\n\r\nIP：源 IP 为服务器1 的 IP，目的 IP 仍然可能是广播地址\r\n255.255.255.255 (取决于客户请求时的 BROADCAST 标志位，见后述)\r\n。\r\n\r\n客户动作：客户收到 DHCP ACK 后，租约正式生效。\r\n\r\n客户在使用这个 IP 地址之前，还会主动发送 ARP 请求，再次确认该 IP\r\n地址没有被网络中其他主机占用 。\r\n如果 ARP 检测到冲突，客户会向服务器发送\r\nDHCP 谢绝报文 (DHCP\r\nDECLINE)，并重新开始 DHCP 过程（发送 DISCOVER） 。\r\n如果 ARP\r\n未检测到冲突，客户就配置好所有网络参数，可以正常通信了。\r\n\r\n\r\nIP 地址租约的更新 (续约)\r\nDHCP 分配的 IP 地址通常有一个租用期限 (Lease\r\nTime)。客户端需要在租约到期前进行续约，否则将失去该 IP\r\n地址的使用权。\r\nT1 时间点 (租用期过半)：\r\n\r\n客户会单播向当初提供租约的 DHCP 服务器（服务器1）发送 DHCP\r\nREQUEST 报文请求续约。\r\n此时 IP 源地址是客户当前租用的 IP，目的 IP 是服务器1 的 IP\r\n。\r\n服务器响应：\r\n\r\n同意 (DHCP ACK)： 服务器回复 DHCP ACK，客户获得新的租期。\r\n不同意 (DHCP NACK)： 服务器回复 DHCP\r\nNACK。客户必须立即停止使用当前 IP，并重新开始\r\nDORA 过程（广播 DISCOVER） 。\r\n无响应：服务器可能宕机或网络不通 。\r\n\r\n\r\nT2 时间点 (租用期过了 87.5%)：\r\n\r\n如果在 T1 时服务器未响应，客户会等到租用期的 87.5% 时广播发送 DHCP\r\nREQUEST 报文，尝试向任何可达的 DHCP\r\n服务器续约。\r\n\r\n如果仍然没有服务器响应，则当租约最终到期后，客户必须立即停止使用该\r\nIP，并重新开始 DORA 过程。\r\n不过, 客户也可以随时提前终止租约（例如正常关机时）。\r\n\r\n报文： 客户向 DHCP 服务器发送 DHCP 释放报文 (DHCP\r\nRELEASE) 。\r\n封装： IP 源地址为 0.0.0.0，目的地址为广播地址 255.255.255.255\r\n。服务器收到后，可以将该 IP 地址回收并分配给其他客户。\r\n\r\n\r\n关于广播与单播响应的补充 (BROADCAST 标志位) 在 DHCP\r\n交互的早期阶段（客户还没有有效 IP 地址时），客户的\r\nTCP/IP 协议栈可能无法正确处理发送给它的单播 IP 数据报。\r\n解决方案是：DHCP 客户可以在发送 DISCOVER 和 REQUEST 报文时，设置一个\r\n“BROADCAST” 标志位 。 - 标志位 = 1：\r\n客户明确告知服务器：“请使用广播方式回复我（发送 OFFER\r\n和 ACK）” 。 - 标志位 = 0：\r\n客户告知服务器：“我能接收单播，请使用单播方式回复我”\r\n。此时，服务器会根据 DISCOVER/REQUEST 报文中客户提供的 MAC\r\n地址来发送单播帧 。\r\n这个机制增强了 DHCP 对不同 TCP/IP 协议栈实现的兼容性 。\r\n\r\nDHCP 中继代理\r\n我们知道, DHCP 客户在启动时发送的 DHCP DISCOVER\r\n报文是一个广播报文（目的 IP 地址为 255.255.255.255）。\r\n而路由器的一个基本工作原则就是隔离广播域，它们不会转发广播报文。\r\n假设 DHCP 客户（主机1, 主机n）位于一个子网，而 DHCP\r\n服务器位于另一个不同的子网，两者之间通过路由器连接。\r\n这会导致客户发送的广播 DHCP DISCOVER\r\n报文到达路由器时，会被路由器直接丢弃，永远无法到达位于另一个子网的 DHCP\r\n服务器。因此，这些客户将无法通过 DHCP 自动获取网络配置参数。\r\n为了解决广播报文不能跨越路由器的问题，引入了 DHCP\r\n中继代理 (DHCP Relay Agent) 的概念 。\r\n实现方式通常是在路由器上启用并配置 DHCP\r\n中继代理功能, 指向真正 DHCP 服务器的 IP\r\n地址。\r\n其工作过程如下:\r\n\r\n接收广播：\r\n启用了中继代理功能的路由器（位于客户子网）在其接口上收到来自 DHCP\r\n客户的广播 DHCP DISCOVER 报文。\r\n转换为单播：\r\n路由器（中继代理）不会丢弃这个广播报文。相反，它会将该报文重新封装成一个单播\r\nIP 数据报。\r\n这个单播报文的目的 IP 地址被设置为配置好的真正 DHCP\r\n服务器的 IP 地址, 源 IP\r\n地址通常是路由器接收到广播报文的那个接口的 IP\r\n地址（这样服务器就知道是哪个子网的请求）。\r\n单播转发： 路由器将这个单播报文转发给 DHCP 服务器 。\r\n服务器响应： DHCP 服务器处理这个请求（如同直接收到 DISCOVER\r\n一样），然后将 DHCP OFFER\r\n报文（或其他响应报文）单播发送回给中继代理（路由器）。\r\n中继转发给客户：\r\n中继代理收到服务器的响应后，再将其转发给最初发起请求的 DHCP\r\n客户（通常使用广播或根据客户 MAC 地址单播）。\r\n后续交互： DHCP 客户与服务器之间的后续报文（如 DHCP REQUEST, DHCP\r\nACK）都会通过这个中继代理进行转发。\r\n\r\n上述就是DHCP中继代理的工作过程,\r\n其主要优势在于实现了集中管理, 我们不必在每一个子网（或\r\nVLAN）上都部署一台 DHCP 服务器 。\r\n从而减少服务器数量：通过使用中继代理，可以在一个中心位置部署少量（甚至一台）DHCP\r\n服务器，来为整个网络（包含多个子网）提供服务。这极大地简化了 DHCP\r\n服务器的管理和维护工作 。\r\n域名系统(DNS)\r\n我们在上网时，更习惯使用域名 (Domain Name)\r\n来访问网站，例如 www.google.com 或 cnnic.net.cn\r\n。因为域名通常具有一定的含义，便于人们记忆 。\r\n然而，因特网上的路由器和主机在网络层进行寻址和通信时，并不直接使用域名，而是使用IP\r\n地址 (IP Address)（例如 42.83.144.13） 。IP\r\n地址是分配给网络接口的数字标识符，便于机器处理和路由。\r\n这就产生了一个矛盾——人类喜欢的易记域名与机器需要的数字 IP\r\n地址之间需要一个转换机制。\r\nDNS 的基本概念\r\n域名系统 (Domain Name System, DNS)\r\n的主要作用就是将域名解析（转换）为对应的 IP\r\n地址 。\r\n\r\nDNS\r\n就像是因特网的“电话簿”。你想找某个网站（知道它的域名，像人名），DNS\r\n就能帮你查到它的 IP\r\n地址（像电话号码），然后你的计算机才能真正连接到它。\r\n\r\n解析过程简化示意：\r\n\r\n用户在浏览器输入域名 cnnic.net.cn 。\r\n主机会先检查自己的本地 DNS\r\n缓存中是否有该域名的记录 。\r\n如果缓存中没有，主机会向配置好的 DNS\r\n服务器发送一个 DNS 查询请求：“cnnic.net.cn 对应的 IP\r\n地址是什么？” 。\r\nDNS 服务器在其域名数据库中查找，找到对应的 IP\r\n地址 42.83.144.13 。\r\nDNS 服务器将查询结果（IP 地址）返回给用户主机 。\r\n用户主机收到 IP 地址后，就可以使用这个 IP 地址与目标 Web\r\n服务器建立连接并访问网站了 。\r\n\r\n这里有一个问题: DNS 可以是单台服务器吗？这会面临以下的问题：\r\n\r\n单点故障与性能瓶颈： 理论上可以将所有域名和 IP\r\n地址的映射关系都存在一台巨大的 DNS 服务器上。但这在实践中是不可行的\r\n。\r\n可靠性差： 一旦这台服务器出现故障，整个因特网的域名解析服务就会瘫痪\r\n。\r\n性能瓶颈：\r\n全世界的域名查询请求都涌向一台服务器，它肯定会因超负荷而无法正常工作\r\n。\r\n距离延迟： 用户可能离这台服务器非常远，查询延迟会很高。\r\n\r\n因此, 一般来说, DNS 是分布式的系统, 由全球成千上万台\r\nDNS 服务器协同工作来完成域名解析任务。\r\n因特网自 1983\r\n年起就采用了层次结构的命名树（域名结构）和分布式的域名系统 。\r\n\r\n高可用性： 即使单个 DNS 服务器故障，也不会影响整个系统的运行 。\r\n高效率： 大多数域名解析可以在本地（或附近的）DNS\r\n服务器完成，只有少量解析需要跨网络通信 。\r\n负载均衡： 查询请求被分散到全球各地的不同服务器上。\r\n\r\n因特网的域名结构\r\n因特网采用了层次树状结构 (Hierarchical Tree\r\nStructure) 来组织域名 。\r\n结构组成: - 域名由若干个分量组成，分量之间用点. 隔开\r\n。 -\r\n最右边的分量级别最高，称为顶级域名\r\n(Top-Level Domain, TLD) 。 - 向左依次是二级域名 (Second-Level Domain,\r\nSLD)、三级域名，等等 。 -\r\n级别最低的域名（通常表示具体主机或服务）写在最左边\r\n。\r\n命名规则：\r\n\r\n每一级域名都由英文字母和数字组成 。\r\n每一级域名长度不超过 63 个字符 。\r\n不区分大小写字母 。\r\n完整的域名总长度不超过 255 个字符 。\r\n\r\n管理： -\r\n各级域名由其上一级的域名管理机构管理 。 -\r\n最高的顶级域名由 ICANN\r\n(因特网名称与数字地址分配机构) 进行管理 。\r\n域名示例：zuits.zju.edu.cn - .cn：顶级域名，表示中国\r\n。 - .edu：二级域名（在 .cn 下注册），表示教育机构 。 -\r\n.zju：三级域名（在 .edu.cn 下注册），表示浙江大学 。 -\r\nzuits：四级域名（由浙江大学自行管理），表示信息技术中心。\r\n顶级域名 (TLD) 的分类：\r\n\r\n国家顶级域名 (nTLD / ccTLD)： 采用\r\nISO 3166 的国家代码标准。例如：.cn (中国), .us (美国), .uk (英国), .jp\r\n(日本) 。\r\n\r\nnTLD\r\n下的二级域名由该国家自行确定规则（例如，日本用\r\n.ac 表示教育机构，.co 表示公司，而非 .edu 和 .com） 。\r\n\r\n通用顶级域名 (gTLD)：\r\n不具有国家属性。常见的有：.com (公司企业), .net (网络服务机构), .org\r\n(非营利性组织), .edu (美国教育机构), .gov (美国政府部门), .mil\r\n(美国军事部门), .int (国际组织) 。\r\n\r\n近年来新增了很多 gTLD，如 .app, .shop, .xyz 等。\r\n\r\n反向域 (Infrastructure\r\nTLD)：只有一个.arpa，用于反向域名解析（即从 IP\r\n地址查询对应的域名） 。\r\n\r\n中国域名体系： 我国在 .cn\r\n顶级域名下，将二级域名划分为两类 ：\r\n\r\n类别域名： .ac (科研), .com (工商金融), .edu\r\n(教育), .gov (政府), .net (网络服务), .mil (军事), .org (非营利) 。\r\n行政区域名： 34 个省、自治区、直辖市的缩写，如 .bj\r\n(北京), .sh (上海), .js (江苏) 。\r\n\r\n域名空间：整个因特网的域名结构可以看作一棵倒置的树。树根在最上方（没有名字），下面是\r\nTLD，再往下是二级、三级域名…\r\n叶节点通常对应具体的主机。\r\n这种按等级管理的命名方法便于维护域名的唯一性，也易于设计高效的查询机制\r\n。\r\n\r\n\r\nalt text\r\n\r\n\r\n重要提示：域名只是一个逻辑概念，它与计算机所在的物理地点没有必然联系。例如，.com\r\n域名的服务器不一定在美国。\r\n\r\n因特网的域名服务器\r\n为了实现分布式、层次化的域名系统，因特网上部署了不同类型的域名服务器，各司其职。主要有以下四种类型：\r\n根域名服务器 (Root DNS Server)\r\n\r\n层级： 位于 DNS 层次结构的最顶层（树根）。\r\n职责： 它不直接负责将域名解析为 IP\r\n地址。它的核心任务是管理所有顶级域名\r\n(TLD)，即它知道所有顶级域名服务器（如负责\r\n.com、.org、.cn 的服务器）的域名和 IP 地址。\r\n数量与分布： 全世界名义上只有 13 个不同 IP 地址的根域名服务器（用\r\nA 到 M\r\n命名）。但实际上，每个“根服务器”都是由分布在全球各地的许多服务器组成的集群，利用任播\r\n(Anycast)\r\n技术，使得用户的查询请求会被路由到地理上最近的一个根服务器实例。这大大提高了查询速度和系统的可靠性。\r\n工作方式： 当收到本地域名服务器的查询请求时（例如查询\r\nwww.google.com），根服务器会返回负责 .com 域的 TLD 服务器的 IP 地址列表\r\n。\r\n\r\n顶级域名服务器 (Top-Level Domain, TLD Server)\r\n\r\n层级： 位于根域名服务器之下。\r\n职责： 负责管理在其下注册的所有二级域名 。例如，.com TLD\r\n服务器管理着所有 .com 结尾的域名（如 google.com, example.com）。.cn TLD\r\n服务器管理着所有 .cn 结尾的域名。\r\n工作方式： 当收到本地域名服务器的查询请求时（例如查询\r\nwww.google.com），.com TLD 服务器会查找负责 google.com\r\n这个二级域名的权限域名服务器的 IP\r\n地址，并将其返回给本地域名服务器。\r\n\r\n权限域名服务器 (Authoritative DNS Server)\r\n\r\n层级： 位于 TLD 服务器之下（或更低层级）。\r\n职责： 这是真正存储着 “域名 ↔︎ IP 地址”\r\n权威映射关系的服务器。每个域名（例如\r\nwww.google.com）都必须在至少一个权限域名服务器处注册登记。\r\n工作方式：\r\n当收到本地域名服务器关于其管辖区域内某个域名的查询请求时（例如查询\r\nwww.google.com），google.com 的权限服务器会直接返回该域名对应的\r\nIP 地址\r\n。它还知道其下级域名服务器的地址（如果有的话）。\r\n\r\n本地域名服务器 (Local DNS Server) - 特殊性：\r\n它不属于上述的根 → TLD → 权限的层次结构 - 角色： 它是主机进行 DNS\r\n查询的“代理”或“第一跳”\r\n。当主机需要解析域名时，它首先将请求发送给本地域名服务器。\r\n- 来源： 通常由用户的因特网服务提供商\r\n(ISP)、大学、公司或机构提供。它离用户地理位置较近。 - 配置：\r\n本地域名服务器的 IP 地址需要手动或通过 DHCP 配置在用户主机的网络设置中。\r\n- 工作方式：\r\n收到主机的查询请求后，本地域名服务器会负责代替主机，在\r\nDNS\r\n层次结构中进行查询（通常是迭代查询，见下文），并将最终结果返回给主机。它还具有缓存功能。\r\n因特网的域名解析过程\r\n主机是如何通过本地域名服务器，并利用上述的服务器层次结构，最终找到域名对应的\r\nIP 地址的呢？主要有两种查询方式：\r\n递归查询 (Recursive Query) - 特点：\r\n“你帮我查到底”。查询责任层层委托。 - 过程： 1.\r\n主机向本地域名服务器发起递归查询：“请告诉我 y.abc.com 的 IP 地址”。 2.\r\n本地域名服务器接受委托，向根域名服务器发起递归查询。 3.\r\n根域名服务器接受委托，向 .com 顶级域名服务器发起递归查询。 4. .com\r\n顶级域名服务器接受委托，向 abc.com 的权限域名服务器发起递归查询。 5.\r\nabc.com 权限服务器知道 y.abc.com 的 IP 地址，将结果返回给 .com TLD\r\n服务器。 6. 结果沿着委托链逐级返回：.com TLD → 根 →\r\n本地域名服务器。 7. 本地域名服务器最终将 IP\r\n地址返回给主机。 - 缺点： 对被查询的服务器（尤其是根和 TLD\r\n服务器）负担过重。它们需要代替查询方去联系下一级服务器。\r\n\r\n迭代查询 (Iterative Query) - 特点：\r\n“我告诉你下一步该问谁”。查询方自己负责联系下一级服务器。\r\n- 过程： 1.\r\n主机向本地域名服务器发起递归查询（这一步通常还是递归）：“请告诉我\r\ny.abc.com 的 IP 地址”。 2.\r\n本地域名服务器开始迭代查询，向根域名服务器发起查询。 3.\r\n根域名服务器不进行委托，它回复：“我不知道，但你应该去问负责 .com 的 TLD\r\n服务器，它们的 IP 地址是 XXX”。 4. 本地域名服务器自己向 .com\r\n顶级域名服务器发起查询。.com TLD 服务器回复：“我不知道，但你应该去问负责\r\nabc.com 的权限服务器，它们的 IP 地址是 YYY”。 5. 本地域名服务器自己向\r\nabc.com 的权限域名服务器发起查询。abc.com 权限服务器回复：“y.abc.com 的\r\nIP 地址是 ZZZ”。 6. 本地域名服务器将最终结果 ZZZ 返回给主机。\r\n\r\n优点： 被查询的服务器（根、TLD）负担轻，只需返回下一级线索即可。\r\n\r\n\r\n实践中，通常采用混合模式： - 主机 →\r\n本地域名服务器使用递归查询（主机只管问，本地服务器负责搞定）。\r\n- 本地域名服务器 → 其他服务器 (根, TLD,\r\n权限)： 使用迭代查询（本地服务器自己跑腿，逐级询问）。\r\n传输协议：DNS 查询和响应报文通常使用 UDP\r\n协议进行封装，服务器监听熟知端口号 53。 &gt; 注：\r\n在某些特殊情况下（如响应报文过长超过 UDP 限制，或进行区域传送时），DNS\r\n也会使用 TCP 端口 53。\r\nDNS 缓存与生存时间 (TTL)\r\nDNS 查询（尤其是涉及根、TLD\r\n和权限服务器的迭代查询）可能需要多次网络往返，带来一定的延迟。为了优化这个过程，DNS\r\n系统广泛使用了高速缓存 (Cache) 。\r\n\r\n提高域名解析效率： 对于经常访问的域名，可以直接从缓存中获取 IP\r\n地址，大大缩短查询时间 。\r\n减轻上级服务器负荷： 特别是减轻根域名服务器和顶级域名服务器的压力\r\n。如果每个查询都要从根开始，它们将不堪重负。\r\n减少因特网上的 DNS 查询报文数量： 降低整体网络流量 。\r\n\r\nDNS 缓存用来存放最近查询过的域名以及与其对应的 IP\r\n地址映射关系。它还会记录是从哪个服务器获得该映射信息的\r\n。\r\n查询流程：\r\n\r\n当 DNS\r\n服务器（尤其是本地域名服务器）或用户主机收到一个域名解析请求时，它会首先检查自己的高速缓存\r\n。\r\n缓存命中 (Cache Hit):\r\n如果缓存中存在该域名的有效记录，则直接使用缓存中的 IP\r\n地址进行响应，无需再向其他 DNS 服务器发起查询。\r\n缓存未命中 (Cache Miss):\r\n如果缓存中没有该域名的记录，或者记录已过期，则按照标准的\r\nDNS 解析流程（递归/迭代查询）去获取 IP 地址\r\n。获取到结果后，将该映射关系存入缓存以备后续使用。\r\n\r\n不过, 域名到 IP 地址的映射关系并不是永久不变的\r\n（例如，服务器更换 IP\r\n地址）。如果缓存中的信息一直不更新，就可能导致用户访问到错误的\r\nIP 地址。\r\n这个问题的解决方案是生存时间 (Time-To-Live, TTL)\r\n为了保持缓存内容的正确性，DNS\r\n记录（由权限域名服务器提供）通常会包含一个生存时间 (TTL)\r\n值。\r\nDNS 服务器和主机在缓存某条记录时，也会记下它的 TTL 。缓存中的记录会在\r\nTTL 到期后被删除。\r\n这样，当下一次再查询该域名时，就会因为缓存未命中而重新向权限服务器获取最新的映射关系。\r\n\r\n实际 TTL\r\n由域名的管理者在权限服务器上配置，可以是几分钟到几天不等。\r\n\r\nDNS 缓存则存在于 DNS 解析路径的多个环节：\r\n\r\n用户主机： 操作系统通常会维护自己的 DNS 缓存\r\n。有些应用程序（如浏览器）也可能有自己的缓存。\r\n本地域名服务器：\r\n这是最主要的缓存地点，服务于大量用户，缓存命中率通常较高\r\n。\r\n中间 DNS 服务器： 在迭代查询过程中，根服务器、TLD\r\n服务器等也可能进行一定程度的缓存（主要是缓存下一级服务器的地址）。\r\n\r\n万维网 (WWW)\r\n首先, 万维网和我们之前提到的因特网, 以太网等概念不同, 万维网 (World\r\nWide Web, WWW)\r\n并非某种特殊的计算机网络，而是运行在因特网之上的一个分布式应用\r\n。\r\n它可以被看作是一个大规模的、联机式的信息储藏所。其核心机制是超链接\r\n(Hyperlink)：万维网通过网页之间的超链接，将分布在全球不同网站上的信息（网页）逻辑上连接成一张巨大的信息网。\r\n万维网的信息载体是网页（Web\r\nPage），它是通过HTML（超文本标记语言）编写的文档，通常包含文本、图像、视频等多媒体内容。用户可以通过浏览器访问这些网页，并通过超链接在不同网页之间导航。\r\n而说到浏览器,\r\n它是用户访问万维网的主要工具。浏览器通过HTTP（超文本传输协议）与托管网页的Web\r\n服务器进行通信，获取网页内容并呈现给用户。\r\n\r\n浏览器最重要的部分是渲染引擎，也称为浏览器内核。它负责解析网页内容（HTML,\r\nCSS, JavaScript 等）并将其显示 (渲染) 在屏幕上。\r\n不同浏览器使用不同的渲染引擎, 例如Chrome和Edge 使用\r\nBlink，Firefox 使用 Gecko，Safari 使用\r\nWebKit等。不同的浏览器内核对网页内容的解析可能存在差异，因此同一个网页在不同内核的浏览器中显示效果可能不同,\r\nWeb 开发者需要考虑跨浏览器兼容性 。\r\n\r\n万维网应用的基本交互过程: 1. 用户输入 URL：\r\n用户在浏览器地址栏输入网站的域名（例如 www.google.com） 。 2. DNS 解析：\r\n浏览器通过 DNS 服务器将域名解析为对应的 IP 地址 。 3. 浏览器发送请求：\r\n浏览器进程 (作为 HTTP 客户端)\r\n向目标万维网服务器发送 HTTP 请求报文。\r\n4. 服务器处理与响应： 万维网服务器进程 (作为 HTTP 服务器)\r\n收到请求后，执行相应操作（如查找文件），然后向浏览器发回\r\nHTTP 响应报文 。 5. 浏览器渲染：\r\n浏览器接收并解析响应报文中的内容（如 HTML\r\n文件），然后将其渲染成用户可见的网页 。\r\n这个看似简单的过程，实际上涉及了 TCP/IP\r\n体系结构中多个层次的协议协同工作，包括应用层的 HTTP, DHCP, DNS；传输层的\r\nTCP；网际层的 IP,\r\nARP；以及网络接口层的数据链路层协议。本章后续将重点介绍 HTTP。\r\n统一资源定位符 (URL)\r\n为了方便、统一地访问分布在世界范围内的各种文档或资源，万维网使用统一资源定位符\r\n(Uniform Resource Locator, URL) 来指明因特网上任何种类资源的位置。\r\nURL\r\n一般由四个部分组成：&lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;\r\n\r\n&lt;协议&gt; (Protocol)： 指明访问该资源所使用的协议。常见的有：\r\n\r\nhttp：超文本传输协议。\r\nhttps：安全的超文本传输协议。\r\nftp：文件传输协议。\r\nfile：本地文件系统。\r\n\r\n&lt;主机&gt; (Host)：\r\n指明存放资源的服务器。可以是域名或\r\nIP 地址。\r\n&lt;端口&gt; (Port)：\r\n指明服务器上监听请求的端口号。\r\n\r\n每个协议都有默认端口（例如 HTTP 默认 80 ，HTTPS 默认 443）。\r\n如果 URL 中省略了端口号，浏览器会自动使用该协议的默认端口。\r\n\r\n&lt;路径&gt; (Path)：\r\n指明资源在服务器上的具体位置（类似文件路径）。\r\n\r\n例如 /index.htm 指向根目录下的 index.htm 文件。\r\n服务器也是一台主机,\r\n上面也有自己的文件系统。资源路径就是指向该文件系统中的具体文件或目录。\r\n\r\n\r\n万维网文档\r\n当我们浏览网页时，浏览器实际上是从 Web\r\n服务器获取并解析、渲染一系列文档。这些文档共同构成了我们看到的丰富多彩、交互式的网页。万维网文档主要由以下三种核心技术（语言）组成\r\n：\r\n\r\nHTML (HyperText Markup Language) - 超文本标记语言\r\n\r\n\r\n核心作用： 定义网页的结构和内容 。\r\n如何工作： HTML 使用各种“标签” (Tag)\r\n来标记文本的不同部分，告诉浏览器这部分内容是什么。\r\n\r\n例如，&lt;p&gt;\r\n标签表示一个段落，&lt;h1&gt;\r\n标签表示一级标题，&lt;img&gt;\r\n标签表示一张图片，&lt;a&gt; 标签表示一个超链接。\r\n\r\n结构： 一个基本的 HTML 文档通常包含\r\n&lt;head&gt;（首部）和\r\n&lt;body&gt;（主体）两大部分 。\r\n\r\n&lt;head&gt; 部分包含元信息，如网页标题\r\n(&lt;title&gt;) 、引用的外部文件等。\r\n&lt;body&gt;\r\n部分包含用户实际看到的网页内容，如文本、图片、链接等 。\r\n\r\n本质： HTML 负责网页的骨架和原始素材。\r\n\r\n\r\nCSS (Cascading Style Sheets) - 层叠样式表\r\n\r\n\r\n核心作用： 描述网页的样式或外观（从审美的角度）。\r\n解决的问题： 纯 HTML\r\n只能定义结构，无法很好地控制内容的显示效果（如颜色、字体大小、布局等）。CSS\r\n的出现实现了内容与样式的分离。\r\n如何工作： CSS 定义规则 (Rule)，指定某个或某些 HTML\r\n元素应该如何显示。\r\n引入方式： CSS 规则可以写在 HTML\r\n文件内部（&lt;style&gt; 标签或 style\r\n属性），但更常见和推荐的方式是写在独立的 .css 文件中，然后在 HTML 文档的\r\n&lt;head&gt; 部分使用 &lt;link&gt;\r\n标签将其引入。\r\n本质： CSS 负责网页的“妆造”和“排版”。\r\n\r\n\r\nJavaScript (JS)\r\n\r\n\r\n核心作用： 控制网页的行为，实现交互功能 。\r\n解决的问题： HTML 和 CSS\r\n主要负责静态内容的展示。如果希望网页能够响应用户的操作（如点击按钮、输入内容）、动态地修改页面内容、与服务器进行异步通信等，就需要\r\nJavaScript。\r\n如何工作： JavaScript\r\n是一种脚本语言，可以在浏览器中运行。它可以：\r\n\r\n操作 HTML 元素： 改变元素的样式、内容、属性等。\r\n响应用户事件： 如鼠标点击、键盘输入、页面加载等。\r\n与服务器通信：\r\n在不刷新整个页面的情况下，向服务器发送请求并更新部分页面内容\r\n(AJAX)。\r\n\r\n引入方式： JavaScript 代码可以写在 HTML\r\n文件内部（&lt;script&gt;\r\n标签），但更常见和推荐的方式是写在独立的 .js 文件中，然后在 HTML 文档的\r\n&lt;head&gt; 或 &lt;body&gt; 末尾使用\r\n&lt;script src=\"...\"&gt; 标签将其引入 。\r\n本质： JavaScript 负责网页的“动作”和“智能”。\r\n\r\nHTML、CSS 和 JavaScript 是构建现代网页的三大基石\r\n。它们各自负责不同的层面：HTML 构建结构和内容，CSS\r\n美化样式和布局，JavaScript\r\n实现交互和动态行为。浏览器内核的工作就是将这三者结合起来，解析并渲染出用户最终看到的完整网页。这些文档（静态页面或由服务器后端程序动态生成）都需要通过\r\nHTTP 协议从服务器传输到用户的浏览器。\r\n超文本传输协议 (HTTP)\r\nHTTP 定义了浏览器 (Web 客户端) 如何向 Web\r\n服务器请求万维网文档（如 HTML, CSS, JS 文件,\r\n图片等），以及服务器如何将这些文档传送给浏览器 。\r\n基本流程：\r\n\r\n建立 TCP 连接： 浏览器进程（HTTP\r\n客户进程）首先需要与 Web 服务器进程（HTTP 服务器进程）建立一条 TCP 连接\r\n。Web 服务器通常监听熟知端口号 80 。\r\n发送 HTTP 请求报文： TCP\r\n连接建立后，浏览器通过该连接向服务器发送一个 HTTP 请求报文 。\r\n服务器处理请求： Web\r\n服务器收到请求报文后，执行相应的操作（如查找请求的文件）。\r\n发送 HTTP 响应报文： 服务器通过同一条 TCP\r\n连接向浏览器发回一个 HTTP 响应报文 。\r\n（可能）释放 TCP 连接： 根据 HTTP 版本的不同，TCP\r\n连接可能会在此之后关闭，也可能保持打开以供后续请求使用。\r\n\r\nHTTP 的连接方式\r\n非持续连接方式 (Non-Persistent Connection) -\r\nHTTP/1.0\r\n\r\n工作模式： 每次浏览器要请求一个文件（例如一个\r\nHTML 文件，或该 HTML 文件引用的一个图片），都需要与服务器建立一个新的\r\nTCP 连接 。当收到对该文件的响应后，TCP\r\n连接立即关闭。\r\n时间开销：\r\n\r\n建立 TCP 连接需要 1 个 RTT (往返时间)。\r\n发送 HTTP 请求并等待响应需要 1 个 RTT。\r\n因此，请求一个文档至少需要 2 RTT 的开销，再加上文档本身的传输时延\r\n。\r\n\r\n缺点： 如果一个网页包含多个对象（HTML 文件 + 10\r\n张图片），则需要建立 11 次 TCP 连接，产生 22 RTT\r\n的开销，效率非常低。虽然浏览器可以通过建立多个并行 TCP\r\n连接来缓解时延，但这会大量占用服务器资源 。  持续连接方式\r\n(Persistent Connection) - HTTP/1.1\r\n工作模式： 万维网服务器在发送响应后仍然保持\r\nTCP 连接打开\r\n。同一个客户（浏览器）和服务器可以在这条已建立的连接上继续传送后续的\r\nHTTP\r\n请求和响应报文。这不仅限于同一个页面上的对象，只要是访问同一个服务器上的资源即可\r\n。\r\n流水线 (Pipelining)： HTTP/1.1\r\n的持续连接还可以使用流水线方式进一步提高效率\r\n。浏览器可以在收到前一个响应之前，就连续发送多个\r\nHTTP 请求报文 。服务器收到这些请求后，再依次发回对应的响应报文\r\n。\r\n优点： 极大地减少了建立 TCP 连接所需的 RTT\r\n开销和服务器负担，提高了文档下载效率 。\r\n\r\nHTTP 的报文格式\r\nHTTP 是面向文本的协议，其报文中的每个字段都是 ASCII\r\n码串，并且字段长度不确定\r\n。报文由行组成，每行以回车换行 (CRLF)\r\n结束 。  HTTP\r\n请求报文 (Request Message) 由以下几部分组成：\r\n\r\n请求行 (Request Line)：方法 URL 版本 CRLF。\r\n\r\n方法 (Method)：指明对资源的操作，如\r\nGET, POST 等 。\r\nURL：请求的资源标识符, 简写形式（不含协议和主机部分）即可，如\r\n/index.htm 。\r\n版本 (Version)：使用的 HTTP 版本，如 HTTP/1.1 。\r\n\r\n首部行 (Header Lines)：\r\n首部字段名: 值 CRLF。可以有零个或多个,\r\n用于传递附加信息，例如，告知服务器浏览器类型、请求的主机名、连接方式等\r\n。\r\n空行 (Empty Line)： 一个 CRLF 。标志着首部行的结束。\r\n实体主体 (Entity Body)： 实际要传输的数据（例如 POST\r\n方法提交的表单数据）。对于 GET 请求，通常不用 。\r\n\r\n 请求行示例：\r\nGET /index.htm HTTP/1.1。 首部行示例：\r\n\r\nHost: www.hnust.cn：指明请求的服务器域名。\r\nConnection: close：告知服务器发送响应后关闭 TCP\r\n连接（非持续连接）。\r\nUser-Agent: Mozilla/5.0：告知服务器浏览器的类型和版本。\r\nAccept-Language: cn：告知服务器用户希望优先接收中文版本的文档。\r\n\r\n请求行的常见方法： - GET：请求获取 URL 标识的资源。 -\r\nHEAD：请求资源的首部信息（与 GET 类似，但响应中没有主体）。 -\r\nPOST：向服务器提交数据（如表单）。 - PUT：在指定 URL\r\n处存储一个文档（上传）。 - DELETE：删除 URL 标识的资源。\r\n HTTP\r\n响应报文 (Response Message) 的格式如下：\r\n\r\n状态行 (Status Line)： 版本 状态码 短语 CRLF 。\r\n\r\n版本 (Version)：HTTP 版本，如 HTTP/1.1 。\r\n状态码 (Status Code)：三位数字，表示请求处理的结果。常见状态码包括：\r\n\r\n200：请求成功。\r\n301：资源永久移动（重定向）。\r\n404：未找到资源。\r\n500：服务器内部错误。\r\n\r\n短语 (Reason Phrase)：对状态码的简短文本描述。\r\n\r\n首部行 (Header Lines)： 与请求报文类似，首部字段名: 值 CRLF\r\n。\r\n空行 (Empty Line)： 一个 CRLF 。\r\n实体主体 (Entity Body)： 实际返回的资源内容（如 HTML\r\n文档、图片数据）。有些响应（如 HEAD\r\n请求的响应，或某些错误响应）可能没有主体 。\r\n\r\n状态码分类： - 1xx：信息性，表示请求已接收，继续处理 。 -\r\n2xx：成功，表示请求已被成功接收、理解、接受 。如 200 OK, 202 Accepted。\r\n- 3xx：重定向，需要后续操作才能完成请求 。如 301 Moved Permanently, 304\r\nNot Modified。 - 4xx：客户端错误，表示请求包含语法错误或无法完成 。如\r\n400 Bad Request, 404 Not Found。 -\r\n5xx：服务器错误，表示服务器在处理请求的过程中发生了错误 。如 500\r\nInternal Server Error, 503 Service Unavailable。\r\n下面是一些状态行示例： -\r\nHTTP/1.1 202 Accepted：请求已被接受 。 -\r\nHTTP/1.1 400 Bad Request：请求有语法错误 。 -\r\nHTTP/1.1 404 Not Found：服务器找不到请求的资源 。 -\r\nHTTP/1.1 500 Internal Server Error：服务器内部错误 。 -\r\nHTTP/1.1 503 Service Unavailable：服务不可用 。\r\n不过,\r\n浏览器通常不会直接显示状态码，而是以更友好的方式（如特定的错误页面）告知用户。例如，看到“找不到页面”通常对应\r\n404 状态码 。\r\nHTTPS\r\nHTTPS (HyperText Transfer Protocol Secure) 是 HTTP\r\n的安全版本，它通过在 HTTP\r\n之上添加一层加密机制来保护数据传输的安全性。 HTTPS 使用\r\nSSL/TLS (安全套接字层/传输层安全协议)\r\n来实现加密和身份验证。\r\nHTTPS 的TLS 握手过程大致如下： 1. 客户端发起连接： 浏览器向服务器发起\r\nHTTPS 连接请求。 2. 服务器响应并发送证书：\r\n服务器返回其数字证书，包含公钥和身份信息。 3. 客户端验证证书：\r\n浏览器验证服务器证书的合法性（如是否由受信任的 CA 签发，是否过期等）。\r\n4. 生成会话密钥：\r\n浏览器生成一个随机的对称加密密钥，并使用服务器的公钥对其加密后发送给服务器。\r\n5. 服务器解密会话密钥： 服务器使用其私钥解密，获得对称加密密钥。 6.\r\n加密通信开始：\r\n双方使用该对称密钥进行加密通信，确保数据在传输过程中不被窃听或篡改。 7.\r\n连接关闭： 通信结束后，双方关闭连接。\r\n使用 Cookie\r\n在服务器上记录信息\r\n早期的万维网应用主要是用户查看存放在不同服务器上的静态文档。为了简化服务器的设计，HTTP\r\n被设计成一种无状态 (Stateless) 协议 。\r\n服务器不保存关于过去客户端请求的任何信息。每个 HTTP\r\n请求都被视为一个独立的事务，与之前的任何请求都没有关联。服务器处理完请求并发回响应后，就“忘记”了这个客户端。\r\n但是随着万维网的发展，出现了网上购物、电子商务、社交网络等需要识别用户身份并保持用户状态的应用\r\n。例如购物网站需要记住用户的购物车内容, 社交网站需要记住用户的登录状态,\r\n新闻网站需要根据用户的偏好推送内容。\r\n如果 HTTP\r\n完全无状态，用户每次点击页面或刷新，服务器都会“忘记”他是谁，导致无法实现这些功能（例如，购物车每次都会被清空）。\r\n上述问题的解决方案就是 Cookie - 为无状态的\r\nHTTP 增加状态\r\nCookie 提供了一种机制，使得 Web\r\n服务器能够“记住”（识别）用户，而无需用户在每个请求中都主动提供身份信息（如反复输入用户名密码）\r\n。\r\n本质： Cookie 是一种对无状态的 HTTP 进行状态化\r\n(Stateful) 的技术\r\n。它允许服务器在客户端（浏览器）存储少量信息，并在后续请求中取回这些信息。\r\n基本工作原理\r\nCookie 的工作涉及浏览器和服务器之间的一系列交互： 1.\r\n首次请求 (浏览器 →\r\n服务器)：当用户的浏览器第一次访问某个 Web\r\n服务器时，它发送一个普通的 HTTP 请求报文。 2.\r\n服务器生成 Cookie 并创建记录 (服务器端)：Web\r\n服务器收到请求后，意识到这是一个新用户（请求中没有携带\r\nCookie 信息）。服务器为该用户（浏览器）生成一个唯一的\r\nCookie 识别码 (Cookie ID)。服务器以此 Cookie ID\r\n作为索引，在其后端数据库中创建一个条目，用来记录该用户访问该网站的各种信息（例如登录状态、购物车内容、偏好设置等）。\r\n3. 服务器发送 Cookie (服务器 → 浏览器)：服务器在发回给浏览器的\r\nHTTP\r\n响应报文中，添加一个特殊的首部行：Set-Cookie: xxx，其值就是刚刚生成的那个唯一的\r\nCookie ID (例如 Set-Cookie: 12345678)。 4. 浏览器存储\r\nCookie (浏览器端)：浏览器收到带有 Set-Cookie:\r\n首部的响应后，会解析出服务器的域名和 Cookie\r\nID。浏览器将这对信息（服务器域名, Cookie\r\nID）存储在本地一个特定的 Cookie\r\n文件或内存中。 5. 后续请求 (浏览器 →\r\n服务器)：当用户再次使用该浏览器访问同一个网站（域名相同）时。浏览器在发送\r\nHTTP 请求报文之前，会自动检查本地 Cookie\r\n文件。它会找到之前存储的、与该域名对应的 Cookie ID (例如\r\n12345678)。浏览器将这个 Cookie ID\r\n放入请求报文的一个首部行：Cookie: xxx\r\n中发送给服务器 (例如 Cookie: 12345678)。 6.\r\n服务器识别用户 (服务器端)：Web 服务器收到带有 Cookie:\r\n首部的请求后，提取出其中的 Cookie ID。服务器使用这个\r\nCookie ID 在其后端数据库中查找对应的记录。 7.\r\n服务器返回个性化内容 (服务器 →\r\n浏览器)：通过 Cookie ID\r\n识别出用户后，服务器就可以获取该用户的状态信息（如登录状态、购物车内容等）。服务器据此生成并返回一个个性化的网页给用户。例如，显示“欢迎回来，用户名！”或展示用户上次加入购物车的商品。\r\n 例如,\r\n当用户在某些网页登录时勾选了“记住我” ，服务器可能会在\r\nSet-Cookie: xxx 响应中为这个 Cookie\r\n设置一个较长的过期时间。这样，即使用户关闭了浏览器甚至重启了电脑，只要\r\nCookie 文件中的记录没过期，下次访问该网站时浏览器仍会自动发送该\r\nCookie，服务器就能识别用户，实现自动登录。\r\n万维网缓存与代理服务器\r\n为了提高万维网 (WWW) 的访问效率，减少网络流量和用户感受到的延迟，Web\r\n系统广泛使用了缓存 (Caching) 机制,\r\n这主要体现在两个方面：\r\n\r\nWeb 缓存 (Web Cache)：\r\n\r\n是一种存储最近访问过的 Web 对象（如 HTML\r\n页面、图片、CSS 文件等）副本的机制 。\r\n位置：\r\n可以位于客户端（例如浏览器自己的缓存），也可以位于网络中的中间系统。\r\n\r\n代理服务器 (Proxy Server)：\r\n\r\n位于中间系统上的 Web\r\n缓存，通常服务于一个机构（如校园网、企业网）内的多个用户\r\n。\r\n作用： 充当用户（浏览器）和原始 Web 服务器之间的中介。\r\n\r\n\r\nWeb 缓存的基本工作原理\r\nWeb 缓存（无论是浏览器缓存还是代理服务器）会把最近的一些 HTTP\r\n请求及其对应的响应（包含 Web\r\n对象）暂存在本地存储（如磁盘）中 。\r\n当一个新的 HTTP 请求到达时（例如，浏览器请求一个图片）：\r\n\r\n浏览器缓存： 浏览器首先检查自己的缓存。\r\n代理服务器：\r\n如果浏览器未缓存或配置了使用代理，请求会发往代理服务器，代理服务器检查自己的缓存。\r\n\r\n此时有两种可能的情况： - 缓存命中 (Cache Hit)：\r\n如果缓存中存在所请求对象的有效副本，缓存（浏览器或代理）就直接将这个副本返回给请求者，无需再向原始\r\nWeb 服务器发起请求 。 - 缓存未命中 (Cache Miss)：\r\n如果缓存中没有所请求对象的副本，或者副本已失效（见下文），缓存服务器（代理）则会代表请求者，向原始\r\nWeb\r\n服务器发起请求，获取该对象。获取到对象后，先将其存入自己的缓存，然后再返回给最初的请求者。\r\n\r\n浏览器缓存和代理服务器缓存有点类似一级缓存和二级缓存的关系。浏览器缓存是用户本地的一级缓存，代理服务器缓存是网络中的二级缓存。\r\n\r\n\r\n\r\nalt text\r\n\r\n缓存一致性问题\r\nWeb 缓存的一个重要挑战是缓存一致性 (Cache\r\nConsistency)\r\n问题：如果原始服务器上的文档已经被修改了，但代理服务器（或浏览器）缓存中的副本还是旧版本，用户获取到的将是过期的信息。如何确保缓存副本与原始文档保持一致？\r\n解决方案是 HTTP 缓存验证机制. HTTP\r\n协议通过特定的首部字段来处理缓存一致性问题：\r\n原始服务器在响应中通常会包含：\r\n\r\nLast-Modified：资源最后修改的时间 。\r\nExpires：资源的过期时间（在此时间前，缓存可认为副本是新鲜的）\r\n。\r\nETag：资源的实体标签，用于标识特定版本的资源。\r\nCache-Control：指示缓存机制的指令。\r\n\r\n缓存验证流程：\r\n\r\n检查本地副本新鲜度：\r\n当代理服务器收到请求时，先检查缓存中是否有该对象的副本。\r\n\r\n副本未过期： 如果副本存在且根据 Expires\r\n字段判断未过期，则直接返回缓存副本给主机 。\r\n副本已过期 (或无 Expires 信息)：\r\n如果副本已过期或没有过期信息，代理服务器不能直接返回副本，需要向原始服务器验证\r\n。\r\n\r\n发送条件 GET 请求 (Conditional GET)：\r\n代理服务器向原始服务器发送一个特殊的 GET 请求，其中包含一个首部行\r\nIf-Modified-Since:，其值就是缓存副本的 Last-Modified 时间\r\n。这个请求的意思是：“请把这个资源发给我，但前提是它在 XXX\r\n时间之后被修改过”。\r\n原始服务器响应：\r\n\r\n未修改 (图 6-51b)： 如果原始服务器发现资源自 If-Modified-Since:\r\n指定的时间以来没有被修改过，它就不会发送整个资源内容，而是返回一个状态码为\r\n304 Not Modified 的响应报文（该响应没有实体主体） 。\r\n已修改 (图 6-51c)：\r\n如果资源已经被修改，原始服务器会返回一个正常的 200 OK\r\n响应，其中包含更新后的资源内容以及新的 Last-Modified 和\r\nExpires（或其他缓存控制）头 。\r\n\r\n代理服务器处理响应：\r\n\r\n收到 304：\r\n代理服务器知道缓存中的副本仍然是有效的。它会更新副本的元数据（如新的\r\nExpires 时间），然后将缓存中的副本返回给主机 。\r\n收到 200：\r\n代理服务器用响应中的新内容更新本地缓存的副本及其元数据，然后将新内容返回给主机\r\n。 \r\n\r\n\r\n通过这种条件 GET\r\n机制，即使缓存副本过期需要验证，如果资源并未实际更改，也可以避免传输整个资源内容，只需传输一个简短的\r\n304 响应即可，仍然节省了带宽。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"数据链路层","url":"/2025/09/16/web/Computer%20Network/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/4.%20%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/","content":"数据链路层的主要功能是让帧在物理介质上可靠地传输。它位于物理层之上，网络层之下，负责将网络层传下来的数据包封装成帧，并处理帧的传输、差错检测和流量控制等问题。\r\n它使用的通信信道主要有两种:\r\n\r\n点对点信道 (Point-to-Point\r\nChannel)：通信双方通过专用的物理链路直接连接，数据在两点之间一对一传输。例如，串行通信、PPP协议等。\r\n广播信道 (Broadcast\r\nChannel)：多个设备共享同一物理链路，数据可以被所有连接到该链路的设备接收。例如，以太网(采用CSMA/CD协议)、Wi-Fi(采用CSMA/CA协议)等。\r\n\r\n数据链路层的主要功能\r\n数据链路层所处的地位\r\n数据链路层位于OSI模型的第二层，介于物理层和网络层之间。\r\n对下：它接收物理层提供的原始比特流服务，并需要处理这些比特流中可能出现的传输错误。\r\n对上：它向网络层提供服务，其主要作用是将源自网络层的数据包（Packet）可靠地传输到相邻节点的目标网络层。它对网络层隐藏了物理传输中的各种复杂细节和错误。\r\n链路管理 (Link Management)\r\n指的是在两个节点之间建立、维持和释放数据链路的过程。这主要用于点对点的连接。\r\n\r\n链路建立：通信双方通过“握手”确认彼此的状态，准备好进行数据传输。\r\n数据传输：在已建立的链路上交换数据。\r\n链路释放：通信结束后，有序地断开连接，释放资源。\r\n\r\n在像以太网这样的广播网络中，链路管理通常是自动且隐含的，但在广域网协议中，这是一个非常明确的步骤。\r\n封装成帧与透明传输\r\n物理层传输的是一长串没有明显边界的比特流。为了让接收方能够区分数据的起点和终点，数据链路层必须将网络层传下来的数据包添加首部（Header）和尾部（Trailer），将它们封装成一个独立的、可识别的数据单元，这个单元就是帧\r\n(Frame)。\r\n接收方可以通过帧的头部和尾部来准确地确定一帧的开始和结束,\r\n帧头通常包含源和目标的物理地址（MAC地址）等控制信息；帧尾通常包含用于差错校验的字段。\r\n而现在还有一个问题:\r\n如果在帧的数据部分（即网络层的数据包）中，恰好出现了与帧尾定界符完全相同的比特组合，接收方就会错误地认为帧已经结束，导致数据解析错误。\r\n透明传输指的是，无论上层交付什么样的数据，数据链路层都有办法将其封装并成功传输，即使数据中包含了与控制信息（如帧定界符）相同的比特模式。\r\n上述问题的解决方法是, 通过字符填充 (Character Stuffing) 或 比特填充\r\n(Bit Stuffing) 技术来实现。\r\n例如, 以比特填充为例, 假设使用 01111110 作为帧的起始和结束标志。\r\n发送方：在发送数据时，会扫描整个数据部分。一旦发现有连续的5个“1”，就立即在其后填充一个“0”。\r\n接收方：在接收数据时，同样扫描数据。一旦发现连续的5个“1”，就检查其后的比特。\r\n- 如果第6个比特是“0”，就将其删除，恢复原始数据。 -\r\n如果第6个比特是“1”（即组成了01111110），则判断这是一个帧定界符。 -\r\n通过这种方式，确保了数据内部永远不会出现与帧定界符相同的模式，实现了透明传输。\r\n流量控制 (Flow Control)\r\n指的是协调发送方和接收方的速率，防止发送速率过快而导致接收方来不及处理，造成数据丢失。\r\n流量控制是一种点对点的控制，确保发送方只在接收方确认有能力接收时才发送数据。\r\n\r\n拥塞控制:\r\n关注的是整个网络宏观上的负载，防止网络因数据过多而瘫痪，这通常是传输层（如TCP）的职责。\r\n\r\n常见的方法有：停止-等待协议、滑动窗口协议（如后退N帧协议、选择重传协议）\r\n差错检测 (Error Detection)\r\n物理链路并非绝对可靠，信号在传输过程中可能会因为噪声等因素产生差错（比特翻转，即0变1或1变0）。差错检测就是让接收方有能力发现收到的数据帧是否在传输中出现了错误。\r\n核心思想是：在发送数据时，根据原始数据计算出一个校验码\r\n(Check\r\nCode)，并将其附加在帧的尾部一起发送。接收方收到后，用同样的方法对数据部分进行计算，比较计算结果和收到的校验码是否一致。\r\n目前使用最广泛的差错检测方法是循环冗余校验 (CRC, Cyclic Redundancy\r\nCheck)。\r\n组帧(Framing)\r\n组帧是数据链路层的基本任务之一。其核心目标是在一连串的比特流中，准确地标识出“帧”的开始和结束，以便接收方能够完整地提取出每一个数据单元。这个过程也称为帧同步。以下是四种经典的组帧方法。\r\n字符/字节计数法\r\n(Character/Byte Count)\r\n这是一种概念上最简单的方法。它在帧的头部设置一个计数字段，用以标明该帧总共包含的字符（或字节）数。\r\n\r\n发送方：在帧首部的计数字段填入该帧的长度（例如，长度为5）。\r\n接收方：首先读取计数字段的值（读到5），然后向后数出对应数量（5个）的字符，这就构成了一个完整的帧。读取完毕后，它就知道下一字节将是下一个新帧的计数字段。\r\n\r\n5 | A | B | C | D | E | 7 | F | G | H | I | J |\r\nK | ↑ 计数字段 ↑ 计数字段\r\n致命缺点：可靠性极差。如果在传输过程中，计数字段的某一位发生了错误（例如，5（二进制00000101）因为噪声变成了7（00000111）），接收方就会错误地读取7个字符。这将导致接收方对后续所有帧的边界判断都发生错误，造成灾难性的失步，且难以恢复。因此，这种方法如今已基本不被使用。\r\n字节填充法 (Byte Stuffing)\r\n使用特定的字符（字节）作为帧的起始和结束定界符，通常称为标志字节\r\n(Flag Byte)。例如，在PPP协议中，标志字节是 01111110（十六进制为\r\n0x7E）。\r\n这种方法容易出现的是透明传输问题：如果帧的数据部分恰好也出现了与标志字节相同的内容，就会造成混淆。解决方法同样是填充：\r\n\r\n发送方：在发送前扫描整个数据部分。\r\n如果数据中出现标志字节\r\n(0x7E)，就在其前面插入一个转义字节 (0x7D)。\r\n如果数据中出现转义字节\r\n(0x7D)，同样在其前面再插入一个转义字节。\r\n接收方：在接收时进行反向操作。当读到转义字节时，就删除这个转义字节，并将其后面的字节当作普通数据接收（无论它是什么）。当读到非转义字节的标志字节时，就认为是帧的边界。\r\n\r\n示例：原始数据: A | 0x7D | 0x7E | B\r\n填充后发送: FLAG | A | 0x7D | 0x7D | 0x7D | 0x7E | B | FLAG\r\n优点：比字符计数法可靠得多，解决了透明传输问题。\r\n缺点：依赖于以8位字节为单位的数据，不适用于非字符编码的数据流。\r\n零比特填充法 (Zero-Bit\r\nStuffing)\r\n这是目前应用最广泛的组帧方法，它同样使用一个特定的比特模式作为帧定界符，即标志字段\r\n01111110。只不过透明传输解决方法有所不同：\r\n\r\n发送方：在硬件层面扫描整个数据比特流（除标志字段外）。只要发现连续的5个“1”，就立即在后面强制插入一个“0”。\r\n接收方：同样在硬件层面扫描。只要发现连续的5个“1”，就检查其后的第6个比特。\r\n\r\n如果第6个比特是“0”，则说明这是一个填充位，必须将其删除以还原原始数据。\r\n如果第6个比特是“1”，则说明这是一个标志字段（结合其后的“0”，构成了\r\n…1111110），表示帧的边界。\r\n\r\n\r\n示例： - 原始数据: …01111110… - 填充后发送: …011111010…\r\n优点：\r\n高效：由硬件执行，速度非常快。\r\n通用：完全不依赖于数据是否为8位字节的整数倍，可以处理任意长度的比特流。\r\n应用：被广泛用于HDLC、SDLC、USB等多种协议中。\r\n违规编码法\r\n(Physical Layer Coding Violations)\r\n这是一种巧妙利用物理层编码冗余性的方法。在某些物理层编码方案中，并非所有信号模式都对应有效的数据。这些“无效”或“违规”的信号模式就可以被借用来定义帧的边界。\r\n示例（以曼彻斯特编码为例）： -\r\n有效编码：在曼彻斯特编码中，每个比特的中间时刻都必须有一次电平跳变（高→低\r\n或 低→高）。 -\r\n违规编码：我们可以定义“连续高电平”和“连续低电平”这种没有中间跳变的信号模式作为帧的起始（Start）和结束（End）定界符。\r\n当接收方检测到这种“违规”信号时，就知道这是一个帧边界，而不是数据。\r\n优点：不需要任何填充，不增加数据载荷，实现了带外（out-of-band）的信令，效率很高,\r\n但是不通用。\r\n应用：常用于令牌环网和一些局域网技术中。\r\n差错控制 (Error Control)\r\n差错控制是数据链路层的核心职责之一。它不仅包括我们之前提到的差错检测，还包括检测到错误后应采取的纠正措施。一个完整的差错控制机制，就是一套发现并解决数据传输错误的方法论。\r\n通常，差错控制的实现策略主要有两种：\r\n自动重传请求 (ARQ - Automatic\r\nRepeat reQuest)\r\n策略：接收方检测到错误后，直接丢弃这个错误的帧，然后通过一个反馈机制（如发送一个否认信息NAK，或不发送确认信息ACK）通知发送方，要求其重新发送该帧。\r\n特点：这种策略实现相对简单，额外开销小。它依赖于检错编码来发现错误。这是目前有线网络（如以太网）中最主流的策略。\r\n前向纠错 (FEC - Forward Error\r\nCorrection)\r\n策略：接收方不仅能检测到错误，还能根据编码中包含的冗余信息，直接确定错误的位置并加以纠正，无需发送方重传。\r\n特点：这种策略实现复杂，冗余信息开销大。它依赖于纠错编码。常用于实时性要求高或单向通信（如广播）以及信道质量差、重传代价高的场景（如无线通信、卫星通信）。\r\n检错编码 (Error-Detecting\r\nCodes)\r\n检错编码的目标是让接收方有能力判断收到的数据是否在传输过程中发生了改变，但不能确定错误的位置。\r\n核心思想：在原始数据 k 位的后面，附加 r\r\n位的冗余信息（校验码），构成一个 n=k+r 位的码字进行传输。这 r\r\n位的冗余信息是根据 k\r\n位的数据通过某种算法计算得出的。\r\n奇偶校验码 (Parity Code)\r\n是最简单的检错码。通过增加1位校验位，使得整个码字中“1”的个数为奇数或偶数。它只能检测出奇数个比特的错误，对于偶数个比特的错误则无能为力。\r\n\r\n奇检验码: 加入一位校验位，使得整个码字中“1”的个数为奇数。\r\n偶检验码: 加入一位校验位，使得整个码字中“1”的个数为偶数。\r\n\r\n循环冗余码 (CRC -\r\nCyclic Redundancy Check)\r\n这是目前应用最广泛的检错码。它利用生成多项式和模2除法，可以生成检错能力极强的校验码，尤其擅长检测计算机网络中常见的突发错误（即连续多个比特出错）。\r\n其核心思想可以概括为：在 k 位的原始数据后面，附加\r\nr 位的校验码（也称为 帧检验序列 FCS,\r\nFrame Check Sequence），构成一个总长为 n=k+r\r\n位的帧。这个构造过程有一个精巧的数学保证：最终生成的这个 n\r\n位帧，作为一个二进制数，一定能被一个预先选定的、长度为\r\nr+1 位的特定二进制数“整除”。\r\n接收方收到帧后，只需用这个约定的“除数”去除以收到的帧。如果余数为零，则认为数据正确；如果余数不为零，则说明数据在传输中已损坏。\r\n下面以一个具体的例子来说明CRC的编码和检验过程：假设数据 M = 101001,\r\n生成多项式(除数)G = 1101, 此时 r = 3 (G的位数-1)\r\n\r\n编码过程\r\n\r\n在数据 M 后面添加 r 个0，得到 M’ = 101001000\r\n用 M’ 除以 G，得到余数 R\r\n(这里的除法是模2除法，即不考虑进位的二进制除法,\r\n也可以看作是按位异或操作, 只要位数够就一直做异或)           1101001101 ) 101001000       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             001 (余数, 要保留r位, 因此还要考虑前面的0)\r\n\r\n附加校验码\r\n\r\n将余数 R = 001 附加在 M 的后面，得到最终的码字 C = 101001001\r\n\r\n检验过程\r\n\r\n接收方收到码字 C’ = 101001001 后，用 G 除以\r\nC’，如果余数为0，则数据正确；否则数据有误。           1101001101 ) 101001001       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             000 (余数为0, 数据正确)\r\n假如在传输过程中, 第3位(从左向右)发生了错误, 接收方收到的码字变为 C’ =\r\n101101001, 此时再用 G 除以 C’:           1101001101 ) 101101001       1101       ----        1110        1101        ----          1110          1101          ----            1100            1101            ----             101 (余数不为0, 数据有误)\r\n\r\n\r\n纠错编码 (Error-Correcting\r\nCodes)\r\n纠错编码不仅能发现错误，还能定位错误并自动修复。\r\n核心思想是：通过增加更多的冗余位，使得码字中任意两个有效码字之间存在足够的“差异”。即使某个码字在传输中发生了少量错误，它在“形态”上依然离原始的正确码字“最近”，而离其他的有效码字“很远”，从而让接收方可以推断出原始的正确码字。\r\n在介绍具体的纠错码之前，我们需要了解一个重要概念：海明距离 (Hamming\r\nDistance)或者码距(Distance)。\r\n它的定义是指两个等长码字之间，对应位置上比特不同的位数。例如，10101\r\n和 10011 之间的海明距离是2（第三位和第四位不同）,\r\n这可以通过异或操作实现。在一个编码集中,\r\n编码级的海明距离是指该编码方案中，任意两个有效码字之间海明距离的最小值。\r\n根据纠错理论, 海明距离的大小直接决定了该编码的检错和纠错能力： -\r\n编码方案的纠错能力(c), 检错能力(d)和码距(l)的关系: l = d + c + 1, 其中\r\nd&gt;=c (能纠错必然能检错) - 若要检测 d\r\n个比特的错误，则编码的海明距离(l)至少需要为 d+1。(c=0的边界情况) -\r\n若要纠正 t 个比特的错误，则编码的海明距离(l)至少需要为\r\n2t+1。(d=t的边界情况)\r\n\r\n例如, 当海明距离为 2t+1 时，如果一个码字发生了 t\r\n位错误，它会变成一个无效码字。但这个无效码字与原始正确码字的海明距离为\r\nt，而与其他任何一个正确码字的海明距离都至少为\r\nt+1。因此，接收方可以通过“选择最近的有效码字”的原则，成功纠正错误。\r\n\r\n一个典型的例子是海明码 (Hamming Code),\r\n它是设计最精巧的纠错编码之一，它不仅能发现错误，还能精确定位单个比特的错误位置。通过设置多个校验位，并且让每个校验位都对一组不同的数据位进行校验。这样，当某个数据位出错时，会同时导致多个校验位的值发生变化。通过观察是哪些校验位“不匹配”，就可以像查字典一样反推出是哪一位数据出错了。\r\n海明码的码距至少为3，因此它能够纠正单个比特错误或检测双比特错误。\r\n公式为: 若信息位有k位, 设需要r位校验位, 则需满足 2r &gt;= k + r +\r\n1.\r\n编码过程示例（以数据1010为例）：\r\n\r\n确定海明码的位数 若信息位有k位, 设需要r位校验位,\r\nr位校验位可以表示2r种状态, 且总位数为k+r,\r\n单个比特位出错的情况有k+r种, 再加上一种正确状态, 则需满足 2r &gt;= k + r +\r\n1, 代入k=4, 可得r=3, 则总位数n=7 则海明码的位数为7位,\r\n其中4位是数据位, 3位是校验位.\r\n\r\n\r\n数据位: d4 d3 d2 d1\r\n校验位: p3 p2 p1\r\n海明码: h7 h6 h5 h4 h3 h2 h1\r\n\r\n\r\n确定校验位的位置 规定校验位 pi\r\n必须放在2的幂次位置 2i − 1 上, 因此p1放在h1,\r\np2放在h2, p3放在h4 此时, 海明码的位数为: | h7 | h6 | h5 | h4 | h3 | h2 |\r\nh1 | | d4 | p3 | d2 | p3 | d1 | p2 |\r\np1 |\r\n分组以形成校验关系 每个校验位负责校验一组特定位置的数据位,\r\n具体规则如下: 具体来说,\r\n校验位根据其二进制位置的1所处位置位来决定它负责校验哪些数据位:\r\n\r\n\r\np1 (h1) 负责校验位置 1, 3, 5, 7 (二进制位中第1位为1的位置),\r\n也就是这里的 h1, h3, h5, h7\r\np2 (h2) 负责校验位置 2, 3, 6, 7 (二进制位中第2位为1的位置),\r\n也就是这里的 h2, h3, h6, h7\r\np3 (h4) 负责校验位置 4, 5, 6, 7 (二进制位中第3位为1的位置),\r\n也就是这里的 h4, h5, h6, h7\r\n\r\n\r\n计算校验位的值\r\n校验位的值通过对其负责校验的数据位进行异或操作来确定:\r\n\r\n\r\np1 = d1 ⊕ d2 ⊕ d4 = 0 ⊕ 1 ⊕ 1 = 0\r\np2 = d1 ⊕ d3 ⊕ d4 = 0 ⊕ 0 ⊕ 1 = 1\r\np3 = d2 ⊕ d3 ⊕ d4 = 1 ⊕ 0 ⊕ 1 = 0 因此, 最终的海明码为: 1010010\r\n\r\n\r\n错误检测与纠正\r\n每个检验组分别利用检验位和参与检验的数据位进行异或运算, 构成r个检验方程.\r\n如果结果全部为0, 则表示数据无误; 如果某一组方程结果为1,\r\n则表示该组数据有误.\r\n\r\n假设在传输过程中, 第3位发生了错误, 接收方收到的码字变为:\r\n1010110, 此时在接收方不知道的情况下,\r\n接收方重新计算校验位: - p1’ = h1 ⊕ h3 ⊕ h5 ⊕ h7 = 0 ⊕ 1 ⊕ 1 ⊕ 1 = 1 -\r\np2’ = h2 ⊕ h3 ⊕ h6 ⊕ h7 = 1 ⊕ 1 ⊕ 0 ⊕ 1 = 1 - p3’ = h4 ⊕ h5 ⊕ h6 ⊕ h7 =\r\n0 ⊕ 1 ⊕ 0 ⊕ 1 = 0 将校验结果组合成一个二进制数, p3’p2’p1’ = 011,\r\n并非全部是0, 说明出现了错误. 转换为十进制为3, 表示第3位出错,\r\n接收方直接将第3位从1改回0, 成功纠正了错误.\r\n\r\n即使是校验位本身出错, 也能通过同样的方法定位并纠正.\r\n校验子（Syndrome）的计算和解码过程，对所有比特一视同仁。无论是数据位还是校验位出错，都会破坏其所在校验组的平衡，从而产生一个精确指向其位置的、独一无二的校验子，使得接收方能够完美地完成定位和纠正。\r\n\r\n需要注意的是, 海明码只能纠正单个比特错误, 如果同时有多个比特出错,\r\n则可能无法正确定位和纠正.\r\n例如, 如果第3位和第5位同时出错, 则收到的码字为:\r\n1010010, 此时重新计算校验位: - p1’ =\r\nh1 ⊕ h3 ⊕ h5 ⊕ h7 = 0 ⊕ 1 ⊕ 0 ⊕ 1 = 0 - p2’ = h2 ⊕ h3 ⊕ h6 ⊕ h7 = 1 ⊕ 1\r\n⊕ 0 ⊕ 1 = 1 - p3’ = h4 ⊕ h5 ⊕ h6 ⊕ h7 = 0 ⊕ 0 ⊕ 0 ⊕ 1 = 1\r\n将校验结果组合成一个二进制数, p3’p2’p1’ = 110, 转换为十进制为6,\r\n但实际上出错的位是3和5, 因此无法正确定位和纠正.\r\n背后的原因在于, 海明码的设计初衷是为了纠正单个比特错误,\r\n它确保了任意两个有效码字之间的海明距离至少为3. 但当有多个比特同时出错时,\r\n可能会导致收到的码字与另一个有效码字之间的距离更近,\r\n从而使得接收方无法正确判断原始码字.\r\n再例如, 第3位, 第5位和第6位同时出错, 则收到的码字为:\r\n10101010, 此时重新计算校验位: - p1’ =\r\nh1 ⊕ h3 ⊕ h5 ⊕ h7 = 0 ⊕ 1 ⊕ 0 ⊕ 1 = 0 - p2’ = h2 ⊕ h3 ⊕ h6 ⊕ h7 = 1 ⊕ 1\r\n⊕ 1 ⊕ 1 = 0 - p3’ = h4 ⊕ h5 ⊕ h6 ⊕ h7 = 0 ⊕ 0 ⊕ 1 ⊕ 1 = 0\r\n将校验结果组合成一个二进制数, p3’p2’p1’ = 000, 误以为数据无误,\r\n实际上数据已经损坏.\r\n这是因为三个码字之间的距离关系导致的. 第三位被p1所检验,\r\n第五位被p1和p3所检验, 第六位被p2和p3所检验. 当这三位同时出错时,\r\n三个校验位的错误相互抵消, 导致校验结果全部为0,\r\n使得接收方误以为数据无误.\r\n流量控制与可靠传输\r\n在数据链路层，我们的目标是将物理层提供的原始、可能出错的比特流，转变为一条对网络层来说高效、无差错的链路。要实现这个目标，必须解决两个核心问题：\r\n流量控制 (Flow\r\nControl)：如何防止速度快的发送方用数据“淹没”速度慢的接收方？这关乎效率和协调。\r\n可靠传输 (Reliable\r\nTransmission)：如何确保发送的数据帧最终能被接收方准确无误地收到，即使在传输过程中发生了丢失或损坏？这关乎正确性和完整性。\r\n这两个问题通常使用同一套协议框架来解决，其中最核心的就是滑动窗口机制。\r\n流量控制与滑动窗口机制\r\n如果发送方发送数据的速率，超过了接收方处理数据的速率，接收方的缓冲区（缓存）就会被填满。此时，后续到达的数据帧将因为无处存放而被丢弃，从而造成数据丢失和网络资源的浪费。\r\n而我们的目标是在发送方和接收方之间建立一种协调机制，让发送方根据接收方的实际接收能力来调整自己的发送速率。\r\n一个简单的起点：停止-等待协议\r\n(Stop-and-Wait)\r\n这是最简单的流量控制协议。工作方式是发送方每发送一帧后，就必须停止发送，并等待接收方返回对该帧的确认（ACK）。只有收到确认后，才能发送下一帧。\r\n优点：机制简单，天然地实现了流量控制和可靠传输（因为接收方不确认，发送方就不会发送）。\r\n缺点：信道利用率极低。在发送方等待确认信号返回的漫长时间里，整个信道都处于空闲状态，造成了巨大的浪费，尤其是在卫星通信这种高延迟的场景下。\r\n高效的解决方案：滑动窗口协议\r\n(Sliding Window)\r\n为了克服停止-等待协议的低效，滑动窗口协议应运而生。其核心思想是允许发送方在收到确认之前，连续发送多个数据帧。\r\n窗口 (Window)：\r\n\r\n发送窗口：在发送方，维持一个允许连续发送的帧的序号范围，称为“发送窗口”。窗口内所有帧都可以被发送出去，而无需等待确认。\r\n接收窗口：在接收方，维持一个允许接收的帧的序号范围，称为“接收窗口”。\r\n\r\n滑动 (Sliding)：\r\n当发送方收到一个确认帧（例如，确认了窗口内的第一个帧）时，它就知道该帧已被成功接收，于是发送窗口就可以向前“滑动”，从而可以发送新的数据帧。\r\n当接收方成功接收并向上层交付数据后，接收窗口也会向前“滑动”，准备接收后续的数据帧。\r\n流量控制的关键在于接收窗口的大小。接收方可以通过确认帧（ACK）告诉发送方自己当前还能接收多少数据帧（即接收窗口的大小）。如果接收方缓冲区已满，它可以将接收窗口大小设为0，发送方收到这个信息后就会暂停发送，直到接收方处理完数据，重新开放窗口。这是一种非常灵活且高效的流量控制方式。\r\n\r\n\r\nalt text\r\n\r\n可靠传输机制\r\n可靠传输机制必须确保数据不丢失、不重复、无差错、按顺序地交付给上层。这通常通过以下技术组合实现：\r\n\r\n帧编号 (Sequence\r\nNumbers)：为每个帧分配一个唯一的序号，接收方可以据此判断是否有帧丢失或失序。\r\n确认 (Acknowledgements,\r\nACKs)：接收方通过发送ACK来告知发送方哪些帧已成功收到。\r\n超时重传 (Timeout\r\nRetransmission)：发送方在发送一个帧后会启动一个计时器。如果在规定时间内没有收到对该帧的确认，就认为该帧（或其ACK）在途中丢失，并重新发送该帧。\r\n\r\n基于滑动窗口，最主流的两种可靠传输协议是回退N帧协议和选择重传协议。他们都属于ARQ(自动重传请求)协议的范畴。\r\n此外,\r\n前面提到的停止-等待协议也可以看作是滑动窗口协议的一种特殊情况,\r\n其发送窗口和接收窗口大小均为1. 这意味着发送方在发送一帧后必须等待确认,\r\n直到收到确认后才能发送下一帧. 在这样的情况下,\r\n帧的编号只需要1位(0或1)即可, 因为在任何时刻,\r\n发送方和接收方都只需要区分当前帧和下一帧.\r\n回退N帧协议 (Go-Back-N, GBN)\r\n工作方式： - 发送方可以连续发送多个帧（发送窗口大小 &gt; 1）。 -\r\n接收方只按顺序接收数据帧（接收窗口大小 =\r\n1）。如果它期望收到第 n 帧，但却收到了第 n+1 帧，它会直接丢弃第 n+1\r\n帧以及后续所有到达的帧，并反复发送对第 n−1\r\n帧的确认。当发送方发现第 n 帧超时后，它会从第 n\r\n帧开始，重新发送它后面所有已发送过的帧（即“回退N帧”）。\r\n优缺点：接收方逻辑简单，无需缓存失序的帧。但效率较低，因为一次超时可能会导致大量本已正确到达的帧被重传。\r\n\r\n\r\nalt text\r\n\r\n需要注意的是, 回退N帧协议要求发送窗口的大小 WT &lt;= 2k − 1 (k为帧序号位数),\r\n以避免序号混淆. 例如, 如果序号位数为3位, 则序号范围为0~7,\r\n发送窗口大小最大只能为7. 这是因为, 如果发送窗口大小等于8,\r\n则在发送方发送完8个帧后, 第一个帧的序号将再次变为0,\r\n此时接收方无法区分这是第一个帧还是第二轮发送的第一个帧,\r\n导致序号混淆.\r\n选择重传协议 (Selective Repeat, SR)\r\n工作方式： - 发送方可以连续发送多个帧（发送窗口大小 &gt; 1）。 -\r\n接收方可以接收并缓存失序的帧（接收窗口大小 &gt;\r\n1）。如果它期望收到第 n 帧，但却收到了第 n+1 帧，它会先将 n+1\r\n帧缓存起来，并发送一个对第 n−1 帧的确认（或专门的否定确认NAK），等待第 n\r\n帧的到来。当发送方发现第 n 帧超时后，它只重新发送第 n\r\n帧，而不会重传那些已经被确认或已经发送过的后续帧。\r\n优缺点：信道效率极高，因为它最大限度地避免了不必要的重传。但实现起来更复杂，要求接收方有足够的缓存空间和更复杂的逻辑来处理失序的帧。\r\n\r\n\r\nalt text\r\n\r\n如上, 这里的选择重传协议还使用了NAK(否定确认)机制,\r\n即接收方在发现某个帧有误或丢失时, 会立即发送一个NAK给发送方,\r\n要求其重传该帧. 这样可以更快地触发重传, 提高传输效率.\r\n不同的是, SR协议对接受窗口和发送窗口的大小都有要求. 具体来说,\r\n发送窗口大小 WT\r\n和接受窗口大小 WR\r\n加起来必须满足 WT + WR &lt;= 2k (k为帧序号位数), 否则,\r\n当确认（ACK）信息丢失时，新旧窗口的序号发生重叠，从而导致接收方无法区分一个收到的帧究竟是“旧帧的重传”还是“新发送的帧”。\r\n一般来说, 因为接受窗口必然&lt;=发送窗口, 因此通常会设置 WT = WR = 2k − 1.,\r\n这样可以最大化窗口利用率, 同时避免序号混淆的问题.\r\n\n    假如违反这种规则 \n    \n      我们设定一个最简单的场景：帧序号用 k=2 位来表示。那么序号空间就是 2^k\r\n= 4，也就是说，序号范围为 0, 1, 2, 3，然后循环回 0。\r\n我们设定发送窗口 W_T=3，接收窗口 W_R=3。这样 W_T+W_R=6 &gt;\r\n4。让我们一步步来看会发生什么：\r\n第一步：初始状态 - 发送方的发送窗口是 {0, 1, 2}。 -\r\n接收方的接收窗口也是 {0, 1, 2}。\r\n第二步：发送与接收 - 发送方将窗口内的帧 0, 1, 2 全部发送出去。 -\r\n接收方成功收到了这三个帧。因为它期望的就是 {0, 1,\r\n2}，所以它将这三个帧的数据交付给上层。\r\n第三步：接收方滑动窗口并发回确认 - 接收方成功接收了 0, 1,\r\n2，于是它的接收窗口向前滑动3个位置。 - 新的接收窗口变成了 {3, 0,\r\n1}。它现在准备接收新一轮的帧了。 - 同时，接收方为 0, 1, 2\r\n这三个帧都发回了确认信息 ACK(0), ACK(1), ACK(2)。\r\n第四步：灾难发生——所有ACK全部丢失 -\r\n假设网络出现问题，接收方发出的三个ACK信号在传输过程中全部丢失了。\r\n第五步：发送方超时重传 - 发送方苦苦等待，但始终没有收到对帧 0, 1, 2\r\n的任何确认。 - 最终，帧 0 的计时器超时。 - 发送方认为帧 0\r\n在传输过程中丢失了，于是它重新发送帧 0。\r\n第六步：接收方收到重传的帧 0 - 接收方此刻的接收窗口是 {3, 0, 1}\r\n(如第三步所示)。 - 它收到了一个序号为 0 的帧 (来自第五步发送方的重传)。\r\n- 从接收方的视角看，序号 0 正好在它的接收窗口 {3, 0, 1}\r\n内。它完全有理由认为，这是一个全新的、属于下一轮传输的帧\r\n0，而不是对上一轮旧帧 0\r\n的重传。它无法分辨这两种情况！最终导致了数据重复，协议的可靠性被彻底打破。\r\n\n    \n  \r\n信道利用率 (Channel\r\nUtilization)\r\n信道利用率是衡量数据链路层协议效率的一个重要指标。它表示在一个发送周期(从发送方开始发送分组到收到第一个确认分组的时间)内，实际用于传输有用数据的时间占总时间的比例。\r\n停止-等待协议的信道利用率\r\n这是最简单的协议，但也是效率最低的。\r\n停止-等待协议的一个完整“发送周期”包含以下几个部分：\r\n\r\nTD（数据帧发送时延）：发送方发送一个数据分组（帧）所需的时间。\r\nRTT（往返传播时延）：信号在信道中往返一次所需的时间，包括数据分组从发送方到接收方的传播时间，以及确认帧（ACK）从接收方回到发送方的传播时间。\r\nTA（确认帧发送时延）：接收方发送一个确认帧所需的时间。\r\n\r\n在一个周期内，发送方只有在最初的 TD\r\n时间内是在发送有效数据，其余的 RTT + TA\r\n时间里，信道都在空闲等待。因此，其总周期为 TD + RTT + TA。\r\n将上述分析代入利用率的定义，我们得到停止-等待协议的信道利用率公式：\r\n\r\n通常情况下，确认帧 TA\r\n很短，可以忽略不计，公式可简化为：\r\n\r\n从公式可以看出, 对于停止-等待协议，当往返时延 RTT\r\n远大于数据帧发送时延 TD\r\n​时，信道利用率会非常低。\r\n连续ARQ协议（滑动窗口）的信道利用率\r\n为了解决停止-等待协议的效率问题，引入了连续ARQ协议，它采用流水线传输\r\n(Pipelining) 的方式，允许发送方在收到确认前连续发送多个分组。\r\n设发送窗口大小为 n（即一次最多可以连续发送 n 个分组）。根据 n\r\n是否能“填满”信道，分为两种情况。\r\n一个完整的发送周期（从发送第1个分组到收到它的确认）总时长仍然是 TD + RTT + TA。我们需要看在这个周期内，发送方究竟发送了多少数据。\r\n情况一：n ⋅ TD &lt; TD + RTT + TA（窗口较小，无法填满信道）\r\n此时发送方把窗口内的 n\r\n个分组全部发完后，第一个分组的 ACK\r\n还没有回来，因此发送方必须停下来等待，造成信道空闲。\r\n利用率计算：在一个发送周期内，发送方有效发送数据的时间是 n ⋅ TD。\r\n\r\n\r\n情况二：n ⋅ TD ≥ TD + RTT + TA（窗口足够大，可以填满信道）\r\n条件解读：当第一个分组的 ACK 返回时，发送方还没发完窗口内的 n\r\n个分组，因此它可以继续不间断地发送新的分组，信道始终处于忙碌状态。\r\n利用率计算：由于信道没有空闲，发送方一直在发送有效数据。\r\nU = 1\r\n\r\n结论： 连续 ARQ\r\n协议通过流水线技术，极大地提高了信道利用率。只要发送窗口 n 足够大（满足 n ⋅ TD ≥ TD + RTT + TA），在不考虑差错的情况下，理论上可以达到\r\n100% 的信道利用率，完全克服了停止-等待协议的效率瓶颈。\r\n一般我们取发送窗口 n 为：\r\n局域网 (Local Area Network,\r\nLAN)\r\n局域网 (LAN)\r\n是指在一个较小的地理范围内（如一栋建筑、一个校园或一个办公室），将各种计算机、服务器、打印机等设备互联起来组成的私有网络。\r\n其特点是覆盖范围小,\r\n但是通常具有高传输速率、低时延、低误码率\r\n局域网的技术标准主要集中在OSI参考模型的最低两层：物理层和数据链路层。IEEE\r\n802系列标准为了适应不同的局域网技术，将数据链路层进一步划分为两个子层：\r\n逻辑链路控制 (LLC - Logical Link\r\nControl) 子层:\r\n负责向上层（网络层）提供一个统一的接口，隐藏了不同MAC协议的差异。它也负责处理一些确认、流量控制等逻辑功能。\r\n介质访问控制 (MAC - Medium Access\r\nControl) 子层:\r\n这是局域网技术的核心。它负责数据帧的封装、物理地址（MAC地址）的寻址，以及最重要的——如何协调对共享物理介质的访问（即我们前面讨论的CSMA/CD、CSMA/CA等协议）。\r\n他们之间的结构关系为: 网络层 (L3) &lt;–&gt; LLC子层 (L2上) &lt;–&gt;\r\nMAC子层 (L2下) &lt;–&gt; 物理层 (L1)\r\n局域网的三个决定性要素是拓扑结构、传输介质和介质访问控制方式，其中介质访问控制方式最为重要\r\n。\r\n以太网与 IEEE 802.3\r\n以太网 (Ethernet) 是当今应用最广泛的有线局域网技术，其技术标准由 IEEE\r\n802.3 规范定义。\r\nMAC地址（或称物理地址）是一个48位（6字节）的全球唯一地址，固化在网卡的ROM中。它通常用12个十六进制数表示，如\r\n02-60-8c-e4-b1-21 。前24位是厂商代码，后24位是厂商分配的序列号。\r\n网卡通过硬件检查收到的MAC帧，如果目的地址是本机地址（单播）、广播地址（全1）或本机所在的多播组地址，则接收该帧，否则丢弃。\r\nIEEE 802.11 无线局域网\r\nVLAN 基本概念与基本原理\r\n虚拟局域网 (VLAN)\r\n是一种将一个大型物理局域网分割成多个逻辑上独立的虚拟网络的技术\r\n。VLAN的作用主要有以下几个方面：\r\n\r\n隔离广播域：一个大型局域网是一个广播域，大量的广播帧（如ARP）会严重影响网络性能\r\n。VLAN将网络分割成多个小的广播域，广播帧被限制在各自的VLAN内部\r\n。\r\n增强安全性和管理：可以将不同部门或用户组划分到不同的VLAN中，即使他们物理上连接在同一台交换机，也无法直接通信，从而提高安全性\r\n。\r\n\r\n广域网(Wide Area Network, WAN)\r\n广域网的基本概念\r\n点对点协议\r\n数据链路层设备\r\n网桥\r\n以太网交换机\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"物理层","url":"/2025/09/25/web/Computer%20Network/%E7%89%A9%E7%90%86%E5%B1%82/3.%20%E7%89%A9%E7%90%86%E5%B1%82/","content":"通信基础\r\n要理解物理层的工作原理，我们首先需要掌握一些通信领域的基础理论。\r\n基本概念\r\n数据：是我们想要传送的信息，是信息的载体。可以是数字的（如文本文件）或模拟的（如语音）。\r\n信号：是数据在物理介质上的电气或电磁表现形式。信号是传输数据的方式。\r\n- 数字信号 (Digital\r\nSignal)：信号的状态是离散、不连续的，例如只有高、低两种电平。 - 模拟信号\r\n(Analog Signal)：信号的幅值是连续变化的，例如正弦波。\r\n信道 (Channel):\r\n信道是信号传输的物理路径。它可以是有形的（如双绞线、光纤）或无形的（如无线电波传播的空间）。\r\n速率相关的概念:\r\n\r\n码元\r\n(Symbol)：在数字通信中，一个固定时长的、具有明确定义的波形（如某个电压、频率或相位）被称为一个码元。码元是承载信息的基本信号单位。\r\n波特率 (Baud\r\nRate)：也称为码元速率，指每秒钟传输的码元个数。单位是波特（Baud）。它描述的是信号变化的速率。\r\n比特率 (Bit\r\nRate)：也称为信息速率，指每秒钟传输的二进制比特（bit）数。单位是比特/秒（bit/s\r\n或 bps）。它描述的是信息传输的速率。\r\n\r\n需要注意, 一个码元可以携带多个比特的信息。如果一个码元有 V\r\n种不同的状态（例如，4种不同的电压等级），那么每个码元就可以表示 log2V\r\n个比特。\r\n从通信双方的信息交互方式来看, 可以有三种模式: - 单工\r\n(Simplex):\r\n通信是单向的，信息只能从发送方传输到接收方，接收方不能向发送方反馈信息。例如，电视广播就是单工通信。\r\n- 半双工 (Half-Duplex):\r\n通信是双向的，但在同一时间内只能有一方发送信息，另一方必须等待。例如，对讲机就是半双工通信。\r\n- 全双工 (Full-Duplex):\r\n通信是双向的，双方可以同时发送和接收信息。例如，电话就是全双工通信。\r\n信道的极限容量\r\n任何信道能够传输数据的速率都不是无限的，它受到物理规律的限制。有两个重要的理论描述了信道的极限容量。\r\n奈奎斯特定理\r\n(Nyquist’s Theorem)\r\n奈氏准则研究的是一个理想的、无噪声的、带宽有限的信道\r\n在信道中，发送过快的信号码元（代表数据的基本信号单元）会在时间上“展宽”，导致前后码元的波形发生重叠，相互“模糊”，使得接收端无法清晰地分辨出每一个码元。这种现象就是码间串扰。\r\n奈氏准则的首要目标，就是确定为了避免码间串扰，码元发送速率的上限是多少\r\n极限码元传输速率: 对于一个带宽为 W (单位为Hz)\r\n的信道，其极限码元传输速率为 2W 波特 (Baud)。\r\n码元速率上限 = 2W(Baud)\r\n极限比特传输速率:\r\n数据传输速率不仅取决于每秒能发多少个码元，还取决于每个码元能携带多少比特的信息。\r\n如果一个码元有 V\r\n种不同的离散状态（例如 4 种不同的电压等级），那么每个码元就可以表示\r\nlog2V 个比特。\r\n因此，理想信道的极限数据传输速率（比特率） C 为：\r\nC = 2Wlog2V  (单位：b/s)\r\n\r\n带宽是瓶颈：信道的带宽 W 直接限制了码元的发送速度。\r\n提升速率靠编码: 在带宽 W 固定的情况下，要想提高数据传输速率\r\nC，唯一的办法就是让每个码元携带更多的比特，即增加 V\r\n的值。这需要更复杂的调制解调技术。\r\n过于理想化:\r\n奈氏准则是在一个没有噪声的完美世界里得出的。它告诉我们，只要技术足够好，理论上可以通过无限增加\r\nV\r\n来无限提升数据速率。但这在现实中是不可能的，因为噪声的存在会限制我们分辨不同码元状态的能力。\r\n\r\n香农定理 (Shannon’s\r\nTheorem)\r\n香农定理则将随机噪声这个现实因素考虑进来，给出了一个有噪声、带宽有限的信道的绝对极限数据传输速率。\r\n这里有一个信噪比的概念：信噪比 (S/N\r\n- Signal-to-Noise Ratio) 是衡量信号与噪声相对强弱的关键指标。S/N\r\n越高，信号越清晰，信道质量越好。\r\n香农定理指出，对于一个带宽为 W，信噪比为 S/N\r\n的信道，其极限数据传输速率C为：\r\n单位：\r\n注意：公式中的 S/N\r\n是信号功率与噪声功率的比值，是一个无单位的数值。\r\n在实际应用中，信噪比常以分贝 (dB) 为单位，换算关系为：\r\ndB = 10log10(S/N)\r\n\r\n进行香农公式计算时，必须将 dB 单位的信噪比换算回无单位的 S/N 值。例如，信噪比为\r\n30dB，意味着 10log10(S/N) = 30，解得\r\nS/N = 1000。\r\n\r\n\r\n速率存在硬上限: 香农定理给出的 C\r\n是一个理论上的极限值。无论采用多么先进的技术（无论奈氏准则中的 V\r\n取多大），只要数据传输速率超过这个 C\r\n值，就不可能实现无差错的传输。\r\n提升速率靠“开源节流”: 要想提高极限数据速率 C，只有两种途径：\r\n\r\n增加带宽 W (“开源”)。\r\n提高信噪比 S/N (“节流”，即增大信号功率或降低噪声干扰)。\r\n\r\n理论上的可能性:\r\n香农定理也给出了一个积极的结论：只要信息传输速率低于信道极限\r\nC，就一定存在某种先进的编码和调制技术，能够实现无差错的传输。\r\n\r\n两者的比较\r\n奈奎斯特定理和香农定理分别从不同的角度描述了信道的极限容量。前者假设无噪声，强调码元速率和编码复杂度；后者考虑噪声，强调带宽和信噪比。\r\n在实际应用中, 我们需要综合考虑这两个方面,\r\n假如按照已知条件计算发现奈奎斯特定理的极限比特率低于香农定理的极限比特率,\r\n那么奈奎斯特定理的结果才是实际可达到的上限,\r\n反之亦然(因为他们本身描述的极限条件不同)。\r\n编码与调制\r\n编码和调制是将原始的数字数据（比特流）转换为适合在信道中传输的信号的过程。\r\n编码 (Encoding)：数字数据 -&gt; 数字信号\r\n目的：主要用于基带传输，即信号的频谱从零频附近开始。例如，以太网内部的传输。编码的主要目标是解决时钟同步、直流分量等问题。\r\n常见编码方式：\r\n不归零编码\r\n(NRZ)：用高电平表示1，低电平表示0。实现简单，但如果出现连续的1或0，会导致接收方时钟漂移，难以同步。\r\n曼彻斯特编码 (Manchester\r\nEncoding)：将每个比特周期分为两半，从高到低跳变表示1，从低到高跳变表示0（反之亦可）。这种编码自带时钟信号，解决了同步问题，但它需要的带宽是NRZ的两倍。\r\n差分曼彻斯特编码：位中间的跳变只用于同步，而位开始处的跳变与否用于表示0或1。\r\n调制 (Modulation)：数字数据 -&gt; 模拟信号\r\n目的：主要用于通带传输(Carrier)，即信号需要被搬移到较高的频率范围进行传输。例如，Wi-Fi、无线电广播和电话线上的调制解调器（Modem）。\r\n\r\n而基带传输则是直接在低频段（从0Hz开始）传输数字信号。\r\n\r\n基本调制技术：通过修改载波信号的属性来表示数字数据。\r\n\r\n幅移键控 (ASK - Amplitude Shift\r\nKeying)：用载波的不同振幅来表示0和1。\r\n频移键控 (FSK - Frequency Shift\r\nKeying)：用载波的不同频率来表示0和1。\r\n相移键控 (PSK - Phase Shift\r\nKeying)：用载波的不同相位来表示0和1。\r\n\r\n混合调制技术：主要是正交幅度调制QAM\r\n正交幅度调制 (QAM - Quadrature Amplitude\r\nModulation)：这是一种更高级的调制技术，它同时结合了幅移键控\r\n(ASK) 和 相移键控\r\n(PSK)。通过组合多个振幅和多个相位，可以使一个码元代表更多的比特（即增大奈奎斯特定理中的\r\nV 值），从而在有限的带宽内实现极高的数据传输速率。例如，16-QAM\r\n使用16种不同的组合状态，每个码元可以传输 log216 = 4\r\n个比特。\r\n此时, 该 QAM 的数据传输速率 R 为 R = W log₂(mn) (单位为 b/s)，其中 W\r\n是带宽，m 是振幅状态数，n 是相位状态数, mn\r\n就是总的状态数(QAM-X中的X)。\r\n这其实就是符号率与比特率的关系, 比特是信息的基本单位,\r\n而符号(码元)是信号的基本单位, 当调制方式增加\r\n每个符号携带的信息量，符号率不变而比特率增加: Rbit​ = Rsymbol​ × 每个符号承载的比特数\r\n传输介质\r\n传输介质，也称为传输媒体或信道，是网络中发送方和接收方之间的物理路径。它决定了网络通信的带宽、距离、成本和可靠性。传输介质可以分为两大类：导向型传输介质和非导向型传输介质。\r\n导向型与非导向型传输介质\r\n在导向型传输介质中，电磁波被限制并沿着一个固态的物理媒介（如金属线或玻璃纤维）传播。\r\n双绞线 (Twisted Pair):\r\n由两根相互绝缘的铜导线，按一定规则绞合而成。\r\n将导线绞合是其最重要的特性。这样做的目的是为了尽可能减少来自外界的电磁干扰（EMI）以及相邻线对之间的串扰（Crosstalk）。两根导线中的电流方向相反，它们产生的磁场可以相互抵消，从而增强了信号的抗干扰能力。\r\n- 非屏蔽双绞线 (UTP - Unshielded Twisted\r\nPair)：无金属屏蔽层，是目前局域网（LAN）中最常见的传输介质 - 屏蔽双绞线\r\n(STP - Shielded Twisted\r\nPair)：在线对外部包裹有金属屏蔽层，抗干扰能力更强，但成本更高，安装也更复杂。\r\n同轴电缆 (Coaxial Cable):\r\n由内到外依次是：中心铜质导体、塑料绝缘层、网状编织的金属屏蔽层和外部保护胶皮\r\n曾广泛用于有线电视（CATV）和早期的以太网（如10BASE-5），但现在在局域网中已基本被双绞线取代。\r\n光纤 (Optical Fiber): 由一个非常细的玻璃或塑料纤芯\r\n(Core) 和一层折射率较低的玻璃包层 (Cladding) 组成。\r\n它传输的不是电信号，而是光脉冲。光信号在纤芯中以全内反射 (Total Internal\r\nReflection) 的方式向前传播。 - 多模光纤 (Multi-mode\r\nFiber)：纤芯较粗，允许多束不同角度的光线同时传播。成本较低，适用于短距离通信（如建筑物内部）。\r\n- 单模光纤 (Single-mode\r\nFiber)：纤芯极细，只允许一束光线沿直线传播。成本高，但衰减小、带宽高，适用于长距离、大容量的通信（如跨洋海底光缆）。\r\n非导向型传输介质就是我们常说的无线传输，它不限制电磁波的传播方向，信号在自由空间中传播。\r\n无线电波 (Radio\r\nWaves)：具有很强的穿透能力，可向所有方向传播。适用于移动通信、调频广播、Wi-Fi和蓝牙等。\r\n微波\r\n(Microwaves)：沿直线传播，频率比无线电波高。主要用于地面点对点通信（如手机基站之间）和卫星通信。\r\n红外线\r\n(Infrared)：沿直线传播，不能穿透墙壁。常用于短距离通信，如电视遥控器\r\n物理层接口的特性\r\n物理层的主要功能之一就是定义了设备与传输介质之间的接口标准。这些标准通常由以下四个特性来规定:\r\n\r\n机械特性 (Mechanical Characteristics):\r\n指明接口的物理属性，如连接器的形状、尺寸、引脚数量和排列方式等。\r\n\r\n例如我们日常使用的USB接口和RJ45网线接口的物理形状和尺寸都是标准化的，确保不同厂商的设备可以物理连接。\r\n\r\n电气特性 (Electrical Characteristics):\r\n规定了在线路上传输的信号的电气参数，如电压的范围、阻抗匹配、传输速率和距离限制等。\r\n\r\n例如规定用-5V到+5V的电压表示比特“1”，用0V表示比特“0”。同时规定了驱动器和接收器的电气参数。\r\n\r\n功能特性 (Functional Characteristics):\r\n指明接口的各个引脚（或线路）的功能和用途。\r\n\r\n示例：在一个串行通信接口中，会明确规定哪个引脚是用于发送数据（TxD），哪个引脚是用于接收数据（RxD），哪个是地线（GND）等。\r\n\r\n过程特性(Procedural Characteristics):\r\n也称为规程特性，它规定了利用接口线路实现比特流传输的一系列操作事件的顺序。\r\n\r\n示例：规定了设备间建立连接的“握手”过程。例如，A设备要向B设备发送数据，A首先要激活“请求发送”（RTS）引脚，等待B激活“清除发送”（CTS）引脚作为响应后，A才能开始发送数据。\r\n物理层设备\r\n物理层设备，也称为Layer\r\n1设备，是网络中最简单的连接设备。它们的共同特点是，它们在OSI模型的第一层（物理层）上工作，只处理电信号（比特流），而不识别更高层次的数据结构，如MAC地址（数据链路层）或IP地址（网络层）。\r\n这些设备的主要作用是信号的再生和分发，以克服物理介质在传输过程中的信号衰减和距离限制。\r\n中继器 (Repeater)\r\n中继器是一种连接两个相同网络段的设备，通常只有两个端口。\r\n其核心功能是信号再生 (Signal Regeneration):\r\n当电信号在电缆中长距离传输时，会发生衰减（信号变弱）和失真。中继器接收到这种衰弱的信号后，并不是简单地将其放大（Amplification）。简单的放大器会同时放大信号和累积的噪声。相反，中继器会解析出原始的比特流（0和1），然后生成一个全新的、标准的、无失真的强信号再发送出去。这个“再生”过程是其关键所在。\r\n主要用途：延长网络的物理距离。例如，以太网标准规定双绞线的最大传输距离为100米。如果需要连接两个相距150米的设备，就可以在中间放置一个中继器来延长通信距离。\r\n局限性: -\r\n无法连接不同类型的网络：它只能连接物理层协议和速率都相同的网络段，例如连接两个以太网段。\r\n- 扩大冲突域：中继器会将其连接的所有网段合并成一个更大的冲突域\r\n(Collision\r\nDomain)。这意味着，如果任何一端的设备发送数据时发生碰撞，这个碰撞信号会被中继器转发，从而影响到另一端的网络。\r\n\r\n冲突域是指在同一时间内，只允许一台设备发送数据的网络范围\r\n\r\n集线器 (Hub)\r\n集线器本质上是一个多端口的中继器 (Multi-port\r\nRepeater)。它是一个中心连接设备，用于将多个计算机或其他网络设备连接在一起，形成一个星型拓扑结构。\r\n当集线器从其任何一个端口接收到数据信号时，它会对信号进行再生，然后将该信号广播到所有其他端口。这意味着连接到集线器的所有设备都会收到这份数据，无论这份数据是不是发给它的。接收到的设备需要在其网络接口卡（网卡）层面判断这份数据是否是自己的，如果不是则丢弃。集线器本身完全不关心数据的目的地。\r\n核心特点与缺点：\r\n\r\n单一冲突域 (Single Collision\r\nDomain)：这是集线器最主要的特征。所有连接到集线器的设备都处于同一个冲突域中。如果两台设备同时发送数据，就会发生碰撞，并且这个碰撞会影响到网络中的所有设备，导致通信失败和重传。\r\n共享带宽 (Shared\r\nBandwidth)：集线器上所有端口共享总带宽。例如，一个100Mbps的8口集线器，如果8台设备都在通信，那么它们必须共享这100Mbps的带宽，每台设备实际可用的带宽会远低于100Mbps。\r\n半双工\r\n(Half-duplex)模式：由于工作在单一冲突域中，设备不能同时发送和接收数据，只能进行半双工通信。\r\n\r\n因此,\r\n由于上述严重的性能瓶颈，集线器目前已基本被淘汰，在现代网络中几乎看不到。它的位置已经被数据链路层的交换机\r\n(Switch) 所取代。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"计算机网络体系结构","url":"/2025/09/16/web/Computer%20Network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/1.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","content":"电路交换, 报文交换和分组交换\r\n\r\n在计算机网络中，数据交换技术是指在网络节点之间传输数据时所采用的方式。根据数据传输的组织形式，主要分为三种基本类型：电路交换\r\n(Circuit Switching)、报文交换 (Message Switching) 和 分组交换 (Packet\r\nSwitching), 三种方式的比较如上图\r\n电路交换\r\n电路交换\r\n是一种在通信双方之间建立一条专用物理连接（电路）的技术。在整个通信过程中，这条电路被双方独占，直到通信结束才被释放。电路交换的通信过程严格分为三个阶段：\r\n\r\n建立连接 (Circuit Establishment):\r\n在数据传输开始之前，源节点（如打电话的人）向网络发出连接请求。网络通过一系列交换机（节点）为通信双方分配并建立一条专用的物理路径。\r\n\r\n此步骤的目的是预留通信所需的所有资源（如信道带宽、交换机端口等），以确保后续数据传输的服务质量\r\n(QoS)，如固定的速率和时延。\r\n\r\n数据传输 (Data Transfer):\r\n连接建立后，源节点开始沿着这条专用电路向目的节点发送数据。数据以恒定的速率传输，中间节点（交换机）不对数据进行存储，而是直接进行转发。\r\n\r\n由于电路是专用的，数据传输几乎没有时延（仅有传播时延和节点处理时延），且时延是固定的，非常适合实时通信。\r\n\r\n释放连接 (Circuit Release):\r\n通信结束后，任何一方（通常是发起方）发出拆除连接的信令。网络收回为该连接分配的所有资源。\r\n\r\n释放资源是为了让其他用户可以使用这些空闲的信道和端口，提高网络资源的整体利用率。\r\n优点： - 实时性强：\r\n一旦连接建立，数据传输时延极小且固定，非常适用于对时延敏感的实时业务（如语音、视频通话）。\r\n- 服务质量保证：\r\n通信双方独占带宽，数据传输速率恒定，不会出现网络拥塞导致的速率波动。\r\n缺点： - 线路利用率低：\r\n无论双方是否在传输数据（例如通话中的沉默时段），电路都会被占用，导致资源浪费，尤其不适合突发性（bursty）的数据通信。\r\n- 建立连接时延： 在数据传输前，必须花费额外的时间来建立连接。 -\r\n难以实现差错控制: 中间节点不具备存储和检验数据的能力,\r\n无法识别和纠正差错\r\n报文交换 (Message Switching)\r\n报文交换\r\n是一种无需预先建立专用路径的数据交换技术。它以报文\r\n(Message)（即一个完整的数据单元，如一封电子邮件）为单位进行传输，并采用“存储-转发”\r\n(Store-and-Forward) 机制。工作原理如下:\r\n\r\n发送报文：\r\n源节点将要发送的数据（报文）附加上目标地址等控制信息，然后将整个报文发送给相邻的第一个交换节点。\r\n存储和转发：交换节点收到完整的报文后，先将其存储在本地缓存（如硬盘）中,\r\n节点需要接收完整的报文并保存，一方面是为了进行差错校验，另一方面是等待输出链路可用。当输出链路空闲时，节点再将该报文转发给下一个节点。这种方式允许多个不同来源的报文共享同一条链路，提高了链路的利用率。\r\n中继传输：\r\n报文在网络中逐个节点地“存储-转发”，直到最终到达目的节点。\r\n\r\n优点在于: - 线路利用率高：\r\n交换节点可以动态分配链路资源，只有在传输报文时才占用链路，提高了信道利用率。\r\n- 无需建立连接： 省去了电路交换中建立连接所需的时间。\r\n缺点： - 时延大且不固定：\r\n每个节点都需要完整接收并存储报文，导致较大的“存储转发时延”。时延会随着网络负载的增加而显著增加。\r\n- 节点缓存要求高：\r\n交换节点必须有足够大的缓存空间（通常是磁盘）来存储可能很长的整个报文。\r\n- 不适合实时通信： 较大的时延使其无法满足实时交互的需求。\r\n分组交换 (Packet Switching)\r\n分组交换 是目前互联网 (Internet)\r\n使用的核心技术。它结合了报文交换的优点（高效的链路共享），并克服了其缺点（时延大、缓存要求高）。互联网\r\n(Internet)、局域网 (LAN)、广域网 (WAN)\r\n等几乎所有现代数据网络都使用这种方式。\r\n它同样采用“存储-转发”机制，但其传输的基本单位是分组\r\n(Packet)——即将一个完整的报文拆分成多个较小的数据块。工作原理为:\r\n\r\n报文分组 (Segmentation):\r\n在源节点，一个完整的报文（如一个网页、一封邮件）被分割成多个固定或可变长度的分组。每个分组都会被添加一个头部\r\n(Header)，包含源地址、目的地址、分组序号等控制信息。这里的将大报文拆分成小单元（分组），有几个关键好处：\r\n\r\n减少时延：\r\n交换节点只需接收一个很小的分组即可开始转发，而无需等待整个报文。这使得网络可以实现“流水线”\r\n(Pipelining) 传输(边接受边传输)，大大降低了端到端时延。\r\n减少缓存需求：\r\n节点缓存中只需存储较小的分组，而非完整的大报文。\r\n提高可靠性：\r\n如果传输中出现错误，只需重传错误的分组，而不是整个报文。\r\n\r\n存储和转发 (Store-and-Forward):\r\n每个分组在网络中被独立地进行“存储-转发”。交换节点（路由器）接收一个分组，将其暂存在内存（速度远快于报文交换的磁盘）中，检查其头部，然后根据路由表选择最佳路径转发给下一个节点。这种方式非常灵活，分组可以动态地选择路径，适应网络拥塞或链路故障。\r\n\r\n路径选择 (Routing):\r\n不同的分组可能会沿着不同的路径传输到目的地。（这主要取决于使用的是数据报方式还是虚电路方式,\r\n数据报方式具有无连接性, 每个分组独立路由; 而虚电路(Virtual Circuit,\r\nVC)则在数据传输前先建立一条逻辑连接（虚电路）,\r\n所有分组都沿着这条逻辑路径按顺序传输）。\r\n\r\n重组 (Reassembly):\r\n分组到达目的节点后，目的主机根据分组头部中的序号信息，将这些可能乱序到达的分组重新排序，组装成原始的报文(由于分组独立路由，它们到达目的地的顺序可能与发送顺序不同，必须重组才能恢复原始数据)\r\n\r\n这种方式的优点在于： -\r\n线路利用率极高：动态共享链路，资源利用率在三种方式中最高。 - 灵活高效：\r\n传输单位小，时延相对较低（虽然不固定）。 - 鲁棒性强 (Robust)：\r\n节点或链路故障时，分组可以动态选择其他路径绕过故障点。\r\n缺点则是： - 时延不固定 (Jitter)：\r\n每个分组的存储转发时延和排队时延是变化的，会导致“时延抖动”，对实时业务（如高质量视频会议）有一定挑战。\r\n- 额外开销：每个分组都需要附加包头信息，这会产生一定的传输开销。\r\n计算机网络的分类\r\n计算机网络可以从多个不同的维度进行分类:\r\n按分布范围分类\r\n这是最常用的一种分类方式，它根据网络所覆盖的地理区域大小来划分：\r\n\r\n广域网 (WAN - Wide Area Network):\r\n覆盖范围非常大，通常直径为几十到几千公里，可以覆盖一个国家、一个大洲甚至全球。它的任务是提供长距离通信，连接不同地区的主机或局域网。它通常使用高速链路和交换机（如路由器）进行数据传输。互联网\r\n(Internet) 的核心部分就是一个全球最大的广域网。\r\n城域网 (MAN - Metropolitan Area Network):\r\n覆盖范围介于WAN和LAN之间，通常覆盖一个城市（直径约 5 km 到 50\r\nkm）。它可以被视为一个大型的局域网，通常采用以太网等技术，用于连接城市内的多个局域网。\r\n局域网 (LAN - Local Area Network):\r\n覆盖范围较小，通常是直径为几米到几千米的区域，例如一栋办公楼、一个校园或一个家庭。局域网通常具有较高的传输速率和较低的误码率。传统上，局域网多采用广播技术（如早期的以太网），而广域网多采用点对点交换技术。\r\n个人区域网 (PAN - Personal Area Network):\r\n覆盖范围最小，通常在个人工作区域（约几米内）。用于在个人设备之间（如智能手机、平板电脑、笔记本电脑、蓝牙耳机）进行短距离通信。当它使用无线技术时，也称为\r\n无线个人区域网 (WPAN)。\r\n\r\n按传输技术分类\r\n\r\n广播式网络 (Broadcast Networks):\r\n网络中所有联网的计算机共享一个公共通信信道。当一台计算机发送一个分组时，信道上的所有其他计算机都会“收听”到这个分组。每台计算机通过检查分组中的目的地址来判断这个分组是否是发送给自己的，从而决定是否接收它。\r\n\r\n传统的局域网（如总线型以太网）基本都采用广播式通信。此外，无线网络和卫星通信网络也属于广播式网络。\r\n\r\n点对点网络 (Point-to-Point Networks):\r\n网络由多条独立的物理线路组成，每条线路连接一对计算机（节点）。如果两台主机没有被一条线路直接连接，它们之间的通信就需要通过中间节点的中继。\r\n\r\n这通常需要“存储-转发” (Store-and-Forward)\r\n机制，即中间节点（如路由器）接收整个分组，将其存储下来，然后查找路由表，最后转发给下一个节点。广域网大多采用点对点技术。\r\n按拓扑结构分类\r\n拓扑结构是指网络中节点（如主机、路由器）与通信线路之间的几何关系，它主要定义了网络的物理布局。\r\n\r\n总线形 (Bus Topology):\r\n所有计算机都连接到一根单根传输线（称为“总线”）上。\r\n\r\n其优点是建网容易，增/减节点方便，节省线路成本;\r\n缺点则在于通信效率在重负载时不高（容易冲突）,\r\n且总线是网络的命脉，任意一处故障都可能导致整个网络瘫痪。\r\n\r\n星形 (Star Topology):\r\n网络中有一个中央设备（如交换机、集线器或路由器），每个终端或计算机都通过单独的线路与该中央设备相连。\r\n\r\n其优点是便于集中控制和管理, 单个节点的故障不会影响其他节点;\r\n缺点则是线路成本较高,\r\n中央设备是网络的“瓶颈”，一旦中央设备发生故障，整个网络都会瘫痪。\r\n现代的局域网（如以太网交换机）基本都采用星形结构。\r\n\r\n环形 (Ring Topology):\r\n所有计算机接口设备被连接成一个闭合的环，信号在环中沿着一个方向单向传输。典型的例子是令牌环\r\n(Token Ring) 局域网。\r\n网状 (Mesh Topology):\r\n每个节点至少有两条路径与其他节点相连，存在高度的冗余连接。\r\n\r\n一个显著优点在于可靠性极高。某条链路或某个节点出现故障时，数据可以自动选择其他路径进行传输。\r\n缺点也很显而易见：\r\n控制非常复杂（需要动态路由算法），线路成本极高。因此多用于广域网的核心层和互联网的骨干网，以确保通信的鲁棒性。\r\n按传输介质分类\r\n\r\n有线网络 (Wired Networks):\r\n使用物理线缆作为传输介质的网络。包括双绞线网络（如以太网）、同轴电缆网络（如早期的有线电视网）、光纤网络等。\r\n无线网络 (Wireless Networks):\r\n使用电磁波在空间中进行数据传输，无需物理线缆。包括 Wi-Fi、蓝牙\r\n(Bluetooth)、微波通信、蜂窝移动网络 (4G/5G) 等。\r\n\r\n计算机网络的性能指标\r\n速率 (Rate): 也常称为数据率(Data Rate)或比特率(Bit\r\nRate), 是指连接到计算机网络上的节点在数字信道上传送数据的速率,\r\n基本单位是 b/s (比特/秒，即 bps)。 - kb/s (千比特/秒) = 10³ b/s - Mb/s\r\n(兆比特/秒) = 10⁶ b/s\r\n- Gb/s (吉比特/秒) = 10⁹ b/s - Tb/s (太比特/秒) = 10¹² b/s\r\n带宽 (Bandwidth):\r\n在计算机网络中，带宽通常是“最高数据传输速率”的同义词,\r\n因此单位也是 b/s\r\n(比特/秒)。我们常说的“我家拉了100兆的宽带”，指的就是这条线路的理论最高速率为\r\n100 Mb/s。它代表了链路传输数据的最大能力。 &gt; 在信息论中，带宽\r\n(Bandwidth) 指的是信号频率范围，单位为赫兹\r\n(Hz)。例如，一个信道的带宽为 3000\r\nHz，表示它可以传输从某一频率到该频率加3000\r\nHz范围内的信号。\r\n吞吐量 (Throughput):\r\n是指在单位时间内，通过某个网络（或信道、接口）的实际数据量。其单位为\r\nb/s, Mb/s, Gb/s 等.\r\n实际的吞吐量会受到网络拥塞、设备处理能力、协议开销、时延等多种因素的限制。因此，吞吐量总是小于或等于带宽。\r\n信道利用率 (Channel Utilization):\r\n指某条信道在特定时间段内，有数据通过的时间所占的百分比。这是衡量信道繁忙程度或效率的指标。不过实际上并非信道利用率越高越好。根据排队理论，当信道利用率过高（例如接近100%）时，会导致分组在路由器队列中等待的时间（即排队时延）急剧增加，网络性能（总时延）会严重恶化，甚至导致大量丢包。\r\n时延带宽积 (Delay-Bandwidth Product):\r\n这是一个表示容量的复合指标，它等于传播时延与信道带宽的乘积\r\n计算公式：时延带宽积 (bit) = 传播时延 (s)× 带宽 (b/s)\r\n我们可以将链路想象成一个圆柱形管道： - 管道的长度 =\r\n传播时延（数据通过管道所需的时间） - 管道的横截面积 =\r\n带宽（单位时间能塞入多少数据） - 时延带宽积 =\r\n管道的容积（这条链路最多能容纳多少比特）\r\n往返时延 (Round-Trip Time, RTT): RTT\r\n是指从发送端发送一个短分组开始，到发送端接收到来自接收端的确认分组为止，所经历的总时间,\r\n它是衡量网络响应速度和进行交互式应用（如网页浏览、在线游戏）时非常重要的指标\r\n需要注意的是,\r\n它并不仅仅*是“传播时延的两倍”。一个完整的RTT至少包括：去程的传播时延 +\r\n接收端的处理时延（用于生成确认）+ 确认分组的发送时延（通常很短）+\r\n回程的传播时延.\r\n在实际的互联网中，RTT还包含了数据分组和确认分组在所有中间路由器上所经历的处理时延和排队时延。因此，RTT通常是一个动态变化的值。\r\n时延\r\n在计算机网络中，时延 (Delay)\r\n是一个核心的性能指标。它指的是一个数据单元（例如一个报文或一个分组）从网络（或链路）的一端传输到另一端所需要的总时间。\r\n这个总时延 (T总)\r\n并不是单一因素决定的，而是由以下四个主要部分构成的：\r\nT总 = T发送 + T传播 +\r\nT处理 + T排队\r\n发送时延 (Transmission Delay)\r\n定义：发送时延，也常被称为传输时延，是指网络节点（如主机或路由器）将一个分组的所有比特”推送”到通信链路（如光纤、网线）上所花费的时间，从第一个Bit开始发送，到最后一个Bit发送完成。\r\n计算公式：\r\nT发送 = 分组长度 (bit) / 发送速率 (bit/s)\r\n这个时延取决于分组的大小和链路的发送速率（也称为带宽）。\r\n传播时延 (Propagation Delay)\r\n定义：传播时延是指电磁波（或光信号）在信道（传输介质）中传播一定距离所花费的时间。通俗地说，就是一个比特从链路的始端传播到末端所需的时间。\r\n计算公式：\r\nT传播 = 信道长度 (m) / 电磁波在信道上的传播速率 (m/s)\r\n从公式中可以看出，这个时间与分组有多大、发送速率有多快无关。\r\n处理时延 (Processing Delay)\r\n定义：指分组到达交换节点（如路由器）时，节点为进行存储转发而进行一系列必要处理所花费的时间。\r\n路由器不是一个简单的”直通”管道。它必须对收到的每个分组进行分析才能决定下一步做什么。处理内容包括：\r\n- 检查分组首部：分析目标地址、协议类型等信息 -\r\n差错校验：检查分组在传输过程中是否出现损坏 -\r\n查找路由：根据目标地址查询本地路由表，确定将分组转发到哪一个输出端口\r\n在现代高速路由器中，处理时延通常非常短（在微秒或更低的级别）。\r\n排队时延 (Queuing Delay)\r\n定义：指分组在路由器的输入队列或输出队列中排队等待所花费的时间。\r\n因为当多个分组同时到达，而路由器无法立即处理它们时（例如，多个输入链路的分组都要转发到同一个正忙的输出链路），这些分组就必须排队等待。\r\n其特点是： - 排队时延是四个时延中唯一一个高度可变的 -\r\n它完全取决于网络的拥塞状况 - 如果网络非常空闲，排队时延可能接近于0 -\r\n如果网络非常拥塞，排队时延可能会变得非常大，成为总时延中最主要的部分，甚至导致路由器缓存溢出而发生丢包\r\n(Packet Loss)\r\n计算机网络分层结构\r\n计算机网络的分层结构是一种将复杂的网络通信任务划分为多个独立层次的设计方法。每一层都负责特定的功能，并通过定义良好的接口与相邻层进行交互。\r\n其基本原则是: - 分层：每一层都执行一组明确定义的功能。 -\r\n服务提供：每一层都为其紧邻的上一层提供服务，同时隐藏了实现该服务的具体细节。\r\n-\r\n对等通信：不同计算机上的同一层（称为对等层）之间似乎在直接通信。实际上，这种通信是通过下层提供的服务来实现的，并由该层的协议来规范。\r\n这里有几个概念需要区分:\r\n服务 (Service):\r\n是下层通过层间接口向上层提供的功能。它描述了某一层能为它的上一层做什么。服务的核心在于功能抽象。上层不需要关心下层是如何实现这些功能的，只需要知道如何使用这些功能即可。\r\n例如,\r\n传输层为应用层提供“可靠的数据传输服务”。应用层（如网页浏览器）只需要请求传输层发送数据，并相信数据会准确无误地到达目的地，而不需要关心传输层是如何通过确认、重传等机制来保证可靠性的。\r\n接口 (Interface):\r\n接口是同一台计算机上相邻两个层次之间的交互点。它定义了上层如何访问下层所提供的服务。它规定了一套操作和参数，用于在层与层之间传递控制信息和数据。\r\n可以将其看作是一个软件函数库的API（应用程序编程接口）。传输层会提供像\r\nsend() 和 receive()\r\n这样的函数调用作为接口，供应用层来使用它的数据传输服务。\r\n协议 (Protocol):\r\n协议是控制不同计算机上对等实体（Peer\r\nEntities，即不同机器上的同一层）之间通信的一组规则。它规定了通信双方需要共同遵守的格式、顺序和操作，确保它们能够正确地理解对方发送的信息。协议是水平的，服务和接口是垂直的。\r\n协议三要素： - 语法\r\n(Syntax)：数据与控制信息的结构或格式。例如，HTTP协议规定一个HTTP请求报文必须包含请求行、请求头和请求体。\r\n- 语义\r\n(Semantics)：需要发出何种控制信息，完成何种动作以及做出何种应答。例如，规定收到一个特定的状态码（如404）代表“未找到资源”。\r\n- 时序\r\n(Timing)：事件实现的顺序。例如，规定发送方发送数据后，必须在多长时间内收到接收方的确认。\r\n计算机网络的两种参考模型\r\n\r\n\r\nalt text\r\n\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"条款5：优先选用 auto, 而非显式型别声明","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/auto/%E6%9D%A1%E6%AC%BE5%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20auto,%20%E8%80%8C%E9%9D%9E%E6%98%BE%E5%BC%8F%E5%9E%8B%E5%88%AB%E5%A3%B0%E6%98%8E/","content":"在现代C++开发中, auto\r\n关键字通过要求初始化、正确推导类型以及适应代码重构，避免了许多由于显式类型声明而导致的微妙的正确性和效率问题,\r\n应当作为大部分情况下的首选项来使用。\r\nstd::function\r\nstd::function 是 C++11 引入的一个非常强大且核心的工具，位于\r\n 头文件中。\r\n它是一个通用的、多态的函数包装器。它的核心价值在于，它可以用一个统一的类型来存储、传递和调用任何符合特定函数签名的“可调用对象”。\r\nstd::function 是什么？\r\n在 C++ 中，“可调用对象”（Callable Object）有多种形式，例如：\r\n\r\n普通函数\r\n函数指针\r\nLambda 表达式\r\n函数对象（Functor，即重载了 operator() 的类实例）\r\n类的成员函数（需要绑定到特定对象实例上）\r\n\r\nstd::function\r\n是一个类模板，它提供了一个统一的类型来“包装”所有这些不同类型的可调用对象，只要它们的调用签名（即参数列表和返回值类型）相匹配,\r\n例如: #include &lt;functional&gt;// 定义一个 std::function 变量 'func'// 它可以持有任何“接受一个 int 和一个 double，并返回一个 bool”的可调用对象std::function&lt;bool(int, double)&gt; func;\r\n为什么需要 std::function？\r\n在 C++11\r\n之前，存储不同类型的可调用对象非常困难，因为它们各自拥有完全不同的、不兼容的\r\nC++ 类型：函数指针的类型是 R(*)(Args…); 每个 Lambda\r\n表达式都有一个由编译器生成的、独一无二的匿名闭包类型;\r\n每个函数对象都有其自定义的类类型（例如 MyFunctor）。\r\n如果没有 std::function，我们无法创建一个变量或一个容器（如\r\nstd::vector）来同时持有上述这些不同类型的对象，即使它们的调用签名完全相同。\r\n而 std::function 提供了单一的、具体的类型（例如\r\nstd::function&lt;void(int)&gt;），它可以持有任何符合 void(int)\r\n签名的可调用物。它实现了“类型擦除”（Type\r\nErasure）机制，隐藏了底层可调用对象的原始类型，只暴露统一的调用接口。\r\n使用示例\r\n假设我们需要一个可以执行“接受一个 int 并返回 bool”操作的包装器,\r\n我们可以让 myFunc 持有以下任何一种对象。 std::function&lt;bool(int)&gt; myFunc;// 1. 普通函数bool isEven(int x) {    return x % 2 == 0;}myFunc = isEven;  // 这里 myFunc 直接持有了函数 isEven 的指针。std::cout &lt;&lt; \"函数调用: \" &lt;&lt; myFunc(10) &lt;&lt; std::endl; // 输出 1 (true)// 2. Lambda 表达式（可以带状态）int divisor = 3;auto isDivisible = [divisor](int x) -&gt; bool {    return x % divisor == 0;};myFunc = isDivisible;  // 这是 std::function 最强大的用途之一。它能够存储 Lambda 表达式，包括 Lambda 捕获的状态（这里捕获了 divisor）。std::cout &lt;&lt; \"Lambda 调用: \" &lt;&lt; myFunc(9) &lt;&lt; std::endl; // 输出 1 (true)// 3. 函数对象struct IsGreaterThan {    int limit;    IsGreaterThan(int val) : limit(val) {}    bool operator()(int x) const {        return x &gt; limit;    }};IsGreaterThan comparator(100);myFunc = comparator;  // std::function 会在内部存储 comparator 对象的一个副本（或移动后的版本）。std::cout &lt;&lt; \"Functor 调用: \" &lt;&lt; myFunc(101) &lt;&lt; std::endl; // 输出 1 (true)\r\n最后, 需要注意的是 std::function\r\n不是零成本抽象。为了实现类型擦除和存储任意可调用对象（特别是带状态的\r\nLambda），它通常需要在堆上进行动态内存分配（尽管许多实现带有“小缓冲区优化”(SBO)\r\n来避免对小型对象的堆分配）。\r\n且调用 std::function\r\n通常涉及一次间接函数调用（类似于虚函数调用），这比直接函数调用或模板化的函数调用要慢。\r\nauto可以解决未初始化变量问题\r\n在 C++ 中，显式声明类型允许变量不被初始化，这可能导致不确定的行为。而\r\nauto\r\n通过类型推导工作，它必须从变量的初始化物中推导类型。这就带来一个巨大的优势：使用\r\nauto 声明的变量必须被初始化，否则代码将无法通过编译。 int x; // 有潜在的未初始化风险auto x; // 编译错误！必须有初始化物auto x = 0; // 没问题，x 被明确定义\r\n这从根本上消除了一整类由于忘记初始化而导致的问题。\r\nauto处理冗长及编译器才知的类型\r\nauto\r\n可以极大地简化代码，特别是当类型名称非常冗长或难以书写时。例如，在 C++98\r\n中获取迭代器所指向的值的类型非常繁琐, 而使用 auto，代码变得清晰简洁：\r\ntypename std::iterator_traits&lt;It&gt;::value_type currValue = *b;auto currValue = *b;\r\n更重要的是，有些类型只有编译器知道，开发者根本无法显式写出，最典型的例子就是\r\nlambda 表达式生成的闭包 (closure) 类型。auto\r\n是存储闭包的理想且唯一直接的方式。\r\n当然, 虽然可以使用 std::function 来存储闭包，但这与 auto\r\n相比存在显著差异：\r\n\r\nauto：使用 auto\r\n声明的、存储闭包的变量与该闭包是同一类型，它占用的内存量与闭包完全相同。\r\nstd::function：这是一个模板的实例，它占有固定尺寸的内存。如果这个尺寸对于它要存储的闭包不够用，std::function\r\n的构造函数会分配堆内存来存储该闭包。\r\n\r\n因此，std::function 的方法通常比 auto\r\n方法占用更多内存，速度更慢（可能导致堆分配和间接函数调用），而 auto\r\n则避免了这些开销。\r\nauto避免“类型捷径”带来的正确性与效率问题\r\n这是优先选用 auto\r\n最有力的论据之一。开发者在显式指定类型时，有时会不经意间写下“错误”的类型，这可能导致隐式类型转换，从而引发正确性或效率问题。auto\r\n可以保证推导出正确的类型。\r\n一个示例是下面的v.size() 与 unsigned 的陷阱:\r\n标准规定 std::vector::size() 返回的类型是\r\nstd::vector::size_type。但在实际编码中，很多程序员会“偷懒”地将其存储在\r\nunsigned 中。\r\nstd::vector&lt;int&gt; v;unsigned sz = v.size(); // 显式类型，但可能不正确\r\n这种写法存在移植性问题。例如，在32位 Windows 上，unsigned 和\r\nstd::vector::size_type 都是32位；但在64位 Windows 上，unsigned\r\n仍然是32位，而 size_type 却是64位。如果容器中的元素超过 232 − 1，这段代码在64位系统上就会表现异常。\r\n使用 auto 则完全避免了这个问题，它保证推导出正确的类型：\r\nauto sz = v.size(); // 正确，sz 的类型是 std::vector&lt;int&gt;::size_type\r\n还有个示例是遍历 std::unordered_map 的陷阱:\r\n在遍历 std::unordered_map 时，很多程序员会写出如下代码：\r\nstd::unordered_map&lt;std::string, int&gt; m;for (const std::pair&lt;std::string, int&gt;&amp; p : m) {    // ...} 这段代码看起来完全合理，但其实是错误的。std::unordered_map\r\n中键值对的实际类型是 std::pair&lt;const std::string, int&gt;（因为键是\r\nconst 的），这与循环变量 p 的类型 std::pair&lt;std::string, int&gt;\r\n并不匹配。\r\n为了让代码通过编译，编译器会在循环的每次迭代中，复制哈希表中的元素来创建一个临时对象，然后将引用\r\np 绑定到那个临时对象上。这会导致不必要的复制开销，而且如果对 p\r\n取址，得到的将是一个指向临时对象的指针。\r\n使用 auto 可以轻松解决这个微妙的错误： for (const auto&amp; p : m) {    // ...} auto\r\n会被正确推导为 std::pair&lt;const std::string, int&gt;，引用 p\r\n会被直接绑定到 map 中的元素，既高效又正确。\r\n同时, 使用 auto\r\n的代码更具适应性。如果一个函数的返回类型发生了变化（例如，从 int 改为\r\nlong），调用该函数并将结果存储在 auto\r\n变量中的客户端代码，在下次编译时会自动更新变量类型。如果代码显式指定了\r\nint，则需要开发者手动查找并修改所有调用点。\r\n\r\n最后, 虽然有些开发者担心 auto\r\n会降低代码的可读性（因为无法一眼看出类型），但现代 IDE\r\n通常可以显示推导出的类型。而且在很多情况下，了解变量的抽象概念（例如它是一个“容器”或“计数器”）比知道它的精确类型更重要，这可以通过良好的变量命名来传达。\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款6：auto 推导的型别不符合要求时，使用带显式型别的初始化物习惯用法","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/auto/%E6%9D%A1%E6%AC%BE6%20-%20%20auto%20%E6%8E%A8%E5%AF%BC%E7%9A%84%E5%9E%8B%E5%88%AB%E4%B8%8D%E7%AC%A6%E5%90%88%E8%A6%81%E6%B1%82%E6%97%B6%EF%BC%8C%E4%BD%BF%E7%94%A8%20%E5%B8%A6%E6%98%BE%E5%BC%8F%E5%9E%8B%E5%88%AB%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E7%89%A9%E4%B9%A0%E6%83%AF%E7%94%A8%E6%B3%95/","content":"虽然 auto\r\n是一个强大的工具（如条款5所述），但它推导出的类型有时会与程序员的直觉或意图不符。这种情况尤其容易发生在涉及“隐形”代理类（proxy\r\nclass）的表达式中。\r\n\r\n什么是代理类: 在 C++ 中，代理类（Proxy\r\nClass）是一种设计模式的实现，属于结构型设计模式的一种。它的主要作用是为某个对象提供一个替代者或中介，以控制对该对象的访问。这个模式被称为代理模式（Proxy\r\nPattern）。广为人知的std::shared_ptr即是这一类\r\n\r\nauto遇到代理类\r\n下面使用 std::vector 作为核心示例。假设我们有一个函数返回\r\nstd::vector，并且我们想获取第五个元素, 下面的代码可以正常运行。\r\nstd::vector&lt;bool&gt; features(const Widget&amp; w);Widget w;bool highPriority = features(w)[5]; // 显式声明类型为 boolprocessWidget(w, highPriority); // 正常运行 然而，如果只是简单地将 bool 替换为\r\nauto，就会导致未定义行为： auto highPriority = features(w)[5]; // 类型推导processWidget(w, highPriority); // 未定义行为！ 究其原因,\r\n在于使用auto推断遇到了std::vector的代理类, 而不是bool类型。\r\nstd::vector\r\n是标准库中的一个特化版本，它为了节省空间，将每个布尔值存储为一个比特位。由于\r\nC++ 禁止对单个比特位（bit）进行引用，因此 std::vector 的\r\noperator[] 并不会返回 bool&amp;。相反，它返回一个扮演 bool&amp;\r\n角色的代理类对象，这个类的类型是 std::vector::reference。\r\n这个 std::vector::reference 代理对象被设计为可以隐式转换为\r\nbool（即它所代表的比特位的值）。对于前一类代码bool highPriority = ...，在这行代码中，features(w)[5]\r\n返回一个 std::vector::reference 对象。为了初始化 bool 类型的变量\r\nhighPriority，这个代理对象会执行向 bool\r\n的隐式类型转换。因此，highPriority 得到了第5个比特位的值，一切正常。\r\n而在后者中, features(w) 返回的是一个临时对象 (一个右值\r\nstd::vector)。且operator[] 返回的 std::vector::reference\r\n代理对象（现在被 highPriority\r\n持有）其内部实现通常包含一个指向那个临时向量所管理的机器字的指针。在\r\nauto highPriority = ... 这条语句的末尾，features(w)\r\n返回的临时 std::vector 对象被析构了。这导致\r\nhighPriority（那个代理对象）现在内部持有一个空悬指针 (dangling\r\npointer)。当这个含有空悬指针的 highPriority 对象在后续代码（如\r\nprocessWidget）中被使用时，就会产生未定义行为。\r\n因此,\r\n我们要避免写出auto someVar = 隐形”代理型别表达式的代码。\r\n### 解决方案：带显式型别的初始化物习惯用法\r\nauto\r\n本身并不是问题所在；问题在于它推导出的类型（代理类）不是我们想要的类型（值\r\nbool）。\r\n条款6提出的解决方案是继续使用 auto，但通过显式类型转换来“引导” auto\r\n推导出我们想要的类型。这种方法被称为“带显式型别的初始化物习惯用法”（explicitly\r\ntyped initializer idiom）。\r\n// 通过 static_cast&lt;bool&gt;(...) 强制调用该代理对象的向 bool 的类型转换运算符auto highPriority = static_cast&lt;bool&gt;(features(w)[5]);\r\n这种习惯用法不仅限于解决代理类问题，它还可以用来明确表达程序员的意图，使那些故意的类型转换在代码中更加清晰可见\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款32：使用初始化捕获将对象移入闭包","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE32%20-%20%E4%BD%BF%E7%94%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E6%8D%95%E8%8E%B7%E5%B0%86%E5%AF%B9%E8%B1%A1%E7%A7%BB%E5%85%A5%E9%97%AD%E5%8C%85/","content":"在 C++11 中，lambda 的捕获列表 [] 只能捕获在 lambda\r\n所在作用域内可见的变量，捕获方式只有两种：按值复制或按引用。这导致了一个问题：C++11\r\n无法直接将对象“移动”到闭包中。\r\n这个局限对两类对象影响很大：\r\n\r\n只移类型 (Move-only Types)：像\r\nstd::unique_ptr、std::future 或 std::thread\r\n这样的类型，它们是不能被复制的。因此，在 C++11 中，你无法将它们捕获到\r\nlambda 闭包中。\r\n复制成本高昂的类型：像 std::vector 或\r\nstd::string\r\n这样的大多数标准库容器，复制它们的成本可能很高，但移动它们的成本却很低。在\r\nC++11\r\n中，如果你想在闭包中拥有一份容器的副本，你只能付出高昂的复制代价。\r\n\r\n这个问题就是下面介绍的初始化捕获所要解决的\r\nC++14 解决方案：初始化捕获\r\n(Init Capture)\r\nC++14 引入了一种全新的、更强大的捕获机制，被称为初始化捕获，也叫广义\r\nlambda 捕获 (generalized lambda capture)。它彻底解决了 C++11\r\n的局限。\r\n初始化捕获允许你做两件事：在 lambda\r\n生成的闭包类中，指定一个新成员变量的名字;\r\n提供一个表达式，用于初始化该成员变量。\r\n语法为：[新变量名 = 初始化表达式]\r\n下面是利用初始化捕获实现移动捕获的一个例子： auto pw = std::make_unique&lt;Widget&gt;();// C++14: 使用初始化捕获，将 pw 移动到闭包的新成员 pw 中auto func = [pw = std::move(pw)] {     return pw-&gt;isValidated() &amp;&amp; pw-&gt;isArchived(); }; pw =\r\nstd::move(pw) 的含义是：在闭包中创建一个名为 pw 的新成员，并用\r\nstd::move(pw) 的结果来初始化它。等号左侧的 pw 是闭包的成员，而右侧的 pw\r\n是外部作用域的局部变量。\r\n此外, 初始化捕获甚至能“捕获”一个表达式的结果，这是 C++11\r\n捕获完全做不到的： // C++14: 直接用表达式的结果初始化闭包成员auto func = [pw = std::make_unique&lt;Widget&gt;()] {    return pw-&gt;isValidated() &amp;&amp; pw-&gt;isArchived();};\r\nC++11 的变通方案：使用\r\nstd::bind 模拟\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款31：避免默认捕获模式","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE31%20-%20%E9%81%BF%E5%85%8D%E9%BB%98%E8%AE%A4%E6%8D%95%E8%8E%B7%E6%A8%A1%E5%BC%8F/","content":"lambda 表达式\r\nLambda 表达式（Lambda\r\nExpression）是一种在需要函数的地方，可以就地定义匿名函数对象的便捷方式。它本质上是一个可调用的代码单元，可以像函数一样使用，但无需为其命名(当然也可以为其命名)。它允许你编写简短、内联的函数，特别适用于作为算法或异步调用的参数，从而让代码更简洁、更具表现力。\r\n为何需要 Lambda？\r\n在 C++11 之前，如果你想向一个算法（如 std::sort 或\r\nstd::find_if）传递自定义逻辑，通常有两种方法：定义一个独立的函数或者定义一个函数对象（Functor）\r\n// 定义函数, 缺点：函数定义与调用点分离，降低了代码的可读性；可能会污染命名空间。bool isOdd(int n) {    return n % 2 != 0;}// ...std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), isOdd);// 定义函数对象, 缺点：语法非常冗长，为了一个简单的操作就需要定义一个完整的类。struct IsOddFunctor {    bool operator()(int n) const {        return n % 2 != 0;    }};// ...std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), IsOddFunctor()); Lambda 表达式正是为了解决这些问题而生的。\r\n它允许你将执行逻辑直接写在调用的地方： std::vector&lt;int&gt; numbers = {1, 2, 3, 4, 5};auto it = std::find_if(numbers.begin(), numbers.end(), [](int n) {    return n % 2 != 0;});\r\n这样做代码紧凑、逻辑清晰，定义与使用紧密相连\r\n语法解析\r\nLambda 表达式的完整语法结构如下： capture\r\nspecifiers -&gt; return_type { body },\r\n其中很多部分是可选的。我们来逐一分解：\r\n\r\n捕获列表 (Capture Clause) 这是\r\nLambda 表达式最强大的功能之一。它定义了 Lambda\r\n函数体内部可以访问哪些来自其外部作用域的变量，以及如何访问它们。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n捕获方式\r\n说明\r\n\r\n\r\n\r\n\r\n[]\r\n不捕获任何外部变量。\r\n\r\n\r\n[=]\r\n按值捕获 (by\r\ncopy)。所有外部变量都以只读副本的形式在函数体内可用。\r\n\r\n\r\n[&amp;]\r\n按引用捕获 (by\r\nreference)。所有外部变量都以引用的形式在函数体内可用，可以修改。\r\n\r\n\r\n[this]\r\n捕获 this 指针。允许在 Lambda\r\n体内访问当前对象的成员变量和函数。\r\n\r\n\r\n[a, &amp;b]\r\n显式捕获。只捕获变量 a（按值）和 b（按引用）。\r\n\r\n\r\n[=, &amp;b]\r\n混合捕获。默认按值捕获，但显式指定 b 按引用捕获。\r\n\r\n\r\n[&amp;, a]\r\n混合捕获。默认按引用捕获，但显式指定 a 按值捕获。\r\n\r\n\r\n[val = expr] (C++14+)\r\n带初始化的捕获（或称广义捕获）。允许创建一个新的变量 val 并用 expr\r\n初始化，该变量仅在 Lambda 体内可见。这对于移动捕获（move\r\ncapture）尤其重要。\r\n\r\n\r\n\r\n需要注意的是, [&amp;] 和 [=] 被称为默认捕获模式 (Default Capture\r\nModes)。当你在捕获列表中使用它们而不指名具体变量时，就为\r\nLambda 设定了一个“自动捕获”的规则, 所有外部的变量都会在使用时被自动捕获.\r\n这个规则在提供便利的同时也可能导致一些问题, 这就是这一讲所提出的.\r\n\r\n全局变量 (Global variables)和静态变量 (Static variables)不需要被捕获,\r\n因为它们已经在全局作用域中定义, 可以直接在 Lambda 表达式中使用。\r\n\r\n\r\n( ) 参数列表 (Parameter List) 与普通函数的参数列表完全相同。如果\r\nLambda 不需要参数，() 可以省略（但如果使用了 mutable 或 -&gt;\r\nreturn_type，则不能省略）。 []() { std::cout &lt;&lt; \"No params.\" &lt;&lt; std::endl; }[](int x, int y) { return x + y; }\r\nspecifiers (可选) 说明符\r\n\r\n\r\nmutable：默认情况下，对于按值捕获的变量，Lambda\r\n体内不能修改它们（它们是 const 的副本）。使用 mutable\r\n关键字可以取消这个限制，允许你修改这些副本。 int count = 0;auto counter = [count]() mutable {    count++; // OK with mutable    std::cout &lt;&lt; count &lt;&lt; std::endl;};counter(); // 输出 1counter(); // 输出 2std::cout &lt;&lt; count &lt;&lt; std::endl; // 仍然输出 0，因为修改的是副本\r\nnoexcept, constexpr (C++17+)\r\n等：与普通函数类似，用于指定异常规范或编译期求值。\r\n\r\n\r\n-&gt; return_type (可选) 返回类型\r\n通常情况下，编译器可以根据函数体中的 return 语句自动推导出 Lambda\r\n的返回类型。因此，这个部分是可选的。\r\n只有在少数复杂情况下（例如期望的返回类型与推导出的不同且可以通过转换实现），才需要显式指定返回类型。\r\n// 自动推导返回类型为 double[](double a) { return a * 1.5; }// 显式指定返回类型为 double[](int a) -&gt; double {    if (a &gt; 0) return a;    return 0.0; // 多个返回语句，但类型可统一推导}\r\n{ } 函数体 (Function Body): Lambda\r\n表达式的具体执行代码，与普通函数的函数体一样。\r\n\r\nLambda 的本质：闭包 (Closure)\r\n理解 Lambda 的关键在于知道它在底层是如何工作的。每当你写下一个 Lambda\r\n表达式，编译器都会自动生成一个唯一的、匿名的类类型，这个类被称为“闭包类型”（Closure\r\nType）。\r\nLambda\r\n表达式本身创建了一个该类型的对象，称为“闭包对象”。这个闭包类重载了\r\noperator()，使得其对象可以像函数一样被调用。函数体就是 Lambda\r\n的 {} 中的代码。\r\n而所有被捕获的变量，都会成为这个闭包类的成员变量。\r\n\r\n按值捕获 [x] -&gt; 成为成员变量 int x;\r\n按引用捕获 [&amp;y] -&gt; 成为成员变量 int&amp; y;\r\n\r\n例如, 以下lambda表达式会生成这样的闭包类: int x = 10;int y = 20;auto my_lambda = [x, &amp;y](int z) { y = x + z; };// 编译器生成的（概念上的）等价物class __Lambda_XYZ_Compiler_Generated {public:    // 构造函数捕获变量    __Lambda_XYZ_Compiler_Generated(int x_val, int&amp; y_ref)        : x(x_val), y(y_ref) {}    // 重载 operator()    void operator()(int z) const {        y = x + z; // 在函数体内使用成员变量    }private:    int x;   // 按值捕获的成员    int&amp; y;  // 按引用捕获的成员};// 创建闭包对象auto my_lambda = __Lambda_XYZ_Compiler_Generated(x, y);\r\n应用场景\r\n\r\n配合 STL 算法（最常见的用途） #include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;std::vector&lt;int&gt; v = {5, -1, 42, 8, 7};// 1. 自定义排序int factor = 10;std::sort(v.begin(), v.end(), [factor](int a, int b) {    // 按与 factor 的距离排序    return std::abs(a - factor) &lt; std::abs(b - factor);});// 2. 查找第一个满足条件的元素auto it = std::find_if(v.begin(), v.end(), [](int n) {    return n &gt; 40;});if (it != v.end()) {    std::cout &lt;&lt; \"Found: \" &lt;&lt; *it &lt;&lt; std::endl; // 输出 Found: 42}// 3. 遍历std::for_each(v.begin(), v.end(), [](int n){    std::cout &lt;&lt; n &lt;&lt; \" \";});\r\n泛型 Lambda (C++14): 使用 auto 关键字作为参数类型，可以让 Lambda\r\n成为一个模板 auto generic_add = [](auto a, auto b) {    return a + b;};int sum_int = generic_add(5, 3);          // 8double sum_double = generic_add(1.5, 2.5);  // 4.0std::string s1 = \"hello\", s2 = \" world\";std::string s3 = generic_add(s1, s2); // \"hello world\"\r\n带初始化的捕获 (C++14): 对于移动（move）一个只能移动的对象（如\r\nstd::unique_ptr）到 Lambda 内部非常有用 #include &lt;memory&gt;auto ptr = std::make_unique&lt;int&gt;(100);// 将 ptr 的所有权移入 Lambdaauto my_lambda = [p = std::move(ptr)]() {    std::cout &lt;&lt; \"Value inside lambda: \" &lt;&lt; *p &lt;&lt; std::endl;};my_lambda();// 此处 ptr 已经是 nullptr，因为所有权已经移交\r\n\r\n避免默认捕获模式\r\n回到标题, 该条款的核心论点是，C++11\r\n提供的两种默认捕获模式——按引用默认捕获 [&amp;] 和 按值默认捕获 [=]\r\n都存在风险，应当避免使用。取而代之的，是显式捕获（explicit\r\ncapture），即明确列出 lambda\r\n表达式所依赖的所有外部变量\r\n按引用默认捕获 ([&amp;])\r\n的风险：悬垂引用\r\n这是最直接也最危险的问题。按引用捕获会导致闭包（lambda\r\n表达式创建的运行时对象）包含指向局部变量或函数参数的引用。如果闭包的生命周期超过了这些局部变量或参数的生命周期，那么闭包内的引用就会悬垂\r\n(dangle)。\r\n假设我们有一个全局的过滤器(函数)容器，一个函数\r\naddDivisorFilter 用于向其中添加一个过滤器。 using FilterContainer = std::vector&lt;std::function&lt;bool(int)&gt;&gt;; // 函数包装器可以存储任何可调用对象FilterContainer filters;void addDivisorFilter() {    auto divisor = computeDivisor(); // divisor 是一个局部变量        // 危险！[&amp;] 捕获了对局部变量 divisor 的引用    filters.emplace_back(        [&amp;](int value) { return value % divisor == 0; }    );} // divisor 在这里被销毁 当\r\naddDivisorFilter 函数返回时，其局部变量 divisor\r\n会被销毁。然而，被添加到全局容器 filters 中的 lambda\r\n闭包仍然存在，并且它内部包含一个指向已被销毁的 divisor\r\n内存地址的引用。任何后续对这个过滤器的调用都将导致未定义行为。 在此时,\r\n显式写出 [&amp;divisor] 比 [&amp;] 更安全。因为它清晰地表明了这个 lambda\r\n的生存依赖于 divisor\r\n的生命周期，迫使开发者去思考和确认这个依赖是安全的。而 [&amp;]\r\n则会隐藏这种依赖关系。\r\n按值默认捕获 ([=]) 的风险\r\n按值默认捕获 [=] 看起来似乎可以解决悬垂引用的问题，并让 lambda\r\n变得“自洽”，但这种想法是具有误导性的，并隐藏着两个主要的陷阱。 #####\r\n陷阱一：悬垂指针（this 指针陷阱）\r\n按值捕获一个指针，只是复制了指针本身，而不是它所指向的对象。如果指针所指向的对象被销毁，闭包中持有的指针副本同样会变成悬垂指针。\r\n这个问题在类的成员函数中尤其隐蔽，因为 [=]\r\n会隐式地捕获 this 指针。 class Widget {public:    void addFilter() const;private:    int divisor;};void Widget::addFilter() const {    // [=] 看起来是按值捕获，但实际上是按值捕获了 this 指针    filters.emplace_back(        [=](int value) { return value % divisor == 0; }    );}void doSomeWork() {    auto pw = std::make_unique&lt;Widget&gt;();    pw-&gt;addFilter(); // 添加了一个依赖 *pw 的过滤器} // pw 在这里被销毁, 但这个指针的值 (即指向 Widget 对象的指针) 已经被复制到了 lambda 闭包中 在 addFilter\r\n中，divisor 是一个成员变量，它无法被直接捕获。为了在 lambda 内部访问\r\ndivisor（实际上是 this-&gt;divisor），[=] 捕获的是this\r\n指针的副本。\r\n而当doSomeWork 函数返回时，pw 所指向的 Widget 对象被销毁。但 filters\r\n容器中的 lambda 闭包仍然存在，并且它内部持有一个指向已被销毁的 Widget\r\n对象的 this 指针。这同样导致了悬垂指针和未定义行为。\r\n陷阱二：“自洽”的假象\r\n[=]\r\n模式给人的感觉是，闭包复制了它所需的一切，因此是完全独立、自洽的。这是错误的。\r\n[=] 不会捕获静态存储期的变量。如果 lambda\r\n使用了全局变量、static 局部变量或\r\nstatic\r\n成员变量，它只是直接引用这些变量，而不会在闭包中创建其副本。\r\nvoid addDivisorFilter() {    static auto divisor = computeDivisor(); // divisor 是静态局部变量        filters.emplace_back(        [=](int value) { return value % divisor == 0; }    );        ++divisor; // 修改静态变量} 这里的 [=] 实际上没有捕获任何东西，因为 divisor 是 static\r\n的。lambda 内部的 divisor 直接引用了那个唯一的静态变量。\r\n每次调用 addDivisorFilter，divisor 的值都会增加。这意味着每次添加到\r\nfilters 中的 lambda 的行为都会因 divisor 的改变而改变，这与 [=]\r\n所暗示的“按值复制、行为固定”的直觉完全相反。\r\n鉴于上述的默认捕获行为的危险性,\r\n最安全的做法是避免使用默认捕获模式，转而显式捕获 lambda\r\n所需的所有变量。这使得代码的依赖关系清晰可见，迫使开发者思考变量的生命周期，从而写出更健壮、更安全的代码。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 23：理解 std::move std::forward","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE23%20-%20%20%E7%90%86%E8%A7%A3%20move%20%E5%92%8C%20forward/","content":"移动语义 (Move Semantics) 和\r\n完美转发 (Perfect Forwarding) 是 C++11\r\n中引入的两个革命性特性，它们共同解决了 C++\r\n中长期存在的资源管理效率和泛型编程（模板）中的参数传递问题。\r\n移动语义 (Move Semantics)\r\n在 C++11\r\n之前，我们只有“拷贝语义”。当我们处理包含堆内存（如指针指向的数据、文件句柄、网络套接字等）的对象时，拷贝操作（通过拷贝构造函数或拷贝赋值运算符）通常意味着“深拷贝”——即分配一块新内存，并将数据完整拷贝过去。\r\n考虑一个返回 std::vector 的函数：\r\nstd::vector&lt;int&gt; create_large_vector() {    std::vector&lt;int&gt; temp_vec(1000000); // 假设分配了大量数据    // ... 填充数据 ...    return temp_vec; // [C++03] 在这里，temp_vec (左值) 将被拷贝到一个“返回值临时对象”(右值)}// [C++03] 调用：std::vector&lt;int&gt; my_vec = create_large_vector(); // [C++03] “返回值临时对象”(右值) 又被拷贝到 my_vec 中。\r\n在 C++03 中，这个过程涉及两次昂贵的深拷贝。但我们知道，函数内的\r\ntemp_vec\r\n和那个“返回值临时对象”在语句结束时都将被销毁。我们其实并不需要拷贝它们内部的数据，我们只需要把数据（即指向堆内存的指针）转移给\r\nmy_vec 就行了。\r\n这个问题的解决方案就是移动语义.\r\n它允许一个对象将其内部资源（如指针）的“所有权”转移\r\n(transfer)\r\n给另一个对象，而不是拷贝它们。这是一种“窃取”或“掠夺”资源的方式，它之所以安全，是因为我们只对那些“即将被销毁”的对象（即右值）执行此操作。\r\n因此,\r\n一个类现在可以定义专门处理右值参数的版本：移动构造函数:\r\nMyClass(MyClass&amp;&amp; other)和移动赋值运算符:\r\nMyClass&amp; operator=(MyClass&amp;&amp; other)\r\n它们的实现逻辑如下：\r\n\r\n窃取资源： 将 other\r\n对象的内部资源（例如，指向数据的指针\r\nother.data_ptr）直接拷贝（浅拷贝）到 this 对象（this-&gt;data_ptr =\r\nother.data_ptr）。\r\n置空源对象： 将 other 原对象的指针设置为\r\nnullptr (other.data_ptr = nullptr;)。\r\n\r\n这是至关重要的安全步骤。因为 other\r\n仍然是一个有效的对象，它在作用域结束时会被析构。如果不将其指针置空，other\r\n的析构函数会释放掉那块内存，导致 this\r\n对象持有一个悬空指针。将其置空后，other 的析构函数调用 delete\r\nnullptr;（这是安全的），而资源的所有权已成功转移给 this。\r\n\r\n\r\nstd::move\r\n对于右值,\r\n编译器会自动调用移动构造函数或移动赋值运算符. 而对于左值,\r\n我们不能直接将一个它传递给一个只接受右值引用的函数（如移动构造函数）。解决方法是,\r\n使用 std::move 来显式请求移动\r\nstd::move\r\n不做任何移动操作。它仅仅是一个强制类型转换：它将其参数（无论左值还是右值）无条件地转换为一个右值引用。\r\n这相当于你对编译器说：“我保证，我不再使用这个左值变量了，请你把它当作一个临时对象（右值）来处理，你可以随意窃取它的资源。”\r\n对于上述示例, 我们可以将 create_large_vector\r\n函数修改为：\r\nstd::vector&lt;int&gt; create_large_vector() {    std::vector&lt;int&gt; temp_vec(1000000); // 假设分配了大量数据    // ... 填充数据 ...    return std::move(temp_vec); // [C++11] 在这里，temp_vec (左值) 将被移动到一个“返回值临时对象”(右值), 因此不会触发深拷贝, 将 O(N) 的资源拷贝操作降维到 O(1) 的指针交换操作。}\r\nstd::move后仅保证右值,\r\n不保证可移动\r\n在 C++ 开发中，我们被教导“尽可能使用\r\nconst”，这是一个良好的编程习惯。同时，为了优化性能，现代\r\nC++（遵循《Effective Modern C++》条款 41\r\n等指导原则）建议我们利用移动语义。然而，当这两个原则被错误地结合时，可能会产生与预期不符的行为。\r\n假设我们正在编写一个 Annotation (注解)\r\n类，它在内部存储一个字符串。根据条款 41\r\n的建议（针对既需要拷贝也需要移动赋值的“sink”参数），我们采用按值传递（pass-by-value）参数，然后将其\r\nstd::move 到数据成员中，以此来高效处理左值（拷贝）和右值（移动）实参\r\n同时, 因为这个构造函数仅仅是读取 text\r\n的值（用于移动），而不会在函数体内对其进行逻辑上的修改。遵循“尽可能使用\r\nconst”的旧习惯，我们将这个按值传递的参数标记为 const：\r\nclass Annotation {public:    // 按值传递 text    explicit Annotation(const std::string text)         : value(std::move(text)) // 将 text 的内容“移动”到 value 中    { }private:    std::string value;};\r\n结果是, 这段代码可以顺利地编译、链接并运行。并且，成员变量 value\r\n最终确实包含了传入的 text 的内容。然而，一个关键的优化丢失了：text\r\n并没有被移动，它被拷贝到了 value 中。\r\n我们迫切想知道, 为什么移动（Move）变成了拷贝（Copy）？\r\n这个行为是 C++ 类型系统和重载解析 (Overload Resolution)\r\n共同作用的结果，并且这种设计对于维持“常量正确性”至关重要。\r\n我们一步一步分析, std::move\r\n本身不执行任何“移动”操作。它是一个无条件的类型转换工具（cast）。它的唯一工作就是将其接收的参数（通常是一个左值）强制转换为一个右值引用（rvalue\r\nreference）\r\n这里的关键点在于，当 std::move 转换一个 const\r\n变量时，其“常量性”（const-ness）会被保留。\r\n在我们的例子中，形参 text 的类型是 const std::string（这是一个左值）;\r\nstd::move(text) 的调用将其转换为右值, 转换的结果类型是const\r\nstd::string&amp;&amp; （一个指向 const std::string 的右值引用）。\r\n当编译器尝试使用这个结果（一个 const 右值）来初始化成员 value (类型为\r\nstd::string) 时，它会检查 std::string\r\n的可用构造函数，主要有两个候选者：\r\nclass string { public:    // 1. 移动构造函数 (Move Constructor)    //    它接受一个“非 const 的”右值引用 (string&amp;&amp;)    string(string&amp;&amp; rhs);     // 2. 拷贝构造函数 (Copy Constructor)    //    它接受一个“const 的”左值引用 (const string&amp;)    string(const string&amp; rhs); };\r\n对于移动构造函数, 我们的参数类型是 const std::string&amp;&amp; (const\r\n右值)。而移动构造函数需要 string&amp;&amp; (非 const 右值)。而C++\r\n不允许将 const 对象绑定到非 const\r\n引用上，因为移动构造函数必须能够修改其参数（例如，将其内部指针设为\r\nnull）, 显然对一个 const 对象执行“窃取”操作是违反常量正确性的。\r\n而对于第二个拷贝构造函数, C++ 语言规则允许一个 const\r\n左值引用（const T&amp;）绑定到一个 const\r\n右值（const T&amp;&amp;）,\r\n所以编译器别无选择，只能调用拷贝构造函数，导致了数据拷贝而非移动。\r\n这个案例带来了两个至关重要的经验：\r\n\r\n不要对计划移动的对象声明 const:\r\n如果你希望能够从一个对象中“移出”数据（即允许该对象被修改并置于一个有效的、但未指定的状态），那么该对象本身绝对不能被声明为\r\nconst。任何对 const\r\n对象的“移动”尝试都会悄无声息地降级为一次“拷贝”操作。\r\nstd::move 不保证“可移动性”: std::move\r\n并不执行移动，它只负责类型转换。它告诉编译器：“请把这个对象当作右值来处理”。它不保证转换后的右值一定能匹配到移动构造函数或移动赋值运算符。如本例所示，如果源对象是\r\nconst，它最终只会匹配到拷贝操作。\r\n\r\n完美转发 (Perfect Forwarding)\r\n完美转发解决的是一个在模板（泛型编程）中遇到的不同问题:\r\n转发时的值类别丢失\r\n假设我们要编写一个“工厂函数”（或任何包装函数），它接受一些参数，然后用这些参数去构造另一个类型的对象（例如\r\nstd::make_unique 或 std::vector::emplace_back）。\r\n\r\n工厂函数（Factory\r\nFunction）是一种封装对象创建过程的函数，它的核心目的是：将对象的构造逻辑从使用者那里抽离出来，让你通过调用一个函数来获得所需的对象，而不需要关心它是如何被创建的。\r\n\r\n我们希望：\r\n\r\n如果工厂函数收到了一个左值，它应该传递一个左值给最终的构造函数（触发拷贝）。\r\n如果工厂函数收到了一个右值，它应该传递一个右值给最终的构造函数（触发移动）。\r\n\r\n// process 根据参数是左值还是右值进行了重载void process(const Widget&amp; lvalArg);  // 处理左值void process(Widget&amp;&amp; rvalArg);        // 处理右值// logAndProcess 是一个函数模板，用于记录日志并转发参数template&lt;typename T&gt;void logAndProcess(T&amp;&amp; param){    // 取得当前时间    auto now = std::chrono::system_clock::now();     makelogEntry(\"Calling 'process'\", now);    // 将 param 完美转发给 process 函数    process(std::forward&lt;T&gt;(param));}// 考虑两种调用 logAndProcess 的情形，一种向其传入左值，一种向其传入右值Widget w;logAndProcess(w);             // 传入左值logAndProcess(std::move(w));  // 传入右值\r\n在 logAndProcess 内，形参 param 被传递给函数 process。而 process\r\n依据其形参是左值还是右值类型进行了重载。所以我们很自然地会期望：\r\n\r\n当调用 logAndProcess 时若传入的是个左值（如 w），则该左值在被传递给\r\nprocess 函数时仍被当作一个左值。\r\n而当调用 logAndProcess 时若传入的是个右值（如\r\nstd::move(w)），则会调用 process 取用右值类型的那个重载版本。\r\n\r\n但是，有一个关键规则：所有（具名的）函数形参皆为左值(即使它是右值引用类型)，param\r\n亦不例外。\r\n\r\n一个值被传递给函数后，在函数内部它就“落地”了，有了一个具体的名字和一块内存。只要有了这两样东西，它就变成了左值，以便在函数体内稳定地使用。\r\n与之不同,\r\n函数返回值的类型情况取决于返回类型如果返回类型是非引用/右值引用,\r\n则返回值是右值; 如果是左值引用则是左值\r\n\r\n因此，如果在 logAndProcess 函数体内只是简单地调用\r\nprocess(param)，那么 process\r\n的所有调用都会调用取用左值类型的那个重载版本（因为 param\r\n本身是左值），即使我们传给 logAndProcess 的是一个右值。\r\n为了避免这种结果，就需要一种机制：当且仅当用来初始化 param\r\n的实参（即传递给 logAndProcess 的实参）是一个右值时，才把 param\r\n强制转换成右值类型。这恰恰就是 std::forward 所做的一切。\r\nstd::forward：有条件的类型转换\r\n这就是为何说 std::forward\r\n是有条件的强制类型转换：仅当它的实参（param）最初是使用一个右值完成初始化时，它才会执行向右值类型的强制类型转换。(也就是说它会”转发”实参的类型保持不变)\r\n你可能会疑惑，std::forward\r\n何以知晓其参数是否通过右值完成初始化？一句话：该信息是被编码到\r\nlogAndProcess(也就是上一层的函数) 的模板形参 T 中的, 该模板参数 T\r\n被传递给 std::forward\r\n后，随即由后者将编码的信息恢复出来，从而决定是返回一个左值引用还是右值引用。\r\n回到 std::forward 本身, 它有两个参数: 模板参数（尖括号里的\r\nT）和函数实参（圆括号里的变量，比如 param）, 其中模板参数T的作用是告诉\r\nstd::forward 调用者传进来的原始实参类型是什么;\r\n而函数实参则是要被转发的对象,\r\n两者结合即可用模板参数还原它的原始值类别。\r\nstd::move 与\r\nstd::forward：语义的明确区分\r\n综上所述, std::move 和 std::forward 都是强制型别转换，唯一不同就在于\r\nstd::move 始终实施强制型别转换，而 std::forward 仅仅有时会实施。\r\n更为重要的是，使用 std::move 和 std::forward\r\n所要传达的语义完全不同：\r\n\r\nstd::move：传达的意思是无条件地向右值类型强制转换。这典型地用于为移动操作做铺垫（“我确定要移动这个对象，请将其视为右值”）。\r\nstd::forward：传达的意思是有条件的强制类型转换（仅仅对绑定到右值的引用实施转换）。这专门用于传递（转发）一个对象到另一个函数，并在此过程中保持该对象原始的左值性\r\n(lvalueness) 或右值性 (rvalueness)。\r\n\r\n这是两个非常不同的行为。这两个行为是如此不同，因而我们最好使用两个不同的函数（以及函数名字）来明确区分这两者。在移动构造函数（或移动赋值运算符）内部，我们确定要将来源对象（rhs）的成员视为右值进行“窃取”，因此我们应该总是使用\r\nstd::move 来表达这种无条件的移动意图。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 24：区分万能引用和右值引用","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE24%20-%20%E5%8C%BA%E5%88%86%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%92%8C%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8/","content":"回忆左值（Lvalue）和右值（Rvalue）\r\n左值（Lvalue）表示一个有名字、可寻址、在表达式结束后仍然存在的对象。其特点是：\r\n\r\n可以出现在赋值语句的左边：x = 5;\r\n可以取地址：&amp;x\r\n通常是变量、数组元素、对象成员、函数形参等\r\n\r\n右值（Rvalue）表示一个临时值，通常在表达式中短暂存在，不能取地址。其特点是：\r\n\r\n只能出现在赋值语句的右边：x = 5;\r\n通常是字面量、临时对象、表达式结果\r\n不具备持久性，生命周期短\r\n可以移动（move），而不能复制（copy）\r\n\r\n基于此, 我们可以得到右值引用 (Rvalue Reference): T&amp;&amp;.\r\n这是一种新的引用类型，用 &amp;&amp;\r\n表示。它有一个关键特性：它只能绑定到右值（临时对象）。这使得我们可以在函数重载时区分传入的是左值还是右值：\r\nvoid foo(const MyClass&amp; obj); // 版本 1: 接受左值 (const引用也可以接受右值，但这是题外话)void foo(MyClass&amp;&amp; obj);      // 版本 2: (C++11 新增) 只接受右值\r\n更进一步地, 右值还可以继续划分: 右值 (rvalue) =\r\n纯右值 (prvalue) + 将亡值 (xvalue)\r\n其中纯右值是没有名字的临时值或返回非引用的函数,\r\n而将亡值特指资源即将被销毁的对象，通常是右值引用表达式即std::move(obj)或者返回T&amp;&amp;类型的函数返回值.\r\n万能引用（Universal\r\nReference）/ 转发引用（Forwarding Reference）\r\n万能引用（转发引用）是一种特殊的引用，它既可以绑定到左值，也可以绑定到右值。它在语法上看起来与右值引用完全相同（都是使用\r\n&amp;&amp;），但它只在非常特定的上下文中出现，并且遵循一套完全不同的类型推导规则。\r\n一个参数要成为“万能引用”，必须同时满足以下两个条件：\r\n\r\n必须涉及模板类型推导或者auto类型推导：\r\n这个引用必须依赖于一个正在被推导的模板参数T或者auto。\r\n参数的声明形式必须是 T&amp;&amp;：\r\n必须是这个精确的形式。不能有\r\nconst，也不能是其他任何形式。\r\n\r\nvoid f(Widget&amp;&amp; param);   // 没有类型推导，是右值引用Widget&amp;&amp; var1 = Widget();  // 右值引用auto&amp;&amp; var2 = var1;    // auto类型推导, 是万能引用template&lt;typename T&gt; void f(std::vector&lt;T&gt;&amp;&amp; param);   // 非精确形式, 是右值引用std: :vector&lt;int&gt; v; f(v); // 此时会错误！不能给右值引用绑定左值template&lt;typename T&gt; void f(const T&amp;&amp; param);   // 非精确形式, 是个右值引用template&lt;typename T&gt; void f(T&amp;&amp; param); // 模板参数推导+精确形式, 是万能引用Widget w; f(w);               // 传递左值, param为左值引用Widget&amp;f (std::move(w));   // 传递右值, param为右值引用Widget&amp;&amp;\r\n万能引用如何工作：特殊的类型推导与引用折叠\r\n万能引用的“魔力”来自于它在模板类型推导中使用的特殊规则，以及 C++\r\n的引用折叠（Reference Collapsing）规则。\r\n当我们使用\r\ntemplate&lt;typename T&gt; void func(T&amp;&amp; param)\r\n时：\r\n\r\n情况一：传递一个左值\r\n\r\n假设我们有一个左值变量：MyClass widget;\r\n我们调用：func(widget);\r\n\r\n类型推导（关键规则）： 当一个左值（类型为 A）被传递给一个\r\nT&amp;&amp; 形式的万能引用时，模板参数 T 被推导为\r\nA&amp; (一个左值引用)。在本例中，T 被推导为\r\nMyClass&amp;。\r\n实例化参数类型： 编译器将 T (即 MyClass&amp;) 替换回参数声明\r\nT&amp;&amp; 中，得到(MyClass&amp;) &amp;&amp;\r\n引用折叠： C++\r\n不允许“引用的引用”。编译器使用“引用折叠”规则来简化它。折叠规则是（简单来说）：只要有\r\n&amp; 出现，最终就折叠为 &amp;。只有当两者都是\r\n&amp;&amp; 时，才折叠为 &amp;&amp;。\r\n\r\nA&amp; &amp; -&gt; A&amp;\r\nA&amp; &amp;&amp; -&gt; A&amp; （我们命中的规则）\r\nA&amp;&amp; &amp; -&gt; A&amp;\r\nA&amp;&amp; &amp;&amp; -&gt; A&amp;&amp;\r\n\r\n最终函数签名： 折叠后，func\r\n被实例化的版本是：void func(MyClass&amp; param);,\r\n结果是函数变成了一个接受左值引用的函数，它成功地绑定到了我们传入的左值\r\nwidget 上。\r\n\r\n\r\n情况二：传递一个右值\r\n\r\n假设我们传递一个临时对象（右值）：func(MyClass());\r\n\r\n类型推导（关键规则）： 当一个右值（类型为\r\nA）被传递给一个 T&amp;&amp; 形式的万能引用时，模板参数 T\r\n被推导为 A (一个普通的、非引用的类型)。本例中，T\r\n被推导为 MyClass。\r\n实例化参数类型： 编译器将 T (即 MyClass) 替换回参数声明\r\nT&amp;&amp; 中，得到：(MyClass) &amp;&amp;，即\r\nMyClass&amp;&amp;。(注意这里不需要发生折叠)\r\n最终函数签名： func\r\n被实例化的版本是：void func(MyClass&amp;&amp; param);函数变成了一个接受右值引用的函数，它成功地绑定到了我们传入的右值临时对象上。\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款34：优先选用 lambda 式，而非 std bind","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE34%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20lambda%20%E5%BC%8F%EF%BC%8C%E8%80%8C%E9%9D%9E%20std%20bind/","content":"在 C++11 中，lambda 表达式几乎总是比 std::bind 更好的选择；到了\r\nC++14，std::bind 基本上已无用武之地。std::bind 是一个源自 C++98\r\n时代函数式编程思想的工具，虽然在 C++11\r\n标准库中被正式引入，但其设计与现代 C++ 的 lambda\r\n表达式相比，在多个方面都相形见绌。\r\nstd::bind\r\nstd::bind 是 C++11 在 \r\n头文件中提供的一个非常有用的函数模板。它就像一个函数适配器，可以接受一个可调用对象（callable\r\nobject），并将其部分或全部参数绑定到特定的值或占位符上，最终生成一个新的、可直接调用的对象（通常称为函数对象\r\nfunction object）。\r\n简而言之，std::bind 的核心作用是延迟调用和参数定制。\r\nstd::bind 的基本语法如下：\r\nauto new_callable = std::bind(callable_object, arg1, arg2, ...);\r\n\r\ncallable_object: 任何可以被调用的对象，例如普通函数指针,\r\n类的成员函数指针, Lambda 表达式, 其他函数对象（如 std::function）等\r\narg1, arg2, …: 要传递给 callable_object\r\n的参数列表。这些参数可以是具体的值(如 10, “hello”, 3.14),\r\n这些参数会被复制或移动并存储在生成的新函数对象中; 也可以是占位符\r\n(Placeholders): 如 _1, _2, _3, …。它们定义在命名空间 std::placeholders\r\n中。占位符表示新生成的可调用对象的参数位置。例如，_1\r\n表示新对象的第一个参数，_2\r\n表示第二个参数，以此类推(注意：使用占位符时，通常需要 using namespace\r\nstd::placeholders; 或显式指定 std::placeholders::_1)\r\n\r\n主要用途与代码示例\r\n下面我们通过几个核心场景来理解 std::bind 的具体用法。\r\n\r\n绑定普通函数参数\r\n这是最常见的用法，用于将一个函数的某些参数固定下来，生成一个参数更少的新函数。假设有一个函数需要三个参数，但我们想创建一个只需要一个参数的简化版本。\r\n#include &lt;iostream&gt;#include &lt;functional&gt;// 原始函数，接受三个参数void print_info(const std::string&amp; name, int age, const std::string&amp; city) {    std::cout &lt;&lt; name &lt;&lt; \" is \" &lt;&lt; age &lt;&lt; \" years old and lives in \" &lt;&lt; city &lt;&lt; \".\" &lt;&lt; std::endl;}int main() {    // 使用占位符命名空间    using namespace std::placeholders;    // 1. 绑定部分参数    // 将 print_info 的第一个和第三个参数固定为 \"Alice\" 和 \"New York\"    // _1 是一个占位符，代表新函数 call_alice 的第一个参数    // 第二个参数被设置为占位符 _1，这意味着 call_alice 的第一个参数将会被传递到 print_info 的第二个位置。    auto call_alice = std::bind(print_info, \"Alice\", _1, \"New York\");    // 调用新生成的函数对象，只需要提供年龄    std::cout &lt;&lt; \"--- Calling with partial binding ---\" &lt;&lt; std::endl;    call_alice(30); // 输出: Alice is 30 years old and lives in New York.    call_alice(25); // 输出: Alice is 25 years old and lives in New York.    // 2. 绑定所有参数    // 将所有参数都固定下来    auto call_bob = std::bind(print_info, \"Bob\", 42, \"London\");    // 调用时不再需要任何参数    std::cout &lt;&lt; \"\\n--- Calling with full binding ---\" &lt;&lt; std::endl;    call_bob(); // 输出: Bob is 42 years old and lives in London.    return 0;}\r\n调整参数顺序: std::bind\r\n还可以通过占位符灵活地调整参数的传递顺序。假如有一个减法函数，我们想创建一个新函数来实现参数顺序颠倒的减法\r\n#include &lt;iostream&gt;#include &lt;functional&gt;double subtract(double a, double b) {    return a - b;}int main() {    using namespace std::placeholders;    // 原始调用    std::cout &lt;&lt; \"subtract(10, 3) = \" &lt;&lt; subtract(10, 3) &lt;&lt; std::endl; // 输出: 7    // 使用 bind 交换参数顺序    // _1 对应新函数的第一个参数，_2 对应第二个    // bind(subtract, _2, _1) 的意思是：    // 调用时，将新函数的第二个参数传给 subtract 的第一个参数    // 将新函数的第一个参数传给 subtract 的第二个参数    auto reversed_subtract = std::bind(subtract, _2, _1);    std::cout &lt;&lt; \"reversed_subtract(10, 3) = \" &lt;&lt; reversed_subtract(10, 3) &lt;&lt; std::endl; // 输出: -7    // 上述调用等效于 subtract(3, 10)        return 0;}\r\n绑定类的成员函数: 这是 std::bind\r\n一个非常重要的应用场景，尤其是在回调函数中。绑定成员函数时，必须提供一个类的实例（或指针、引用）作为\r\nstd::bind 的第一个参数(在函数参数之后)。也就是说,\r\n绑定成员函数时，第一个参数必须是成员函数指针，第二个参数必须是对象实例（或指针）\r\n#include &lt;iostream&gt;#include &lt;functional&gt;#include &lt;string&gt;class Greeter {public:    void say_hello(const std::string&amp; name) {        std::cout &lt;&lt; \"Hello, \" &lt;&lt; name &lt;&lt; \"!\" &lt;&lt; std::endl;    }};int main() {    using namespace std::placeholders;    Greeter greeter_instance;    // 绑定成员函数    // 第一个参数是成员函数指针：&amp;Greeter::say_hello    // 第二个参数是对象实例的地址：&amp;greeter_instance    // 第三个参数 _1 是占位符，对应 say_hello 的 name 参数    auto greet_func = std::bind(&amp;Greeter::say_hello, &amp;greeter_instance, _1);    greet_func(\"World\");   // 输出: Hello, World!    greet_func(\"C++\");    // 输出: Hello, C++!    // 如果传递对象实例本身，会发生拷贝    auto greet_func_copy = std::bind(&amp;Greeter::say_hello, greeter_instance, _1);    greet_func_copy(\"Copied\"); // 输出: Hello, Copied!    return 0;} &gt;\r\n&amp;greeter_instance：这是调用该成员函数的对象实例的指针。this\r\n指针被隐式地绑定到了 greeter_instance。你也可以直接传递\r\ngreeter_instance，此时会拷贝一份对象。\r\n\r\nstd::bind 与 Lambda\r\n表达式的对比\r\n在现代 C++ (C++14 及以后) 中，Lambda 表达式通常是比 std::bind\r\n更好的选择。因为 Lambda\r\n通常更具可读性、更灵活，并且可能产生更高效的代码。让我们用 Lambda\r\n重写上面的第一个例子： #include &lt;iostream&gt;#include &lt;string&gt;#include &lt;functional&gt;void print_info(const std::string&amp; name, int age, const std::string&amp; city) {    std::cout &lt;&lt; name &lt;&lt; \" is \" &lt;&lt; age &lt;&lt; \" years old and lives in \" &lt;&lt; city &lt;&lt; \".\" &lt;&lt; std::endl;}int main() {    // ---- std::bind 版本 ----    using namespace std::placeholders;    auto call_alice_bind = std::bind(print_info, \"Alice\", _1, \"New York\");    call_alice_bind(30);    // ---- Lambda 版本 ----    // 捕获 name 和 city 变量，age 作为参数传入    std::string name = \"Alice\";    std::string city = \"New York\";    auto call_alice_lambda = [name, city](int age) {        print_info(name, age, city);    };    call_alice_lambda(30);    return 0;} Lambda 的优势： - 可读性更强：name, city{…} 的意图非常清晰：捕获 name 和\r\ncity，并接受一个 age 参数。而 std::bind(…, “Alice”, _1, …) 的 _1\r\n语法相对晦涩。 - 更灵活：Lambda\r\n内部可以包含更复杂的逻辑，定义局部变量等，而 std::bind\r\n只是单纯的函数调用包装。 -\r\n性能可能更好：编译器通常能更好地内联和优化 Lambda\r\n表达式，因为 Lambda 的类型是唯一的、在编译期确定的。而\r\nstd::bind 产生的函数对象类型较为复杂，可能给优化带来挑战。 -\r\n无需占位符：Lambda 自然地处理参数，不需要引入 std::placeholders\r\n命名空间和 _1, _2 等符号。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款33：对 auto&& 型别的形参使用 decltype, 以 std forward 之","url":"/2025/09/20/lang/CPP/Effective%20modern%20C++/lambda%20%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%9D%A1%E6%AC%BE33%20-%20%E5%AF%B9%20auto&&%20%E5%9E%8B%E5%88%AB%E7%9A%84%E5%BD%A2%E5%8F%82%E4%BD%BF%E7%94%A8%20decltype,%20%E4%BB%A5%20std%20forward%20%E4%B9%8B/","content":"该条款的核心是解决一个在 C++14 泛型 lambda\r\n中进行完美转发时遇到的具体语法问题。\r\n泛型lambda\r\n简单来说，泛型 Lambda (Generic Lambda) 是一种可以使用 auto\r\n关键字作为参数类型的 Lambda 表达式。这使得该 Lambda\r\n能够接受任意类型的参数，其行为类似于一个函数模板。\r\n\r\n在 C++14 之前，如果你想让一个 Lambda\r\n接受不同类型的参数，你需要为每种类型写一个\r\nLambda，或者使用更复杂的模板技巧（比如定义一个带模板化 operator()\r\n的函数对象）。C++14 通过允许在 Lambda 参数中使用\r\nauto，极大地简化了这一过程。\r\n\r\n正如我们前面所说, lambda的本质是闭包类, 因此泛型 Lambda\r\n的本质也是闭包类, 只是这个闭包类的 operator() 是一个模板函数,\r\n可以接受任意类型的参数。 auto my_lambda = [](auto x) { /* ... */ };// 可以理解为下列代码class __compiler_generated_functor_name {public:    template&lt;typename T&gt;    auto operator()(T x) const {        /* ... */    }};auto my_lambda = __compiler_generated_functor_name{}; 也就是说, 泛型 Lambda\r\n本质上是一个拥有模板化的函数调用运算符 (operator())\r\n的函数对象的语法糖。这使得每一次用不同类型的参数调用该\r\nLambda 时，编译器都能为其生成一个特定的函数实例。\r\n泛型 Lambda 与完美转发\r\n而在许多情况下(例如工厂函数), 我们需要在泛型 Lambda 中进行完美转发,\r\n即保留参数的左值/右值属性, 为此我们需要将 lambda 的形参声明为万能引用\r\nauto&amp;&amp;，并在内部使用 std::forward. 此时会出现一个问题\r\n// auto&amp;&amp; x 是万能引用auto f = [](auto&amp;&amp; x) {    // ??? 应该是什么类型？    return func(normalize(std::forward&lt;???&gt;(x)));}; 在常规的函数模板中，我们会写 std::forward(x)，这里的 T\r\n是模板参数。但在 lambda\r\n表达式中，我们无法直接访问到编译器在背后为我们生成的那个模板参数\r\nT。那么，??? 处应该填什么呢？\r\n条款33给出的解决方案是使用 decltype 来获取 lambda\r\n形参的类型，并将其作为 std::forward 的模板参数, 也就是:\r\nauto f = [](auto&amp;&amp; param) {    return func(normalize(std::forward&lt;decltype(param)&gt;(param)));};\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"传输层","url":"/2025/10/22/web/Computer%20Network/%E4%BC%A0%E8%BE%93%E5%B1%82/%E4%BC%A0%E8%BE%93%E5%B1%82/","content":"我们前面介绍的网络层提供的服务是主机到主机\r\n(Host-to-Host)，目标是克服网络互联的复杂性，确保数据包能够跨越各种异构网络（如\r\nLAN、WAN、路由器）找到正确的目标主机。其主要焦点在于路由和寻址（使用\r\nIP 地址）。\r\n在此基础上，传输层（Transport\r\nLayer）的核心任务是为运行在不同主机上的应用进程提供直接的逻辑通信服务。因此，传输层协议也被称为端到端协议。\r\n\r\n在计算机网络中，实际进行通信的实体并不是主机本身，而是主机上运行的应用进程。例如，主机A上的浏览器进程（AP1）可能正在与主机B上的\r\nWeb 服务器进程（AP3）通信。\r\n\r\n为了区分同一主机上的不同应用进程，运输层引入了端口号（Port\r\nNumber）作为应用进程的标识符。端口号是一个 16 位的整数，范围从 0 到\r\n65535。这里的“端口”是逻辑端口，而非物理端口。具体内容将在后续章节中详细介绍。\r\n\r\n\r\nalt text\r\n\r\n同样的，传输层之间的通信看起来像是数据在通信双方的传输层实体之间沿着水平方向直接传输（端到端）。但实际上，数据是沿着垂直方向在各层之间传递，并通过网络层及其以下层次进行实际的物理传输。传输层屏蔽了底层网络核心的细节（如网络拓扑、路由协议等）。\r\n在TCP/IP体系结构中，运输层有两个核心协议，它们基于不同的设计哲学和应用需求，提供两种主要的运输服务。\r\n用户数据报协议（UDP）\r\n-\r\n服务特性：无连接的、不可靠的数据传输服务。UDP在发送数据前不需要建立连接，收到数据后也不需要发送确认。它只在IP数据报的服务上增加了一些简单的复用和分用功能。\r\n- 主要特点：\r\n- 无连接：传输数据前无需建立连接，开销小。\r\n- 不可靠：不保证数据可靠交付，不处理误码、丢失、重复、失序等问题。\r\n-\r\n面向报文：对应用层传下来的报文，UDP不做拆分或合并，保留报文边界。\r\n- 首部开销小：仅有8字节的固定首部。\r\n- 适用场景：对实时性要求高，且能容忍少量丢包的应用，如\r\nIP电话、视频会议、DNS查询。\r\n传输控制协议（TCP）\r\n-\r\n服务特性：面向连接的、可靠的数据传输服务。TCP通过复杂的机制（如连接管理、确认机制、超时重传等）来确保数据在网络中传输时不会出现误码、丢失、失序或重复。\r\n- 主要特点：\r\n-\r\n面向连接：数据传输前必须经过“三报文握手”建立连接，数据传输后要经过“四报文挥手”释放连接。\r\n- 可靠传输：采用确认、重传等机制，保证数据正确、有序、完整地到达。\r\n-\r\n面向字节流：认为应用层数据是一连串的无结构字节流，TCP可能会对应用层报文进行拆分或合并，不保留报文边界。\r\n- 全双工通信：允许数据在两个方向上同时独立传输。\r\n-\r\n适用场景：对数据可靠性要求高的应用，如文件传输（FTP）、电子邮件（SMTP）、网页浏览（HTTP）。\r\n\r\n传输层端口号、复用与分用\r\n我们知道，在操作系统内部，唯一标识一个进程的是进程标识符\r\n(PID)。但是，PID 是由各个操作系统（Windows, Linux, Mac\r\nOS）独立管理的，格式并不统一。如果主机A上的进程想和主机B上的进程通信，它无法知道对方的\r\nPID。因此，TCP/IP\r\n体系结构需要一个统一的、独立于操作系统的标识符来标记应用进程，这就是端口号。\r\n端口号是一个 16 比特的数字，取值范围是 0 ~\r\n65535。它被分为三大类：\r\n服务器端使用的端口号\r\n- 熟知端口号 (Well-known Ports): 0 ~ 1023\r\n- 这是“全球通用”的号码，由 IANA (因特网号码分配管理局) 严格分配给 TCP/IP\r\n体系中最重要、最核心的应用层协议。\r\n- HTTP (Web服务)：80\r\n- HTTPS (安全Web服务)：443\r\n- FTP (文件传输)：21 (控制) 和 20 (数据)\r\n- SMTP (电子邮件)：25\r\n- DNS (域名解析)：53\r\n- 登记端口号 (Registered Ports): 1024 ~ 49151\r\n- 这些端口是为那些没有熟知端口号的应用程序准备的。使用这类端口号必须在\r\nIANA 按规定手续登记，以防止重复。\r\n- Microsoft RDP (远程桌面) 使用的 3389 端口。\r\n客户端使用的短暂端口号 (Ephemeral Ports): 49152 ~\r\n65535\r\n-\r\n这类端口也称为临时端口号。当一个客户端进程（如你的浏览器）需要发起网络通信时，它会动态地从这个范围内选择一个当前未被占用的端口供自己使用。\r\n-\r\n当服务器收到请求报文时，它会看到这个短暂端口号（作为源端口），并在响应时将其作为目的端口，这样数据就能准确返回给发起请求的那个浏览器进程了。通信结束后，这个端口号会被系统收回，供其他进程使用。\r\n需要注意的是，端口号只具有本地意义，且不同协议（如 TCP 和\r\nUDP）可以使用相同的端口号。要在网络中唯一标识一个应用进程，必须结合IP地址和传输层协议类型（TCP或UDP）一起使用。这三个要素共同构成了一个套接字\r\n(Socket)，它是网络通信中端到端连接的唯一标识符。\r\n发送方的复用\r\n(Multiplexing) 和接收方的分用 (Demultiplexing)\r\n首先，“复用”（Multiplexing）这个概念指的是允许多个不同的数据流共享使用同一个公共的资源或信道。这是传输层利用端口号实现其功能的动态过程，也是整个\r\nTCP/IP 体系协同工作的关键环节。\r\n发送方的复用 (Multiplexing): “多对一”\r\n的汇集过程。\r\n-\r\n传输层复用：在发送方主机上，可能同时有多个应用进程（如浏览器、FTP客户端、邮件客户端）在发送数据。传输层（TCP或UDP）会接收来自这些不同进程的应用报文，为它们打上各自的端口号和协议（如浏览器用TCP、DNS查询用UDP），然后将这些封装好的\r\nTCP 报文段 或 UDP 用户数据报 向下统一交给 IP 层。\r\n-\r\n这里的复用体现在：多个应用进程的数据通过传输层被汇集到一个传输层实体（TCP或UDP）中。\r\n- IP 层复用：IP 层接收来自 TCP 和 UDP 的数据包，将它们再次封装成\r\nIP 数据报（IP 复用），然后发送到网络中。\r\n- 这里的复用体现在：来自不同传输层协议（TCP和UDP）的数据通过 IP\r\n层被汇集到一个 IP 实体中。\r\n接收方的分用 (Demultiplexing): “一对多”\r\n的分发过程，是复用的逆过程\r\n- IP 分用 (网络层)：接收方主机的 IP 层收到一个 IP 数据报。它会检查 IP\r\n首部中的 “协议”字段。\r\n- 如果协议字段的值 = 17，IP 层就知道其数据载荷是一个 UDP\r\n用户数据报，于是将其向上交付给传输层的 UDP。\r\n- 如果协议字段的值 = 6，IP 层就知道其数据载荷是一个 TCP\r\n报文段，于是将其向上交付给传输层的 TCP。\r\n- 这里的分用体现在：IP\r\n层根据协议字段将数据分发给不同的传输层协议实体（TCP或UDP）。\r\n- 传输层分用 (传输层)：传输层（UDP 或 TCP）收到数据后，会检查其首部中的\r\n“目的端口号” 字段。\r\n- 例如：TCP 收到一个目的端口为 80 的报文段，它就会查找本地正在 80\r\n端口“监听”的进程（即 Web 服务器进程），并将数据交付给它。\r\n- UDP 收到一个目的端口为 53 的用户数据报，它就会将数据交付给正在 53\r\n端口“监听”的 DNS 服务器进程。\r\n- 这里的分用体现在：传输层根据目的端口号将数据分发给不同的应用进程。\r\n\r\n\r\nalt text\r\n\r\n下面是一个实际场景：你的用户PC (192.168.0.1)，想访问 Web服务器\r\n(www.porttest.net)。Web 服务器的 IP 地址 (192.168.0.3) 记录在 DNS服务器\r\n(192.168.0.2) 中。\r\n\r\n\r\n第一阶段：DNS 查询（使用 UDP）\r\n目的：PC 必须先获取 www.porttest.net 对应的 IP 地址。\r\n\r\n发送 DNS 查询请求（PC → DNS 服务器）\r\n\r\n协议：UDP\r\n\r\n源端口：49152（一个短暂端口号，由 PC 动态分配）\r\n\r\n目的端口：53（DNS 的熟知端口号）\r\n\r\n收到 DNS 响应（DNS 服务器 → PC）\r\n\r\n协议：UDP\r\n\r\n源端口：53（DNS 的熟知端口号）\r\n\r\n目的端口：49152（PC 发起请求时使用的短暂端口）\r\n\r\n\r\n结果：PC 收到响应，得知 www.porttest.net 的 IP 地址为\r\n192.168.0.3。随后，PC 归还短暂端口 49152。\r\n\r\n第二阶段：HTTP 请求（使用 TCP）\r\n目的：PC 已经知道 IP 地址，现在可以向 Web 服务器请求网页内容。\r\n\r\n发送 HTTP 请求（PC → Web 服务器）\r\n\r\n协议：TCP\r\n\r\n源端口：49152（一个短暂端口号，系统可能重新分配同一个端口）\r\n\r\n目的端口：80（HTTP 的熟知端口号）\r\n\r\n收到 HTTP 响应（Web 服务器 → PC）\r\n\r\n协议：TCP\r\n\r\n源端口：80（HTTP 的熟知端口号）\r\n\r\n目的端口：49152（PC 发起请求时使用的短暂端口）\r\n\r\n\r\n结果：PC 收到网页内容，浏览器将其渲染显示。通信结束后，PC\r\n归还短暂端口 49152。\r\nTCP 和 UDP 对比\r\n\r\n无连接的 UDP 和面向连接的 TCP\r\n\r\nUDP (用户数据报协议)：无连接 (Connectionless)\r\n\r\n工作模式：UDP\r\n采取一种“随心所欲”的发送策略。它不需要在传输数据前与对方进行任何协商或“握手”。\r\n\r\n应用程序可以随时将数据打包成 UDP 用户数据报并发送出去。\r\n\r\n\r\nTCP (传输控制协议)：面向连接 (Connection-oriented)\r\n\r\n工作模式：TCP\r\n采用一种严谨的、类似于“打电话”的模式。在传输数据之前，通信双方必须先进行协商，建立起一条逻辑连接。\r\n\r\n过程：\r\n\r\n“三报文握手”建立连接：在传输数据之前，通信双方必须先进行协商，交换初始序号、窗口大小等参数，建立起一条逻辑连接。\r\n\r\n数据传输：双方在已建立的连接上进行可靠的数据通信。\r\n\r\n“四报文挥手”释放连接：数据传输结束后，双方通过协商来关闭这条逻辑连接，释放资源。\r\n\r\n\r\n这里的“连接”是逻辑上的、虚拟的连接关系，并不是一条物理电路。它只是双方为了确保可靠通信而在内存中维护的一种状态。\r\n\r\n\r\nUDP 和 TCP 对单播、多播和广播的支持情况\r\n\r\nUDP：支持全部三种通信方式。由于 UDP\r\n是无连接的，它可以自由地向任何目标发送数据\r\n\r\n单播 (Unicast)：一对一通信（最常见）。\r\n\r\n多播 (Multicast)：一对多通信（发送给一个特定组）。\r\n\r\n广播 (Broadcast)：一对全通信（发送给子网内的所有主机）。\r\n\r\n\r\nTCP：仅支持单播。TCP\r\n的“面向连接”特性决定了它必须在两个确定的端点（一对一）之间建立连接。\r\n\r\n“三报文握手”这个过程本身就是点对点的协商。你无法和一个“组”（多播）或“所有人”（广播）同时进行握手并建立一个统一的连接状态。\r\n\r\n\r\nUDP 和 TCP 对应用层报文的处理\r\n这个区别决定了应用程序如何看待和处理发送及接收到的数据。\r\n\r\nUDP：面向应用报文\r\n(Message-oriented)，对应用层交下来的报文，采取“原封不动”的策略。\r\n\r\n过程：它既不合并（多个小报文合成一个），也不拆分（一个大报文拆成多个）。它只是简单地给应用报文添加一个\r\n8 字节的 UDP 首部，然后就向下交付给 IP 层。\r\n\r\n发送方发送了几个报文，接收方就会收到几个报文。它保留了应用层报文的边界。\r\n\r\n\r\nTCP：面向字节流\r\n(Byte-stream-oriented)，并不关心应用层交下来的是几个报文。\r\n\r\n过程：TCP\r\n会将应用层数据视为一长串无结构的字节流，全部放入自己的“发送缓存”中。然后，TCP\r\n根据自己的发送策略（如网络拥塞情况、MSS\r\n大小等）从缓存中取出任意数量的字节，打包成 TCP\r\n报文段发送出去。\r\n\r\n发送方应用进程可能调用了 10 次 send 发送了 10 个短报文，但 TCP\r\n可能将它们合并成 1 个 TCP 报文段发送。也可能发送方 1 次 send\r\n发送了一个很长的报文，TCP 会将其拆分成 4 个 TCP 报文段发送。\r\n\r\nTCP 不保留应用层报文的边界。接收方的 TCP\r\n也是将收到的数据放入“接收缓存”，应用进程需要自己从这个字节流中“解析”出有意义的应用层报文。\r\n\r\n\r\nUDP 和 TCP 对数据传输可靠性的支持\r\n这是基于它们的设计哲学的直接体现。\r\n\r\nUDP：不可靠 (Unreliable)，只是在 IP\r\n层“尽最大努力交付”的基础上增加了端口功能，它自己不提供任何可靠性保证。\r\n\r\n误码：UDP\r\n首部有检验和字段，能检查出误码。但如果发现误码，它唯一的动作就是丢弃该报文，并不会通知发送方。\r\n\r\n丢失/失序：UDP 完全不关心报文是否丢失或是否按顺序到达。\r\n\r\n适用：适用于实时应用，如 IP\r\n电话、视频会议。这些应用能容忍少量丢包，但对延迟非常敏感。\r\n\r\n\r\nTCP：可靠 (Reliable)。TCP 的核心价值在于，它在不可靠的 IP\r\n层之上，构建了一个面向连接的可靠数据传输服务。\r\n\r\n应用程序使用 TCP\r\n时，可以将其想象成一条“可靠信道”，数据在上面传输不会出现误码、丢失、失序和重复。\r\n\r\n这是通过 TCP\r\n复杂的首部和机制（如序号、确认、重传、流量控制、拥塞控制）实现的。\r\n\r\n适用：适用于可靠性要求极高的应用，如文件传输、电子邮件。\r\n\r\n\r\nUDP 首部和 TCP 首部的对比\r\n首部的复杂度直接反映了协议功能的复杂度。\r\n\r\nUDP 首部：极其简单 (Simple)\r\n\r\n结构：只有 4\r\n个字段：源端口、目的端口、长度、检验和。\r\n\r\n大小：每个字段 2 字节，总共固定的 8 字节。\r\n\r\n原因：因为 UDP\r\n功能简单（只管分用和差错检测），所以首部开销极小。\r\n\r\n\r\n\r\nTCP 首部：非常复杂 (Complex)\r\n\r\n结构：包含源端口、目的端口、序号、确认号、数据偏移、6\r\n个控制标志位（SYN, ACK, FIN\r\n等）、窗口大小、检验和、紧急指针，以及一个可变的选项字段。\r\n\r\n大小：固定的首部就有 20\r\n字节，加上选项字段，最大可达 60 字节。\r\n\r\n原因：TCP\r\n所有复杂的可靠传输、流量控制和拥塞控制功能，都依赖于首部中这些字段来承载信息。\r\n\r\n\r\n\r\n一个共同点：伪首部 (Pseudo-header)，无论是 UDP 还是\r\nTCP，在计算检验和时，都需要在数据报首部和数据载荷前，额外添加一个 12\r\n字节的“伪首部”。\r\n\r\n伪首部内容：包含源 IP 地址、目的 IP\r\n地址、协议号（UDP=17,\r\nTCP=6）、数据报长度等。\r\n\r\n目的：这样做的目的是为了再次确认 IP 数据报是否传错了主机（IP\r\n地址错误）以及 IP 层是否交付错了协议（协议号错误）。\r\n\r\n\r\n\r\n传输控制协议（TCP）\r\n传输控制协议（Transmission Control Protocol,\r\nTCP）是互联网协议族中的核心协议之一。它提供了一种面向连接的、可靠的数据传输服务，确保数据在不可靠的\r\nIP 网络上能够正确、有序地传输到目标主机的应用进程。\r\nTCP 的首部\r\nTCP 报文段的首部是 TCP 协议的灵魂所在，TCP\r\n的所有功能（可靠性、流量控制、拥塞控制等）都是通过其首部中的各个字段来实现的。\r\n与 UDP 固定的 8 字节首部不同，TCP 首部要复杂得多。它由两部分组成：20\r\n字节的固定首部和最大 40 字节的扩展首部（选项）。\r\n\r\n源端口 (Source Port) 和 目的端口 (Destination Port)\r\n\r\n大小：各 16 比特（2 字节）。\r\n\r\n作用：这两个字段与 UDP\r\n的端口字段作用完全相同，用于实现进程到进程的通信。\r\n\r\n源端口：标识发送方主机的应用进程。\r\n\r\n目的端口：标识接收方主机的应用进程。\r\n\r\n序号 (Sequence Number)\r\n\r\n大小：32 比特（4 字节）。\r\n\r\n作用：这是 TCP 可靠传输和字节流服务的基石。\r\n\r\n核心理解：TCP\r\n是面向字节流的，它将整个数据流中每一个字节都进行了编号。本字段（序号）的值，并不是报文段的编号（如第1个、第2个包），而是指本报文段数据载荷\r\n(Payload) 中第一个字节在整个数据流中的序号。\r\n\r\n举例：如果一个 TCP 报文段的数据载荷是 “Hello”，而 “H”\r\n是整个数据流中的第 166 个字节，那么这个报文段的序号字段的值就是\r\n166。\r\n\r\n范围：序号从 0 到 232 − 1，溢出后会再从 0\r\n开始。\r\n\r\n确认号 (Acknowledgement Number)\r\n\r\n大小：32 比特（4 字节）。\r\n\r\n作用：这是 TCP 实现可靠传输的确认机制的核心。\r\n\r\n核心理解：确认号字段的值，代表期望收到对方下一个报文段的数据载荷的第一个字节的序号。\r\n\r\n重要引申义：确认号为 n，意味着“到序号 n − 1\r\n为止的所有数据，我都已经正确接收了，请你下次从序号 n\r\n开始发送”。这是一个累积确认。\r\n\r\n数据偏移 (Data Offset)\r\n\r\n大小：4 比特。\r\n\r\n作用：指出 TCP 报文段的首部长度。\r\n\r\n核心理解：这个字段的名字有些误导，它不表示数据的位置，而是表示“数据载荷部分距离\r\nTCP 报文段起始处有多远”。它的单位是 4 字节（32\r\n位字）。\r\n\r\n举例：如果该字段值为 5（二进制 0101），则首部长度 = 5 × 4 = 20 字节（这是最小的 TCP\r\n首部长度）。如果该字段值为 15（二进制 1111），则首部长度 = 15 × 4 = 60 字节（这是最大的 TCP\r\n首部长度）。\r\n\r\n保留 (Reserved)\r\n\r\n大小：6 比特。\r\n\r\n作用：为今后使用而保留，目前必须全部置为 0。\r\n\r\n六个控制标志位 (Control Flags)\r\n\r\n这 6 个比特位是 TCP\r\n的“开关”，用来控制连接状态和数据传输的行为。\r\n\r\nURG (紧急标志位)：当 URG = 1\r\n时，表明紧急指针字段有效。它告诉接收方本报文段中有“紧急数据”（如\r\nCtrl+C 中断信号），应优先处理。\r\n\r\nACK (确认标志位)：只有当 ACK = 1 时，上面的确认号字段才有效。TCP\r\n规定，在连接建立后（即“三报文握手”的第二个报文之后），所有传送的\r\nTCP 报文段都必须把 ACK 置 1。\r\n\r\nPSH (推送标志位)：提示接收方 TCP\r\n应尽快将数据推送（Push）给应用进程，而不要等待填满内部缓存。主要用于交互式应用（如\r\nSSH），发送方也会立即发送，不等待缓存。\r\n\r\nRST (复位标志位)：当 RST = 1 时，表明 TCP\r\n连接中出现严重差错（如主机崩溃），必须释放连接，然后再重新建立。它也用来拒绝一个非法的连接请求。\r\n\r\nSYN (同步标志位)：用于建立连接。SYN = 1, ACK =\r\n0：表示这是一个连接请求报文段。SYN = 1, ACK =\r\n1：表示这是一个连接接受（响应）报文段。SYN\r\n报文段即使不携带数据，也要消耗掉一个序号。\r\n\r\nFIN (终止标志位)：用于释放连接。当 FIN = 1\r\n时，表明发送方的数据已经全部发送完毕，要求释放连接。FIN 报文段和 SYN\r\n一样，即使不带数据，也要消耗一个序号。\r\n\r\n窗口 (Window)\r\n\r\n大小：16 比特（2 字节）。\r\n\r\n作用：实现 TCP 流量控制。\r\n\r\n核心理解：这个字段的值（0 ∼ 216 − 1）指出的是发送本报文段一方的接收窗口\r\n(rwnd) 大小。它告诉对方：“我现在还有 N\r\n字节的接收缓存可用空间，你最多只能再给我发 N 字节的数据”。\r\n\r\n举例：如果一方发送 ack=800 且窗口=1000，它是在告诉对方：“序号\r\n799 之前的数据我已收到。我的接收缓存还能装 1000\r\n字节，所以你接下来可以发送序号从 800 到 1799 的数据”。\r\n\r\n检验和 (Checksum)\r\n\r\n大小：16 比特（2 字节）。\r\n\r\n作用：检查整个 TCP\r\n报文段（包括首部和数据载荷）在传输过程中是否出现了误码。\r\n\r\n计算方式：与 UDP 类似，计算时也要在 TCP 报文段前面加上 12\r\n字节的伪首部（包含源/目的 IP 地址、协议号等信息）。\r\n\r\n紧急指针 (Urgent Pointer)\r\n\r\n大小：16 比特（2 字节）。\r\n\r\n作用：仅在 URG = 1 时有效。\r\n\r\n核心理解：它是一个偏移量，指出本报文段中紧急数据的长度。它指向紧急数据末尾的下一个字节。\r\n\r\n处理：接收方收到 URG=1\r\n的报文段，会根据紧急指针字段的值，从数据载荷中“插队”取出紧急数据，并直接上交给应用进程。\r\n\r\n选项 (Options)\r\n\r\n大小：长度可变，最大 40 字节。\r\n\r\n作用：增加 TCP 的功能。\r\n\r\n主要选项：\r\n\r\nMSS\r\n(最大报文段长度)：这是最重要的选项之一。它指的是 TCP\r\n报文段中数据载荷 (Payload) 部分的最大长度，不包括 TCP\r\n首部。双方在建立连接时协商 MSS。目的是尽量让 TCP 报文段封装成 IP\r\n数据报后，不需要在网络层进行分片。如果主机不设置，默认 MSS 值为 536\r\n字节。\r\n\r\n窗口扩大选项：用于扩大 16 位的窗口字段（在高速网络中 65535\r\n字节的窗口太小）。\r\n\r\n时间戳选项：用于更精确地计算往返时间 (RTT)，以及防止序号绕回\r\n(PAWS)。\r\n\r\n选择确认选项\r\n(SACK)：允许接收方确认“非连续”的数据块，提高重传效率。\r\n\r\n\r\n填充 (Padding)\r\n\r\n作用：由于选项字段的长度是可变的，填充字段（用 0\r\n填充）的目的是确保整个 TCP 首部（固定+选项）的长度是 4\r\n字节的整数倍。\r\n\r\n原因：这是为了匹配数据偏移字段（以 4 字节为单位）的定义。\r\n\r\n\r\nTCP 的连接管理\r\nTCP 协议最核心的机制之一：连接管理。这是 TCP “面向连接”\r\n特性的具体体现，确保了数据传输的有序和可靠。\r\n这个管理过程主要分为三个阶段 ： - 建立 TCP 连接（通过“三报文握手”） -\r\n数据传送（在已建立的连接上进行） - 释放 TCP 连接（通过“四报文挥手”）\r\n三报文握手建立 TCP 连接\r\nTCP\r\n客户端和服务器在传输应用数据前，必须通过“三报文握手”建立逻辑连接。握手的目的有三点：\r\n\r\n确知对方存在：双方确认彼此“在线”且“可达”。\r\n协商参数：包括\r\nMSS（最大报文段长度）、窗口大小、时间戳选项、SACK、窗口扩大等高级功能。\r\n分配和初始化资源：双方在操作系统内核中分配缓存空间、连接状态变量等资源。\r\n\r\n详细过程如下：\r\n\r\n初始状态\r\n\r\n\r\n\r\n服务器进程创建传输控制块（TCB），进入\r\nLISTEN（监听）状态，等待连接请求。\r\n\r\n客户端进程也创建 TCB，准备发起连接。\r\n\r\n\r\n第一次握手（客户端 → 服务器）\r\n\r\n\r\n\r\n客户端发送 TCP 连接请求报文段。\r\n\r\n标志位：SYN=1, ACK=0\r\n\r\n序号：seq=x（x\r\n为客户端随机选择的初始序号）\r\n\r\n客户端进入 SYN-SENT 状态。\r\n\r\n注意：SYN 报文段即使不携带数据，也要消耗一个序号。\r\n\r\n\r\n第二次握手（服务器 → 客户端）\r\n\r\n\r\n\r\n服务器收到请求后，发回连接确认报文段。\r\n\r\n标志位：SYN=1, ACK=1\r\n\r\n序号：seq=y（y\r\n为服务器随机选择的初始序号）\r\n\r\n确认号：ack=x+1（确认客户端的 SYN）\r\n\r\n服务器进入 SYN-RCVD 状态。\r\n\r\n注意：此报文段同样消耗一个序号。\r\n\r\n\r\n第三次握手（客户端 → 服务器）\r\n\r\n\r\n\r\n客户端收到确认后，发送普通 TCP 确认报文段。\r\n\r\n标志位：ACK=1\r\n\r\n序号：seq=x+1\r\n\r\n确认号：ack=y+1（确认服务器的 SYN）\r\n\r\n客户端进入 ESTABLISHED 状态。\r\n\r\n注意：此报文段可携带数据，不携带数据则不消耗序号。\r\n\r\n\r\n握手完成\r\n\r\n\r\n\r\n服务器收到第三次握手的 ACK 后，也进入 ESTABLISHED 状态。\r\n\r\n双方确认收发能力，连接建立成功，可以开始数据传输。\r\n\r\n\r\n\r\nalt text\r\n\r\n为什么必须是“三报文握手”，而不是“两报文”？\r\n这是 TCP\r\n连接管理中一个经典问题。答案是为了防止已失效的连接请求报文段突然又传送到了服务器，因而导致错误。\r\n设想一个“两报文握手”的场景：\r\n\r\n客户发送一个 SYN 请求 (seq=x)，但这个包在网络中长时间滞留了\r\n。\r\n客户超时重传了一个新的 SYN 请求 (seq=x’)，这次成功了。\r\n服务器用 SYN/ACK 响应\r\n(ack=x’+1)，客户收到后（在两报文握手模型中）就认为连接已建立，开始传数据\r\n。\r\n数据传输完毕，双方关闭连接 。\r\n此时，那个滞留的旧 SYN 请求 (seq=x) 突然到达了服务器 。\r\n服务器误认为这是客户发起的一个全新的连接请求 。\r\n服务器发送 SYN/ACK 响应 (ack=x+1)，并立即进入 ESTABLISHED\r\n状态（因为是两报文握手）。\r\n客户早已处于 CLOSED 状态，收到这个 SYN/ACK 后会不予理睬\r\n。\r\n\r\n结果： 服务器单方面进入了 ESTABLISHED\r\n状态，并一直等待客户发来数据，白白浪费了主机的资源 。\r\n“三报文握手”如何解决这个问题：如果采用三报文握手，服务器发送 SYN/ACK\r\n后会进入 SYN-RCVD 状态，等待客户的第三次握手 (ACK)。由于客户不会发送这个\r\nACK，服务器在 SYN-RCVD\r\n状态超时后就会关闭这个（虚假的）连接，从而避免了资源浪费。\r\n四报文挥手释放 TCP 连接\r\n数据传输结束后，通信双方都可以发起释放连接的请求。这个过程需要交换四个报文段。\r\n为什么是“四报文”而不是“三报文”？\r\n核心在于 TCP 的半关闭 (Half-Close)\r\n状态(TCP是全双工的)。当一方（如客户）表示不再发送数据时（发送\r\nFIN），它只是关闭了自己到服务器的数据发送通道,\r\n但是自己还可以接收数据；但此时服务器可能还有数据没发完，服务器到客户的数据通道不应立即关闭。因此，必须等服务器也发送\r\nFIN，双方各自确认对方的 FIN 后，连接才真正关闭。\r\n假设客户（主动关闭方）发起释放请求：\r\n\r\n初始状态\r\n\r\n\r\n\r\n双方都处于 ESTABLISHED 状态。\r\n\r\n\r\n第一次挥手（报文 1：客户 → 服务器）\r\n\r\n\r\n\r\n客户进程通知 TCP 主动关闭连接，TCP\r\n发送连接释放报文段。\r\n\r\n标志位：FIN = 1, ACK = 1（ACK=1\r\n因为连接期间所有报文都要置 1）。\r\n\r\n序号：seq = u（u 等于客户已传送数据的最后一个字节序号 +\r\n1）。\r\n\r\n状态：客户发送后，进入 FIN-WAIT-1（终止等待 1）状态。\r\n\r\n注意：FIN\r\n报文段即使不携带数据，也要消耗一个序号。\r\n\r\n\r\n第二次挥手（报文 2：服务器 → 客户）\r\n\r\n\r\n\r\n服务器收到 FIN 后，发送一个普通的 TCP\r\n确认报文段。\r\n\r\n标志位：ACK = 1\r\n\r\n序号：seq = v（v 等于服务器已传送数据的最后一个字节序号\r\n+ 1）。\r\n\r\n确认号：ack = u + 1（这是对客户 FIN 的确认）。\r\n\r\n状态：服务器发送后，进入 CLOSE-WAIT（关闭等待）状态。\r\n\r\n服务器动作：服务器 TCP\r\n应立即通知高层应用进程：“客户要断开连接了”。\r\n\r\n进入“半关闭”状态：客户收到第二次挥手的 ACK 后，进入\r\nFIN-WAIT-2（终止等待 2）状态。\r\n\r\n此时：客户 → 服务器方向的连接已释放（客户不能再发数据），但服务器 →\r\n客户方向的连接仍未关闭。服务器如果还有数据要发，可以继续发送；客户仍需接收。\r\n\r\n\r\n第三次挥手（报文 3：服务器 → 客户）\r\n\r\n\r\n\r\n当服务器的应用进程也处理完数据，通知 TCP 被动关闭连接时，TCP\r\n发送连接释放报文段。\r\n\r\n标志位：FIN = 1, ACK = 1\r\n\r\n序号：seq = w（w 可能等于\r\nv，也可能因为半关闭期间又发了数据而大于 v）。\r\n\r\n确认号：ack = u + 1（重复确认第一次挥手）。\r\n\r\n状态：服务器发送后，进入\r\nLAST-ACK（最后确认）状态，等待客户的最后确认。\r\n\r\n\r\n第四次挥手（报文 4：客户 → 服务器）\r\n\r\n\r\n\r\n客户收到服务器的 FIN 后，必须发送一个普通的 TCP\r\n确认报文段。\r\n\r\n标志位：ACK = 1\r\n\r\n序号：seq = u + 1（因为客户的 FIN\r\n消耗了一个序号）。\r\n\r\n确认号：ack = w + 1（这是对服务器 FIN 的确认）。\r\n\r\n状态：客户发送后，进入 TIME-WAIT（时间等待）状态。\r\n\r\n\r\n挥手完成\r\n\r\n\r\n\r\n服务器：收到第四次挥手的 ACK 后，立即进入\r\nCLOSED（关闭）状态，撤销 TCB。\r\n\r\n客户：必须在 TIME-WAIT 状态等待\r\n2MSL（最长报文段寿命，例如 4 分钟）后，才能进入 CLOSED\r\n状态，撤销 TCB。 \r\n\r\n为什么客户最后要等待 2MSL（TIME-WAIT 状态）？\r\nTCP 在连接释放时，客户进入 TIME-WAIT 状态并等待 2MSL（Maximum Segment\r\nLifetime，报文段最大生存时间），主要有两个目的：\r\n\r\n确保服务器能收到最后一个 ACK（可靠性）\r\n\r\n\r\n\r\n在四次挥手的最后，客户向服务器发送 ACK 报文段。如果这个 ACK\r\n丢失，服务器（处于 LAST-ACK 状态）会超时重传 FIN 报文段。\r\n\r\n如果客户立即关闭连接（进入 CLOSED 状态），就无法响应服务器重传的\r\nFIN，导致服务器无法正常关闭。\r\n\r\n保持 TIME-WAIT 状态，客户可以接收重传的 FIN，并再次发送\r\nACK，确保服务器顺利关闭连接。\r\n\r\n\r\n确保本次连接的所有报文段都从网络中消失（健壮性）\r\n\r\n\r\n\r\n2MSL\r\n的等待时间足以让本次连接中的所有“迷路”报文段（包括迟到的数据包或\r\nACK）从网络中彻底消失。\r\n\r\n这样可以防止这些旧连接的报文段干扰到后续可能建立的、使用相同四元组（源\r\nIP、源端口、目的 IP、目的端口）的新连接。\r\n\r\nTCP 保活计时器 (Keepalive\r\nTimer)\r\n如果 TCP\r\n双方建立了连接，但客户主机突然出现故障（如宕机或网线断开），服务器怎么办？服务器会一直处于\r\nESTABLISHED 状态，白白等待下去 。\r\n解决方案是： TCP 设有一个保活计时器 (Keepalive\r\nTimer) 。\r\n\r\n服务器每收到一次客户的数据，就重置计时器（通常为\r\n2 小时）。\r\n如果 2 小时内未收到客户的任何数据，计时器超时,\r\n服务器发送一个探测报文段。\r\n若无响应，则每隔 75 秒发送一次。\r\n若连续发送 10\r\n个探测报文段后仍无响应，服务器就认为客户主机出了故障，于是关闭这个连接。\r\n\r\nTCP 的流量控制\r\n首先, 建立 TCP 连接的双方（例如 A 和\r\nB）都会在内核中为该连接分配一个接收缓存（Receiver\r\nBuffer） 。\r\nA 作为发送方，B 作为接收方。如果 A 发送数据的速率过快，导致 B\r\n的应用程序（如浏览器）来不及从 B 的接收缓存中读取数据，那么 B\r\n的接收缓存最终会被填满 。\r\n一旦缓存溢出，B\r\n将不得不丢弃后续到达的数据包，从而导致数据丢失 。\r\n为了解决这个问题，TCP 引入了流量控制 (Flow Control)\r\n机制，用于防止发送方发送数据太快，导致接收方来不及接收。\r\n核心思想是,\r\n让接收方根据自己的接收能力（即接收缓存的可用空间大小），来反向控制发送方的发送速率。\r\n\r\n与“拥塞控制”的区别： 流量控制：\r\n是一个端到端的问题。它只关心“我（发送方）”和“你（接收方）”之间的速度匹配，防止“我”把“你”的缓存撑爆。\r\n拥塞控制：\r\n是一个全局性的问题。它关心的是整个网络的健康状况，防止过多的数据注入网络导致路由器瘫痪，是“我（发送方）”与“整个网络”之间的协调。我们稍后会详细讨论拥塞控制。\r\n\r\nTCP 的流量控制方法：滑动窗口\r\nTCP 使用滑动窗口 (Sliding Window)\r\n机制来巧妙地实现流量控制, 使用到了 TCP 首部中的\r\n“窗口”字段。\r\n该字段的值由接收方设置，用来通告自己的接收窗口\r\n(Receiver Window, rwnd) 大小。rwnd\r\n的值等于接收方当前接收缓存的可用空间大小。\r\n\r\n接收方 B 通过这个字段告诉发送方 A：“我的仓库（接收缓存）现在还剩下\r\nrwnd 字节的空位，你接下来最多只能再发给我 rwnd 字节的数据。”\r\n\r\n发送方 A 收到 B 发来的 rwnd\r\n值后，会调整自己的发送窗口 (Sender Window,\r\nswnd)，确保其小于或等于 B 通告的 rwnd。\r\n这样，发送方 A 就被限制住了，其发送速率自动地受到了接收方 B\r\n接收能力的制约。\r\n让我们通过一个实例来理解这个动态过程。假设 A 给 B 发送数据，B 对 A\r\n进行流量控制 。\r\n\r\n初始状态： 建立连接时，B 告诉 A：“我的 rwnd=400” 。A 将自己的\r\nswnd 也设置为 400 。\r\nA 开始发送： A 连续发送了 4 个报文段（1-100, 101-200,\r\n201-300(丢失), 301-400） 。\r\nB 第一次流量控制： B 收到了 1-100 和 101-200。但此时 B\r\n的应用进程只取走了 100 字节的数据，导致接收缓存只空出了 300 字节。B\r\n发送确认：ack=201（期望 201 号字节），rwnd=300（我只剩 300 字节空间了）\r\n。\r\nA 调整速率： A 收到 rwnd=300 的通知，立即将自己的 swnd 调整为 300\r\n。\r\nA 超时重传： A 发现 201-300 的报文段超时，于是重传 201-300\r\n。\r\nB 第二次流量控制： B 收到了重传的 201-300，以及之前收到的\r\n301-400, 401-500。此时 B 的缓存被占满，只剩 100 字节。B\r\n发送确认：ack=501，rwnd=100 。\r\nA 再次调整： A 收到 rwnd=100，将 swnd 调整为 100 。\r\nA 发送最后数据： A 发送 501-600 。\r\nB 第三次流量控制 (零窗口通知)： B 收到 501-600，此时 B\r\n的接收缓存彻底满了，可用空间为 0。B 发送确认：ack=601，rwnd=0\r\n。\r\nA 停止发送： A 收到 rwnd=0，将 swnd 调整为 0 。此时，A\r\n不能再发送任何普通的 TCP 数据报文段 。\r\n\r\n\r\n\r\nalt text\r\n\r\n但是, 上述第 10 步带来了一个严重问题：A 正在等待 B\r\n发送一个非零的 rwnd 通知，才能继续发送数据 。\r\n假设 B 的应用进程终于读取了数据，缓存空出来了（例如 rwnd 变为\r\n300）。B 很高兴地向 A 发送了一个 rwnd=300 的“非零窗口通知”报文段\r\n。但是，这个 ACK 报文段在网络传输中丢失了！\r\n结果是：A 永远在等待 B 的窗口更新通知（它不知道那个通知丢失了） 。B\r\n永远在等待 A 发送更多数据（它不知道 A 的 swnd 还是 0）\r\n。双方陷入了永久的互相等待，连接死锁\r\n为了打破这种由“非零窗口通知丢失”引起的死锁，TCP\r\n设计了持续计时器 。\r\n\r\n启动：当发送方 A 收到对方 B 发来的零窗口通知 (rwnd=0) 时，A\r\n就启动持续计时器 。\r\n超时： 当持续计时器超时后，A\r\n会主动发送一个“零窗口探测报文段” (Zero-Window Probe)\r\n。\r\n探测报文： 这个探测报文段通常只携带 1 字节的数据 。\r\nB 的响应： 接收方 B 在收到这个探测报文段时，必须回复一个\r\nACK 报文，并在 ACK 中通告自己当前最新的 rwnd 值 。 &gt;\r\nTCP协议规定, 即使 rwnd=0, 接收方也必须接收零窗口确认报文,\r\n确认报文以及携带紧急数据的报文\r\n\r\n情况 1： 如果 B 的 rwnd 仍然是 0。A 收到 rwnd=0 的 ACK\r\n后，重置持续计时器，等待下一个超时再继续探测 。\r\n情况 2： 如果 B 的 rwnd 已经恢复为 300（那个丢失的 ACK\r\n就是想通知这个）。A 收到 rwnd=300 的 ACK 后，就知道可以继续发送数据了\r\n。死锁被打破 。\r\n\r\n\r\n\r\n鲁棒性： 如果 A 发送的“零窗口探测报文段”自己也丢失了怎么办？\r\n没关系，探测报文段本身也受超时重传机制保护\r\n。如果探测报文丢失，A\r\n会在另一个计时器（重传计时器）超时后，重传这个探测报文，确保探测动作一定能被\r\nB 收到。\r\n\r\nTCP 的拥塞控制\r\nTCP 拥塞控制是 TCP 协议中最为复杂、也最为关键的机制之一。它决定了 TCP\r\n如何在保证可靠性的同时，最大限度地利用网络带宽，而又不会导致网络崩溃。\r\n什么是拥塞\r\n(Congestion)？简而言之，就是“僧多粥少”。当网络中某一资源（如链路带宽、路由器缓存、处理机）的需求超过了该资源所能提供的可用部分时，网络性能就会变坏，这种情况就叫作拥塞\r\n。\r\n如果没有拥塞控制，所有主机都试图以最快速度发送数据，很快就会超出网络（尤其是路由器）的处理极限\r\n。这会导致路由器缓存溢出、大量数据包被丢弃，发送方因收不到确认而集体超时重传，这又进一步加剧了网络拥塞，最终可能导致网络吞吐量急剧下降甚至为\r\n0，即“拥塞崩溃” (Congestion Collapse)。\r\n目前, TCP 的拥塞控制方法是隐式闭环控制 -\r\n闭环控制 (Closed-Loop)： TCP\r\n采用基于反馈的控制方法\r\n。它包含监测、通知和调整三个步骤\r\n。 - 隐式反馈 (Implicit Feedback)：\r\n网络中的路由器不会显式地告诉 TCP“我快不行了”。TCP\r\n必须推断网络是否发生了拥塞. 而TCP\r\n判断拥塞的依据就是超时重传（Timeout） 。TCP\r\n发送方认为，数据包在网络中丢失（导致超时）的主要原因就是网络拥塞（路由器繁忙而丢弃了分组）\r\n。\r\nTCP 的四种拥塞控制方法\r\nTCP 的发送方需要额外维护两个非常重要的状态变量：\r\n\r\n拥塞窗口 (Congestion Window,\r\ncwnd)：是发送方根据网络拥塞程度估算出的一个窗口值。它代表了在收到确认前，发送方最多可以发送多少数据。\r\n\r\n注意： 发送方真正的发送窗口 swnd，是取拥塞窗口 cwnd 和流量控制窗口\r\nrwnd 中的较小值 ，即：swnd = min(cwnd, rwnd)\r\n(在接下来的讨论中，我们假设接收方总是有足够大的缓存，即 rwnd\r\n很大，因此 swnd = cwnd )。\r\n\r\n慢开始门限 (Slow Start Threshold,\r\nssthresh)：这是一个边界值，用于区分何时使用“慢开始”算法，何时使用“拥塞避免”算法\r\n。\r\n\r\ncwnd &lt; ssthresh 时： 使用慢开始算法 。\r\ncwnd &gt; ssthresh 时： 使用拥塞避免算法 。\r\ncwnd = ssthresh 时： 两者皆可 。\r\n\r\n\r\n这四种算法是一个协同工作的完整流程\r\n慢开始 (Slow-Start)\r\n目的：在连接刚建立或超时重传后，采用指数增长的方式快速探测网络的可用带宽。这里的“慢”指的是初始拥塞窗口（cwnd）很小（通常为\r\n1 MSS），而不是增长速度慢。\r\n算法流程： - 连接建立时，cwnd = 1 MSS（假设初始\r\nssthresh = 16 MSS）。 - 每收到一个对新报文段的确认（ACK），cwnd 增加 1\r\nMSS。\r\n效果（指数增长）：假设往返时延（RTT）固定。 - 第 1\r\n轮：发送 1 个报文段，收到 1 个 ACK，cwnd 变为 2 MSS。 - 第 2 轮：发送 2\r\n个报文段，收到 2 个 ACK，cwnd 变为 4 MSS。 - 第 3 轮：发送 4\r\n个报文段，收到 4 个 ACK，cwnd 变为 8 MSS。 - 以此类推，cwnd 每经过一个\r\nRTT 就会翻倍。\r\n结论：慢开始阶段，cwnd 以指数速度增长，直到达到\r\nssthresh 阈值或发生丢包事件。\r\n拥塞避免 (Congestion\r\nAvoidance)\r\n目的：当 cwnd 增长到 ssthresh\r\n门限后，说明已经接近网络容量，此时需要减缓增长速度，转为线性增长，小心地探测可用带宽。\r\n算法：当 cwnd ≥ ssthresh 时，进入拥塞避免阶段。此时，每经过一个\r\nRTT（即收到了上一轮发出的所有报文段的 ACK），cwnd 的值只增加 1 MSS。\r\n效果（线性增长）：cwnd = 16 → 17 → 18 → …\r\n到此为止，TCP\r\n窗口一直在增长，但什么时候停止？答案是：直到出现拥塞。TCP\r\n感知拥塞有两种方式：\r\n\r\nA. 发生“超时重传”（严重拥塞）\r\n\r\n判断： 发送方等待了很久（RTO 超时）也没收到\r\nACK，认为网络发生了严重拥塞（数据包和 ACK 都可能丢了）。\r\n动作 (TCP Tahoe/Reno 共同点)：\r\n\r\n更新门限： ssthresh = 当前 cwnd / 2 。\r\n重置窗口： cwnd = 1 。\r\n重新开始： 立即退回到慢开始阶段 。\r\n\r\n如图, cwnd 增长到 24 时超时。ssthresh = 24 / 2 = 12。cwnd =\r\n1。重新从 1 开始慢开始，直到 cwnd 增长到 12\r\n时，再切换到拥塞避免。\r\n这是 TCP 拥塞控制中最保守的反应方式, 1988 年提出的 TCP Tahoe\r\n就采取了这种方法。到了 1990 年, TCP Reno\r\n引入了更为激进的“快重传”和“快恢复”机制, 以提高网络利用率。 \r\n\r\nB. 轻微拥塞（3 个重复 ACK）\r\n\r\n有时网络并未发生严重拥塞，只是个别报文段丢失（如 M3 丢失） 。但\r\nM4, M5, M6 仍然按时到达了接收方。\r\n接收方动作： 接收方收到 M4、M5、M6（失序报文）时，会立即发送对 M2\r\n的重复确认（M2 是最后一个按序收到的） 。\r\n发送方动作： 当发送方连续收到 3 个对 M2\r\n的重复确认（Dup-ACKs）时，它不等超时，立即触发快速重传\r\n(Fast Retransmit) 机制，重传丢失的 M3 。\r\n这种机制基于一个假设：如果网络发生了严重拥塞，导致大量报文段丢失，那么发送方不会收到这么多重复\r\nACKs，因为 ACKs 也会丢失。因此，收到 3 个重复 ACKs\r\n通常意味着只是个别报文段丢失，网络状况还不错。因此, 为了提高效率,\r\n发送方可以立即重传丢失的报文段，而不必等到超时。 ######\r\n快重传 (Fast Retransmit)\r\n\r\n\r\n动作： 发送方立即重传它认为丢失的那个报文段（即\r\nM3），而不必等待超时计时器到期, 从而极大地提高了重传效率 。\r\n快恢复 (Fast Recovery)\r\n既然发送方能收到 3 个重复\r\nACK，说明网络只是丢了个别包，信道并没有瘫痪。如果此时像超时一样把 cwnd\r\n降为 1（慢开始），就太保守了。\r\n算法（与快重传配合使用）：\r\n\r\n更新门限： ssthresh = 当前 cwnd / 2 。\r\n设置窗口： cwnd = ssthresh （而不是降为 1）。\r\n进入阶段： 立即跳过慢开始，直接进入拥塞避免阶段（cwnd 线性增长）\r\n。\r\n\r\n如图, cwnd 增长到 16 时收到 3 个重复 ACK。ssthresh = 16 / 2 = 8。cwnd\r\n= 8。立即从 8 开始执行拥塞避免（线性增长到 9, 10…） 。\r\n\r\n\r\nalt text\r\n\r\n总结\r\nTCP 的拥塞控制就是在这四种算法之间，根据收到的 ACK\r\n情况（正常、超时、3 个重复 ACK）不断切换的动态过程：\r\n\r\n启动：慢开始（cwnd=1）。\r\n慢开始阶段：cwnd 指数增长。\r\n\r\n如果发生超时：\r\n\r\nssthresh = cwnd / 2\r\ncwnd = 1\r\n返回慢开始阶段。\r\n\r\n如果收到3 个重复 ACK：\r\n\r\n进入快恢复：\r\n\r\nssthresh = cwnd / 2\r\ncwnd = ssthresh\r\n进入拥塞避免阶段。\r\n\r\n\r\n如果 cwnd ≥ ssthresh：\r\n\r\n进入拥塞避免阶段。\r\n\r\n\r\n拥塞避免阶段：cwnd 线性增长。\r\n\r\n如果发生超时：\r\n\r\nssthresh = cwnd / 2\r\ncwnd = 1\r\n返回慢开始阶段。\r\n\r\n如果收到3 个重复 ACK：\r\n\r\n进入快恢复：\r\n\r\nssthresh = cwnd / 2\r\ncwnd = ssthresh\r\n保持在拥塞避免阶段。\r\n\r\n\r\n\r\n\r\n这种机制保证了 TCP\r\n能根据网络状况动态调整发送速率，实现高效且可靠的数据传输。\r\n\r\n\r\nalt text\r\n\r\nTCP\r\n拥塞控制与网际层拥塞控制的关系\r\nTCP\r\n的拥塞控制（发送方根据网络状况调整发送速率）是一种隐式反馈机制。它依赖于猜测网络是否拥塞（通过超时或重复\r\nACK）。\r\n然而，网络中的路由器（工作在网际层）是真正处理拥塞的地方。因此，路由器如何处理（或丢弃）IP\r\n数据报的策略，将极大地影响 TCP 的行为 。\r\n传统的丢弃策略：尾部丢弃 (Tail-drop Policy),\r\n这是最简单、最被动的一种路由器队列管理策略。\r\n路由器的输入缓存（队列）通常按照“先进先出”（FIFO）的规则处理 IP\r\n数据报。由于队列长度有限，当队列已满时，之后所有新到达的 IP\r\n数据报都将被丢弃 。\r\n然而,\r\n这种策略非常“被动”，它要等到问题（队列已满）发生后才开始丢包,\r\n在网络拥塞时会引发一个灾难性的连锁反应，称为全局同步。发生过程（多米诺骨牌效应）：\r\n\r\n路由器拥塞： 大量 TCP\r\n连接的数据流涌入某个路由器，导致其队列被填满。\r\n尾部丢弃：\r\n路由器开始丢弃所有后续到达的报文段，这可能同时来自多个不同的 TCP\r\n连接。\r\n集体超时： 这些 TCP\r\n连接的发送方会（大约在同一时间）因收不到确认而集体发生超时重传。\r\n集体慢开始： 根据 TCP 拥塞控制算法（5.3.4\r\n节），发生超时重传被视为严重拥塞。因此，所有这些 TCP\r\n连接会同时将自己的拥塞窗口 cwnd 降为\r\n1，并集体进入慢开始阶段。\r\n\r\n后果是网络通信量骤降,\r\n整个网络的通信量突然大幅下降。而网络恢复后通信量又激增：\r\n在网络恢复正常后，这些连接又会（大约在同一时间）一起开始“慢开始”的指数增长，导致通信量突然激增，很可能再次引发拥塞和另一次全局同步\r\n。\r\n也就是说, 网络吞吐量会在高位和低位之间产生剧烈振荡，效率极低。\r\n为了解决“尾部丢弃”和“全局同步”问题，IETF 在 1998\r\n年提出了主动队列管理 (Active Queue Management,\r\nAQM) 的思想: “未雨绸缪”，而不是“亡羊补牢”。\r\n路由器不应该等到队列已满（被动）才开始丢包，而应在队列长度达到某个“值得警惕”的阈值时（即出现拥塞征兆时），就主动地开始丢弃\r\nIP 数据报 。\r\n通过“主动”丢包，AQM 故意让个别 TCP\r\n连接的发送方提前（早于其他连接）感知到拥塞（通过超时或快重传），从而提前降低发送速率\r\n。\r\n这就避免了所有 TCP 连接在同一时刻集体超时，从而避免了全局同步。\r\nRED（也称随机早期丢弃）是 AQM\r\n中最著名的一种实现算法. 工作机制为：\r\n\r\n路由器维护两个队列长度门限：最小门限和最大门限。\r\n路由器会持续计算平均队列长度（注意：是“平均”长度，不是瞬时长度，这可以平缓突发流量）。\r\n当一个新数据报到达时，RED 按以下规则处理：\r\n\r\n若平均队列长度 &lt; 最小门限：存入队列（网络良好）。\r\n若平均队列长度 &gt;\r\n最大门限：丢弃数据报（拥塞严重，退化为尾部丢弃）。\r\n若平均队列长度 在 最小门限 和 最大门限 之间：按一个概率 p 丢弃该数据报。\r\n\r\n\r\n这里的早期 (Early)指的是在队列未满时，就开始丢包（平均队列长度 &gt;\r\n最小门限）。\r\n随机(Random)则是在警告阶段（两门限之间），按概率 p\r\n随机丢包。这个“随机性”是关键，它确保了丢包被分散到不同的 TCP\r\n连接上，而不是像“尾部丢弃”那样惩罚同一时刻到达的所有连接。\r\n通过随机地让个别 TCP 连接减速，RED 有效地避免了全局同步问题。\r\nTCP 可靠传输的实现\r\nTCP\r\n可靠传输基于字节流模型和动态滑动窗口机制。为便于理解，假设数据单向传输（发送方\r\n→ 接收方），暂不考虑拥塞控制（即 swnd = rwnd）。\r\n1. 发送窗口 (swnd) 与接收窗口\r\n(rwnd)\r\n\r\n接收窗口\r\n(rwnd)：由接收方通告，反映其接收缓存的可用空间，是流量控制的依据。\r\n发送窗口\r\n(swnd)：由发送方维护，任意时刻必须小于等于接收方通告的\r\nrwnd。\r\n\r\n2. 发送方的工作机制\r\n发送方维护一个发送缓存，并用三个指针标记数据状态：\r\n\r\nP1：指向“已发送且收到确认”的下一个字节（窗口后沿）。\r\nP2：指向“已发送但未收到确认”的下一个字节。\r\nP3：指向“允许发送但尚未发送”的下一个字节（窗口前沿）。\r\n\r\n缓存区域划分如下：\r\n\r\n灰色区域\r\n(&lt;P1)：已发送且收到确认的数据，可从缓存删除。\r\n蓝色区域\r\n([P1…P2-1])：已发送但未确认的数据，需保留以便重传。\r\n绿色区域\r\n([P2…P3-1])：允许发送但尚未发送的数据，可随时发送。\r\n白色区域 (≥P3)：超出窗口的数据，暂不可发送。\r\n\r\n窗口滑动机制：\r\n\r\n窗口后沿 (P1) 前移：收到新的累积确认（如\r\nack=34），P1 前移到 34，表示 34 之前的数据已被确认。\r\n窗口前沿 (P3) 前移：P3 = P1 + rwnd。P1 前移或 rwnd\r\n增大时，P3 前移；rwnd 减小时，P3\r\n后移（但标准不建议后移，避免已发送数据变为“非法”）。\r\n\r\n3. 接收方的工作机制\r\n接收方维护接收缓存，大小等于 rwnd，处理按序和失序数据：\r\n\r\n按序到达：若收到期望的下一个字节（如\r\n31），接收方将其及后续连续数据（如 32,\r\n33）交付应用层，窗口滑动，发送累积确认（ack=34）。\r\n失序到达：若收到非期望字节（如 32, 33，期望\r\n31），接收方通常缓存失序数据，但不能确认，只能发送重复确认（ack=31），提示发送方缺失数据。\r\n\r\n4. 可靠传输的补充说明\r\n\r\n累积确认 (Cumulative ACK)：ack=N 表示 N − 1\r\n之前所有字节已收到。优点是简单、ACK\r\n报文少；缺点是丢包时无法告知后续数据已收到（可用 SACK 选项优化）。\r\n推迟确认 (Delayed ACK)：接收方可延迟发送\r\nACK（如最多 0.5 秒），以减少纯 ACK\r\n报文数量，但延迟过久可能导致发送方误判超时。\r\n失序数据处理：标准未强制要求缓存失序数据，但现代实现通常缓存失序数据，待缺失部分补齐后再交付应用层，提高效率。\r\n全双工通信：上述机制在通信双方均独立运行，每方既管理自己的\r\nswnd，也处理对方的 rwnd。\r\n\r\n\r\n\r\nalt text\r\n\r\nTCP 超时重传时间 (RTO) 的选择\r\n超时重传时间 (Retransmission Timeout, RTO) 的选择是 TCP\r\n最复杂的问题之一 。这个时间设置得是长是短，会产生截然不同的后果：\r\n\r\nRTO 设置得太短:\r\n报文段可能并没有丢失，只是在网络中传输得慢了一点。但 RTO\r\n已经超时，导致发送方不必要地重传了报文段,\r\n增大了网络负荷，可能导致网络更加拥塞 。\r\nRTO 设置得太长 (见图\r\n5-43)：报文段确实丢失了，但发送方需要等待很长一段时间（RTO）后才能发现并重传。这会使重传推迟的时间太长，导致网络空闲时间增大，降低了数据传输效率\r\n。\r\n\r\n显而易见，理想的 RTO\r\n的值应该设置为略大于报文段的往返时间\r\n(RTT) 。\r\n理想很美好，但现实是 RTT 并不是一个固定值。TCP\r\n下层是复杂的因特网，数据包可能经过高速率的局域网，也可能经过低速率、高拥塞的广域网，路由还可能随时变化.\r\n第一次测得的 RTT0\r\n可能很短，但第二次测得的 RTT1\r\n可能非常长\r\n因此, RTO\r\n必须是一个动态的、自适应的值，不能基于某一次的 RTT\r\n样本来“写死”。\r\n加权平均往返时间 (RTTs): 为了平缓 RTT\r\n的瞬时波动，TCP 不使用单个 RTT 样本，而是计算一个加权平均往返时间\r\n(Smoothed RTT, RTTS)。该值综合了历史\r\nRTT 样本和最新 RTT\r\n样本的信息，反映了当前的网络状况。\r\n计算公式： - 首次测量： RTTS\r\n直接取第一个 RTT 样本的值 - 后续测量： 新的\r\nRTTS = (1 − α) × 旧的\r\nRTTS + α × 新的\r\nRTT样本 . - [RFC 6298] 推荐 α 的值为 1/8 (即 0.125) ,\r\n这意味着新的 RTTS\r\n87.5% 取决于历史平均值，12.5% 取决于刚测到的新样本。这使得 RTTS\r\n的变化非常平滑。\r\n根据计算, RTTS\r\n是一个平滑的平均值，但 RTO 必须比它大，而且要大到足以覆盖 RTT 的正常抖动\r\n(Jitter)。因此，TCP 引入了 RTT 偏差的加权平均值\r\nRTTD。\r\n- 计算 RTTD\r\n(RTT 偏差的加权平均值)： - 目的： 测量 RTT 的抖动程度。 - 公式： 新的\r\nRTTD = (1 − β) × 旧的\r\nRTTD + β × |RTTS − 新的\r\nRTT样本| - 计算 RTO (超时重传时间)：\r\nRTO = RTTS + 4 × RTTD\r\n- 理解： RTO 等于“平均往返时间”加上一个“4 倍的安全抖动余量”。\r\n这个余量确保即使 RTT 有较大波动，RTO 仍然足够大，不会频繁超时。\r\n不过, 上述讨论还面临一个最大的难题：ACK 的歧义性\r\n(ACK Ambiguity)\r\n所有公式都依赖一个前提：我们能准确测量 RTT\r\n样本。但在发生超时重传时，RTT 的测量会变得极其困难 。\r\n场景 1：报文丢失\r\n\r\nA 发送“原报文段”，计时开始。\r\n报文丢失 。\r\nA 超时，重传“重传报文段”。\r\nA 收到 B 对“重传报文段”的 ACK。\r\n\r\n此时 A 无法判断这个 ACK\r\n是对“原报文段”的（迟到的）确认，还是对“重传报文段”的确认 。\r\n如果 A 误以为这是对“原报文段”的确认，它计算出的 RTT 样本会极大，导致\r\nRTO 变得过大，降低传输效率 。\r\n场景 2：ACK 迟到\r\n\r\nA 发送“原报文段”，计时开始。\r\nB 收到并发送 ACK，但 ACK 在网络中长时间滞留 。\r\nA 超时，重传“重传报文段”。\r\nA 收到 B（迟到的）对“原报文段”的 ACK。\r\n\r\n同样, A 无法判断这个 ACK\r\n是对“原报文段”的确认，还是对“重传报文段”的确认 。\r\n如果 A 误以为这是对“重传报文段”的确认，它计算出的 RTT\r\n样本会极小，导致 RTO 变得过小，引发未来不必要的重传。\r\n目前的解决方案是 Karn 算法及其修正Karn\r\n算法：为了解决上述的歧义性问题，Karn\r\n提出了一个简单的算法：只要一个报文段重传了，就不采用它返回的 ACK\r\n所计算出的 RTT 样本。\r\n换句话说，发生重传时，不更新 RTTS\r\n和 RTO 。\r\nKarn 算法的问题：设想网络时延突然永久性增大（例如路由变更）。A\r\n会发现原 RTO 太短，导致超时重传。根据 Karn 算法，A 会忽略这个重传报文的\r\nRTT 样本（这个样本本可以反映新的网络时延）。RTO 永远得不到更新，导致 A\r\n不断地重传，网络效率极低。\r\nKarn 算法修正 (指数退避)：为了解决这个问题，Karn\r\n算法增加了修正条款：报文段每重传一次，就把 RTO\r\n增大一些。典型的做法是将新的 RTO 值取为旧 RTO 值的 2 倍。\r\nTCP 的选择确认 (Selective\r\nACK, SACK)\r\nTCP 默认使用累积确认（Cumulative ACK），即 ack=N 表示“到 N − 1\r\n为止的所有字节我都收到了”。但在如下场景下效率很低：\r\n\r\n发送方依次发送 1-1000、1001-1500、1501-3000、3001-3500、3501-4500\r\n等数据块。\r\n接收方正确收到 1-1000，但 1001-1500 丢失，后续的 1501-3000 和\r\n3501-4500 却已收到。\r\n由于 1001-1500 未到，接收方只能不断发送 ack=1001（期望收到\r\n1001），无法告知发送方后续数据已收到。\r\n发送方收到重复的 ack=1001，只能重传 1001-1500，却不知道 1501-3000 和\r\n3501-4500 已经安全抵达，可能会不必要地重传这些块，浪费带宽。\r\n\r\n为解决上述问题，TCP 引入了选择确认（SACK）选项。SACK\r\n允许接收方在发送累积确认（ack=1001）的同时，额外报告已收到的非连续数据块。\r\nSACK 的工作机制：\r\n\r\n协商：SACK 是可选项，需在三报文握手阶段双方协商支持。\r\n原 ACK 字段不变：确认号字段仍为累积确认。\r\nSACK 选项格式：每个 SACK 块由两个 32\r\n位序号组成，分别表示该块的左边界（第一个字节序号）和右边界（最后一个字节序号\r\n+ 1）。\r\n\r\n回到上述场景，接收方会发送一个 TCP 报文段：\r\n\r\n确认号字段：ack=1001（累积确认）\r\nSACK 选项：报告块 1：L1=1501, R1=3001（表示 1501-3000\r\n已收到）；报告块 2：L2=3501, R2=4501（表示 3501-4500 已收到）\r\n\r\n发送方收到 SACK 后，明确知道只需重传 1001-1500 和\r\n3001-3500，无需重传已收到的数据块，从而显著提高效率。\r\nSACK 的限制：\r\n\r\nTCP 首部选项字段最大为 40 字节\r\n每个 SACK 块需 8 字节（4 字节左边界 + 4 字节右边界）\r\nSACK 选项本身还需 2 字节（类型和长度）\r\n因此，一个 TCP 报文最多可报告 4 个 SACK 块（8 × 4 + 2 = 34 ≤ 40）\r\n\r\nTCP 窗口和缓存的关系\r\n在之前的讨论中，我们经常交替使用“窗口”和“缓存”这两个词，但它们在物理上是不同的概念\r\n。理解它们的区别对于深入掌握 TCP 流量控制至关重要。\r\n发送缓存 (Sending Buffer)：\r\n\r\n定义：这是 TCP\r\n在内存中为一条连接分配的物理存储区域 。\r\n作用：它用来存放所有“待处理”的数据，具体包括:\r\n\r\n发送方应用进程已经写入、但 TCP 尚未发送的数据\r\n。\r\nTCP 已发送、但尚未收到确认 (ACK)\r\n的数据（这些数据必须保留，以便超时重传） 。\r\n\r\n\r\n发送窗口 (Sending Window, swnd)：\r\n\r\n定义：这是一个逻辑上的概念，它代表“当前允许发送的数据范围”。\r\n关系：发送窗口通常只是发送缓存的一部分 。\r\n发送缓存的左边界（起始点）与发送窗口的左边界（即“已发送但未收到确认”的第一个字节）重合\r\n。当 TCP 收到新的 ACK，窗口和缓存的左边界一起前移，ACK\r\n之前的数据被从缓存中删除 。\r\n发送缓存的右边界则由应用进程决定（应用进程写入了多少数据）。\r\n制约： 应用进程写入缓存的速率必须受到控制，不能超过 TCP\r\n发送和确认的速率，否则发送缓存会溢出 。\r\n\r\n\r\n\r\nalt text\r\n\r\n接收缓存 (Receiving Buffer)：\r\n\r\n定义： 接收方 TCP 在内存中分配的物理存储区域 。\r\n作用： 它用来存放所有已收到但尚未被应用进程读取的数据，具体包括：\r\n\r\n按序到达的、但尚未被应用进程读取的数据 。\r\n未按序到达的、暂时无法交付给应用进程的数据（如 SACK\r\n机制中提到的那些不连续块） 。\r\n\r\n\r\n接收窗口 (Receiving Window, rwnd)：\r\n\r\n定义：这是一个逻辑概念，代表接收缓存中当前的可用空间 。\r\n关系：rwnd 的大小 = 接收缓存总大小 - (已按序到达未读数据 +\r\n已未按序到达数据)。\r\n接收缓存的总大小是固定的。\r\n随着数据（无论是按序还是失序）的到达，缓存被占用，rwnd（可用空间）减小\r\n。\r\n随着接收方应用进程从缓存中读取数据（只能读取按序的数据），缓存被释放，rwnd\r\n增大 。\r\n\r\n\r\n\r\nalt text\r\n\r\n流量控制的实现就在于接收方将这个动态变化的 rwnd\r\n值，填入它所发送的 ACK 报文首部的“窗口”字段中，通告给发送方 。\r\n如果应用进程停止读取，缓存会被填满，rwnd 变为 0 。\r\n发送方收到 rwnd=0\r\n后，就会停止发送数据（触发持续计时器），从而实现了流量控制 。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"条款 25 - 针对右值引用实施 std move, 针对万能引用实施 std forward","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE25%20-%20%E9%92%88%E5%AF%B9%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E5%AE%9E%E6%96%BD%20std%20move,%20%E9%92%88%E5%AF%B9%E4%B8%87%20%E8%83%BD%E5%BC%95%E7%94%A8%E5%AE%9E%E6%96%BD%20std%20forward/","content":"我们在条款23了解了std::move 与 std::forward,\r\n而条款25提供了一个简单、强大且几乎永远正确的指导方针，用于决定何时使用\r\nstd::move 以及何时使用 std::forward, 那就是: -\r\n对右值引用，总是使用 std::move\r\n来进行转发。 - 对万能引用，总是使用\r\nstd::forward 来进行转发。\r\nstd::move 用于右值引用\r\n右值引用（如\r\nWidget&amp;&amp;）在形参中有一个明确的特性：它只能绑定到右值，即那些可以被移动的对象。虽然形参本身（例如\r\nrhs）是一个左值，但我们确切地知道它所引用的对象是临时的或被显式标记为可移动的。\r\n因此，当我们要将这个形参传递给其他函数（例如，在构造函数中初始化成员）时，我们应该无条件地将其转换为右值，以触发移动操作。std::move\r\n就是执行这种无条件转换的工具。\r\n如下, 在移动构造函数中，形参 rhs 是一个右值引用。我们使用 std::move\r\n来移动其成员 name 和 p 到当前对象的成员中。 class Widget {public:    Widget(Widget&amp;&amp; rhs) // rhs 是右值引用      : name(std::move(rhs.name)), // 对 rhs 的成员实施移动        p(std::move(rhs.p))    { ... }private:    std::string name;    std::shared_ptr&lt;SomeDataStructure&gt; p;};\r\n这个指导方针也适用于按值返回的函数。当你在 return\r\n语句中返回一个绑定到右值引用的形参对象时，应该相应地使用\r\nstd::move 来避免拷贝, 提升效率。 Matrix operator+(Matrix&amp;&amp; lhs, const Matrix&amp; rhs) {    lhs += rhs;    return std::move(lhs); // 将 lhs 移动到返回值中}\r\n然而, 如果你的 return 语句中返回的是局部变量,\r\n千万不要对局部变量使用 std::move,\r\n例如这样的代码 Widget makeWidget() {    Widget w;    // ...    return std::move(w); // 错误的做法！} 上述两者之所以不同, 是因为 C++\r\n编译器具有返回值优化(Return Value Optimization, RVO)\r\n机制。对于 return w;\r\n这样的语句，编译器通常可以直接在为函数返回值分配的内存中构造\r\n局部变量w，从而完全避免任何复制或移动操作。同时, C++标准规定，在\r\nreturn 语句中，局部变量会被自动视为右值。这意味着 return w;\r\n的行为等同于 return std::move(w);\r\n如果使用 std::move(w) 会将 w\r\n转换为右值引用。返回一个局部对象的引用会阻止编译器执行 RVO。因此，添加\r\nstd::move 不仅没有好处，反而可能阻止一项重要的编译器优化，弄巧成拙,\r\n导致性能下降。\r\n而返回形参时, 由于形参不是函数内部创建的局部对象,\r\n被视为左值，且不受RVO规则的约束。为了触发移动，你必须使用 std::move\r\nstd::forward 用于万能引用\r\n万能引用（在模板中声明为\r\nT&amp;&amp;）则不同，它既可以绑定到右值，也可以绑定到左值。我们需要在转发它时保留其原始的左/右值属性。如果原始实参是右值，我们就应该将其作为右值转发；如果原始实参是左值，我们就应该将其作为左值转发\r\n。\r\n因此, std::forward 正是执行这种有条件的转换的工具。它会检查模板参数 T\r\n的推导类型，并仅在原始实参是右值的情况下，才将形参转换为右值。\r\n如下,在一个接受万能引用的 setName 函数中，我们使用 std::forward 来将\r\nnewName 转发给成员 name 的赋值运算符, 从而确保了当 setName\r\n接收到右值时，会触发 std::string\r\n的移动赋值；而当接收到左值时，则触发复制赋值。 class Widget {public:    template&lt;typename T&gt;    void setName(T&amp;&amp; newName) { // newName 是万能引用        name = std::forward&lt;T&gt;(newName); // 转发 newName    }    // ...};std::string getWidgetName(); // 工厂函数，返回右值Widget w;w.setName(getWidgetName()); // 调用时传入右值，setName 内部发生移动赋值auto n = getWidgetName();w.setName(n); // 调用时传入左值 n，setName 内部发生复制赋值 &gt;\r\n如果在万能引用上误用\r\nstd::move，将导致一个严重的bug：它会无条件地将形参转换为右值，即使调用者传入的是一个左值。这会导致调用者的局部变量被意外“掏空”\r\n同理, 当你在 return\r\n语句中返回一个绑定到万能引用形参的对象时，应该相应地使用\r\nstd::forward。这里的情况与上述的std::move一致 template&lt;typename T&gt;Fraction reduceAndCopy(T&amp;&amp; frac) // frac 是一个万能引用{    frac.reduce();    // 关键：按值返回，但使用 std::forward 转发 frac    return std::forward&lt;T&gt;(frac); }\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 27 - 熟悉依万能引用型别进行重载的替代方案","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE27%20-%20%E7%86%9F%E6%82%89%E4%BE%9D%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%9E%8B%E5%88%AB%E8%BF%9B%E8%A1%8C%E9%87%8D%E8%BD%BD%E7%9A%84%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/","content":"条款26明确指出，对万能引用进行重载是一个坏主意，因为它过于“贪婪”，会意外地匹配到许多本意是想调用其他重载函数的调用。本条款则提供了多种替代方案，让我们可以在需要区分处理不同类型的同时，安全地使用万能引用的强大功能。\r\n简单的替代方案\r\n在介绍复杂技术之前，有几种简单的替代方法：\r\n\r\n舍弃重载，使用不同函数名：这是最简单的办法。与其重载\r\nlogAndAdd(T&amp;&amp;) 和 logAndAdd(int)，不如创建两个名字不同的函数，如\r\nlogAndAddName 和\r\nlogAndAddByIdx。这完全避免了重载决议的问题。但它的缺点是无法用于构造函数，因为构造函数的名称是固定的。\r\n传递 const T&amp;：放弃完美转发，回归 C++98 的 const T&amp;\r\n传参方式(同样可以接受左值和右值)。这种方法简单，但牺牲了完美转发带来的效率（例如，无法移动右值，也无法避免为字符串字面量等创建临时对象）。\r\n传值：将参数按值传递。这在某些情况下能够提升性能，但其适用场景和利弊权衡非常复杂（条款41有详细讨论），并非一个通用的解决方案。\r\n\r\n标签分派 (Tag Dispatch)\r\n标签分派是一种在编译期根据类型的某些“属性”（而非类型本身）来选择不同函数实现的技术。它通过创建一系列空的“标签”类型（通常是空结构体\r\nstruct），并利用函数重载机制，让编译器根据传入的标签类型自动选择最优或最正确的代码路径。这是一种强大且经典的模板元编程技术，可以完美解决重载问题。\r\n理解标签分派\r\n为了在将标签分派和万能引用结合时不至于困惑,\r\n我们先思考一个更自然的问题: 为何需要标签分派？\r\n我们都知道 C++标准库中的 std::advance 函数,\r\n这个函数的作用是将一个迭代器前进 n\r\n步。而不同容器的迭代器性能天差地别：\r\n\r\n随机访问迭代器 (Random Access Iterator)：例如\r\nstd::vector::iterator。它可以进行常数时间 O(1) 的跳跃，直接使用 it += n\r\n即可。\r\n双向迭代器 (Bidirectional Iterator)：例如\r\nstd::list::iterator。它只能一步一步地前进或后退，前进 n 步需要 O(n)\r\n的时间，即执行 n 次 ++it。\r\n前向迭代器 (Forward Iterator)：例如\r\nstd::forward_list::iterator。它只能一步一步地前进，同样需要 O(n)\r\n的时间。\r\n\r\n现在，如果我们想自己实现一个泛型的 my_advance\r\n函数，该怎么做？一个朴素的想法可能是这样的： template&lt;typename InputIterator, typename Distance&gt;void my_advance_naive(InputIterator&amp; it, Distance n) {    // 这种实现对所有迭代器都有效，但对随机访问迭代器来说效率极低！    while (n &gt; 0) {        ++it;        --n;    }} 显然,\r\n这个实现对于 std::vector::iterator\r\n来说太慢了。我们希望当传入的迭代器是随机访问迭代器时，能自动调用 it +=\r\nn。\r\n那我们该如何判断迭代器的类型呢？在函数体内使用 if\r\n判断是运行时行为，并且我们无法在编译期根据这个条件选择不同的代码。而我们想要的是编译期就能确定最佳策略，没有任何运行时开销。这就是标签分派大显身手的地方。\r\n标签分派的实现步骤\r\n实现标签分派通常包含以下四个步骤： 1. 创建标签 (Tags)\r\n首先，定义一组空结构体，它们的存在仅仅是为了在类型系统中作为“标签”，以区分不同的特性。对于迭代器，C++标准库已经为我们定义好了这些标签（在\r\n 头文件中）： // 位于 std 命名空间struct input_iterator_tag {};struct output_iterator_tag {};struct forward_iterator_tag : public input_iterator_tag {};struct bidirectional_iterator_tag : public forward_iterator_tag {};struct random_access_iterator_tag : public bidirectional_iterator_tag {};// 注意：这些标签之间有继承关系，这使得一个随机访问迭代器同时也可以被视为一个双向迭代器，依此类推。\r\n\r\n关联类型与标签 (Type Traits)\r\n我们需要一种机制来查询一个类型（比如一个迭代器）对应的标签是什么。这就是类型萃取\r\n(Type Traits) 的作用。\r\n\r\nC++标准库提供了\r\nstd::iterator_traits，它可以提取出任何迭代器的属性，其中就包括它的迭代器类别\r\n(iterator category)。例如,\r\nstd::iterator_traits&lt;std::vector::iterator&gt;::iterator_category\r\n的类型是 std::random_access_iterator_tag。\r\n\r\n实现多个“工作”函数 (Worker Functions)\r\n接下来，我们编写多个内部辅助函数。这些函数执行实际的工作，并且它们根据不同的标签类型进行重载。\r\n// 这是 my_advance 的内部实现，用户不直接调用namespace detail {// 版本1：为随机访问迭代器特化的实现template&lt;typename RandomAccessIterator, typename Distance&gt;void my_advance_impl(RandomAccessIterator&amp; it, Distance n, std::random_access_iterator_tag) {    std::cout &lt;&lt; \"Using random access iterator implementation (O(1))\\n\";    it += n; // 高效的 O(1) 操作}// 版本2：为双向迭代器特化的实现template&lt;typename BidirectionalIterator, typename Distance&gt;void my_advance_impl(BidirectionalIterator&amp; it, Distance n, std::bidirectional_iterator_tag) {    std::cout &lt;&lt; \"Using bidirectional iterator implementation (O(n))\\n\";    if (n &gt;= 0) {        while (n-- &gt; 0) ++it;    } else {        while (n++ &lt; 0) --it;    }}// 版本3：为输入/前向迭代器特化的实现template&lt;typename InputIterator, typename Distance&gt;void my_advance_impl(InputIterator&amp; it, Distance n, std::input_iterator_tag) {    std::cout &lt;&lt; \"Using input iterator implementation (O(n))\\n\";    // (为简化，假设 n &gt;= 0)    while (n-- &gt; 0) ++it;}} // namespace detail 我们定义了三个名为 my_advance_impl\r\n的重载函数。它们唯一的区别是第三个参数的类型，分别是不同的迭代器标签。编译器在编译时会根据传入的标签类型，精确地选择其中一个版本。\r\n创建“分派”函数/公开函数 (Dispatcher Function)\r\n最后，我们创建一个公开的、用户调用的接口函数。这个函数不执行任何实际工作，它的唯一任务就是：获取迭代器的类型标签,\r\n创建一个该标签类型的临时对象,\r\n然后调用内部的“工作”函数，并将这个标签对象作为参数传进去，从而触发正确的重载。\r\ntemplate&lt;typename InputIterator, typename Distance&gt;void my_advance(InputIterator&amp; it, Distance n) {    // 步骤1：通过 iterator_traits 获取迭代器的类别（即标签类型）    using category = typename std::iterator_traits&lt;InputIterator&gt;::iterator_category;    // 步骤2 &amp; 3：调用内部实现，并传入一个标签类型的临时对象 category{}    // 编译器会根据 category{} 的类型来选择正确的 my_advance_impl 重载版本    detail::my_advance_impl(it, n, category{});} 这里实现编译期决定调用的关键在于: category\r\n是一个类型，而不是一个变量。关于类型的所有决策，都是在编译期由编译器完成的，而不是在程序运行时。\r\n\r\n\r\n当然, 在现代C++中, 我们有了更直接的工具: if constexpr (C++17),\r\n可以在编译期进行分支判断，代码可以写在同一个函数内，更简洁; Concepts\r\n(C++20),\r\n提供了更强大的模板约束能力，可以直接在函数声明中要求类型的属性，使得重载更加清晰。\r\n\r\nlogAndAdd 示例分析\r\n// 为了处理左值引用，我们需要 std::remove_referencetemplate&lt;typename T&gt;void logAndAdd(T&amp;&amp; name) {    logAndAddImpl(        std::forward&lt;T&gt;(name),        // 根据 name 的类型（移除引用后）是否为整型来创建标签        std::is_integral&lt;typename std::remove_reference&lt;T&gt;::type&gt;()    );}// 实现版本1：为非整型准备（标签类型为 std::false_type）template&lt;typename T&gt;void logAndAddImpl(T&amp;&amp; name, std::false_type) {    names.emplace(std::forward&lt;T&gt;(name));}// 实现版本2：为整型准备（标签类型为 std::true_type）void logAndAddImpl(int idx, std::true_type) {    names.emplace(nameFromIdx(idx));}\r\n当 logAndAdd 被调用时，std::is_integral\r\n会在编译期判断传入的参数类型是否为整型。如果传入的是\r\nstd::string，is_integral 的结果是 std::false_type，于是编译器会选择匹配\r\nstd::false_type 的 logAndAddImpl 版本。而如果传入的是 int，is_integral\r\n的结果是 std::true_type，于是编译器会选择匹配 std::true_type 的\r\nlogAndAddImpl 版本。\r\n由于公开的 logAndAdd\r\n函数没有被重载，从而避免了条款26中的问题。真正的重载发生在实现函数\r\nlogAndAddImpl\r\n上，但由于其签名中包含了不同的标签类型，重载决议可以精确无误地进行。\r\n类型萃取\r\n上述代码中, 我们使用了 std::iterator_traits 来获取迭代器的类型标签,\r\n使用 std::remove_reference 来移除引用,\r\n这些都是类型萃取工具, 因此下面我们对此进行详细的解释,\r\n学习这一现代C++泛型编程中不可或缺的一部分。\r\n类型萃取 (Type Traits)\r\n是一种在编译期查询和获取一个类型（Type）的各种属性（Traits）的编程技术。你可以把它想象成一个内置于C++编译器的“类型信息查询系统”。\r\n它的核心思想是：为给定的类型\r\nT，提供一个统一的接口（通常是一个模板类），通过这个接口，我们可以在编译期间得到关于\r\nT 的各种信息，例如：\r\n\r\n这个类型是不是一个整数？（is_integral）\r\n这个类型是不是一个指针？（is_pointer）\r\n如果去掉这个类型的 const\r\n限定符，它会是什么类型？（remove_const）\r\n两个类型是不是完全相同？（is_same）\r\n\r\n这些查询完全在编译期进行，不会产生任何运行时开销。编译器会利用查询结果来生成最优化的代码。\r\n为什么需要类型萃取？\r\n前面我们使用的“标签分派”技术就是利用了类型萃取的能力,\r\n它可以根据类型的属性, 选择不同的实现路径,\r\n从而实现编译期的多态。这便是类型萃取的一个重要应用场景:\r\n在泛型编程中，我们经常需要编写一个模板函数来处理各种不同的类型。然而，不同类型往往需要不同的处理方式才能达到最佳性能或保证正确性。\r\n下面这个例子再帮助我们强化一下: 假设我们要写一个泛型函数\r\nmy_copy，将一个数组的元素拷贝到另一个数组。一个简单通用的实现是逐个元素拷贝:\r\ntemplate&lt;typename T&gt;void my_copy_simple(T* dest, const T* src, size_t n) {    for (size_t i = 0; i &lt; n; ++i) {        dest[i] = src[i]; // 逐个调用赋值操作符    }} 这个实现是正确的，但不是最高效的。对于像 int, char, double\r\n这样的普通旧数据类型 (Plain Old Data,\r\nPOD)，或者更现代的说法是可平凡拷贝的类型\r\n(Trivially Copyable\r\nTypes)，它们没有复杂的构造、析构或赋值逻辑，其内存布局就是一串字节。对于这些类型，使用\r\nC 语言的 memcpy 函数进行内存块的整体拷贝会快得多。\r\n但问题来了：我们的 my_copy 函数如何在编译期知道类型 T\r\n是否是“可平凡拷贝的”呢？我们不能用 if\r\n(some_runtime_check)，因为这会带来运行时开销，而且我们希望为不同类型生成完全不同的机器码。这正是类型萃取要解决的问题。我们可以利用类型萃取来“询问”编译器关于类型\r\nT 的信息： #include &lt;type_traits&gt; // C++11 之后，所有类型萃取工具都在这里#include &lt;cstring&gt;template&lt;typename T&gt;void my_copy_optimized(T* dest, const T* src, size_t n) {    // 在编译期查询 T 是否是可平凡拷贝的    if constexpr (std::is_trivially_copyable_v&lt;T&gt;) {        // 如果是，编译器只会生成这部分代码        memcpy(dest, src, n * sizeof(T));    } else {        // 如果不是，编译器只会生成这部分代码        for (size_t i = 0; i &lt; n; ++i) {            dest[i] = src[i];        }    }} 这里的std::is_trivially_copyable_v\r\n是一个类型萃取。它是一个编译期常量，如果 T 是可平凡拷贝的，它的值就是\r\ntrue，否则是 false。而if constexpr (C++17)\r\n指示编译器在编译时进行判断。如果条件为 true，else\r\n分支的代码甚至不会被编译，反之亦然。这样就实现了为不同类型属性生成不同代码路径的目的。\r\n类型萃取是如何实现的？\r\n类型萃取的核心机制是 模板特化 (Template\r\nSpecialization)。我们通过定义一个基础模板（提供默认值），然后为我们感兴趣的特定类型提供特化版本（提供特定的值）。\r\ntemplate&lt;typename T&gt;struct is_pointer {    static const bool value = false;};template&lt;typename T&gt;struct is_pointer&lt;T*&gt; { // 这个 &lt;T*&gt; 就是特化    static const bool value = true;}; 当编译器遇到 is_pointer 时，它无法匹配特化版本\r\n&lt;T*&gt;，所以会使用基础模板，得到 value = false。\r\n当编译器遇到 is_pointer&lt;int&gt; 时，它发现这完美匹配特化版本\r\n&lt;T&gt;（此时 T 是 int），于是它会使用这个特化版本，得到 value =\r\ntrue。\r\n为了使用起来更方便（不用写\r\n::value），C++14之后通常会提供一个变量模板, 这样，我们就可以直接写\r\nis_pointer_v&lt;int*&gt; 来获取 true template&lt;typename T&gt;constexpr bool is_pointer_v = is_pointer&lt;T&gt;::value;\r\nC++标准库中的类型萃取\r\nC++标准库在 \r\n头文件中提供了极其丰富的一套工具，可以分为几大类： - 主类型类别 (Primary\r\nType Categories): 判断一个类型属于哪个大的分类。\r\n- std::is_void&lt;T&gt;\r\n- std::is_integral&lt;T&gt; (是否为整数类型)\r\n- std::is_floating_point&lt;T&gt; (是否为浮点数类型)\r\n- std::is_array&lt;T&gt; (是否为数组类型)\r\n- std::is_pointer&lt;T&gt; (是否为指针类型)\r\n- std::is_class&lt;T&gt; (是否为类类型)\r\n- std::is_function&lt;T&gt; (是否为函数类型)\r\n\r\n类型属性 (Type Properties): 查询类型的具体属性。\r\n\r\nstd::is_const (是否为 const 类型)\r\nstd::is_volatile (是否为 volatile 类型)\r\nstd::is_trivial (是否为平凡类型)\r\nstd::is_trivially_copyable (是否可平凡拷贝)\r\nstd::is_abstract (是否为抽象类)\r\nstd::is_constructible&lt;T, Args…&gt; (T是否能用Args…参数构造)\r\n\r\n类型关系 (Type Relationships): 比较两个类型之间的关系。\r\n\r\nstd::is_same&lt;T, U&gt; (T和U是否是同一类型)\r\nstd::is_base_of&lt;Base, Derived&gt; (Base是否是Derived的基类)\r\nstd::is_convertible&lt;From, To&gt;\r\n(From类型是否能隐式转换为To类型)\r\n\r\n类型修改 (Type Modifications):\r\n在编译期对一个类型进行“计算”，得到一个新类型。\r\n\r\nstd::remove_const::type -&gt; std::remove_const_t\r\nstd::add_const::type -&gt; std::add_const_t\r\nstd::remove_reference::type -&gt; std::remove_reference_t\r\nstd::add_pointer::type -&gt; std::add_pointer_t\r\nstd::decay::type -&gt; std::decay_t\r\n(模拟按值传参时的类型退化)\r\n\r\n\r\n约束模板：std::enable_if\r\n对于构造函数等无法使用标签分派的场景，我们可以使用 std::enable_if\r\n来约束模板，这项技术是基于 SFINAE（Substitution Failure\r\nIs Not An Error，替换失败并非错误）规则。\r\nstd::enable_if\r\n可以根据一个编译期条件，来决定一个模板是否“存在”。如果条件为\r\nfalse，模板就会在重载决议中被“禁用”或“移除”，编译器会假装它不存在。\r\nSFINAE\r\nSFINAE 是 “Substitution Failure Is Not An Error”\r\n的缩写，其中文直译为“替换失败并非错误”。\r\n这是一个 C++\r\n编译器的规则，指的是在为模板进行类型推导和参数替换时，如果某个替换导致了无效的代码（例如，调用了不存在的成员函数或使用了不存在的类型），编译器不会立即报错并停止编译，而是会静默地将这个模板从重载决议的候选集中移除，然后继续尝试其他可行的重载。这个特性是实现\r\nC++ 类型萃取（Type Traits）和许多高级模板技术的基础。\r\n我们可以拆解这个过程如下: 1. 模板实例化与替换 (Template Instantiation\r\nand Substitution)\r\n当你调用一个模板函数时，编译器会根据你提供的参数推导出模板参数的具体类型。例如，调用\r\ntemplate void func(T arg); 时使用 func(123)，编译器会推导出\r\nT 是 int。然后，编译器会用 int 替换 (substitute) 模板定义中所有的\r\nT。\r\n\r\n替换失败 (Substitution Failure)\r\n在替换过程中，如果生成的代码在语法上是无效的，就称之为“替换失败”。常见的替换失败场景包括：\r\n\r\n\r\n访问一个不存在的嵌套类型：例如，模板代码使用了 typename\r\nT::inner_type，但 T 被替换为 int，而 int 并没有 inner_type。\r\n调用一个不存在的成员函数：模板代码调用了\r\narg.foo()，但传入的参数类型没有 foo() 成员。\r\n使用了不满足 static_assert 或其他编译期断言的类型。\r\n\r\n\r\n并非错误 (Is Not An Error) 这是 SFINAE\r\n的关键。一个替换失败并不会让编译器立刻报错。相反，编译器会认为：“好吧，这个模板函数对于给定的参数是不可行的，我将它从候选列表中移除，看看有没有其他同名的函数或模板可以匹配这次调用。”\r\n\r\n如果所有的候选函数（包括普通函数和模板）都因为不匹配或 SFINAE\r\n而被排除了，那么最终编译器才会报告一个“没有匹配的函数”的错误。\r\nstd::enable_if：SFINAE\r\n的主要工具\r\n在实践中，我们很少直接依赖隐式的替换失败，而是通过一个标准库工具\r\nstd::enable_if 来主动、清晰地触发 SFINAE。\r\nstd::enable_if 是一个条件编译的辅助模板。它的定义大致如下：\r\n// 如果 B 为 true, std::enable_if&lt;B, T&gt; 会有一个名为 type 的成员，其类型为 Ttemplate&lt;bool B, class T = void&gt;struct enable_if {};// 特化版本：当 B 为 true 时template&lt;class T&gt;struct enable_if&lt;true, T&gt; {    using type = T;}; 当第一个模板参数 B 为 true 时，std::enable_if&lt;true,\r\nT&gt; 结构体内部会有一个 type 成员。如果 B 为\r\nfalse，则会匹配基础模板，而基础模板是空的，里面没有 type\r\n成员。当我们试图访问一个不存在的 type 成员时，就会触发“替换失败”。\r\n从 C++14 开始，我们通常使用别名 std::enable_if_t&lt;B,\r\nT&gt;，它等价于 typename std::enable_if&lt;B, T&gt;::type。\r\n下面是一个例子，我们编写一个函数，使其只对整数类型（integral\r\ntypes）有效。 #include &lt;iostream&gt;#include &lt;type_traits&gt; // for std::is_integral, std::enable_if_t// 方式一：作为返回类型（最常见）// 如果 T 是整数，返回类型为 void；否则，替换失败。template&lt;typename T&gt;std::enable_if_t&lt;std::is_integral_v&lt;T&gt;, void&gt;process(T value) {    std::cout &lt;&lt; \"Processing an integral value: \" &lt;&lt; value &lt;&lt; std::endl;}// 方式二：作为函数参数// 如果 T 是浮点数，这个重载版本才有效template&lt;typename T&gt;void process(T value, std::enable_if_t&lt;std::is_floating_point_v&lt;T&gt;&gt;* = nullptr) {    std::cout &lt;&lt; \"Processing a floating point value: \" &lt;&lt; value &lt;&lt; std::endl;}方式三：作为模板参数（C++11及以后）template&lt;typename T, typename = std::enable_if_t&lt;std::is_arithmetic_v&lt;T&gt;&gt;&gt;void some_other_func(T value) {    // ...}int main() {    process(10);      // 调用第一个版本，T=int, std::is_integral_v&lt;int&gt; is true    process(3.14);    // 调用第二个版本，T=double, std::is_floating_point_v&lt;double&gt; is true    // process(\"hello\"); // 编译错误！两个 process 模板都因 SFINAE 被排除了                       // 没有匹配的函数    return 0;} 当调用 process(10) 时，编译器尝试匹配两个\r\nprocess 模板。对于第一个模板，T 推导为 int。std::is_integral_v 是\r\ntrue，所以 std::enable_if_t&lt;true, void&gt; 成功替换为\r\nvoid。函数签名为 void process(int)。这是一个有效的候选。\r\n对于第二个模板，T 推导为 int。std::is_floating_point_v 是\r\nfalse，std::enable_if_t 试图访问不存在的 type\r\n成员，导致替换失败。此模板被移除。最终，只有第一个模板是唯一候选，因此被调用。\r\n当调用 process(3.14) 时，情况正好相反，第一个模板被 SFINAE\r\n排除，第二个模板成为唯一候选。\r\nSFINAE\r\n的局限性与现代C++的演进\r\n尽管 SFINAE 非常强大，但它也有明显的缺点：\r\n\r\n复杂的语法：typename std::enable_if&lt;…&gt;::type\r\n这样的代码非常冗长且不直观。\r\n糟糕的错误信息：当所有重载都因为 SFINAE\r\n被排除时，编译器通常会给出一个非常庞大且难以理解的错误报告，因为它会列出所有尝试过的失败的模板，而不是告诉开发者“你传入的类型不满足整数的要求”。\r\n概念表达能力弱：它是一种“曲线救国”的方式来表达对模板参数的约束，而不是直接地描述。\r\n\r\n为了解决这些问题，现代 C++ 提供了更好的工具：\r\nif constexpr (C++17): if constexpr\r\n允许在函数体内部进行编译期分支。它不是选择不同的函数重载，而是在一个函数模板内部丢弃不符合条件的代码块。\r\ntemplate&lt;typename T&gt;void process_modern(T value) {    if constexpr (std::is_integral_v&lt;T&gt;) {        std::cout &lt;&lt; \"Integral value (if constexpr): \" &lt;&lt; value &lt;&lt; std::endl;    } else if constexpr (std::is_floating_point_v&lt;T&gt;) {        std::cout &lt;&lt; \"Floating point value (if constexpr): \" &lt;&lt; value &lt;&lt; std::endl;    } else {        // 在编译时就给出清晰的错误        static_assert(std::is_arithmetic_v&lt;T&gt;, \"process_modern only accepts arithmetic types\");    }} 不同在于, SFINAE\r\n在重载决议阶段起作用，用于选择哪个函数。if constexpr\r\n在模板实例化后起作用，用于决定函数体内哪些代码被编译,\r\n不过后者需要将逻辑聚合在一个函数内。\r\nConcepts (C++20): C++20 引入的 Concepts 是 SFINAE\r\n的终极替代品。它允许我们直接、清晰地在模板定义上声明其参数必须满足的约束。\r\n#include &lt;iostream&gt;#include &lt;concepts&gt; // for std::integral// 使用 requires 子句来约束模板参数 Ttemplate&lt;typename T&gt;requires std::integral&lt;T&gt;void process_concepts(T value) {    std::cout &lt;&lt; \"Processing an integral value (concepts): \" &lt;&lt; value &lt;&lt; std::endl;}template&lt;typename T&gt;requires std::floating_point&lt;T&gt;void process_concepts(T value) {    std::cout &lt;&lt; \"Processing a floating point value (concepts): \" &lt;&lt; value &lt;&lt; std::endl;} 使用requires关键字,\r\n语法极其清晰易读。且当约束不满足时，编译器会给出非常明确的错误信息，例如：“process_concepts(std::string)\r\nfailed because std::string does not satisfy the concept\r\nstd::integral”。\r\n回到上一条款的示例\r\n条款26中的 Person\r\n类，其完美转发构造函数会意外“劫持”拷贝构造函数的调用。我们的目标是：仅当传入的类型不是\r\nPerson 或其派生类时，才启用这个完美转发构造函数。 #include &lt;type_traits&gt; // for std::enable_if, std::is_base_of, std::decay etc.// 前面提到的方式三class Person {public:    template&lt;        typename T,        // 仅当 T 不是 Person 或其派生类时，这个模板才有效        typename = std::enable_if_t&lt;            !std::is_base_of&lt;Person, std::decay_t&lt;T&gt;&gt;::value        &gt;    &gt;    explicit Person(T&amp;&amp; n);    // ... 其他构造函数}; 这里的\r\nstd::decay_t用于移除类型 T 的引用和 const/volatile\r\n限定符，得到其“纯粹”的类型; std::is_base_of&lt;Base, Derived&gt;用于判断\r\nBase 是否为 Derived 的基类（或类型相同）。\r\n当尝试拷贝 Person p 时（auto\r\nclone(p);），编译器会尝试匹配完美转发构造函数，此时 T 被推导为\r\nPerson&amp;。因此std::decay_t&lt;Person&amp;&gt; 的结果是 Person,\r\n!std::is_base_of&lt;…&gt;::value 为 false。\r\n正是这个 std::enable_if_t 导致了“替换失败”。根据 SFINAE\r\n规则，这不是一个编译错误，而是简单地将这个构造函数模板从候选列表中移除。此时，唯一剩下的候选者就是编译器生成的拷贝构造函数，它被正确地选中了。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 28 - 理解引用折叠","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE28%20-%20%E7%90%86%E8%A7%A3%E5%BC%95%E7%94%A8%E6%8A%98%E5%8F%A0/","content":"这一条款是对之前条款的理论原理呈现, 揭示了支撑万能引用和\r\nstd::forward工作的底层核心机制。这个机制就是引用折叠\r\n(Reference Collapsing, 在之前的条款24中已有介绍)\r\n引用折叠会在四种语境中发生：模板实例化、auto 类型生成、创建和运用\r\ntypedef 和别名声明，以及 decltype。\r\n详细内容请参考条款24。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 26 - 避免依万能引用型别进行重载","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE26%20-%20%E9%81%BF%E5%85%8D%E4%BE%9D%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%9E%8B%E5%88%AB%E8%BF%9B%E8%A1%8C%E9%87%8D%E8%BD%BD/","content":"这一讲开门见山:\r\n将一个接受万能引用参数的函数或模板与其他函数进行重载，是一个非常危险的设计，因为它几乎总是会导致意想不到的行为和难以理解的编译错误。\r\n核心问题：万能引用的“贪婪”\r\n万能引用（在模板中声明为\r\nT&amp;&amp;）之所以危险，是因为它过于“贪婪”。根据C++的模板类型推导和重载决议规则，万能引用可以为几乎任何类型的实参生成一个精确匹配\r\n(Exact Match) 的函数实例。\r\n在重载决议中，精确匹配的优先级非常高，高于那些需要类型提升（如\r\nshort 到\r\nint）、类型转换（如派生类到基类）或添加\r\nconst\r\n的匹配。这意味着，一旦万能引用版本的重载成为候选，它就会像磁铁一样“吸走”大量本意是想调用其他重载版本的函数调用。\r\n示例一：logAndAdd ——\r\n万能引用与常规函数的重载\r\n这个例子展示了最直接的问题。假设我们有一个高效的、使用万能引用的\r\nlogAndAdd 函数，同时为了方便，我们又重载了一个接受 int 索引的版本,\r\n当我们用一个 short 类型的变量来调用它时: // 全局数据std::multiset&lt;std::string&gt; names;// 重载版本 1: 万能引用template&lt;typename T&gt;void logAndAdd(T&amp;&amp; name) {    names.emplace(std::forward&lt;T&gt;(name));}// 重载版本 2: intvoid logAndAdd(int idx) {    names.emplace(nameFromIdx(idx));}short nameIdx;// ...logAndAdd(nameIdx); // 错误！调用的是万能引用版本 首先,\r\n程序员的意图非常明确，short 是一个整数类型，应该调用 logAndAdd(int idx)\r\n这个版本。而重载决议过程却不是这样的. 它会尝试下列两种匹配\r\n对于尝试匹配 logAndAdd(int)：short 到 int\r\n的转换是类型提升\r\n(Promotion)，这是一个合法的匹配，但不是精确匹配。\r\n而对于匹配\r\nlogAndAdd(T&amp;&amp;)：编译器可以为万能引用实例化一个版本，其中\r\nT 被推导为 short&amp;。这个 logAndAdd(short&amp;) 的实例对于 short\r\n类型的实参来说是精确匹配 (Exact Match)。\r\n由于精确匹配的优先级高于类型提升，编译器选择了万能引用版本的\r\nlogAndAdd。也就是说, 在万能引用版本的函数体内，代码尝试用一个 short\r\n去构造 names（一个 std::multiset）中的\r\nstd::string。由于不存在从 short 到 std::string 的构造函数，代码最终在\r\nemplace\r\n这一步编译失败。这个错误信息通常非常复杂，因为它发生在模板的深层实例化中，让程序员难以定位问题的根源。\r\n示例二：Person\r\n构造函数 —— 完美转发构造函数的危险\r\n这个例子揭示了一个更微妙、更危险的问题。当一个类的构造函数被重载为万能引用时（通常被称为“完美转发构造函数”），它会“劫持”类的拷贝和移动机制。\r\nclass Person {public:    // 完美转发构造函数    template&lt;typename T&gt;    explicit Person(T&amp;&amp; n) : name(std::forward&lt;T&gt;(n)) {}    explicit Person(int idx) : name(nameFromIdx(idx)) {}        // 编译器会自动生成拷贝和移动构造函数};Person p(\"Nancy\");auto cloneOfP(p); // 或者Person cloneOfP(p), 意图是调用拷贝构造函数 当客户端代码尝试拷贝一个 Person 对象时,\r\n程序员希望调用编译器生成的拷贝构造函数 Person(const\r\nPerson&amp;)。此时重载决议过程如下：\r\n\r\n匹配拷贝构造函数：实参 p 的类型是 Person（一个非 const\r\n左值）。为了匹配拷贝构造函数的参数 const Person&amp;，需要为 p 添加\r\nconst 限定符。这是一个合法的匹配，但不是精确匹配。\r\n匹配完美转发构造函数：编译器可以为万能引用构造函数实例化一个版本，其中\r\nT 被推导为 Person&amp;。这个 Person(Person&amp;) 的实例对于 Person\r\n类型的左值实参 p 来说是精确匹配。\r\n\r\n同样，精确匹配胜出。编译器选择了完美转发构造函数，而不是拷贝构造函数。在完美转发构造函数体内，代码尝试用\r\np（一个 Person 对象）来初始化 name（一个 std::string\r\n成员）。这当然会失败，并产生一堆令人费解的错误信息。\r\n在这个例子里,\r\n完美转发构造函数破坏了类的基本功能（拷贝）。它同样会劫持派生类对基类的拷贝和移动调用，导致继承体系出现问题。\r\n总而言之,\r\n在设计函数和类时，应极力避免将接受万能引用的版本与其他版本进行重载。在下一讲条款27会详细介绍如何处理那些确实需要类似重载行为的场景，例如使用标签分派、static_assert\r\n或 C++20 的 concepts 等技术来约束模板，从而安全地实现期望的功能。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 30 - 熟悉完美转发的失败情形","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE30%20-%20%E7%86%9F%E6%82%89%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%83%85%E5%BD%A2/","content":"“完美转发”是 C++11\r\n中一个极其强大的特性，但它并非在所有情况下都“完美”。该条款的核心是揭示几种完美转发会失败或产生非预期行为的边界情况，并提供相应的解决方案。\r\n什么是完美转发失败\r\n完美转发的理想目标是：一个转发函数 fwd 在接收某个表达式 expr\r\n时，其行为应与将 expr 直接传递给目标函数 f 的行为完全相同。\r\nf(expression);      // 直接调用fwd(expression);    // 通过转发函数间接调用\r\n当直接调用成功，而间接调用却失败（例如，无法通过编译，或调用了错误的重载版本）时，就称完美转发失败。\r\n失败的根本原因在于，编译器在处理fwd(expression)时，必须先推导fwd的模板参数类型，而这个推导过程不考虑最终目标函数f的形参类型。而在直接调用f(expression)时，编译器会同时看到实参和形参，并可以进行必要的隐式类型转换。当类型推导失败或推导出“错误”的类型时，完美转发就会失败。\r\n五种导致完美转发失败的实参\r\n\r\n大括号初始化物 (Braced Initializers): 直接将 {}\r\n初始化列表传递给目标函数通常是合法的，但通过转发函数传递则会失败。\r\nvoid f(const std::vector&lt;int&gt;&amp; v);f({1, 2, 3}); // 成功：\"{1,2,3}\"被隐式转换为 std::vector&lt;int&gt;template&lt;typename T&gt;void fwd(T&amp;&amp; param) { f(std::forward&lt;T&gt;(param)); }fwd({1, 2, 3}); // 错误！ 原因在于, 将 {…} 传递给一个未声明为 std::initializer_list\r\n的函数模板参数，属于C++标准中的非推导语境 (non-deduced\r\ncontext)。编译器被禁止从 {1, 2, 3} 中为 fwd 的模板参数 T\r\n推导出类型。由于类型推导失败，代码无法通过编译。\r\n\r\n解决方案也很简单, 先使用 auto 将大括号初始化物创建为一个\r\nstd::initializer_list 对象，再将该对象传递给转发函数。 auto il = {1, 2, 3};fwd(il); // 成功：il 被推导为 std::initializer_list&lt;int&gt;\r\n\r\n以 0 或 NULL 表示的空指针 直接调用时，0 或 NULL\r\n可能会被正确解释为空指针，但转发时则不行。\r\n\r\n原因是, 如条款8所述，0 和 NULL 的真实类型是整型（int 或\r\nlong）。模板类型推导会忠实地将其推导为整型，而不是指针类型。当这个错误的整型被转发给期望指针的目标函数时，就会发生类型不匹配的错误。\r\n解决方案是使用 nullptr 代替 0 或 NULL。nullptr 的类型是\r\nstd::nullptr_t，它可以被正确地推导并转发。\r\n\r\n仅有声明的整型 static const 成员变量\r\n在类中声明但未在实现文件中定义的整型 static const\r\n成员，可以直接作为值使用，但不能通过完美转发传递。 class Widget {public:    static const std::size_t MinVals = 28; // 仅有声明};f(Widget::MinVals); // 成功：编译器直接替换为值 28fwd(Widget::MinVals); // 错误：通常会导致链接失败\r\n完美转发是通过引用（万能引用\r\nT&amp;&amp;）来接受参数的。传递引用在底层实现上通常等同于传递指针，这意味着被引用的对象必须有明确的内存地址。仅有声明的\r\nstatic const\r\n成员变量，编译器通常会通过“常数传播”优化直接使用其值，而不会为其分配内存地址。因此，当\r\nfwd 尝试获取其引用时，链接器会因为找不到该变量的定义而报错。\r\n\r\n解决方案是在实现文件中为该成员变量提供定义即可 // 在 Widget 的 .cpp 文件中const std::size_t Widget::MinVals; // 无需再次指定值\r\n\r\n重载的函数名字和模板名字\r\n直接将一个重载函数的名字传递给目标函数是合法的，但通过转发函数传递则会失败。\r\nvoid f(int (*pf)(int)); // f 接受一个函数指针int processVal(int);int processVal(int, int);f(processVal); // 成功：编译器根据f的签名选择了 int(int) 版本fwd(processVal); // 错误！ 原因是, processVal\r\n这个名字本身代表一个函数重载集，它没有一个确定的类型。在直接调用\r\nf 时，编译器可以根据 f 的参数类型（int\r\n(*)(int)）来确定应该选用哪个重载版本。但在调用 fwd\r\n时，编译器只看到了实参 processVal，由于其类型不确定，模板类型推导 T\r\n失败。函数模板的名字也存在同样的问题。\r\n\r\n解决方案：手动指定需要转发的是哪一个重载版本或模板实例(确定类型)，例如通过创建一个函数指针来消除歧义。\r\nusing ProcessFuncType = int (*)(int);ProcessFuncType processValPtr = processVal;fwd(processValPtr); // 成功\r\n\r\n位域 (Bitfields)\r\n可以直接将位域作为值传递给函数，但不能通过完美转发传递。 &gt;\r\n什么是位域: 位域是 C/C++\r\n中的一种数据结构特性，它允许我们在一个结构体（struct）或联合体（union）中，为一个成员变量指定其占用的二进制位数（bit）。它是一种空间优化技术，主要用于将多个小的、通常是标志位或状态值的变量打包到单个机器字（如一个字节或一个整数）中，从而极大地节省内存空间。\r\nstruct IPv4Header { std::uint32_t totalLength:16; };void f(std::size_t s);IPv4Header h;f(h.totalLength); // 成功fwd(h.totalLength); // 错误！ 原因：C++标准禁止将非 const\r\n引用绑定到位域。因为位域可能只占一个字节中的几个比特，它没有自己独立的内存地址，而引用在底层通常是作为指针实现的。既然无法获取一个比特位的地址，自然也无法将其绑定到非\r\nconst 引用上。完美转发函数 fwd 的参数 T&amp;&amp;\r\n是一个引用，因此该调用失败。\r\n\r\n解决方案：传递位域值的副本。任何接受位域的函数实际上接收的都是其值的副本，因此可以手动创建这个副本再传递。\r\nauto length = static_cast&lt;std::uint16_t&gt;(h.totalLength);fwd(length); // 成功\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款41 ：针对可复制的形参，在移动成本低并且一定会被复制的前提下，考虑将其按值传递","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%BE%AE%E8%B0%83/%E6%9D%A1%E6%AC%BE41%20-%20%E9%92%88%E5%AF%B9%E5%8F%AF%E5%A4%8D%E5%88%B6%E7%9A%84%E5%BD%A2%E5%8F%82%EF%BC%8C%E5%9C%A8%E7%A7%BB%E5%8A%A8%E6%88%90%E6%9C%AC%E4%BD%8E%E5%B9%B6%E4%B8%94%E4%B8%80%E5%AE%9A%E4%BC%9A%E8%A2%AB%E5%A4%8D%E5%88%B6%E7%9A%84%E5%89%8D%E6%8F%90%E4%B8%8B%EF%BC%8C%E8%80%83%E8%99%91%E5%B0%86%E5%85%B6%E6%8C%89%E5%80%BC%E4%BC%A0%E9%80%92/","content":"该条款探讨了一种在特定情况下，可以替代“为左值和右值分别重载”这一常规做法的编码技巧。C++98\r\n的一条重要准则是“避免按值传递用户定义类型”，而该条款则解释了在C++11的移动语义下，这条准则何时可以被“打破”。\r\n当一个函数需要持有其参数的一个副本时（例如，将其存入一个数据成员），在\r\nC++11 中最常见的做法是提供两个重载版本：\r\n\r\n一个版本接受 const T&amp;（左值），并在函数体内复制它。\r\n另一个版本接受 T&amp;&amp;（右值），并在函数体内移动它。\r\nclass Widget {public:    // 方案一：为左值和右值分别重载    void addName(const std::string&amp; newName) { names.push_back(newName); }       // 复制左值    void addName(std::string&amp;&amp; newName)      { names.push_back(std::move(newName)); } // 移动右值private:    std::vector&lt;std::string&gt; names;};\r\n这种做法虽然正确且高效，但缺点是需要编写和维护两份几乎相同的代码。\r\n\r\n按值传递的替代方案\r\n条款41提出的替代方案是，编写一个单一的、按值传递的函数，并在函数体内\r\nstd::move 这个参数副本。 class Widget {public:    // 方案二：按值传递    void addName(std::string newName) { // newName 是一个副本        names.push_back(std::move(newName)); // 将副本移动到容器中    }private:    std::vector&lt;std::string&gt; names;};\r\n这个方案的精妙之处在于它如何利用移动语义来处理不同类型的实参。\r\n当传入一个左值时（例如 std::string name; w.addName(name);）：\r\n\r\n重载方案：const std::string&amp; 版本被调用。成本是 1 次复制（在\r\npush_back 内部）。\r\n按值传递方案：形参 newName 通过复制构造函数从 name 创建。 (1\r\n次复制); 在 push_back 内部，newName 被移动到 vector 中。(1 次移动).\r\n总成本：1 次复制 + 1 次移动。\r\n\r\n当传入一个右值时（例如 w.addName(“hello”);）： -\r\n重载方案：std::string&amp;&amp; 版本被调用。成本是 1 次移动（在\r\npush_back 内部）。 - 按值传递方案：形参 newName\r\n通过移动构造函数从右值实参创建。(1 次移动); 在 push_back 内部，newName\r\n被移动到 vector 中。(1 次移动). 总成本：2 次移动。\r\n因此,\r\n与重载方案相比，按值传递方案在处理左值时多了一次移动，处理右值时也多了一次移动。\r\n按值传递的适用条件\r\n既然按值传递会带来额外的移动开销，那么只有在满足一系列严格条件时，它才是一个值得考虑的选项。这些条件都体现在条款的标题中：\r\n形参是可复制的 (Copyable)：如果参数是只移类型（如\r\nstd::unique_ptr），那么重载方案只需要写一个 T&amp;&amp;\r\n版本即可（成本1次移动），而按值传递方案则需要2次移动，成本翻倍，因此不适用。\r\n移动成本低廉 (Cheap to\r\nMove)：按值传递方案的额外成本是一次移动。只有当这个移动操作非常廉价时（例如，对于\r\nstd::string 或 std::vector\r\n等大多数标准容器），这笔额外开销才是可以接受的。\r\n形参一定会被复制 (Always\r\nCopied)：函数必须在所有代码路径上都确实需要这个参数的副本。如果函数中存在某个分支（例如一个检查失败的\r\nif\r\n语句）会提前返回而不使用该副本，那么按值传递方案中提前创建副本的开销就被浪费了。\r\n必须避免切片问题 (Slicing\r\nProblem)：按值传递不适用于多态场景。如果你按值传递一个基类对象，那么当调用者传入一个派生类对象时，其派生类特有的部分将被“切掉”，这通常会导致非预期的行为。\r\n总之, 按值传递并非要颠覆 C++98\r\n中“避免按值传递”的传统智慧。然而，在现代 C++\r\n中，对于那些可复制、移动成本低、总是需要被复制且不涉及多态的参数，按值传递提供了一种简洁的替代方案。它用一次额外的廉价移动操作，换取了更少的代码量和更简单的维护，避免了函数重载或模板带来的复杂性。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款42 ：考虑置入而非插入","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%BE%AE%E8%B0%83/%E6%9D%A1%E6%AC%BE42%20-%20%E8%80%83%E8%99%91%E7%BD%AE%E5%85%A5%E8%80%8C%E9%9D%9E%E6%8F%92%E5%85%A5/","content":"该条款的核心是介绍 C++11 引入的“置入函数”（如 emplace_back, emplace\r\n等），并将其与传统的“插入函数”（如 push_back, insert\r\n等）进行比较。在许多情况下，置入函数比插入函数更高效。这是因为置入函数避免了不必要的复制或移动操作，直接在容器中构造对象，而插入函数则需要先构造对象，然后再将其复制或移动到容器中。\r\n插入函数和置入函数的根本区别在于它们接受的参数类型：\r\n\r\n插入函数 (如 push_back,\r\ninsert)：接受一个对象（容器所存储类型的对象）作为参数。\r\n置入函数 (如 emplace_back,\r\nemplace)：接受用于在容器中构造一个对象的构造函数实参。它使用完美转发将这些参数直接传递给对象的构造函数。\r\n\r\n因此, 置入函数的主要性能优势在于，它可以避免创建和销毁临时对象。\r\nstd::vector&lt;std::string&gt; vs;// 插入操作vs.push_back(\"xyzzy\");// 置入操作, 这里由于是字符串因此构造函数实参和对象一致vs.emplace_back(\"xyzzy\"); push_back 的过程： - 编译器首先从字符串字面量 “xyzzy”\r\n创建一个临时的 std::string 对象。 - 然后，这个临时的 std::string\r\n对象（一个右值）被移动构造到 vector 的内存空间中。 - 最后，这个临时的\r\nstd::string 对象被析构。 -\r\n整个过程涉及一次临时对象的构造、一次移动构造和一次析构。\r\nemplace_back 的过程： - emplace_back 将其参数 (“xyzzy”)\r\n完美转发到 std::string 的构造函数。 -\r\nstd::string 对象直接在 vector 的内存空间中被构造出来。 -\r\n这个过程完全避免了创建和销毁临时对象，因此效率更高。\r\n理论上，置入函数应该永远不比插入函数慢。在实践中，当以下三个条件都成立时，置入几乎肯定会比插入更高效：\r\n-\r\n值是以构造而非赋值方式加入容器：这对于所有基于节点的容器（如\r\nstd::list, std::map）和在序列容器（如 std::vector）尾部 emplace_back\r\n都成立。 -\r\n传递的实参类型与容器持有之物的类型不同：性能优势主要来自于避免创建临时对象。如果传递的实参类型与容器内元素的类型不同（如传递\r\nconst char* 给 std::vector），置入就能避免创建临时的\r\nstd::string。 - 容器不太可能因为存在重复值而拒绝新值：对于 std::set 或\r\nstd::map 等不允许重复键的容器，emplace\r\n的实现通常会先创建一个新节点，再将其与容器内现有节点比较。如果此时发现值已存在，这个新创建的节点就会被销毁，其构造和析构的开销就被浪费了。\r\n置入的注意事项与陷阱\r\n尽管置入很高效，但在使用时也存在两个重要的陷阱。\r\n陷阱一：资源管理与异常安全\r\n当容器持有资源管理类对象（如智能指针）时，使用置入函数可能会破坏异常安全。\r\nstd::list&lt;std::shared_ptr&lt;Widget&gt;&gt; ptrs;// push_back 版本（异常安全）ptrs.push_back(std::shared_ptr&lt;Widget&gt;(new Widget, killWidget));// emplace_back 版本（危险！）ptrs.emplace_back(new Widget, killWidget); push_back 的情况：std::shared_ptr 的临时对象在 push_back\r\n函数被调用前就已经创建了，它安全地接管了 new Widget\r\n返回的裸指针。如果后续 push_back 在分配内存时抛出异常，这个临时\r\nshared_ptr 的析构函数会确保 Widget 被正确删除，不会发生资源泄漏。\r\nemplace_back 的情况：new Widget 的结果（一个裸指针）被直接转发到\r\nemplace_back 内部。如果在 emplace_back 内部、在为 std::shared_ptr\r\n分配内存之前，发生了另一次内存分配失败（例如为 list\r\n的节点分配内存），那么 new Widget\r\n返回的裸指针就会丢失，导致资源泄漏。\r\n陷阱二：与 explicit 构造函数的交互\r\n置入函数使用直接初始化，而插入函数使用复制初始化。这意味着置入函数可以调用\r\nexplicit 的构造函数，而插入函数不能。 因为 emplace_back\r\n的内部行为相当于直接调用构造函数，这遵循的是直接初始化\r\n(Direct-Initialization) 的规则 std::vector&lt;std::regex&gt; regexes;// 已知std::regex 的构造函数 std::regex(const char*) 是 explicit 的。// 编译失败：push_back 使用复制初始化，不能调用 explicit 构造函数regexes.push_back(nullptr);// 编译成功！emplace_back 使用直接初始化，可以调用 explicit 构造函数regexes.emplace_back(nullptr); 这里虽然\r\nemplace_back(nullptr) 能通过编译，但将一个空指针传递给 std::regex\r\n的构造函数会在运行时导致未定义行为。\r\n因此, 置入函数可能会调用那些会被插入函数拒绝的 explicit\r\n构造函数，这可能会“隐藏”一些潜在的\r\nbug，让本应在编译期发现的问题延迟到运行时。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款36 ：如果异步是必要的，则指定 std::launch::async","url":"/2025/09/22/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE36%20-%20%E5%A6%82%E6%9E%9C%E5%BC%82%E6%AD%A5%E6%98%AF%E5%BF%85%E8%A6%81%E7%9A%84%EF%BC%8C%E5%88%99%E6%8C%87%E5%AE%9A%20std%20launch%20async/","content":"该条款的核心论点是，std::async\r\n的默认启动策略虽然为标准库调度器提供了有用的灵活性，但也给程序员带来了不确定性，可能导致难以发现的bug。因此，当你确实需要函数必须异步执行时，就应该明确指定这一点。\r\nstd::async 的启动策略\r\nstd::async 可以接受一个启动策略参数，来控制任务的执行方式： -\r\nstd::launch::async：此策略保证任务会在一个不同的线程上异步执行 。 -\r\nstd::launch::deferred：此策略意味着任务会被延迟执行。它只会在返回的\r\nstd::future 对象上调用 get() 或 wait() 时，才同步地（即阻塞地）在调用\r\nget() 或 wait() 的那个线程上执行。如果 get() 或 wait()\r\n一直未被调用，任务将永远不会执行 。 -\r\n默认启动策略：如果你不指定任何策略，std::async 会使用 std::launch::async\r\n| std::launch::deferred 的组合策略 。\r\n默认的组合策略赋予了标准库调度器极大的灵活性，让它可以根据系统当前的线程负载情况来决定任务的执行方式，这有助于避免线程耗尽和超订问题（如条款35所述）。然而，这种灵活性也给程序员带来了几个严重的不确定性：\r\n\r\n无法预知任务是否并发运行：你无法保证任务 f 会与调用 std::async\r\n的线程 t 并发执行 。\r\n无法预知任务运行在哪一个线程上：你无法确定任务 f\r\n是运行在一个新线程上，还是运行在对 future 调用 get() 或 wait()\r\n的那个线程上 。这对 thread_local 变量的使用会产生影响 。\r\n无法保证任务一定会被执行：如果 std::async 返回的 future\r\n在程序的任何路径上都未被调用 get() 或\r\nwait()，那么被延迟执行的任务可能永远不会启动。\r\n\r\n核心陷阱：基于超时的 wait\r\n与无限循环\r\n默认策略最危险的陷阱在于它与基于超时的等待函数（如\r\nwait_for）的交互\r\nusing namespace std::literals;void f() {    std::this_thread::sleep_for(1s);}auto fut = std::async(f); // 采用默认启动策略// 意图是每 100ms 检查一次任务是否完成while (fut.wait_for(100ms) != std::future_status::ready) {    // ... 这个循环可能永远不会结束！}\r\n如果调度器因为系统负载过高等原因，为任务 f 选择了\r\nstd::launch::deferred 策略，那么 fut.wait_for(…) 的返回值将永远是\r\nstd::future_status::deferred。这也就意味着, fut.wait_for(…)\r\n的结果永远不等于 std::future_status::ready，导致 while\r\n循环成为一个无限循环。这个bug非常隐蔽，因为它可能只在高负载的生产环境中才会出现。\r\n解决方案：显式指定启动策略\r\n该条款给出的结论非常明确：如果你需要确保任务必须异步执行，从而避免上述所有不确定性和陷阱，你就必须在调用\r\nstd::async 时显式指定 std::launch::async 启动策略。 auto fut = std::async(std::launch::async, f); // 保证 f 会异步执行\r\n这样做之后，f 一定会在一个不同的线程上运行，你可以安全地使用基于超时的\r\nwait，并且不必担心任务会因为未调用 get 或 wait 而不被执行。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款37 ：使 std::thread 型别对象在所有路径皆不可联结","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE37%20-%20%E4%BD%BF%20std%20thread%20%E5%9E%8B%E5%88%AB%E5%AF%B9%E8%B1%A1%E5%9C%A8%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84%E7%9A%86%E4%B8%8D%E5%8F%AF%E8%81%94%E7%BB%93/","content":"该条款的核心论点是，由于销毁一个可联结（joinable）的 std::thread\r\n对象会导致程序终止，因此开发者必须确保在 std::thread\r\n对象被销毁前，在代码的所有可能路径上都将其变为不可联结状态(设定join()或detach())。\r\nstd::thread 的可联结性\r\n(Joinability)\r\n一个 std::thread 对象存在两种状态：\r\n\r\n可联结 (Joinable)：该 std::thread\r\n对象对应于一个底层的、正在运行或已完成运行的系统线程。\r\n不可联结 (Unjoinable)：该 std::thread\r\n对象不对应任何正在运行的线程。这包括：\r\n\r\n默认构造的 std::thread（还未关联任何线程）。\r\n已被移动的 std::thread（所有权已转移）。\r\n已被 join 的 std::thread（已等待其完成）。\r\n已被 detach 的 std::thread（已与其底层线程分离）。\r\n\r\n\r\n最关键的规则：当一个可联结的 std::thread\r\n对象的析构函数被调用时(此时还不应该结束)，程序的执行会立即终止。\r\n制定这条严格规则的原因是，另外两种看似合理的备选方案————隐式 join()\r\n和隐式 detach()会带来更严重的问题。\r\n\r\n隐式 Join (Implicit Join)\r\n指的是一个管理线程生命周期的对象（例如一个线程包装类）在其析构函数中自动调用\r\njoin()\r\n方法的行为。这意味着当该对象离开其作用域（scope）并被销毁时，程序会自动地、无需显式代码指示地阻塞，直到它所管理的线程执行完毕。这是一种设计选择，而不是\r\nC++ std::thread 的标准行为。std::thread 本身不会进行隐式 join。\r\n\r\n\r\n隐式 Join\r\n的缺陷：性能陷阱。它可能在开发者不经意间引入长时间的阻塞，使程序的性能变得不可预测和难以调试。一个看似简单的函数返回或对象销毁，背后可能隐藏着一个漫长的等待。\r\n隐式 Detach 的缺陷：未定义行为。如果析构函数自动\r\ndetach()，线程可能会继续访问已经销毁的局部变量（通过引用或指针捕获），导致内存崩溃。这是比性能问题更严重的安全问题。\r\n\r\n由于隐式 join 和隐式 detach\r\n都存在严重缺陷，标准委员会选择了最安全、最明确的策略：直接终止程序，迫使开发者必须显式地处理线程的生命周期。\r\n解决方案：使用 RAII\r\n对象确保线程被处理\r\n确保在代码的所有退出路径（包括正常返回、break、continue\r\n和异常）上都执行某个操作的最佳 C++ 实践是RAII (Resource Acquisition Is\r\nInitialization)。即创建一个局部对象，并在其析构函数中执行所需的操作。\r\n标准库没有为 std::thread 提供现成的 RAII\r\n类，但我们可以自己轻松实现一个。\r\n\r\n你可能疑惑, 上面的隐式 join() 不也是通过 RAII 封装线程类实现的吗?\r\n为什么上面的不可以, 而下面的可以? 问题的根源不在于使用 RAII\r\n本身，而在于那个“坏”的 RAII 对象实现了一个糟糕的、隐晦的策略（比如总是\r\njoin 或总是 detach）; 而解决方案中的“好”的 RAII\r\n对象，则实现了一个优秀的、明确的策略, 程序员通过将解决策略显式地指出,\r\n确保我们预先设定的、明确的策略（通常是\r\njoin）在任何情况下都能被严格执行。\r\n\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;stdexcept&gt;class thread_guard {public:    // 构造函数获取线程的引用    explicit thread_guard(std::thread&amp; t) : t_(t) {}    // 析构函数：如果线程还 joinable，就 join 它    ~thread_guard() {        if (t_.joinable()) {            t_.join();        }    }    // 删除拷贝构造和赋值操作，防止所有权混乱    thread_guard(const thread_guard&amp;) = delete;    thread_guard&amp; operator=(const thread_guard&amp;) = delete;private:    std::thread&amp; t_;};void do_something_in_background() {    std::cout &lt;&lt; \"后台任务运行中...\\n\";    // 模拟抛出异常    throw std::runtime_error(\"后台任务发生错误!\");    std::cout &lt;&lt; \"后台任务完成。\\n\";}void process() {    std::cout &lt;&lt; \"process 函数开始。\\n\";    std::thread t(do_something_in_background);        // *** 关键在这里 ***    // 我们显式地创建了一个 guard 对象，其意图非常明确：    // “我希望在这个作用域的任何出口处，都对线程 t 执行 join 操作”    thread_guard g(t);    std::cout &lt;&lt; \"process 函数即将结束（或因异常退出）。\\n\";    // 当 process 因为异常而退出时，g 的析构函数会被调用    // g 的析构函数会安全地 join 线程 t}int main() {    try {        process();    } catch (const std::exception&amp; e) {        std::cout &lt;&lt; \"main 捕获到异常: \" &lt;&lt; e.what() &lt;&lt; std::endl;    }    return 0;}\r\n线程的创建 (std::thread t(…)) 和“生命周期管理策略” (thread_guard\r\ng(t)) 是分离的、显式的。程序员通过创建 thread_guard\r\n对象，清晰地表达了“我要在这个作用域结束时 join\r\n这个线程”的意图。这不再是隐式的行为，而是一种明确的声明。即使函数因为异常而提前退出，这个声明依然有效，保证了程序的健壮性。\r\nC++20\r\n的终极解决方案：std::jthread\r\nC++20 标准直接引入了\r\nstd::jthread，它本质上就是一个官方实现的、更加完善的\r\nthread_guard。它的析构函数总是会\r\njoin，但这是它公开的、众所周知的、作为其核心设计的行为。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款35 ：优先选用基于任务而非基于线程的程序设计","url":"/2025/09/22/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE35%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E5%9F%BA%E4%BA%8E%E4%BB%BB%E5%8A%A1%E8%80%8C%E9%9D%9E%E5%9F%BA%E4%BA%8E%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/","content":"该条款的核心观点是，当需要异步运行一个函数时，使用\r\nstd::async 的基于任务 (task-based)\r\n的方法，通常优于直接使用 std::thread\r\n的基于线程 (thread-based) 的方法。\r\n基于线程 (Thread-based) 与\r\nstd::thread\r\nstd::thread 是 C++ 标准库中对操作系统线程 (Thread)\r\n的直接封装。线程可以看作是 CPU 上一个独立的执行流。\r\nstd::async\r\nstd::async\r\n是一个函数模板，用于以异步方式（可能在一个单独的线程中）启动一个任务。相比于直接使用\r\nstd::thread，std::async\r\n提供了一种更高层次、更方便的抽象，特别适用于那些需要从异步任务中获取返回值的场景。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款39 ：考虑针对一次性事件通信使用以 void 为模板型别实参的期值","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE39%20-%20%E8%80%83%E8%99%91%E9%92%88%E5%AF%B9%E4%B8%80%E6%AC%A1%E6%80%A7%E4%BA%8B%E4%BB%B6%E9%80%9A%E4%BF%A1%E4%BD%BF%E7%94%A8%E4%BB%A5%20void%20%E4%B8%BA%E6%A8%A1%E6%9D%BF%E5%9E%8B%E5%88%AB%E5%AE%9E%E5%8F%82%E7%9A%84%E6%9C%9F%E5%80%BC/","content":"\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款40 ：对并发使用 std atomic，对特种内存使用 volatile","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE40%20-%20%E5%AF%B9%E5%B9%B6%E5%8F%91%E4%BD%BF%E7%94%A8%20std%20atomic%EF%BC%8C%E5%AF%B9%E7%89%B9%E7%A7%8D%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%20volatile/","content":"\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款10：优先选用限定作用域的枚举型别，而非不限作用域的枚举型别","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE10%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E9%99%90%E5%AE%9A%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%9A%84%E6%9E%9A%E4%B8%BE%E5%9E%8B%E5%88%AB%EF%BC%8C%E8%80%8C%E9%9D%9E%E4%B8%8D%E9%99%90%E4%BD%9C%E7%94%A8%E5%9F%9F%E7%9A%84%E6%9E%9A%E4%B8%BE%E5%9E%8B%E5%88%AB/","content":"C++98\r\n风格的枚举（现在称为不限作用域的枚举型别）存在两个主要缺陷。C++11\r\n引入的限定作用域的枚举型别（也称“枚举类”）则直接解决了这两个问题。\r\n了解枚举\r\n在 C++ 中，枚举 (Enumeration, 简称 enum)\r\n是一种用户自定义的数据类型，它允许我们为一组相关的整型常量赋予具有描述性的名称。\r\n使用枚举的主要目的是增强代码的可读性和类型安全，避免在代码中直接使用“魔术数字”（Magic\r\nNumbers，即未经解释的字面常量）。\r\nC++ 语言中存在两种截然不同的枚举类型：\r\n\r\n不限定作用域的枚举（Unscoped Enumerations，也称为 C 风格枚举）\r\n限定作用域的枚举（Scoped Enumerations，C++11 引入，使用 enum class\r\n关键字）\r\n\r\n不限定作用域的枚举 (C 风格)\r\n这是从 C 语言继承而来的传统枚举, 它使用 enum 关键字定义。\r\n// 定义一个表示颜色的枚举enum Color {    RED,    // 默认值为 0    GREEN,  // 默认值为 1    BLUE    // 默认值为 2};enum Status {    Pending = 10,    Processing,   // 未指定，值为前一个 + 1，即 11    Completed = 20,    Failed        // 值为 21}; 这里我们定义了一个名为 Color 的新类型。RED、GREEN 和 BLUE\r\n是这个类型的枚举器（Enumerators）。其赋值的默认规则是，第一个枚举器（RED）的值为\r\n0，后续枚举器依次递增 1; 我们也可以为枚举器指定具体的值，如 Pending =\r\n10, Completed = 20。\r\n尽管 C 风格枚举提高了可读性，但它在 C++ 中存在两大严重问题：\r\n\r\n缺陷一：作用域污染 (Scope Pollution): C\r\n风格枚举的枚举器会泄漏到其外围作用域（例如，全局作用域或所在的命名空间/类）。\r\nenum Color { RED, GREEN, BLUE };enum TrafficLight { RED, YELLOW, GREEN }; // 编译错误！// 错误原因：RED 和 GREEN 在同一作用域内被重复定义了。// 编译器无法区分 Color 的 RED 和 TrafficLight 的 RED。\r\n缺陷二：弱类型与隐式转换 (Weak Typing): C\r\n风格枚举的枚举器会自动地、隐式地转换为整型（如 int）。这破坏了类型安全。\r\nColor myColor = RED;int colorValue = myColor; // 合法，myColor (值为 0) 被隐式转换为 int 0if (myColor == 0) { // 合法，但不推荐    // ...}// 更糟糕的是，不同枚举类型之间也可能进行比较（只要它们底层值相同）TrafficLight light = RED; // 假设 TrafficLight 的 RED 也是 0if (myColor == light) { // 编译通过！    // 这种比较在逻辑上是无意义的，但编译器允许}\r\n\r\n限定作用域的枚举 (C++11 enum\r\nclass)\r\n为了解决上述所有问题，C++11\r\n引入了“限定作用域的枚举”，也称为“枚举类”。这是在现代 C++\r\n中定义枚举的首选方式。它使用 enum class 关键字（或者等效的 enum\r\nstruct）来定义。 enum class Color {    RED,    GREEN,    BLUE};enum class TrafficLight {    RED,    YELLOW,    GREEN};\r\n它的优势一是强作用域 (Strongly Scoped): enum class\r\n的枚举器被严格限制在枚举类型的花括号内，不会泄漏到外部作用域。不过也正因此,\r\n访问这些枚举器时，必须使用枚举类型名称作为限定符。 // 必须通过类型名::枚举器 来访问Color myColor = Color::RED; TrafficLight light = TrafficLight::RED;// 编译通过！// Color::RED 和 TrafficLight::RED 位于不同作用域，互不干扰。Color c = RED; // 编译错误！RED 不在当前作用域中。\r\n优势二是强类型，禁止隐式转换为整型. 这是 enum class\r\n提供的最关键的类型安全保证。 Color myColor = Color::RED;int colorValue = myColor; // 编译错误！                        // 无法将 Color 类型隐式转换为 intif (myColor == 0) { // 编译错误！                  // 无法在 Color 类型和 int 类型之间进行比较}// 不同枚举类型之间也不能比较if (myColor == TrafficLight::RED) { // 编译错误！}\r\n\r\n如果确实需要将枚举值转换为整数，我们必须使用显式类型转换（通常是\r\nstatic_cast）。强制使用 static_cast\r\n表明程序员是有意图地要将这个具有强类型的枚举值转换为一个普通的整数，这使得代码意图更加清晰。\r\n\r\n两者的底层类型\r\n在C++98的默认情况下，编译器会为枚举选择一个足够大的整数类型（如\r\nint）来存储所有枚举值,\r\n但这必须要求枚举定义完成之后(也就是C++98无法实现枚举的前向声明)。但在\r\nC++11 中，我们可以为两种枚举（C 风格和 enum class）显式指定底层存储类型,\r\n主要的好处在于:\r\n\r\n内存控制： 当枚举值范围很小时（例如\r\n0-255），可以指定一个小的类型（如 std::uint8_t，即无符号 8\r\n位整数），这在定义大型数组或内存敏感的结构体时非常重要。\r\nAPI 兼容性： 确保与需要特定整数宽度（如 32 位）的 C API\r\n或库函数兼容。\r\n前向声明： enum\r\n如果指定了底层类型，就可以被前向声明（在头文件中提前声明类型，而在 .cpp\r\n中定义具体内容）。\r\n\r\n限定作用域(enum class)的枚举默认的底层类型是 int ,\r\n由于底层类型总是已知的（要么是默认的\r\nint，要么是用户指定的），因此它们总是可以被前置声明(总之限定作用域的枚举更优越)\r\n。\r\n不限作用域(enum)的枚举没有默认的底层类型,\r\n因此必须显式指定了底层类型，不限作用域的枚举才可以被前置声明 。\r\n// 语法：enum class 类型名 : 底层整数类型 { ... };// 这个枚举将使用一个 8 位的无符号字节来存储enum class CompactColor : std::uint8_t {    RED,    GREEN,    BLUE};\r\n\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 29 - 假定移动操作不存在、成本高、未使用","url":"/2025/09/19/lang/CPP/Effective%20modern%20C++/%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8,%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/%E6%9D%A1%E6%AC%BE29%20-%20%E5%81%87%E5%AE%9A%E7%A7%BB%E5%8A%A8%E6%93%8D%E4%BD%9C%E4%B8%8D%E5%AD%98%E5%9C%A8%E3%80%81%E6%88%90%E6%9C%AC%E9%AB%98%E3%80%81%E6%9C%AA%E4%BD%BF%E7%94%A8/","content":"该条款旨在为开发者对C++11移动语义的性能预期“降温”，提醒我们移动语义并非万能的性能优化选择。在编写代码时，尤其是在编写通用代码（如模板）时，更安全的做法是假定移动操作可能不存在、可能成本高昂，或者在特定上下文中可能不会被使用。\r\n移动语义是C++11的标志性特性，它允许编译器用成本低廉的移动操作来代替昂贵的复制操作，甚至在某些情况下，只需重新编译C++98的代码就能获得性能提升\r\n。然而，这种“传奇”般的描述常常掩盖了现实中的复杂性。本条款的目的就是揭示这些复杂性，让我们对移动语义有一个更现实的期望。\r\n移动语义可能不会带来好处的四种场景\r\n在以下几种情况中，你将无法从移动语义中获得预期的性能增益：\r\n\r\n没有移动操作 (No move operations):\r\n待移动的对象根本没有提供移动操作（移动构造函数和移动赋值运算符）。\r\n\r\n实际上,\r\n许多为C++11之前编写的遗留代码中的类没有移动操作。即使在C++11中，如果一个类显式声明了复制操作、移动操作或析构函数中的任何一个，编译器都不会自动为其生成移动操作（参见条款17）。\r\n当代码请求移动一个没有移动操作的对象时，编译器会退而求其次，转而执行复制操作\r\n。\r\n\r\n移动未能更快 (Move is not faster):\r\n待移动的对象虽然提供了移动操作，但其实现并不比复制操作更快。\r\n\r\n例如 std::array 的内容是直接存储在对象内部的，不像 std::vector\r\n那样在堆上分配内存并只持有一个指针。因此，移动一个 std::array\r\n必须逐个移动其内部的所有元素, 这是一个线性时间的操作，其成本与复制一个\r\nstd::array 相当，远非人们想象中“像复制指针一样快” 。\r\n再比如 std::string 与小型字符串优化 (SSO), 许多 std::string\r\n的实现采用了SSO技术，即将短字符串直接存储在 std::string\r\n对象内部的缓冲区中，避免了堆内存分配。当移动一个采用了SSO的短字符串时，其操作本质上就是复制内部缓冲区，因此其成本与复制操作并无区别\r\n。\r\n\r\n移动不可用 (Move is not available):\r\n在某些需要强异常安全保证的语境下，移动操作只有在被声明为 noexcept\r\n时才会被调用。\r\n\r\n以 std::vector 扩容为例，如果元素的移动构造函数可能会抛出异常，vector\r\n在移动了一半元素后若发生异常，将无法恢复到原始状态，破坏了强异常安全保证。为了维持异常安全，如果一个类型的移动操作没有被标记为\r\nnoexcept，那么在这些需要强异常安全的场景中（如 std::vector\r\n扩容），编译器会强制调用复制操作，即使移动操作本身存在且可能更高效\r\n。\r\n\r\n源对象是个左值 (Source object is an lvalue):\r\n移动操作的源通常必须是右值（例如，临时对象或通过 std::move\r\n转换的对象。如果尝试从一个左值“移动”，实际上会触发复制操作，除非显式使用了\r\nstd::move\r\n\r\n最后需要指出,\r\n本条款的建议并非是完全放弃对移动语义的依赖，而是要采取一种审慎的态度。在通用代码中（如模板）：由于你无法预知将要处理的类型\r\nT\r\n是否支持高效且不抛异常的移动，最安全的做法是假定移动成本高昂，像在C++98中那样谨慎地对待复制操作\r\n。\r\n而在特定代码中, 如果你明确知道正在使用的类型（例如 std::vector 或\r\nstd::string）的移动语义细节，并且确定它们在你的使用场景中是高效且会被调用的，那么你完全可以依赖移动语义来提升性能\r\n。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 15 - 只要有可能使用 constexpr, 就使用它","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE15%20-%20%E5%8F%AA%E8%A6%81%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BD%BF%E7%94%A8%20constexpr,%20%E5%B0%B1%E4%BD%BF%E7%94%A8%E5%AE%83/","content":"constexpr（Constant Expression，常量表达式）是 C++11\r\n引入的一个至关重要的关键字，它允许我们将计算的执行时机从运行时 (Runtime)\r\n提前到编译时 (Compile Time)。\r\n这不仅仅是一项微小的优化，它从根本上改变了 C++\r\n的编程范式，使得在编译阶段进行复杂的计算和逻辑判断成为可能，从而提高了程序的运行效率并增强了编译期的检查能力。\r\nconstexpr 对象/变量\r\n当 constexpr 应用于对象时，它实际上是 const 属性的加强版。\r\nconst 对象：一个被声明为 const\r\n的对象，其值在初始化后不能被修改。但是，它的初始值不一定在编译期就已知。它可以由一个运行时才计算出的值来初始化。\r\nint sz;const auto arraySize = sz; // 合法，但 arraySize 的值在编译期未知// std::array&lt;int, arraySize&gt; data; // 错误！arraySize 不是编译期常量\r\nconstexpr 对象：该对象不仅是 const\r\n的，而且其值必须在编译期就已知（准确地说是“翻译期间”可知）。并且所有\r\nconstexpr 对象都是 const 对象，但并非所有 const 对象都是 constexpr\r\n对象。正因如此, 它强制要求该变量必须在编译时被一个“常量表达式”初始化\r\n由于其值在编译期已知，constexpr 对象拥有特权，它们可以被用在 C++\r\n要求“整型常量表达式”的任何语境中，例如指定数组的尺寸（C-style 数组，非\r\nstd::vector）int arr[N] (这里的 N\r\n必须是编译期常量)、作为模板的非类型参数(Non-Type\r\nTemplate Arguments) std::array&lt;int, N&gt; (这里的 N\r\n必须是编译期常量)、枚举量的初始化值等。\r\nconstexpr auto arraySize2 = 10; // 没问题，10 是编译期常量std::array&lt;int, arraySize2&gt; data; // 没问题！\r\nconstexpr 函数\r\n当 constexpr 应用于函数时，其含义变得更加灵活: 首先, 一个 constexpr\r\n函数不一定返回编译期已知的结果。\r\n\r\n如果一个 constexpr\r\n函数被调用时，传入的实参都是编译期常量，那么该函数的产出结果也将是一个编译期常量。\r\n如果它被调用时，传入的参数中至少有一个是运行时才已知的值，那么该函数将会在运行时被执行，其行为和结果都与普通函数无异。\r\n\r\n这是 constexpr\r\n函数最强大的特性：只需编写一次函数，它就可以同时服务于编译期和运行时两种场景。\r\n// 一个 constexpr 阶乘函数constexpr long long factorial(int n) {    return (n &lt;= 1) ? 1 : (n * factorial(n - 1));}// === 场景 1: 编译时使用 ===// 因为参数 5 是一个编译期常量（字面量），// 编译器会直接在编译期间计算 factorial(5)，即 120。constexpr long long F5 = factorial(5);// 下面这行代码在编译后，等同于 std::array&lt;int, 120&gt; arr;std::array&lt;int, factorial(5)&gt; arr; // === 场景 2: 运行时使用 ===std::cout &lt;&lt; \"请输入一个数字: \";int x;std::cin &gt;&gt; x; // x 是一个运行时变量// 编译器无法在编译时知道 x 的值，// 于是 factorial(x) 会像一个普通函数一样，在程序运行时被调用和计算。long long result = factorial(x); std::cout &lt;&lt; \"结果是: \" &lt;&lt; result &lt;&lt; std::endl;\r\n我们只编写了一个 factorial\r\n函数，但它既能用于需要编译期常量的模板参数（场景1），也能用于处理运行时的用户输入（场景2）。这就是\r\nconstexpr 函数的核心价值。\r\n\r\n需要注意的是, 上面那个 factorial 示例就是 C++11 风格的。在 C++11\r\n中，constexpr 函数几乎是“函数式”的。它内部只能包含一个单独的 return\r\n语句,\r\n不允许有局部变量、循环，只允许使用（极其复杂的）递归和三元运算符（?:）来实现逻辑。而C++14后的constexpr\r\n函数基本与正常函数无异\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款14：只要函数不会发射异常，就为其加上 noexcept 声明","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE14%20-%20%E5%8F%AA%E8%A6%81%E5%87%BD%E6%95%B0%E4%B8%8D%E4%BC%9A%E5%8F%91%E5%B0%84%E5%BC%82%E5%B8%B8%EF%BC%8C%E5%B0%B1%E4%B8%BA%E5%85%B6%E5%8A%A0%E4%B8%8A%20noexcept%20%E5%A3%B0%E6%98%8E/","content":"正如标题所指出的, noexcept\r\n是一个关键的函数接口规范，它能带来显著的编译器优化，并对移动语义的实现至关重要。\r\n\r\n在 C++11 之前，C++98 提供了异常规格（如 throw(SomeException) 或\r\nthrow()），但这套机制要求开发者列出函数可能抛出的所有异常类型，这在实践中难以维护，且编译器通常不会严格检查其一致性，导致该特性最终被普遍弃用。实际上,\r\n开发者真正关心的信息是二元的：一个函数是否可能发射异常。noexcept\r\n声明就是 C++11 中用于保证函数不会发射异常的工具\r\n\r\n核心动机：编译器优化\r\n为函数添加 noexcept\r\n声明的最直接动机是，它允许编译器生成更优的目标代码。这源于 noexcept 和\r\nC++98 的 throw() 在违反承诺时的不同处理方式：\r\n\r\nint f(int x) throw(); (C++98\r\n风格)：如果在运行时，一个异常企图逸出 f\r\n的作用域，程序会中止，但在中止前，调用栈必须被“展开”（unwound）至 f\r\n的调用方。\r\nint f(int x) noexcept; (C++11\r\n风格)：如果一个异常企图逸出 f\r\n的作用域，程序也会中止，但标准规定栈只是可能会被开解。\r\n\r\n这个“必须开解”与“可能开解”的区别对优化器至关重要。对于一个 noexcept\r\n函数，编译器在生成代码时，无需在异常逸出函数时将执行期栈保持在可开解状态，也无需保证函数内的所有对象以其构造顺序的逆序完成析构。这种灵活性使得优化器可以生成更精简、更高效的代码。而没有\r\nnoexcept 声明的函数则无法享受这种优化。\r\n关键用例：noexcept 与移动语义\r\nnoexcept 最重要的实际应用在于它与移动语义的交互。许多 C++11\r\n的功能（特别是标准库容器）为了性能会优先选用移动操作而非复制操作，但前提是它们必须保证不破坏\r\nC++98 代码所依赖的异常安全承诺。\r\n以 std::vector::push_back 为例：当向 std::vector\r\n添加一个新元素，而此时其 size() 等于 capacity() 时，vector\r\n必须分配一块新的、更大的内存，并将所有旧元素转移到新内存中。\r\n\r\nC++98 (复制)：在 C++98\r\n中，这个转移是通过复制元素完成的。这提供了强异常安全保证：如果在复制第\r\nn+1 个元素时抛出异常（例如内存不足），vector\r\n可以保持在原始状态（因为旧内存中的元素都还在,\r\n旧内存中的元素直至所有的元素被成功复制入新内存以后，才会被执行析构），保证了数据的不变性。\r\nC++11 (移动)：在 C++11\r\n中，使用移动操作来转移元素会高效得多。但是，移动操作通常会“掏空”源对象。如果在移动了\r\nn 个元素后，在移动第 n+1\r\n个元素时抛出异常，此时操作无法回滚：旧内存中的前 n\r\n个元素已被移走（处于无效状态），而新内存也没有完全构建好。这破坏了强异常安全保证。\r\n\r\n为了解决这个冲突，std::vector::push_back 等函数在 C++11\r\n中遵循一个规则：它们只会在元素的移动构造函数被显式声明为\r\nnoexcept 时，才会使用移动操作。如果移动构造函数没有 noexcept\r\n声明（意味着它可能会抛出异常），vector\r\n将退回到使用（更慢的）复制操作，以确保强异常安全保证不被破坏。\r\n\r\nstd::vector::push_back 采取了这种“能移动则移动，必须复制才复制” (move\r\nif you can, but copy if you must) 策略,\r\n而它并不是标准库中唯一这样做的函数。 C++98\r\n中其他因为强异常安全保证而酷炫的函数 (std::vector:: reserve,\r\nstd::deque::insert 等）的行为也是这样。所有这些函数都把其中 C++98\r\n的复制操作替换成了 C++11\r\n中的移动操作，但仅在已经移动操作不会发射异常(声明为noexcept)的前提下。\r\n\r\n连锁效应：swap 函数\r\n前面的规则似乎已经很完备, 然而,\r\n对于模板（template）或管理其他类型成员的复合类型（composite\r\ntypes），我们编写函数时（如\r\nswap），并不知道它所操作的底层类型是否会抛出异常。这就是\r\nnoexcept(expression) 这种用法（条件\r\nnoexcept）的用武之地。这里的关键是区分：\r\n\r\nnoexcept\r\n关键字（修饰符）：放在函数声明的末尾，告诉编译器这个函数是否承诺不抛出异常。\r\nnoexcept(expression)\r\n运算符：一个在编译期求值的运算符。如果\r\nC++ 编译器确定 expression\r\n表达式（它并不会真的执行这个表达式，只是分析它）保证不会抛出异常（即表达式本身是\r\nnoexcept 的），那么这个运算符返回 true；否则返回 false。\r\n\r\n下面是针对数组和pair的条件noexcept示例: template &lt;class T, size_t N&gt; void swap(T (&amp;a)[N], T (&amp;b)[N])     noexcept(noexcept(swap(*a, *b))); template &lt;class T1, class T2 &gt; struct pair {     void swap(pair&amp; p) noexcept(noexcept(swap(first, p.first)) &amp;&amp;                                 noexcept(swap(second, p.second)));     // ...};\r\n第一个模板代码是一个针对 C 风格数组（具有相同类型 T 和相同大小 N）的\r\nswap 函数模板的特化版本。我们知道, 要交换两个数组，其实现（例如\r\nstd::swap 对数组的实现）通常是遍历数组，并对数组中的每一个对应元素执行\r\nswap 操作。\r\n而这个数组 swap 函数是否会抛出异常？这完全取决于它在循环内部调用的\r\nswap(a[i], b[i]) 是否会抛出异常。如果交换一个 T 类型的元素（swap(T&amp;,\r\nT&amp;)）是 noexcept 的，那么交换整个数组（循环执行N次）也自然是\r\nnoexcept 的。反之，如果交换 T 可能会抛异常，那么这个数组 swap\r\n函数也必须被视为可能抛异常。\r\n这便是代码noexcept(noexcept(swap(*a, *b)))的意义, 内部的\r\nnoexcept(swap(a, b))是一个 noexcept 运算符, 它检查是否调用类型\r\nT 的 swap（即 swap(T&amp;, T&amp;)）被声明为 noexcept. 如果是，noexcept\r\n运算符返回 true; 外部的 noexcept(…)是一个 noexcept 修饰符,\r\n它接收内部运算符返回的 bool 值（true 或\r\nfalse）并决定是否修饰函数。第二个示例同理\r\n通过使用条件 noexcept，这些模板（数组\r\nswap）和复合类型（pair）能够将其自身的异常规范建立在其所依赖的底层类型的异常规范之上。\r\n\r\n最后还要区分“异常中立”函数：大多数函数本身不抛出异常，但它们调用的其他函数可能会抛出异常。这种“路过”异常的函数被称为“异常中立”\r\n(exception-neutral) 的，它们也不应该被声明为 noexcept。\r\n\r\n\r\n在 C++11\r\n中，默认规定内存释放函数和所有的析构函数（无论是用户定义的，还是编译器自动生成的）都隐式地具备\r\nnoexcept 性质。\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款38 ：对变化多端的线程句柄析构函数行为保持关注","url":"/2025/09/23/lang/CPP/Effective%20modern%20C++/%E5%B9%B6%E5%8F%91API/%E6%9D%A1%E6%AC%BE38%20-%20%E5%AF%B9%E5%8F%98%E5%8C%96%E5%A4%9A%E7%AB%AF%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%8F%A5%E6%9F%84%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%E8%A1%8C%E4%B8%BA%E4%BF%9D%E6%8C%81%E5%85%B3%E6%B3%A8/","content":"该条款的核心论点是，std::thread 和期值（std::future /\r\nstd::shared_future）虽然都可以看作是系统线程的句柄，但它们的析构函数行为却截然不同，这种差异对于编写健壮的并发代码至关重要。\r\n对于std::thread, 正如前面所说, 其析构函数的行为非常严格和明确：如果\r\nstd::thread 对象是可联结的\r\n(joinable)，其析构函数的调用将导致程序终止\r\n与 std::thread\r\n不同，期值(std::future)析构函数的行为要复杂得多。为了理解它，首先需要了解共享状态\r\n(shared state) 的概念:\r\n共享状态是期值通信机制的核心。它通常是在堆上分配的一个对象，用于存储由异步任务（被调方）计算出的结果或抛出的异常，并将其传递给期值（调用方）\r\n。\r\n期值析构函数的行为完全取决于其所引用的共享状态。具体来说，有两种截然不同的行为模式。\r\n常规行为：仅析构期值对象\r\n对于绝大多数期值，其析构函数只会做一件事：销毁期值对象本身。这意味着它不会\r\njoin，也不会\r\ndetach，不会阻塞，也不会运行任何东西。它仅仅是销毁期值的成员变量，并递减共享状态的引用计数。这种常规行为适用于所有通过\r\nstd::promise 或 std::packaged_task 创建的期值。\r\n特殊行为：阻塞并等待\r\n存在一个非常重要的例外情况。当且仅当一个期值同时满足以下所有条件时，其析构函数会阻塞，直到异步任务完成（效果等同于隐式的\r\njoin）：该期值所引用的共享状态是由 std::async\r\n的调用所创建的。该任务的启动策略是 std::launch::async\r\n（无论是显式指定还是由默认策略选择的）。该期值是最后一个引用该共享状态的期值。\r\n// 析构函数可能会阻塞std::vector&lt;std::future&lt;void&gt;&gt; futs; class Widget {private:    // Widget 对象的析构函数可能会阻塞    std::shared_future&lt;double&gt; fut;};\r\n如果这些容器或对象中持有的期值恰好是最后一个引用由 std::async\r\n启动的异步任务的期值，那么在容器或对象析构时，程序就会在此处阻塞，直到任务完成。\r\n特殊行为的成因与后果\r\n成因：标准委员会为了避免隐式 detach\r\n可能导致的未定义行为（参见条款37），但又不希望像 std::thread\r\n那样直接终止程序，最终妥协设计了这种针对 std::async 任务的隐式 join\r\n行为。\r\n后果：开发者无法仅通过期值的类型来判断其析构函数是否会阻塞。这可能会在不经意间引入性能问题，尤其是在关键路径上或GUI线程中，意外的阻塞可能是致命的。\r\n因此，在处理期值时，了解其来源至关重要。如果一个期值来自\r\nstd::async，你就必须警惕其析构函数可能导致的阻塞行为。\r\n\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款8：优先选用 nullptr, 而非 NULL 或者0","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE8%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20nullptr,%20%E8%80%8C%E9%9D%9E%20NULL/","content":"首先, 我们需要开门见山地指出, 0 和 NULL 都不具备指针类型,\r\n它们的本质是整数，只是依赖于上下文（Context）被“特殊看待”为空指针\r\n\r\n0 的类型是 int：它是一个整数字面常量。C++\r\n只是在语言层面做一个不得已的“变通”：仅在上下文强制要求指针的语境中，才将\r\n0\r\n勉强解释为空指针。但在重载决议等情况下，它的“真实身份”——int——会优先被匹配。\r\nNULL 的类型是整型：NULL 是一个预处理宏，它在 C++\r\n中通常被定义为 0（一个 int）或 0L（一个 long）。因此，NULL\r\n也不是指针类型，它是一个整型字面量。\r\n\r\n不区分三者最大的隐患：重载决议失败\r\n假设有三个重载函数： void f(int);    // 重载版本 #1void f(bool);   // 重载版本 #2void f(void*);  // 重载版本 #3 (接受指针) 分析 f(0) 和 f(NULL)：\r\n\r\n调用 f(0)：由于 0 的类型是 int，它与 f(int)\r\n构成完美匹配。因此，编译器会毫不犹豫地选择调用重载版本\r\n#1。它永远不会调用 f(void*)。\r\n调用 f(NULL)：由于 NULL 通常被定义为 0（一个 int），这与调用 f(0)\r\n的情况完全相同。编译器依然会选择 f(int)。\r\n\r\n这完全违背了程序员的意图。程序员传入 0 或 NULL\r\n的本意是想传递一个“空指针”，希望调用版本 #3，但结果却调用了 int\r\n版本。\r\nC++11 引入的 nullptr 解决了这个问题。nullptr\r\n的类型不是整型。它的实际类型是 std::nullptr_t, 并且\r\nstd::nullptr_t 可以隐式转换为所有裸指针类型（如 void, int,\r\nWidget* 等）。\r\n当调用 f(nullptr) 时，nullptr 无法被匹配为 f(int) 或\r\nf(bool)。但它可以被隐式转换为 void*，因此它精确地匹配并调用了重载版本\r\n#3，这完全符合程序员的意图。\r\n提升代码清晰度：auto 与\r\nnullptr\r\n在现代 C++ 中，auto 的广泛使用使得 0 和 NULL 的歧义性更加突出。例如:\r\nauto result = findRecord(/* ... */);if (result == 0) { /* ... */ } // 这是什么意思?if (result == nullptr) { /* ... */ } // 意思很明确 分析 result == 0：当读者看到这行代码时，无法立即判断\r\nresult 的类型。findRecord 返回的 result\r\n究竟是一个指针类型，还是一个整型（例如，错误码或计数）？代码存在歧义。\r\n分析 result == nullptr：这行代码则毫无歧义。它能通过编译的唯一前提是\r\nresult 必须是一个指针类型（或智能指针等支持与 nullptr\r\n比较的类型）。这极大地提升了代码的清晰度。\r\n保证模板类型推导的正确性\r\n0 和 NULL\r\n最大的失败在于模板类型推导。当它们被传递给模板时，编译器会推导它们的“真实”类型（即整型），而不是程序员“期望”的空指针。这种类型上的差异导致了在泛型代码中（如模板函数）传递空指针意图时，只有\r\nnullptr 能够保证类型安全和编译成功。\r\n???\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款16：保证 const 成员函数的线程安全性","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE16%20-%20%E4%BF%9D%E8%AF%81%20const%20%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7/","content":"mutable关键字\r\nmutable（意为“可变的”）是一个存储说明符关键字，它的唯一目的就是“突破\r\nconst 限制”。\r\n我们知道，一个被 const 修饰的成员函数（例如 void myFunction()\r\nconst;）向调用者承诺：“这个函数不会修改对象的任何成员变量。”. 然而, 因为\r\nmutable 用于修饰类的非静态数据成员, 一旦一个成员变量被声明为\r\nmutable，那么即使在一个 const 成员函数中，这个变量也可以被修改。\r\n也就是说, mutable 是 const 这个规则的一个“例外条款”。 class MyClass {private:    int regularValue;    mutable int mutableValue; // 被 mutable 修饰public:    MyClass(int v1, int v2) : regularValue(v1), mutableValue(v2) {}    void regularFunc() {        regularValue = 100;   // OK：普通函数可以修改普通成员        mutableValue = 200;   // OK：普通函数当然也可以修改 mutable 成员    }    void constFunc() const {        // regularValue = 100; // 编译错误！const 函数不能修改非 mutable 成员        mutableValue = 200;   // 正确！mutable 成员可以在 const 函数中被修改    }};\r\n#### 为什么需要 mutable？\r\n你可能会问：const\r\n函数的意义不就是“不修改”吗？允许修改岂不是违背了初衷？这里引出了 C++\r\n中关于 “const” 的两个重要概念：\r\n\r\n按位 Const (Bitwise\r\nConstness)：这是编译器默认的实现方式。只要一个成员函数没有修改对象内存布局中的任何一个\r\nbit（位），它就是 const 的。\r\n逻辑 Const (Logical\r\nConstness)：这是开发者和调用者所期望的。只要一个成员函数没有修改对象的“外部可见的逻辑状态”，它就应该是\r\nconst 的。\r\n\r\n在大多数情况下，两者是一致的。但有时，为了维持“逻辑上的不变”，我们可能需要修改一些“内部实现上的细节”。mutable\r\n就是用来实现“逻辑 Const”的工具。\r\nmutable用例\r\n用例 1：缓存 (Caching) / 延迟计算 (Memoization)\r\n假设你有一个类，它有个函数需要执行非常昂贵的计算，但这个计算结果在对象生命周期内是固定的。\r\nclass ExpensiveCalculator {private:    SomeInputData data;        // 用于缓存计算结果    mutable double cachedResult;     mutable bool cacheValid = false; // 跟踪缓存是否有效    double expensiveCalculation() const {        // ... 执行非常复杂和耗时的计算 ...        return 42.0;     }public:    double getValue() const { // 这是一个 const 函数，因为它逻辑上不改变计算器的状态        if (!cacheValid) {            // 这是修改操作，但它只发生在 const 函数内部            cachedResult = expensiveCalculation(); // 必须是 mutable            cacheValid = true;                     // 必须是 mutable        }        return cachedResult;    }}; getValue() 承诺自己是 const\r\n的，因为它返回的值（逻辑状态）始终是相同的。但是为了提高性能，它在内部使用了\r\nmutable\r\n变量来缓存结果。从外部调用者看来，这个对象没有发生任何逻辑上的改变,\r\n尽管内部的确发生了一些无关紧要的优化类型的变量改变.\r\n用例 2：用于 Mutex 假设我们有一个类，它的大多数成员函数都是\r\nconst（因为它们只是读取数据），但我们希望这些读取操作在多线程环境下是安全的。\r\nclass ThreadSafeReader {private:    std::string sharedData = \"Data\";    mutable std::mutex dataMutex; // 关键！Mutex 必须是 mutable 的public:    std::string getData() const { // 这是一个 const 成员函数                // 我们需要锁，因为可能有其他线程（通过非 const 函数）正在写入 sharedData        // 但是 lock() 是一个“非 const”操作（它会修改 mutex 内部的状态）        // 为了能在 const 函数 getData() 内部调用 dataMutex.lock()，        // dataMutex 必须被声明为 mutable。                std::lock_guard&lt;std::mutex&gt; guard(dataMutex); // 这在编译上是合法的                return sharedData;    }    void setData(const std::string&amp; s) {        std::lock_guard&lt;std::mutex&gt; guard(dataMutex);        sharedData = s;    }}; 在这个例子中，getData() 从逻辑上看是 const\r\n的（它只是返回数据，不改变类的逻辑状态）。但是为了保证线程安全，它必须对内部的\r\ndataMutex 进行 lock() 操作。lock() 操作会修改 mutex\r\n对象本身的状态。因此，为了让编译器允许 const 函数修改 mutex 成员，这个\r\nmutex 必须被声明为 mutable。\r\n这是 mutable 最常见、最标准的用途之一：允许 const\r\n成员函数获取锁以实现线程安全。\r\nmutex 互斥量\r\nmutex 不是关键字，它是 C++11 在  头文件中提供的一个类，全称为\r\nMutual Exclusion（互斥）。\r\n它是多线程编程中的一种同步原语（Synchronization Primitive）,\r\n其核心作用是保护共享资源，以防止多个线程同时访问和修改该资源时引发的竞态条件\r\n(Race Condition)。\r\n为什么需要 mutex？\r\n在多线程程序中，如果多个线程同时尝试修改同一个变量（例如一个全局计数器\r\ncounter），就会发生问题。\r\n一个简单的 counter++ 操作在底层汇编中通常至少包含三个步骤： - 读取\r\n(Read)：将 counter 的当前值从内存加载到 CPU 寄存器。 - 修改\r\n(Modify)：在寄存器中将该值加 1。 - 写回\r\n(Write)：将寄存器中的新值写回到内存中的 counter 位置。\r\n竞态条件示例：假设 counter 当前为 10, 首先线程 A\r\n读取 counter得到 10（此时发生上下文切换）, 线程 B 读取 counter (也得到\r\n10); 接着线程 B 修改寄存器变为 11并写回 11 到 counter; 然后再切回线程\r\nA(不同线程执行时间有差异), 线程 A 仍然拿着旧值 10修改寄存器变为 11并写回\r\n11 到 counter。\r\n最后的结果是两个线程都执行了 ++ 操作，但 counter 的最终结果是\r\n11，而不是预期的 12。数据损坏了。\r\nMutex 如何工作？\r\nmutex 通过提供两个核心操作 lock() 和 unlock() 来解决这个问题。\r\n我们可以把共享资源（如 counter）想象成一个“秘密会议室”，而 mutex\r\n就是挂在门上的“唯一的锁”。\r\n\r\n临界区 (Critical\r\nSection)：那段必须被保护起来、不允许并发执行的代码（如\r\ncounter++）被称为“临界区”。\r\nlock()：当一个线程想要进入临界区时，它必须先尝试获取锁，即调用\r\nmy_mutex.lock()。如果锁可用，该线程获取锁，然后进入临界区;\r\n如果锁已被其他线程持有，该线程将阻塞 (Block)，直到那个线程释放锁。\r\nunlock()：当线程完成临界区的工作后，它必须释放锁，即调用\r\nmy_mutex.unlock()，以便其他正在等待的线程可以获取它。\r\n\r\n通过这种机制，mutex\r\n确保了在任何时刻，只有一个线程能够进入临界区，从而保证了操作的原子性\r\n(Atomicity)。\r\n现代 C++\r\n中的安全用法：RAII 与 std::lock_guard\r\n手动调用 lock() 和 unlock() 是非常危险的。如果在 lock()\r\n之后、unlock() 之前，代码抛出了一个异常，那么 unlock()\r\n将永远不会被调用，这个锁将永久锁定，所有其他等待该锁的线程将无限期阻塞（称为死锁\r\nDeadlock）。\r\n为了解决这个问题，C++ 提供了\r\nRAII（资源获取即初始化）模式的封装类：std::lock_guard。 #include &lt;mutex&gt;#include &lt;thread&gt;int counter = 0;std::mutex mtx; // 全局互斥量，用于保护 countervoid thread_task() {    for (int i = 0; i &lt; 10000; ++i) {        // 安全的做法：使用 lock_guard        // 1. 当 guard 对象被创建时（构造函数），它自动调用 mtx.lock()        std::lock_guard&lt;std::mutex&gt; guard(mtx);                counter++; // 这里是临界区，现在是线程安全的                // 2. 当 guard 离开作用域时（在 '}' 处），其析构函数被自动调用，        //    析构函数会自动调用 mtx.unlock()。        //    即使 counter++ 抛出异常（虽然 int++ 不会），析构函数也会被调用，保证解锁。    }}\r\nstd::lock_guard 利用了 C++\r\n的构造函数和析构函数机制。在构造时自动加锁，在析构时（无论函数是正常返回还是因异常退出）自动解锁，从而完美地保证了锁的释放。\r\nstd::atomic\r\n我们之前讨论了 mutex（互斥锁）。mutex 采用阻塞 (Blocking),\r\n是解决多线程数据竞争的一种重量级的同步机制。而 std::atomic\r\n提供了一种非阻塞 (Non-Blocking) 的同步方式。下面我们先了解一下\r\nstd::atomic\r\n\r\n多线程阻塞这种“挂起”和“唤醒”操作涉及到了操作系统内核态与用户态的切换，这是一个非常昂贵（高延迟）的操作。对于那些需要频繁更新、但冲突并不严重的共享变量（例如一个全局访问计数器），使用\r\nmutex 就像“杀鸡用牛刀”，开销太大了。\r\n\r\nstd::atomic 是 C++11 引入的一个极其重要的特性，它位于 \r\n头文件中。它是 C++ 底层内存模型和原子操作的基石，也是实现无锁编程\r\n(Lock-Free Programming) 的核心工具。\r\nstd::atomic\r\n提供了一种能力，使得对某个变量的简单操作（如读、写、增、减、交换等）可以原子性\r\n(Atomically) 地完成。它依赖于 CPU 硬件层面提供的原子指令 (Atomic\r\nInstructions)（例如 x86 上的 LOCK CMPXCHG）。这些特殊的 CPU\r\n指令可以在硬件层面保证一个“读-改-写”的操作序列在执行的中途不会被任何其他线程打断（即它是原子的）。\r\n当一个变量被声明为 std::atomic\r\n时，编译器会确保对这个变量的所有操作都转化为这些特殊的原子 CPU\r\n指令，而不是我们之前担心的普通的“读、改、写”三部曲。\r\n上述示例中采用std::atomic的同款代码如下: #include &lt;atomic&gt;std::atomic&lt;int&gt; atomic_counter(0); // 将 counter 封装为 atomic 类型void task() {    atomic_counter++; // 这一行代码会被编译成一条单一的、原子的 CPU 指令                       // (例如在 x86 上是 \"LOCK XADD\")                           // 或者使用等效的 fetch_add，语义更清晰：    atomic_counter.fetch_add(1); // 以原子的方式“取回当前值并加1”} 在 atomic\r\n版本中，当多个线程同时执行 atomic_counter.fetch_add(1) 时，CPU\r\n硬件会保证这些指令依次排队执行，一个完成了下一个才能开始（在极小的 CPU\r\n指令时间尺度上），它们不会像普通 ++ 那样发生“读-改-写”步骤的交错。\r\n最重要的是，这个过程完全在用户态完成，没有线程会被操作系统挂起（阻塞）。如果发生冲突，线程通常只会进行几次“自旋\r\n(Spin)”（即 CPU 空转几个周期再试一次），这比内核调度的开销小得多。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 17 - 理解特种成员函数的生成机制","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE17%20-%20%E7%90%86%E8%A7%A3%E7%89%B9%E7%A7%8D%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%9F%E6%88%90%E6%9C%BA%E5%88%B6/","content":"“特种成员函数”指的是那些C++编译器在特定情况下会自动生成的成员函数。在C++11之后,\r\n特种成员函数指的是默认构造函数, 析构函数, 拷贝构造函数, 拷贝赋值运算符,\r\n移动构造函数, 移动赋值运算符。一般来说,\r\n这些函数仅在代码中需要它们，且程序员没有显式声明它们时才会被自动生成。同时,\r\n这些函数的自动生成存在一些机制, 下面我们来详细了解一下。\r\n移动操作的生成规则\r\n编译器仅在同时满足以下所有三个条件时，才会为类生成移动操作（移动构造函数和移动赋值运算符）\r\n：\r\n\r\n类中没有用户声明的拷贝操作（拷贝构造函数或拷贝赋值运算符）。\r\n类中没有用户声明的移动操作（移动构造函数或移动赋值运算符）。\r\n类中没有用户声明的析构函数。\r\n\r\n针对上述内容, 解释如下:\r\n首先,\r\n如果程序员为一个类编写了拷贝操作，这表明默认的、按成员拷贝的方式不适用于该类。编译器据此推断，默认的、按成员移动的方式很可能也不适用，因此不再自动生成移动操作\r\n。\r\n而如果程序员编写了析构函数，这通常意味着该类在进行某种需要手动清理的资源管理，这正是C++98“三法则”（Rule\r\nof\r\nThree）的核心思想。在这种情况下，编译器假定默认的成员移动操作是不正确的，因此也会禁止生成移动操作。\r\n\r\n三法则是指,\r\n如果你声明了拷贝构造函数、拷贝赋值运算符，或析构函数中的任何一个，你就得同时声明所有三个函数。\r\n\r\n拷贝操作的生成规则\r\n如果用户为一个类声明了移动操作（移动构造函数或移动赋值运算符），编译器会将拷贝操作（拷贝构造函数和拷贝赋值运算符）删除（即\r\ndelete）。\r\n其逻辑是，如果一个类需要自定义的移动逻辑，那么简单的按成员拷贝很可能是不正确的。为了防止意外调用了行为不正确的拷贝函数，编译器选择直接将其删除，而不是简单地不生成。\r\n但是, 为了兼容部分C++98代码,\r\n如果用户声明了析构函数或复制构造函数，编译器仍然会自动生成复制赋值运算符\r\n强制生成函数：= default\r\n如果因为上述规则，某个特种成员函数没有被自动生成（例如，因为声明了析构函数而导致移动操作被抑制），但我们确信编译器生成的默认实现正是所需要的，可以使用\r\n= default 来显式地要求编译器生成默认版本 。\r\nclass Base {public:    virtual ~Base() = default;  // 一旦用户声明了析构函数，移动操作的自动生成就被抑制了     // 因此还需要制编译器生成被抑制的移动操作    Base(Base&amp;&amp;) = default;    Base&amp; operator=(Base&amp;&amp;) = default;    // 为了可移动，最好也把复制操作加上    Base(const Base&amp;) = default;    Base&amp; operator=(const Base&amp;) = default;};\r\n其他规则\r\n默认构造函数仅当类中不包含用户声明的构造函数时才生成。\r\n另外,\r\n一个需要特别注意的规则是：类中的成员函数模板（例如一个接受任意类型的构造函数模板）永远不会抑制编译器生成任何特种成员函数\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款1 ：理解模板型别推导","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE1%20-%20%E7%90%86%E8%A7%A3%E6%A8%A1%E6%9D%BF%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC/","content":"如果一个复杂系统的用户对于该系统的运作方式一无所知，然而却对其提供的服务表示满意，这就充分说明系统设计得好。如果从这样的角度来看，\r\nC++的模板型别推导取得了极大的成功。\r\n模板的型别推导，是现代C++最广泛应用的特性之一 ————\r\nauto的基础。也就是说，如果你对C++98\r\n推导模板型别的运作方式感觉满意，那么你也会自然而然地愉快接受C++11 中推导\r\nauto\r\n型别的运作方式。而坏消息则是，当模板型别推导规则应用于auto语境时，它们不像应用于模板时那么符合直觉。出于这个缘故，了解作为auto\r\n基础的模板型别推导的方方面面就变得相当重要了。\r\n不过在学习类型推导之前, 我们有必要复习一下const的基础用法\r\nconst 的基本用法\r\n最简单的形式是定义一个常量。一旦初始化，它的值就不能再被改变。这个概念很简单，但当\r\nconst 和指针、引用以及模板结合时，情况就变得复杂了。\r\nconst int MAX_SIZE = 100;// MAX_SIZE = 200; // 编译错误！不能修改 const 变量\r\nconst与指针\r\nconst 与指针的结合有两种关键形式，理解它们的区别是核心。我们可以通过\r\nconst 的位置来判断它的作用对象(距离最近的或者左侧的那个)。\r\n\r\n首先是指向常量的指针，也称为“底层 const” (low-level const)。\r\n\r\nconst int* ptr;   // 距离最近的是int, 所以const修饰的是int// 或者 (效果完全相同)int const* ptr;   // 左侧的是int, 所以const修饰的是intint a = 10;int b = 20;const int* ptr = &amp;a;// *ptr = 15; // 编译错误！不能通过 ptr 修改 a 的值ptr = &amp;b;    // 正确。ptr 可以指向另一个地址\r\n含义：你不能通过这个指针 ptr\r\n来修改它所指向的数据。但是，你可以让这个指针 ptr 指向别处。\r\n\r\n常量指针 (Constant Pointer), 也称为“顶层 const” (top-level const)。\r\nint* const ptr = &amp;a; // 必须在声明时初始化; 左侧是int*, 所以const修饰的是int*int a = 10;int b = 20;int* const ptr = &amp;a;*ptr = 15; // 正确！可以通过 ptr 修改 a 的值，现在 a 变成 15// ptr = &amp;b; // 编译错误！不能修改 ptr 指向的地址\r\n\r\n含义：指针 ptr\r\n本身的值（即它存储的地址）是不能被修改的。它必须永远指向初始化时的那个地址。但是，你可以通过它来修改它所指向的数据（前提是数据本身不是\r\nconst）。\r\n此外, 指向常量的常量指针 (Constant Pointer to Constant\r\nData)是上面两种情况的结合。指针 ptr\r\n本身的指向和它指向的数据都不能被修改。 const int* const ptr = &amp;a;\r\nconst 与引用\r\nconst\r\n与引用的关系比较简单，因为引用本身就像一个别名，它不能被“重新绑定”到另一个对象，所以只有类似“指向常量的指针”也就是底层调用这一种情况。\r\nint a = 10;const int&amp; ref = a;  // 距离最近的是int, 所以const修饰的是int// ref = 20; // 编译错误！不能通过 const 引用修改数据a = 30;    // 正确。原始变量可以修改，ref 的值也会跟着变为 30\r\nconst int&amp;\r\n是一个非常重要的编程惯用法。当按引用传递函数参数时，如果函数不需要修改这个参数，强烈建议形参使用\r\nconst 引用。这有两个好处：首先是安全,\r\n防止函数内部意外修改了外部数据。其次还高效：避免了按值传递时创建对象的拷贝开销。同时也具有灵活性,\r\n可以接受临时对象（右值）。\r\n模板型别推导\r\n所谓 C++ 模板参数推导的核心目标是：编译器必须为模板参数（如\r\nT）找到一个（唯一的）类型，使得当这个 T\r\n被替换回函数签名后，形成的形参（Parameter）类型能够合法地接收（绑定）我们传入的实参（Argument）。\r\n模板函数在推导类型 T 时，参数的 const 属性是否被保留，取决于函数参数\r\nparam 的声明方式。下列讨论针对的一般形式如下\r\ntemplate&lt;typename T&gt; void f(ParamType param); f(expr);   // 从 expr 来推导 T 和 ParamType 的型别\r\n情况 1：按值传递 (T param)\r\n首先, 将实参的引用部分忽略.\r\n接着, 当函数参数是按值传递时，实参的 const\r\n属性会被忽略。这是因为按值传递会创建一个新的对象，而新对象的\r\nconst 属性与实参无关。\r\n\r\n若实参是个volatile 对象，同忽略之(volatile\r\n对象不常用，它们一般仅用于实现设备驱动程序)。\r\n\r\ntemplate&lt;typename T&gt;void f(T param) {    // ...}int x = 10;const int cx = x;const int&amp; rx = x;f(x);  // T 被推导为 int, param 的类型是 intf(cx); // T 被推导为 int, param 的类型是 int (cx 的 const 被忽略)f(rx); // T 被推导为 int, param 的类型是 int (rx 的 const 和引用都被忽略)\r\n考虑这种情况： expr是个指涉到 const 对象的 const 指针，且\r\nexpr按值传给 param: template&lt;typename T&gt; void f(T param);  // param 仍按值传递const char* const ptr = \"Fun with pointers\";  // ptr 指涉到 const 对象的 const 指针f(ptr);  // 传递型别为 canst char* canst 的实参 这里，位于星号右侧的 const 将 ptr\r\n声明为 const: ptr 不可以指涉到其他内存位置，也不可将 ptr 置为\r\nnull。而位于星号左侧的 const 则将 ptr 指涉到的对象（那个字符串）为const,\r\n即该字符串不可修改。 可 ptr 被传递给 f\r\n时，这个指针本身将会按比特复制给param。换言之，ptr这个指针自己会被按值传递。依照按值传递形参的型别推导规则，ptr\r\n的const性会被忽略，param 的型别会被推导为 canst\r\nchar*，即一个可修改的、指涉到一个 const 字符串的指针。 即对于上述示例,\r\n在型别推导的过程中，ptr指涉到的对象的常量性会得到保留，但其自身的常量性则会在以复制方式创建新指针param的过程中被忽略。\r\n情况 2：按指针或引用传递 (T&amp;\r\n或 T*)\r\n当函数参数是指针或引用时，引用实参的 const\r\n属性或者指针所指数据的const属性会被保留并成为类型 T\r\n的一部分\r\ntemplate&lt;typename T&gt;void f_ref(T&amp; param) {    // ...}template&lt;typename T&gt;void f_ptr(T* param) {    // ...}int x = 10;const int cx = x;f_ref(x);  // T 被推导为 int, param 的类型是 int&amp;f_ref(cx); // T 被推导为 const int, param 的类型是 const int&amp;const int* px = &amp;x;int* const ppx = &amp;x;f_ptr(&amp;x); // T 被推导为 int, param 的类型是 int*f_ptr(px); // T 被推导为 const int, param 的类型是 const int*f_ptr(ppx); // T 被推导为 int, param 的类型是 int*; 因为传递指针本质也是按指针拷贝(拷贝指针a的值也就是变量的地址到指针b), 而这里的指针具有常量性, 因此在按值拷贝的过程中会失去; 上一个示例的const修饰的不是指针所以在指针的按值拷贝过程中不会失去\r\n在这个过程中，编译器就像在解一个方程. 再例如: // 模板函数定义template&lt;typename T&gt; void f(const T&amp; param); // 一个返回 std::vector 的工厂函数std::vector&lt;Widget&gt; createVec(); // 使用工厂函数返回值初始化 vwconst auto vw = createVec(); if (!vw.empty()) {     // 调用模板函数    f(&amp;vw[0]); } -\r\n函数模板（签名）: template void f(const T&amp; param); -\r\n形参类型 (P): const T&amp; - 实参类型 (A): const Widget*\r\n下面我们求解 T：根据规则, T 获取实参的底层const属性,\r\n同时因为传入指针而形参不存在指针, 编译器自然假设 T = const Widget*。\r\n接着将 T 替换回形参 P ( const T&amp; )后得到形参类型：param\r\n的类型变为 const (const Widget) &amp;, 这也通常被读作 const\r\nWidget const &amp;。(这是一个“对 [指向 const Widget 的 const 指针]\r\n的 const 引用”)\r\n尝试绑定：编译器再次尝试将实参 (A) 绑定到这个新生成的形参 (P)\r\n上：此时实参 (A): const Widget; 形参 (P): const (const Widget)\r\n&amp; (即 const Widget* const &amp;)\r\n因为实参类型 const Widget* 与形参期望引用的核心类型的主体 const\r\nWidget* 完全匹配。没有发生任何丢弃常量性的危险操作;\r\n同时我们的实参（&amp;vw[0] 的结果）是一个临时产生的指针，它是一个右值\r\n(rvalue)。C++ 规定，右值不能绑定到非 const 的左值引用 (non-const lvalue\r\nreference)，但它们可以完美地绑定到 const 的左值引用 (const lvalue\r\nreference)。我们的形参 const (const Widget*) &amp; 正是一个 const\r\n左值引用，因此它可以合法地绑定来自实参的右值。\r\n情况 3：按万能引用传递\r\n(T&amp;&amp; param)\r\n这种情况更为特殊，但规则与情况2类似：const 属性会被保留。\r\ntemplate&lt;typename T&gt;void f_forward(T&amp;&amp; param) {    // ...}int x = 10;const int cx = x;f_forward(x);  // T 被推导为 int&amp;f_forward(cx); // T 被推导为 const int&amp;\r\n详细情况线上略\r\n数组实参和字符指针\r\n以上已经基本讨论完模板型别推导的主流情况，但还有一个边缘情况值得了解。这种情况是：数组型别有别千指针型别，尽管有时它们看起来可以互换。形成这种假象的主要原因是，在很多语境下，数组会退化成指涉到其首元素的指针。\r\n函数实参和函数指针\r\n总之,\r\n在模板型别推导过程中，数组或函数型别的实参会退化成对应的指针，除非它们被用来初始化引用\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款9：优先选用别名声明，而非 typedef","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%8E%B0%E4%BB%A3C++/%E6%9D%A1%E6%AC%BE9%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%E5%88%AB%E5%90%8D%E5%A3%B0%E6%98%8E%EF%BC%8C%E8%80%8C%E9%9D%9E%20typedef/","content":"在 C++ 中，typedef 和 C++11 引入的“别名声明”（Alias\r\nDeclaration）都用于创建类型同义词。例如，以下两行代码在功能上是完全等效的：\r\n// C++98 的做法typedef std::unique_ptr&lt;std::unordered_map&lt;std::string, std::string&gt;&gt; UPtrMapSS; [cite: 723]// C++11 的做法：别名声明using UPtrMapSS = std::unique_ptr&lt;std::unordered_map&lt;std::string, std::string&gt;&gt;; [cite: 726]\r\n尽管两者功能相同，但条款9强烈建议优先选用别名声明（using），主要原因在于它对模板的完美支持以及在模板元编程中的易用性。\r\n易读性(次要)\r\n对于复杂的类型，特别是函数指针，using 的语法通常更直观、更易于阅读。\r\n// Typedef：类型名称（FP）被“包围”在中间，阅读顺序不自然typedef void (*FP)(int, const std::string&amp;); [cite: 728]// 别名声明：语法更像赋值，左侧是新名称，右侧是原类型，逻辑清晰using FP = void (*)(int, const std::string&amp;); [cite: 729]\r\n核心优势：对模板的支持\r\n别名声明最重要且最具压倒性的优势在于它可以被模板化，而 typedef 不能\r\n。通过 using\r\n创建的模板化类型同义词被称为别名模板 (Alias\r\nTemplate)。\r\n如果我们想创建一个自定义分配器的 std::list\r\n的同义词，使用别名模板非常简单： template&lt;typename T&gt;using MyAllocList = std::list&lt;T, MyAlloc&lt;T&gt;&gt;;MyAllocList&lt;Widget&gt; lw; // 而由于 typedef\r\n不能被模板化，为了在 C++98\r\n中实现相同的效果，我们必须使用一个繁琐的变通方法：将 typedef\r\n嵌套在一个模板化的 struct 内部 ： template&lt;typename T&gt;struct MyAllocList {    typedef std::list&lt;T, MyAlloc&lt;T&gt;&gt; type; };\r\n这种方法不仅更复杂，而且客户端代码在使用时也必须通过 ::type\r\n来获取真正的类型，并且常常需要与 typename 关键字配合。 &gt;\r\n当一个类型依赖于模板参数（如 MyAllocList::type 依赖于\r\nT）时，这个类型被称为依赖类型 (dependent type) 。C++\r\n规则要求，对于依赖类型，必须在其前面显式添加 typename\r\n关键字，以告知编译器这个依赖名称是一个类型，而不是一个数据成员或别的什么\r\n。 // 使用 typedef 版本的代码template&lt;typename T&gt;class Widget {private:    // 必须使用 \"typename\" 和 \"::type\"    typename MyAllocList&lt;T&gt;::type list; [cite: 740, 742, 743]};// 使用别名模板版本的代码template&lt;typename T&gt;class Widget {private:    // 代码更简洁，无需 typename 和 ::type    MyAllocList&lt;T&gt; list; [cite: 747]}; 别名模板完美地解决了这个问题。当编译器看到\r\nMyAllocList 时，它知道 MyAllocList 是一个别名模板，因此\r\nMyAllocList\r\n必然是一个类型。它不再是一个“依赖类型”（在C++的定义中），因此不再需要\r\ntypename 关键字，也不需要 ::type 后缀\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款3：理解 decltype","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE3%20-%20%E7%90%86%E8%A7%A3%20decltype/","content":"decltype 是 C++11 引入的一个非常重要的关键字. 作为一个类型说明符\r\n(type specifier), 它是 “declared type” (声明的类型) 的缩写, 也是 C++\r\n泛型编程（模板）和类型推导系统中至关重要的一块拼图。\r\n它的核心功能是：在编译时检查一个表达式，并“返回”该表达式所对应的确切类型，但并不会实际计算（执行）这个表达式。\r\n不过在介绍decltype之前, 我们先介绍一下返回值类型后置语法。\r\n返回值类型后置语法”（Trailing\r\nReturn Type Syntax）\r\n“返回值类型后置语法”（Trailing Return Type Syntax）是 C++11\r\n引入的一种语法，用于定义函数的返回值类型。它的基本形式是在函数参数列表后面使用\r\n-&gt; 符号，后面跟着返回值类型,\r\n而原先返回值类型的位置则使用auto作为占位符。\r\n// 经典语法return_type function_name(parameters);int add(int a, int b);// 后置语法auto function_name(parameters) -&gt; return_type;auto add(int a, int b) -&gt; int;\r\n对于像 int add(int a, int b)\r\n这样的简单函数，新语法看起来更冗长，似乎毫无必要。那么，C++\r\n委员会为什么要引入这种语法呢？\r\n\r\n原因一：解决模板中依赖参数类型的返回类型推导\r\n\r\n这是引入该语法的最主要动机。在 C++11\r\n之前，当我们编写模板函数时，如果返回类型依赖于参数的类型，我们就很难（甚至不可能）正确地声明它。\r\n假设我们要写一个模板函数\r\nadd，它接受两个不同类型的参数，并返回它们相加后的结果类型。例如，add(int,\r\ndouble) 应该返回 double。在 C++11 中，我们可以使用 decltype\r\n来推导表达式的类型。因此我们很自然地会尝试这样写（使用经典语法）：\r\n// C++03/C++11 经典语法的“错误”尝试template&lt;typename T, typename U&gt;decltype(a + b) add(T a, U b); // 编译失败！\r\n但是, 因为在编译器解析到 decltype(a + b)\r\n时，它处于函数声明的最前端。此时，参数 a 和 b\r\n尚未进入作用域（Scope），编译器根本不知道 a 和 b 是什么，因此无法计算 a\r\n+ b 的类型。\r\nC++11\r\n引入的后置语法完美地解决了这个问题。通过将返回类型“拖尾”到参数列表之后，当编译器解析到\r\n-&gt; 后面的 decltype 部分时，参数 a 和 b\r\n已经声明并且位于作用域内了。这样做使得指定返回类型时可以使用函数的形参\r\ntemplate&lt;typename T, typename U&gt;auto add(T a, U b) -&gt; decltype(a + b) // 完全正确！{    return a + b;}\r\n其过程为: 当编译器看到 auto\r\n时，它知道这是一个占位符，真正的返回类型在后面 –&gt; 编译器解析参数列表\r\n(T a, U b)。此时，变量 a 和 b 被声明 –&gt; 编译器解析\r\n-&gt; decltype(a + b)。由于 a 和 b 此时在作用域内，decltype\r\n可以成功推导出 a + b 的结果类型（例如，如果是 int 和 double，则推导出\r\ndouble）–&gt; 这个推导出的类型（double）将替换掉前面的占位符 auto。\r\n\r\n虽然 C++14 引入了更简洁的 auto 返回类型推导（auto add(T a, U b) {\r\nreturn a + b; }），但在 C++11\r\n中，后置语法是解决此问题的唯一标准方法。\r\n\r\n\r\n原因二：提高复杂函数声明的可读性\r\n\r\nC++\r\n的经典函数声明语法（尤其是涉及函数指针或C风格数组指针时）是出了名的难以阅读（通常需要“从里向外”的“螺旋法则”来解析）。例如,\r\n假设你要声明一个函数 foo，它接受一个\r\nint，并返回一个“指向函数的指针”，该指针指向的函数接受 (int, int) 并返回\r\nvoid。\r\n// 经典语法：非常难以阅读和书写void (*foo(int))(int, int);\r\n而使用后置语法，这个声明变得像从左到右阅读的普通句子一样清晰：\r\n// 后置语法：清晰易读auto foo(int) -&gt; void(*)(int, int);\r\n\r\n原因三：与 Lambda 表达式语法保持一致\r\n\r\nC++11 同时引入了 Lambda 表达式。当 Lambda\r\n表达式需要显式指定返回类型时，它们必须使用后置语法（因为 Lambda\r\n没有“函数名”可以在其前面放置类型）。 auto my_lambda = [](int a, int b) -&gt; double {    if (b == 0) return 0.0;    return static_cast&lt;double&gt;(a) / b;};\r\n让普通函数也支持这种语法，使得 C++ 的可调用对象（函数和\r\nLambda）在外观上更加统一和现代化。\r\n为什么需要 decltype？（与\r\nauto 的对比）\r\n在 C++11 中，我们已经有了 auto 关键字用于自动类型推导，但 auto\r\n有一个特性：根据我们前面提到的条款1,\r\n它在不加任何修饰使用时会“衰变”(decay)。这意味着 auto 会丢弃顶层的\r\nconst、volatile 以及引用 (&amp;)。\r\nconst int x = 10;const int&amp; ref_x = x;auto a = x;     // a 的类型是 int (const 被丢弃)auto b = ref_x; // b 的类型是 int (const 和引用 &amp; 都被丢弃，b 成了 x 的一个副本)\r\n但在很多泛型编程场景下，我们不希望类型被“衰变”，我们希望得到变量被声明时的确切类型。\r\n因为 decltype 保留精确类型,\r\n因此它的作用就是获取那个确切的类型，而不会丢弃引用或 const\r\nconst int x = 10;const int&amp; ref_x = x;decltype(x) c = x;     // c 的类型是 const int (保留 const)decltype(ref_x) d = ref_x; // d 的类型是 const int&amp; (保留 const 和引用)                         // d 只是 ref_x 的一个别名，而不是副本。\r\ndecltype 的核心规则\r\n首先, decltype(expr)是一个类型说明符, 就像 int、std::string 一样,\r\n必须出现在声明或类型别名等需要类型的地方。\r\ndecltype\r\n的行为规则非常精确，但也有些微妙。它的行为取决于你给它的是一个“实体名称”还是一个更复杂的“表达式”。\r\n\r\n参数是实体（变量、函数参数等）\r\n\r\n如果传递给 decltype\r\n的是一个没有被括号括起来的变量名、函数参数名或类成员名,\r\ndecltype 返回该实体在声明时的确切类型。 int i = 5;const int ci = 10;const double&amp; rd = 3.14;static int s_var;decltype(i)    type_i;    // 类型是: intdecltype(ci)   type_ci;   // 类型是: const intdecltype(rd)   type_rd = rd; // 类型是: const double&amp;decltype(s_var) type_s;   // 类型是: int (注意：static 不属于类型的一部分)\r\n\r\n参数是表达式（或函数调用）\r\n\r\n如果传递给 decltype\r\n的是除规则1以外的任何东西——比如一个函数调用、一个算术运算，或者被额外括号括起来的变量,\r\n那么 decltype 的结果将取决于该表达式的值类别 (Value Category)。\r\n\r\n如果表达式的结果是一个 prvalue (纯右值)，decltype 返回该值的类型\r\nT。\r\n如果表达式的结果是一个 lvalue (左值)，decltype 返回 T&amp;\r\n(对该类型的左值引用)。\r\n如果表达式的结果是一个 xvalue (消亡值)，decltype 返回 T&amp;&amp;\r\n(对该类型的右值引用)。 int i = 10;int* p = &amp;i;// 1. 纯右值 (prvalue) -&gt; Tdecltype(i + 5) type_add; // i + 5 产生一个临时的 int (纯右值)，所以类型是 int// 2. 左值 (lvalue) -&gt; T&amp;decltype(*p) type_ptr_deref = i; // *p (指针解引用) 是一个左值，类型是 int&amp;                               // (注意：这里 type_ptr_deref 成为了 i 的引用)// 3. 消亡值 (xvalue) -&gt; T&amp;&amp;decltype(std::move(i)) type_move; // std::move(i) 的结果是 int&amp;&amp; (消亡值)，所以类型是 int&amp;&amp;\r\n\r\n关键陷阱：decltype(x) vs\r\ndecltype((x))\r\n这是 decltype\r\n中最著名、也最容易混淆的知识点。它完美地展示了规则1和规则2的区别：\r\n对于 decltype(x)：\r\n\r\nx 是一个实体名称，没有被括号括起来。\r\n它匹配规则 1。\r\n结果是 x 被声明的类型，即 int。\r\n\r\n对于 decltype((x))：\r\n\r\n\r\n不是一个实体名称，它是一个表达式。（在C++标准中，任何用括号括起来的变量都被视为一个表达式）。\r\n\r\n任何具名变量（如 x）的表达式（如 (x)）都是一个左值\r\n(lvalue)。\r\n它匹配规则 2（lvalue 情况）。\r\n结果是 T&amp;，其中 T 是 x 的类型 (int)。因此，结果是\r\nint&amp;。\r\n\r\n这个细微的差别在模板元编程中至关重要，因为它允许我们检测一个表达式是否是左值。\r\ndecltype 的主要应用场景\r\n第一点就是我们上面提到过的泛型编程与返回值类型后置,\r\n即auto add(T a, U b) -&gt; decltype(a + b);. 需要注意的是:\r\na + b 是一个表达式。它产生一个纯右值 (prvalue)。根据规则 2，decltype\r\n返回其结果类型 T（例如 int + double = double）。这个 double 类型被用于\r\n-&gt; 之后的返回类型声明。\r\n第二点是 C++14 的 decltype(auto): decltype 本身是一个类型说明符，而\r\nC++14 更进一步，引入了 decltype(auto) 语法。它告诉编译器：“请使用 auto\r\n占位，但在推导时，请严格应用 decltype 的规则（而不是\r\nauto 的衰变规则）。”\r\n这对于完美转发包装函数的返回值至关重要，它可以精确地保持被调用函数返回的是值、左值引用还是右值引用。\r\n// C++14：这个包装器完美地返回了 func(t) 所返回的一切，包括引用template&lt;typename F, typename... Args&gt;decltype(auto) forwardWrapper(F func, Args&amp;&amp;... args) {    return func(std::forward&lt;Args&gt;(args)...);}int g_var = 10;int&amp; get_g_var() { return g_var; }//...decltype(auto) ref = forwardWrapper(get_g_var); // ref 的类型被正确推导为 int&amp;\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款2：理解 auto 型别推导","url":"/2025/09/13/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE2%20-%20%E7%90%86%E8%A7%A3%20auto%20%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC/","content":"首先我们抛出这一讲的核心思想: auto\r\n类型推导几乎就是模板类型推导,\r\n除了稍后会介绍到的唯一区别之外\r\n两者概念性的转换\r\n这种对应关系可以通过一个概念性的转换来理解。例如,\r\n对于前一讲介绍的函数模板调用：\r\ntemplate&lt;typename T&gt;void f(ParamType param);f(expr); // 编译器利用 expr 推导 T 和 ParamType\r\n一个使用auto声明的变量可以被看作是这个模式的变体，其中auto扮演了模板中的T，而变量的类型修饰符（如const、&amp;等）和T一起则扮演了ParamType\r\n。\r\n例如，以下auto声明： auto x = 27;const auto cx = x;const auto&amp; rx = x;\r\n在概念上，编译器为了推导它们的类型，其行为就如同为每个声明生成了一个模板并用初始化物调用它一样\r\n： // 概念上为推导 x 的类型可以理解为存在以下模板template&lt;typename T&gt;void func_for_x(T param);func_for_x(27); // param 的类型就是 x 的类型// 概念上为推导 cx 的类型template&lt;typename T&gt;void func_for_cx(const T param);func_for_cx(x); // param 的类型就是 cx 的类型// 概念上为推导 rx 的类型template&lt;typename T&gt;void func_for_rx(const T&amp; param);func_for_rx(x); // param 的类型就是 rx 的类型\r\nauto的三种推导情况\r\n因为auto类型推导与模板类型推导机制相同，条款1中划分的三种推导情况也完全适用于auto。\r\n\r\n情况1：类型修饰符是指针或引用（但非万能引用）\r\n\r\n此时推导规则与模板相同，初始化表达式的引用性和const属性会被保留。\r\nconst auto&amp; rx = x; // rx 是一个非万能引用 [cite: 278]\r\n\r\n情况2：类型修饰符是万能引用\r\n\r\n当使用auto&amp;&amp;时，左值和右值初始化物会被区别对待，推导出不同的类型。\r\nauto&amp;&amp; uref1 = x;  // x 是 int 且是左值, uref1 类型为 int&amp; [cite: 279]auto&amp;&amp; uref3 = 27; // 27 是 int 且是右值, uref3 类型为 int&amp;&amp; [cite: 279]\r\n\r\n情况3：类型修饰符既非指针也非引用\r\n\r\n此时推导规则也与模板相同，初始化表达式的引用性、const和volatile属性都会被忽略。\r\nauto x = 27; // 情况3 (x既非指针也非引用) [cite: 276]const auto cx = x; // cx 也属于情况3 [cite: 277]\r\n同样地，数组和函数名在auto类型推导中也会退化成指针，除非auto被声明为引用。\r\nconst char name[] = \"R. N. Briggs\";    // name 的类别是 const char[13]auto arr1 = name; // arr1 的类别是 const char*auto&amp; arr2 = name; // arr2 的类别是 const char (&amp;)[13]void someFunc(int, double); // someFunc 是个函数，类别是 void(int, double)auto func1 = someFunc; // func1 的类别是 void (*)(int, double)auto&amp; func2 = someFunc; // func2 的类别是 void (&amp;)(int, double)\r\n唯一的例外：大括号初始化表达式\r\nauto类型推导和模板类型推导真正的唯一区别在于它们如何处理用大括号括起来的初始化表达式。\r\n正如在条款7中提到的, 在C++11中，有多种语法可以初始化一个int：\r\nint x1 = 27;int x2(27);int x3 = {27};int x4{27};\r\n当把int替换为auto时，前两种写法的行为符合预期，变量被推导为int。然而，后两种使用大括号的写法，会触发一条针对auto的特殊推导规则：当用于auto声明的变量的初始化表达式是用大括号括起时，推导所得的类型就是std::initializer_list\r\n。\r\nauto x1 = 27;   // 类型是 int [cite: 291]auto x2(27);  // 类型是 int [cite: 293]auto x3 = {27}; // 类型是 std::initializer_list&lt;int&gt; [cite: 293]auto x4{27};  // 类型是 std::initializer_list&lt;int&gt; [cite: 294]\r\n这个特殊规则是auto独有的。如果将同样的大括号初始化物传递给一个函数模板，类型推导会失败，代码将无法通过编译;\r\n而auto则可以 auto x = {11, 23, 9}; // x 的类型是 std::initializer_list&lt;int&gt; [cite: 300]template&lt;typename T&gt;void f(T param);f({11, 23, 9}); // 错误！无法为 T 推导出类型 #### 在lambda表达式中的特殊\r\n不过需要注意的是，这条关于大括号的特殊规则仅适用于auto变量声明。在C++14中，当auto被用于推导函数返回值或用于lambda表达式的形参时，它遵循的是模板类型推导的规则，而非auto的特殊规则\r\n。\r\n因此，一个返回大括号初始化表达式的函数将无法通过编译，因为它遵循的是模板类型推导，而模板类型推导无法处理这种情况\r\n。\r\n// C++14auto createInitList() {    return {1, 2, 3}; // 错误！无法为 {1, 2, 3} 完成类型推导 }std:: vector&lt;int&gt; v; auto resetV =     [&amp;v ](const auto&amp; newValue) { v = newValue; } ; // (++14 合法)    resetV({ 1, 2, 3 }) ; // 错误！无法为{ 1, 2, 3} 完成型别推导\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款7：区别使用( )与{ }创建对象","url":"/2025/09/12/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE7%20-%20%E5%8C%BA%E5%88%AB%E4%BD%BF%E7%94%A8(%20)%E4%B8%8E%7B%20%7D%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1/","content":"复习初始化语法\r\n在 C++11 中, 进行对象初始化的语法大致可以分为三类: - 使用小括号, 如\r\nint x(10); - 使用大括号, 如 int x{10}; -\r\n使用等号, 如 int x = 10; 当然,\r\n很多情况下也可以使用一个等号和大括号来初始化对象,\r\n如：int z = { o } ;,\r\n下面的讨论我们将忽略这种”等号加大括号“语法，因为 C++\r\n通常会把它和只有大括号的语法同样处理。\r\n容易引起歧义的是, 使用等号来书写初始化语句往往会让\r\nC++新手误以为这里面会发生一次赋值，但实际上却是没有的。我们要明白,\r\n初始化和赋值这两种行为背后调用的是不同的函数： Widget w1;  // 调用的是默认构造函数Widget W2 = w1;  // 不是赋值而是初始化, 调用的是拷贝构造函数w1 = W2;   // 是赋值, 调用的是拷贝赋值运算符\r\n统一初始化\r\n尽管有了那么多初始化语法，但在 C++98\r\n中却仍然没有办法来表达某些想要进行的初始化。比如，之前是没有办法直接指定\r\nSTL 容器在创建时持有N个特定集合的 值的(比如持有 1 、3 、5)\r\n为了着手解除众多的初始化语法带来的困惑，也为了解决这些语法不能覆盖所有初始化场景的问题，\r\nC++11\r\n引入了统一初始化：单一的、至少从概念上可以用于一切场合的初始化语法。它的基础是大括号形式的初始化\r\n使用大括号来指定容器的初始内容是非常简单的：\r\nstd: :vector&lt;int&gt; v{ 1, 3, 5 }; std: :vector&lt;int&gt; v2 = { 1, 3, 5 };  // 与上述等价\r\n大括号同样可以用来为非静态成员指定默认初始化值，这项能力（在\r\nC++11 中新增）也可以使用 “=” 的初始化语法，却不能使用小括号：\r\nclass Widget { private:     int x{ 0 };     int y = 0;     // int z(0) 不可行!}; \r\n另一方面, 不可复制的对象（如 std::atomic\r\n型别的对象，参见条款 40）可以采用大括号和小括号来进行初始化，却不能使用\r\n“=” 来初始化. std::atomic&lt;int&gt; ai{ 0 };  // 可行std::atomic&lt;int&gt; ai2(0);  // 可行std::atomic&lt;int&gt; ai3 = 0;  // 错误\r\n这么一来，就很容易理解为何大括号初始化被冠以“统一” 之名了。在\r\nC++的各种初始化表达式的写法中，只有大括号适用所有场合。\r\n禁止内建型别之间进行隐式窄化型别转换\r\n大括号初始化有一项新特性，就是它禁止内建型别之间进行隐式窄化型别转换(narrowing\r\nconversion)\r\n。如果大括号内的表达式无法保证能够采用进行初始化的对象来表达，则代码不能通过编译：\r\ndouble x, y, z; int sum{ x + y + z }; // 错误，double 型别之和在大括号内无法窄化转换为 int 表达\r\n而采用小括号和“=“的初始化则不会进行窄化型别转换检查，因为如果那样的话就会破坏太多的遗留代码了：\r\nint sum2( x + y + z) ;  // 没问题（表达式的值被截断为 intint sum3 = x + y + z;   // 同上\r\n最令人苦恼之解析语法\r\n(mostvexing parse) 免疫。\r\n大括号初始化的另一项值得一提的特征是，它对于 C++\r\n的最令人苦恼之解析语法 (mostvexing parse) 免疫。 C++\r\n规定：任何能够解析为声明的都要解析为声明，而这会带来副作用。所谓最令人苦恼之解析语法就是说，程序员本来想要以默认方式构造一个对象，结果却不小心声明了一个函数。这个错误的根本原因在于构造函数调用语法。\r\n当你想以传参方式调用构造函数时，可以这样写：widget w1(10);\r\n但如果你试图用对等语法来调用一个没有形参的 Widget\r\n构造函数的话，那结果却变成了声明了一个函数而非对象：Widget w2 ();\r\n这个语句实际上声名了一个名为 w2 、返回widget对象的函数！\r\n由于函数声明不能使用大括号来指定形参列表，所以使用大括号来完成对象的默认构造没有上面这个问题：widget w3{}; // 调用没有形参的构造函数\r\n大括号的缺陷\r\n关于大括号初始化，也说了不少了。这种语法可以应用的语境最为宽泛，可以阻止隐式窄化型别转换，还对最令人苦恼之解析语法免疫。那么，为什么本章的章名不干脆换成“优先选用大括号初始化语法”之类呢？\r\n大括号初始化的缺陷在于伴随它有时会出现的意外行为,\r\n这种行为源于大括号初始化物、std::initializer_list\r\n以及构造函数重载决议之间的纠结关系。这几者之间的相互作用可以使得代码看起来是要做某一件事，但实际上是在做另一件事。\r\n先认识 std::initializer_list\r\nstd::initializer_list（初始化列表）是一个轻量级的类模板，它的主要目的是让我们可以方便地使用花括号\r\n{} 来初始化对象或向函数传递一组值。它是 C++11 中统一初始化 (Uniform\r\nInitialization) 语法的重要基石。\r\n下面我们介绍它的几个特性: - 轻量级代理 (Lightweight Proxy):\r\nstd::initializer_list\r\n本身不拥有它所表示的元素。它更像一个“代理”或“视图”，内部通常只包含两个成员：一个指向元素序列头部的指针，以及一个表示元素数量的计数器。这些元素本身被编译器存放在一个临时的、只读的数组中。因为\r\nstd::initializer_list\r\n只是“指向”这个临时数组，所以它的创建和拷贝开销非常小。 - 同质性\r\n(Homogeneous): 一个 std::initializer_list 对象中的所有元素都必须是 T\r\n类型，或者可以隐式转换为 T 类型。例如，std::initializer_list\r\n只能持有整数。 - 只读性 (Read-only): 你不能修改通过\r\nstd::initializer_list 访问的元素。它提供的迭代器是 const\r\n迭代器，返回的是对 const T 的引用。这保证了初始化数据源的安全性。\r\n大括号初始化 auto 类型变量\r\n当使用 auto\r\n声明变量时，大括号初始化会导致一个可能出人意料的结果。具体细节可以参考条款2：理解auto型别推导。简单来说，如果用大括号初始化表达式来初始化一个\r\nauto 型别的变量，那么推导出来的型别就会是\r\nstd::initializer_list。但如果使用相同的表达式来初始化一个非 auto\r\n型别的变量，或者用小括号或”=“的方式来初始化 auto 型别的变量，auto\r\n就会推导出你想要的型别\r\n规则：编译器强烈优先选择\r\nstd::initializer_list 构造函数\r\n首先, 在构造函数被调用时, 如果形参中没有任何一个具备 std::\r\ninitializer_list 型别,那么小括号和大括号的意义就没有区别： class Widget { public:     Widget(int i, bool b); // 构造函数的形参中没有任何一个具备 std::initializer_list 型别    Widget(int i, double d); // std::initializer_list 型别}; Widget w1(10, true);  // 调用的是第一个构造函数Widget w2{10, true};  // 调用的还是第一个构造函数Widget w3(10, 0.0);  // 调用的是第二个构造函数Widget w4{10, 0.0};  // 调用的还是第二个构造函数\r\n然而,\r\n当使用大括号初始化语法进行对象构造时，如果类中存在一个或多个构造函数接受\r\nstd::initializer_list\r\n作为参数，编译器会强烈优先选择这些重载版本。这种偏好非常强烈，以至于它会覆盖其他看起来更匹配的构造函数，甚至包括复制和移动构造函数\r\n。\r\n同时, 编译器还会尽一切可能将大括号内的参数转换为\r\nstd::initializer_list 中元素的类型，即使这意味着需要进行类型转换。\r\n#include &lt;initializer_list&gt;class Widget {public:    Widget(int i, double d) { /* ... */ }  // #1    Widget(std::string str) { /* ... */ } // #2    // initializer_list 构造函数，但元素类型会导致窄化    Widget(std::initializer_list&lt;bool&gt; il) { /* ... */ } };int main() {    Widget w0(10, 5.0);  // 小括号正常匹配    Widget w1{\"Hello\"};  // 调用#2    Widget w2{10, 5.0}; // 错误！} 上述示例中, 我们可以看到,\r\n如果大括号初始化语法中,编译器会优先调用 std::initializer_list\r\n构造函数。在此基础上又分为两种情况: - 窄化转换导致编译失败（“否决”行为）\r\n- w2这个场景展示的是，即使存在一个其他方面看起来很匹配的构造函数，但只要\r\nstd::initializer_list\r\n版本的构造函数可以通过窄化转换来匹配，编译器就会优先尝试它，并且假如在此过程中因为窄化转换被禁止而报错，编译器就不会再考虑其他选项而直接编译失败。\r\n- 非窄化转换导致调用普通构造函数 -\r\n这个场景展示的是，当大括号内的参数完全无法被转换(而不是窄化转换失败)为\r\nstd::initializer_list 的元素类型时，编译器会放弃initializer_list\r\n构造函数，回到正常的重载决议流程中，并选择其他匹配的构造函数。\r\n总之，即使存在精确匹配的普通构造函数，只要\r\nstd::initializer_list\r\n版本的构造函数可以通过非窄化转换被调用，编译器就会选择它。不过如果转换是窄化的，则调用会失败，即使其他构造函数可以成功匹配\r\n。\r\n另一个方向是, 即使是平常会执行复制或移动的构造函数也可能被带有 std::\r\ninitializer_list 型别形参的构造函数劫持： class Widget { public:     Widget(int i, bool b);     Widget(int i, doubled);     Widget(std: :initializer_list&lt;long double&gt; il);    operator float() const; // 强制转换成 float 型别}; Widget w1(w4);  // 使用小括号，调用的是拷贝构造函数Widget w2{w4};  // /／ 使用大括号，优先调用的是带有 std::initializer_list 型别形参的构造函数(即使看起来像拷贝构造). 这里w4的返回值被强制转换为float, 随后float又被强制转换为long doubeWidget w3(std::move(w4));  // 同理 Widget w4{std::move(w4)};  // 同理\r\n特殊情况：空大括号\r\n需要注意的是, 上述情况有个例外: 当使用一对空大括号 {}\r\n进行初始化时，如果类同时拥有默认构造函数和 std::initializer_list\r\n构造函数，C++\r\n规定优先调用默认构造函数。空大括号被解释为“没有参数”，而不是“一个空的\r\nstd::initializer_list” 。\r\nWidget w2{}; // 调用默认构造函数 Widget w4({});   // 调用 std::initializer_list 构造函数 Widget w5{{}};  // 同上 \r\n如果你确实想用一个空的列表来调用 std::initializer_list\r\n构造函数，需要将空大括号作为参数显式传递 。\r\n经典案例: std::vector 的初始化\r\n对于我们今天讨论的大括号还是小括号初始化, 直接受到影响的一个类就是\r\nstd::vector\r\nstd::vector 有多个可以重载的构造函数,\r\n其中一个构造函数的形参中没有任何一个具备 std:: initializer_list\r\n型别的构造函数，它允许你指定容器的初始尺寸，以及一个初始化时让所有元素拥有的值;\r\n但它还有个带 std: :initializer_list\r\n型别形参的构造函数，允许你逐个指定容器中的元素 值。\r\n因此, 如果你要创建一个元素为数值型别的 std:: vector(比如\r\nstd::vector),\r\n并传递了两个实参给构造函数的话，你把这两个实参用小括号还是大括号括起来，结果会大相径庭：\r\n// 创建一个包含 10 个元素的 vector，每个元素的值都是 20 std::vector&lt;int&gt; v1(10, 20);// 创建一个包含 2 个元素的 vector，元素值分别为 10 和 20 std::vector&lt;int&gt; v2{10, 20};\r\n在上述示例中, 我们可以看到, v1\r\n使用小括号，调用了指定容器尺寸和初始值的构造函数 。而 v2\r\n使用大括号，由于 std::vector 有一个接受 std::initializer_list\r\n的构造函数，编译器优先选择了这个版本 。\r\n启示\r\n对于类的设计者而言，一个核心结论是，在设计构造函数时必须意识到\r\nstd::initializer_list 带来的影响。\r\n如果在重载的构造函数中，有任何一个接受 std::initializer_list\r\n类型的形参，那么使用大括号初始化的客户端代码将极有可能只会匹配到这个版本的构造函数\r\n。这种行为的优先级非常高，以至于它不仅仅是与其他重载版本竞争，而是可能完全掩盖它们，导致其他构造函数“连露脸的机会都不给”\r\n。\r\n因此，最佳实践是设计类的构造函数时，应确保客户无论使用小括号还是大括号，都不会意外地改变被调用的重载版本。从这个角度看，std::vector\r\n的接口设计常被视为一个反面教材，应当从中吸取教训 。\r\n对于使用类的程序员来说，在创建对象时应该仔细思考是选用小括号\r\n() 还是大括号 {}\r\n初始化。目前并没有一个统一的定论，因为两种方式各有优劣，开发者通常会根据自己的偏好选择一种作为默认风格。\r\n偏好使用大括号 {} 的开发者\r\n看重的是其更广泛的适用场景、能够禁止隐式的窄化类型转换，以及对\r\nC++“最令人苦恼的解析语法”免疫的特性\r\n。他们也承认，在某些特定情况下（例如为 std::vector\r\n指定初始尺寸和元素值），使用小括号是必需的 。\r\n偏好使用小括号 () 的开发者 则倾向于保持与 C++98 语法的传统一致性\r\n。这样做可以避免因 auto 类型推导产生的意外（即推导为\r\nstd::initializer_list），并且不会意外地触发接受 std::initializer_list\r\n的构造函数\r\n。他们同样承认，在某些场景下（例如用一组初始值创建容器），必须使用大括号\r\n。\r\n最终，由于两种风格各有合理的理由，最好的建议是开发者可以根据团队的偏好任选一种，并在此后的代码中保持一致\r\n。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 19 - 使用 std::shared_ptr 管理具备共享所有权的资源","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE19%20-%20%E4%BD%BF%E7%94%A8%20std%20shared_ptr%20%E7%AE%A1%E7%90%86%E5%85%B7%E5%A4%87%E5%85%B1%E4%BA%AB%E6%89%80%E6%9C%89%E6%9D%83%E7%9A%84%E8%B5%84%E6%BA%90/","content":"不同于std::unique_ptr，std::shared_ptr\r\n是一种用于管理共享所有权资源的智能指针。当多个代码块需要共同拥有和管理同一个对象的生命周期，并且希望在该对象的最后一个使用者结束使用时自动销毁它，std::shared_ptr\r\n就是理想的选择。它实现了类似垃圾回收的自动内存管理，但其析构是确定性的。\r\n工作原理：引用计数\r\nstd::shared_ptr 的核心机制是引用计数 (reference\r\ncounting)。而引用计数的关键在于控制块 (Control Block)：每一个由\r\nstd::shared_ptr\r\n管理的资源都有一个与之关联的、在堆上分配的“控制块”。这个控制块中包含一个引用计数值，用来跟踪有多少个\r\nstd::shared_ptr 正指向该资源 。\r\n当一个新的 std::shared_ptr 通过直接构造,\r\n拷贝构造或拷贝赋值指向一个资源时，其引用计数值会递增（原子操作）。当一个\r\nstd::shared_ptr\r\n被析构或被赋值为指向另一个资源时，其原指向资源的引用计数值会递减（原子操作）。\r\n当引用计数值减至 0 时，意味着不再有 std::shared_ptr\r\n指向该资源，最后一个递减计数的 std::shared_ptr 会负责销毁该资源 。\r\n注意, 不能说 std::shared_ptr 的构造函数一定会增加引用计数,\r\n因为从一个已有 std: :shared_ptr\r\n移动构造一个新的std::shared ptr 会将源 std: shared ptr\r\n置空,\r\n结果是不需要进行任何引用计数操作。从这里也可以看出来移动操作要比拷贝操作快不少\r\n性能与内存开销\r\nstd::shared_ptr 并非零开销，其成本主要体现在：\r\n\r\n尺寸：一个 std::shared_ptr 对象的大小是裸指针的两倍\r\n。一个指针用于指向资源，另一个指针用于指向控制块 。\r\n控制块分配：控制块本身需要在堆上动态分配内存。不过，条款21中介绍的\r\nstd::make_shared 可以避免这次额外的分配。\r\n原子操作：引用计数的增减必须是原子操作，因为不同线程可能同时对指向同一资源的\r\nstd::shared_ptr 进行操作。原子操作通常比非原子操作要慢 。\r\n\r\n自定义删除器\r\n与 std::unique_ptr 类似，std::shared_ptr\r\n也支持自定义删除器。但两者之间存在一个关键区别：std::shared_ptr\r\n的删除器类型不是其类型的一部分 。\r\n这意味着不同删除器的 std::shared_ptr\r\n具有完全相同的类型。这使得它们可以被存储在同一个容器中（例如\r\nstd::vector&lt;std::shared_ptr&gt;），提供了比 std::unique_ptr\r\n更高的灵活性 。\r\n另一点不同，是自定义析构器不会改变 std::shared_ptr\r\n的尺寸。无论析构器是怎样的型别，std::shared_ptr\r\n对象的尺寸都相当于裸指针的两倍.\r\n这是因为自定义删除器被存储在堆上的控制块中，而不是\r\nstd::shared_ptr 对象本身内部。更进一步, std::shared_ptr\r\n的第二个指针所指的控制块包含下列许多信息: \r\n一个对象的控制块由创建首个指涉到该对象的 std::shared_ptr\r\n来确定。此外, 控制块的基本规则如下: - std::make_shared（参见条款\r\n21）总是创建一个控制块。std::make_shared\r\n会生成一个用于管理所涉及新对象的控制块，因为在调用\r\nstd::make_shared 的时刻，显然不会有针对该对象的控制块存在。\r\n\r\n从具备专属所有权的指针（即 std::unique_ptr 或 std::auto_ptr\r\n指针）出发构造一个 std::shared_ptr\r\n会创建一个控制块。专属所有权指针不使用控制块，因此对于其所指涉的对象来说，不应存在控制块。作为构造过程的一部分，std::shared_ptr\r\n被指定了其所指涉对象的所有权，因此那个专属所有权的智能指针会被置空。\r\n当 std::shared_ptr\r\n的构造函数使用裸指针作为实参调用时，它会创建一个控制块。这个看起来平平无奇的点会造成一种致命的错误。例如:\r\nauto pw = new Widget; // pw 是一个裸指针// 错误！为同一个裸指针创建了两个控制块std::shared_ptr&lt;Widget&gt; spw1(pw); // 为 *pw 创建一个控制块，引用计数为 1std::shared_ptr&lt;Widget&gt; spw2(pw); // 也为 *pw 创建一个控制块，引用计数为 1 spw1 和 spw2 各自创建了一个独立的控制块。它们都认为自己是\r\n*pw 的唯一所有者群体。当 spw1\r\n被销毁时，它会发现其引用计数变为0，于是它会 delete pw。之后，当 spw2\r\n被销毁时，它也会发现其引用计数变为0，于是它会再次 delete\r\npw。对同一个指针进行两次删除会导致未定义行为。\r\n\r\n因此, 永远不要用同一个裸指针来初始化多个 std::shared_ptr,\r\n而是应该通过复制一个已存在的 std::shared_ptr 来创建新的\r\nstd::shared_ptr，以确保它们共享同一个控制块。\r\nthis 指针问题与\r\nstd::enable_shared_from_this\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"1. 线程管理","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/1.%20%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86/","content":"\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"条款4：掌握查看型别推导结果的方法","url":"/2025/09/14/lang/CPP/Effective%20modern%20C++/%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/%E6%9D%A1%E6%AC%BE4%20-%20%20%E6%8E%8C%E6%8F%A1%E6%9F%A5%E7%9C%8B%E5%9E%8B%E5%88%AB%E6%8E%A8%E5%AF%BC%E7%BB%93%E6%9E%9C%E7%9A%84%E6%96%B9%E6%B3%95/","content":"typeid介绍\r\ntypeid 是一个 C++ 内置的运算符（就像 sizeof 或 decltype 一样）, 是\r\nC++ 运行时类型识别（Runtime Type Information,\r\nRTTI）机制的核心组成部分。它允许你的程序在代码运行时查询一个对象的动态类型（Dynamic\r\nType）, 当然也可以进行静态类型的查询。\r\n\r\nRTTI 并非没有代价（它会给对象增加额外的开销，主要是虚函数表 vtable\r\n中的类型信息指针），因此大多数 C++ 编译器允许你通过选项（如 GCC/Clang 的\r\n-fno-rtti）来禁用它。如果 RTTI 被禁用，typeid\r\n在某些情况下（尤其是多态类型）将无法按预期工作。\r\n\r\n具体来说,\r\n它可以用于获取一个类型或一个表达式的类型信息。它有两种使用形式：\r\n\r\ntypeid(Type)：直接传递一个类型名称,\r\n如std::cout &lt;&lt; (typeid(int).name()) &lt;&lt; std::endl;   // 输出 \"int\"。\r\ntypeid(expression)：传递一个表达式（例如一个变量名）,下面主要考虑这一点\r\n。\r\n\r\n不过, typeid\r\n的真正威力体现在它处理多态（Polymorphic）类型时的能力。一个类如果拥有至少一个\r\nvirtual 函数，它就是多态类型。\r\n\r\n情况一：非多态类型（或静态类型查询）\r\n\r\n当你对一个非多态类型（如\r\nint、struct，或没有虚函数的类），或者对一个指针（ptr）本身（而不是它指向的内容\r\n*ptr），或者对一个类型名称使用 typeid 时，它返回的是静态类型（Static\r\nType）。\r\n静态类型是对象在编译时被声明的类型。这个操作是在编译期完成的。\r\nint x = 10;std::string s = \"hello\";// 这些都是静态类型查询std::cout &lt;&lt; (typeid(int).name()) &lt;&lt; std::endl;   // 输出 \"int\" (或其修饰名)std::cout &lt;&lt; (typeid(x).name()) &lt;&lt; std::endl;     // x 是 int，输出 \"int\"std::cout &lt;&lt; (typeid(s).name()) &lt;&lt; std::endl;     // 输出 \"std::string\" (或其修饰名)\r\n\r\n情况二：多态类型（动态类型查询）\r\n\r\n这是 typeid 最重要的用途。当你将 typeid\r\n应用于一个多态类型的左值表达式（通常是对一个基类指针或引用的解引用）时，它会执行运行时查询，以确定该对象的动态类型（Dynamic\r\nType）。\r\n动态类型是对象在内存中被创建时的“真正”类型，即其派生最深的类型 (most\r\nderived type)。\r\n#include &lt;iostream&gt;#include &lt;typeinfo&gt; // 必须包含此头文件struct Base {    virtual void foo() {} // 关键：必须有虚函数才能成为多态类型    virtual ~Base() {}};struct Derived : public Base {    void foo() override {}};struct OtherDerived : public Base {    void foo() override {}};int main() {    Base b_obj;    Derived d_obj;    Base* ptr_b = new Derived(); // 基类指针，指向派生类对象    // --- 静态类型 vs 动态类型 ---    // 1. ptr_b 本身是一个指针变量，变量类型是 Base* (非多态)    // 静态类型查询：    std::cout &lt;&lt; (typeid(ptr_b).name()) &lt;&lt; std::endl;     // 输出: \"Base *\" (或其修饰名，如 \"P4Base\")    // 2. *ptr_b 是对指针的解引用，这是一个多态类型的左值    // 动态类型查询：    std::cout &lt;&lt; (typeid(*ptr_b).name()) &lt;&lt; std::endl;     // 输出: \"Derived\" (或其修饰名，如 \"7Derived\")    // 尽管 ptr_b 是 Base*，RTTI 发现它实际指向一个 Derived 对象    delete ptr_b;}\r\n在这种情况下, 如果 typeid\r\n运算符被应用于一个指向多态类型的空指针的解引用，它将抛出一个\r\nstd::bad_typeid 异常。 Base* null_b_ptr = nullptr;try {    typeid(*null_b_ptr); // 试图解引用一个多态类型的空指针} catch (const std::bad_typeid&amp; e) {    std::cout &lt;&lt; \"Caught exception: \" &lt;&lt; e.what() &lt;&lt; std::endl;}\r\nstd::type_info 类\r\nstd::type_info：是一个定义在  头文件中的类。前面的 typeid\r\n运算符的返回值就是一个对 std::type_info 对象的常量引用 (const\r\nstd::type_info&amp;), 这个对象中存储了关于特定类型的信息。\r\nC++ 标准保证对于程序中的每一种类型，都只有一个 std::type_info\r\n对象实例与之对应。这使得我们可以安全地使用 == 和 != 来比较它们。\r\nstd::type_info 类的主要成员函数包括：\r\n\r\noperator== 和 operator!=：用于比较两个类型是否相同,\r\n例如typeid(*ptr) == typeid(Derived)。\r\nname()：返回一个 const char*，代表该类型的名称。\r\n\r\n值得注意的是, C++\r\n标准没有规定这个名称的具体格式，它只要求这个名称是唯一的。在实际中，大多数编译器会返回一个“修饰过的名称”（mangled\r\nname）, 有时候并不易读（例如，7MyClass 而不是 MyClass）。\r\n这个函数主要用于调试和日志记录，不应该依赖它返回的字符串内容来进行程序逻辑判断（例如，不要写\r\nif (strcmp(typeid(T).name(), “MyClass”) == 0)）。\r\n\r\n\r\nBoost\r\nBoost 库是一个庞大、高质量、经过同行评审（peer-reviewed）且可移植的\r\nC++ 库集合, 我们可以将其理解为 C++ 标准库的“扩展包”和“试验场”。许多在\r\nBoost 库中经过多年开发、测试和广泛使用的组件，最终被 C++\r\n标准委员会采纳，并成为了 C++ 标准库的一部分, 例如: - 智能指针 (Smart\r\nPointers)： C++11 中的 std::shared_ptr 和 std::weak_ptr 直接源自 Boost\r\n中的 boost::shared_ptr。\r\n\r\n线程库 (Threading)： C++11 的 std::thread, std::mutex\r\n等多线程工具，其设计和 API 大量借鉴了 Boost.Thread 库。\r\n可选值：C++17 的 std::optional 源于 boost::optional。\r\n类型特征 (Type Traits)：C++11 \r\n头文件中的许多工具，最早在 Boost.TypeTraits 中实现。\r\n函数对象包装器：C++11 的 std::function 源于\r\nboost::function。\r\n\r\nBoost.TypeIndex\r\nBoost.TypeIndex 是 Boost\r\n库中的一个具体组件（子库），它提供了一套可移植的、功能更强的运行时类型识别（RTTI）机制，旨在作为\r\nC++ 标准 RTTI（即 typeid 操作符和 std::type_info\r\n类）的替代品或增强版。\r\n为什么需要\r\nTypeIndex？（标准 RTTI 的问题）\r\n要理解 Boost.TypeIndex 的价值，首先必须了解 C++ 标准 typeid\r\n的局限性：\r\n\r\n不可移植的类型名称：C++ 标准只规定 typeid(T).name()\r\n必须返回一个字符串，但没有规定这个字符串的具体内容。在实际中，不同编译器返回的是“重整”（mangled）后的内部名称。例如，对于\r\nstd::vector, GCC/Clang 可能返回类似：St6vectorIiSaIiEE, 而MSVC\r\n可能返回类似：.NSt3__16vectorIiNS_9allocatorIiEEEE.\r\n这种字符串对开发者来说几乎不可读，且在不同平台和编译器之间完全不一致，导致调试和日志记录非常困难。\r\n对 RTTI 开关的依赖：typeid 的功能依赖于编译器开启 RTTI\r\n选项。在许多高性能、游戏开发或嵌入式项目中，开发者会选择关闭\r\nRTTI（例如在 GCC/Clang 上使用 -fno-rtti\r\n标志）来减少二进制文件大小和潜在的虚函数表开销。而一旦 RTTI\r\n被关闭，typeid\r\n对多态类型（带有虚函数的类）的操作将失效（通常会导致编译错误或运行时异常），这使得依赖\r\ntypeid 的代码不具备健壮性。\r\nCVR 限定符的丢失：标准的 typeid 在计算类型时，会自动忽略顶层的\r\nconst（常量）、volatile（易失）和 reference（引用）限定符（统称 CVR\r\n限定符）。例如，typeid(int)、typeid(const int) 和 typeid(const int&amp;)\r\n这三者返回的 std::type_info 对象是完全相同的，它们都代表 int\r\n类型。在某些需要精确类型区分的元编程或泛型编程场景中，这是致命的缺陷。\r\n\r\nBoost.TypeIndex 的解决方案\r\nBoost.TypeIndex 通过引入核心类 boost::typeindex::type_index\r\n来解决上述所有问题：\r\n\r\n可移植的“美化”名称 (Pretty Name)：Boost.TypeIndex 提供了\r\n.pretty_name() 成员函数, 无论在哪个编译器上，也不论 RTTI\r\n是否开启，它都会尽最大努力返回一个人类可读的、统一的类型名称。例如，对于\r\nstd::vector，它将一致地返回字符串 “std::vector&lt;int,\r\nstd::allocator &gt;”\r\n（或类似的清晰形式），而不是混乱的重整名称。\r\n独立于 RTTI 开关：Boost.TypeIndex 具有智能的回退机制. 如果 RTTI\r\n开启：它在内部优先使用 typeid，以获得最高效、最准确的多态类型识别; 如果\r\nRTTI\r\n关闭：它会自动切换到一套基于编译时模板元编程的机制来模拟类型信息（对于非多态类型）。这使得代码无论在哪种编译配置下都能工作。\r\n保留 CVR 限定符：Boost.TypeIndex\r\n提供了两种获取类型信息的方式，以满足不同需求：\r\n\r\nboost::typeindex::type_id()：\r\n\r\n功能说明：这个函数模拟标准 typeid 的行为，返回去除 CVR\r\n限定符后的基础类型。适用于需要“模糊”匹配类型的场景。\r\n\r\nboost::typeindex::type_id_with_cvr()：\r\n\r\n功能说明：这是关键的增强功能。它返回包含 CVR 限定符的精确类型。\r\n\r\n例如：type_id_with_cvr&lt;const int&amp;&gt;() 返回的 type_index\r\n对象的 .pretty_name() 将是 “int const&amp;”，这与\r\ntype_id_with_cvr()（返回\r\n“int”）是截然不同的，从而允许开发者进行精确的类型区分。\r\n\r\n\r\n不同阶段用来查看编译器类型推导结果的技术\r\n了解了上述内容之后,\r\n我们可以总结出三种在软件开发不同阶段(撰写代码阶段、编译阶段和运行时阶段)用来查看编译器类型推导结果的技术。这些方法可以帮助开发者确认模板、auto\r\n或 decltype 推导出的类型是否符合预期。\r\n\r\nIDE 编辑器\r\n\r\n在IDE的代码编辑器中，将鼠标指针悬停在变量、参数或函数上时，编辑器通常会显示该实体的推导类型\r\n。\r\n其局限性在于,\r\n这种方法需要代码基本处于可编译状态，因为IDE依赖内嵌的编译器前端来进行分析\r\n。对于简单的类型（如int）显示良好，但对于复杂的类型，IDE显示的型别信息可能非常冗长且难以阅读，实用性会降低\r\n。\r\n\r\n编译器诊断信息\r\n\r\n我们可以通过故意制造一个编译错误，来迫使编译器在诊断信息中报告出它所推导出的类型\r\n。\r\n一种方式是, 我们声明一个类模板，但不去定义它（例如\r\ntemplate&lt;typename T&gt; class TD;）。\r\n接着尝试使用你想查看的类型来具现这个模板（例如，TD&lt;decltype(x)&gt; xType;）\r\n。\r\n编译器在试图创建 xType 对象时，会因为 TD 是一个不完整类型 (incomplete\r\ntype) 而报错，错误信息中几乎必然会包含 T 被推导出的完整类型（例如\r\n“aggregate ‘TD xType’ has incomplete type”）。\r\n\r\n运行时输出\r\n\r\n一种不太可靠的方法是使用typeid, 例如通过typeid(x).name()\r\n来在运行时打印类型名称。然而,\r\n根据C++标准，std::type_info::name\r\n在处理类型时，会如同函数按值传递形参一样。这意味着它会忽略类型的引用（&amp;）属性，并移除顶层的\r\nconst 和 volatile 修饰符(CVR丢失)。这会导致输出错误的类型，例如，一个\r\nconst Widget* const&amp; 类型可能会被错误地报告为 const\r\nWidget*(详见条款1的情况2部分): // 模板函数定义template&lt;typename T&gt; void f(const T&amp; param); // 一个返回 std::vector 的工厂函数std::vector&lt;Widget&gt; createVec(); // 使用工厂函数返回值初始化 vwconst auto vw = createVec(); if (!vw.empty()) {     // 调用模板函数    f(&amp;vw[0]); }template&lt;typename T&gt; void f(const T&amp; param) {     using std::cout;     cout &lt;&lt; \"T = \" &lt;&lt; typeid(T).name() &lt;&lt; '\\n';       // 显示 T 的类型    cout &lt;&lt; \"param = \" &lt;&lt; typeid(param).name() &lt;&lt; '\\n'; // 显示 param 的类型}\r\n上述结果的输出为:T = class Widget const * param = class Widget const *\r\n而显而易见, 在模板 f 中，形参 param 被声明为 const T&amp;。无论 T\r\n被推导成什么，param 的类型都应该是在 T 的基础上增加了 const 和 &amp;\r\n限定符（或者根据引用折叠规则）。T 和 param（即 const\r\nT&amp;）不可能是同一个类型。\r\n出现这个问题的原因就在于std::type_info::name的腐化性(丢失CVR): C++\r\n标准规定，typeid 在返回 name()\r\n之前，会像函数按值传递（pass-by-value）那样来处理它获取到的类型。\r\n应用到我们的例子：根据原理,\r\n我们推导出了T = const Widget*和param = const (const Widget*) &amp;.\r\n对于 typeid(T), 它分析 const Widget*。这是一个指针类型，不是引用，它的\r\nconst 是底层的（指向\r\nconst），不是顶层的。因此，按值传递规则不会移除任何东西。\r\n但是对于 typeid(param), 它分析 const Widget* const &amp;, 首先 &amp;\r\n被移除，类型变为 const Widget* const (一个指向 const Widget 的 const\r\n指针)。接着因为该类型有一个顶层的 const（即指针本身的常量性）。这个\r\nconst 被移除。结果是和T一样的const Widget* 。\r\n更可靠的方法\r\n(Boost.TypeIndex)：\r\n一个更准确的运行时解决方案是使用 Boost 库的 TypeIndex 。\r\n使用\r\nboost::typeindex::type_id_with_cvr&lt;T&gt;().pretty_name()\r\n可以获取一个包含人类可读的、精确类型表示的字符串。其名称中的 “cvr”\r\n表明它会保留 const、volatile 和引用饰词，从而提供准确的类型信息 。\r\n#include &lt;boost/type_index.hpp&gt; // 引入 Boost.TypeIndex 库#include &lt;iostream&gt;           using std::cout; // 导入 Boost.TypeIndex 的核心函数，用于获取包含 const/volatile/&amp; 的精确类型using boost::typeindex::type_id_with_cvr; template&lt;typename T&gt;void f(const T&amp; param) {     cout &lt;&lt; \"T  = \"          &lt;&lt; type_id_with_cvr&lt;T&gt;().pretty_name()          &lt;&lt; '\\n';     // 2. 显示 param 的类型    // 在这个函数签名中，param 的类型永远是 const T&amp;。    cout &lt;&lt; \"param = \"          &lt;&lt; type_id_with_cvr&lt;decltype(param)&gt;().pretty_name()          &lt;&lt; '\\n'; }int main() {    int x = 10;    const int cx = 20;    const int&amp; rx = x;    cout &lt;&lt; \"--- 调用 f(x) --- (x 是 int)\\n\";    f(x);     cout &lt;&lt; \"\\n--- 调用 f(cx) --- (cx 是 const int)\\n\";    f(cx);    cout &lt;&lt; \"\\n--- 调用 f(rx) --- (rx 是 const int&amp;)\\n\";    f(rx);    cout &lt;&lt; \"\\n--- 调用 f(42) --- (42 是右值)\\n\";    f(42);     return 0;}\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 21 - 优先选用 std::make_unique 和 std::make_shared, 而非直接使用 new","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE21%20-%20%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8%20std%20make_unique%E5%92%8Cstd%20make_shared,%20%E8%80%8C%E9%9D%9E%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%20new/","content":"三大make系列函数\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"6. 无锁并发数据结构设计","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/6.%20%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/","content":"无锁并发数据结构的定义\r\n首先, 在探讨无锁和有锁之前, 我们先回顾一下阻塞 (Blocking) vs. 非阻塞\r\n(Non-blocking)\r\n阻塞 (Blocking)\r\n数据结构/算法：这是我们前面章节（特别是第3、4、6章）主要讨论的方式。它们依赖于阻塞式的同步原语，如：\r\n- 互斥量 (std::mutex)：调用 lock() 可能导致线程被挂起。\r\n- 条件变量 (std::condition_variable)：调用 wait()\r\n会挂起线程。 - 期望 (std::future)：调用 get() 或 wait()\r\n可能挂起线程。\r\n当一个线程因为等待某个条件（如锁被释放、通知到达、结果就绪）而被阻塞时，操作系统通常会完全挂起该线程，剥夺它的CPU时间片，并将其交给其他可运行的线程。只有当等待的条件满足时，操作系统才会将其唤醒并重新调度。\r\n这种方式的优点是CPU资源不会在等待时被浪费。\r\n缺点是线程挂起和唤醒本身有上下文切换开销；可能导致死锁、优先级反转等问题。\r\n非阻塞 (Non-blocking)\r\n数据结构/算法：不使用任何可能导致线程被操作系统长期挂起的阻塞式库函数。线程即使在等待，通常也是在执行指令（例如，在一个循环中检查某个条件）。\r\n例如之前介绍的自旋锁 (Spinlock),\r\n优点是避免了线程挂起和唤醒的开销, 但缺点是如果等待时间较长,\r\n会浪费CPU资源.\r\n非阻塞数据结构\r\n(Non-blocking ≠ Lock-Free)\r\n我们回顾一下之前实现的自旋锁 (Spinlock):\r\nclass spinlock_mutex {  std::atomic_flag flag = ATOMIC_FLAG_INIT;public:  void lock() {    while(flag.test_and_set(std::memory_order_acquire)); // 循环直到成功设置 flag  }  void unlock() {    flag.clear(std::memory_order_release);  }};\r\n显然, 它是非阻塞的. lock()\r\n函数没有调用任何会让操作系统挂起线程的函数。它只是在一个\r\nwhile 循环中不断地执行 test_and_set\r\n原子操作，消耗CPU时间片，直到成功获取锁（test_and_set\r\n返回 false）。\r\n然而，它仍然是一个锁。在任何时刻，只有一个线程能够成功退出\r\nlock() 循环并进入临界区。\r\n如果持有锁的线程被操作系统意外挂起（例如，时间片用完），所有其他正在自旋等待锁的线程将无法取得任何进展，它们只能继续空转，直到持有锁的线程被唤醒并释放锁。这违反了无锁的定义。\r\n因此, 非阻塞数据结构/算法 (Non-blocking Data Structures/Algorithms)\r\n并不等同于无锁数据结构/算法 (Lock-Free Data Structures/Algorithms)。\r\n无锁数据结构 (Lock-Free)\r\n这是比“非阻塞”更强的保证:\r\n如果一个数据结构的操作是无锁的，它保证系统整体（即所有正在操作该数据结构的线程中，至少有一个）总能在有限步骤内完成其操作，而不管其他线程的速度如何，或者是否有线程被挂起。\r\n换句话说,\r\n系统作为一个整体总是在前进，不会因为某个线程被挂起而导致所有线程都卡住。\r\n实现特征：通常严重依赖原子操作，特别是比较并交换\r\n(Compare-and-Swap, CAS)，并且经常包含循环。 &gt; CAS\r\n循环失败的原因必须是因为其他线程修改了数据（即其他线程取得了进展），而不是因为持有锁的线程被挂起。\r\n可能的缺点：线程饥饿 (Starvation).\r\n无锁不保证每个线程都能在有限时间内完成操作。\r\n可能存在一个“运气不好”的线程，它每次尝试 CAS\r\n操作时，都正好被其他线程抢先修改了数据，导致它永远在循环重试，无法完成自己的任务。\r\n无等待数据结构 (Wait-Free)\r\n这是最强的非阻塞保证:\r\n如果一个数据结构的操作是无等待的，它保证每一个线程都能在有限步骤内完成其操作，而不管其他线程的速度如何、是否被挂起、或者是否存在争用。\r\n换句话说：每个线程都有自己取得进展的保证，没有饥饿问题。\r\n实现难度：无等待算法通常比无锁算法复杂得多。它们需要保证即使在最坏的争用情况下，每个线程的操作也能在固定的步数内完成。这往往需要非常精巧的设计，有时甚至在没有争用的情况下也需要执行更多的步骤。\r\n这种算法在实际应用中较少见，因为它们的复杂性和开销通常超过了它们所提供的好处。因此,\r\n本章后续内容将主要关注无锁数据结构/算法的设计与实现。\r\n无锁数据结构的利与弊\r\n(Why pursue Lock-Free?)\r\n优点 (Pros)：\r\n\r\n最大化并发 (Maximize\r\nConcurrency)：理论上，无锁允许线程在大部分时间里并行执行，避免了锁带来的序列化瓶颈。无等待则提供了更强的并发保证。\r\n鲁棒性\r\n(Robustness)：如果一个线程在操作无锁结构的中途崩溃或被杀死，它不会破坏数据结构的整体可用性（只可能丢失该线程正在进行的操作）。其他线程仍然可以继续安全地访问和修改数据结构。这对于高可用系统很重要。（相比之下，持有锁的线程崩溃会导致锁永远无法释放）。\r\n无死锁 (No\r\nDeadlock)：因为没有锁，所以不会发生因锁依赖关系导致的死锁。\r\n\r\n缺点 (Cons)：\r\n\r\n设计极其复杂\r\n(Complexity)：正确实现无锁（尤其是无等待）算法非常困难。需要深刻理解原子操作、内存模型、指令重排以及各种微妙的竞争条件。\r\nABA 问题 (ABA Problem)：CAS\r\n操作可能因为一个值被修改（A-&gt;B）然后又被改回（B-&gt;A）而错误地成功，它完全不知道这种情况的发生，尽管底层数据的状态可能已经完全不同。\r\n性能开销 (Performance Overhead)：\r\n\r\n原子操作本身：原子操作通常比非原子操作慢。\r\n缓存一致性开销 (Cache\r\nPing-Pong)：在高争用下，多个 CPU\r\n核心频繁地通过原子操作修改同一个内存位置（例如，无锁栈的\r\nhead\r\n指针），会导致缓存行在不同核心之间不断失效和同步（“乒乓”），这会成为严重的性能瓶颈，甚至可能比基于锁的实现更慢。\r\n\r\n例如, A 线程修改了 head 指针, 导致 B 线程的缓存行失效, B\r\n线程再次修改 head 指针, 导致 A 线程的缓存行失效, 如此反复.\r\n\r\n活锁\r\n(Livelock)：在无锁（非无等待）算法中，多个线程可能陷入不断重试但都无法成功的状态，互相干扰，导致虽然\r\nCPU\r\n在忙碌但系统整体没有进展。（类似两个人过独木桥，互相谦让但都过不去）。活锁通常是暂时的，取决于线程调度，但会影响性能。\r\n\r\n内存管理困难 (Memory\r\nManagement)：如何安全地回收（删除）无锁结构中的节点是一个巨大的挑战，因为你无法确定何时没有其他线程再持有指向该节点的指针。\r\n\r\n结论：无锁设计并非总是更好。它是一种权衡。只有在锁成为明显瓶颈，并且你有能力正确、高效地实现并充分测试无锁算法时，才值得考虑。在许多情况下，精心设计的基于锁的方案（如第6章的细粒度锁）可能已经足够好，甚至性能更优。性能测量\r\n(Profiling) 是做出最终决定的关键。\r\n无锁数据结构示例\r\n在本节中，我们将通过几个经典的无锁数据结构示例，来说明无锁设计的基本思路和实现方法。这些示例将涵盖无锁栈、无锁队列等常见数据结构。\r\n无锁栈 (Lock-Free Stack)\r\n这一节的目标是展示如何使用第5章介绍的原子操作（特别是\r\ncompare_exchange_weak）来构建一个无锁的线程安全栈。这个过程将揭示无锁设计的核心思想以及它所带来的主要挑战之一——内存管理。\r\n基本思路：链表与原子头指针 -\r\n数据结构：和许多栈实现一样，我们选择单向链表作为底层结构。栈顶元素位于链表的头部。\r\n- 核心指针：只需要一个指向链表头节点的指针 head。 -\r\n原子性要求：因为多个线程可能同时尝试修改 head（push 新节点或 pop\r\n移除节点），所以 head\r\n指针必须是原子的：std::atomic&lt;node*&gt; head;\r\n无锁 push 操作\r\npush\r\n操作的目标是将一个新节点原子性地添加到链表的头部。单线程步骤回顾：\r\n\r\n创建新节点 new_node。\r\nnew_node-&gt;next = head;\r\nhead = new_node;\r\n\r\n并发挑战：步骤 2 和 3 之间存在竞争。如果线程 A 读取了 head\r\n(H1)，然后线程 B 快速完成了 push (将 head 改为 H2)，接着线程 A 执行步骤\r\n3 将 head 设为 new_node_A（其 next 仍然指向 H1），那么线程 B 的 push\r\n操作就丢失了！(此时的新head是 new_node_A, 而不是 new_node_B) &gt;\r\n本质上还是读-改-写的竞争。\r\n无锁解决方案 (CAS)：使用 compare_exchange_weak\r\n原子地执行步骤 2 和 3。 template&lt;typename T&gt;class lock_free_stack{private:  struct node  {    T data;    node* next;    node(T const&amp; data_): // 1. 构造函数直接存数据     data(data_) // (这里假设 T 的拷贝构造是安全的)    {}  };  std::atomic&lt;node*&gt; head; // 原子头指针public:  void push(T const&amp; data)  {    // 2. 创建新节点 (注意：这里在锁外完成耗时操作)    node* const new_node = new node(data);     // 3. 读取当前的 head，并设置 new_node 的 next    //    这里的 load 可以是 relaxed，因为 CAS 会重新检查    new_node-&gt;next = head.load();     // 4. 关键：CAS 循环    //    尝试原子地将 head 从 \"new_node-&gt;next\"(期望值) 更新为 \"new_node\"(新值)    while(!head.compare_exchange_weak(new_node-&gt;next, new_node));   }  // ... pop() 待实现 ...}; - 节点构造：新节点 new_node\r\n在进入原子操作循环之前就完全构造好了，包括其数据\r\ndata。这一点至关重要：一旦 head 指向 new_node，它就可能被其他线程\r\npop，所以它必须是“完整的”。 - 设置 next：读取当前的 head\r\n指针，并将其设置为新节点的 next 指针。 - CAS\r\n循环：head.compare_exchange_weak(expected, desired)\r\n是核心。 - expected: new_node-&gt;next (即上一步读取到的 head 值)。 -\r\ndesired: new_node (我们想要设置的新 head)。 - 原子操作： - 如果 head\r\n的当前值 仍然等于 expected（意味着从上一步读取后没有其他线程修改过\r\nhead），那么就将 head 更新为 desired\r\n(new_node)，操作成功，compare_exchange_weak 返回 true，while 循环结束。\r\n- 如果 head 的当前值 不等于\r\nexpected（意味着在上一步读取后，有其他线程已经修改了\r\nhead，比如另一个 push 或\r\npop），那么操作失败，compare_exchange_weak 返回\r\nfalse。并且，compare_exchange_weak 会自动将 expected\r\n(即 new_node-&gt;next) 更新为 head 当前的值。\r\n\r\n循环重试：当 CAS 失败时，new_node-&gt;next 已经被自动更新为最新的\r\nhead 值，while 循环条件为 true，因此会再次尝试\r\ncompare_exchange_weak，使用更新后的 expected\r\n值。这个循环会一直进行，直到 CAS 成功为止。\r\n\r\n\r\n为何使用 weak? 因为操作已经在 while 循环中，即使\r\ncompare_exchange_weak 发生“伪失败”（即值匹配但仍然返回\r\nfalse），循环也会自动重试，不会影响正确性。在某些平台上，weak\r\n在循环中可能比 strong 更高效。\r\n\r\n无锁 pop 操作\r\npop 操作的目标是原子性地移除并返回头节点的数据。单线程步骤回顾：\r\n\r\nold_head = head;\r\nhead = old_head-&gt;next;\r\nresult = old_head-&gt;data;\r\ndelete old_head;\r\nreturn result;\r\n\r\n并发挑战：\r\n\r\nUse-After-Free：如果线程 A 和 B 同时读取 head (H1)，然后 A 成功将\r\nhead 更新为 H1-&gt;next 并 delete H1，此时 B 仍然持有指向 H1\r\n的指针，如果 B 尝试访问 H1-&gt;next，就会访问已删除内存（未定义行为）。\r\n\r\n例如B先读取head为H1, 然后被操作系统挂起\r\n(这是操作系统调度层面的, 无法避免); A完成pop并delete H1;\r\nB恢复后尝试访问H1-&gt;next, 导致错误.\r\n\r\nDouble Pop：如果未使用原子操作，两个线程可能都认为自己成功 pop\r\n了同一个节点。\r\n\r\n无锁解决方案 (CAS + 暂时忽略删除)：使用 CAS 来原子地更新\r\nhead，确保只有一个线程能成功“声明”对头节点的所有权。暂时不处理删除节点的问题（即故意造成内存泄露），以避免\r\nUse-After-Free。\r\ntemplate&lt;typename T&gt;class lock_free_stack{private:  struct node  {    std::shared_ptr&lt;T&gt; data; // 1. 使用 shared_ptr 管理数据 (为了异常安全和方便返回)    node* next;    node(T const&amp; data_):      data(std::make_shared&lt;T&gt;(data_)) // 2. 在 push 时就创建 shared_ptr    {}  };  std::atomic&lt;node*&gt; head;public:  void push(T const&amp; data) { /* ... 如上 ... */ }  std::shared_ptr&lt;T&gt; pop()  {    node* old_head = head.load();    // 3. 循环直到成功将 head 从 old_head 更新为 old_head-&gt;next    //    必须检查 old_head 是否为 null (空栈)    while(old_head &amp;&amp;           !head.compare_exchange_weak(old_head, old_head-&gt;next));    // 4. 如果 old_head 非空 (pop 成功)，返回其数据；否则返回空 shared_ptr    return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();         // !!! 警告：这里没有 delete old_head，存在内存泄露 !!!  }};\r\n\r\nshared_ptr 数据 (①, ②)：为了解决第3章讨论过的 pop\r\n返回值时的异常安全问题，我们在 push 时就将数据存储在 shared_ptr\r\n中。这样 pop 操作只需要返回（或\r\nswap）shared_ptr，这个操作本身是安全的，不会因为拷贝 T\r\n而抛异常导致数据丢失。\r\nCAS 循环：\r\n\r\nold_head = head.load() 读取当前头。\r\nwhile 循环条件首先检查 old_head 是否为\r\nnullptr（空栈）。如果是，循环不会执行，函数直接返回空\r\nshared_ptr。如果非空，尝试\r\ncompare_exchange_weak(old_head, old_head-&gt;next)。\r\n\r\n成功：head 被原子地更新为下一个节点，compare_exchange_weak 返回\r\ntrue，使 while 条件为 false，循环终止。当前线程成功“拥有”了\r\nold_head。\r\n失败：意味着 head 在 load 后被其他线程修改了。CAS 会将 old_head\r\n更新为当前的 head 值。循环继续，用新的 old_head 重试。\r\n\r\n\r\n返回数据：如果 old_head 不是 nullptr（意味着 CAS\r\n最终成功了或者一开始栈就不空），就返回存储在 old_head 中的\r\nshared_ptr。\r\n\r\n内存泄露：最关键的问题是，成功弹出的 old_head\r\n节点从未被 delete！我们暂时牺牲了内存来换取避免 Use-After-Free\r\n导致的未定义行为。\r\n安全性分析与总结\r\n在异常安全方面： - push：new node(data) 可能抛异常（内存分配或\r\nmake_shared），但此时栈未被修改，安全。\r\n\r\npop：主要操作是原子操作和 shared_ptr\r\n操作，通常不抛异常。空栈情况已处理。安全。\r\n数据竞争：head 指针通过原子操作和 CAS 保护，没有数据竞争。对\r\nnode-&gt;data 的访问通过返回 shared_ptr 保证安全。对 node-&gt;next\r\n的访问发生在 CAS 成功“拥有”节点之后（暂时安全，因为没\r\ndelete）。暂时没有数据竞争（但有内存泄露）。\r\n死锁：没有使用锁，无死锁。\r\n\r\n在并发进展方面：push 和 pop 都使用了 while 循环 + CAS。\r\n这是无锁 (Lock-Free) 的：如果多个线程竞争，CAS\r\n保证了至少有一个线程的操作会成功（修改了\r\nhead），从而使系统整体取得进展。\r\n但它不是无等待 (Wait-Free) 的：一个线程可能运气不好，每次 CAS\r\n都失败，导致饥饿 (Starvation)。\r\n总之, 本节成功地使用原子 head 指针和 CAS\r\n循环实现了无锁的 push 和 pop 操作，解决了 head\r\n指针上的竞争问题，并保证了基本的线程安全（在忽略内存泄露的前提下）。\r\n然而，内存泄露是不可接受的。pop\r\n操作无法安全删除节点的问题，是无锁数据结构设计中面临的核心挑战之一。如何安全地回收这些节点，同时避免\r\nUse-After-Free，将是后续小节要解决的关键问题，涉及更复杂的内存管理技术（如基于计数的回收、风险指针、引用计数）。\r\n停止内存泄露：使用无锁数据结构管理内存\r\n在上一节中，我们实现了一个无锁栈，但留下了一个严重的内存泄露问题：pop\r\n操作只是将节点从链表中移除，但从未 delete\r\n它。这样做是为了避免使用后释放(Use-After-Free)\r\n的未定义行为——即一个线程删除了节点 N，而另一个线程仍然持有指向 N\r\n的指针并试图访问 N-&gt;next。\r\n本节的目标就是解决这个内存泄露问题，探讨如何在无锁环境中安全地回收不再使用的节点内存。\r\n核心问题：何时可以安全删除\r\n根源：pop 操作的核心在于 compare_exchange_weak(old_head,\r\nold_head-&gt;next) 循环。在这个循环中，线程会先 load 一个 head 指针\r\n(old_head)，然后在尝试 CAS 之前，可能会需要读取 old_head-&gt;next。\r\n危险：如果在线程 T1 读取了 old_head (指向节点 N) 之后、读取\r\nold_head-&gt;next 之前，另一个线程 T2 成功地 pop 了节点 N 并将其\r\ndelete，那么 T1 对 old_head-&gt;next 的访问就是 Use-After-Free。\r\n安全删除条件：一个节点 N\r\n只有在确定没有任何线程（无论是正在 pop\r\n循环中，还是将来可能访问它）会再持有指向它并试图解引用的指针时，才能被安全地\r\ndelete。\r\n一个草率的尝试:\r\n基于全局计数的回收\r\n这是一种尝试性的、简单但有缺陷的解决方案。\r\n核心思想：用一个原子计数器 threads_in_pop\r\n来追踪当前有多少个线程正在执行 pop 函数。\r\n当一个线程成功 pop 出一个节点 old_head 后，它暂时不删除该节点。\r\n它检查 threads_in_pop 的值。如果只有它自己在 pop (threads_in_pop ==\r\n1)，那么似乎可以安全删除。\r\n如果还有其他线程在 pop（它们可能仍持有指向 old_head\r\n或其他待删除节点的指针），则将 old_head\r\n添加到一个全局的“待删除”链表 (to_be_deleted)\r\n中，推迟删除。\r\n当一个线程发现自己是最后一个离开 pop 函数的线程时（即它将\r\nthreads_in_pop 减为 0），它负责清空并删除整个“待删除”链表。\r\ntemplate&lt;typename T&gt;class lock_free_stack{private:  // ... node 结构体和 head 原子指针同上 ...  std::atomic&lt;unsigned&gt; threads_in_pop;  //  原子变量计数器, 是全局的  std::atomic&lt;node*&gt; to_be_deleted;  // 待删除链表头指针  static void delete_nodes(node* nodes)  {    while(nodes)  // 删除整个链表    {      node* next = nodes-&gt;next;  // 先保存下一个节点      delete nodes;  // 删除当前节点      nodes = next;  // 继续下一个节点    }  }  void try_reclaim(node* old_head) // 尝试回收节点内存  {    if(threads_in_pop==1)  // 如果只有当前线程在 pop    {      node* nodes_to_delete = to_be_deleted.exchange(nullptr);  // 取走全局待删除链表      if(!--threads_in_pop)  // 再次检查是否只有一个线程调用pop()      {        delete_nodes(nodes_to_delete);  // 删除待删除链表        }      else if(nodes_to_delete)  // 在此期间有其他线程在 pop, 这些新线程可能已经看到了 nodes_to_delete 中的某些节点, 删除它们不安全, 因此需要再将取走的节点放回待删除链表      {         chain_pending_nodes(nodes_to_delete);  // 放回待删除链表      }      delete old_head;  // 删除自己刚刚 pop 出来的节点。注意这里仍然是安全的，因为只有本线程成功通过 CAS 获取了它。    }    else  // 多个线程在 pop    {      chain_pending_node(old_head);  // 把 old_head 加入待删除链表 8      --threads_in_pop;    }  }  void chain_pending_nodes(node* nodes)  // 将多个节点加入待删除链表  {    node* last = nodes;    while (node* const next = last-&gt;next)  // 让next指针指向链表的末尾    {      last = next;    }    chain_pending_nodes(nodes, last);  // 此时的last是链表的最后一个节点  }  void chain_pending_nodes(node* first,node* last)  // 将[first,last]区间的节点加入待删除链表  {    last-&gt;next = to_be_deleted;  // 将待删除链表接在last后面    while(!to_be_deleted.compare_exchange_weak(  // 用循环来保证last-&gt;next的正确性      last-&gt;next,first));  }  void chain_pending_node(node* n)  // 将单个节点加入待删除链表  {    chain_pending_nodes(n,n);  // 调用上面的函数, 传入相同的节点作为first和last  }public:  std::shared_ptr&lt;T&gt; pop()  {    ++threads_in_pop;  // 2 在做事之前，计数值加1    node* old_head=head.load();    while(old_head &amp;&amp;      !head.compare_exchange_weak(old_head,old_head-&gt;next));    std::shared_ptr&lt;T&gt; res;    if(old_head)    {       res.swap(old_head-&gt;data);  // 从节点中直接提取数据，而非拷贝指针    }    try_reclaim(old_head);      return res;  }};\r\n该方案的致命缺陷：高争用下的内存泄露\r\n这个方案依赖于存在一个“静止” (quiescent) 状态，即\r\nthreads_in_pop 能够降到 1 或 0 的时刻。\r\n然而, 在一个繁忙的高争用系统中，可能永远都有多个线程在同时执行 pop\r\n操作。threads_in_pop 可能永远不会降到 1 以下。\r\n后果是：try_reclaim 函数中的检查 1 (threads_in_pop == 1) 永远为\r\nfalse。所有被 pop 的节点都会被不断地添加到 to_be_deleted 链表，但检查 2\r\n(!–threads_in_pop) 永远不会满足，因此\r\ndelete_nodes永远不会被调用。to_be_deleted\r\n链表无限增长，导致严重的内存泄露。\r\n因此,\r\n基于全局线程计数的内存回收方案虽然想法简单，但在实际的高并发（高争用）场景下是不可靠的，会因无法找到安全的回收时机而导致内存泄露。\r\n这表明我们需要更健壮的内存管理技术，这些技术不依赖于全局的“静止”状态，而是能够精确地追踪哪些节点确实不再被任何线程引用。\r\n这直接引出了后续两种更高级（也更复杂）的解决方案：\r\n\r\n风险指针 (Hazard\r\nPointers)：线程显式地“声明”它们正在使用的指针。\r\n引用计数 (Reference\r\nCounting)：为每个节点维护引用计数。\r\n\r\n解决方案 1：风险指针 (Hazard\r\nPointers)\r\n之所以存在内存泄漏,\r\n根本问题在于，一个线程（回收者）无法知道是否有其他线程（读取者）仍然持有指向它想要\r\ndelete 的节点的指针，并且可能在稍后解引用该指针。\r\n风险指针的思路：反转责任。不再让回收者猜测，而是要求读取者在即将访问一个可能被回收的指针之前，先显式地声明：“我现在正在使用这个指针\r\nP，请暂时不要删除它！”。这个声明就是“风险指针”。\r\n具体机制为:\r\n\r\n风险指针列表：存在一个全局可见的列表（通常是固定大小的数组），其中每个活跃的读取线程都“拥有”一个或多个风险指针槽位\r\n(Hazard Pointer Slots)。每个槽位可以存储一个\r\nvoid*（或原子化的\r\nstd::atomic&lt;void*&gt;）。(在后续的示例代码中，我们假设每个线程只有一个风险指针槽位)。\r\n\r\n虽然这里是void*，但实际存储的通常是指向数据结构节点（如\r\nstack::node）的指针。\r\n\r\n读取者设置风险指针：当一个读取线程（例如在 pop\r\n中）从共享结构（如 head 指针）读取了一个节点指针\r\nptr，并且在解引用它（例如访问 ptr-&gt;next）之前，它必须将 ptr\r\n的值写入它自己的风险指针槽位。\r\n读取者清除风险指针：当读取线程不再需要访问 ptr\r\n时（例如，它成功地将 head CAS\r\n到了下一个节点，或者它决定放弃当前操作），它必须将自己的风险指针槽位清除（例如，设置为\r\nnullptr）。\r\n回收者检查风险指针：当一个线程（回收者）成功地将一个节点\r\nN 从数据结构中移除（例如 pop 成功）并想要 delete N\r\n时，它不能立即删除。它必须遍历所有线程的所有风险指针槽位。\r\n\r\n如果节点 N\r\n的地址出现在任何一个风险指针槽位中，说明有其他线程正在（或即将）使用它。回收者不能删除\r\nN，必须将其放入一个“待回收”列表 (reclaim_later)。\r\n如果节点 N\r\n的地址没有出现在任何风险指针槽位中，说明此刻没有线程声明正在使用它，回收者可以安全地\r\ndelete N。\r\n\r\n处理“待回收”列表：回收者需要定期地（或者在每次\r\npop 成功后）尝试处理“待回收”列表。对于列表中的每个节点，它再次执行步骤 4\r\n和 5（检查所有风险指针）。如果检查通过，就将其从列表中移除并\r\ndelete。\r\n\r\n下面是使用风险指针技术实现的 pop 函数。 template&lt;typename T&gt; // 假设在 lock_free_stack 类中class lock_free_stack {  // ... node, head ...    // 假设这些辅助函数已存在:  std::atomic&lt;void*&gt;&amp; get_hazard_pointer_for_current_thread();  // 获取当前线程的风险指针槽位引用  bool outstanding_hazard_pointers_for(node* p);  // 检查是否有任何线程的风险指针指向节点 p  void reclaim_later(node* p);  // 将节点 p 添加到待回收列表  void delete_nodes_with_no_hazards();  // 处理待回收列表，删除没有风险指针指向的节点public:  std::shared_ptr&lt;T&gt; pop() {    // 先获取当前线程自己的风险指针槽位的引用    std::atomic&lt;void*&gt;&amp; hp = get_hazard_pointer_for_current_thread(); // 风险指针槽位    node* old_head = head.load(); // 初始读取 head        // 外层循环：处理 CAS 失败重试    do {      node* temp;      // 1. 内层循环：安全地设置风险指针      do {        temp = old_head; // 保存读取到的 head        hp.store(old_head); // 设置风险指针！        old_head = head.load(); // 重新读取 head      } while (old_head != temp); // 如果 head 在设置 HP 期间改变了，重试内层循环      // 到这里，HP 已安全设置为 old_head (head 在期间未变)      // 现在可以尝试 CAS 更新 head    } while (old_head &amp;&amp; // 检查 old_head 非空 (处理空栈)             !head.compare_exchange_strong(old_head, old_head-&gt;next)); // CAS 操作    hp.store(nullptr); // 2. CAS 成功或栈空，清除风险指针    std::shared_ptr&lt;T&gt; res;    if (old_head) { // 如果成功 pop 了一个节点      res.swap(old_head-&gt;data); // 移出数据      // 3. 检查是否有其他线程的 HP 指向 old_head      if (outstanding_hazard_pointers_for(old_head)) {        reclaim_later(old_head); // 4. 如果有，推迟删除      } else {        delete old_head; // 5. 如果没有，立即删除      }      delete_nodes_with_no_hazards(); // 6. 尝试清理待回收列表    }    return res;  }}; - 内层循环\r\n(标记 ①)：这是关键的安全保障。从 head.load() 读取 old_head 到\r\nhp.store(old_head) 之间存在时间窗口。如果在此期间 head 被改变（其他线程\r\npop 了 old_head 并可能删除了它），那么 hp.store\r\n就会设置一个指向无效内存的风险指针。 - 解决方案：在设置 HP\r\n后立即重新读取 head，并与设置 HP 前读取的值 (temp)\r\n进行比较。如果两者不同，说明 head 在此期间被修改了，设置的 HP\r\n可能无效，必须重试内层循环，直到成功设置 HP 且 head\r\n在此期间保持不变。\r\n\r\n外层循环：这是标准的 CAS 循环，用于原子地更新 head 指针。如果 CAS\r\n失败（compare_exchange_strong 返回 false），它会自动将 old_head\r\n更新为当前 head\r\n的值，然后外层循环会继续，重新执行内层循环以安全地设置新的风险指针。\r\n清除 HP (标记 ②)：一旦 CAS 成功（当前线程“拥有”了\r\nold_head）或者发现栈为空 (old_head 为 nullptr)，就不再需要保护对\r\nold_head 的访问了，必须清除风险指针，允许其他线程回收它（如果是其他线程\r\npop 的）。\r\n回收决策 (标记 ③, ④, ⑤)：在成功 pop 后，调用\r\noutstanding_hazard_pointers_for 检查所有其他线程的\r\nHP。根据结果决定是立即 delete 还是调用 reclaim_later。\r\n清理 (标记 ⑥)：调用 delete_nodes_with_no_hazards\r\n尝试清理全局的“待回收”列表。\r\n\r\n辅助函数\r\nget_hazard_pointer_for_current_thread() (获取当前线程的风险指针槽位):\r\n这个函数的目标是为调用它的线程分配并返回一个专属的风险指针槽位（类型为\r\nstd::atomic&lt;void*&gt;&amp;），该线程可以用这个槽位来声明它正在使用的指针。实现的关键在于线程本地存储\r\n(thread_local) 和槽位分配。 // 全局风险指针数组 (固定大小)unsigned const max_hazard_pointers = 100;struct hazard_pointer {  std::atomic&lt;std::thread::id&gt; id;    // 槽位所有者的线程ID  std::atomic&lt;void*&gt; pointer; // 存储的风险指针};hazard_pointer hazard_pointers[max_hazard_pointers]; // 全局数组, 存储所有线程的风险指针槽位// RAII 类，用于管理线程对 HP 槽位的所有权class hp_owner {  hazard_pointer* hp; // 指向该线程拥有的槽位public:  hp_owner(hp_owner const&amp;) = delete;  hp_owner operator=(hp_owner const&amp;) = delete;  hp_owner() : hp(nullptr) {    // 构造时：遍历全局数组，尝试获取一个空闲槽位    for (unsigned i = 0; i &lt; max_hazard_pointers; ++i) {      std::thread::id old_id; // 期望 ID 是空的 (默认构造)      // 6. 原子地尝试将槽位 i 的 id 从空改为当前线程 id      if (hazard_pointers[i].id.compare_exchange_strong(            old_id, std::this_thread::get_id()))      {        hp = &amp;hazard_pointers[i]; // 获取成功，保存槽位指针        break; // 7. 停止搜索      }    }    // 1. 如果找不到空闲槽位，抛异常 (资源耗尽)    if (!hp) {      throw std::runtime_error(\"No hazard pointers available\");    }  }  // 返回该线程拥有的风险指针槽位的引用  std::atomic&lt;void*&gt;&amp; get_pointer() {    return hp-&gt;pointer;  }  // 2. 析构时：释放槽位所有权  ~hp_owner() {    hp-&gt;pointer.store(nullptr); // 8. 清空指针    hp-&gt;id.store(std::thread::id()); // 9. 清空所有者 ID  }};// 3. 获取风险指针的接口函数std::atomic&lt;void*&gt;&amp; get_hazard_pointer_for_current_thread() {  // 4. 每个线程第一次调用时会创建一个 hp_owner 实例  thread_local static hp_owner hazard;  // 5. 返回该线程专属的风险指针槽位  return hazard.get_pointer();} - thread_local static hp_owner\r\nhazard (④): 这是核心。thread_local 确保每个线程都有自己独立的 hazard\r\n对象。static 确保它只被构造一次（在该线程首次调用此函数时）。\r\n\r\nhp_owner 构造函数 (⑥, ⑦, ①): 当线程首次调用\r\nget_hazard_pointer_for_current_thread() 时，hazard\r\n对象被构造。构造函数会遍历全局 hazard_pointers 数组，使用\r\ncompare_exchange_strong 原子地尝试“认领”一个 id\r\n为空的槽位。一旦成功，它就保存指向该槽位的指针 hp\r\n并退出。如果遍历完都找不到空槽位（说明活跃线程数超过了\r\nmax_hazard_pointers），则抛出异常。\r\nhp_owner 析构函数 (②, ⑧, ⑨): 当线程退出时，其 thread_local 的\r\nhazard 对象会被析构。析构函数负责将风险指针清空 (⑧)，并将槽位的 id\r\n设回空 (⑨)，以便其他新线程可以复用这个槽位。\r\n返回值 (⑤): 函数最终返回\r\nhazard.get_pointer()，这是对该线程已成功认领的那个\r\nstd::atomic&lt;void*&gt; 槽位的引用。\r\n\r\noutstanding_hazard_pointers_for(void* p)\r\n(检查指定指针是否危险):\r\n这个函数由回收者调用，用于判断一个它想要删除的节点指针\r\np 当前是否被任何其他线程的风险指针所引用。 bool outstanding_hazard_pointers_for(void* p) {  // 遍历全局风险指针数组  for (unsigned i = 0; i &lt; max_hazard_pointers; ++i) {    // 原子地读取槽位 i 的指针值，并与 p 比较    if (hazard_pointers[i].pointer.load() == p) {      return true; // 找到了匹配，说明指针 p 当前是危险的    }  }  return false; // 遍历完没有找到匹配，指针 p 当前是安全的} - 逻辑:\r\n非常直接。它线性扫描 hazard_pointers\r\n数组中的每一个槽位。对每个槽位，它原子地 (load())\r\n读取当前存储的指针值，并与传入的、想要删除的节点指针 p 进行比较。 -\r\n效率: 这是一个 O(N) 操作，其中 N 是\r\nmax_hazard_pointers。这是风险指针机制的主要性能开销点之一，尤其是在 N\r\n很大时。\r\nreclaim_later(T* data) (将节点加入待回收列表): 当\r\npop 操作成功移除一个节点 old_head，并且\r\noutstanding_hazard_pointers_for(old_head) 返回 true\r\n时，回收者不能立即删除 old_head，必须调用此函数将其放入“待回收”列表。\r\n// 通用删除函数模板template&lt;typename T&gt;void do_delete(void* p) {  delete static_cast&lt;T*&gt;(p);}// 待回收链表的节点结构struct data_to_reclaim {  void* data;                         // 指向要删除的原始节点  std::function&lt;void(void*)&gt; deleter; // 正确的删除器 (类型擦除)  data_to_reclaim* next;              // 指向链表下一个节点  // 1. 构造函数：保存指针和对应的删除器  template&lt;typename T&gt;  data_to_reclaim(T* p) :    data(p),    deleter(&amp;do_delete&lt;T&gt;), // 使用函数指针指向正确的删除函数    next(nullptr)  {}  // 2. 析构函数：调用正确的删除器  ~data_to_reclaim() {    deleter(data);  }};// 全局待回收链表的头指针 (原子)std::atomic&lt;data_to_reclaim*&gt; nodes_to_reclaim;// 3. 将节点原子地添加到待回收链表头部void add_to_reclaim_list(data_to_reclaim* node) {  node-&gt;next = nodes_to_reclaim.load(); // 读取当前头  // 使用 CAS 循环尝试更新头指针  while (!nodes_to_reclaim.compare_exchange_weak(node-&gt;next, node));}// 4. reclaim_later 接口函数 (模板)template&lt;typename T&gt;void reclaim_later(T* data) {  // 5. 创建 data_to_reclaim 节点 (包含指针和删除器)，并添加到链表  add_to_reclaim_list(new data_to_reclaim(data));} - data_to_reclaim 结构: 这是待回收链表的节点。 - data:\r\n存储指向原始待删除节点（例如 lock_free_stack::node）的 void。 -\r\ndeleter (①): 关键。因为回收机制是通用的\r\n(void)，我们需要一种方法在最终删除时调用正确类型的\r\ndelete。这里使用了 std::function (或函数指针)\r\n来存储一个类型擦除的删除器。构造函数 (①) 会根据传入的\r\nT* 自动设置正确的 do_delete。 - next: 指向链表中的下一个\r\ndata_to_reclaim 节点。\r\n\r\n析构函数 (②): 当 data_to_reclaim 对象本身被 delete 时（在\r\ndelete_nodes_with_no_hazards 中），它的析构函数会调用存储的 deleter\r\n来真正释放原始节点 data 的内存。\r\nnodes_to_reclaim:\r\n一个原子指针，指向待回收链表的头节点。必须是原子的，因为多个线程可能同时调用\r\nreclaim_later。\r\nadd_to_reclaim_list (③):\r\n实现了一个无锁的链表头插法。它读取当前的头，设置新节点的 next\r\n指向它，然后使用 CAS 循环尝试原子地更新 nodes_to_reclaim 指针。\r\nreclaim_later (④, ⑤): 模板函数，负责创建 data_to_reclaim\r\n节点（分配内存并设置好数据指针和删除器），然后调用 add_to_reclaim_list\r\n将其加入全局链表。\r\n\r\ndelete_nodes_with_no_hazards() (尝试清理待回收列表):\r\n这个函数由回收者线程（通常是在 pop\r\n成功后）调用，尝试遍历待回收列表，并删除那些当前不再被任何风险指针引用的节点。\r\nvoid delete_nodes_with_no_hazards() {  // 6. 原子地取走整个待回收链表，并将全局头设为 nullptr  data_to_reclaim* current = nodes_to_reclaim.exchange(nullptr);  while (current) { // 遍历取走的链表    data_to_reclaim* const next = current-&gt;next; // 先保存下一个节点    // 7. 检查当前节点的数据指针是否还在任何 HP 槽位中    if (!outstanding_hazard_pointers_for(current-&gt;data)) {      // 8. 如果不在，安全删除 data_to_reclaim 节点      //    (其析构函数会调用 deleter 删除原始数据)      delete current;    } else {      // 9. 如果还在，不能删除，将其重新添加回全局待回收链表      add_to_reclaim_list(current);    }    current = next; // 处理下一个节点  }} - 原子夺取链表 (⑥): nodes_to_reclaim.exchange(nullptr)\r\n是关键的第一步。它原子地将全局链表头设为\r\nnullptr，并返回之前的头指针。这确保了只有一个线程在处理这一批待回收节点，避免了对链表本身的并发修改（除了\r\nadd_to_reclaim_list 的头插）。\r\n\r\n遍历与检查 (⑦): 对取下的链表进行遍历。对于每个 data_to_reclaim\r\n节点 current，调用 outstanding_hazard_pointers_for(current-&gt;data)\r\n检查其存储的原始数据指针是否危险。\r\n安全删除 (⑧): 如果检查结果为 false（不危险），就 delete\r\ncurrent。这会触发 data_to_reclaim 的析构函数，进而调用正确的 deleter\r\n删除原始节点。\r\n重新添加 (⑨): 如果检查结果为 true（危险），就调用\r\nadd_to_reclaim_list(current) 将这个 data_to_reclaim\r\n节点重新放回全局待回收链表，等待下一次清理。\r\n\r\n性能问题与优化\r\n主要瓶颈：outstanding_hazard_pointers_for\r\n需要遍历所有可能的风险指针槽位（max_hazard_pointers\r\n个），并且 delete_nodes_with_no_hazards\r\n对待回收链表中的每个节点都要执行一次这个遍历。在高线程数和高回收压力下，这会非常慢。\r\n优化策略：\r\n\r\n批量回收 (Batching)：delete_nodes_with_no_hazards 不在每次 pop\r\n后都调用，而是等到“待回收”链表的长度达到某个阈值（例如 R *\r\nmax_hazard_pointers，R &gt; 1）时才触发一次。这可以摊销扫描 HP\r\n列表的成本。\r\n线程本地回收列表 (Thread-local Reclaim Lists)：每个线程将自己 pop\r\n的节点放入自己的待回收列表。只有当本地列表达到阈值时，才执行 HP\r\n检查并尝试回收。这避免了对全局回收列表头部的争用。线程退出时需要将本地列表合并到全局列表或其他机制处理。\r\n\r\n总结:\r\n风险指针是一种有效的无锁内存回收机制。它通过让读取线程显式声明正在使用的指针，使得回收线程能够安全地判断何时可以删除节点。\r\n优点：解决了 Use-After-Free\r\n问题，使得无锁数据结构可行。相比某些计数方法，对读取路径的性能影响相对可控（主要是设置/清除\r\nHP 的原子操作）。\r\n缺点：实现复杂，回收操作（扫描 HP 列表）开销较大，存在固定大小（HP\r\n列表）的限制，需要合理配置 max_hazard_pointers。\r\n解决方案2: 引用计数\r\n(Reference Counting)\r\n继风险指针之后，本节介绍了另一种解决无锁内存管理问题的主流技术——引用计数\r\n(Reference Counting)。\r\n核心思想：为每一个可能被共享的节点维护一个引用计数器。这个计数器追踪当前有多少“引用”（指针）指向该节点。当引用计数降为\r\n0 时，表明没有任何指针再指向该节点，因此可以安全地将其删除。\r\n与风险指针的区别在于,\r\n风险指针是读取者主动声明“我正在用这个”节点，回收者被动检查所有声明。而引用计数是每个节点被动记录有多少引用指向它，回收者（通常是最后一个释放引用的线程）根据计数值主动决定是否删除。\r\n挑战：如何原子性地、无锁地管理这个引用计数？简单的 ++count 和 –count\r\n本身就需要同步。\r\n方案 1：使用 std::shared_ptr\r\n最直接的想法是利用 C++ 内置的、自带原子引用计数的\r\nstd::shared_ptr。\r\n实现思路：将链表的 head 指针和每个节点的 next 指针都改为\r\nstd::shared_ptr&lt;node&gt; 类型。同时，head\r\n本身需要是原子的，即\r\nstd::atomic&lt;std::shared_ptr&lt;node&gt;&gt; head;（或者使用之前介绍的\r\nshared_ptr 原子自由函数）。 template&lt;typename T&gt;class lock_free_stack // 基于 shared_ptr 的理想化版本{private:  struct node {    std::shared_ptr&lt;T&gt; data;    std::shared_ptr&lt;node&gt; next; // next 也是 shared_ptr    node(T const&amp; data_) : data(std::make_shared&lt;T&gt;(data_)) {}  };  std::shared_ptr&lt;node&gt; head; // head 也是 shared_ptr (假设其原子操作无锁)public:  void push(T const&amp; data) {    std::shared_ptr&lt;node&gt; const new_node = std::make_shared&lt;node&gt;(data);    new_node-&gt;next = std::atomic_load(&amp;head); // 原子加载 head    // 原子 CAS 更新 head    while (!std::atomic_compare_exchange_weak(&amp;head,                                              &amp;new_node-&gt;next, new_node));  }  std::shared_ptr&lt;T&gt; pop() {    std::shared_ptr&lt;node&gt; old_head = std::atomic_load(&amp;head);    // 原子 CAS 更新 head    while (old_head &amp;&amp; !std::atomic_compare_exchange_weak(&amp;head,                                                        &amp;old_head, old_head-&gt;next));    // 如果 pop 成功 (old_head 非空)，返回其 data    // 内存管理完全由 shared_ptr 自动处理！    return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();  }  // ... 析构函数不再需要手动清理 ...};\r\n优点：代码极其简洁！内存管理（节点的分配和回收）完全由\r\nshared_ptr 自动处理。当最后一个指向某节点的 shared_ptr\r\n被销毁（无论是 head 更新还是 pop 返回的 shared_ptr\r\n最终被销毁），该节点会被自动 delete。\r\n致命缺点：此方案依赖于 std::atomic_is_lock_free(&amp;some_shared_ptr)\r\n返回 true，即平台必须提供对 shared_ptr\r\n的无锁原子操作。C++ 标准不保证这一点！在许多平台上，对\r\nshared_ptr\r\n的原子操作实际上是基于锁的（内部使用互斥量）。如果原子操作有锁，那么整个数据结构就不再是无锁的了，违背了本章的目标。\r\n方案\r\n2：手动实现分离引用计数 (Split Reference Counting)\r\n如果不能依赖无锁的 shared_ptr\r\n原子操作，我们就需要手动实现引用计数。\r\n挑战：直接在节点内放一个 std::atomic&lt;int&gt; count\r\n并不能完全解决问题。在 pop 中，存在一个微妙的竞争：初始化 count=1, 线程\r\nT1 创建局部指针读取 head 指向节点 N，线程 T2 也读取 head 指向 N,\r\n但是现在 count 并没有增加, 因为两个线程都只是读取 head,\r\n并没有去尝试修改所指节点的值, 也就没有机会去增加 count。现在 T1 成功 CAS\r\n将 head 指向 N-&gt;next，然后 T1 原子地递减 N 的 count 到 0 并 delete\r\nN。此时 T2 仍然持有指向 N 的指针，但 N 已被删除！\r\n解决方案：分离引用计数,\r\n将引用计数分为两部分，以区分“指针引用”和“内部访问引用”。\r\n\r\n外部计数 (External\r\nCount)：追踪有多少指针（head\r\n指针、其他节点的 next\r\n指针、线程临时持有的指针）指向该节点。\r\n\r\n这个计数在每次读取节点指针时增加（例如，在 pop 中读取 head\r\n指针时增加）。\r\n在节点被成功从数据结构中移除（pop 成功 CAS 更新\r\nhead）后，外部计数会减少，因为数据结构不再持有对该节点的引用。\r\n\r\n内部计数 (Internal\r\nCount)：追踪有多少线程正在内部访问该节点（例如，在\r\npop 的 CAS\r\n循环中读取了该节点指针，准备访问其\r\nnext）。\r\n\r\n这个计数在每次线程准备访问节点时增加（例如，在 pop 中成功增加 head\r\n的外部计数后，准备访问该节点时增加）。\r\n在节点访问完成后减少。\r\n\r\n\r\n安全删除条件：一个节点只有在外部计数为 0 且 内部计数为 0\r\n时才能被安全删除。 template&lt;typename T&gt;class lock_free_stack{private:  struct node;  struct counted_node_ptr  // 这是一个带外部计数的指针  {    int external_count;  // 维护的是 ptr 所指节点的外部计数    node* ptr;  };  struct node   // 这是节点结构  {    std::shared_ptr&lt;T&gt; data;    std::atomic&lt;int&gt; internal_count;  // 这是内部计数, 初始化为0    counted_node_ptr next;  // 带外部计数的 next 指针    node(T const&amp; data_):      data(std::make_shared&lt;T&gt;(data_)),      internal_count(0)    {}  };  std::atomic&lt;counted_node_ptr&gt; head;  // 带外部计数的 head 指针  void increase_head_count(counted_node_ptr&amp; old_counter)  // 增加 head 所指节点的外部计数  {    counted_node_ptr new_counter;  // 声明一个新的计数器    do    {      new_counter = old_counter;      ++new_counter.external_count;    }    while(!head.compare_exchange_strong(old_counter,new_counter));  // 尝试更新 head    old_counter.external_count = new_counter.external_count;  // 更新传入的 old_counter 的外部计数  }public:  ~lock_free_stack()  {    while(pop());  // 清空栈  }  void push(T const&amp; data)  // push 操作  {    counted_node_ptr new_node;  // 创建新节点    new_node.ptr=new node(data);  // 初始化新节点    new_node.external_count=1;   // 外部计数初始化为1, 因为 head 会指向它    new_node.ptr-&gt;next=head.load();  // 设置 next 指针    while(!head.compare_exchange_weak(new_node.ptr-&gt;next,new_node));  }  std::shared_ptr&lt;T&gt; pop()  {    counted_node_ptr old_head = head.load();  // 读取 head    for(;;)    {      increase_head_count(old_head);  // 这里增加的 EC 代表的就是当前持有的这个 old_head 临时指针      node* const ptr = old_head.ptr;  // 获取节点指针, 只是方便地获取裸指针进行解引用。      if(!ptr)      {        return std::shared_ptr&lt;T&gt;();      }      if(head.compare_exchange_strong(old_head,ptr-&gt;next))  // 尝试更新 head      {        std::shared_ptr&lt;T&gt; res;        res.swap(ptr-&gt;data);         int const count_increase = old_head.external_count - 2;  // 它代表在 CAS 成功移除 head 指针后，除了 head 指针和当前线程的临时引用之外，剩余的外部引用数量。这些主要是其他线程在 increase_head_count 中增加的临时外部引用。        if(ptr-&gt;internal_count.fetch_add(count_increase)== -count_increase){ // 节点最终被删除的时刻，是当最后一个持有（无论是外部还是内部）引用的线程，在释放其引用时，发现总计数（合并计算后体现在 internal_count 上）变为 0 的那一刻。          delete ptr;        }        return res;  // 返回弹出的数据      }      else if(ptr-&gt;internal_count.fetch_sub(1)==1) // CAS 失败, 因为其他线程修改了 head, 准备重来一次      // 而此时 ptr 仍然被当前线程持有, 所以要把它的内部计数减1      {        delete ptr;        }    }  }};\r\n总结\r\n使用 std::shared_ptr 进行无锁引用计数是最理想的，但依赖于平台对\r\nshared_ptr 原子操作的无锁支持。\r\n手动实现的分离引用计数是一种可行的替代方案，但极其复杂。核心难点是需要原子地同时操作指针和它的外部计数（通常需要\r\nDWCAS 支持才能无锁），并且需要仔细设计内部/外部计数的增减逻辑，以确保在\r\nCAS\r\n成功和失败路径下都能正确判断何时可以安全删除节点。这种复杂性是无锁内存管理的主要障碍之一。\r\n应用于无锁栈上的内存模型\r\n在前面的小节中，我们构建了一个使用分离引用计数的无锁栈，并且所有原子操作都使用了默认的\r\nstd::memory_order_seq_cst 内存顺序。虽然这样做保证了正确性（因为 seq_cst\r\n提供了最强的保证），但在性能敏感的无锁编程中，它可能是不必要且低效的。\r\n本节的目标是重新审视这个实现，并根据操作之间真正必要的依赖关系，尝试放松内存顺序要求（例如，使用\r\nacquire, release, relaxed），以期提高性能，同时维持正确性。\r\n\r\n放松内存顺序的基本方法是： 1.\r\n识别依赖关系：分析代码，找出哪些操作的结果（特别是内存写入）必须对其他线程的哪些操作（特别是内存读取）可见，以保证程序的逻辑正确性（避免数据竞争、保证读取到有效数据）。\r\n2.\r\n确定同步点：找出负责在线程间建立这种可见性保证的关键原子操作。\r\n3.\r\n选择最小顺序：为每个原子操作选择最弱（最宽松）的内存顺序标签，只要它能满足第1步中识别出的所有必要依赖关系。\r\n\r\n分析 push 操作\r\n核心操作：\r\n\r\n创建新节点 new_node (包含 data 和 next=nullptr)。\r\nnew_node-&gt;ptr-&gt;next = head.load(…) (读取旧 head 以设置\r\nnext)。\r\nhead.compare_exchange_weak(…, new_head, …) (CAS 更新 head)。\r\n\r\n依赖关系：\r\n\r\npush -&gt; pop：当一个 pop 线程通过 increase_head_count 中的 CAS\r\n成功读取到 push 写入的 new_head 值时，它需要能够安全地访问\r\nnew_head.ptr-&gt;data 和 new_head.ptr-&gt;next (这个 next 是在步骤 2\r\n中设置的)。\r\n这意味着 push 中对 new_node (包括其 data 和 next)\r\n的写入必须先行于 (happen-before) pop 线程对这些成员的读取。\r\n\r\n同步点：push 中的 head.compare_exchange_weak (CAS) 成功时，是\r\nnew_node 对 pop 线程“可见”的时刻。这个 CAS 操作需要建立同步。\r\n内存顺序选择：\r\n\r\nhead.compare_exchange_weak (成功)：为了与 pop 中的 acquire\r\n操作同步，这里需要 memory_order_release 语义。它确保在 CAS\r\n之前的所有写入（对 new_node 的初始化）对成功读取该值的 acquire\r\n操作是可见的。\r\nhead.compare_exchange_weak (失败)：如果 CAS 失败，说明 head\r\n被修改了，push\r\n操作会继续循环。失败本身不需要与任何其他线程同步。可以使用\r\nmemory_order_relaxed。\r\nhead.load() (用于设置 next)：这次 load 发生在 release CAS\r\n之前。它的结果只用于设置 new_node-&gt;ptr-&gt;next 和作为 CAS 的\r\nexpected\r\n值。它不需要从其他线程“获取”任何信息，也不需要“释放”任何信息。可以使用\r\nmemory_order_relaxed。\r\n\r\n优化后的 push 实现如下： void push(T const&amp; data) {  counted_node_ptr new_node;  new_node.ptr = new node(data);  new_node.external_count = 1;  // next 指针的设置读取 head 时使用 relaxed  new_node.ptr-&gt;next = head.load(std::memory_order_relaxed);   // CAS 循环：成功用 release，失败用 relaxed  while (!head.compare_exchange_weak(new_node.ptr-&gt;next, new_node,        std::memory_order_release, std::memory_order_relaxed));}\r\n分析 pop 操作\r\npop 的逻辑更复杂，涉及多个原子操作和依赖关系。\r\n核心操作：\r\n\r\nold_head = head.load(…) (初始加载)。\r\nincrease_head_count(old_head): 内部循环 CAS\r\n(head.compare_exchange_strong) 以增加 external_count。\r\nptr = old_head.ptr。\r\nif (ptr == nullptr) … (空栈判断)。\r\nhead.compare_exchange_strong(old_head, ptr-&gt;next, …) (主\r\nCAS，尝试移除节点)。\r\n\r\n成功路径: res.swap(ptr-&gt;data),\r\nptr-&gt;internal_count.fetch_add(count_increase, …) (更新内部计数),\r\ndelete ptr (如果计数为0)。\r\n失败路径: ptr-&gt;internal_count.fetch_add(-1, …) (或 release_ref),\r\ndelete ptr (如果计数为0)。\r\n\r\n\r\n依赖关系：\r\n\r\npop &lt;- push: pop 需要看到 push 对 ptr-&gt;data 和 ptr-&gt;next\r\n的写入。\r\npop (访问) &lt;- pop (删除): pop 线程 T1 在访问 ptr-&gt;next 或\r\nptr-&gt;data 时，必须确保没有其他 pop 线程 T2 已经将 ptr 删除。\r\npop (修改 ptr-&gt;data) -&gt; pop (删除 ptr): 对 ptr-&gt;data\r\n的修改 (通过 swap) 必须先行于对 ptr 的 delete 操作（由将引用计数减为 0\r\n的那个线程执行）。\r\n\r\n同步点与内存顺序选择：\r\n\r\nincrease_head_count 中的 CAS:\r\n\r\n目的：安全地读取 head 并增加外部计数，同时确保读取到的 ptr\r\n是有效的，并且能看到 push 写入的 ptr-&gt;next 和 ptr-&gt;data。\r\n顺序: 这个 CAS 读取 head。为了与 push 的 release CAS\r\n同步，它在成功时需要 memory_order_acquire\r\n语义。失败时可以relaxed。\r\n\r\n主 CAS (head.compare_exchange_strong(old_head, ptr-&gt;next, …)):\r\n\r\n目的: 原子地将 head 指向下下个节点。\r\n依赖: 它需要读取 ptr-&gt;next。ptr-&gt;next 的可见性已经由\r\nincrease_head_count 的 acquire CAS 保证了。\r\n同步: 这个 CAS 写入 head。这个写入需要与后续的 pop\r\n操作同步吗？不一定需要强同步，因为后续的 pop 会执行自己的 acquire\r\n操作。因此，这个 CAS 可以使用 memory_order_relaxed。\r\n\r\ninternal_count.fetch_add(count_increase, …) (成功路径):\r\n\r\n目的: 将外部计数转移到内部计数，并检查是否可以删除。\r\n依赖: 必须发生在 res.swap(ptr-&gt;data) 之后（序前）。\r\n同步: 如果这个 fetch_add 导致计数为 0，当前线程将执行 delete\r\nptr。为了确保 swap 操作先行于 delete（即使在弱排序内存模型下），这个\r\nfetch_add 需要 memory_order_release 语义。它确保了在 fetch_add\r\n之前的所有内存操作（包括 swap）对于之后（在同一个线程中）的 delete\r\n操作是可见且有序的。\r\n\r\ninternal_count.fetch_add(-1, …) (失败路径，或 release_ref):\r\n\r\n目的: 减少当前线程持有的内部引用。如果计数变为 0，则删除节点。\r\n同步: 如果这个操作导致计数为 0，当前线程需要 delete\r\nptr。删除操作需要确保能看到所有先前对该节点的操作。原文的最终实现（清单\r\n7.12）在这里使用了 memory_order_relaxed，但在 delete\r\n之前增加了一个额外的\r\nptr-&gt;internal_count.load(std::memory_order_acquire)。\r\n理由 (推测): 可能是为了确保在执行 delete\r\n之前，确实获取了所有其他线程对该 internal_count 的 release\r\n修改（虽然这里没有明显的配对 release）。或者，这是一种防御性编程，确保在\r\ndelete 前有一个 acquire\r\n屏障。这部分逻辑比较微妙，原文解释也略显模糊。但遵循最终代码是安全的。\r\n\r\n\r\n优化后的 pop 实现如下： std::shared_ptr&lt;T&gt; pop() {  counted_node_ptr old_head = head.load(std::memory_order_relaxed); // relaxed  for (;;) {    increase_head_count(old_head); // 内部 CAS: acquire on success, relaxed on failure    node* const ptr = old_head.ptr;    if (!ptr) { return std::shared_ptr&lt;T&gt;(); }    // 主 CAS 使用 relaxed    if (head.compare_exchange_strong(old_head, ptr-&gt;next,                                     std::memory_order_relaxed))     {      std::shared_ptr&lt;T&gt; res;      res.swap(ptr-&gt;data);      int const count_increase = old_head.external_count - 2;      // 成功路径 fetch_add 使用 release      if (ptr-&gt;internal_count.fetch_add(count_increase,             std::memory_order_release) == -count_increase)       {        delete ptr;      }      return res;    }     // 失败路径 fetch_add 使用 relaxed    else if (ptr-&gt;internal_count.fetch_add(-1,                std::memory_order_relaxed) == 1)     {      // 在 delete 前加一个 acquire load (来自清单 7.12)      ptr-&gt;internal_count.load(std::memory_order_acquire);       delete ptr;    }  }}\r\n总结:\r\n放松内存顺序是一项优化，目标是减少不必要的同步开销，提高性能。它需要非常仔细地分析操作之间的数据依赖和控制依赖，以确定最低要求的内存顺序。\r\n基本原则：\r\n\r\n如果一个写操作 W 的结果需要被另一个线程的读操作 R 看到，W\r\n通常需要 release (或 acq_rel, seq_cst)，R 通常需要 acquire (或 acq_rel,\r\nseq_cst, consume)。\r\n如果一个原子操作的结果只在当前线程内部使用，或者它不需要建立跨线程的先行关系，那么\r\nrelaxed 通常是足够的。\r\nRMW 操作（如\r\nfetch_add）本身构成了释放序列的一部分，这有助于同步传递。\r\n\r\n复杂性：正确地推理和验证放松后的内存顺序极其困难，容易出错。相比之下，seq_cst\r\n虽然可能慢一些，但更容易保证正确性。因此，放松内存顺序应谨慎进行，并最好有充分的性能测试数据支持。\r\n无锁的线程安全队列\r\n与栈的不同之处: - 栈 (LIFO)：push 和 pop\r\n都作用于同一个端点（head 指针）。主要挑战在于同步对\r\nhead 的并发修改以及弹出节点的内存管理。\r\n\r\n队列 (FIFO)：\r\n\r\npush 操作作用于尾部 (tail)。\r\npop 操作作用于头部 (head)。\r\n新的挑战：需要确保对一端的修改（例如 push 修改了 tail\r\n或最后一个节点的 next）能够正确、安全地被另一端的操作（例如 pop 读取\r\nhead-&gt;next）所观察到。\r\n潜在的优势：由于操作发生在不同端点，理论上 push 和 pop\r\n之间存在更大的并行可能性。\r\n\r\n\r\n单生产者/单消费者 (SPSC)\r\n的简单情况\r\n如果队列严格限制为只有一个线程执行 push，一个线程执行\r\npop，那么无锁实现可以非常简单（甚至比无锁栈更简单）。实现思路：\r\n\r\n使用哑节点 (Dummy Node)来解耦头尾。\r\nhead 和 tail 都是原子指针\r\n(std::atomic&lt;node*&gt;)。\r\npush (生产者):\r\n\r\n准备新节点 p 和数据 new_data。\r\n获取当前 old_tail = tail.load()。\r\n将 new_data 存入 old_tail-&gt;data（原子地或非原子地，取决于 data\r\n是否原子）。\r\n原子地设置 old_tail-&gt;next = p（需要 old_tail-&gt;next\r\n也是原子的，或者确保只有生产者修改它）。\r\n原子地更新 tail.store(p)。\r\n\r\npop (消费者):\r\n\r\n读取 old_head = head.load()。\r\n检查是否为空 (old_head == tail.load())。\r\n原子地更新 head.store(old_head-&gt;next)。\r\n读取 old_head-&gt;data。\r\ndelete old_head (在 SPSC\r\n中是安全的，因为只有消费者会删除，生产者不会持有旧 head 的引用)。\r\n\r\n\r\ntemplate&lt;typename T&gt;class lock_free_queue{private:  struct node  {    std::shared_ptr&lt;T&gt; data;    node* next;    node():       next(nullptr)    {}  };  std::atomic&lt;node*&gt; head;  std::atomic&lt;node*&gt; tail;  node* pop_head()  {    node* const old_head=head.load();    if(old_head==tail.load())  // 1    {      return nullptr;    }    head.store(old_head-&gt;next);    return old_head;  }public:  lock_free_queue():      head(new node),tail(head.load())  {}  lock_free_queue(const lock_free_queue&amp; other)=delete;  lock_free_queue&amp; operator=(const lock_free_queue&amp; other)=delete;  ~lock_free_queue()  {    while(node* const old_head=head.load())    {      head.store(old_head-&gt;next);      delete old_head;    }  }  std::shared_ptr&lt;T&gt; pop()  {    node* old_head=pop_head();    if(!old_head)    {      return std::shared_ptr&lt;T&gt;();    }    std::shared_ptr&lt;T&gt; const res(old_head-&gt;data);  // 2    delete old_head;    return res;  }  void push(T new_value)  {    std::shared_ptr&lt;T&gt; new_data(std::make_shared&lt;T&gt;(new_value));    node* p=new node;  // 3    node* const old_tail=tail.load();  // 4    old_tail-&gt;data.swap(new_data);  // 5    old_tail-&gt;next=p;  // 6    tail.store(p);  // 7  }};\r\nSPSC 安全性分析：在严格的 SPSC\r\n约束下，上述实现是可以工作的。生产者只修改 tail 附近，消费者只修改 head\r\n附近，它们的操作通过 head == tail 检查和 next\r\n指针链条隐式同步。内存回收也简单。\r\n问题：现实世界很少是严格的 SPSC。我们需要\r\nMPMC（多生产者，多消费者）。\r\n多生产者/多消费者 (MPMC)\r\n的复杂情况\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"条款 20 - 对类似 std::shared_ptr 但有可能空悬的指针使用 std::weak_ptr","url":"/2025/09/18/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE20%20-%20%E5%AF%B9%E7%B1%BB%E4%BC%BC%20std%20shared_ptr%20%E4%BD%86%E6%9C%89%E5%8F%AF%E8%83%BD%E7%A9%BA%20%E6%82%AC%E7%9A%84%E6%8C%87%E9%92%88%E4%BD%BF%E7%94%A8%20std%20weak_ptr/","content":"\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"条款 18 - 使用 std::unique_ptr 管理具备专属所有权的资源","url":"/2025/09/15/lang/CPP/Effective%20modern%20C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/%E6%9D%A1%E6%AC%BE18%20-%20%E4%BD%BF%E7%94%A8%20std%20%20unique_ptr%20%E7%AE%A1%E7%90%86%E5%85%B7%E5%A4%87%E4%B8%93%E5%B1%9E%E6%89%80%E6%9C%89%E6%9D%83%E7%9A%84%E8%B5%84%E6%BA%90/","content":"进入现代C++, 传统的指针由于容易出现资源泄露等缺点,\r\n智能指针成为了管理资源的重要工具. C++11 中共有四种智能指针：std::auto\r\n_ptr, std::unique_ptr, std::shared_ptr 和 std:\r\n:weak_ptr。所有这些智能指针都是为管理动态分配对象的生命期而设计的，其中,\r\nstd::unique_ptr 是一种独占式智能指针,\r\n它确保在任何时候只有一个指针指向资源. 这使得\r\nstd::unique_ptr\r\n成为了管理具备专属所有权的资源的理想选择.\r\n而且在一般情况下, std::unique_ptr 应该是智能指针的默认首选,\r\n它在效率上也几乎与裸指针无异\r\n\r\nstd::auto_ptr 是从 C++98 中残留下来的弃用特性,\r\n现在已经基本被std::unique_ptr 所替代.\r\n\r\n专属所有权与移动语义\r\nstd::unique_ptr 体现了“专属所有权”的概念，即一个非空的\r\nstd::unique_ptr 总是拥有其所指向的资源\r\n。任何时刻，资源都只有一个所有者。这确保了资源的安全释放，避免了内存泄漏和悬空指针的问题。\r\n轻量且高效：在默认情况下（即使用 delete 作为删除器），std::unique_ptr\r\n的尺寸与裸指针完全相同，并且其操作（如解引用）的执行效率也与裸指针相同\r\n。这使得它即使在对性能和内存要求极为苛刻的场景下也同样适用 。\r\n移动专属 (Move-Only)：std::unique_ptr\r\n不允许复制, 如果你尝试复制一个\r\nstd::unique_ptr，代码将无法通过编译。这是为了保证所有权的唯一性。因此要转移资源的所有权，只能且必须使用\r\nstd::move 。当一个 std::unique_ptr\r\n被移动后，源指针将被置为 nullptr 。\r\n自动资源管理：当一个 std::unique_ptr\r\n被销毁时（例如离开作用域），它会自动销毁其所拥有的资源\r\n。默认情况下，它通过在其内部的裸指针上调用 delete 来完成这一操作 。\r\n典型用例：工厂函数\r\nstd::unique_ptr 最常见的用法之一，是作为工厂函数的返回类型\r\n。工厂函数通常在堆上创建一个对象并返回一个指向它的指针，而调用者则负责该对象的生命周期,\r\n这与 std::unique_ptr 的专属所有权语义完美契合。工厂函数通过返回一个\r\nstd::unique_ptr，清晰地将新创建的对象的所有权转移给调用方 。\r\n// 假设 Investment 是一个多态基类class Investment { ... };// 工厂函数返回一个 unique_ptr，将所有权转移给调用者template&lt;typename... Ts&gt;std::unique_ptr&lt;Investment&gt; makeInvestment(Ts&amp;&amp;... params);{    // 调用工厂函数，获取资源的所有权    auto pInvestment = makeInvestment(arguments);    } // pInvestment 在此处离开作用域，其管理的 Investment 对象被自动销毁 调用方的代码将变得非常安全和简洁，因为当 pInvestment\r\n离开作用域时，std::unique_ptr\r\n的析构函数会自动确保资源被正确释放，即使在发生异常时也是如此 。\r\n自定义删除器\r\nstd::unique_ptr 不仅限于使用 delete\r\n来释放资源，它还支持自定义删除器 (custom deleter)\r\n。删除器可以是任意函数或函数对象（包括 lambda 表达式），用于在\r\nstd::unique_ptr 销毁时执行特定的清理操作。自定义删除器的类型是\r\nstd::unique_ptr 模板的第二个参数 。 // 自定义删除器，在删除前先写入日志auto delInvmt = [](Investment* pInvestment) {    makeLogEntry(pInvestment);    delete pInvestment;};// 在 unique_ptr 的类型中指定删除器的类型std::unique_ptr&lt;Investment, decltype(delInvmt)&gt;    pInv(nullptr, delInvmt); 需要注意的是,\r\n自定义删除器可能会增加 std::unique_ptr 的尺寸 。\r\n函数指针删除器：如果删除器是一个函数指针，std::unique_ptr\r\n的尺寸通常会从一个字长（裸指针的大小）增加到两个字长（一个用于裸指针，一个用于函数指针）。\r\n函数对象删除器（包括\r\nlambda）：如果删除器是一个函数对象，其尺寸取决于该函数对象中存储了多少状态。如果是一个无捕获的\r\nlambda，它不包含任何状态，编译器通常可以将其完全优化掉，此时\r\nstd::unique_ptr 的尺寸不会增加，仍然和一个裸指针一样大 。\r\n因此，当需要自定义删除器时，使用无捕获的 lambda\r\n是比使用函数指针更高效的选择 。\r\nstd::unique_ptr\r\n的两种形式：单个对象与数组\r\nstd::unique_ptr 提供两种形式：一种用于单个对象，一种用于数组 。\r\n\r\nstd::unique_ptr：用于单个对象。它提供了 operator* 和\r\noperator-&gt;。\r\nstd::unique_ptr&lt;T[]&gt;：用于数组。它提供了 operator[]\r\n索引运算符，但不提供 * 和 -&gt; 。\r\n\r\n不过, 在现代 C++ 中，std::array、std::vector 和 std::string\r\n等标准容器几乎总是比裸数组更好的选择，因此 std::unique_ptr&lt;T[]&gt;\r\n的使用场景非常有限 。\r\n转换为 std::shared_ptr\r\nstd::unique_ptr 的一个非常吸引人的特性是，它可以方便且高效地转换为\r\nstd::shared_ptr。\r\n并且通常来说, std::unique_ptr 是构建 std::shared_ptr\r\n的完美来源。这使得 std::unique_ptr\r\n成为工厂函数的理想返回类型。工厂函数返回一个高效的\r\nstd::unique_ptr，将专属所有权交给调用者。如果调用者后续需要共享这个资源，他们可以自行决定将其转换为\r\nstd::shared_ptr，从而将所有权模型从专属升级为共享 。\r\n","categories":["language"],"tags":["language","CPP"]},{"title":"Inline 函数","url":"/2025/10/11/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%87%BD%E6%95%B0/Inline/","content":"inline 是 C++\r\n中的一个关键字，用于向编译器提供一个建议，希望它将一个函数的调用替换为该函数体的直接展开。这是一种用空间（代码膨胀）换取时间（性能提升）的优化手段。\r\ninline 关键字在现代 C++\r\n中有两个主要作用，第二个作用甚至比第一个更重要。\r\n作用一：向编译器提议“内联展开”以提升性能\r\n这是 inline 最原始、最广为人知的作用。\r\n普通的函数调用涉及: - 参数压栈, 将函数参数按调用约定放入栈中。 -\r\n保存返回地址：将调用点下一条指令的地址压栈。 - 跳转：CPU\r\n跳转到函数的内存地址。 - 函数体执行, 压栈局部变量。 -\r\n返回：从栈中取出返回地址，跳转回去。 - 栈清理。\r\ninline 的解决方案是：如果编译器接受了 inline\r\n建议，它会在编译时直接将函数调用替换为函数体代码。\r\n// 源码int result = add(3, 5);// 编译器可能将其展开为：int result = 3 + 5; // 无函数调用开销\r\n适用场景：对于那些函数体小、逻辑简单、且被频繁调用的函数（例如，一个简单的\r\ngetter/setter\r\n或数学运算函数），消除调用开销带来的性能提升是相当可观的。\r\n作用二：解决“一次定义规则 (One Definition Rule,\r\nODR)”的限制\r\n\r\nODR 是 C++\r\n语言中的一个重要规则，规定在一个程序中，任何实体（变量、函数、类、模板等）在整个程序中必须有且仅有一个定义,\r\n不过可以有多个声明（declaration） 在通常情况下, 如果不使用 inline,\r\n你只能把函数声明放在头文件中，而把函数定义放在一个单独的源文件中，这样会增加代码的复杂度和维护难度。\r\n\r\n这是 inline 在现代 C++ 工程实践中至关重要的作用。\r\nC++ ODR 规定，一个非 inline\r\n的函数在一个程序中只能被定义一次。如果你把一个普通函数的定义放在头文件\r\n(.h) 中，而这个头文件被多个源文件 (.cpp) 包含，那么在链接 (Link)\r\n阶段，链接器会发现这个函数有多个重复的定义，从而报链接错误 (LNK2005:\r\nmultiple definition)。\r\ninline 的解决方案：inline\r\n关键字对链接器说：“嘿，你可能会在不同的编译单元中看到这个函数的多个定义,\r\n但我保证它们是相同的,\r\n你只需要随便选一个保留下来，把其他的都丢掉就行了。”\r\n这使得我们可以安全地将函数定义放在头文件中，这对于模板编程和编写纯头文件库\r\n(Header-only libraries) 至关重要。\r\n注意事项: - inline 是一个建议，而非强制命令:\r\n编译器拥有最终决定权。它可能会忽略你的 inline\r\n请求，如果它认为内联并不划算（例如，函数体过大、包含循环或递归、是虚函数等）。反过来，现代编译器非常智能，它们可能会自动内联一些你没有标记为\r\ninline 的、足够简单的函数（尤其是在开启了优化选项，如 -O2 或 -O3\r\n时）。\r\n\r\n滥用 inline 会导致代码膨胀 (Code Bloat):\r\n如果你将一个很大的函数标记为\r\ninline，并且它被调用了很多次，那么这个大函数的代码就会在程序的多个地方被复制。这会导致最终生成的可执行文件体积急剧增大。更糟糕的是，这可能会降低性能，因为它会严重影响\r\nCPU 的指令缓存 (Instruction\r\nCache)。一个巨大的程序更难被全部加载到高速缓存中，导致缓存未命中 (Cache\r\nMiss)，CPU 需要去更慢的内存中读取指令，反而得不偿失。\r\n递归函数不能内联:\r\n递归函数在调用自身时需要一个明确的调用栈来跟踪每次调用的状态。如果递归函数被内联展开，编译器将无法正确地管理这些调用状态，从而导致逻辑错误和不可预测的行为。\r\n\r\n使用inline的语法是, 将 inline\r\n关键字放在函数返回类型的前面或者变量类型的前面: // --- 在头文件中 (e.g., math_utils.h) ---#ifndef MATH_UTILS_H#define MATH_UTILS_H// 这是一个很好的 inline 候选函数：// 1. 函数体非常小。// 2. 逻辑简单，没有循环或递归。// 3. 放在头文件中，可以被多个.cpp文件包含而不会产生链接错误。inline int max(int a, int b) {    return a &gt; b ? a : b;}#endif 如上,\r\n将简单的函数使用inline定义在头文件中是个好主意。在现代 C++ 中，inline\r\n的性能优化作用已经部分被编译器的自动优化所取代。它更重要的角色是解决 ODR\r\n问题，允许你在头文件中定义函数。\r\n还要注意类的成员函数：在类定义内部实现的成员函数，编译器会自动将其视为\r\ninline 函数，你不需要显式地添加 inline 关键字。 class Box {private:    double volume;public:    // 这个函数被隐式地当作 inline    double getVolume() const {        return volume;    }};\r\n","categories":["CPP","函数"],"tags":["CPP"]},{"title":"2. 线程间共享数据","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/2.%20%E7%BA%BF%E7%A8%8B%E9%97%B4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE/","content":"共享数据带来的问题\r\n并发编程为我们带来了更高的性能和响应能力，但也引入了新的挑战，尤其是在多个线程需要访问和修改共享数据时。正确地管理这些共享数据对于确保程序的正确性和稳定性至关重要。\r\n条件竞争 (Race Condition)\r\n这一节是理解并发编程为何困难的基石。它主要阐述了两个核心概念：不变量\r\n(Invariants) 的破坏是问题的表现形式，而\r\n数据竞争 (Data Race)\r\n是C++标准中导致这种问题的底层原因，并会引发未定义行为\r\n(Undefined Behavior)。\r\n不变量 (Invariants)\r\n的破坏和条件竞争\r\n首先，我们来理解什么是“不变量”以及它为何如此重要。\r\n通俗理解,\r\n不变量是数据结构在任何“稳定”时刻都必须遵守的规则。它就像一个数据结构的“健康承诺”,\r\n确保数据结构在任何时候都处于一个有效的状态。\r\n例如, 一个计数器变量 count 必须始终等于列表中实际的项数;\r\n在一个双向链表中，如果节点A的“下一个”指针（next）指向节点B，那么节点B的“前一个”指针（prev）必须指向节点A。\r\n但是不变量是如何被破坏的呢？\r\n问题在于，几乎所有的数据结构更新操作都不是原子的（即一步完成）。它们需要多个步骤，而在这些步骤的中间，不变量是暂时被破坏的。\r\n让我们来看一个完美阐释不变量被破坏的双向链表删除节点的例子。\r\n\r\n不变量：如上所述，A-&gt;next == B 和 B-&gt;prev == A\r\n必须同时成立。\r\n删除操作的步骤（假设删除节点N，其前一个节点是P，后一个节点是S）：\r\n\r\n找到要删除的节点N。\r\n更新前一个节点P的 next 指针，使其指向N的下一个节点S（即 P-&gt;next =\r\nS）。\r\n更新后一个节点S的 prev 指针，使其指向N的前一个节点P（即 S-&gt;prev =\r\nP）。\r\n释放节点N的内存。\r\n\r\n不变量被破坏的时刻：在第2步和第3步之间, 此时，P-&gt;next\r\n已经指向了 S（P-&gt;next = S），但 S 的 prev 指针仍然指向 N（S-&gt;prev\r\n==\r\nN）。在这个瞬间，数据结构处于一个“非健康”或“损坏”的状态。P\r\n和 S 之间的双向链接是不一致的。\r\n并发访问的后果：如果此时（第2步和第3步之间），线程B开始从 P\r\n节点向后遍历链表，它会通过 P-&gt;next 直接跳到\r\nS，跳过了节点N（N此时理论上还在链表中）。\r\n\r\n更糟糕的是，如果线程C试图从 S 节点向前遍历，它会访问到\r\nS-&gt;prev，也就是 N，但 N 的前一个节点 P 已经不指向 N 了。\r\n如果线程D试图删除节点 S，它在修改 P\r\n节点时可能会与线程A（正在删除N）发生冲突，导致链表被永久性损坏，最终导致程序崩溃。\r\n\r\n\r\n上面描述的这种“后果取决于哪个线程先执行”的现象，就是条件竞争。\r\n并发中竞争条件的形成，取决于一个以上线程的相对执行顺序，每个线程都抢着完成自己的任务。\r\n当然，并不是所有的竞争条件都会导致严重的问题。我们可以将竞争条件分为两类：\r\n\r\n良性竞争\r\n(Benign)：两个线程都往一个队列里添加任务。谁先谁后可能无所谓，队列的“不变量”（如队列的完整性）没有被破坏。\r\n恶性竞争\r\n(Problematic)：这就是我们真正关心的。它特指那些在不变量被破坏时发生的竞争，如上面的双向链表示例。\r\n\r\n条件竞争的特点, 也是我们面对条件竞争时的痛点：\r\n\r\n难以复现：它发生的概率可能很低，只在极端的线程调度顺序下才出现。\r\n受负载影响：系统负载越大，线程切换越频繁，问题复现的概率越高。\r\n调试时消失：在调试模式下，程序的执行时序会发生变化（例如I/O变慢、断点），导致竞争条件“神秘消失”，这使得它极难被定位。\r\n\r\n数据竞争 (Data Race)\r\n与未定义行为\r\nC++标准库为上述提到的这种混乱状态提供了一个精确的定义:\r\n数据竞争 (Data Race):\r\n当两个或以上的线程并发（非同步）地访问同一个内存地址，并且至少有一个访问是写操作时，即构成数据竞争。(是条件竞争的一种具体表现形式)\r\n在双向链表的例子中，当线程A在写入 P-&gt;next\r\n指针时，如果线程B正在读取\r\nP-&gt;next（用于遍历），这就构成了一次数据竞争。\r\n更重要的是, 数据竞争是未定义行为 (Undefined Behavior)\r\n的一种原因。\r\n“未定义行为”是C++标准中的“最高警告”。它意味着程序不再受C++标准的任何约束,\r\n且编译器可以（并且经常会）进行“激进”的优化，它会假设你的代码中没有数据竞争。\r\n当数据竞争实际发生时，结果可能是：程序崩溃、数据损坏、计算出错误结果，或者（最坏的情况下）程序看起来“正常工作”了很长一段时间，直到在某个关键时刻才爆发。\r\n避免恶性条件竞争\r\n在上一节我们明确了问题的根源：多线程修改共享数据时，会导致数据结构的不变量\r\n(Invariants)\r\n被暂时破坏，如果此时被其他线程访问，就会产生恶性条件竞争。\r\n本小节则宏观地提出了三种解决这个问题的策略。其核心思想是：必须采用一种方法，确保当一个线程正在修改数据（即处于破坏不变量的“中间状态”）时，其他线程无法访问这些数据。从其他线程的视角来看，这个修改操作必须是原子的——要么是“已经完成了”，要么是“还没开始”。\r\n保护机制（互斥量）\r\n这是最简单、最直接的办法，也是本章后续内容的核心。\r\n它的核心思想：对数据结构采用某种保护机制（例如一把“锁”）。\r\n\r\n线程A在开始修改数据之前，先“锁住”这个数据。\r\n线程A执行修改操作（此时不变量可能被暂时破坏，但因为数据被锁住了，所以很安全）。\r\n线程A完成修改，恢复不变量。\r\n线程A“解锁”数据。\r\n\r\n效果：当线程A持有锁时，任何其他试图访问该数据的线程（如线程B）都必须等待，直到线程A释放锁。这样就保证了线程B永远不会看到数据结构在“中间状态”时的样子。\r\nC++标准库提供了很多此类机制，而最基本、最通用的就是\r\n互斥量 (Mutex), 也就是我们后面要重点讲解的内容。\r\n无锁编程 (Lock-free\r\nprogramming)\r\n这是一种完全不同的、更高级也更复杂的思路。它不使用“锁”，而是从根本上改变数据结构的设计。\r\n核心思想是：重新设计数据结构及其不变量，使得每一次修改都能通过一系列不可分割的变化来完成。\r\n例如,\r\n修改操作（添加或删除节点等）被设计成一个或多个原子操作\r\n(Atomic\r\nOperations)。在任何一个步骤中，数据结构的不变量都保持稳定（或者说，它能“原子地”从一个稳定状态跳转到另一个稳定状态，没有中间态）。\r\n由于不变量始终保持稳定，其他线程可以随时安全地访问数据结构，即使有线程正在对其进行修改，也不需要等待。\r\n不过,\r\n无锁编程对于程序员来说是一个巨大的挑战。它需要对C++内存模型（第5章）有深刻的理解，是一种专家级的技术（第7章）。\r\n软件事务内存 (STM)\r\n这是一种借鉴自数据库领域的、偏理论和研究的策略。\r\n核心思想是：像操作数据库一样，使用事务 (Transaction)\r\n来处理数据更新。\r\n\r\n线程A开始一个“事务”。\r\n线程A读取所需数据，并将所有修改操作记录在“事务日志”中（此时真正的共享数据还没被修改）。\r\n线程A完成所有操作后，尝试“提交\r\n(Commit)”这个事务，将日志中的所有修改合为一步，一次性应用到共享数据上。\r\n\r\n如果在线程A执行事务的过程中（从第1步到第3步），有其他线程（线程B）已经修改了A所依赖的数据，那么线程A的“提交”就会失败。如果提交失败，事务将回滚\r\n(Rollback)，并且线程A必须重启整个操作。\r\n这保证了所有修改要么全部成功（原子提交），要么全部失败（回滚），数据结构永远不会停留在不一致的状态。\r\n这是一个热门的研究领域，但在C++标准中没有直接支持，因此本书不会深入探讨。\r\n使用互斥量保护共享数据\r\n这一节是上面提出的“保护机制”策略的具体C++实现。它介绍了用于保护共享数据的最核心工具：std::mutex，以及使用它的最佳实践：std::lock_guard,\r\n和更高级的 std::unique_lock。\r\nC++ 中使用互斥量\r\nstd::mutex：基本的锁机制\r\n\r\n头文件：std::mutex 和 std::lock_guard 都在\r\n&lt;mutex&gt; 头文件中声明。\r\n创建：通过实例化 std::mutex 来创建一个互斥量对象。\r\n\r\n#include &lt;mutex&gt;std::mutex some_mutex; \r\n核心操作（不推荐直接使用）：\r\n\r\nlock()：上锁。如果互斥量 some_mutex\r\n没有被任何线程持有，则调用此函数的线程将获得锁，并继续执行。如果锁已被其他线程持有，则调用\r\nlock() 的线程将被阻塞\r\n(block)，即暂停执行，直到该锁被释放。\r\nunlock()：解锁。释放该线程对互斥量的所有权，以便其他正在等待的线程可以获取它。\r\n\r\n声明互斥量之后, 就意味着 mutex 可以保护由 lock() 和 unlock()（或 RAII\r\n封装如 std::lock_guard）界定的临界区（Critical Section）,\r\n在这里线程可以安全地访问和修改共享数据。\r\n特定的互斥量实例 some_mutex 只能保护与其关联的共享数据,\r\n确保在任何时刻, 只有一个线程可以进入由 some_mutex\r\n保护的临界区。多个互斥量可以保护不同的数据。\r\n理解互斥量\r\n互斥量的本质是一个同步原语（Synchronization\r\nPrimitive），它在底层依赖于原子操作和操作系统（OS）内核来实现排他性。\r\n核心机制：原子操作（Hardware Support）\r\n互斥量的实现离不开 CPU\r\n提供的原子指令，这是实现“锁”的基础，例如\r\nTest-and-Set、Compare-and-Swap (CAS) 或 Exchange。\r\n当一个线程尝试获取锁时，它会执行一个原子指令来检查锁的状态并尝试将其设置为“已锁定”。原子性保证了检查和设置这两个操作是不可分割的。\r\n\r\n如果锁未被占用，原子操作成功，线程获得锁。\r\n如果锁已被占用，原子操作失败，线程进入等待状态。\r\n\r\n这个过程确保了两个线程不可能同时成功地将锁的状态从“未锁定”改为“已锁定”。\r\n接着就是等待和阻塞（OS Kernel Support）\r\n当锁已被占用，线程不能简单地空转等待（空转等待被称为忙等待/自旋锁，会浪费\r\nCPU\r\n资源）。高效的互斥量会依赖操作系统将等待的线程挂起（Suspend）。\r\n\r\n即线程阻塞：\r\n当一个线程无法获取互斥量时，它会通过调用操作系统内核的函数将自己置于阻塞状态（Blocking）。\r\n\r\n接着是内核调度： 操作系统内核将该线程从 CPU\r\n的调度队列中移除，并将其放入该互斥量关联的等待队列中。此时，该线程不再消耗\r\nCPU 资源。\r\n最后是线程唤醒： 当持有锁的线程调用 unlock()\r\n时，操作系统内核会被通知。内核会从等待队列中选择一个或多个线程，将其唤醒（Wake\r\nup）并重新放入 CPU 调度队列，使其有机会竞争该锁。\r\n另外,\r\n互斥量除了提供排他性之外，还提供了至关重要的内存同步功能（或称内存可见性）,\r\n这是通过对lock() 和 unlock() 的内存屏障 (Memory Barriers) 实现的。\r\n\r\nunlock() 的作用（释放）： 确保在 unlock()\r\n之前对共享内存所做的所有写入操作，对所有其他线程都是可见的。这通常涉及清空或刷新\r\nCPU 缓存。\r\nlock() 的作用（获取）： 确保在 lock()\r\n之后，线程能够看到先前持有该锁的线程所做的所有修改。\r\n\r\n使用 std::lock_guard (RAII)\r\n确保安全\r\n虽然可以直接使用 std::mutex 的 lock() 和 unlock()\r\n方法来保护临界区，但这要求你必须“记住在每个函数出口都要去调用\r\nunlock()”。\r\n这很容易出错，尤其是在函数中途有多个返回路径，或者在持锁期间发生异常时。\r\n\r\n多重返回路径：如果你的函数很复杂，在中间有 return\r\n语句，你可能会忘记在 return 之前调用 unlock()。\r\n异常 (Exceptions)：如果在 lock() 和 unlock()\r\n之间发生了异常，unlock() 调用将被跳过。\r\n\r\n如果 unlock() 没有被及时调用，互斥量将永远保持锁定状态。任何其他试图\r\nlock() 这个互斥量的线程都将永久阻塞，导致整个程序死锁或挂起。\r\n为了解决上述危险，C++标准库提供了\r\nstd::lock_guard，这是一个遵循 RAII（Resource\r\nAcquisition Is Initialization，资源获取即初始化,\r\n将资源的生命周期与一个对象的生命周期绑定）惯用语法的模板类。\r\nstd::lock_guard 的工作原理：\r\n\r\n构造：std::lock_guard&lt;std::mutex&gt; guard(some_mutex);.\r\n当你创建 guard 对象时，它会在其构造函数中自动调用\r\nsome_mutex.lock()。\r\n\r\n如果 some_mutex 已被其他线程锁定，构造 guard\r\n的这一行代码将会阻塞，直到锁可用。\r\n\r\n析构：当 guard 对象离开其作用域时，guard 的析构函数会被调用,\r\n且其析构函数还会自动调用 some_mutex.unlock()。\r\n\r\n好处：\r\n\r\n绝对安全：无论函数是正常结束、从中间\r\nreturn，还是因为抛出异常而退出，guard 对象都会被正确析构。\r\n保证解锁：这意味着互斥量总是会被正确地解锁。你再也不用手动管理\r\nunlock() 了。\r\n\r\n下面是一个使用 std::lock_guard 的示例：\r\n#include &lt;list&gt;#include &lt;mutex&gt;#include &lt;algorithm&gt;std::list&lt;int&gt; some_list;   // 1. 全局共享数据std::mutex some_mutex;      // 2. 用于保护 some_list 的全局互斥量void add_to_list(int new_value){  // 3. 创建 guard 对象，自动调用 some_mutex.lock()  std::lock_guard&lt;std::mutex&gt; guard(some_mutex);    some_list.push_back(new_value);} // guard 在此离开作用域，自动调用 some_mutex.unlock()bool list_contains(int value_to_find){  // 4. 创建 guard 对象，自动调用 some_mutex.lock()  std::lock_guard&lt;std::mutex&gt; guard(some_mutex);    return std::find(some_list.begin(), some_list.end(), value_to_find)          != some_list.end();} // guard 在此离开作用域，自动调用 some_mutex.unlock()\r\nadd_to_list() 是一个“写者”函数，list_contains()\r\n是一个“读者”函数。它们都试图访问同一个共享资源\r\nsome_list, 且它们都使用了同一个互斥量 some_mutex\r\n来进行保护。\r\n\r\n互斥量和共享资源应该是一一对应的关系。每个共享资源都应该有一个专门的互斥量来保护它，避免不同资源之间的锁冲突。\r\n\r\n由于 std::lock_guard 的存在，系统保证在任何时刻，只有一个线程可以执行\r\nadd_to_list() 或 list_contains() 中被 guard 保护的代码块。\r\n\r\n如果线程A正在执行 add_to_list()（已持有锁），线程B试图调用\r\nlist_contains()，线程B将在 std::lock_guard\r\n的构造函数处被阻塞，直到线程A退出 add_to_list() 并释放锁。\r\n\r\n结果：list_contains() 永远不可能看到 add_to_list()\r\n正在修改列表的“中间状态”。它看到的列表要么是修改前的，要么是修改后的。不变量得到了保护。\r\n将互斥量和数据封装在类中\r\n虽然上述示例能工作，但使用全局变量（some_list）和全局互斥量（some_mutex）通常是糟糕的面向对象设计。\r\n更好的做法是将数据和用于保护它的互斥量封装在同一个类中,\r\n同时在所有公开的需要访问该数据的成员函数中使用\r\nstd::lock_guard。\r\nclass protected_list {private:    std::list&lt;int&gt; some_list;    std::mutex some_mutex; // 互斥量和数据都是 privatepublic:    void add_to_list(int new_value) {        std::lock_guard&lt;std::mutex&gt; guard(some_mutex);        some_list.push_back(new_value);    }    bool list_contains(int value_to_find) {        std::lock_guard&lt;std::mutex&gt; guard(some_mutex);        // ... (find logic) ...    }};\r\n优势：\r\n\r\n封装：将数据和锁紧密联系在一起。\r\n清晰：private\r\n访问修饰符使得所有人都清楚地知道这些数据是受保护的。\r\n强制安全：外部代码无法直接访问 some_list 或\r\nsome_mutex，它们必须通过 protected_list\r\n的公共成员函数。只要所有公共成员函数都正确使用了\r\nstd::lock_guard，数据访问就是绝对安全的。\r\n\r\n精心组织代码来保护共享数据\r\n尽管使用互斥量和 std::lock_guard\r\n可以保护共享数据，但仅仅这样做是不够的。你必须精心设计和组织代码，以避免一些常见的陷阱和错误。\r\n（陷阱）避免返回受保护数据的指针或引用\r\n\r\n在设计类的接口时要格外小心，以防止受保护数据的指针或引用“泄漏”出去\r\n\r\nstd::lock_guard 的保护是有作用域的。它只能保护在 lock_guard\r\n对象存在期间（即锁被持有的期间）执行的代码。\r\n如果一个函数（即使它内部正确地使用了\r\nstd::lock_guard）以任何方式将一个指向“被保护数据”的原始指针或引用交给了外部代码，那么：\r\n\r\nstd::lock_guard 会在函数返回时释放锁。\r\n外部代码现在拥有了一个指向数据的“后门”\r\n外部代码可以在不获取锁的情况下，通过这个“后门”指针/引用随时访问甚至修改数据。\r\n\r\n此时，如果另一个线程正在（合法地）持有锁并修改数据，而外部代码通过“后门”也在访问数据，数据竞争\r\n(Data Race) 就发生了。\r\n下面是通过返回值或输出参数实现的泄露, 这是最明显的一种泄漏：\r\nclass BadDesign {private:    std::mutex m;    int protected_data;public:    // 危险：返回了受保护数据的引用！    int&amp; get_data() {        std::lock_guard&lt;std::mutex&gt; guard(m);        return protected_data;     }};BadDesign bd;int&amp; leaked_ref = bd.get_data(); // 锁在 get_data() 返回时已释放leaked_ref = 10; // 灾难：在无保护的情况下修改了数据！\r\nget_data() 函数本身是线程安全的，但它返回的引用 leaked_ref\r\n却成了一个“迷失的引用”。任何持有 leaked_ref 的代码都可以绕过互斥锁 m\r\n来读写 protected_data。\r\n（陷阱）避免在持锁时调用用户代码\r\n还有一种方式是通过传递给用户提供的函数泄露,\r\n这是一种更隐蔽、更危险的泄漏方式。 // 要保护的数据class some_data{  int a;  std::string b;public:  void do_something();};// 封装数据的类class data_wrapper{private:  some_data data;  std::mutex m;public:  template&lt;typename Function&gt;  void process_data(Function func)  {    std::lock_guard&lt;std::mutex&gt; l(m);    func(data);  // 1. 漏洞所在：将“受保护”数据传递给用户函数  }};// --- 恶意用户的代码 ---some_data* unprotected; // 一个全局指针，用于“接应”泄漏的数据void malicious_function(some_data&amp; protected_data){  unprotected = &amp;protected_data; // 将数据的地址存储到全局指针中}data_wrapper x;void foo(){  // 2. 传递恶意函数，执行“攻击”  x.process_data(malicious_function);   // 3. 在无保护的情况下访问保护数据！  // 此时，`process_data` 已返回，锁已释放  // 但 `unprotected` 指针已指向 `x` 内部的 `data`  unprotected-&gt;do_something(); }\r\ndata_wrapper::process_data 函数看起来是安全的。它正确地用\r\nstd::lock_guard 锁定了互斥量 m。\r\n但是, 在持有锁的同时，它调用了用户传入的函数 func，并将受保护的 data\r\n的引用作为参数传了进去。\r\n这就给了用户代码(传入的函数)一个机会，可以在函数执行期间(也是持锁期间)\r\n偷偷保存 data 的地址，从而绕过互斥量的保护。\r\nprocess_data 函数返回，std::lock_guard\r\n析构，锁被释放。但是此时用户代码仍然可以通过全局指针 unprotected\r\n直接调用 data 的成员函数，完全绕过了互斥量 m\r\n的保护。\r\n如果此时有另一个线程（线程B）正在调用\r\nx.process_data(…)（并持有了锁），foo 函数（线程A）对\r\nunprotected-&gt;do_something()\r\n的调用就会与线程B的操作发生数据竞争，导致未定义行为。\r\n通过上述两个陷阱，我们可以看到，即使正确使用了互斥量和\r\nstd::lock_guard，设计不当的接口仍然可能导致保护机制失效，从而引发数据竞争。\r\n保护是必须的，但接口设计决定了保护是否有效。\r\nC++线程库无法帮你自动防止这种逻辑错误。程序员必须遵守一个严格的准则：“切勿将受保护数据的指针或引用传递到互斥锁作用域之外”\r\n这包括：\r\n\r\n不作为函数返回值。\r\n不存储在外部可见的内存中（如全局变量、或传递给你的其他对象的成员）。\r\n不作为参数传递到用户提供的（你无法控制的）函数中去。\r\n\r\n如果需要让用户操作数据，最好的实现是拷贝数据的副本传给用户函数，或者提供一个受保护的接口，让用户通过这个接口间接操作数据，而不是直接访问数据本身。\r\n发现接口内在的条件竞争\r\n在实际的编程中, 即使你完美地用 std::lock_guard 保护了每个函数,\r\n没有泄露任何指针或引用，你的类依然可能存在严重的条件竞争。\r\n问题不再是实现的错误，而是接口设计本身就“内置”了竞争,\r\n各个操作之间是有“间隙”的\r\nstd::lock_guard 保证了单个成员函数（如\r\npush()）的执行是原子的——它要么没开始，要么就做完了。\r\n但是，如果用户为了完成一个逻辑操作（比如“获取并删除栈顶元素”），需要调用两个或更多的、各自独立的、原子的成员函数时，问题就出现了。\r\n在第一个函数调用（持有锁A，释放锁A）和第二个函数调用（持有锁B，释放锁B）之间，存在一个“间隙”。在这个“间隙”中，本线程不持有锁，其他线程可以自由进入并修改数据结构，从而破坏本线程的操作逻辑。\r\nstd::stack 的\r\nempty()/top() 示例 (TOCTTOU 竞争)\r\n假设我们有一个 threadsafe_stack，它的每个成员函数（empty, top,\r\npop）内部都正确使用了 std::lock_guard。\r\n在单线程中，我们经常这样写： // 单线程安全代码stack&lt;int&gt; s;if (!s.empty()) {  // 1. 检查 (Check)  int const value = s.top(); // 2. 使用 (Use)  s.pop();  do_something(value);}\r\n这段代码依赖于一个假设：如果在第1行 empty() 返回 false，那么到第2行\r\ntop() 执行时，栈仍然是非空的。\r\n在多线程环境下，这个假设完全失效：\r\n\r\n线程A 调用 s.empty()。s.empty() 内部加锁、检查、返回\r\nfalse（假设栈内有1个元素）、释放锁。\r\n（间隙） 此时，操作系统切换到线程B。\r\n线程B 调用 s.empty()（返回\r\nfalse）、s.top()（获取元素）、s.pop()（栈变空了）。线程B的锁被释放。\r\n（间隙） 操作系统切换回线程A。\r\n线程A 执行到第2行 s.top()。s.top()\r\n内部加锁，但此时栈已经是空的！\r\n结果：对空栈调用 top() 是未定义行为 (Undefined\r\nBehavior)，程序很可能崩溃。\r\n\r\n这就是一个经典的 TOCTTOU（Time-of-Check to\r\nTime-of-Use，检查时-使用时）条件竞争。这个竞争的产生，不是因为\r\nempty() 或 top()\r\n没有加锁，而是因为接口设计迫使你将“检查”和“使用”分成了两个独立的操作。\r\nstd::stack 的 top()/pop() 示例\r\n(重复处理)\r\n类似地，假设我们想要“获取并删除栈顶元素”，我们可能会写如下代码：\r\n// 假设栈 s 中有两个元素 [B, A] (A在栈顶)// 线程A 和 线程B 同时执行以下逻辑：if (!s.empty()) {  int const value = s.top(); // 2  s.pop();                 // 3  do_something(value);}\r\n一种可能的执行顺序：\r\n\r\n线程A：s.empty() 返回 false。（锁释放）\r\n线程B：s.empty() 返回 false。（锁释放）\r\n线程A：s.top()。value 被赋值为 A。（锁释放）\r\n线程B：s.top()。value 也被赋值为 A（因为线程A还没\r\npop）。（锁释放）\r\n线程A：s.pop()。栈 s 移除 A，现在栈顶是 B。（锁释放）\r\n线程A：do_something(A)。\r\n线程B：s.pop()。栈 s 移除 B，现在栈是空的。（锁释放）\r\n线程B：do_something(A)。\r\n\r\n结果：元素 A 被处理了两次，而元素 B 被 pop\r\n掉后永远地丢失了。这不是程序崩溃，而是一个更难排查的逻辑错误。\r\n异常安全对接口设计的影响\r\n既然问题出在接口上，解决方案就是改变接口。必须将多个分离的步骤合并成一个单一的、原子的操作。\r\n我们希望的逻辑是“获取并删除栈顶元素”。std::stack 将其分为 top() 和\r\npop() 两个独立的操作，这就导致了上述的条件竞争。\r\n你可能会想：“为什么 std::stack 不直接提供一个 T pop()\r\n函数来返回值呢？”\r\n答案是异常安全 (Exception Safety)。\r\n想象一下 stack&lt;std::vector&lt;int&gt;&gt; s;.\r\n如果我们调用 std::vector&lt;int&gt; value = s.pop();, pop()\r\n函数的实现可能是：\r\n\r\n从栈中移除 vector（此时已从栈上分离）。\r\n返回 vector（这会触发拷贝构造函数）。\r\nstd::vector 的拷贝构造函数需要分配内存，如果内存不足，它会抛出\r\nstd::bad_alloc 异常。\r\n\r\n后果：栈顶元素在第1步被成功移除了，但在第2步拷贝时失败了。这个数据永久丢失了！\r\n\r\n除了这里之外, 在return语句中返回值的拷贝构造也可能抛出异常。\r\n\r\nstd::stack 将 top() 和 pop() 分开，就是为了让你能安全地先 top()\r\n获取引用，安全地拷贝它（如果拷贝失败，栈本身没变），确认拷贝成功后，然后才调用\r\npop() 删除它。\r\n设计线程安全的\r\nthreadsafe_stack\r\n如果要优化上述问题, 我们的新接口必须同时满足：\r\n\r\n线程安全：top 和 pop 的逻辑必须是原子的，不能有“间隙”。\r\n异常安全：在返回值的过程中如果发生异常，数据不能丢失。\r\n\r\n解决方案1: 提供一个新的成员函数\r\nbool try_pop(T&amp; value)，它将“获取并删除栈顶元素”的逻辑合并在一起：\r\ntemplate&lt;typename T&gt;class threadsafe_stack {private:    std::stack&lt;T&gt; data_stack;    std::mutex m;public:    bool try_pop(T&amp; value) {        std::lock_guard&lt;std::mutex&gt; guard(m);        if (data_stack.empty())            return false; // 栈空，无法弹出        value = data_stack.top(); // 获取栈顶元素的副本        data_stack.pop();         // 删除栈顶元素        return true;              // 成功弹出    }    // 其他成员函数 (push, empty, etc.)};\r\n优点是可以保证没有数据冲突, 如果第1步的赋值操作 value = data.top()\r\n抛出异常（例如 T 的赋值运算符抛异常），data.pop()\r\n不会被执行，栈保持不变，数据不丢失。同时不通过 return\r\n返回实际的值，而是通过引用参数传递，避免了返回值拷贝可能抛异常的问题。\r\n缺点是要求 T 类型必须支持赋值，并且用户需要先构造一个 T\r\n的实例传进去，可能有额外开销。\r\n解决方案2: 使用智能指针 (如 std::shared_ptr&lt;T&gt;)\r\n来避免拷贝：\r\nstd::shared_ptr&lt;T&gt; pop() {    std::lock_guard&lt;std::mutex&gt; lock(m);    if(data.empty()) throw empty_stack();    // 1. 在栈顶元素被 pop 之前，为其创建一个 shared_ptr    std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(data.top()));     data.pop(); // 2. pop 栈    return res; // 3. 返回 shared_ptr}\r\n这是解决异常安全问题的绝佳方案。第1步 make_shared\r\n可能会因内存不足而抛异常，但此时 data.pop()\r\n也没执行，栈保持不变。第3步返回 shared_ptr\r\n本身（拷贝指针）是不会抛出异常的。\r\n缺点就是, 对于 int 这样的简单类型，使用 shared_ptr\r\n会带来不必要的堆分配和管理开销。\r\n死锁：问题描述及解决方案\r\n在前面的小节中，我们主要担心的是“保护不足”或“接口竞争”。而本节介绍了一个完全相反的问题：过度保护或保护顺序不当导致的“永久等待”，即死锁\r\n(Deadlock)。\r\n死锁的定义（两个线程互相等待）\r\n死锁，也称为“致命拥抱”(Deadly\r\nEmbrace)，发生在两个或多个线程互相等待对方释放资源（锁）时。由于所有线程都在等待，没有线程可以继续执行来释放它持有的锁，因此所有相关线程都将永久阻塞。\r\n当一个操作需要同时获取两个或更多的互斥量时，死锁的风险就出现了。\r\n一个常见的错误建议是：“只要所有线程总是以相同的顺序获取锁（例如，总是先锁A，再锁B），就不会死锁。”,\r\n但这个建议在实践中很难遵守。例如下面的一个类的 swap\r\n函数，用于交换两个实例的内容。为了保证交换的原子性，你必须同时锁住两个实例。\r\nclass X {private:    some_big_object data;    std::mutex m;public:    friend void swap(X&amp; lhs, X&amp; rhs);};\r\n使用 std::lock()\r\n一次性锁定多个互斥量\r\n为了解决这种“需要一次性获取多个锁”的困境，C++标准库提供了 std::lock\r\n函数。\r\nstd::lock (在 &lt;mutex&gt;\r\n中)是一个可变参数模板函数，可以接受任意数量的“可锁定”对象（如\r\nstd::mutex）: std::lock(m1, m2, m3, ...);,\r\n它会以一种避免死锁的算法来锁定所有传入的互斥量。\r\nC++标准库保证：std::lock\r\n返回时，你要么成功获取了所有的锁，要么一个都没获取到（例如，如果它在尝试获取锁的途中抛出异常，它会保证释放掉已经获取的锁）。它绝不会只持有一部分锁而导致死锁。\r\n但是, std::lock 只负责“上锁”，它不负责“解锁”。如果我们手动\r\nunlock()，又会遇到忘记 unlock 或异常安全的问题。因此，最佳实践是将\r\nstd::lock 与 std::lock_guard\r\n结合使用，但需要一个特殊的技巧：使用 std::adopt_lock\r\n标志。\r\nstd::adopt_lock 的使用\r\nstd::adopt_lock\r\n是一个标志，表示“我已经拥有了这个锁”，用于告诉\r\nstd::lock_guard 不要尝试再次锁定互斥量。 下面是一个使用 std::lock 和\r\nstd::adopt_lock 的示例：\r\n// 清单 3.6: 交换操作中使用 std::lock() 和 std::lock_guardclass X{// ... (同上) ...public:  friend void swap(X&amp; lhs, X&amp; rhs)  {    // 1. 检查是否为同一实例    if(&amp;lhs == &amp;rhs)      return;    // 2. 核心：无死锁地锁定两个互斥量    std::lock(lhs.m, rhs.m);     // 3. 创建 lock_guard，并传入 std::adopt_lock    //    告诉 lock_a \"你不需要再 lock() 了，    //    你只需要领养(adopt)这个已经锁定的互斥量，并在析构时 unlock() 它\"    std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m, std::adopt_lock); // 标记 2    // 4. 对 rhs.m 做同样的操作    std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock); // 标记 3    // 5. 现在可以安全地执行操作了    swap(lhs.some_detail, rhs.some_detail);  } // lock_b 和 lock_a 在此析构，自动调用 unlock()};\r\nif(&amp;lhs==&amp;rhs) 是极端重要的: 同一个\r\nstd::mutex（非递归互斥量）在同一个线程上被 lock()\r\n两次是未定义行为。如果用户调用 swap(my_x,\r\nmy_x)，std::lock(my_x.m, my_x.m)\r\n就会触发未定义行为。这个检查避免了这种情况。\r\nstd::lock(lhs.m, rhs.m) 是避免死锁的关键。std::lock\r\n内部会使用一种算法（例如，可能尝试锁定，如果失败就全部释放再重试，或者按地址排序锁定）来保证它能同时获取\r\nlhs.m 和 rhs.m，而不会和另一个 swap(rhs, lhs) 调用的 std::lock\r\n产生死锁。\r\nstd::adopt_lock 是一个“标签”常量。它告诉 std::lock_guard\r\n的构造函数：“不要调用 m.lock()（因为 std::lock\r\n已经做过了），请你“领养”这个锁的所有权，你唯一的职责就是在你被析构时调用\r\nm.unlock()。”\r\n这完美地将 std::lock 的死锁安全上锁功能与 std::lock_guard 的 RAII\r\n自动解锁功能结合了起来。\r\n避免死锁的进阶指导\r\nstd::lock()\r\n是一个很棒的工具，但它只解决了“同时获取多个锁”这一个特定问题。而死锁是一个更广泛的系统设计问题。本节提供了四个超越\r\nstd::lock()\r\n的核心设计准则，以及一个扩展思考，帮助你从架构层面根除死锁。\r\n(1) 避免嵌套锁\r\n这是最简单、最激进的规则。如果一个线程在任何时候最多只持有一个锁，那么“循环等待”的条件就永远无法形成，死锁也就不可能发生。因为死锁的最小条件是：线程A持有锁1，等待锁2;\r\n且线程B持有锁2，等待锁1。\r\n如果遵循“避免嵌套锁”规则，线程A在持有锁1时，根本不允许它再去尝试获取锁2。它必须先释放锁1，才能去获取锁2。这就打破了死锁的第一个条件。\r\n在实践中,\r\n当你发现你需要持有锁A的同时去获取锁B时，重新审视你的设计。是否可以先释放A？或者，是否可以将两个锁合并为一个？如果实在无法避免，请使用准则三或准则四。\r\n(2) 避免在持有锁时调用用户代码\r\n\r\n“用户提供的代码”是指你无法控制的代码，例如回调函数、虚函数、模板参数的函数、Lambda\r\n表达式等。\r\n\r\n这条准则是准则一（避免嵌套锁）的一个重要推论。你（调用者）可能没有在持有锁时获取第二个锁，但你调用的“用户代码”可能会去获取第二个锁（甚至是第一个锁，导致递归死锁）。\r\n\r\n隐蔽的嵌套锁：你的代码（线程A）持有 lock_A，然后调用\r\nuser_function()。user_function() 内部尝试获取 lock_B。\r\n经典的死锁：与此同时，线程B持有\r\nlock_B，调用了另一个函数，这个函数尝试获取 lock_A。死锁发生。\r\n\r\n在实践中,\r\n在调用用户代码之前释放你的锁。如果用户代码需要访问受保护的数据，请先在锁内将数据复制一份，然后在锁外将副本传递给用户代码。\r\n(3) 使用固定顺序获取锁\r\n核心思想：如果“避免嵌套锁”不可行，你必须获取多个锁，那么强制所有线程在任何时候都必须以完全相同的、全局固定的顺序来获取这些锁。\r\n这是最经典的死锁预防算法。我们给所有互斥量一个全局唯一的排序（例如，按它们的内存地址排序，或按功能命名排序）。\r\n假设全局顺序是 lock_A -&gt; lock_B,\r\n线程A想获取A和B，它先锁A，再锁B。线程B想获取A和B，它也必须先锁A，再锁B。\r\n如果线程A获得了 lock_A，正在等待 lock_B。线程B此时不可能持有 lock_B\r\n并等待 lock_A。为什么？因为它必须先获取 lock_A 才能去获取 lock_B，而\r\nlock_A 已经被线程A持有了。线程B要么在等待\r\nlock_A（被A阻塞），要么还没开始。\r\n这种方式将“循环等待”变成了“单向排队”。\r\n(4)\r\n使用锁的层次结构（hierarchical_mutex 示例）\r\n这是准则三（固定顺序）的一个更高级、更灵活、可运行时检查的实现,\r\n为系统中每一个互斥量分配一个唯一的“层级值”（一个数字）。高层锁有高值（如\r\n10000），低层锁有低值（如 5000）。\r\n一个线程在已经持有某个层级的锁时，只能再去获取比它层级更低（数字更小）的锁,\r\n从而保证锁的获取顺序总是“从高到低”。\r\n这种“只准向下”的规则使得“循环等待”在逻辑上变得不可能。\r\n\r\n线程A：获取 lock_10000 (高) -&gt; 获取 lock_5000 (低)。（允许）\r\n线程B：获取 lock_5000 (低) -&gt; 尝试获取 lock_10000\r\n(高)。（禁止！）\r\n\r\n线程B的非法尝试会被立即在运行时检测到并抛出异常，而不是引发一个难以复现的死锁。\r\nhierarchical_mutex high_level_mutex(10000); // 1. 层级为 10000hierarchical_mutex low_level_mutex(5000);  // 2. 层级为 5000// ...void low_level_func(){  std::lock_guard&lt;hierarchical_mutex&gt; lk(low_level_mutex); // 3. 锁 5000  // ...}void high_level_func(){  std::lock_guard&lt;hierarchical_mutex&gt; lk(high_level_mutex); // 4. 锁 10000  high_level_stuff(low_level_func()); // 5. 在持有 10000 时，调用函数去锁 5000}void thread_a()  // 6. 遵守规则的线程{  high_level_func();}hierarchical_mutex other_mutex(100); // 7. 另一个层级为 100 的锁void other_stuff(){  high_level_func();  // 8. 尝试在持有 100 时，调用函数去锁 10000  do_other_stuff();}void thread_b() // 9. 违反规则的线程{  std::lock_guard&lt;hierarchical_mutex&gt; lk(other_mutex); // 10. 锁 100  other_stuff();}\r\n上面就是一个使用 hierarchical_mutex 的示例, thread_a\r\n遵守了层级规则，而 thread_b 违反了规则: 在 thread_b 中，other_stuff()\r\n试图在持有层级为 100 的锁时调用 high_level_func()，而 high_level_func()\r\n试图获取层级为 10000 的锁。这违反了“只能获取更低层级锁”的规则，因此\r\nhierarchical_mutex 会在运行时抛出一个异常，防止死锁的发生。\r\n这里实现层级锁的关键在于 thread_local 变量\r\ncurrent_hierarchy_value，它记录了当前线程持有的最高层级锁的层级值。每次获取一个新的锁时，都会检查这个值，确保新锁的层级低于当前持有的锁。\r\nclass hierarchical_mutex{  std::mutex internal_mutex;  unsigned long const hierarchy_value; // 这个互斥量实例的层级值  unsigned long previous_hierarchy_value;  // 1. 核心：每个线程独有一份的“当前层级”变量  static thread_local unsigned long this_thread_hierarchy_value;   void check_for_hierarchy_violation()  {    // 2. 规则检查    if(this_thread_hierarchy_value &lt;= hierarchy_value)     {      throw std::logic_error(“mutex hierarchy violated”);    }  }  void update_hierarchy_value()  {    // 3. “下降”：保存旧层级，设置新层级    previous_hierarchy_value=this_thread_hierarchy_value;     this_thread_hierarchy_value=hierarchy_value;  }public:  explicit hierarchical_mutex(unsigned long value):      hierarchy_value(value), previous_hierarchy_value(0)  {}  void lock()  {    check_for_hierarchy_violation(); // 检查    internal_mutex.lock();           // 4. 锁住真正的互斥量    update_hierarchy_value();        // 5. 更新本线程的层级  }  void unlock()  {    // 6. “上升”：恢复到上一个层级    this_thread_hierarchy_value=previous_hierarchy_value;     internal_mutex.unlock();  }  // ... try_lock() 类似 ...};// 8. (在类外) 初始化线程本地变量thread_local unsigned long    hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX);\r\nstatic 意味着它属于类，而不是类的实例; thread_local\r\n意味着每个线程都拥有它自己独立的一个副本。\r\n因此，this_thread_hierarchy_value\r\n完美地跟踪了当前线程所持有的最高层级锁（准确地说是最后一个锁）的层级。它被初始化为\r\nULONG_MAX\r\n，一个极大的值，表示“最高层级”，因此任何锁在开始时都可以被获取。\r\nstd::unique_lock——灵活的锁\r\n在之前，我们学习了 std::lock_guard。它是一个严格的 RAII\r\n包装器：一旦创建，它就必须锁定互斥量；一旦销毁，它就必须解锁互斥量。它非常高效，但也非常“死板”。\r\n本节引入了一个更强大、更灵活的工具：std::unique_lock。\r\n与 std::lock_guard 的对比\r\nstd::lock_guard：始终拥有它所管理的互斥量。它不维护任何状态，因此体积小、速度快。\r\n而std::unique_lock：不一定拥有它所管理的互斥量。它内部维护一个状态标志\r\n(flag) 来跟踪自己当前是否拥有锁。\r\n这种灵活性是 std::unique_lock\r\n一切功能的来源，但它也带来了轻微的代价：\r\n\r\n空间代价：它需要存储这个状态标志，因此 std::unique_lock\r\n对象通常比 std::lock_guard 对象更大。\r\n时间代价：在构造、析构和所有操作中，它都需要检查或更新这个标志，因此会比\r\nstd::lock_guard 稍慢一点。\r\n\r\nstd::defer_lock\r\n的使用（延迟加锁）\r\nstd::unique_lock 的灵活性首先体现在构造函数上。std::lock_guard\r\n只有一种构造方式（立即锁定），而 std::unique_lock\r\n有多种，其中最重要的是 std::defer_lock,\r\n这是一个传递给构造函数的“标签”常量。\r\n它告诉 std::unique_lock\r\n的构造函数：“请不要在构造时锁定互斥量。你只管关联这个互斥量，但保持你的‘拥有锁’状态标志为\r\nfalse。”.\r\n这样做是为了能将“上锁”这个动作推迟到以后执行，特别是为了能将\r\nstd::unique_lock 对象本身传递给 std::lock() 函数。\r\n// 清单 3.9: 交换操作中 std::lock() 和 std::unique_lock 的使用class X{private:  some_big_object some_detail;  std::mutex m;public:  X(some_big_object const&amp; sd):some_detail(sd){}  friend void swap(X&amp; lhs, X&amp; rhs)  {    if(&amp;lhs==&amp;rhs)      return;    // 1. 延迟锁定：创建 lock_a 和 lock_b，但它们暂不持有锁    std::unique_lock&lt;std::mutex&gt; lock_a(lhs.m, std::defer_lock);     std::unique_lock&lt;std::mutex&gt; lock_b(rhs.m, std::defer_lock);     // 2. 互斥量在这里被（无死锁地）锁定    std::lock(lock_a, lock_b);         swap(lhs.some_detail, rhs.some_detail);  } // lock_a 和 lock_b 在此析构，并自动解锁};\r\n在上面的代码中, 我们首先创建了两个 std::unique_lock 对象 lock_a 和\r\nlock_b，并传入 std::defer_lock 标志，表示它们暂时不持有锁,\r\n这里的延迟锁定是为了能将 lock_a 和 lock_b 传递给 std::lock() 函数,\r\n从而实现无死锁地一次性锁定两个互斥量。(这比使用 std::lock_guard\r\n更加灵活, 因为它不需要 std::adopt_lock 这个额外的“标签”)\r\n当然, 除了 std::defer_lock 实现延迟锁定,\r\nstd::unique_lock 还有更加灵活的用法: -\r\n所有权转移：锁可以像对象一样被移动（move）\r\n-\r\n手动解锁和重新加锁：可以在持有锁期间临时释放锁，然后再重新获取锁\r\n- 条件变量的集成：std::unique_lock 是与条件变量\r\n(std::condition_variable)\r\n一起使用的标准锁类型，因为它允许在等待条件时释放锁。\r\n不过, 代价就是 std::unique_lock 体积更大，速度稍慢。\r\n不同域中互斥量所有权的传递\r\n这一节的核心是 std::unique_lock\r\n的一个强大特性，它来源于C++11的移动语义 (Move Semantics)。\r\nstd::unique_lock\r\n的移动语义 (Move Semantics)\r\n首先, 锁可以是“可移动”的，但一定是“不可拷贝”的。\r\n你不能“拷贝”一个锁的所有权。std::lock_guard 和 std::unique_lock\r\n都禁止拷贝。这在逻辑上是说得通的：锁是“独占”的。你不能把一个锁复制一份，然后让两个人同时“拥有”这个锁。\r\nstd::unique_lock&lt;std::mutex&gt; lk1(m);std::unique_lock&lt;std::mutex&gt; lk2 = lk1; // 编译错误！\r\n不过, std::unique_lock\r\n是可移动的。“移动”意味着所有权的转移。它不像拷贝（“我有一份，你也有一份”），而是像转交（“我把它给你了，我就没有了”）。\r\nstd::unique_lock&lt;std::mutex&gt; lk1(m);std::unique_lock&lt;std::mutex&gt; lk2 = std::move(lk1); // 正确！ 执行后, lk2 现在拥有对互斥量 m 的锁。它负责在将来解锁\r\nm。lk1 不再拥有锁。它仍然是一个 std::unique_lock\r\n对象，但其内部的状态标志为 false（不拥有锁）。当 lk1\r\n析构时，它不会去解锁 m。\r\n从函数返回锁\r\n这种“可移动”的特性，最常见的应用场景就是跨函数（跨作用域）传递锁的所有权。\r\n第一种情况是隐式移动：当 std::unique_lock\r\n作为函数返回值时，C++编译器会自动为你调用移动构造函数，你不需要显式使用\r\nstd::move()。 std::unique_lock&lt;std::mutex&gt; get_lock(){  extern std::mutex some_mutex;  // 假设在某处定义了这个互斥量  std::unique_lock&lt;std::mutex&gt; lk(some_mutex); // lk 在此获取了锁  prepare_data(); // 在持有锁的情况下准备数据    return lk;  // 1. 隐式移动发生}void process_data(){  // 2. 所有权被转移到这里的 lk  std::unique_lock&lt;std::mutex&gt; lk(get_lock());   do_something(); // 3. 在仍然持有锁的情况下处理数据  } // 4. lk 在此析构，释放了最初在 get_lock() 中获取的锁 我们看 get_lock 中的\r\nreturn lk;: lk 是一个局部变量。当它被\r\nreturn\r\n时，编译器知道它即将被销毁，于是自动将其视为一个“右值”(rvalue)。std::unique_lock\r\n的移动构造函数被调用，创建了一个临时的、匿名的返回值对象，这个临时对象接管了\r\nlk 对 some_mutex 的锁所有权, 然后这个临时对象被传递给 process_data\r\n函数中的 lk 用作移动构造。(发生了两次所有权转移)\r\n现在, process_data 中的 lk 合法地拥有了那个最初在 get_lock\r\n函数内部获取的锁。do_something() 在锁的保护下安全执行。process_data\r\n结束，lk 析构，其内部标志为 true，于是它最终调用\r\nsome_mutex.unlock()，锁被正确释放。\r\nget_lock 函数返回，其局部的 lk 对象被析构。由于所有权已“移走”，lk\r\n的析构函数不会去解锁 some_mutex。\r\n\r\n或许可能会好奇, 为什么要传递锁? 不能直接在 get_lock\r\n内部完成所有工作吗? 答案是: 有时你需要在不同的作用域中持有锁,\r\n例如在调用栈的不同层次,\r\n或者分离不同的模块, 例如 prepare_data() 在数据层,\r\ndo_something() 在业务层, 从而清晰划分职责。同时,\r\n还可以避免重复代码\r\n(如果有多个函数都需要以相同的方式启动一个被锁定的操作prepare_data()),\r\n实现可插拔的业务逻辑。\r\n\r\n除了直接将 std::unique_lock\r\n作为返回值外，还有一种更高级、更封装的模式，称为“网关类”。其核心思想是：不直接返回\r\nstd::unique_lock（这暴露了实现细节），而是返回一个自定义的“网关”对象,\r\n它封装了 std::unique_lock，并在析构时自动释放锁。\r\nclass LockedDataAccess {private:    std::unique_lock&lt;std::mutex&gt; lock; // 锁是它的成员    ProtectedData&amp; data_ref;public:    // 构造函数是可移动的    LockedDataAccess(std::unique_lock&lt;std::mutex&gt; lk, ProtectedData&amp; data)        : lock(std::move(lk)), data_ref(data) {}    // 提供安全访问数据的函数    void write() { data_ref.do_write(); }    int read() { return data_ref.do_read(); }    // Gateway 对象本身也是可移动的};LockedDataAccess get_locked_data() {    std::unique_lock&lt;std::mutex&gt; lk(some_mutex);    // ...    return LockedDataAccess(std::move(lk), my_data);}void use_it() {    LockedDataAccess gateway = get_locked_data();    gateway.write();} // gateway 在此析构，其成员 lock 随之析构，释放锁\r\n锁的粒度\r\n这是在使用互斥量时需要权衡的一个核心设计问题。它不是一个有“唯一正确答案”的问题，而是一个关于性能和安全之间取舍的工程决策。\r\n细粒度锁\r\n(Fine-grained) vs. 粗粒度锁 (Coarse-grained)\r\n首先, 锁的粒度 (Lock Granularity)\r\n是一个描述“一个锁到底保护了多少数据”的术语。我们通常将锁的粒度分为两类：粗粒度锁\r\n和 细粒度锁。\r\n粗粒度锁 (Coarse-grained lock)：\r\n\r\n定义：用一个互斥量保护大量的数据。\r\n示例：一个全局互斥量保护程序中的所有共享数据；或者一个类的互斥量保护该类的所有成员变量。\r\n优点：\r\n\r\n简单：易于实现和推理，很难“漏掉”保护。\r\n安全：对于需要访问多个数据块的复杂操作，因为所有东西都被一个锁罩住，所以天生就是安全的。\r\n\r\n缺点：\r\n\r\n性能极差\r\n(严重瓶颈)：这会扼杀并发性。如果线程A想访问数据块1，线程B想访问完全不相关的数据块100，线程B也必须排队等待线程A释放那个唯一的锁。\r\n\r\n早期的Linux内核使用一个全局锁，导致双核系统的性能甚至不如两个单核系统。\r\n\r\n\r\n\r\n细粒度锁 (Fine-grained lock)：\r\n\r\n定义：使用多个互斥量，每个互斥量只保护一小部分数据。\r\n示例：一个DNS缓存（一个 std::map），不锁住整个 map，而是为 map\r\n中的每一条DNS记录分配一个单独的互斥量。\r\n优点：\r\n\r\n并发性高：线程A访问记录1和线程B访问记录2可以完全并行执行，因为它们获取的是不同的锁。\r\n\r\n缺点：\r\n\r\n复杂：如果一个操作需要同时访问记录1和记录2（例如，swap\r\n操作），你就必须同时获取两个锁，这立刻带来了死锁的风险（必须使用 3.2.4\r\n中的 std::lock）。\r\n开销：更多的互斥量对象会占用更多内存。\r\n\r\n\r\n一个关于链表的不同粒度锁: -\r\n细粒度锁可以为链表中的每个节点分配一个互斥量，这样线程在访问不同节点时就可以并行执行。\r\n- 但是,\r\n如果一个操作需要遍历整个链表（例如，搜索一个值），它必须依次获取每个节点的锁，这会导致复杂性和死锁风险增加。\r\n-\r\n而粗粒度锁则是为整个链表分配一个互斥量，任何线程在访问链表时都必须获取这个锁，导致并发性差。\r\n除了“锁多少数据”，粒度问题还包括“锁多长时间”。这是本节强调的另一个关键点。黄金准则是：在任何情况下，持有锁的时间应尽可能缩减到最小。\r\n并且,\r\n不要在持有锁的同时执行任何可能阻塞或耗时的操作。例如文件\r\nI/O、网络请求、数据库查询、等待用户输入、sleep()，甚至尝试获取另一个锁（除非你用了\r\nstd::lock 或有层次结构）。\r\n使用\r\nunique_lock::unlock() 和 lock() 临时释放锁\r\nstd::lock_guard\r\n无法解决“持有时间”的问题，因为它从构造到析构必须一直持有锁。\r\n而 std::unique_lock\r\n就是为此而生的。它允许你手动、临时地释放和重新获取锁。\r\nvoid get_and_process_data(){  // 1. 获取锁，进入受保护区域  std::unique_lock&lt;std::mutex&gt; my_lock(the_mutex);    // 2. 快速操作：从共享结构中复制/移动出所需数据  some_class data_to_process = get_next_data_chunk();    // 3. 关键！在慢速操作之前，手动释放锁  my_lock.unlock();     // 4. 耗时操作：在锁之外执行。  //    此时，其他线程可以自由地获取 a_mutex 来 get_next_data_chunk()  result_type result = process(data_to_process);    // 5. 关键！为写入结果，重新获取锁  //    这里会阻塞，直到锁可用  my_lock.lock();     // 6. 快速操作：将结果写回共享结构  write_result(data_to_process, result);} // 7. my_lock 在析构时，检查到自己仍持有锁，于是自动解锁\r\n这个模式是 std::unique_lock\r\n的一个核心用途，它完美地平衡了数据保护（在第2步和第6步）和并发性能（在第4步）。\r\n细粒度锁的陷阱：微妙的语义变化\r\n然而,\r\n当你试图将锁的粒度（特别是持有时间）降到最小时，你可能会在不经意间改变操作的含义。\r\n下面是一个operator==的细粒度锁优化实现：\r\nclass Y{private:  int some_detail;  mutable std::mutex m;  int get_detail() const  {    std::lock_guard&lt;std::mutex&gt; lock_a(m);  // 1. 只在获取时加锁    return some_detail;  } // 锁在这里释放public:  Y(int sd):some_detail(sd){}  friend bool operator==(Y const&amp; lhs, Y const&amp; rhs)  {    if(&amp;lhs == &amp;rhs) return true;    int const lhs_value = lhs.get_detail();  // 2. 获取 lhs (锁A，释放A)    int const rhs_value = rhs.get_detail();  // 3. 获取 rhs (锁B，释放B)    return lhs_value == rhs_value; // 4. 比较  }};\r\n优点（表面上的）：\r\n\r\n锁的持有时间极短（只在 get_detail 内部）。\r\n一次只持有一个锁，绝对不会死锁。\r\n\r\n缺点（致命的逻辑错误）：\r\n\r\n这个函数没有回答“lhs 和 rhs 在同一时刻是否相等？”\r\n它回答的是“lhs 在时间点T1 的值是否等于 rhs 在时间点T2 的值？”\r\n\r\n导致错误的条件竞争（逻辑竞争）：\r\n\r\n初始状态：lhs.some_detail = 10, rhs.some_detail = 20。\r\n线程A 执行到 lhs.get_detail()，得到 lhs_value 为 10。\r\n(上下文切换)\r\n线程B（另一个线程）执行 lhs.some_detail = 20; 和 rhs.some_detail =\r\n10;。\r\n(上下文切换)\r\n线程A 执行到 rhs.get_detail()，得到 rhs_value 为 10。\r\n线程A 执行 return lhs_value == rhs_value; (④)，即 return 10 ==\r\n10;。\r\n\r\n结果：函数返回 true，但 lhs 和 rhs 在任何时刻都不曾相等过。\r\n如果你真的需要原子性的比较（即比较它们在同一时刻的值），你必须同时锁住两者\r\nfriend bool operator==(Y const&amp; lhs, Y const&amp; rhs){    if(&amp;lhs == &amp;rhs) return true;    std::lock(lhs.m, rhs.m); // 同时锁住两者    std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m, std::adopt_lock);    std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock);    return lhs.some_detail == rhs.some_detail; // 在持有两个锁时比较}\r\n这个实现是逻辑正确的，但它的粒度更粗（同时持有两个锁，且持有时间更长）。\r\n总之, “锁的粒度”是一个没有完美答案的设计权衡：\r\n\r\n太粗：安全，但性能差。\r\n太细：性能好，但复杂（易死锁，易出现上述的逻辑错误）。\r\n持有时间太长：性能差（尤其是在I/O时）。\r\n持有时间太短：可能导致逻辑错误。\r\n\r\n你的工作是根据具体场景，选择一个“合适”的粒度。如果 std::mutex\r\n无法在性能和安全之间提供一个“合适”的平衡（例如，读多写少的情况），你就需要下一节中介绍的替代设施。\r\n保护共享数据的替代设施\r\n保护共享数据的初始化过程\r\n在上一节中，我们讨论的互斥量（std::mutex）是一种通用的保护机制，适用于数据会被反复读写的场景。\r\n然而，有一种非常特殊但常见的场景：数据在初始化后就几乎不再改变（通常是只读的）。例如，全局配置、单例对象、数据库连接等。\r\n一般来说,\r\n上述这样的资源（如数据库连接、全局配置）创建开销很大，我们不想在程序启动时就创建它，而是希望在第一次使用它时才创建。\r\n问题是：在多线程环境下，如何安全地处理这个“第一次”？\r\n本节就探讨了解决这个问题的错误方法和正确方法。\r\n延迟初始化 (Lazy\r\ninitialization)\r\n延迟初始化是一种设计模式，指的是推迟对象的创建或资源的分配，直到它们真正被需要的时候。\r\n在单线程代码中，这很简单： std::shared_ptr&lt;some_resource&gt; resource_ptr;void foo(){  if(!resource_ptr) // 检查是否已初始化  {    resource_ptr.reset(new some_resource); // 1. 未初始化，则初始化  }  resource_ptr-&gt;do_something();}\r\n在并发中, 我们可能会使用 std::mutex 这样尝试 std::shared_ptr&lt;some_resource&gt; resource_ptr;std::mutex resource_mutex;void foo(){  std::unique_lock&lt;std::mutex&gt; lk(resource_mutex); // 1. 每次调用都加锁  if(!resource_ptr)  {    resource_ptr.reset(new some_resource);   }  lk.unlock();  resource_ptr-&gt;do_something();}\r\n这样做功能上是正确的，线程安全。\r\n但是缺点是性能极差。资源只需要初始化一次，但这段代码迫使每一个调用\r\nfoo()\r\n的线程（即使是第1000个线程）都必须排队、获取互斥锁，仅仅是为了执行一次\r\nif(!resource_ptr)\r\n检查。这在初始化完成后造成了完全不必要的序列化和性能瓶颈。\r\n（陷阱）双重检查锁定\r\n(Double-Checked Locking) 的危害\r\n为了避免每次都加锁，一开始程序员们发明了一种叫做“双重检查锁定,\r\nDCLP”的模式： // 警告：这是未定义行为！void undefined_behaviour_with_double_checked_locking(){  if(!resource_ptr)  // 1. 第一次检查 (无锁)  {    std::lock_guard&lt;std::mutex&gt; lk(resource_mutex);    if(!resource_ptr)  // 2. 第二次检查 (有锁)    {      resource_ptr.reset(new some_resource);  // 3. 写入    }  }  resource_ptr-&gt;do_something();  // 4. 使用}\r\n这样的设计思路其实很自然：在“快路径”（资源已初始化）上，线程看到\r\nresource_ptr\r\n非空，就直接跳过判断去使用，完全避免了加锁，性能极高。只有“慢路径”（第一次初始化）才需要加锁。\r\n然而, 它是绝对错误的 : 这是一个数据竞争 (Data\r\nRace)。无锁的读取与有锁的写入之间没有同步。\r\n致命缺陷在于,\r\nCPU或编译器可能会进行指令重排。写入操作\r\nresource_ptr.reset(new some_resource) 包含两个步骤： - A. 分配内存并构造\r\nsome_resource 对象； - B. 将 resource_ptr 指向这块内存。\r\n假设线程B 执行到// 3.写入时，CPU/编译器可能先执行 B\r\n(写指针)，再执行 A (构造对象)。此时 resource_ptr\r\n已经非空，但它指向的内存上的 some_resource\r\n对象尚未构造完成！\r\n上下文切换后, 另一个线程A\r\n执行到// 1.第一次检查 (无锁)。它看到了一个非空的\r\nresource_ptr（因为线程B执行了B步骤）。线程A跳过锁，直接执行\r\nresource_ptr-&gt;do_something()。\r\n结果是：线程A在一个未构造完成的、半成品的对象上调用了成员函数，导致程序崩溃或数据损坏。\r\n为了解决上述问题, C++11 提出了两种可靠的解决方案。\r\n解决方案\r\n1：std::call_once 和 std::once_flag\r\n这是C++标准库提供的、专门用于“只执行一次”场景的工具。\r\n\r\nstd::once_flag：一个特殊的（不可拷贝、不可移动的）对象，用于存储“是否已执行过”的状态。\r\nstd::call_once(flag, function,\r\n…args)：一个函数，它保证 function\r\n在多线程环境下绝对只被执行一次。\r\n\r\nstd::shared_ptr&lt;some_resource&gt; resource_ptr;std::once_flag resource_flag;  // 1. 创建状态标志void init_resource() // 初始化的函数{  resource_ptr.reset(new some_resource);}void foo(){  // 2. 保证 init_resource() 只被调用一次  std::call_once(resource_flag, init_resource);   resource_ptr-&gt;do_something();}\r\n第一个调用 std::call_once 的线程会执行 init_resource 并设置\r\nresource_flag。\r\n其他同时调用 std::call_once 的线程会阻塞，直到 init_resource\r\n执行完毕。\r\n在此之后所有调用 std::call_once 的线程（例如第1000个线程）会看到\r\nresource_flag 已被设置，于是立即返回，几乎没有开销。\r\n这完美解决了“尝试1”的性能瓶颈，且完全线程安全。\r\n并且, std::call_once\r\n同样适用于类的成员变量函数（延迟初始化数据库连接）。\r\nclass X{private:  connection_handle connection;  std::once_flag connection_init_flag;  void open_connection() { /* ... */ }public:  void send_data(data_packet const&amp; data) // 1  {    // 2. 调用成员函数，需传入 this 指针    std::call_once(connection_init_flag, &amp;X::open_connection, this);     connection.send_data(data);  }  // ... (receive_data 类似) ...}; 无论是 send_data 还是 receive_data\r\n被首先调用，std::call_once 都会保证 open_connection 只被执行一次。\r\n解决方案\r\n2：线程安全的 static 局部变量初始化\r\n对于“我只需要一个全局实例”的场景，C++11提供了一个更简单、更优雅的语法,\r\n也就是 C++11 标准的保证：\r\nC++11强制要求 static\r\n局部变量的初始化必须是线程安全的。\r\nclass my_class;my_class&amp; get_my_class_instance(){  // 编译器会自动保证这里的初始化是线程安全的  // (通常内部实现就是用的 call_once)  static my_class instance;   return instance;}\r\n当多个线程同时第一次调用 get_my_class_instance()\r\n时，C++运行时会保证只有一个线程会执行 my_class\r\n的构造函数，其他线程会等待。\r\n初始化完成后，所有后续调用都会直接返回 instance 的引用。\r\n这是实现线程安全“单例模式” (Singleton) 的最简洁、最推荐的方法。\r\n保护很少更新的数据结构\r\n继上面讨论了“只初始化一次”的场景后，本节讨论了另一种常见的特殊场景：“读多写少”\r\n(Read-Mostly)。\r\n想象一个数据结构（如DNS缓存、系统配置、字典等），它需要被大量的线程频繁地读取，但只会被极少数的线程偶尔地写入（更新）。\r\n如果使用 std::mutex, 它提供的是独占访问 (Exclusive\r\nAccess)。\r\n这意味着，如果线程A正在读取数据（持有了锁），线程B也只想读取数据（这对数据安全没有任何威胁），线程B也必须排队等待。\r\n在“读多写少”的场景下，所有的“读者”线程都会被迫序列化（排队），这严重扼杀了并发性，使得多线程的读取性能和单线程一样差，甚至更糟（因为锁的开销）。\r\n读者-写者锁 (Reader-Writer\r\nMutex)\r\n为了解决这个特定问题，我们需要一种更“聪明”的锁，它能区分“读者”和“写者”：\r\n核心思想：\r\n\r\n允许多个读者线程同时、并发地访问数据。\r\n只允许一个写者线程独占地访问数据。\r\n\r\n工作规则：\r\n\r\n规则1\r\n(读-读并发)：如果一个线程A持有了“读锁”，其他线程B、C、D也可以立即获得“读锁”。\r\n规则2\r\n(写-写互斥)：如果一个线程A持有了“写锁”，其他线程（无论是读者还是写者）都必须等待。\r\n规则3\r\n(读-写互斥)：如果任何线程持有了“读锁”（哪怕只有一个），一个试图获取“写锁”的线程必须等待，直到所有读者都释放了锁。\r\n\r\nstd::shared_mutex (C++17)\r\n虽然 C++11 标准库中没有提供这种互斥量，但从 C++17 开始，标准库提供了\r\nstd::shared_mutex, 它实现了上述的读者-写者锁机制。而 std::shared_lock\r\n则是与之配套的读锁 RAII 包装器。\r\n\r\n头文件：std::shared_mutex 和\r\nstd::shared_lock 都在 &lt;shared_mutex&gt;\r\n头文件中声明。\r\n互斥量本身：std::shared_mutex\r\nRAII\r\n包装器（读者）：std::shared_lock&lt;std::shared_mutex&gt;,\r\n这是 std::lock_guard 的“读者版本”。\r\n\r\n它的构造函数获取一个共享锁 (Shared Lock) 或称读锁\r\n(Read Lock)。\r\n\r\nRAII\r\n包装器（写者）：std::lock_guard&lt;std::shared_mutex&gt; 或\r\nstd::unique_lock&lt;std::shared_mutex&gt;\r\n\r\n它们的构造函数获取一个独占锁 (Exclusive Lock)\r\n或称写锁 (Write Lock)。\r\n\r\n\r\n#include &lt;map&gt;#include &lt;string&gt;#include &lt;mutex&gt;#include &lt;shared_mutex&gt; // 引入 C++17 的 &lt;shared_mutex&gt;class dns_entry;class dns_cache{  std::map&lt;std::string, dns_entry&gt; entries;  mutable std::shared_mutex entry_mutex; // 使用 std::shared_mutexpublic:  // \"读者\" 函数 (高频)  dns_entry find_entry(std::string const&amp; domain) const  {    // 1. 获取一个“共享锁” (读锁)    std::shared_lock&lt;std::shared_mutex&gt; lk(entry_mutex);         std::map&lt;std::string, dns_entry&gt;::const_iterator const it =        entries.find(domain);    return (it == entries.end()) ? dns_entry() : it-&gt;second;  } // lk 析构，释放“共享锁”  // \"写者\" 函数 (低频)  void update_or_add_entry(std::string const&amp; domain,                           dns_entry const&amp; dns_details)  {    // 2. 获取一个“独占锁” (写锁)    std::lock_guard&lt;std::shared_mutex&gt; lk(entry_mutex);         entries[domain] = dns_details;  } // lk 析构，释放“独占锁”};\r\n在上面的代码中, dns_cache 类使用 std::shared_mutex 来保护其内部的\r\nentries 映射。如果多个线程同时调用\r\nfind_entry()，它们可以并发地获取共享锁，从而实现高效的读取。\r\n不过, 需要注意的是, std::shared_mutex 比 std::mutex\r\n更复杂，管理锁状态（有多少读者？有没有写者在等？）的内部开销更大。\r\n因此是否能提升性能，完全取决于实际负载。\r\n如果“写”操作的比例稍微高一点，或者处理器核心数较少，那么读者-写者锁的额外开销可能会抵消并发读取带来的好处，甚至可能慢于简单的\r\nstd::mutex。\r\n在使用它之前，最好在目标系统上进行性能分析\r\n(Profiling)，以确保它真的带来了好处。\r\n嵌套锁\r\n这一节讨论的是一个在面向对象编程中很常见的问题：当一个已经持有锁的函数，又调用了同一个类中的另一个也需要锁的函数时，会发生什么？\r\n问题的根源来自 std::mutex 的“非递归”性。\r\nstd::mutex 是一个非递归互斥量。这意味着，如果一个线程已经持有了某个\r\nstd::mutex 的锁，它绝对不能尝试第二次 lock()\r\n这个互斥量,\r\n这样做会导致未定义行为，在很多平台上程序会立即死锁或崩溃。\r\n假如你有一个类，它用一个 std::mutex m\r\n来保护其所有成员数据。你遵循了之前的建议，让每个 public\r\n成员函数都在函数开头使用 std::lock_guard 来加锁。\r\n问题来了：假设 public 成员函数 func1() 在其实现中，需要调用另一个\r\npublic 成员函数 func2()。\r\nclass MyClass {private:    std::mutex m;    int data;public:    void func2() {        std::lock_guard&lt;std::mutex&gt; lock(m); // 2. func2 尝试第二次加锁        // ... (操作 data)    }    void func1() {        std::lock_guard&lt;std::mutex&gt; lock(m); // 1. func1 第一次加锁        // ... (操作 data)        func2(); // 3. 调用 func2        // ...    } // 4. func1 结束，释放锁};MyClass obj;obj.func1(); // 5. 线程在这里崩溃或死锁！\r\nfunc1 调用 func2(), func2 的 lock_guard 再次尝试获取锁\r\nm。由于线程已经持有 m，这个第二次 lock() 操作导致了未定义行为。\r\nstd::recursive_mutex\r\n为了解决上述问题,\r\nC++标准库提供了std::recursive_mutex（递归互斥量）。\r\nstd::recursive_mutex\r\n允许同一个线程多次获取同一个锁。它在内部维护一个“锁定计数器”。\r\n\r\nlock()：如果锁未被持有，线程获取它，计数器设为1。如果锁已被本线程持有，计数器+1。如果锁被其他线程持有，则阻塞。\r\nunlock()：计数器-1。只有当计数器归零时，这个锁才会被真正释放，其他线程才能获取它。\r\n\r\nclass MyClass_Recursive {private:    std::recursive_mutex m; // 使用递归互斥量public:    void func2() {        std::lock_guard&lt;std::recursive_mutex&gt; lock(m); // 2. 成功！(计数器=2)        // ...    } // 3. func2 析构，计数器=1    void func1() {        std::lock_guard&lt;std::recursive_mutex&gt; lock(m); // 1. 成功！(计数器=1)        // ...        func2();        // ...    } // 4. func1 析构，计数器=0，锁被释放};\r\n在使用时, 我们可以简单地将 std::mutex m; 替换为 std::recursive_mutex\r\nm;\r\nstd::lock_guard（和 std::unique_lock）可以完美地配合\r\nstd::recursive_mutex 工作，它们会正确地处理计数。\r\n（警告）嵌套锁通常是设计缺陷的标志\r\n尽管 std::recursive_mutex\r\n解决了燃眉之急，但强烈建议不要使用它。std::recursive_mutex\r\n往往是糟糕设计的标志。\r\n回想一下，我们加锁的根本原因是什么？是为了在我们修改数据时，保护数据结构，因为在修改的中间过程，类的不变量（必须保持的规则）可能会被暂时破坏。\r\n在 func1 的例子中：\r\n\r\nfunc1\r\n加锁（计数器=1），因为它准备修改数据，不变量可能即将被破坏。\r\nfunc1 修改了数据A，但还没来得及修改数据B（此时不变量已破坏）。\r\nfunc1 调用了 func2。\r\nfunc2\r\n成功加锁（计数器=2），它开始在一个不变量已被破坏的对象上执行操作！\r\n\r\n这是具有极大风险的：func2\r\n的代码很可能是基于“类的所有不变量都保持完好”这个假设来编写的。但当它被\r\nfunc1 在“中间状态”调用时，这个假设不成立了，可能导致 func2\r\n产生错误的计算或逻辑混乱。\r\n更好的解决方案是重构代码,\r\n分离“加锁逻辑”和“工作逻辑”。\r\n我们提取出一个新的私有 (private)\r\n成员函数，这个函数不加锁，它假定调用者已经持有了锁。\r\nclass MyClass_Refactored {private:    std::mutex m; // 1. 换回 std::mutex    int data;    // 2. 新的 private 辅助函数，它不加锁！    // 命名中的 \"_impl\" 或 \"_unsafe\" 常用    void func2_impl() {         // 假设 m 已经被锁住        // ... (操作 data)    }public:    // 3. func2 的 public 版本只负责加锁    void func2() {        std::lock_guard&lt;std::mutex&gt; lock(m);        func2_impl(); // 调用无锁的实现    }    void func1() {        std::lock_guard&lt;std::mutex&gt; lock(m); // 4. func1 加锁        // ... (操作 data)                func2_impl(); // 5. 直接调用无锁的实现                // ...    }};\r\n这种设计更清晰地分离了职责：public\r\n函数负责接口和线程安全（加锁），private\r\n函数负责核心实现（假定已安全）。\r\n这也确保了 func2_impl 要么被 func1\r\n在一个完整的、原子的操作中调用，要么被 func2\r\n在一个完整的、原子的操作中调用，不变量始终受到保护。\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"函数和栈","url":"/2025/10/11/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%87%BD%E6%95%B0/%E5%87%BD%E6%95%B0%E5%92%8C%E6%A0%88/","content":"我们通过下面这张图来整体理解函数调用和栈的关系： \r\n这张图非常经典，它清晰地展示了计算机程序在执行函数调用时，内存中栈（Stack）的结构和工作原理。图中描述了一个场景：一个名为\r\nDrawSquare 的函数在执行过程中，调用了另一个名为 DrawLine 的函数。\r\n我们先理解下面两个概念: 函数调用栈 (Call Stack) 和 栈帧 (Stack\r\nFrame)。\r\n\r\n函数调用栈 (Call Stack)：一块特殊的内存区域，遵循后进先出 (LIFO,\r\nLast-In, First-Out)\r\n的原则。每当一个函数被调用，就会在栈顶为其分配一块内存；当函数返回时，这块内存会被释放。\r\n栈帧 (Stack\r\nFrame)：每次函数调用时在栈上创建的这块专属内存区域，就称为一个栈帧。它包含了该次函数调用所需的所有信息。每个栈帧通常包含三个主要部分,\r\n且它们按照以下顺序从栈底到栈顶排列：\r\n\r\n参数 (Parameters)：存放调用者函数传递给被调用函数的值。在图中,\r\nParameters for DrawSquare 是调用 DrawSquare 时传入的参数。Parameters for\r\nDrawLine 是 DrawSquare 函数调用 DrawLine 时传入的参数。\r\n返回地址 (Return Address):\r\n这是至关重要的一部分。它存储了函数调用指令的下一条指令在内存中的地址。当被调用的函数执行完毕后，CPU\r\n就通过读取这个返回地址，知道应该跳转回哪里继续执行调用者函数的代码。在图中,\r\nDrawLine 栈帧中的 Return Address 指向 DrawSquare 函数中调用 DrawLine\r\n语句的下一行代码。\r\n局部变量 (Locals):\r\n存放函数内部定义的局部变量。这些变量在函数开始执行时创建，在函数返回时被销毁，其生命周期与函数调用绑定。在图中,\r\nLocals of DrawLine 存放的是 DrawLine 函数内部声明的变量。\r\n\r\n\r\n图中展示了两个栈帧，DrawLine 的栈帧位于 DrawSquare\r\n的栈帧之上（在内存地址较低的一侧），这表明 DrawSquare 函数调用了\r\nDrawLine 函数。\r\n除此之外, 图中还标示了两个非常重要的 CPU\r\n寄存器，它们是管理栈的关键。\r\n\r\n栈指针/栈顶指针 (Stack Pointer,\r\nSP)\r\n\r\n作用：始终指向栈的顶部 (top of stack)。在图中，它指向 DrawLine\r\n栈帧中局部变量区域的末端。\r\n行为：当函数分配局部变量或进行新的函数调用（压栈，push）时，SP\r\n会向低地址方向移动（栈增长）。当函数返回（出栈，pop）时，SP\r\n会向高地址方向移动（栈收缩）。\r\n\r\n帧指针 (Frame Pointer, FP)\r\n\r\n作用：也称为基址指针 (Base Pointer,\r\nBP)。它指向当前活动栈帧(即位于栈顶的,\r\n最后被调用且正在执行的那个函数)的一个固定位置，通常是栈帧的底部（或返回地址和参数之间的边界）。\r\n意义：FP\r\n提供了一个稳定的基准地址。在函数执行期间，SP\r\n可能会因为局部变量的动态分配而移动，但 FP\r\n保持不变。因此，程序可以通过 FP\r\n以固定的偏移量来准确地访问参数（正向偏移）和局部变量（负向偏移），而不受\r\nSP 移动的影响。\r\n\r\n\r\n结合这张图，我们可以还原整个函数调用的动态过程：\r\n\r\n调用 DrawSquare：DrawSquare\r\n的参数被压入栈中。\r\n\r\n调用指令 call DrawSquare 执行，将返回地址（main\r\n函数或其他调用者的下一条指令地址）压入栈中。\r\nDrawSquare\r\n函数开始执行，创建自己的栈帧，分配局部变量空间。FP 和\r\nSP 指针更新，指向这个新栈帧。\r\n\r\nDrawSquare 调用 DrawLine (图示的状态)：DrawSquare 将调用 DrawLine\r\n所需的参数压入栈中。\r\n\r\n执行 call DrawLine 指令，将返回地址（DrawSquare\r\n中的下一条指令地址）压入栈中。\r\nDrawLine 函数开始执行，在 DrawSquare\r\n栈帧的上方创建自己的栈帧，并分配局部变量空间。\r\n\r\nFP 和 SP\r\n指针再次更新，指向最顶部的 DrawLine\r\n栈帧。这正是图中捕捉到的瞬间。\r\nDrawLine 返回：DrawLine 函数执行完毕,\r\n它的栈帧被销毁（出栈）。SP 和 FP\r\n会恢复到指向 DrawSquare 栈帧的状态。CPU 读取 DrawLine\r\n栈帧中保存的返回地址，并跳转到该地址，回到 DrawSquare\r\n中继续执行。\r\nDrawSquare 返回：DrawSquare\r\n执行完毕，其栈帧被销毁，控制权返回给最初的调用者。\r\n\r\n","categories":["CPP","函数"],"tags":["CPP"]},{"title":"Ucontext","url":"/2025/10/11/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%8D%8F%E7%A8%8B/Ucontext/","content":"ucontext 是一套定义在 &lt;ucontext.h&gt; 头文件中的 C\r\n语言函数库，它属于 POSIX\r\n标准的一部分（尽管在后续标准中被标记为“过时”）。它的核心功能是允许程序员在用户态（User\r\nSpace）直接、显式地控制程序的执行上下文（Execution\r\nContext）。\r\n为了理解这一点，我们可以将程序的一次执行想象成一个“任务”。这个任务包含了它继续执行下去所需要的一切信息：\r\n\r\n当前代码执行到哪一行了？\r\n(由程序计数器PC寄存器记录)\r\n当前的局部变量、函数参数是什么？\r\n(存储在程序的栈上，由栈指针SP寄存器管理)\r\n计算过程中的中间值是多少？\r\n(存储在各种通用CPU寄存器中)\r\n\r\n执行上下文就是这些信息在某个瞬间的“快照”。ucontext\r\n的本质，就是提供了一套工具，让我们能够保存（存档）、恢复（读档）和创建（新游戏）这些快照。\r\n这套机制是实现用户级线程（User-level\r\nThreads）或协程（Coroutines）的基石，因为它使得任务切换完全在程序内部完成，无需陷入操作系统内核，从而大大降低了切换的开销。\r\n核心组件\r\nucontext 主要由一个核心结构体和四个主要函数组成。\r\n\r\n结构体 ucontext_t #include &lt;ucontext.h&gt;typedef struct ucontext {    struct ucontext *uc_link;   // 指向后继上下文    sigset_t uc_sigmask;        // 信号屏蔽集    stack_t uc_stack;           // 栈信息    mcontext_t uc_mcontext;     // 机器上下文（寄存器状态）    ...} ucontext_t;\r\n\r\n这是用来存储上下文“快照”的容器。你可以把它理解为一个“存档文件”。它的主要成员包括：\r\n\r\nmcontext_t uc_mcontext:\r\n这是最核心的部分，存储了所有平台相关的CPU寄存器状态（如EIP/RIP,\r\nESP/RSP,\r\nEAX/RAX等）。这是上下文的真正“快照”数据。\r\nstack_t uc_stack:\r\n描述了该上下文所使用的栈空间。包含了栈的起始地址\r\n(ss_sp) 和大小\r\n(ss_size)。每个独立的执行流（协程）都必须有自己独立的栈。\r\nsigset_t uc_sigmask:\r\n保存了该上下文的信号屏蔽集。当切换到这个上下文时，进程的信号屏蔽集也会被恢复。\r\nucontext_t *uc_link: 指向一个“后继”上下文,\r\n即返回后继续执行的位置。如果当前上下文的函数执行完毕并正常返回，程序会自动激活\r\nuc_link 指向的上下文。如果 uc_link 为\r\nNULL，则当前协程执行完毕后整个进程会退出。\r\n\r\n\r\n主要函数\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n函数\r\n功能比喻\r\n详细解释\r\n\r\n\r\n\r\n\r\nint getcontext(ucontext_t *ucp)\r\n存档 (Save)\r\n捕获当前执行上下文，将所有信息保存到\r\nucp 指向的结构体中。用于保存当前进度或创建新上下文。\r\n\r\n\r\nint setcontext(const ucontext_t *ucp)\r\n读档 (Load)\r\n丢弃当前上下文，无条件加载\r\nucp\r\n中的快照并恢复执行。成功后不会返回，因为执行流已被新上下文取代。\r\n\r\n\r\nvoid makecontext(ucontext_t *ucp, void (*func)(), int argc, ...)\r\n创建新任务 (New Game)\r\n修改通过 getcontext 获取的\r\nucp，将其与新函数\r\nfunc 绑定。激活时执行\r\nfunc。绑定前需手动分配栈空间和设置后继上下文。\r\n\r\n\r\nint swapcontext(ucontext_t *oucp, const ucontext_t *ucp)\r\n切换任务 (Switch)\r\n原子地保存当前上下文到\r\noucp，并加载激活\r\nucp\r\n指向的新上下文。是协程调度的核心。\r\n\r\n\r\n\r\n示例\r\n下面是一个简单的示例，展示了如何使用 ucontext\r\n实现协程之间的切换：\r\n#include &lt;stdio.h&gt;#include &lt;ucontext.h&gt;#include &lt;unistd.h&gt;// 为每个协程准备一个上下文结构体ucontext_t main_context, coroutine1_context, coroutine2_context;// 协程的栈空间char coroutine1_stack[16384];char coroutine2_stack[16384];// 协程函数1void coroutine_func1() {    for (int i = 0; i &lt; 5; ++i) {        printf(\"Coroutine 1: ping %d\\n\", i);        // 保存当前状态到 coroutine1_context，并切换到 coroutine2_context        swapcontext(&amp;coroutine1_context, &amp;coroutine2_context);    }}// 协程函数2void coroutine_func2() {    for (int i = 0; i &lt; 5; ++i) {        printf(\"Coroutine 2: pong %d\\n\", i);        // 保存当前状态到 coroutine2_context，并切换到 coroutine1_context        swapcontext(&amp;coroutine2_context, &amp;coroutine1_context);    }}int main() {    // 1. 初始化协程1的上下文    // 步骤说明：首先获取一个当前上下文作为模板，以确保所有字段都被正确初始化。    getcontext(&amp;coroutine1_context);        // 步骤说明：为协程1设置独立的栈空间。这是必须的，否则它的局部变量会与main函数或其他协程冲突。    coroutine1_context.uc_stack.ss_sp = coroutine1_stack;    coroutine1_context.uc_stack.ss_size = sizeof(coroutine1_stack);        // 步骤说明：设置后继上下文。当coroutine_func1执行完毕后，程序会返回到main_context继续执行。    // 如果设置为 NULL，coroutine_func1执行完毕后会导致程序退出。    coroutine1_context.uc_link = &amp;main_context;        // 步骤说明：将该上下文与协程函数coroutine_func1绑定。    makecontext(&amp;coroutine1_context, coroutine_func1, 0);    // 2. 初始化协程2的上下文 (步骤同上)    getcontext(&amp;coroutine2_context);    coroutine2_context.uc_stack.ss_sp = coroutine2_stack;    coroutine2_context.uc_stack.ss_size = sizeof(coroutine2_stack);    coroutine2_context.uc_link = &amp;main_context;    makecontext(&amp;coroutine2_context, coroutine_func2, 0);    printf(\"Main: Starting coroutines\\n\");    // 3. 启动协程    // 步骤说明：保存main函数的当前状态到main_context，并切换到协程1开始执行。    // 这是协程的入口点。    swapcontext(&amp;main_context, &amp;coroutine1_context);    printf(\"Main: Coroutines finished\\n\");    return 0;}\r\n预期输出： Main: Starting coroutinesCoroutine 1: ping 0Coroutine 2: pong 0Coroutine 1: ping 1Coroutine 2: pong 1Coroutine 1: ping 2Coroutine 2: pong 2Coroutine 1: ping 3Coroutine 2: pong 3Coroutine 1: ping 4Coroutine 2: pong 4Main: Coroutines finished\r\n首先, main 函数初始化了两个协程的上下文，并为它们分配了独立的栈。main\r\n调用 swapcontext(&amp;main_context,\r\n&amp;coroutine1_context)，保存自己的状态，然后跳转到 coroutine_func1\r\n开始执行。\r\n接着 coroutine_func1 打印 “ping 0”，然后调用\r\nswapcontext，保存自己的状态（此时它在循环的第一次迭代中），并跳转到\r\ncoroutine_func2。coroutine_func2 从头开始执行，打印 “pong 0”，然后调用\r\nswapcontext，保存自己的状态，并跳转回 coroutine_func1。\r\n在这里, coroutine_func1 从它上次离开的地方（swapcontext\r\n调用之后）继续执行，进入下一次循环，打印 “ping 1”，然后再次切换。\r\n这个“乒乓”过程一直持续，直到两个协程的循环都结束。coroutine_func2\r\n最后一次切换回 coroutine_func1，coroutine_func1 循环结束，函数返回。\r\n由于之前设置了 coroutine1_context.uc_link = &amp;main_context，当\r\ncoroutine_func1 返回时，程序会自动激活 main_context。main\r\n函数从它当初调用 swapcontext 的地方继续执行，打印 “Main: Coroutines\r\nfinished”，程序结束。\r\n\r\n在某种程度上, getcontext() + makecontext()的组合类似于 Linux 下的\r\nfork() + exec()，它们都遵循复制–修改的操作逻辑 getcontext()\r\n获取当前线程的执行上下文“快照”,\r\n然后程序员手动修改这个上下文结构体，为其分配一个新的栈空间，并使用\r\nmakecontext()\r\n将其与一个全新的函数绑定。这创造了一个新的、待执行的逻辑分支（协程）。\r\n而 fork()\r\n则是复制当前进程的所有资源（包括内存空间、文件描述符等），然后父进程使用\r\nexec() 加载一个全新的程序映像，开始执行一个完全不同的代码路径。\r\n\r\n"},{"title":"shared_ptr与weak_ptr","url":"/2025/09/27/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/shared_ptr%E4%B8%8Eweak_ptr/","content":"std::shared_ptr：共享所有权的管理者\r\nstd::shared_ptr 是一种拥有共享所有权的智能指针。这意味着多个\r\nshared_ptr\r\n实例可以共同拥有和管理同一个动态分配的对象。当最后一个指向该对象的\r\nshared_ptr 被销毁或重置时，该对象会被自动释放。\r\n核心理念：引用计数\r\nshared_ptr 的核心机制是引用计数（Reference\r\nCounting）。它通过一个“控制块”来实现这一机制。\r\n控制块（Control\r\nBlock）是一个与被管理对象分离的内存块,\r\n存储在堆上。当第一个 shared_ptr\r\n创建时，控制块也随之被创建。它包含以下关键信息：\r\n\r\n强引用计数（Strong Reference Count）：记录有多少个 shared_ptr\r\n正指向同一个对象。\r\n弱引用计数（Weak Reference Count）：记录有多少个 weak_ptr\r\n正在“观察”这个对象。\r\n指向被管理对象的指针。\r\n（可选）自定义删除器的指针。\r\n\r\n一般来说, 引用计数和控制块的工作流程如下：\r\n\r\n当一个新的 shared_ptr\r\n创建或通过拷贝构造或拷贝赋值指向一个已有对象时，强引用计数 +1。\r\n当一个 shared_ptr\r\n被销毁（例如离开作用域）、被重置（reset()）或指向其他对象时，强引用计数\r\n-1。\r\n当强引用计数变为 0 时，shared_ptr\r\n会自动调用删除器（默认为 delete）来释放被管理的对象。\r\n当弱引用计数和强引用计数都变为 0 时，控制块本身才会被释放。\r\n\r\n这种引用计数的加减还是线程安全的：shared_ptr\r\n的引用计数增减操作是原子的，这意味着在多线程环境下，仅对 shared_ptr\r\n对象本身进行拷贝、赋值和销毁是线程安全的，不会导致引用计数出错。但它并不保护被管理对象本身，如果多线程要修改对象内容，仍需手动加锁。\r\n创建 shared_ptr\r\n函数模板 std::make_shared 的函数原型如下: namespace std {    template &lt;typename T, typename... Args&gt;    std::shared_ptr&lt;T&gt; make_shared(Args&amp;&amp;... args);}\r\nT是要指向的对象的类型,\r\nargs是传给T这个类构造函数的参数（如果有的话）。\r\n#include &lt;memory&gt;    // 存放智能指针相关#include &lt;iostream&gt;class MyClass {public:    MyClass() { std::cout &lt;&lt; \"MyClass 构造\" &lt;&lt; std::endl; }    ~MyClass() { std::cout &lt;&lt; \"MyClass 析构\" &lt;&lt; std::endl; }    void greet() { std::cout &lt;&lt; \"Hello!\" &lt;&lt; std::endl; }};int main() {    // 推荐方式：使用 std::make_shared    // 优点：1. 更高效（对象和控制块一次性分配内存） 2. 异常安全    std::shared_ptr&lt;MyClass&gt; sp1 = std::make_shared&lt;MyClass&gt;();        // 不太推荐的方式：使用 new, 虽然最终也能通过shared_ptr安全管理, 但是会分两次（一次 new T()，一次为控制块）分配内存    std::shared_ptr&lt;MyClass&gt; sp2(new MyClass());     auto sp3 = sp1; // 直接拷贝构造    // 创建完毕后, 这两个指针指向的对象都在堆上, 控制块也在堆上}\r\n对于std::shared_ptr, 还有一些需要了解但是不太常用的接口: - 通过 get()\r\n方法来获取原始指针，适用于和旧版C语言库等只接受原始指针的接口交互 - 通过\r\nreset() 来减少一个强引用计数， 适用于提前终止对资源的管理 -\r\n通过use_count()来查看一个对象的引用计数。\r\n共享所有权\r\n// 创建一个 shared_ptrstd::shared_ptr&lt;MyClass&gt; sp1 = std::make_shared&lt;MyClass&gt;();std::cout &lt;&lt; \"sp1 创建后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 1{    // sp2 通过拷贝 sp1 创建    std::shared_ptr&lt;MyClass&gt; sp2 = sp1;    std::cout &lt;&lt; \"sp2 创建后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 2        sp2-&gt;greet(); // 可以像普通指针一样使用} // sp2 在这里离开作用域并被销毁std::cout &lt;&lt; \"sp2 销毁后, 引用计数: \" &lt;&lt; sp1.use_count() &lt;&lt; std::endl; // 输出: 1// sp1 在 main 函数结束时销毁，引用计数变为0，MyClass 对象被析构\r\n优点： - 自动管理内存，有效防止内存泄漏。 -\r\n易于使用，可以像普通指针一样操作。 - 明确了资源的“共享所有权”语义。\r\n但是, 如果只使用std::shared_ptr, 会存在一个难以察觉的陷阱:\r\n循环引用（Circular Reference）, 这是 shared_ptr 最大的问题，也是\r\nweak_ptr 存在的原因。\r\n循环引用（Circular Reference）\r\n如下是一个双向链表的实现代码 #include &lt;iostream&gt;#include &lt;memory&gt;struct Node {    int value;    // 错误的方式：前后指针都使用 shared_ptr    std::shared_ptr&lt;Node&gt; next;    std::shared_ptr&lt;Node&gt; prev;    Node(int v) : value(v) {        std::cout &lt;&lt; \"构造函数: Node(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }    ~Node() {        std::cout &lt;&lt; \"析构函数: ~Node(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }};void create_leaky_list() {    std::cout &lt;&lt; \"--- 进入 create_leaky_list 函数 ---\" &lt;&lt; std::endl;        // 创建两个节点    auto node1 = std::make_shared&lt;Node&gt;(10); // Node(10) 的强引用计数为 1    auto node2 = std::make_shared&lt;Node&gt;(20); // Node(20) 的强引用计数为 1    // 将它们互相连接，形成双向链表    node1-&gt;next = node2; // Node(20) 的强引用计数变为 2 (来自 node2 和 node1-&gt;next)    node2-&gt;prev = node1; // Node(10) 的强引用计数变为 2 (来自 node1 和 node2-&gt;prev)        std::cout &lt;&lt; \"连接后, Node(10) 的引用计数: \" &lt;&lt; node1.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"连接后, Node(20) 的引用计数: \" &lt;&lt; node2.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"--- 准备离开 create_leaky_list 函数 ---\" &lt;&lt; std::endl;}int main() {    create_leaky_list();    std::cout &lt;&lt; \"\\n--- create_leaky_list 函数已结束 ---\" &lt;&lt; std::endl;    std::cout &lt;&lt; \"程序即将退出，检查是否有析构函数被调用...\" &lt;&lt; std::endl;    return 0;} 当 create_leaky_list\r\n函数结束时，栈上的 node1 和 node2 两个 shared_ptr\r\n指针变量被销毁(指向的堆上的对象并没有)。node1 销毁，导致 Node(10)\r\n的强引用计数从 2 降为 1。但不为 0，因为 Node(20)-&gt;prev 仍然指向它;\r\nnode2 销毁，导致 Node(20) 的强引用计数从 2 降为 1。但不为 0，因为\r\nNode(10)-&gt;next 仍然指向它。\r\n最终结果是,\r\n由于两个节点(对象)的强引用计数都无法归零，它们的析构函数永远不会被调用，导致它们所占用的内存无法被释放。\r\nshared_from_this()\r\n它的作用是: 在类的成员函数中安全地获取一个指向自己（this）的\r\nstd::shared_ptr 智能指针。\r\n先看一个错误示范: #include &lt;iostream&gt;#include &lt;memory&gt;struct A {    void foo() {        // ❌ 自己 new 一个 shared_ptr(this)        std::shared_ptr&lt;A&gt; p(this);        std::cout &lt;&lt; \"use_count = \" &lt;&lt; p.use_count() &lt;&lt; std::endl;    }};int main() {    auto p1 = std::make_shared&lt;A&gt;();    p1-&gt;foo();  // 错误！} 外部的 p1 和内部 p\r\n各自维护独立的引用计数。p\r\n析构时会释放对象内存。而外部的 p1 还以为对象存在，结果访问已被释放的内存\r\n→ 崩溃！\r\n正确的做法是让类 A 继承自\r\nstd::enable_shared_from_this，这样就可以使用 shared_from_this()\r\n方法来获取一个指向自己的 shared_ptr: #include &lt;iostream&gt;#include &lt;memory&gt;struct A : public std::enable_shared_from_this&lt;A&gt; {    void foo() {        std::shared_ptr&lt;A&gt; p = shared_from_this();  // ✅ 正确        std::cout &lt;&lt; \"use_count = \" &lt;&lt; p.use_count() &lt;&lt; std::endl;    }};int main() {    auto p1 = std::make_shared&lt;A&gt;();    p1-&gt;foo();  // use_count = 2} shared_from_this()\r\n会返回一个新的 std::shared_ptr，它与外部的 p1\r\n共享同一个控制块（引用计数）。\r\n其内部实现大致如下: class enable_shared_from_this {protected:    std::weak_ptr&lt;T&gt; weak_this;  // 不增加引用计数public:    std::shared_ptr&lt;T&gt; shared_from_this() {        return std::shared_ptr&lt;T&gt;(weak_this);    }}; 当你用 std::make_shared()\r\n创建对象时，shared_ptr 会自动把自己的弱引用 weak_this 填进去。这样\r\nshared_from_this() 就能安全地从弱引用里恢复出共享指针。\r\n一般来说, 只有当类的对象确实会被 shared_ptr\r\n管理时，才应该使用 enable_shared_from_this，否则调用\r\nshared_from_this() 会抛出异常。适用于需要在类的成员函数中获取 shared_ptr\r\n的场景，比如实现观察者模式、回调函数等。\r\nstd::weak_ptr：打破循环引用的观察者\r\nstd::weak_ptr\r\n是一种非拥有型的智能指针。它像一个“观察者”，可以指向一个由\r\nshared_ptr 管理的对象，但不会增加对象的强引用计数。\r\n也就是说, 这种指针是一种弱引用:\r\n\r\nweak_ptr 的存在不会影响对象的生命周期。它只是监视对象是否存在。\r\n它指向与 shared_ptr\r\n相同的控制块，并通过创建和销毁来增减控制块中的弱引用计数。\r\n你不能直接通过 weak_ptr 访问对象（没有 * 或\r\n-&gt; 操作符），因为对象可能随时被销毁。\r\n\r\n创建 weak_ptr\r\n和访问对象（核心操作：lock()）\r\nweak_ptr 只能从 shared_ptr 或另一个 weak_ptr 构造,\r\n而不能构造一个来指向某个新对象 std::shared_ptr&lt;int&gt; sp = std::make_shared&lt;int&gt;(10);std::weak_ptr&lt;int&gt; wp = sp; // 从 shared_ptr 创建\r\nweak_ptr 最重要的函数是\r\nlock()。它会安全地检查被观察对象是否存在：\r\n\r\n如果对象仍然存在，lock() 会返回一个指向该对象的有效的\r\nshared_ptr，并使对象的强引用计数 +1。\r\n如果对象已被销毁，lock() 会返回一个空的 shared_ptr。\r\n\r\n这种“检查并获取”的模式是原子操作，保证了线程安全。 std::weak_ptr&lt;MyClass&gt; weak_p;{    std::shared_ptr&lt;MyClass&gt; shared_p = std::make_shared&lt;MyClass&gt;();    weak_p = shared_p; // weak_p 观察 shared_p 管理的对象    // 尝试从 weak_p 获取一个 shared_ptr    if (auto sp_temp = weak_p.lock()) { // 看是否能够成功获取        std::cout &lt;&lt; \"对象仍然存在, 可以安全访问。\" &lt;&lt; std::endl;        sp_temp-&gt;greet();    }} // shared_p 在此销毁, MyClass 对象也被析构// MyClass 对象已被析构, weak_p无指向, 再次尝试 lock会失败if (auto sp_temp = weak_p.lock()) {    // 这段代码不会执行} else {    std::cout &lt;&lt; \"对象已被销毁, 无法访问。\" &lt;&lt; std::endl;}\r\n还有个常用的函数: std::weak_ptr::expired(),\r\n用于判断当前 weak_ptr\r\n是否已经失效，也就是它所观察的对象是否已经被销毁。如果返回 true,\r\n表示对象已经被销毁，weak_ptr 不再指向有效资源; 返回\r\nfalse则表示对象仍然存在，可以尝试通过 lock() 获取一个有效的\r\nshared_ptr。\r\n结合起来上面的代码还可以修改为: if (!weak_ptr.expired()) {    weak_ptr.lock()-&gt;greet();} else {    std::cout &lt;&lt; \"对象已被销毁, 无法访问。\" &lt;&lt; std::endl;}\r\n解决循环引用\r\n只需将循环引用链中的任意一环从 shared_ptr 改为 weak_ptr\r\n即可。通常，我们会选择从属关系中的“子”指向“父”的指针(在双向链表中通常是\r\nprev 指针)改为 weak_ptr。\r\n#include &lt;iostream&gt;#include &lt;memory&gt;struct CorrectNode {    int value;    std::shared_ptr&lt;CorrectNode&gt; next;    // 解决方案：将 prev 指针改为 weak_ptr    std::weak_ptr&lt;CorrectNode&gt; prev;    CorrectNode(int v) : value(v) {        std::cout &lt;&lt; \"构造函数: CorrectNode(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }    ~CorrectNode() {        std::cout &lt;&lt; \"析构函数: ~CorrectNode(\" &lt;&lt; value &lt;&lt; \")\" &lt;&lt; std::endl;    }};void create_correct_list() {    std::cout &lt;&lt; \"--- 进入 create_correct_list 函数 ---\" &lt;&lt; std::endl;    auto node1 = std::make_shared&lt;CorrectNode&gt;(10); // Node(10) 强引用 = 1    auto node2 = std::make_shared&lt;CorrectNode&gt;(20); // Node(20) 强引用 = 1    node1-&gt;next = node2; // Node(20) 强引用 = 2    node2-&gt;prev = node1; // Node(10) 强引用不变，仍为 1 (因为 prev 是 weak_ptr)    std::cout &lt;&lt; \"连接后, Node(10) 的引用计数: \" &lt;&lt; node1.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"连接后, Node(20) 的引用计数: \" &lt;&lt; node2.use_count() &lt;&lt; std::endl;    std::cout &lt;&lt; \"--- 准备离开 create_correct_list 函数 ---\" &lt;&lt; std::endl;}int main() {    create_correct_list();    std::cout &lt;&lt; \"\\n--- create_correct_list 函数已结束 ---\" &lt;&lt; std::endl;    std::cout &lt;&lt; \"程序即将退出，检查是否有析构函数被调用...\" &lt;&lt; std::endl;    return 0;}\r\n当 create_correct_list 函数结束时，栈上的 node1 和 node2 被销毁。因为\r\nnode1 销毁，Node(10) 的强引用计数从 1 降为 0。Node(10) 对象被析构,\r\n导致其成员 next（一个指向 Node(20) 的 shared_ptr）被销毁。这导致\r\nNode(20) 的强引用计数从 2 降为 1。\r\n随后，node2 销毁，Node(20) 的强引用计数从 1 降为 0。Node(20)\r\n对象被析构。最终结果是, 所有节点都被正确地、依次地销毁。\r\n总结对比\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\nstd::shared_ptr\r\nstd::weak_ptr\r\n\r\n\r\n\r\n\r\n所有权\r\n拥有（共享所有权）\r\n不拥有（观察者）\r\n\r\n\r\n引用计数\r\n创建/销毁/拷贝会改变强引用计数\r\n创建/销毁/拷贝会改变弱引用计数\r\n\r\n\r\n生命周期\r\n它的存在会延长对象的生命周期\r\n不影响对象的生命周期\r\n\r\n\r\n直接访问\r\n可以，通过 * 和 -&gt; 操作符\r\n不可以\r\n\r\n\r\n安全访问方式\r\n直接使用\r\n必须调用 lock() 获取一个临时的 shared_ptr\r\n\r\n\r\n主要用途\r\n管理具有共享所有权的动态资源\r\n1. 打破 shared_ptr 的循环引用2. 实现缓存系统3.\r\n观察者模式\r\n\r\n\r\n如何创建\r\nstd::make_shared 或从原始指针构造\r\n从 shared_ptr 或其他 weak_ptr 构造\r\n\r\n\r\n\r\n智能指针这种技术并不新奇，在很多语言中都是一种常见的技术，现代 C++\r\n将这项技术引进，在一定程度上消除了 new/delete\r\n的滥用，是一种更加成熟的编程范式。\r\n"},{"title":"3. 线程间的等待与通知","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/3.%20%E5%90%8C%E6%AD%A5%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C/","content":"这一章是继上一章“保护共享数据”之后的进阶，核心是解决线程间的“等待”与“通知”问题，即一个线程如何高效地等待另一个线程完成某个操作。\r\n等待一个事件\r\n假如你正在坐一趟夜间火车,\r\n你需要在正确的站点下车。现在有三种策略可以选择：\r\n策略1：忙等待 (Busy-Waiting),\r\n也就是整晚不睡，每到一站都探出头去看。优点是绝对不会错过下车点,\r\n但缺点是极度疲劳（浪费CPU）。\r\n策略2：轮询休眠 (Polling with Sleep),\r\n也就是看一眼时间表，估计一个大致时间，设个闹钟。优点是可以休息，比一直忙等待好很多；缺点是时间很难把握。火车晚点？你被早早吵醒，还是得等（引入延迟）。闹钟出问题？你睡过站了（bug）。\r\n策略3：条件变量 (Ideal Solution), 这是最优的策略,\r\n你可以安心睡觉，让乘务员在火车到站时（事件发生时）来唤醒你。它不浪费精力（CPU），也不会错过（无延迟）。\r\n回到多线程编程中，常见的场景是一个线程需要等待另一个线程完成某个任务后才能继续执行。例如，主线程可能需要等待工作线程完成数据处理后才能使用处理结果。而只有互斥量是无法满足这种需求的，因为互斥量只能保护共享数据的访问，而不能实现线程间的等待与通知。\r\n对于这个任务, 与上述示例对应的策略1就是忙等待 (Busy-Waiting):\r\n一个线程在一个 while\r\n循环中不断地加锁、检查标志、解锁。\r\n// 策略1：忙等待（非常糟糕）while(true) {    std::lock_guard&lt;std::mutex&gt; lk(m);    if(flag) {        break; // 条件满足    }    // 锁被释放，但循环立即再次开始} 缺点是灾难性的: 不仅浪费CPU, 等待线程在 while(true)\r\n中空转，消耗宝贵的CPU时间片;\r\n而且还会引发锁竞争：等待线程（消费者）为了检查 flag\r\n而频繁加锁，这会阻塞那个唯一能设置\r\nflag 的线程（生产者）！\r\n对应的策略2是轮询休眠 (Polling with Sleep),\r\n也就是在每次检查标志之前让等待线程休眠一段时间: bool flag;std::mutex m;void wait_for_flag(){  std::unique_lock&lt;std::mutex&gt; lk(m);  while(!flag)  {    lk.unlock();  // 1. 关键：在休眠前必须解锁    // 2. 休眠，不占用CPU    std::this_thread::sleep_for(std::chrono::milliseconds(100));     lk.lock();    // 3. 重新加锁，准备在 while 循环中再次检查  }} 优点： -\r\n不空转：线程在 sleep_for\r\n期间是休眠的，不消耗CPU。 -\r\n释放锁：它很聪明地在休眠前解锁了互斥量，这使得生产者线程可以在此期间获取锁并设置\r\nflag。\r\n缺点是休眠时间无法确定： -\r\n太短（如1毫秒）：和“忙等待”几乎一样，依然有大量的加锁/解锁开销。 -\r\n太长（如100毫秒）：生产者可能在第1毫秒就设置了\r\nflag，但消费者线程要睡到第100毫秒才醒来。这引入了99毫秒的延迟\r\n(Latency)。\r\n而策略3：条件变量 (Condition Variable)\r\n则是理想的解决方案。它允许一个线程等待某个条件，并在条件满足时被另一个线程通知。条件变量内部会自动处理线程的休眠和唤醒，避免了忙等待和轮询休眠的问题。\r\n条件变量(condition_variable)\r\n条件变量是 C++11 标准库提供的一个同步原语，定义在\r\n&lt;condition_variable&gt;\r\n头文件中。它允许线程在等待某个条件时进入休眠状态，并在条件满足时被其他线程唤醒。目前有两种主要的条件变量类型：\r\n- std::condition_variable：首选, 它性能更高，但只能和\r\nstd::mutex 配合使用。 -\r\nstd::condition_variable_any：更通用（因此叫 _any）,\r\n它可以和任何满足“可锁定”要求的锁（如\r\nstd::shared_mutex）配合使用。 -\r\n因为更通用，所以它有额外的开销（体积、性能），应避免在\r\nstd::mutex 场景下使用。\r\n条件变量必须和一个互斥量 (Mutex)\r\n配合使用。互斥量保护的是共享数据,\r\n但同时也是条件变量本身,\r\n因为条件变量检查和修改条件时需要保证原子性。\r\n下面是一个经典的生产者-消费者示例，展示了如何使用条件变量来实现线程间的等待与通知。\r\nstd::mutex mut;std::queue&lt;data_chunk&gt; data_queue;  // 1. 被保护的“条件”std::condition_variable data_cond;// 生产者线程void data_preparation_thread(){  while(more_data_to_prepare())  {    data_chunk const data = prepare_data();    std::lock_guard&lt;std::mutex&gt; lk(mut); // 生产者加锁    data_queue.push(data);  // 2. 修改“条件”    data_cond.notify_one(); // 3. 唤醒一个等待者（“嘿，有新数据了！”）  }}// 消费者线程void data_processing_thread(){  while(true)  {    // 4. 必须使用 unique_lock，不能用 lock_guard    std::unique_lock&lt;std::mutex&gt; lk(mut);         // 5. 核心：等待    data_cond.wait(lk, []{ return !data_queue.empty(); });              data_chunk data = data_queue.front();    data_queue.pop();        // 6. 尽早解锁    lk.unlock();         process(data);    // ...  }}\r\ndata_cond.wait(lk, []{return !data_queue.empty();});\r\n这一行是理解本章的关键。它有两个参数：一个锁（lk）和一个谓词（predicate，即lambda函数）。\r\nwait() 函数的内部逻辑如下： - 检查谓词：wait 首先调用 lambda\r\n函数 []{ return !data_queue.empty(); }。 -\r\n如果谓词为 true（队列不为空）：wait 函数立即返回,\r\n线程继续持有锁 lk，向下执行（去 pop\r\n数据）。 - 如果谓词为 false（队列是空的）：wait 函数释放互斥锁\r\nlk, 并将当前线程（消费者）置于休眠/等待状态。\r\n- 被唤醒后：当生产者线程调用 data_cond.notify_one()\r\n时，等待的消费者线程会被唤醒。wait 函数会重新获取锁\r\nlk，然后再次检查谓词。 - 如果谓词现在为\r\ntrue：wait 函数返回，线程继续执行。(这是为了防止“虚假唤醒”,\r\n即没有notify的唤醒却醒来的情况) - 如果谓词仍为 false：wait\r\n函数会再次释放锁并进入休眠，直到被再次唤醒。\r\n\r\n也就是 wait() 函数一开始是没有锁的,\r\n因此必须和互斥量配合使用，先加锁再调用 wait()\r\n\r\n还要注意, 与条件变量配合使用的锁必须是\r\nstd::unique_lock&lt;std::mutex&gt; 类型，不能使用\r\nstd::lock_guard&lt;std::mutex&gt;。这是因为 wait()\r\n函数需要在等待时释放锁，而 lock_guard\r\n不支持中途解锁操作。\r\n使用条件变量构建线程安全队列\r\n在上一节,\r\n我们构造了一个使用条件变量的“生产者-消费者”代码。那个例子是有效的，但它是“一次性”的：mut、data_queue\r\n和 data_cond\r\n都是全局变量，紧密耦合在两个特定的函数中。\r\n本节的目标是重构这些代码，将其封装成一个通用的、可复用的、线程安全的\r\nthreadsafe_queue 类。\r\n当然, 这一切的灵感来源还是来自 std::queue 标准实现的固有缺陷.\r\n它的主要接口有以下三类：\r\n\r\nempty() / size() (检查状态)\r\nfront() / back() (获取元素)\r\npush() / pop() / emplace() (修改队列)\r\n\r\n问题是, 这些接口的依旧存在固有条件竞争, 这与我们在第3章中讨论的\r\nstd::stack 有完全相同的问题。\r\nstd::queue\r\n的接口迫使你将“获取”和“删除”分成两个步骤：\r\n\r\nT&amp; value = my_queue.front(); (检查/获取)\r\nmy_queue.pop(); (修改/使用)\r\n\r\n在多线程环境下，在这两个调用之间存在一个“间隙”，可能导致数据被重复处理或丢失。同样，if (!my_queue.empty()) { ... }\r\n也是一个经典的 TOCTTOU 竞争。\r\n为了解决这些竞争，我们必须将“检查”、“获取”和“删除”合并成原子的操作。\r\n此外，因为这是一个用于并发环境的队列，我们必须考虑一个新问题：当队列为空时，消费者想\r\npop 怎么办？\r\n在第3章的 stack\r\n示例中，我们只是抛出了一个异常。但在第4章，我们有了条件变量，所以我们可以提供一个更好的选项：等待\r\n(Wait)。这导致我们设计出两种 pop 操作：\r\n\r\ntry_pop()（非阻塞）：“尝试\r\npop”。如果队列中有数据，就获取它并返回\r\ntrue。如果队列是空的，不要等待，立即返回\r\nfalse。\r\nwait_and_pop()（阻塞）：“等待并\r\npop”。如果队列中有数据，就获取它。如果队列是空的，就使用条件变量进入休眠，直到生产者\r\npush 了数据并通知它。\r\n\r\n为了兼顾异常安全和灵活性，我们为 pop 操作提供了和 stack\r\n一样的两种重载：\r\n\r\ntry_pop(T&amp;\r\nvalue)：通过引用返回，（如果成功）返回 bool。\r\ntry_pop()：返回\r\nstd::shared_ptr。（如果失败）返回 nullptr。\r\nwait_and_pop(T&amp;\r\nvalue)：通过引用返回，（阻塞直到成功）。\r\nwait_and_pop()：返回\r\nstd::shared_ptr，（阻塞直到成功）。\r\n\r\n#include &lt;queue&gt;#include &lt;memory&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;template&lt;typename T&gt;class threadsafe_queue{private:  mutable std::mutex mut;  // 1 互斥量必须是可变的   std::queue&lt;T&gt; data_queue;  std::condition_variable data_cond;public:  threadsafe_queue(){}  threadsafe_queue(threadsafe_queue const&amp; other)  {    std::lock_guard&lt;std::mutex&gt; lk(other.mut); // 复制时加锁    data_queue=other.data_queue;  }  void push(T new_value)    {    std::lock_guard&lt;std::mutex&gt; lk(mut);  // push 只是一个快速的、非阻塞的操作，所以它使用最高效的 std::lock_guard 来保护队列。    data_queue.push(new_value);    data_cond.notify_one();  }  void wait_and_pop(T&amp; value)  {    std::unique_lock&lt;std::mutex&gt; lk(mut);  // wait 必须使用 unique_lock    data_cond.wait(lk, [this]{return !data_queue.empty();});     value = data_queue.front();  // 传出参数    data_queue.pop();  }  std::shared_ptr&lt;T&gt; wait_and_pop()  {    std::unique_lock&lt;std::mutex&gt; lk(mut);    data_cond.wait(lk, [this]{return !data_queue.empty();});    std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front()));  // 构造智能指针传出    data_queue.pop();    return res;  }  bool try_pop(T&amp; value)  // 非阻塞版本  {    std::lock_guard&lt;std::mutex&gt; lk(mut);  // 不需要 unique_lock，因为不需要等待    if(data_queue.empty())      return false;    value = data_queue.front();    data_queue.pop();    return true;  }  std::shared_ptr&lt;T&gt; try_pop()  // 非阻塞版本  {    std::lock_guard&lt;std::mutex&gt; lk(mut);    if(data_queue.empty())      return std::shared_ptr&lt;T&gt;();    std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front()));    data_queue.pop();    return res;  }  bool empty() const  // 声明为 const 成员函数  {    std::lock_guard&lt;std::mutex&gt; lk(mut);  // 读取时加锁, 因为加锁也是修改, 所以 mut 必须是 mutable    return data_queue.empty();  }};\r\n这里需要注意的是 mutable 关键字的使用。因为 empty()\r\n函数是一个 const\r\n成员函数，它不能修改类的任何成员变量。然而，为了保证线程安全，我们需要在\r\nempty() 中加锁,\r\n而锁定互斥量是一个修改（non-const）互斥量本身的操作。因此，我们将互斥量\r\nmut 声明为 mutable，这样即使在 const\r\n成员函数中也可以对其进行修改（加锁/解锁）。 &gt; mutable\r\n关键字的含义是允许在 const\r\n成员函数中修改该成员变量。它通常用于那些逻辑上不影响对象状态的成员变量，例如缓存或互斥量。\r\n除了notify_one()，条件变量还有另一个通知函数：notify_all()。它们的区别在于唤醒的线程数量：\r\n- notify_one()：当 push\r\n一个数据项时，我们只唤醒一个消费者线程。这是最高效的，因为只有一个线程能成功获取该数据项。如果唤醒所有线程，其他线程醒来后会发现队列又空了（因为被第一个线程拿走了），然后再次进入休眠，这被称为“惊群效应\r\n(Thundering Herd)”。 - notify_all()：适用于“广播”事件,\r\n唤醒所有等待该事件的线程。例如，当一个共享配置被更新，或系统即将关闭时，你希望所有等待这个事件的线程都醒来并作出反应。\r\n使用 std::future\r\n等待一次性事件\r\n在上一节,\r\n我们学习了“条件变量”，它非常适合于“重复性”的等待（例如，一个消费者反复等待一个队列变为非空）。\r\n而本节引入了一种完全不同的同步模型，它专为“一次性事件”\r\n(one-off event) 而设计。 &gt;\r\n“一次性事件”是指在程序的某个时间点上，你预期会发生一次的事件。一旦它发生了，它就永远处于“已发生”状态，不能被重置。\r\nC++标准库（在 &lt;future&gt;\r\n头文件中）将这种模型称为“期望” (Future)。 -\r\nstd::future&lt;T&gt;：代表一个未来的 T\r\n类型的值。 -\r\nstd::future&lt;void&gt;：如果事件没有关联的数据（只是一个“信号”），则使用\r\nvoid 特化版。\r\n关键特性：一个 future\r\n一旦变为“就绪”状态，它就不能被重置。\r\n期望有两种类型 ：std::future\r\nvs. std::shared_future -\r\nstd::future&lt;T&gt; (唯一期望),\r\n可以类比：std::unique_ptr&lt;T&gt;。 -\r\n所有权：它代表了对异步结果的唯一所有权。\r\n- 不可拷贝 (Non-copyable), 只可移动 (Move-only)。 -\r\n含义：在任何时刻，只有一个 std::future\r\n对象可以关联到那个“一次性事件”的结果。你可以通过\r\nstd::move\r\n将这个所有权从一个线程转移到另一个线程，但永远只有一张“登机牌”。 -\r\n限制：get()\r\n成员函数（用于获取结果）只能被调用一次。调用后，future\r\n对象内部的状态就变了（不再持有值）。\r\n\r\nstd::shared_future&lt;T&gt; (共享期望), 类比\r\nstd::shared_ptr&lt;T&gt;。\r\n\r\n所有权：它代表了对异步结果的共享所有权。\r\n可以拷贝 (Copyable), 将一个 std::shared_future\r\n拷贝多份，分发给多个不同的线程。当“事件”发生时，所有这些拷贝的\r\nshared_future 对象会同时变为“就绪”。\r\n限制：get()\r\n成员函数可以被多次调用（每个拷贝对象都可以调用）。（注意：get()\r\n在 shared_future 上返回的是 const T&amp;，而不是 T）。\r\n\r\n\r\nfuture 对象的主要成员函数如下： -\r\n.get()：阻塞等待任务完成并获取返回值。只能调用一次，之后\r\nfuture 变为无效状态。 -\r\n.wait()：阻塞等待任务完成，但不获取返回值。适用于你只关心任务是否完成，而不需要结果的情况。\r\n- .valid()：检查 future\r\n对象是否关联了一个有效的异步任务。如果 future 是默认构造的，或者 get()\r\n已经被调用过，它将返回 false。 - .wait_for() 和\r\n.wait_until()：允许你以超时的方式等待任务完成。例如，你可以等待最多\r\n100 毫秒，如果任务在这段时间内没有完成，你可以选择继续做其他事情。 -\r\n.share()：将一个 std::future&lt;T&gt;\r\n转换为\r\nstd::shared_future&lt;T&gt;。这允许你将同一个异步结果共享给多个线程。\r\n带返回值的后台任务(std::async)\r\n在只使用 std::thread\r\n的情况下，如果你想让一个新线程计算一个值并返回给主线程，你必须手动实现一套复杂的同步机制：\r\n\r\n在主线程创建一个共享变量（如 int result）。\r\n创建一个 std::mutex 来保护这个变量。\r\n（可能还需要一个 std::condition_variable 和一个 bool\r\n标志）来通知主线程“计算已完成”。\r\n主线程需要加锁、等待、然后才能安全地读取 result。\r\n\r\n这个过程非常繁琐且容易出错。\r\nC++11在 &lt;future&gt; 头文件中提供了一个高级函数模板\r\nstd::async，它将启动任务和返回结果这两个过程完美地封装了起来。\r\n它是一个函数，你像 std::thread\r\n一样传递给它一个“任务”（函数、lambda、可调用对象）,\r\n之后它（通常）会启动一个新线程来执行这个任务。\r\n不同于 std::thread 的是, 它立即返回一个\r\nstd::future&lt;T&gt; 对象, T\r\n就是你传递的那个任务的返回值类型。\r\n你可以在主线程继续执行其他操作而不需要阻塞等待,\r\n当你需要那个计算结果时，你对 future 对象调用 .get()\r\n方法。\r\n#include &lt;future&gt;#include &lt;iostream&gt;int find_the_answer_to_ltuae(); // 一个耗时的计算任务void do_other_stuff(); // 主线程要做的其他工作int main(){  // 1. 启动异步任务, 构造一个 future 对象接收结果  std::future&lt;int&gt; the_answer = std::async(find_the_answer_to_ltuae);    // 2. 主线程并发执行其他工作  do_other_stuff();    // 3. 当需要结果时，调用 .get()  //    如果任务还没完成，get() 会阻塞等待直到结果可用  std::cout &lt;&lt; \"The answer is \" &lt;&lt; the_answer.get() &lt;&lt; std::endl;}\r\n此外, 对于 std::async,\r\n其实不一定会启动一个新线程。具体实现取决于它的启动策略\r\n(Launch Policies)\r\n你可以通过一个 std::launch\r\n类型的可选第一参数来指定“启动策略”：\r\n\r\nstd::launch::async (异步执行): 强制 std::async\r\n必须在一个新线程上异步执行任务，就像 std::thread\r\n一样。例如auto f6 = std::async(std::launch::async, Y(), 1.2);\r\nstd::launch::deferred (延迟执行): 强制\r\nstd::async\r\n不要启动新线程。例如auto f7 = std::async(std::launch::deferred, baz, std::ref(x));\r\n\r\n那任务何时执行？ 任务会被“延迟”，直到你调用\r\n.get() 或 .wait()时,\r\n它会在调用 .get()\r\n的那个线程上（即主线程）同步地执行。\r\n类似于Lazy - loading（惰性加载）\r\n某种程度上来说, 这并不是真正的“异步并发”操作,\r\n因为任务实际上还是在主线程上执行的, 只不过被推迟了。\r\n\r\nstd::launch::async |\r\nstd::launch::deferred (默认策略): 当不设定时,\r\n意味着你把决定权交给了C++标准库。库的实现可以自由选择：它可能会启动一个新线程（async），也可能会将其标记为“延迟”（deferred）。\r\n\r\n这是为了“任务超额”时的自动负载均衡。如果库发现你已经启动了1000个线程，快耗尽资源了，它可能会自动将你的新任务切换为\r\ndeferred 模式，以避免系统崩溃。\r\n如果你确定你需要真正的并发执行，最好显式指定\r\nstd::launch::async。\r\n\r\n\r\n下面是 std::async 传递参数的规则： struct X{  void foo(int, std::string const&amp;);  std::string bar(std::string const&amp;);};X x;// f1: 调用 x.foo(42, \"hello\")auto f1 = std::async(&amp;X::foo, &amp;x, 42, \"hello\"); // f2: 调用 tmpx.bar(\"goodbye\")，tmpx 是 x 的拷贝副本auto f2 = std::async(&amp;X::bar, x, \"goodbye\"); struct Y{  double operator()(double);};Y y;// f3: 调用 Y() 构造的临时对象的 operator()(3.141)auto f3 = std::async(Y(), 3.141);// f4: 调用 y.operator()(2.718)，y 是通过引用传递的auto f4 = std::async(std::ref(y), 2.718); class move_only{  // ... (一个只能移动，不能拷贝的类) ...  void operator()();};// f5: 调用一个通过移动构造的 move_only 临时对象的 operator()auto f5 = std::async(move_only());\r\n任务与期望\r\n(std::packaged_task)\r\n上一节, 我们学习了\r\nstd::async。它是一个“高级”工具，像一个黑盒：你给它一个任务，它自己决定如何运行（新线程或延迟），然后给你一个\r\nfuture。\r\n本节介绍了一个更“底层”、更灵活的工具：std::packaged_task。\r\nstd::packaged_task\r\n的名字就说明了它的作用：它是一个“被打包的任务”。\r\n\r\n它是一个类模板，它将一个可调用对象（函数、lambda等）与一个期望\r\n(future) 绑定（打包）在一起。\r\n核心机制：\r\n\r\n你创建一个 packaged_task 对象时，它内部就包含了一个准备好的\r\nfuture。\r\npackaged_task 本身也是一个可调用对象（它有\r\noperator()）。\r\n当你调用这个 packaged_task\r\n对象时，它会执行内部绑定的函数，然后自动将函数的返回值（或抛出的异常）存储到\r\nfuture 中，使 future\r\n变为“就绪”状态。这样，你就可以在另一个线程中等待这个\r\nfuture，并获取结果。\r\n\r\n\r\nstd::async vs\r\nstd::packaged_task 对比\r\n它们最大的区别在于“谁来执行任务”：\r\nstd::async：执行与绑定合一。\r\n\r\n当你调用 std::async\r\n时，你不仅是“打包”了任务，你还同时“命令”C++运行时去执行它（要么马上在新线程，要么延迟）。\r\n\r\nstd::packaged_task：执行与绑定分离。\r\n\r\n当你创建 packaged_task\r\n时，你只是“打包”了任务，任务并不会被执行。\r\n你得到了一个可以被传来传去的 task\r\n对象。执行这个任务的时间和地点（即在哪个线程上）完全由你决定。\r\n\r\n为什么这种分离很重要？ 因为它允许你实现 std::async\r\n无法做到的高级模式，例如：\r\n\r\n线程池：你可以创建100个\r\npackaged_task，把它们全都塞进一个队列，然后让一个固定的线程池（比如8个线程）去队列里取任务并执行。\r\n特定线程执行（清单 4.9）：你可以把一个\r\npackaged_task\r\n发送到一个特定的线程（例如，GUI线程）去执行。\r\n\r\npackaged_task 的模板与用法\r\n模板参数：std::packaged_task&lt;R(Args...)&gt; ,\r\n它接受一个函数签名作为模板参数。例如:\r\nstd::packaged_task&lt;std::string(std::vector&lt;char&gt;*, int)&gt;\r\n\r\nR (即\r\nstd::string)：这是返回值类型。它决定了\r\nget_future() 返回的 future 类型，即\r\nstd::future&lt;std::string&gt;。\r\nArgs… (即\r\nstd::vector&lt;char&gt;*, int)：这是参数列表。它决定了\r\npackaged_task 对象自己的 operator() 接受什么参数，即\r\ntask(my_vector, 42);。\r\n\r\n打包好的task对象有两个主要成员函数： -\r\n.get_future()：返回与该任务关联的 std::future 对象。 -\r\n.operator()\r\n(Args…)：调用该任务，传递参数并执行绑定的函数。 -\r\n或者直接传递给 std::thread 构造函数。\r\n标准用法如下：\r\n// 1. 一个要执行的函数int my_task(std::string s) { return s.length(); }// 2. 打包任务，指定函数签名std::packaged_task&lt;int(std::string)&gt; task(my_task);// 3. 关键：在任务被“移走”之前，获取 futurestd::future&lt;int&gt; result = task.get_future();// 4. 将任务交给新线程执行//    注意：packaged_task 和 thread 一样，不可拷贝，只能移动 (std::move)std::thread t(std::move(task), \"hello\");t.detach();// 5. 在主线程或其他地方等待结果std::cout &lt;&lt; \"Result: \" &lt;&lt; result.get() &lt;&lt; std::endl; // 会阻塞直到 t 运行了 task\r\n下面是一个 packaged_task\r\n最典型的应用场景：任务分发。\r\n假设有一个多线程程序，但只有 gui_thread\r\n才能更新UI。如果一个后台线程（比如网络线程）想在UI上显示“下载完成”，它该怎么办？它不能直接调用UI函数。\r\n解决方案是,\r\n后台线程必须把“更新UI”这个任务（一个函数）发送给\r\ngui_thread 去执行。并且，后台线程可能还想知道\r\ngui_thread 何时完成了这个任务。 // 全局的、受互斥量保护的任务队列std::mutex m;std::deque&lt;std::packaged_task&lt;void()&gt;&gt; tasks; // 只接受“无参、无返回”的任务// 1. GUI 线程的执行函数void gui_thread() {  while(!gui_shutdown_message_received()) // 2. GUI 循环, 只要没收到关闭消息就继续  {    get_and_process_gui_message(); // 3. 处理自己的事 (如鼠标点击)        std::packaged_task&lt;void()&gt; task;    {      std::lock_guard&lt;std::mutex&gt; lk(m);      if(tasks.empty()) // 4. 检查任务队列        continue;              task = std::move(tasks.front()); // 5. 从队列中“窃取”一个任务      tasks.pop_front();    }    task(); // 6. 关键：在 GUI 线程上“执行”这个任务  }}// 7. 任何其他线程都可以调用的“发布”函数template&lt;typename Func&gt;std::future&lt;void&gt; post_task_for_gui_thread(Func f){  std::packaged_task&lt;void()&gt; task(f); // 8. 打包任务  std::future&lt;void&gt; res = task.get_future(); // 9. 获取 future    std::lock_guard&lt;std::mutex&gt; lk(m); // 10. 加锁队列  tasks.push_back(std::move(task)); // 11. 将“任务”移入队列    return res; // 12. 立即将“future”返回给调用者}\r\n总之, std::packaged_task\r\n是一个强大的中间件。它将任务的定义（你想做什么）与任务的执行（何时、何地做）以及结果的获取（future）分离开来。这使它成为实现线程池、任务队列和特定线程调度（如GUI）等高级并发模式的基础构件。\r\n使用 std::promise\r\n这是创建 std::future\r\n的第三种，也是最底层、最灵活的方式。\r\n\r\nstd::async：自动创建 future + 自动运行任务。\r\nstd::packaged_task：自动创建 future +\r\n手动运行任务（task()）。\r\nstd::promise：自动创建 future +\r\n手动设置值（set_value()）。\r\n\r\nstd::promise 实现了 “承诺/期望” (Promise/Future)\r\n模型。它将设置值的“入口”（承诺）与获取值的“出口”（期望）完全分离开来。\r\n\r\nstd::promise&lt;T&gt;：一个“承诺”对象，它承诺在未来某个时刻会提供一个\r\nT 类型的值。它就是那个“生产者”或“事件触发者”。\r\n\r\n在之前的std::async和std::packaged_task中,\r\n结果的设置是自动完成的（任务执行完毕后自动设置结果）,\r\n且一般就是函数的返回值。\r\n而在 std::promise 中，生产者线程需要显式地手动调用\r\npromise 对象的 set_value() 方法来提供结果,\r\n可以是任何值,\r\n也可以在任何时间点调用（不一定是函数返回时）。\r\n\r\nstd::future&lt;T&gt;：一个“期望”对象，它期望从对应的\r\npromise 那里获取一个 T\r\n类型的值。它就是那个“消费者”或“等待者”。\r\n\r\n工作机制:\r\n\r\n创建：你首先创建一个 std::promise&lt;T&gt; 对象,\r\n例如std::promise&lt;int&gt; p;\r\n获取 Future：你立即从 promise\r\n中获取其唯一关联的 future 对象。\r\nstd::future&lt;int&gt; f = p.get_future();\r\n分发：这是最关键的一步。你将 f 和 p\r\n分发到不同的线程：\r\n\r\nstd::future f -&gt;\r\n发送给等待线程（消费者）。\r\nstd::promise p -&gt;\r\n发送给（或保留在）工作线程（生产者）。\r\n（注意：std::promise 和 std::future\r\n一样，是“只移动”的，所以跨线程传递时需要\r\nstd::move）。\r\n\r\n等待：消费者线程在需要结果时调用\r\nf.get()，它会在这里阻塞。\r\n履约：生产者线程在计算出结果（例如 result =\r\n42）或者决定发送某种事件/状态通知后，手动显式调用\r\np.set_value(result)。\r\n唤醒：set_value() 的调用是一个原子事件。它会使 f\r\n的状态变为“就绪”，并立即唤醒正在 f.get()\r\n上阻塞的消费者线程，消费者线程随后会收到值 42。\r\n\r\n使用场景\r\nstd::promise\r\n适用于异步事件，特别是那些不由函数返回值触发的事件。\r\n“多网络连接”是一个完美的例子：一个高性能服务器需要同时处理上千个网络连接。\r\n错误方案：为每个连接创建一个线程（如\r\nstd::async）。这会创建上千个线程，耗尽系统资源，导致上下文切换风暴，性能崩溃。\r\n正确方案：使用 IO多路复用 或\r\n事件循环。一个（或少数几个）线程处理所有的网络读写事件。\r\npromise 如何解决同步问题？\r\n场景：“逻辑线程A”想通过网络发送一个数据包，并且需要确认数据包何时被真正发送。流程：\r\n\r\n逻辑线程A： std::promise&lt;bool&gt; p;\r\nstd::future&lt;bool&gt; f = p.get_future();\r\n逻辑线程A：创建一个 outgoing_packet 对象，这个对象同时包含\r\ndata 和 std::move(p)。\r\n逻辑线程A：将这个 packet\r\n放入一个队列，交给“网络线程”。\r\n逻辑线程A：调用\r\nf.get()。它在这里阻塞，等待网络线程的确认。\r\n网络线程：在其事件循环中，从队列取出 packet，将 data\r\n发送到操作系统Socket。\r\n网络线程：当操作系统确认“发送完成”时，它调用\r\npacket.promise.set_value(true);。\r\n唤醒：set_value() 使 f 变为就绪，逻辑线程A 从 f.get()\r\n唤醒，得知发送成功。\r\n\r\n也就是说, 逻辑线程A 和 网络线程 之间通过 promise/future\r\n实现了异步事件通知，而不是通过函数调用栈或任务完成来传递结果。\r\nstd::promise\r\n提供了一种灵活的机制，允许你在任何时间点、任何线程中手动触发事件，并将结果传递给等待的线程，而不依赖于函数调用栈或任务执行的完成。这使得它非常适合处理复杂的异步工作流和事件驱动的编程模型。\r\nstd::unordered_map&lt;int, std::promise&lt;payload_type&gt;&gt; incoming_promises_;// 网络/IO线程处理连接集合的事件循环void process_connections(connection_set&amp; connections){  while(!done(connections)) // 1. 如果还有连接未完成  {    for(connection_iterator ... ) // 2. 遍历所有连接    {      if(connection-&gt;has_incoming_data()) // 3. 检查【入站】事件      {        data_packet data = connection-&gt;incoming(); // 读取数据                // 4. 查找与此数据ID关联的 \"承诺\", 这个get_promise() 应该加锁访问保存的promise哈希表, promise和id应该在连接建立时由外部线程注册        std::promise&lt;payload_type&gt;&amp; p =            connection-&gt;get_promise(data.id);                     p.set_value(data.payload); // 履约：将数据发给等待者      }            if(connection-&gt;has_outgoing_data()) // 5. 检查【出站】事件      {        outgoing_packet data =            connection-&gt;top_of_outgoing_queue();                    connection-&gt;send(data.payload); // 发送数据                // 6. 履约：告诉请求者“发送已完成”, 这里的data.promise 应该是 outgoing_packet 结构的一部分, 它在创建 outgoing_packet 时由外部线程传入        data.promise.set_value(true);       }    }  }}// 可能的其他部分代码std::future&lt;payload_type&gt; Connection::send_request_async(...){    // ... 其他初始化代码 ...        { // 互斥量作用域开始        std::lock_guard&lt;std::mutex&gt; lock(mutex_); // &lt;&lt; 业务线程加锁 &gt;&gt;                // 业务线程安全地修改共享表：        // 1. 获取下一个 ID        // 2. 将 Promise 对象插入共享的 map 中        incoming_promises_.emplace(request_id, std::move(p));     } // 互斥量作用域结束，业务线程解锁        // ... 后续操作，如将发送请求推入出站队列 ...        return f;}std::promise&lt;payload_type&gt;&amp; Connection::get_promise(int id){    std::lock_guard&lt;std::mutex&gt; lock(mutex_); // &lt;&lt; I/O 线程加锁 &gt;&gt;        // I/O 线程安全地查找共享表    auto it = incoming_promises_.find(id);        // ... 查找和错误处理 ...        return it-&gt;second;} // I/O 线程解锁\r\n这个流程描述了一个典型的 业务线程 (T1) 如何通过\r\nI/O 线程 (T2)\r\n向数据中心完成一次异步的请求-响应循环。\r\n\r\n业务线程 (T1)：发起请求，等待最终结果。\r\nI/O 线程 (T2)：运行 I/O 事件循环，负责网络读写和结果通知。\r\nConnection 对象 (共享)：包含 mutex、incoming_promises_\r\n映射表（用于入站匹配）和 outgoing_queue_（用于出站任务）。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n步骤\r\n角色\r\n动作描述\r\n核心机制\r\n\r\n\r\n\r\n\r\n1\r\n业务线程 (T1)\r\n创建请求任务：创建两个 Promise/Future 对：a.\r\n响应匹配：P_Resp（用于等待外部响应，需注册 ID）；b.\r\n发送确认：P_Sent（用于等待本地发送完成）。\r\nstd::promise\r\n\r\n\r\n2\r\n任务打包 (T1)\r\n将请求数据、ID 和 P_Sent 一起打包成 outgoing_packet。\r\n出站 Promise：P_Sent 随任务数据一起传递\r\n\r\n\r\n3\r\n注册响应 (T1)\r\n加锁并将响应 Promise (P_Resp) 与 ID 注册到共享的 incoming_promises_\r\n映射表中。\r\n入站 Promise 存储在共享 Map 中\r\n\r\n\r\n4\r\n提交任务 (T1)\r\n将打包好的 outgoing_packet 放入 outgoing_queue_；T1 在 F_Resp.get()\r\n上阻塞，等待外部响应。\r\noutgoing_queue_\r\n\r\n\r\n5\r\nI/O 线程执行 (T2)\r\n循环处理：T2 检查 outgoing_queue_ 并取出任务进行发送。\r\nI/O Loop\r\n\r\n\r\n6\r\n兑现出站 (T2)\r\n执行发送（connection-&gt;send()）；发送完成后，T2 调用\r\ndata.promise.set_value(true) 以兑现 P_Sent。\r\noutgoing_packet 内嵌的 promise\r\n\r\n\r\n7\r\n确认完成 (T1)\r\nT1 的另一个 future (F_Sent) 被唤醒，确认请求已离站；随后 T1\r\n可继续等待或处理最终响应（由 F_Resp 提供）。\r\n本地同步完成\r\n\r\n\r\n8\r\n外部返回\r\n外部系统处理完 T2 发出的请求，生成响应，并在数据包中原样带回 T1\r\n提供的 ID。\r\n网络协议：保证 ID 的回显\r\n\r\n\r\n9\r\nI/O 线程接收 (T2)\r\nT2 在事件循环中通过\r\nif(connection-&gt;has_incoming_data()) 接收到响应包。\r\nI/O Loop\r\n\r\n\r\n10\r\n查找匹配 (T2)\r\n加锁：T2 从响应包中提取 ID，并用该 ID 到共享的\r\nincoming_promises_ 映射表中查找等待响应的 P_Resp。\r\nconnection-&gt;get_promise(data.id)\r\n\r\n\r\n11\r\n兑现入站 (T2)\r\n通知：T2 将响应的 Payload 存入找到的 P_Resp。\r\np.set_value(data.payload)\r\n\r\n\r\n12\r\n业务线程完成 (T1)\r\n获取结果：T1 在 F_Resp.get() 上的阻塞被解除，立即获取到 Payload\r\n数据。\r\nstd::future 自动唤醒\r\n\r\n\r\n13\r\n清理 (T2)\r\nT2 将该 ID 及其 P_Resp 从共享映射表中移除，释放资源。\r\nMap 清理\r\n\r\n\r\n\r\n之所以两个promise/future对分开，是因为它们代表了两个不同的异步事件：\r\n-\r\n发送完成：这是一个本地事件，表示数据包已成功发送出去。直接将promise与outgoing_packet绑定即可。\r\n-\r\n响应到达：这是一个远程事件，表示外部系统已处理请求并返回了结果。需要通过ID在共享映射表中查找对应的promise,\r\n因为响应可能会乱序到达, 必须通过ID进行匹配。 ###\r\n为“future”存储“异常”\r\n这一节讨论的是一个对于并发编程至关重要的“健壮性”问题：如果在后台异步执行的任务（无论是通过\r\nstd::async、std::packaged_task 还是\r\nstd::promise）没有成功返回一个值，而是抛出了一个异常，那么等待这个结果的线程会怎么样？\r\n在普通的单线程（同步）代码中，异常会沿着调用栈向上传播，你可以用\r\ntry…catch 块来捕获它：\r\ndouble square_root(double x) {  if(x &lt; 0) {    throw std::out_of_range(\"x&lt;0\");  }  return sqrt(x);}void sync_call() {  try {    double y = square_root(-1); // 异常在这里被抛出  } catch (std::out_of_range&amp; e) {    // 异常在这里被捕获  }}\r\n但在异步（多线程）代码中，情况完全不同： void async_call() {  std::future&lt;double&gt; f = std::async(square_root, -1);  // ... (主线程继续执行)    // 异常在“后台线程”中被抛出。  // 它无法“跳”到主线程的调用栈。    double y = f.get(); // 那么，这里会发生什么？}\r\n这个问题的解决方案是：future 会“运输”异常\r\nC++的“期望”机制提供了一个优雅的解决方案：如果后台任务抛出了异常，这个异常会被捕获并存储在\r\nfuture 的共享状态中。\r\n当等待线程调用 .get()\r\n时，它不会得到一个值，而是会重新抛出 (re-throw)\r\n那个被存储的异常。\r\n因此, 你可以在等待线程中使用 try…catch\r\n块来捕获这个异常，就像在同步代码中一样。 void async_call_correct() {  std::future&lt;double&gt; f = std::async(square_root, -1);  // ... (主线程继续执行)    try {    double y = f.get(); // 异常在这里被“重新抛出”  } catch (std::out_of_range&amp; e) {    // 异常在这里被主线程成功捕获！  }}\r\n三种机制的异常处理方式\r\nfuture 只是一个“容器”，异常是如何被“放”进去的，取决于你是如何创建这个\r\nfuture 的。\r\nstd::async 和 std::packaged_task\r\n(自动处理)\r\nstd::async 和 std::packaged_task 会自动为你处理异常。\r\n\r\nstd::async：当你调用 std::async(my_func, …)\r\n时，C++库的实现（在后台线程）实际上是在类似\r\ntry { my_func(...); } catch(...) { ... }\r\n的代码块中执行你的函数。如果 my_func\r\n抛出异常，async\r\n会自动捕获它，并将其存储到返回的 future\r\n中。\r\nstd::packaged_task：当你调用 task() 时，packaged_task 的\r\noperator() 内部也会做同样的事情。它会 try…catch\r\n你绑定的函数，如果捕获到异常，就自动将其存储到关联的\r\nfuture 中。\r\n\r\nstd::promise (手动处理)\r\nstd::promise 是最底层的机制，它不会自动\r\ntry…catch\r\n你的代码。你（“生产者”线程）必须手动捕获异常，并手动将其存入\r\npromise。\r\n你有两种方法来做到这一点：\r\n方法\r\n1：set_exception(std::current_exception())\r\n(最常用)\r\n\r\n你必须在 try…catch(…) 块中调用计算函数。\r\n在 catch(…) 块中，你调用\r\nstd::current_exception()，它会捕获当前正在处理的异常，并将其打包成一个\r\nstd::exception_ptr。\r\n你将这个 exception_ptr 传递给\r\npromise.set_exception()。\r\nextern std::promise&lt;double&gt; some_promise;try{    some_promise.set_value(calculate_value()); // 尝试设置值}    catch(...){ // 如果 calculate_value() 抛出任何异常      // 捕获活动异常，并将其存入 promise    some_promise.set_exception(std::current_exception()); }\r\n\r\n还有一个非常重要的隐式异常：如果 promise 或 packaged_task\r\n被销毁了，但它承诺的值（或异常）却从未被设置，会发生什么？\r\n假设生产者线程创建了 std::promise p 和 std::future\r\nf。消费者线程拿到了 f，并阻塞在 f.get() 上。\r\n生产者线程因为某个错误（或者就是忘了）退出了，导致 p 被析构，而\r\np.set_value() 或 p.set_exception() 从未被调用。后果是,\r\n如果没有任何机制，消费者线程将永久死锁，永远等待一个不会到来的值。\r\n解决方案：\r\nstd::promise 和 std::packaged_task\r\n的析构函数会检查：“我是否在还未‘履约’的情况下就被销毁了？”\r\n如果是，析构函数会自动在 future\r\n的共享状态中存储一个特殊的异常：std::future_error。这个异常带有一个错误码：std::future_errc::broken_promise。\r\n正在 f.get() 上等待的消费者线程会被唤醒，并抛出\r\nstd::future_error\r\n异常。这就避免了死锁，并明确地通知消费者：“你的值永远不会来了，因为生产者放弃了”。\r\n多个线程的等待\r\n这一节解决了 std::future\r\n的一个核心局限性：如果有多个线程都需要等待同一个一次性事件的结果，该怎么办？\r\n问题的根源在于 std::future (唯一期望) 存在两大局限：\r\n\r\n它是“只移动”的 (Move-only)：就像 std::unique_ptr，std::future\r\n代表了对结果的独占所有权。\r\n\r\n你不能“拷贝”一个 std::future 分给两个线程。你只能将它从一个地方\r\nstd::move 到另一个地方。\r\n\r\nget() 只能调用一次：当唯一的那个线程调用 get() 之后，future\r\n内部的值就被“取走”了，future 对象变为空（valid() 返回 false）。\r\n\r\n这使得 std::future 无法被多个线程共享。\r\n\r\n\r\n结论：std::future\r\n只适用于一个线程（唯一的“所有者”）等待结果的场景。\r\n为了解决这个问题，C++标准库提供了 std::shared_future\r\n(共享期望)。\r\n\r\n类比：std::future 对应 std::unique_ptr，而 std::shared_future 对应\r\nstd::shared_ptr。\r\n\r\n它代表了对异步结果的共享所有权,\r\n是“可拷贝”的 (Copyable)。\r\n\r\n你可以创建 std::shared_future\r\n的多个拷贝，并将这些拷贝分发给任意数量的线程。\r\n所有这些拷贝都指向同一个内部的“共享状态”（即那个“一次性事件”的结果）。\r\n当事件发生（例如 promise 被 set_value）时，所有的 shared_future\r\n拷贝会同时变为“就绪”状态。\r\n每个线程都可以在它自己的拷贝上调用 get() 来获取结果（get() 在\r\nshared_future 上返回 const\r\nT&amp;，并且可以被多次调用）。\r\n\r\n如何创建 std::shared_future\r\n你不能直接创建 std::shared_future。它必须从一个 std::future\r\n转换而来，因为 std::future 是那个“唯一所有者”。\r\n方法 1：构造时显式 std::move (最清晰)\r\nstd::future 是“唯一”的，shared_future\r\n是“共享”的。要从“唯一”变为“共享”，你必须交出“唯一所有权”。\r\nstd::promise&lt;int&gt; p;std::future&lt;int&gt; f = p.get_future();assert(f.valid()); // 1. f 是合法的 (持有状态)// 2. 将 f 的所有权“移动”给 sfstd::shared_future&lt;int&gt; sf(std::move(f)); assert(!f.valid()); // 3. f 此时不再合法 (它已交出所有权)assert(sf.valid()); // 4. sf 现在是合法的\r\n方法 2：隐式 std::move (从右值)\r\n如果 std::future\r\n是一个临时对象（右值），C++会自动进行移动。\r\np.get_future() 返回的就是一个临时的 std::future\r\n对象。 std::promise&lt;std::string&gt; p;// 1. p.get_future() 返回的临时 future 被自动移动构造 sfstd::shared_future&lt;std::string&gt; sf(p.get_future());\r\n方法 3：使用 .share() 成员函数 (最便捷)\r\nstd::future 提供了一个 .share() 成员函数，它为你执行 std::move\r\n并返回一个新的 std::shared_future。 std::promise&lt;int&gt; p;std::shared_future&lt;int&gt; sf = p.get_future().share();// 这种方式在类型很复杂时特别有用，可以配合 auto：std::promise&lt;std::map&lt;MyKey, MyData&gt;::iterator&gt; p;// auto 会自动推导出那个非常长的 shared_future 类型auto sf = p.get_future().share();\r\n通过使用\r\nstd::shared_future，你可以轻松地实现多个线程等待同一个异步结果的场景，而不需要复杂的同步机制。\r\n使用同步操作简化代码\r\n这里的同步不同于阻塞机制,\r\n是广义上的、指代线程间协调和结果传递的机制，特别是非互斥量的同步工具。\r\n它指的是使用 std::future、std::promise、std::packaged_task\r\n等这些工具，以一种更高层、更抽象的方式来管理线程间的协作，从而简化代码结构。\r\n使用“future”的函数化编程 (FP)\r\n在并发上下文中，FP 模式的核心思想是避免共享可变状态,\r\n尽量使用纯函数 (Pure Function)。 -\r\n纯函数指的是一个函数，其输出只依赖于其输入参数，并且不会改变任何外部状态（没有“副作用”）。例如\r\nsin(x)、sqrt(x)、3 + 3。\r\n如果你的代码主要由纯函数构成，那么并发将变得极其简单。\r\n没有共享的可变数据 = 没有数据竞争 = 不需要互斥量 =\r\n没有死锁。\r\n两个 sin(x) 和 cos(y)\r\n的调用可以安全地在两个线程上完全并行执行，因为它们不共享任何东西。\r\nC++11 通过 Lambda、std::bind 和 auto 使得编写 FP\r\n风格的代码变得更加容易。更重要的是, 还有 std::future 这个 FP\r\n并发模式的“粘合剂”\r\n在 FP 模式中，如果函数不共享内存，它们如何协同工作呢？\r\n答案是：一个函数的输出成为另一个函数的输入。\r\nstd::future（期望）就是实现这种“数据流”的完美工具。它充当了一个异步的通信通道。\r\n它允许一个线程（任务A）的计算结果（future）被另一个线程（任务B）作为依赖项来等待。\r\n线程B等待的是“数据”（future.get()），而不是“锁”（mutex.lock()）。这是一种更高级、更声明式的同步。\r\n示例：并行快速排序\r\n\r\n快速排序是一种经典的排序算法。它的基本思想是： 1. 选择一个“基准”元素\r\n(pivot)。 2. 将数组划分为两部分：小于基准的元素和大于基准的元素。 3.\r\n递归地对这两部分进行排序。 4. 最后将排序好的两部分与基准元素合并。\r\n\r\n首先是一个简单的顺序版本： template&lt;typename T&gt;std::list&lt;T&gt; sequential_quick_sort(std::list&lt;T&gt; input){  if(input.empty())  {    return input;  }  std::list&lt;T&gt; result;  result.splice(result.begin(),input,input.begin());  // 1  T const&amp; pivot=*result.begin();  // 2  auto divide_point=std::partition(input.begin(),input.end(),             [&amp;](T const&amp; t){return t&lt;pivot;});  // 3  std::list&lt;T&gt; lower_part;  lower_part.splice(lower_part.end(),input,input.begin(),             divide_point);  // 4  auto new_lower(             sequential_quick_sort(std::move(lower_part)));  // 5  auto new_higher(             sequential_quick_sort(std::move(input)));  // 6  result.splice(result.end(),new_higher);  // 7  result.splice(result.begin(),new_lower);  // 8  return result;}\r\n现在，我们使用 std::async 和 std::future 将其并行化。\r\n思路：第4步（排序低区）和第5步（排序高区）是完全独立的，它们可以并行执行\r\ntemplate&lt;typename T&gt;std::list&lt;T&gt; parallel_quick_sort(std::list&lt;T&gt; input){  if(input.empty()) { return input; }    std::list&lt;T&gt; result;  result.splice(result.begin(), input, input.begin());  T const&amp; pivot = *result.begin();    auto divide_point = std::partition(...);    std::list&lt;T&gt; lower_part;  lower_part.splice(..., divide_point);  // 1. 【变化点 1】：异步执行“低区”排序  std::future&lt;std::list&lt;T&gt;&gt; new_lower(       std::async(&amp;parallel_quick_sort&lt;T&gt;, std::move(lower_part)));  // 2. 【变化点 2】：当前线程“复用”自身，同步执行“高区”排序  auto new_higher(      parallel_quick_sort(std::move(input)));  // 3. 拼接“高区”（它已经完成了）  result.splice(result.end(), new_higher);     // 4. 【变化点 3】：等待“低区”结果并拼接  result.splice(result.begin(), new_lower.get());     return result;} std::future 允许我们用 FP\r\n风格编写并发代码。我们不再思考“哪个线程在何时锁定了哪个互斥量”，而是转为思考“任务A依赖于任务B的结果”。\r\nstd::future 充当了 B 和 A 之间的“依赖通道”，A 通过 B.get()\r\n来声明这种依赖关系，C++运行时会自动处理底层的阻塞和唤醒，极大简化了代码。\r\n使用消息传递的同步操作\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"5. 基于锁的并发设计结构","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/5.%20%E5%9F%BA%E4%BA%8E%E9%94%81%E7%9A%84%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1%E7%BB%93%E6%9E%84/","content":"为并发设计\r\n首先,\r\n什么是并发数据结构？一个并发数据结构是指一个可以被多个线程同时访问的数据结构。\r\n也就是说, 其最低要求是线程安全 (Thread Safety)\r\n这意味着，即使多个线程并发地对数据结构执行操作（无论是相同还是不同的操作），数据结构也必须保持其内部一致性:\r\n\r\n无数据丢失或损坏。\r\n所有的不变量 (Invariants)\r\n必须始终保持（或者说，没有线程能看到不变量被破坏的中间状态）。\r\n无数据竞争 (Data Races)。\r\n\r\n然而,\r\n仅仅“线程安全”是不够的：许多简单的方法可以实现线程安全（例如，用一个巨大的互斥锁锁住整个数据结构），但这样做往往会牺牲性能。\r\n因此,\r\n本节的核心论点是：设计并发数据结构的真正意义不仅仅在于线程安全，更在于允许真正的并行处理，从而提高程序的性能,\r\n高效地利用多核处理器, 实现”真正的并发”。\r\n“真并发” (True\r\nConcurrency)：目标是让多个线程能够在同一时间点上，有效地在数据结构的不同部分或执行不同的（非冲突的）操作上取得进展。这与仅仅保证“一次只有一个线程能安全访问”形成了鲜明对比。\r\n序列化 (Serialization),\r\n或者说串行化则是并发的天敌：当你使用单一的全局互斥量来保护整个数据结构时（就像第3章、第4章中的简单栈和队列实现），虽然保证了线程安全，但也引入了序列化。\r\n序列化意味着：无论有多少线程想要访问数据结构，它们都必须排队等待获取那唯一的锁。在任何时刻，只有一个线程能够实际工作。这实际上将并发访问变成了串行访问（一个接一个），完全抵消了使用多线程带来的潜在性能优势。CPU\r\n核心闲置，线程都在等待。\r\n总之, 这一章设计的核心目标是：\r\n\r\n减少保护区域 (Reduce Protected\r\nSections)：尽量缩小必须持有锁的代码范围。\r\n减少序列化 (Reduce\r\nSerialization)：尽量避免让所有线程都争抢同一个锁。\r\n提升并发访问的潜力 (Increase Potential for\r\nConcurrency)：通过更精细的控制，允许多个线程在不冲突的情况下同时操作数据结构。\r\n\r\n这需要我们超越简单的单锁模型，仔细思考如何分解数据结构，使用更细粒度的锁或其他同步机制，以最大限度地减少线程等待，最大化并行处理的机会。\r\n指导原则第一方面：确保访问安全\r\n(Ensure Safety)\r\n要想设计真正并发的数据结构，首先必须确保访问安全/线程安全。这意味着无论有多少线程同时访问数据结构，都不会导致数据损坏或不一致。\r\n这部分原则主要是对第3章中已经讨论过的线程安全问题的回顾和强调，因为安全是并发设计的基石。\r\n\r\n确保不变量不被破坏时可见 (Protect\r\nInvariants)：\r\n\r\n核心：必须保证任何线程在任何时候都不会访问到数据结构处于“中间状态”（即不变量暂时被破坏时）的数据。\r\n实现：通常通过锁（互斥量）来保护那些修改数据结构并可能暂时破坏不变量的代码段。\r\n\r\n小心接口造成的条件竞争 (Design Interfaces\r\nCarefully)：\r\n\r\n核心：即使每个单独的成员函数都是线程安全的（内部加锁），函数之间的组合调用也可能产生条件竞争（例如第3章\r\nstack 的 empty/top 问题）。\r\n建议：接口应该提供原子性的操作，完成一个完整的逻辑功能，而不是提供一系列需要用户组合起来才能完成功能的“步骤”函数。\r\n\r\n注意异常安全 (Ensure Exception Safety)：\r\n\r\n核心：当数据结构的操作（特别是在持有锁时）抛出异常，必须保证数据结构的状态仍然是有效的（不变量未被永久破坏），并且锁能够被正确释放。\r\n实现：\r\n\r\n使用 RAII 锁管理（如 std::lock_guard,\r\nstd::unique_lock）来确保锁在异常时自动释放。\r\n仔细设计操作步骤，确保在可能抛出异常的操作（如内存分配、拷贝/移动用户数据）失败时，数据结构能回滚到一致状态，或者至少保持有效状态。\r\n\r\n\r\n将死锁风险降至最低 (Minimize Deadlock\r\nRisk)：\r\n\r\n核心：死锁是并发设计中的常见陷阱，尤其是在使用多个锁时。\r\n建议：\r\n\r\n限制锁的范围：尽可能缩短持有锁的时间。\r\n避免嵌套锁：一个线程已持有锁A时，避免再去获取锁B。\r\n按固定顺序加锁：如果必须获取多个锁，所有线程都按同一顺序获取。\r\n避免在持有锁时调用用户代码：防止用户代码尝试获取其他锁导致死锁。\r\n\r\n\r\n考虑特殊成员函数：\r\n\r\n构造函数/析构函数：通常需要独占访问。用户必须保证在构造完成前、析构开始后，没有其他线程访问该对象。\r\n拷贝构造/赋值/swap()：如果你的数据结构支持这些操作，作为设计者，你需要明确它们在并发环境下的行为：它们是线程安全的吗？它们需要独占访问吗？用户在使用这些操作时需要注意什么？\r\n\r\n\r\n指导原则第二方面：确保真正的并发访问\r\n(Enable True Concurrency)\r\n这部分原则是本章的新重点，关注如何在保证安全的前提下，最大化数据结构的并行处理能力。\r\n\r\n锁的范围能否缩小？ (Minimize Lock Scope)\r\n\r\n问题：当前持有锁执行的操作中，是否有部分可以安全地移到锁的范围之外执行？\r\n示例：内存分配\r\n(new)、数据的拷贝/准备等耗时操作，如果可以，应在获取锁之前或释放锁之后进行（如在\r\npush 之前 make_shared 的例子）。\r\n\r\n能否使用多个锁？ (Fine-grained Locking)\r\n\r\n问题：数据结构的不同部分是否可以由不同的互斥量来保护？\r\n目标：实现细粒度锁。如果线程A操作数据结构的A部分（锁A），线程B操作B部分（锁B），它们就可以并行执行。\r\n挑战：增加了复杂性，需要仔细管理多个锁，并警惕死锁（如果一个操作需要同时获取多个锁）。\r\n\r\n是否所有操作都需要同级锁？ (Different Lock\r\nTypes)\r\n\r\n问题：对于“只读”操作和“读写”操作，是否需要相同的（独占）锁保护？\r\n目标：利用读写锁（如\r\nstd::shared_mutex）。允许多个“读者”线程并发访问，只有“写者”线程需要独占访问。\r\n适用场景：“读多写少”的数据结构（如查询表）。\r\n\r\n能否通过修改结构来增加并发？ (Modify Structure\r\nfor Concurrency)\r\n\r\n问题：当前数据结构的内部组织方式是否本身就限制了并发？能否通过简单的修改来减少冲突点？\r\n示例：后面将要介绍的队列实现，通过引入一个“哑节点”，将\r\npush（操作尾部）和\r\npop（操作头部）的操作目标分离开，从而允许它们在大部分时间里使用不同的锁并行执行。\r\n\r\n\r\n所有这些并发指导原则都服务于一个核心思想：如何在保证安全（通过必要的锁和同步）的前提下，最大限度地减少线程因锁而产生的等待（序列化），从而最大化线程能够并行执行（真并发）的机会？\r\n这是一个权衡 (Trade-off)\r\n的过程。更细粒度的锁、更复杂的同步机制可以带来更高的并发潜力，但也显著增加了设计的复杂性、出错（死锁、竞争）的风险以及可能的额外开销。设计者需要根据数据结构的具体使用场景和性能需求来做出明智的选择。\r\n基于锁的并发数据结构\r\n首先, 基于锁的设计天然就面临着挑战：\r\n\r\n锁的本质是互斥 (Mutual\r\nExclusion)：它通过阻止并发访问来保证安全。\r\n并发的目标是并行\r\n(Parallelism)：我们希望允许多个线程同时工作。\r\n\r\n这两者本身就存在一定的矛盾。简单地使用一个大锁保护整个数据结构虽然安全，但会完全序列化访问，牺牲并发性。因此，本节的目标是探索如何在必要的保护（使用锁）与最大化的并发之间找到平衡点。\r\n本节的核心策略是：最小化锁的影响\r\n对于基于锁的数据结构，提高并发性的关键策略在于最小化锁的持有时间和范围：\r\n\r\n持有锁的时间最短：只在绝对必要（访问或修改共享状态）时才持有锁。耗时的操作（如内存分配、复杂计算、I/O）应尽可能在锁外完成。\r\n锁的粒度尽可能小 (Fine-grained\r\nLocking)：如果数据结构的不同部分可以独立修改，考虑使用多个锁分别保护不同部分，而不是用一个锁保护所有部分。\r\n\r\n线程安全栈——使用锁\r\n这一节的目标是重新审视我们在第3章实现的那个线程安全的栈，并使用上一节提出的指导原则来对其进行严格的分析，特别是评估它的安全性和并发性。\r\n首先，我们回顾一下这个栈的实现。它本质上是用一个 std::mutex\r\n包装了一个标准的 std::stack。 #include &lt;exception&gt;#include &lt;stack&gt; // 引入 std::stack#include &lt;mutex&gt;#include &lt;memory&gt; // 为了 std::shared_ptrstruct empty_stack: std::exception{  const char* what() const throw(); // 假设已实现};template&lt;typename T&gt;class threadsafe_stack{private:  std::stack&lt;T&gt; data;  mutable std::mutex m; // mutable 允许 const 成员函数 lockpublic:  threadsafe_stack(){} // 默认构造  // 拷贝构造函数  threadsafe_stack(const threadsafe_stack&amp; other)  {    std::lock_guard&lt;std::mutex&gt; lock(other.m); // 锁住源对象    data = other.data; // 在锁内执行拷贝  }  threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; // 禁止赋值  // push 操作  void push(T new_value)  {    std::lock_guard&lt;std::mutex&gt; lock(m);    data.push(std::move(new_value));  // 1. 可能调用 T 的移动构造  }  // pop 操作 (返回 shared_ptr)  std::shared_ptr&lt;T&gt; pop()  {    std::lock_guard&lt;std::mutex&gt; lock(m);    if(data.empty()) throw empty_stack();  // 2. 检查空 (在锁内)    // 3. 创建 shared_ptr (可能调用 T 的拷贝/移动构造)    std::shared_ptr&lt;T&gt; const res(      std::make_shared&lt;T&gt;(std::move(data.top())));    data.pop();  // 4. 从栈中移除 (noexcept)    return res;  }  // pop 操作 (写入引用)  void pop(T&amp; value)  {    std::lock_guard&lt;std::mutex&gt; lock(m);    if(data.empty()) throw empty_stack(); // 检查空 (在锁内)    value = std::move(data.top());  // 5. 移动赋值给 value (可能调用 T 的移动赋值)    data.pop();  // 6. 从栈中移除 (noexcept)  }  // empty 操作  bool empty() const  {    std::lock_guard&lt;std::mutex&gt; lock(m);    return data.empty();  }};\r\n安全性分析\r\n\r\n不变量保护: 通过在每一个成员函数（push, pop, empty,\r\n拷贝构造）的入口处使用\r\nstd::lock_guard&lt;std::mutex&gt; lock(m);，该实现保证了在任何时刻只有一个线程能够访问底层的\r\nstd::stack&lt;T&gt; data。 因此，当一个线程正在修改\r\ndata（例如 push 或 pop）并可能暂时破坏 std::stack\r\n的内部不变量时，没有其他线程能够看到这种中间状态。\r\n接口条件竞争:\r\n\r\nempty()/pop() 竞争：pop()\r\n函数在获取锁之后、执行任何操作之前，会显式地检查 data.empty()\r\n。因此，即使外部调用者先检查了 empty()，pop()\r\n内部的检查也能保证操作的安全性，避免了 TOCTTOU 竞争。（已处理）\r\ntop()/pop() 竞争：标准 std::stack\r\n将这两个操作分开，导致竞争。这里的 threadsafe_stack\r\n通过提供合并的 pop 操作（直接返回弹出的值，无论是通过\r\nshared_ptr 还是引用）来避免了这个接口竞争。（已处理）\r\n\r\n异常安全:\r\n\r\n锁管理: 使用 std::lock_guard\r\n保证了即使在操作中（如内存分配或用户类型操作）抛出异常，互斥锁 m\r\n也会被自动、安全地释放。\r\npush(T new_value): 异常可能来自 data.push() 内部（内存分配失败或\r\nT 的移动构造函数抛异常）。而 std::stack::push\r\n通常提供强异常保证（失败时栈不变）。因此 push 是异常安全的。\r\npop() (shared_ptr 版本):\r\n\r\nempty_stack 异常 (标记 2): 抛出前未修改数据，安全。\r\nmake_shared&lt;T&gt;(...) (标记 3):\r\n可能因内存分配失败或 T 的拷贝/移动构造函数抛异常。如果发生，data.pop()\r\n(标记 4) 不会被执行，栈保持不变。标准库保证 make_shared\r\n失败时无内存泄漏。因此是异常安全的（强保证）。\r\ndata.pop() (标记 4): 本身保证不抛异常 (noexcept)。\r\n\r\npop(T&amp; value) (引用版本):\r\n\r\nempty_stack 异常: 安全。\r\nvalue = std::move(data.top()) (标记 5): 可能因 T\r\n的移动赋值运算符抛异常。如果发生，data.pop() (标记 6)\r\n不会被执行，栈保持不变。因此是异常安全的（强保证）。\r\ndata.pop() (标记 6): 本身保证不抛异常 (noexcept)。\r\n\r\nempty(): 只读操作，使用 lock_guard，异常安全。\r\n结论: 该栈设计具有良好的异常安全性。\r\n\r\n死锁风险:\r\n\r\n主要风险点：在持有互斥锁 m 的同时，调用了用户提供的代码：\r\n\r\npush 中的 T 的移动构造函数 (间接在 data.push 内),\r\n虽然是隐式调用。\r\npop (shared_ptr) 中的 T 的拷贝/移动构造函数 (在 make_shared 内),\r\n同样是隐式调用。\r\npop (引用) 中的 T 的移动赋值运算符。\r\n拷贝构造函数中的 T 的拷贝赋值运算符 (在 data = other.data 内)。\r\n(\r\n因为T的类型是用户定义的，用户可能在这些操作中尝试获取其他锁，从而引发死锁\r\n)\r\n\r\n死锁场景：如果这些用户代码（直接或间接地）尝试再次锁定同一个\r\nthreadsafe_stack 实例的互斥锁 m，就会发生死锁（如果用 std::mutex\r\n则是未定义行为）。\r\n责任：实际上,\r\n避免这种由用户代码引起的死锁是用户的责任，数据结构本身无法完全阻止。用户不应该在\r\nT 的操作中对包含它的栈进行操作。（存在风险，依赖用户）\r\n\r\n特殊成员函数:\r\n\r\n拷贝构造: 明确定义了，并且通过锁住源对象 (other.m)\r\n来保证拷贝过程的线程安全。\r\n赋值: 被显式删除 (=\r\ndelete)，避免了复杂的、难以保证线程安全的赋值语义。\r\n构造/析构:\r\n它们本身不是线程安全的。用户必须确保在对象完全构造好之前没有其他线程访问它，并且在对象开始析构后也没有线程再访问它。这是标准的C++对象生命周期规则，适用于所有对象，不仅仅是并发数据结构。（用户责任）\r\n\r\n\r\n并发性分析\r\n\r\n锁的范围:\r\n几乎每个成员函数都立即获取锁，并在函数结束时才释放锁。锁的范围覆盖了函数的整个执行过程。\r\n多个锁: 只使用了一个互斥量 m 来保护整个 std::stack\r\ndata。\r\n不同锁级别: 没有使用读写锁等不同级别的锁。\r\n结构修改: 没有对 std::stack\r\n的内部结构进行修改以提高并发性，只是简单地包装。\r\n\r\n结论: 这个设计通过将所有操作完全序列化\r\n(Serialization)\r\n来保证线程安全。在任何时刻，最多只有一个线程可以对栈执行任何操作（无论是\r\npush, pop 还是 empty）。\r\n因此并发性极差。它没有利用多核处理器的能力。如果多个线程频繁访问栈，它们大部分时间都会阻塞在等待锁上。\r\n而且, 这个实现还存在缺乏等待机制的问题.\r\n当栈为空时，pop 操作会抛出 empty_stack\r\n异常。如果一个“消费者”线程需要等待“生产者”线程向栈中 push\r\n数据，它该怎么办？\r\n目前的实现只能够不断循环调用 try_pop 或 empty (忙等待/轮询), 不断调用\r\npop 并捕获异常。\r\n这些方案浪费CPU资源，并且可能因为频繁的锁竞争而降低整体性能。\r\n更好的方案则需要数据结构内部提供高效的等待机制，例如使用条件变量。\r\n总之, threadsafe_stack\r\n是一个线程安全数据结构的基本示例。它满足了安全性的基本要求（虽然有用户代码导致死锁的风险）。\r\n然而，它在并发性方面表现很差，因为它将所有操作都序列化了。并且，它缺乏有效的等待机制，不适合典型的生产者-消费者场景。\r\n线程安全队列——使用锁和条件变量\r\n本节实际上是重新审视并分析了第4章已经实现的那个队列, 比起栈,\r\n它引入了条件变量来处理线程等待的问题。\r\n这个队列的核心是使用一个 std::mutex 来保护底层的\r\nstd::queue，并使用一个 std::condition_variable 来实现等待功能。\r\ntemplate&lt;typename T&gt;class threadsafe_queue{private:  mutable std::mutex mut;  std::queue&lt;T&gt; data_queue;  std::condition_variable data_cond;public:  threadsafe_queue() {}  // Push 操作  void push(T new_value)  {    std::lock_guard&lt;std::mutex&gt; lk(mut);    data_queue.push(std::move(new_value)); // 原文可能是 data，应为 new_value    data_cond.notify_one();  // 1. 唤醒一个等待者  }  // Wait and Pop 操作 (阻塞，写入引用)  void wait_and_pop(T&amp; value)  // 2  {    std::unique_lock&lt;std::mutex&gt; lk(mut); // 必须用 unique_lock    // 等待，直到 lambda 返回 true (队列非空)    data_cond.wait(lk, [this]{ return !data_queue.empty(); });    value = std::move(data_queue.front());    data_queue.pop();  }  // Wait and Pop 操作 (阻塞，返回 shared_ptr)  std::shared_ptr&lt;T&gt; wait_and_pop()  // 3  {    std::unique_lock&lt;std::mutex&gt; lk(mut); // 必须用 unique_lock    // 4. 等待    data_cond.wait(lk, [this]{ return !data_queue.empty(); });    // 可能抛异常点 1: make_shared 分配内存    // 可能抛异常点 2: T 的拷贝/移动构造    std::shared_ptr&lt;T&gt; res(      std::make_shared&lt;T&gt;(std::move(data_queue.front())));    data_queue.pop(); // 不抛异常    return res;  }  // Try Pop 操作 (非阻塞，写入引用)  bool try_pop(T&amp; value)  {    std::lock_guard&lt;std::mutex&gt; lk(mut); // 非阻塞，可用 lock_guard    if(data_queue.empty())      return false; // 不等待，立即返回    value = std::move(data_queue.front()); // 可能调用 T 的移动赋值    data_queue.pop();    return true;  }  // Try Pop 操作 (非阻塞，返回 shared_ptr)  std::shared_ptr&lt;T&gt; try_pop()  {    std::lock_guard&lt;std::mutex&gt; lk(mut); // 非阻塞，可用 lock_guard    if(data_queue.empty())      return std::shared_ptr&lt;T&gt;();  // 5. 返回空指针表示失败    // 可能抛异常点 1: make_shared    // 可能抛异常点 2: T 的拷贝/移动构造    std::shared_ptr&lt;T&gt; res(      std::make_shared&lt;T&gt;(std::move(data_queue.front())));    data_queue.pop();    return res;  }  // Empty 操作  bool empty() const  {    std::lock_guard&lt;std::mutex&gt; lk(mut);    return data_queue.empty();  }};\r\n与 threadsafe_stack\r\n的对比与分析\r\n这个队列的设计与上述的栈有很多相似之处，但也引入了关键的不同.\r\n相似性:\r\n\r\n仍然使用单一互斥量 (mut) 保护整个底层容器\r\n(data_queue)。\r\n接口设计上，同样通过合并 front/pop 操作到\r\nwait_and_pop/try_pop 中，避免了接口固有的条件竞争。\r\ntry_pop 的逻辑与栈的 pop 非常相似（除了失败时不抛异常，而是返回\r\nfalse 或 nullptr）。\r\n同样存在因调用用户代码（T的构造/赋值）而导致的死锁风险。\r\n构造/析构函数同样不是线程安全的，需要用户保证生命周期管理。\r\n\r\n关键不同点:\r\n\r\n等待机制: wait_and_pop 使用\r\nstd::condition_variable::wait\r\n来高效地等待队列非空。这解决了栈实现中消费者需要“忙等待”或轮询的问题。\r\n通知机制: push 操作 (标记 ①) 在添加元素后调用\r\ndata_cond.notify_one() 来唤醒一个可能正在 wait_and_pop\r\n中等待的消费者线程。\r\n锁类型: wait_and_pop 必须使用 std::unique_lock，因为 wait\r\n操作需要在等待期间释放锁，并在被唤醒后重新获取锁。push, try_pop, empty\r\n等非阻塞操作则可以使用更高效的 std::lock_guard。\r\n\r\n然而, wait_and_pop\r\n引入条件变量的同时也带来了一个新的异常安全挑战：\r\n假设多个消费者线程阻塞在 wait_and_pop 的 data_cond.wait() 上。\r\n一个生产者线程调用 push，然后调用 notify_one()唤醒了一个消费者线程\r\nC1。C1 从 wait 返回，成功获取了锁，并且检查到队列非空。\r\n问题点: 在 C1 执行 std::make_shared&lt;T&gt;(...) 或\r\nvalue = std::move(...) 时，如果 T\r\n类型的构造函数或赋值运算符抛出异常, 后果是 C1\r\n抛出异常，data_queue.pop()\r\n不会被执行，数据项仍然留在队列中。\r\n但是，唤醒 C1 的那个 notify_one\r\n信号已经被“消耗”了。\r\n如果没有其他生产者再 push 新数据并发送新的 notify_one\r\n信号，那么其他原本在等待的消费者线程（C2,\r\nC3…）将永远不会被唤醒来处理那个留在队列中的数据项！它们会永久阻塞。\r\n这个问题目前有三种可能的解决方案：\r\n\r\nnotify_all(): 在 push 中总是调用\r\nnotify_all()。当 C1 异常退出时，其他线程 C2, C3…\r\n也会被唤醒，其中一个会成功处理数据。但是显然效率低下（惊群效应\r\nThundering Herd）。\r\n在 catch 中重新 notify_one(): 在 wait_and_pop\r\n内部加上 try…catch 可能抛异常的操作，在 catch\r\n块中调用 notify_one() 唤醒另一个线程，然后 throw;\r\n重新抛出异常。缺点是代码复杂。\r\n在队列中存储 std::shared_ptr:\r\n通过将数据项包装在 std::shared_ptr\r\n中，可以确保即使在异常情况下，数据项也能被正确处理。\r\n```cpp template class threadsafe_queue{ private:\r\nmutable std::mutex mut; std::queue&lt;std::shared_ptr&gt; data_queue;\r\nstd::condition_variable data_cond; public: threadsafe_queue() {}\r\n  void wait_and_pop(T&amp; value)\r\n  {\r\n      std::unique_lock&lt;std::mutex&gt; lk(mut);\r\n      data_cond.wait(lk,[this]{return !data_queue.empty();});\r\n      value=std::move(*data_queue.front());  // 1\r\n      data_queue.pop();\r\n  }\r\n\r\n  bool try_pop(T&amp; value)\r\n  {\r\n      std::lock_guard&lt;std::mutex&gt; lk(mut);\r\n      if(data_queue.empty())\r\n      return false;\r\n      value=std::move(*data_queue.front());  // 2\r\n      data_queue.pop();\r\n      return true;\r\n  }\r\n\r\n  std::shared_ptr&lt;T&gt; wait_and_pop()\r\n  {\r\n      std::unique_lock&lt;std::mutex&gt; lk(mut);\r\n      data_cond.wait(lk,[this]{return !data_queue.empty();});\r\n      std::shared_ptr&lt;T&gt; res=data_queue.front();  // 3\r\n      data_queue.pop();\r\n      return res;\r\n  }\r\n\r\n  std::shared_ptr&lt;T&gt; try_pop()\r\n  {\r\n      std::lock_guard&lt;std::mutex&gt; lk(mut);\r\n      if(data_queue.empty())\r\n      return std::shared_ptr&lt;T&gt;();\r\n      std::shared_ptr&lt;T&gt; res=data_queue.front();  // 4\r\n      data_queue.pop();\r\n      return res;\r\n  }\r\n\r\n  void push(T new_value)\r\n  {\r\n      std::shared_ptr&lt;T&gt; data(\r\n      std::make_shared&lt;T&gt;(std::move(new_value)));  // 5\r\n      std::lock_guard&lt;std::mutex&gt; lk(mut);\r\n      data_queue.push(data);\r\n      data_cond.notify_one();\r\n  }\r\n\r\n  bool empty() const\r\n  {\r\n      std::lock_guard&lt;std::mutex&gt; lk(mut);\r\n      return data_queue.empty();\r\n  }\r\n}; 关键改动:\r\npush 函数现在在获取锁之前就创建\r\nstd::shared_ptr&lt;T&gt;。这包含了可能抛异常的内存分配和 T\r\n的构造。\r\n锁内操作: 在锁保护下，push 只需要将 shared_ptr\r\n(这是一个很小的对象) 拷贝/移动到 std::queue\r\n中。这个操作通常很快，并且不太可能抛异常。\r\npop 操作: 在 wait 返回后，pop 操作只需要从队列中拷贝/移动\r\nshared_ptr。拷贝 shared_ptr\r\n是原子操作且不涉及用户代码，非常安全。之后如果需要返回 T&amp;\r\n，则需要解引用并移动赋值，这里仍然存在 T\r\n的移动赋值可能抛异常的风险，但原始数据（shared_ptr）已被安全取出。\r\n\r\n优点: - 解决了异常安全问题: wait_and_pop 在锁内执行的操作（拷贝\r\nshared_ptr）基本不会抛异常，大大降低了“丢失唤醒”的风险。 -\r\n提高了性能/并发潜力: 将耗时的内存分配 (make_shared) 和 T 的构造移到了\r\npush 函数的锁范围之外。这意味着 push\r\n操作持有锁的时间大大缩短，其他线程（执行 push, pop 或\r\nempty）等待锁的时间也相应减少，提高了并发的可能性。\r\n并发性分析和总结\r\n核心限制:\r\n无论是原先的线程安全队列还是使用指针优化后的队列，它们都仍然使用单一互斥量\r\n(mut) 来保护整个 data_queue。\r\n后果就是所有对队列的操作（push, wait_and_pop, try_pop,\r\nempty）在同一时间点仍然只能有一个线程在执行。\r\n\r\n尽管使用指针优化后的队列通过减少锁持有时间略微提高了并发潜力，但本质上这个队列仍然是一个序列化访问的结构，并发性受限于单锁瓶颈。\r\n\r\n基于单锁和条件变量的 threadsafe_queue (特别是存储 shared_ptr 的版本)\r\n是一个实用且常用的并发数据结构。它安全、解决了等待问题，并且通过优化减少了锁争用。\r\n要实现更高程度的并发（允许多个 push 或多个 pop\r\n同时进行），就需要打破单一锁的限制，采用更细粒度的锁策略。这正是下一节将要探讨的内容，通过重新实现队列的底层链表结构来引入多个锁。\r\n线程安全队列——使用细粒度锁和条件变量\r\n继上一节指出单锁队列并发性不足后，本节的目标是打破单锁瓶颈，通过使用多个锁（细粒度锁）来显著提升队列的并发性能。\r\n首先问题回顾：上一节的队列虽然安全且解决了等待问题，但所有操作（push,\r\npop, empty）都被同一个互斥量 mut 序列化了。即使一个线程想\r\npush（操作队尾），另一个线程想\r\npop（操作队头），它们也必须排队等待同一个锁。\r\n核心思路：队列的 push 和 pop\r\n操作在逻辑上是作用于队列的两端。我们能否设计一种锁策略，使得对队头和队尾的操作能够并行进行？\r\n初步尝试：简单的链表与头尾锁\r\n如果依旧使用deque或std::queue作为底层容器，实现细粒度锁会非常复杂，因为这些容器的内部结构并不支持独立地锁定头部和尾部。\r\n因此在底层结构上, 我们选择放弃\r\nstd::queue，自己实现一个简单的单向链表来表示队列,\r\nhead 指针指向第一个节点, tail\r\n指针指向最后一个节点, 每个节点包含数据和指向下一个节点的 next\r\n指针。\r\n细粒度锁的初步想法： - 用 head_mutex 保护 head 指针。pop 操作需要获取\r\nhead_mutex(尾进头出) - 用 tail_mutex 保护 tail 指针。push 操作需要获取\r\ntail_mutex。\r\n致命缺陷 (空队列 &amp; 单元素队列)：\r\n\r\n空队列：head 和 tail 都为 nullptr。push 第一个元素时，需要同时修改\r\nhead 和 tail，必须获取两个锁。pop 需要读取 head。\r\n单元素队列：head 和 tail 指向同一个节点。pop 需要读取 head-&gt;next\r\n(为 nullptr) 并将 head 设为 nullptr。push 需要读取 tail-&gt;next (为\r\nnullptr) 并修改 tail-&gt;next 指向新节点，然后更新 tail。\r\n\r\n冲突：push 和 pop 同时在竞争访问和修改同一个节点的\r\nnext 指针！简单的头尾锁无法解决这个冲突。\r\n\r\n\r\n解决方案：引入哑节点 (Dummy\r\nNode)\r\n为了解耦头尾操作，特别是处理空队列和单元素队列的边界情况，引入了“哑节点”技术：\r\n机制：队列永远包含至少一个节点——这个节点就是“哑节点”，它不存储有效数据。tail\r\n指针始终指向这个哑节点。head\r\n指针指向队列中的第一个实际数据节点。\r\n空队列：当队列为空时，head 指针也指向哑节点 (即 head == tail)。\r\n操作流程 (简化版)：\r\n\r\npush(value)：push 主要操作的是 tail 指针和原 tail 指向的节点。\r\n\r\n创建一个新的哑节点 p。\r\n将 value 存入当前的哑节点（tail 指向的那个）。\r\n将当前哑节点的 next 指向新的哑节点 p。\r\n将 tail 指针更新为指向 p。\r\n\r\npop()：pop 主要操作的是 head 指针。\r\n\r\n读取 head 指向节点的数据。\r\n将 head 指针更新为 head-&gt;next。\r\n(旧的 head 节点会被 unique_ptr 自动删除, 因为它超出了作用域)。\r\n\r\n\r\n优点：通过哑节点作为缓冲区，push 和 pop\r\n操作（在队列非空时）访问和修改的是不同的节点和指针，为使用不同的锁提供了基础。\r\n细粒度锁与条件变量的完整实现\r\n基于哑节点，现在可以设计真正的细粒度锁队列： #include &lt;memory&gt;               // For std::unique_ptr, std::shared_ptr, std::make_shared#include &lt;mutex&gt;                // For std::mutex, std::lock_guard, std::unique_lock#include &lt;condition_variable&gt; // For std::condition_variabletemplate&lt;typename T&gt;class threadsafe_queue{private:  struct node  {    // 数据使用 shared_ptr 包装，以便在锁外安全地复制（返回）。    std::shared_ptr&lt;T&gt; data;    // 使用 unique_ptr 管理下一个节点，实现 RAII 自动内存管理。    std::unique_ptr&lt;node&gt; next;  };  // --- 核心成员变量 ---  std::mutex head_mutex;            // 只保护 'head' 指针的访问  std::unique_ptr&lt;node&gt; head;       // 队列头（独占所有权）  std::mutex tail_mutex;            // 保护 'tail' 指针以及 'tail' 指向的节点  node* tail;                       // 队列尾（非所有权的观察指针）  std::condition_variable data_cond; // 用于 'wait_and_pop' 的条件变量  // --- 私有辅助函数 (Private Helper Functions) ---  node* get_tail()  // 访问 tail 指针的线程安全方法  {    std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);  // 先锁定 tail_mutex 再访问 tail    return tail;  }  std::unique_ptr&lt;node&gt; pop_head()  // 弹出头节点，返回节点指针 (假设已锁定 head_mutex)  {    std::unique_ptr&lt;node&gt; old_head = std::move(head);  //     head = std::move(old_head-&gt;next);    return old_head;  }  std::unique_lock&lt;std::mutex&gt; wait_for_data() // 等待直到队列非空, 返回已锁定的 head_mutex  {    // 1. 获取 head_mutex。必须用 unique_lock 以便 'wait' 使用。    std::unique_lock&lt;std::mutex&gt; head_lock(head_mutex);        // 2. 在条件变量上等待。    //    lambda 谓词是“队列非空” (head != tail)。    //    wait() 会原子地：    //    a. 检查谓词，如果为 false (队列空)，释放 head_lock 并休眠。    //    b. 被唤醒时，重新获取 head_lock，再次检查谓词（防止虚假唤醒）。    //    c. 谓词检查 (head.get() != get_tail()) 会在持有 head_lock    //       的情况下调用 get_tail()，这会获取 tail_mutex。    //       锁顺序 (head -&gt; tail) 是安全的，不会死锁。    data_cond.wait(head_lock, [&amp;]{ return head.get() != get_tail(); });        // 3. 此时，队列非空，且 head_lock 仍被持有。    //    通过 std::move 将锁的所有权返回给调用者。    return std::move(head_lock);  // 3  }  std::unique_ptr&lt;node&gt; wait_pop_head() // 等待并弹出头节点，返回节点指针。  {    // 1. 等待数据，并获取已锁定的 head_lock。    std::unique_lock&lt;std::mutex&gt; head_lock(wait_for_data());           // 2. 在锁的保护下，调用内部(无锁)的 pop_head()。    return pop_head();  }  std::unique_ptr&lt;node&gt; wait_pop_head(T&amp; value) //  等待并弹出头节点，将数据移入 'value'。  {    // 1. 等待数据，并获取已锁定的 head_lock。    std::unique_lock&lt;std::mutex&gt; head_lock(wait_for_data());          // 2. (关键：异常安全) 先移动数据。    //    如果 T 的移动赋值操作抛异常，pop_head() 不会被调用，    //    锁会释放，但节点仍留在队列中，数据不丢失。    value = std::move(*head-&gt;data);        // 3. 数据安全移动后，再弹出节点。    return pop_head();  }  std::unique_ptr&lt;node&gt; try_pop_head() // 尝试弹出头节点，返回节点指针。  {    // 1. 锁定 head_mutex。    std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);        // 2. 执行线程安全的“空队列”检查 (锁顺序 head -&gt; tail)。    if(head.get() == get_tail())    {      return std::unique_ptr&lt;node&gt;(); // 返回 nullptr    }        // 3. 队列非空，在锁保护下弹出。    return pop_head();  }  std::unique_ptr&lt;node&gt; try_pop_head(T&amp; value) // 尝试弹出头节点，将数据移入 'value'。  {    // 1. 锁定 head_mutex。    std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);        // 2. 执行线程安全的“空队列”检查。    if(head.get() == get_tail())  // 锁的固定顺序 head -&gt; tail , 避免死锁    {      return std::unique_ptr&lt;node&gt;(); // 返回 nullptr    }        // 3. (关键：异常安全) 先移动数据，再弹出节点。    //    理由同 wait_pop_head(T&amp; value)。    value = std::move(*head-&gt;data);        // 4. 弹出节点。    return pop_head();  }public:  threadsafe_queue():    head(new node), tail(head.get()) // 初始化时创建哑节点, head 和 tail 指向它  {}  // 禁止拷贝和赋值, 因为有独占所有权的指针成员和互斥量成员  threadsafe_queue(const threadsafe_queue&amp; other) = delete;  threadsafe_queue&amp; operator=(const threadsafe_queue&amp; other) = delete;  // --- 公共接口 (Public Interface) ---  void push(T new_value)   {    // --- 1. 锁外准备 (性能优化) ---    // 在锁外创建 T 的实例 (make_shared) 和新节点 (new node)。    // 内存分配是耗时操作，不应在锁内执行。    std::shared_ptr&lt;T&gt; new_data(std::make_shared&lt;T&gt;(std::move(new_value)));      std::unique_ptr&lt;node&gt; p(new node); // 新的哑节点    node* const new_tail = p.get(); // 保存新节点的原始指针    // --- 2. 锁内操作 (快速) ---    {      // 只锁定 tail_mutex, push 操作与 pop 操作 (锁 head_mutex) 可以并发。      std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);      tail-&gt;data = new_data;  // 将数据 *填充* 到 *当前的* 虚拟节点中      tail-&gt;next = std::move(p);  // 将 *新的* 虚拟节点链接到链表末尾, 所有权转移      tail = new_tail;  // 更新 tail 指针指向新的虚拟节点    } // tail_lock 在此释放    // --- 3. 通知 (锁外) ---    data_cond.notify_one();  }  std::shared_ptr&lt;T&gt; wait_and_pop() // 等待并弹出一个元素，返回 std::shared_ptr。  {    // 1. 调用辅助函数，它会阻塞直到有数据，并安全地弹出一个节点, 返回旧头节点。    std::unique_ptr&lt;node&gt; const old_head = wait_pop_head();  // 现在old_head管理旧头节点的所有权        // 2. 从弹出的节点中返回数据。      return old_head-&gt;data;  } // (RAII: old_head 在此销毁，自动 delete 节点)  void wait_and_pop(T&amp; value) // 等待并弹出一个元素，通过引用写入 'value'。  {    // 1. 调用异常安全的辅助函数。    //    数据在 wait_pop_head(value) 内部已经被移入 'value'。    std::unique_ptr&lt;node&gt; const old_head = wait_pop_head(value);        // 2. (RAII: old_head 在此销毁，自动 delete 节点)  }  std::shared_ptr&lt;T&gt; try_pop() // 尝试弹出头元素，返回 std::shared_ptr&lt;T&gt;。  {    // 1. 调用辅助函数。old_head 要么是弹出的节点，要么是 nullptr。    std::unique_ptr&lt;node&gt; old_head = try_pop_head();        // 2. 在锁外检查结果并返回数据 (或空指针)。    return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();  }  bool try_pop(T&amp; value) // 尝试弹出头元素，通过引用写入 'value'。  {    // 1. 调用异常安全的辅助函数。    std::unique_ptr&lt;node&gt; const old_head = try_pop_head(value);        // 2. 利用 unique_ptr 到 bool 的隐式转换返回成功与否。    //    (true: old_head 非空, 弹出成功; false: old_head 为空, 队列空)    return old_head;  }  bool empty() // 公共接口, 检查队列是否为空  {    // 1. 锁定 head_mutex。    std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);        // 2. 执行与 pop 操作 *完全一致* 的线程安全“空队列”检查。    return (head.get() == get_tail());  }}; #####\r\n流程一：入队（Push）\r\n\r\n锁外准备（性能优化）\r\n\r\n\r\n创建 shared_ptr&lt;T&gt; new_data（指向待入队数据\r\nA）。\r\n创建 std::unique_ptr&lt;node&gt; p（指向新的空节点\r\nD2）。\r\n这些耗时操作在锁外完成，减少锁持有时间。\r\n\r\n\r\n获取锁\r\n\r\n\r\n仅获取\r\ntail_mutex：std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);\r\n\r\n\r\n修改队列（锁内）\r\n\r\n\r\ntail-&gt;data = new_data;：将数据 A 填充到当前虚拟节点\r\nD1。\r\ntail-&gt;next = std::move(p);：将 D1 链接到新的虚拟节点\r\nD2。\r\ntail = new_tail;：更新 tail 指针指向\r\nD2。\r\n\r\n\r\n释放锁与通知（锁外）\r\n\r\n\r\n释放 tail_mutex。\r\ndata_cond.notify_one();：通知一个等待的消费者线程。\r\n\r\n\r\n流程二：非阻塞出队（try_pop）\r\n\r\n调用辅助函数\r\n\r\n\r\ntry_pop() 调用 try_pop_head()。\r\n\r\n\r\n获取锁\r\n\r\n\r\n获取\r\nhead_mutex：std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);\r\n\r\n\r\n安全检查（队列是否为空）\r\n\r\n\r\nif(head.get() == get_tail())：检查队列是否为空。\r\n\r\nhead.get()（D1），get_tail()（D2，需临时获取\r\ntail_mutex）。\r\n\r\n锁顺序始终为 head_mutex →\r\ntail_mutex，避免死锁。\r\n\r\n\r\n修改队列（锁内）\r\n\r\n\r\n调用 pop_head()：\r\n\r\nstd::unique_ptr&lt;node&gt; old_head = std::move(head);\r\nhead = std::move(old_head-&gt;next);（head 指向\r\nD2）\r\n\r\n\r\n\r\n释放锁与返回（锁外）\r\n\r\n\r\n释放 head_mutex。\r\n返回 old_head-&gt;data（即 A）。\r\n\r\n\r\n内存回收（RAII）\r\n\r\n\r\nold_head 在函数末尾被销毁，自动释放 D1 节点。\r\n\r\n\r\n流程三：阻塞出队（wait_and_pop）\r\n\r\n进入等待\r\n\r\n\r\n调用 wait_pop_head(value) →\r\nwait_for_data()。\r\n获取 head_mutex（unique_lock）。\r\ndata_cond.wait(head_lock, ...)：谓词为\r\nhead.get() != get_tail()。\r\n若队列为空，自动释放 head_mutex，线程休眠。\r\n\r\n\r\n生产者唤醒\r\n\r\n\r\n另一个线程调用 push(A)，最后执行\r\ndata_cond.notify_one()。\r\n\r\n\r\n消费者苏醒\r\n\r\n\r\n被唤醒后重新获取 head_mutex。\r\n再次检查谓词，队列已非空，继续执行。\r\n\r\n\r\n安全弹出（锁内）\r\n\r\n\r\n持有\r\nhead_mutex，先移动数据：value = std::move(*head-&gt;data);\r\n若移动赋值抛异常，节点未弹出，数据不丢失。\r\n调用 pop_head()，弹出节点。\r\n\r\n\r\n释放\r\n\r\n\r\n释放 head_mutex。\r\nold_head（unique_ptr）在函数结束时销毁，自动释放节点。\r\n\r\n\r\n总结:\r\n通过引入哑节点和分离的头尾锁，可以实现并发性能远超单锁版本的线程安全队列。push\r\n和 pop 在大部分情况下可以并行执行，显著提高了吞吐量。\r\n不过实现极其复杂，需要非常小心地处理锁的范围、边界条件（空队列）以及潜在的竞争条件（如\r\npop_head 中的 get_tail 时机）。\r\n带有等待功能的版本（wait_and_pop）以及需要处理异常安全（特别是引用版本）时，复杂性进一步增加。\r\n这个例子充分展示了细粒度锁带来的性能优势和设计挑战。\r\n基于锁设计更加复杂的数据结构\r\n在上一节中，我们深入探讨了相对简单的线性数据结构——栈和队列——的并发设计，从单锁演进到了细粒度锁。\r\n本节将目光转向更复杂、接口更多样化的数据结构，例如查找表（类似\r\nmap）和链表（类似\r\nlist）。设计这些结构面临着新的挑战，但也提供了更多的并发可能性。\r\n复杂数据结构的特点及与栈/队列的区别：\r\n\r\n栈/队列：接口相对固定（push, pop, empty\r\n等），主要用于特定的数据流模式。大多数操作都会修改结构。\r\n复杂结构 (Map, List, Tree 等)：\r\n\r\n支持更多样化的操作（查找、插入、删除、更新、遍历、获取大小等）。\r\n使用模式更灵活，通常读取操作可能远多于修改操作（例如查找表）。\r\n内部结构可能更复杂（如树的平衡、哈希表的冲突链/开放寻址）。\r\n\r\n\r\n这种多样性带来了双重影响： - 更大的并发潜力： -\r\n操作不冲突的可能性增加：例如，在哈希表中，对不同桶的插入操作理论上可以完全并行。对同一个桶的多次读取操作也可以并行（如果使用读写锁）。\r\n-\r\n读多写少：查找表等结构通常读取远多于写入，这天然适合使用读写锁来允许多个读者并发。\r\n\r\n更高的设计难度：\r\n\r\n保护更困难：需要仔细考虑所有可能的操作组合之间的相互影响。例如insert\r\n操作进行时，find 操作是否安全？delete 操作进行时，其他 delete 或 find\r\n是否安全？如果结构需要内部重组（如哈希表扩容、树再平衡），如何保证这些“全局”操作与其他“局部”操作的安全交互？\r\n接口设计更关键：需要更加警惕接口固有的条件竞争，并仔细设计迭代/遍历机制（这是并发容器的一大难点）。\r\n\r\n\r\n但不管怎么样, 两个原则依旧要遵守: -\r\n安全第一：必须保证不变量、接口安全、异常安全、避免死锁。 -\r\n追求并发：通过最小化锁的范围和持有时间，以及采用细粒度锁或读写锁等策略，来最大化并行执行的机会。\r\n### 编写一个使用锁的线程安全查询表\r\n查找表（也称为字典或映射），这是一种更常用的数据结构，用于关联键（Key）和值（Value）。C++标准库提供了\r\nstd::map（基于树）和\r\nstd::unordered_map（基于哈希表）。\r\n本节的核心是探讨如何设计一个线程安全且高并发的查找表。\r\n查找表的特点与挑战\r\n\r\n读多写少：查找表通常被查询（读取）的频率远高于插入、更新或删除（写入）的频率。\r\n接口更复杂：除了基本的增删改查，还可能需要检查空、获取大小、甚至遍历。\r\n\r\n主要挑战则在于接口设计与并发性：std::map 和 std::unordered_map\r\n的接口严重依赖迭代器 (Iterators)。\r\n然而在并发环境下，迭代器非常危险。当一个线程持有指向某个元素的迭代器时，另一个线程可能删除该元素，导致迭代器失效\r\n(Invalidation)，继续使用它会导致未定义行为。要安全地管理并发迭代器极其困难，通常需要迭代器自身也持有锁，但这会带来新的复杂性和死锁风险。\r\n为了简化设计并保证安全，本节实现的线程安全查找表不提供传统意义上的迭代器接口。遍历等操作需要通过其他方式（如内部迭代函数或快照）实现。\r\n基本操作与接口设计\r\n一个基本的线程安全查找表需要支持以下操作：\r\n\r\n添加/更新键值对：\r\n\r\n接口竞争：如果提供单独的 add(key, value) 和 update(key, value)\r\n函数，或者 if (!find(key)) add(key, value); 这样的用户代码模式，都会存在\r\nTOCTTOU 竞争。\r\n解决方案：提供一个原子的 add_or_update_mapping(key,\r\nvalue) 操作, 将添加和更新合并为一个操作,\r\n从而避免条件竞争(在锁内进行检查和修改)。\r\n\r\n删除键值对：remove_mapping(key)。\r\n查找值：value_for(key, default_value)。\r\n\r\n接口选择：当键不存在时如何处理？\r\n\r\n返回默认值（如本节实现）。\r\n返回 std::optional&lt;Value&gt; (C++17) 或\r\nstd::pair&lt;Value, bool&gt;。\r\n返回智能指针\r\n(std::shared_ptr&lt;Value&gt;)，不存在时返回 nullptr。\r\n安全原则：绝不能返回\r\nValue&amp;（值的引用），因为这会违反第3章的原则（不允许受保护数据的引用泄漏出锁的作用域）。\r\n\r\n\r\n\r\n并发策略：从单锁到细粒度锁\r\n设计线程安全查找表的第一步是选择合适的并发控制策略。这里介绍两种常见策略：\r\n策略 1：单锁 (Single Lock), 使用一个 std::mutex 或\r\nstd::shared_mutex 保护整个查找表。 -\r\n优点：实现简单，易于保证线程安全。使用 shared_mutex 可以允许多个\r\nvalue_for (读操作) 并发执行。 -\r\n缺点：写操作（add_or_update,\r\nremove）被完全序列化。在任何时刻，最多只有一个线程能修改表，这在高写入负载下会成为严重瓶颈。\r\n策略 2：细粒度锁 (Fine-grained Locking) - 本节重点 -\r\n目标：允许多个写操作（只要它们不冲突）和读写操作并发执行。\r\n- 如何实现？ 需要选择合适的底层数据结构,\r\n从而可以构建分离的锁保护不同部分的数据。\r\n- 二叉搜索树\r\n(BST)：不适合。所有操作（查找、插入、删除）通常都需要从根节点开始，根节点会成为锁竞争的瓶颈。即使使用“手递手”锁，效果也不理想。\r\n-\r\n有序数组：更不适合。插入和删除可能需要移动大量元素，几乎总是需要锁住整个数组。\r\n- 哈希表 (Hash Table)：将数据分散到多个桶 (Buckets) 中,\r\n每个桶可以独立锁定。 -\r\n并发优势：操作（增删改查）通常只影响一个桶。因此，我们可以为每个桶分配各自的锁。\r\n- 效果：对不同桶的操作可以完全并行执行！\r\n细粒度锁哈希表的实现\r\n下面是一个使用细粒度锁实现的线程安全查找表的示例代码。该查找表基于哈希表结构，每个桶都有自己的读写锁，允许多个读者并发访问同一个桶，同时确保写操作的独占性。\r\ntemplate&lt;typename Key, typename Value, typename Hash=std::hash&lt;Key&gt;&gt;class threadsafe_lookup_table {private:    // 内部类：代表哈希表的一个桶    class bucket_type {    private:        typedef std::pair&lt;Key, Value&gt; bucket_value;        typedef std::list&lt;bucket_value&gt; bucket_data; // 桶内使用链表处理哈希冲突        typedef typename bucket_data::iterator bucket_iterator; // 桶内元素迭代器, 即指向链表节点的指针        bucket_data data;  // 桶内存储的键值对链表        mutable boost::shared_mutex mutex; // 1. 每个桶有自己的读写锁！        // 查找桶内元素的辅助函数 (假设已加锁)        bucket_iterator find_entry_for(Key const&amp; key) const{          return std::find_if(data.begin(),data.end(),                  [&amp;](bucket_value const&amp; item) {return item.first==key;}          );        }    public:        // 读操作：查找值        Value value_for(Key const&amp; key, Value const&amp; default_value) const {            boost::shared_lock&lt;boost::shared_mutex&gt; lock(mutex); // 3. 获取桶的【共享锁】            bucket_iterator const found_entry = find_entry_for(key); // 查找元素, 返回迭代器            return (found_entry == data.end()) ? default_value : found_entry-&gt;second; // 返回值或默认值        }        // 写操作：添加或更新        void add_or_update_mapping(Key const&amp; key, Value const&amp; value) {            std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex); // 4. 获取桶的【独占锁】            bucket_iterator const found_entry = find_entry_for(key);            if (found_entry == data.end()) {                data.push_back(bucket_value(key, value));  // 如果不存在则添加新键值对            } else {                found_entry-&gt;second = value; // 如果存在则更新值            }        }        // 写操作：删除        void remove_mapping(Key const&amp; key) {            std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex); // 5. 获取桶的【独占锁】            bucket_iterator const found_entry = find_entry_for(key);            if (found_entry != data.end()) {                data.erase(found_entry);            }        }    }; // bucket_type 结束    std::vector&lt;std::unique_ptr&lt;bucket_type&gt;&gt; buckets; // 6. 存储所有桶的 vector, 以指针形式管理    Hash hasher; // 哈希函数对象, 重载了 operator()    // 根据 Key 获取对应的桶 (无锁操作)    bucket_type&amp; get_bucket(Key const&amp; key) const { // 7        std::size_t const bucket_index = hasher(key) % buckets.size();  //  计算桶索引        return *buckets[bucket_index];  // 返回对应桶的引用    }public:    // 构造函数：创建指定数量的桶    threadsafe_lookup_table(unsigned num_buckets = 19, /* ... */) : buckets(num_buckets), /* ... */ {        for (unsigned i = 0; i &lt; num_buckets; ++i) {            buckets[i].reset(new bucket_type); // 初始化每个桶. 这里的reset函数将unique_ptr指向新创建的bucket_type对象        }    }    // 禁止拷贝和赋值    threadsafe_lookup_table(const threadsafe_lookup_table&amp;) = delete;    threadsafe_lookup_table&amp; operator=(const threadsafe_lookup_table&amp;) = delete;    // 公共接口：委托给对应的桶    Value value_for(Key const&amp; key, Value const&amp; default_value = Value()) const {        return get_bucket(key).value_for(key, default_value); // 先通过 get_bucket 获取桶, 再调用桶的 value_for     }    void add_or_update_mapping(Key const&amp; key, Value const&amp; value) {        get_bucket(key).add_or_update_mapping(key, value);     }    void remove_mapping(Key const&amp; key) {        get_bucket(key).remove_mapping(key);     }    // ... 可能的其他接口，如 get_map() ...}; 核心设计：\r\n\r\nthreadsafe_lookup_table 包含一个 std::vector ，其中存储了固定数量的\r\nbucket_type 实例（通过 unique_ptr 管理）。\r\nget_bucket(key) 使用哈希函数 hasher 计算键 key\r\n应该属于哪个桶，并返回该桶的引用。这个定位过程是无锁的，因为 buckets\r\n向量在构造后是只读的。真正的锁在 bucket_type 内部。每个桶有自己独立的\r\nboost::shared_mutex (或 std::shared_mutex)。\r\n查找表的三个公共接口只是简单地调用 get_bucket\r\n定位到正确的桶，然后调用该桶的相应成员函数（value_for,\r\nadd_or_update_mapping, remove_mapping）。\r\n桶内操作：\r\n\r\nvalue_for (读) 获取桶的共享锁。\r\nadd_or_update_mapping / remove_mapping (写) 获取桶的独占锁。\r\n桶内部使用 std::list 来处理哈希冲突（链地址法）。\r\n\r\n\r\n并发性分析：极高。 -\r\n对不同桶的操作（无论是读还是写）可以完全并行执行，因为它们获取的是不同的锁。\r\n- 对同一个桶的多个读操作 (value_for)\r\n也可以并行执行，因为它们获取的是共享锁。 - 只有对同一个桶的写操作\r\n(add_or_update, remove) 或读写混合操作才需要互斥（通过独占锁）。 -\r\n并发度大约与桶的数量成正比。\r\n异常安全分析：基本异常安全。 - value_for：只读，安全。 -\r\nremove_mapping：std::list::erase 对迭代器通常是 noexcept 的，安全。 -\r\nadd_or_update_mapping： - push_back：std::list::push_back\r\n提供强异常保证，安全。 - found_entry-&gt;second = value：如果 Value\r\n的拷贝赋值运算符抛异常，桶内链表的状态可能只更新了一半（如果 Value\r\n是复杂类型），但这不影响数据结构的整体一致性，由用户负责 Value\r\n类型的异常安全。\r\n有时,\r\n还需要获取整个查找表的一致性快照（例如，用于序列化或调试）。此时需要同时阻止对所有桶的修改，才能获得一个原子性的快照。\r\n具体实现: 1. 创建一个\r\nstd::vector&lt;std::unique_lock&lt;boost::shared_mutex&gt;&gt; locks;,\r\n用于存储所有桶的锁。 2. 按固定顺序（例如，桶的索引从 0 到 N-1）遍历\r\nbuckets 向量。 3. 对每一个桶的 mutex 创建一个\r\nstd::unique_lock（获取独占锁）并添加到 locks\r\n向量中。现在所有桶都被锁定了。 4. 创建一个新的\r\nstd::map&lt;Key, Value&gt; res;, 用于存储快照结果。 5.\r\n遍历所有桶，将每个桶 list 中的所有键值对 insert 到 res 中。 6. 函数返回\r\nres。当函数退出时，locks 向量析构，所有 unique_lock\r\n析构，所有桶的锁被自动释放。\r\n\r\n死锁避免：必须按固定顺序（如索引顺序）获取所有桶的锁。如果两个线程同时尝试获取快照，它们会按相同顺序请求锁，最多只有一个线程会阻塞，不会发生死锁。\r\n\r\n总结:\r\n基于哈希表和桶级细粒度锁（特别是读写锁）是实现高并发线程安全查找表的有效策略。它通过将锁的范围限制在单个桶内，极大地提高了并发度，允许对不同桶的操作完全并行。相比单锁实现，并发性能得到了显著提升。\r\n不过需要仔细处理接口设计（避免迭代器）、哈希冲突（如使用链表）以及需要全局一致性的操作（如快照，需锁住所有桶并注意死锁）。\r\n编写一个使用锁的线程安全链表\r\n继查找表之后，本节将探讨另一种基础但重要的数据结构——链表 (Linked\r\nList) 的并发设计。链表的设计，特别是涉及到迭代 (Iteration)\r\n时，面临着与哈希表截然不同的挑战。\r\n与哈希表相似, 链表的核心挑战依旧是并发环境下的迭代器 -\r\n链表特性：链表的操作（插入、删除、查找）通常需要遍历节点。\r\n- 标准迭代器的问题： - 失效\r\n(Invalidation)：标准库迭代器通常持有指向容器内部节点的指针或引用。如果一个线程持有迭代器\r\nit 指向节点 N，而另一个线程删除了节点 N，迭代器 it\r\n就失效了。继续使用失效的迭代器是未定义行为。 -\r\n生命周期与锁：要使迭代器在并发环境下安全，迭代器本身可能需要持有它所指向（或将要访问）节点的锁。但这极大地增加了复杂性：\r\n-\r\n迭代器的生命周期通常独立于容器的操作，管理锁的释放变得困难。\r\n-\r\n持有锁时间过长：如果迭代器在其整个生命周期内都持有锁，会严重阻塞其他线程。\r\n结论：直接暴露标准库风格的迭代器对于并发链表来说极其危险且难以正确实现。\r\n一种避免暴露迭代器的策略是提供成员函数来进行迭代，例如\r\nfor_each，它接受一个用户提供的函数 f，并在内部为链表中的每个元素调用\r\nf。\r\n优点在于容器内部可以管理遍历过程中的锁，用户不需要直接处理迭代器和锁。\r\n主要缺点 (严重)： - 违反死锁指导原则：for_each\r\n必须在持有内部锁（至少是当前节点的锁）的情况下，调用用户提供的代码\r\n(f)。如果用户代码 f\r\n尝试获取其他锁（甚至是同一个链表上其他操作所需的锁），就可能导致死锁。 -\r\n引用传递风险：为了让用户代码 f 能够操作元素，for_each\r\n通常需要将元素的引用传递给\r\nf。如果用户代码保存了这个引用，并在 for_each\r\n调用结束后（锁已释放）再去访问它，就会发生数据竞争。 -\r\n拷贝开销：可以通过传递元素的拷贝给 f\r\n来避免引用风险，但这对于大型或昂贵的对象来说开销可能过大。\r\n结论：虽然可行，但这种方法将避免死锁和数据竞争的责任推给了用户，使得接口不够安全和易用。\r\n最终,\r\n为了在允许一定并发性的同时安全地支持遍历和修改，本节采用了节点级锁结合“手递手”锁定的策略。\r\n\r\n节点级锁 (Node-Level\r\nLocking)：每一个链表节点内部都包含自己的\r\nstd::mutex。\r\n“手递手”锁定 (Hand-over-Hand / Lock\r\nCoupling)：在遍历链表时，线程的操作流程如下：\r\n\r\n持有当前节点 current 的锁。\r\n找到下一个节点 next。\r\n锁住 next 节点的锁。\r\n解锁 current 节点的锁。（关键步骤！）\r\n现在 next 节点成为新的 current 节点，继续遍历。\r\n\r\n\r\n效果：就像爬绳子时“一只手抓住上面，另一只手才松开下面”一样，线程在移动到下一个节点之前，会同时持有当前和下一个节点的锁，然后释放前一个。这保证了遍历过程的连续性和安全性，同时允许多个线程在链表的不同位置并发地进行遍历或修改。\r\n细粒度锁链表的实现\r\n下面是一个使用节点级锁和手递手锁定策略实现的线程安全链表的示例代码。该链表支持基本的插入、删除和查找操作，同时允许安全地遍历链表。\r\ntemplate&lt;typename T&gt;class threadsafe_list{  struct node  // 1. 节点结构  {    std::mutex m; // 每个节点都有自己的锁    std::shared_ptr&lt;T&gt; data; // 使用 shared_ptr 管理数据    std::unique_ptr&lt;node&gt; next; // 使用 unique_ptr 管理下一个节点    node() : next() {} // 2. 哑节点的构造    node(T const&amp; value) : data(std::make_shared&lt;T&gt;(value)) {} // 3. 数据节点的构造  };  node head; // 哑/哨兵头节点 (简化边界处理)public:  threadsafe_list() {}  ~threadsafe_list() { remove_if([](node const&amp;){ return true; }); } // 清理  // 禁止拷贝和赋值  threadsafe_list(threadsafe_list const&amp;) = delete;  threadsafe_list&amp; operator=(threadsafe_list const&amp;) = delete;  // 添加到头部  void push_front(T const&amp; value)  {    std::unique_ptr&lt;node&gt; new_node(new node(value));  // 4. 锁外分配    std::lock_guard&lt;std::mutex&gt; lk(head.m); // 只锁头节点    new_node-&gt;next = std::move(head.next);  // 5. 链接    head.next = std::move(new_node);  // 6. 更新头指针  }  // 内部迭代：为每个元素调用 f  template&lt;typename Function&gt;  void for_each(Function f) // 7  {    node* current = &amp;head;    std::unique_lock&lt;std::mutex&gt; lk(head.m); // 8. 初始锁住头节点    while(node* const next = current-&gt;next.get()) // 9. 找到下一个节点    {      std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m); // 10. 锁住下一个节点      lk.unlock();  // 11. 解锁当前节点 (Hand-over-Hand!)      f(*next-&gt;data); // 12. 调用用户函数 (只持有 next 节点的锁)      current = next; // 前进      lk = std::move(next_lk); // 13. 将 next_lk 的所有权转移给 lk，准备下次循环    }  }  // 内部查找：找到第一个满足 p 的元素  template&lt;typename Predicate&gt;  std::shared_ptr&lt;T&gt; find_first_if(Predicate p) // 14  {    node* current = &amp;head;    std::unique_lock&lt;std::mutex&gt; lk(head.m);    while(node* const next = current-&gt;next.get())    {      std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m);      lk.unlock();      if(p(*next-&gt;data)) // 15. 检查条件 (只持有 next 节点的锁)      {         return next-&gt;data; // 16. 找到，返回数据 (shared_ptr)      }      current = next;      lk = std::move(next_lk);    }    return std::shared_ptr&lt;T&gt;(); // 未找到  }  // 内部删除：删除所有满足 p 的元素  template&lt;typename Predicate&gt;  void remove_if(Predicate p) // 17  {    node* current = &amp;head;    std::unique_lock&lt;std::mutex&gt; lk(head.m); // 锁住当前节点 (初始是 head)    while(node* const next = current-&gt;next.get())    {      std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m); // 锁住下一个节点      if(p(*next-&gt;data)) // 18. 检查条件      {        // 需要删除 next 节点        std::unique_ptr&lt;node&gt; old_next = std::move(current-&gt;next); // 从 current 断开 next, 此时 old_next 拥有 next 的所有权        current-&gt;next = std::move(next-&gt;next); // current 跳过 next，指向 next 的下一个        next_lk.unlock(); // 19. 解锁要删除的节点 next        // old_next 在离开作用域时会自动删除节点 (20)      }      else // 不需要删除 next 节点      {        lk.unlock(); // 21. 解锁当前节点 (Hand-over-Hand)        current = next; // 前进        lk = std::move(next_lk); // 移动锁所有权      }    }  }}; - node 结构 (①)：关键在于 std::mutex\r\nm，每个节点都有自己的锁。使用 shared_ptr&lt;T&gt;\r\n存数据，便于安全返回和管理生命周期。unique_ptr&lt;node&gt;\r\n管理节点所有权。\r\n\r\nhead 哑节点：构造函数创建了一个 head 节点 (②)，它本身不存数据\r\n(data 为空)，作为链表的起点。这简化了 push_front\r\n和遍历的逻辑，无需特殊处理空链表或头节点插入/删除。\r\npush_front (④, ⑤, ⑥)：实现简单高效。只需锁住 head\r\n节点，修改 head.next 和新节点的 next\r\n即可。分配节点在锁外完成。\r\nfor_each (⑦ - ⑬)：完美体现了“手递手”锁定。注意在调用用户函数 f\r\n(⑫) 之前解锁了 current 节点 (⑪)，调用 f 时只持有 next\r\n节点的锁，减小了持有锁的时间和潜在的死锁风险（如果 f\r\n内部访问链表，只会与当前节点的操作冲突）。\r\nfind_first_if (⑭ - ⑯)：与 for_each\r\n逻辑类似，但找到匹配项后立即返回 (⑯)。返回\r\nshared_ptr&lt;T&gt;\r\n保证了即使节点稍后被删除，返回的数据指针仍然有效。\r\nremove_if (⑰ - ㉑)：最复杂的操作,\r\n但同样遵循“手递手”锁定模式。\r\n\r\n当需要删除 next 节点时 (⑱)，它必须持有 current 节点的锁\r\n(lk)，因为它需要修改 current-&gt;next 来跳过 next 节点。\r\n它也持有 next 节点的锁 (next_lk) 来安全地读取 next-&gt;next。\r\n修改完 current-&gt;next 后，立即解锁 next_lk (⑲)。\r\n节点的实际删除 (⑳) 发生在 old_next (一个 unique_ptr)\r\n离开作用域时，此时 next 节点的锁已释放。\r\n安全性：虽然 next 节点的锁在节点被删除前释放了，但由于修改\r\ncurrent-&gt;next 的操作是在持有 lk（current\r\n的锁）的情况下完成的，没有其他线程可以通过 current 到达那个即将被删除的\r\nnext 节点。后续的遍历会直接跳过它。\r\n如果不需要删除 (㉑)，则执行与 for_each\r\n相同的“手递手”解锁和前进。\r\n\r\n\r\n安全性与并发性分析\r\n安全性： - 数据竞争：通过节点级锁和手递手策略避免了对节点内部数据和\r\nnext 指针的竞争。 -\r\n死锁：由于总是按从头到尾的顺序获取锁，不可能出现循环等待，不会发生死锁（前提是用户提供的\r\nf 或 p 不会尝试以不兼容的方式锁住链表）。 -\r\n迭代器失效：通过内部迭代函数避免了传统迭代器失效问题。\r\n并发性： -\r\n优点：允许多个线程在链表的不同部分并发操作。例如，线程A可以在链表前端\r\npush_front，同时线程B在链表中部执行 find_first_if，线程C在链表尾部执行\r\nremove_if（只要它们操作的节点不重叠或不相邻太近）。这远优于单锁实现。 -\r\n缺点/瓶颈：“手递手”锁定本质上仍然是顺序依赖的。如果一个线程在处理某个节点时花费了很长时间（例如，用户函数\r\nf\r\n很慢），它会阻塞所有想要通过该节点的其他线程（无论是向前还是尝试从更前面追赶）。它提高了并发度，但并不能实现完全的并行访问。\r\n总结:\r\n基于节点级锁和“手递手”策略的线程安全链表是一种在安全性和并发性之间取得较好平衡的方案。它通过细粒度锁显著提高了并发潜力，允许多线程在链表不同区域同时工作;\r\n通过内部迭代函数避免了传统迭代器的并发安全问题;\r\n它通过固定的加锁顺序避免了死锁。\r\n其主要局限在于手递手锁定带来的顺序瓶颈，一个慢操作会阻塞后续线程。并且这种设计的复杂性也远高于单锁实现。\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"4. 内存模型和原子操作","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/C++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/4.%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/","content":"内存模型基础\r\nC++是一个系统级别的编程语言，标准委员会的目标之一就是不需要比C++还要底层的高级语言。C++应该向程序员提供足够的灵活性，无障碍的去做他们想要做的事情；当需要的时候，可以让他们“接触硬件”。原子类型和原子操作就允许他们“接触硬件”，并提供底层级别的同步操作，通常会将常规指令数缩减到1~2个CPU指令。\r\n对象和内存位置\r\n在一个C++程序中的所有数据都是由对象(objects)构成。这里的对象不是指面向对象编程中的对象,\r\n而是指一块有类型的内存区域。C++标准定义类对象为“存储区域”,\r\n每个对象都存储在一个或多个“内存位置”上(memory\r\nlocation)，这里的内存位置是由对象的起始地址和对象的大小决定的。两个对象如果它们的内存位置重叠(overlap)，那么它们就不是独立的对象。\r\n例如, 一个 int\r\n类型的对象通常占用4个字节的内存。如果有两个 int\r\n对象分别位于内存地址0x1000和0x1004，那么它们的内存位置不重叠，是独立的对象；但如果一个\r\nint\r\n对象位于0x1000，另一个位于0x1002，那么它们的内存位置就重叠了，不是独立的对象。\r\n此外,\r\n位域(bit-field)成员变量也是对象，但多个相邻的位域可能会共享同一个内存位置(如果没有被强制分隔的话)，这会导致数据竞争的问题。\r\n\r\n位域指的是在结构体(struct)或联合体(union)中定义的特殊成员变量，它们允许程序员指定成员变量占用的位数，而不是默认的字节数。位域通常用于节省内存空间，特别是在需要存储大量布尔值或小整数时。\r\n\r\n 如图的这个struct的结构如下\r\nstruct S {  char c;       // 成员 c (对象)  int i;        // 成员 i (对象)  int bf1 : 10; // 位域 bf1 (对象)  int bf2 : 20; // 位域 bf2 (对象)  int : 0;      // 匿名位域 (bf3)  int bf4 : 10; // 位域 bf4 (对象)  std::string s;  // 成员 s (对象)  double d;     // 成员 d (对象)}; 我们来分析这个 struct S 的实例：\r\n\r\nstruct S\r\n本身：是一个大对象，它包含了很多“子对象”（即它的成员）。\r\nc (char)：一个对象，它自己独占一个内存位置。\r\ni (int)：一个对象，它自己独占一个内存位置。\r\nbf1 和 bf2\r\n(相邻位域)：它们是两个不同的对象。但是，因为它们是相邻的位域，C++标准规定它们共享同一个内存位置（这个位置是它们所属的\r\nint）。\r\n\r\n这会造成并发后果：如果线程A写入 bf1，同时线程B写入\r\nbf2，它们是在访问同一个内存位置，这构成数据竞争 (Data\r\nRace)！\r\n\r\nbf3（匿名的\r\nint : 0;）是一个特殊的布局说明符，它强制\r\nbf4 与 bf1/bf2 分开。\r\n由于 bf3 的分隔, bf4\r\n是一个对象，它自己独占一个新的内存位置。\r\ns (std::string)：s 本身是一个对象, 但 std::string\r\n内部实现很复杂（可能包含指针、大小、容量等）。因此，s\r\n对象是由内部多个内存位置组成的。\r\n\r\n总之, 这一章要我们记住的四个原则:\r\n\r\n每一个变量都是一个对象（包括成员变量）。\r\n每个对象至少占有一个内存位置。\r\n基本类型（如 int, char, float,\r\nT*）的对象都有自己确定的内存位置（即使它们在数组中相邻,\r\n这是因为它们的类型和大小是固定的4个字节倍数,\r\n天然对齐）。\r\n（关键）相邻的位域共享同一个内存位置。\r\n\r\n并发下的内存位置\r\n在上一节中，我们精确定义了“内存位置”（特别是位域的陷阱）。本节将阐明为什么这个定义对并发编程是致命重要的。它影响了C++并发中最危险的情况：数据竞争\r\n(Data Race) 和 未定义行为 (Undefined Behavior)。\r\n首先, 我们来看一下并发访问的三种场景\r\n场景 1：访问“不同”的内存位置 -\r\n线程A 写入 my_struct.c (一个 char)，同时线程B 写入 my_struct.i (一个\r\nint)。 - 结果：完全安全。 - 原因：c 和 i\r\n是不同的对象，它们位于不同的内存位置。因此，线程A和B在各自的“领地”上操作，互不相干。\r\n场景 2：访问“相同”的内存位置（全部只读） - 线程A\r\n读取 my_struct.i，同时线程B 也读取 my_struct.i。 - 结果：完全安全。 -\r\n原因：只读数据不需要保护或同步。\r\n场景\r\n3：访问“相同”的内存位置（至少一个写）\r\n- 线程A 写入 my_struct.i，同时线程B 读取 my_struct.i。 - 线程A 写入\r\nmy_struct.i，同时线程B 写入 my_struct.i。 - 线程A 写入 my_struct.bf1\r\n(位域)，同时线程B 写入 my_struct.bf2 (相邻位域)。 -\r\n上述三种情况都是极度危险的, 是“条件竞争”的根源。\r\n让我们再回忆一下数据竞争 (Data Race) 的定义： -\r\n有两个或以上的线程并发（即没有同步）地执行。 - 它们访问相同的内存位置。\r\n- 这些访问中至少有一个是写操作。 - （并且）它们不是 std::atomic\r\n类型的操作。\r\n而数据竞争的直接后果就是未定义行为。\r\n如何避免数据竞争?\r\n尤其是在需要访问相同内存位置的情况下？答案是在不同的访问之间建立一个强制的执行顺序\r\n(Execution Order)。\r\n方法一就是我们之前提到的使用互斥量 (Mutex) - 当线程A\r\nlock() 互斥量时，它就建立了一个“屏障”。 - 当线程B 尝试\r\nlock() 同一个互斥量时，它被迫等待。 - lock() 和 unlock()\r\n操作在线程A和线程B之间强制建立了一个“先行发生”\r\n(Happens-before) 关系，从而避免了数据竞争。\r\n方法二则是这一讲要介绍的原子操作 (Atomic Operations)\r\n- std::atomic 类型的操作（如\r\nload()、store()）本身就提供了同步机制，它们也可以（在特定条件下）在线程间建立“先行发生”关系。\r\n修改顺序 (Modification Order)\r\n对于C++程序中的任意一个独立的对象（例如，一个 int 变量\r\nx），C++内存模型规定，在一次程序的完整执行中，所有线程对这一个\r\nx\r\n的所有写入操作（从初始化开始），都必须存在一个单一的、全局的总顺序。\r\n换句话说：即使有10个线程在并发地写入\r\nx，在程序结束时，我们必须能（在理论上）将这些写入操作排成一个唯一的队伍，比如：“初始化”\r\n-&gt; “线程A的写入” -&gt; “线程C的写入” -&gt; “线程F的写入”…\r\n并且,\r\n在某一次特定的程序运行中，所有线程都必须“同意”这个唯一的顺序。它也不是在每次运行时都相同的。在大多数情况下，这个顺序不同于执行中的顺序（因为线程调度的不可预测性）。但是,\r\n所有线程必须对这个顺序达成一致。 &gt; 注意:\r\n这里的“达成一致”并不是指线程间需要通信或协商，而是指在程序执行结束后，所有线程都能观察到同一个修改顺序。这在某种程度上是一种”马后炮”的全局共识。\r\n例如线程A执行x = 10; 线程B执行x = 20;\r\n\r\n运行 1：可能的“修改顺序”是 init -&gt; (x=10) -&gt; (x=20)。\r\n运行 2：可能的“修改顺序”是 init -&gt; (x=20) -&gt; (x=10)。\r\n\r\n两种都是合法的。但关键是，在“运行 1”中，所有在之后读取 x\r\n的线程都必须认同 (x=10) 发生在 (x=20) 之前。\r\n从上面的例子中也可以看到, 一般变量的修改顺序是不可预测的, 而 C++\r\n标准通过原子操作强制实现了这个“修改顺序”, 这正是原子\r\n(Atomic) 类型和非原子 (Non-Atomic) 类型的根本区别。\r\n\r\n对于非原子类型（例如，一个普通的 int x）：\r\n\r\n编译器和CPU不提供任何保证。\r\n你（程序员）的责任：你必须使用互斥量 (Mutex)\r\n等同步工具来手动强制建立这个“修改顺序”。\r\n后果：如果你不使用同步（即在不同线程中对 int x\r\n进行读/写），线程之间就无法“同意”一个单一的修改顺序。这就造成了数据竞争\r\n(Data Race)，它会导致未定义行为 (Undefined Behavior)。\r\n\r\n对于原子类型（例如，std::atomic&lt;int&gt; x）：\r\n\r\n编译器和CPU的责任：当你使用原子操作时，编译器和CPU必须保证（通常是通过特殊的CPU指令和内存屏障）所有线程都能“同意”一个对\r\nx 的单一修改顺序。\r\n这是原子类型提供的核心保证：它使你摆脱了“数据竞争”和“未定义行为”。\r\n\r\n\r\n这个“所有线程必须同意一个顺序”的规则，反过来限制了编译器和CPU能做什么：\r\n\r\n禁止读取“过去”：如果一个线程已经读取了 x\r\n的某个值（例如，x=20），那么它在之后的任何读取操作，必须返回 x=20\r\n或者是“修改顺序”中排在 x=20 之后的值（例如\r\nx=30）。它绝不能返回一个排在 x=20 之前的值（例如 x=10）。\r\n写操作的可见性：任何写操作必须（在修改顺序上）出现在它自己线程的前一个写操作之后。\r\n读操作的可见性：任何读操作必须返回修改顺序中某个（或某个读-改-写链上的）值。\r\n\r\n不过 ,十分重要的一点是:\r\n“修改顺序”是针对“每一个独立对象”的,\r\n它不提供“跨对象”的顺序。\r\n例如, 有两个独立的原子对象 x 和 y, 初始值都是0: -\r\n线程 A 执行 x.store(1); y.store(1); - 线程 B\r\n执行 y_val = y.load(); x_val = x.load(); -\r\n线程 C 执行 x_val = x.load();\r\ny_val = y.load();\r\n毫无疑问, 所有线程都会同意 x 的修改顺序是 0 -&gt; 1, y 的修改顺序也是\r\n0 -&gt; 1, 这是原子操作的保证。\r\n但是, 线程B 可能会看到 y_val=1 和 x_val=0。（它看到\r\ny 的修改在 x 之前）. 同理线程C 可能会看到 x_val=1 和\r\ny_val=0。（它看到 x 的修改在 y 之前）\r\n这是因为处理器和编译器为了优化性能，可能会重排（Reorder）指令。当操作是针对两个不相关的内存位置（即\r\nx 和 y）时，这种重排是允许的。\r\n线程 A\r\n内部的程序顺序（x.store(1); y.store(1);）只是一个“在本线程内”的顺序。这种顺序并不会自动同步给观察者线程\r\nB 和 C，让它们看到 x\r\n的写入严格发生在 y\r\n的写入之前。\r\n\r\n要实现跨对象的顺序同步，需要使用更强的同步机制，例如内存栅栏\r\n(Memory Fences) , 即指定更强的内存顺序语义 (Memory\r\nOrder Semantics)（例如\r\nstd::memory_order_seq_cst）的原子操作，或者使用互斥量等同步工具。\r\n\r\n任何线程都会承认 x\r\n的所有写操作是按 Wx1, Wx2, …\r\n的顺序发生的，也会承认 y\r\n的所有写操作是按 Wy1, Wy2, …\r\n的顺序发生的。但是，线程 A 可能会看到 Wx1 发生在 Wy1 之前，而线程\r\nB 则可能会看到 Wy1 发生在 Wx1\r\n之前，这两种视角都是合法且可能发生的。\r\n总之,\r\n本节定义了并发程序的一个基本“健康”标准——所有线程必须能对任一单个对象的修改历史达成一致。原子类型会自动帮你做到这一点，从而避免数据竞争。但它不会自动帮你处理多个对象之间的相对顺序问题\r\nC++中的原子操作和原子类型\r\n标准原子类型\r\n首先,\r\n原子类型是并发编程中用于在多线程环境中安全地访问和修改共享数据的类型,\r\n它们提供了一种机制，确保对这些数据的操作是原子的，即不可分割的,\r\n从而避免使用传统的锁机制（如互斥量）来进行同步。\r\n然而, 原子操作真的是”无锁编程”吗? 也就是is_lock_free()这个概念\r\n一般来说, 原子性\r\n(Atomicity)这个概念保证操作是不可分割的。其实现存在两种方式：\r\n真·无锁 (Lock-Free)：\r\n\r\n编译器使用特殊的CPU指令（例如 x86 上的 LOCK\r\nCMPXCHG）来保证操作的原子性。\r\n优点：效率极高，没有互斥量的阻塞、上下文切换等开销。\r\n\r\n假·无锁” (Lock-Based)：\r\n\r\n编译器内部使用一个隐藏的互斥量 (Mutex)\r\n来“模拟”原子性。\r\n当你调用 my_atomic.store(x)\r\n时，编译器（在幕后）执行的可能是：internal_mutex.lock(); my_value = x; internal_mutex.unlock();\r\n优点：它依然是线程安全的，能避免数据竞争。\r\n缺点：它有锁的全部性能开销，会阻塞其他线程。\r\n\r\nis_lock_free()\r\n成员函数：bool my_atomic.is_lock_free() const;\r\n这是一个运行时检查，它告诉你：“在这个特定的CPU架构和编译器上，对这个对象的操作是‘真·无锁’（返回\r\ntrue）还是‘假·无锁’（返回 false）？”\r\n\r\n在x86/x86-64等主流平台上，你可以期望\r\nstd::atomic&lt;int&gt;、std::atomic&lt;void*&gt;\r\n等基础类型是无锁的，但C++标准并不对此做保证。\r\n\r\nstd::atomic_flag：最基础的原子类型\r\n这是标准库中最简单的原子类型。它就是一个布尔标志。\r\nstd::atomic_flag\r\n是唯一被C++标准保证在所有平台上都必须是无锁的类型。\r\n因为它必须是无锁的，所以它的功能被极度阉割，只被用作最底层的“构建块”（例如自旋锁）。\r\n它没有 is_lock_free()（因为永远是 true），没有 load 或 store。它只有\r\nclear() 和 test_and_set()\r\n等几个非常受限的操作。\r\nstd::atomic&lt;&gt;：主要的类模板\r\n这是我们实际使用中最主要的原子类型, 使用一个非原子类型 T\r\n来特化它，以得到对应的原子版本\r\n\r\nstd::atomic&lt;bool&gt;\r\nstd::atomic&lt;int&gt;\r\nstd::atomic&lt;unsigned long&gt;\r\nstd::atomic&lt;MyClass*&gt; , 指针类型的原子版本\r\nstd::atomic&lt;MyUserDefinedType&gt; ,\r\n用户自定义类型的原子版本（前提是该类型满足某些要求，例如可拷贝、大小适中等）。\r\n\r\n这些类型提供了全套的操作（load, store, exchange\r\n等），但不保证是无锁的（你需要用 is_lock_free()\r\n来检查）\r\n核心属性\r\n除了类型 T 的要求外，std::atomic&lt;T&gt;\r\n还有以下几个核心属性( atomic_flag 除外)： -\r\n不可拷贝构造 / 不可拷贝赋值\r\n(Non-Copyable /\r\nNon-Assignable)：std::atomic&lt;int&gt; x = y; // 编译错误！\r\n-\r\n原因：“拷贝”是一个包含“读（y）”和“写（x）”的两个操作。C++无法将这两个独立的操作合并成一个原子操作。\r\n- 但是可以从非原子类型来构造和赋值：\r\nstd::atomic&lt;int&gt; x(5); // 正确\r\nx = 10; // 正确 (这调用了 x.store(10))\r\n\r\n核心操作：\r\n\r\nload() (加载), store() (存储)\r\nexchange() (交换)\r\ncompare_exchange_weak/strong() (CAS)\r\n\r\n整数/指针的特殊操作：\r\n\r\nfetch_add(), fetch_sub()\r\n+=, -=, ++, –(重载了上述操作符)\r\n\r\n内存顺序：这是本章的重点。load, store\r\n等所有操作都有一个可选的内存顺序参数。\r\n\r\n默认值：如果你不指定，所有操作默认都是\r\nstd::memory_order_seq_cst（最强、最安全、但也最慢的顺序）。\r\n\r\n\r\nstd::atomic_flag\r\n这是C++标准库中最基础、最简单的原子类型。它就是一个布尔标志。\r\n\r\n它只有两种状态：“设置” (set, true)\r\n和 “清除” (clear, false)。\r\n唯一保证：它是C++标准中唯一保证始终无锁 (lock-free)\r\n的类型。std::atomic&lt;bool&gt; 都不一定能做到这一点。\r\n角色：它不是为通用布尔逻辑设计的，而是作为最底层的构建块存在的（例如，用来实现其他锁）。\r\n\r\n初始化：ATOMIC_FLAG_INIT\r\nstd::atomic_flag\r\n的初始化非常特殊，它不能像其他原子类型那样在构造函数中传入 true 或\r\nfalse。你必须使用宏 ATOMIC_FLAG_INIT。\r\n并且 ATOMIC_FLAG_INIT 只能将 atomic_flag 初始化为“清除” (clear)\r\n状态（即 false）。你没有别的选择。 std::atomic_flag f = ATOMIC_FLAG_INIT;\r\n静态初始化保证：当 std::atomic_flag 被声明为\r\nstatic 或全局变量时，使用\r\nATOMIC_FLAG_INIT\r\n可以保证它是“静态初始化”的，这意味着它在程序开始（甚至在多线程启动）之前就已经被初始化了，不会有初始化顺序问题。\r\n\r\n与之类似的还有静态局部变量的初始化保证：C++11及以后的标准保证，函数内的静态局部变量在多线程环境下只会被初始化一次，且初始化过程是线程安全的。\r\n\r\n核心操作：test_and_set() 和\r\nclear()\r\nstd::atomic_flag\r\n的功能被极度限制。一旦初始化，你只能对它做两件事：\r\nclear() (清除): 原子性地将标志的状态设置为“清除”\r\n(false)。 void clear(std::memory_order = std::memory_order_seq_cst);  // 默认为 seq_cstf.clear(std::memory_order_release); // 使用 release 语义f.clear(); // 使用默认的 seq_cst\r\n这是一个“存储 (Store)”操作, 它可以接受 memory_order_relaxed,\r\nmemory_order_release, 或 memory_order_seq_cst。\r\ntest_and_set() (测试并设置)：这是 atomic_flag\r\n最关键的操作，它是一个原子的“读-改-写”\r\n(Read-Modify-Write, RMW) 操作。 bool test_and_set(std::memory_order = std::memory_order_seq_cst);  // 默认为 seq_cstbool old = f.test_and_set(std::memory_order_acquire); // 使用 acquire 语义bool old2 = f.test_and_set(); // 使用默认的 seq_cst\r\n它同时做两件事： - 改 (Modify)：将标志的状态设置为“设置”\r\n(true)。 - 读\r\n(Read)：返回该标志在被设置之前的旧状态。\r\n并且作为RMW操作，它可以接受所有类型的内存顺序。\r\n返回值分析：\r\n\r\n如果标志之前是 false (clear)：test_and_set()\r\n返回 false，然后将标志设为 true。\r\n如果标志之前是 true (set)：test_and_set()\r\n返回 true，标志保持为 true。\r\n\r\n关键限制\r\n\r\n不可拷贝 / 不可赋值：\r\n\r\n这是所有原子类型的共性。“拷贝”/“赋值”涉及两个对象（源和目标），需要“从A读”和“向B写”两个步骤。这“两个”步骤无法合并为一个原子操作，因此被禁止。\r\nstd::atomic_flag f2 = f; // 编译错误！f2 = f; // 编译错误！\r\n\r\n没有“只读”操作：\r\n\r\n这是 atomic_flag\r\n最致命的局限性：你无法在不修改它的情况下检查它的当前值。\r\n它没有 load() 或 test() 这样的函数。你唯一的“读”操作就是\r\ntest_and_set()，而它会强制将标志设为\r\ntrue。\r\n\r\n\r\n示例：实现自旋锁 (Spinlock)\r\natomic_flag\r\n的局限性使它成为实现自旋互斥锁的完美（虽然非常基础）工具。\r\n\r\n“清除” (false) 状态代表锁是“可用” (unlocked)。\r\n“设置” (true) 状态代表锁是“被持有” (locked)。\r\n\r\nclass spinlock_mutex{  std::atomic_flag flag;public:  spinlock_mutex():    flag(ATOMIC_FLAG_INIT) // 1. 构造函数：初始化为“清除”(unlocked)  {}    void lock()  {    // 2. 关键：自旋 (spin)    while(flag.test_and_set(std::memory_order_acquire));    // memory_order_acquire (获取) 语义是 release 的配对。它确保：在 lock 成功之后，该线程能看到前一个线程在 unlock 之前写入的所有数据。  }    void unlock()  {    // 3. 释放锁    flag.clear(std::memory_order_release);  }};\r\n行为分析： - unlock() (解锁)： - 非常简单。调用 clear()\r\n将标志位原子性地设为 false (unlocked)。 -\r\nmemory_order_release (释放) 语义确保了：在此 unlock\r\n之前的所有内存写入（即在锁保护下的代码），对于下一个 lock\r\n它的线程都是可见的。\r\n\r\nlock() (上锁)：\r\n\r\n这是最精妙的部分。线程会执行 while(flag.test_and_set(…))。\r\n情况 1：锁是可用的 (flag == false)\r\n\r\n线程调用 test_and_set()。\r\ntest_and_set() 原子地返回 false（之前的状态），并将 flag 设为\r\ntrue。\r\nwhile(false)：循环条件为 false，循环立即终止。\r\n结果：线程成功获取了锁（只用了一次\r\ntest_and_set），并继续执行。\r\n\r\n情况 2：锁已被持有 (flag == true)\r\n\r\n线程调用 test_and_set()。\r\ntest_and_set() 原子地返回 true（之前的状态），flag 保持为\r\ntrue。\r\nwhile(true)：循环条件为\r\ntrue，线程继续循环（这就是“自旋”）。\r\n线程会一遍又一遍地调用 test_and_set()，每次都返回 true，直到…\r\n\r\n情况 3：锁被释放\r\n\r\n某个持有锁的线程调用了 unlock()，将 flag clear() 为 false。\r\n自旋中的线程在其下一次 test_and_set() 调用中，命中了情况1。\r\ntest_and_set() 返回 false，循环终止，该线程获取了锁。\r\n\r\n\r\n\r\nstd::atomic&lt;bool&gt;\r\n的相关操作\r\nstd::atomic&lt;bool&gt; 可以看作是普通 bool\r\n类型的线程安全、原子版本。与极其基础的 std::atomic_flag\r\n相比，它提供了更完整、更易于使用的布尔操作集。然而，代价是它不像\r\natomic_flag 那样被标准保证一定是无锁的。\r\n你可以直接用普通的 bool 值来初始化\r\nstd::atomic&lt;bool&gt;，也可以将一个 bool 值赋给它。\r\nstd::atomic&lt;bool&gt; b(true); // 用 true 初始化b = false; // 赋值 false (这实际上调用了 b.store(false)) 关于赋值的关键点：赋值操作符\r\n(=)，以及其他对原子变量进行修改的操作返回的是被赋的值本身（在此例中是\r\nbool），而不是对原子对象的引用。这样做是为了避免潜在的竞争条件：如果你获取了一个引用，在你读取这个引用的值之前，另一个线程可能已经再次修改了原子变量的值。\r\n\r\n假设赋值操作符返回的是引用,\r\n当我们执行这样一行代码：bool result = (atomic_b = false);，此时如果另一个线程在我们读取\r\nresult 之前又将 atomic_b 修改为 true，那么我们得到的 result\r\n就是一个不一致的值。因为对于这样的链式调用,\r\natomic_b在赋值时和被读取时是原子的, 但是中间存在非原子的间隙。\r\n而返回被赋的值本身（不是引用）可以避免这种问题，因为我们直接得到的是赋值时的那个值,\r\n即使 atomic_b 在之后被其他线程修改了, 也不会影响我们已经得到的 result。\r\n同理还有 if (atomic_b = true) { ... }这种用法,\r\n因为赋值返回的是值本身, 所以不会因为后续的修改而影响条件判断。\r\n\r\n核心操作\r\nstd::atomic&lt;bool&gt; 支持几个基本的原子操作：\r\n\r\nload()：原子性地读取当前值。\r\n\r\nbool x = b.load(std::memory_order_acquire);\r\n这是一个读 (Read) 操作。它仅仅返回 b 中当前存储的布尔值（true 或\r\nfalse）。你也可以通过隐式转换来读取值（bool x =\r\nb;），这同样执行原子加载。\r\n\r\nstore(bool)：原子性地写入一个新值。\r\n\r\nb.store(true);\r\n这是一个写 (Write) 操作。它用提供的值（这里是 true）替换 b\r\n中的当前值。赋值操作符（b = false;）是 b.store(false); 的简写形式。\r\n\r\nexchange(bool)：原子性地用一个新值替换当前值，并返回旧的值。\r\n\r\nbool old_value = b.exchange(false, std::memory_order_acq_rel);\r\n这是一个原子的读-改-写 (Read-Modify-Write, RMW)\r\n操作。它不可分割地执行两个动作：\r\n\r\n将 b 的值设置为新值（这里是 false）。\r\n返回 b 在此操作之前所持有的值。\r\n\r\n\r\n\r\n比较并交换\r\n(Compare-and-Swap, CAS) 操作\r\n这是最强大的 RMW\r\n操作，是许多无锁算法的基础。它们尝试更改值，但仅当当前值与预期值匹配时才进行。\r\n\r\n逻辑：“如果当前值是\r\nexpected，那么就把它设置为\r\ndesired。并通过返回值告诉我是否成功了。”\r\n形式: 目前 C++ 标准提供了两个版本的 CAS 函数\r\n\r\nbool compare_exchange_weak(T&amp; expected, T desired, ...);\r\nbool compare_exchange_strong(T&amp; expected, T desired, ...);\r\n\r\n参数：两个 CAS 函数都至少接受两个参数\r\n\r\nexpected：一个引用，指向一个 bool\r\n变量，该变量持有你期望原子变量当前应该具有的值,\r\n且是引用类型。\r\ndesired：你希望在期望匹配时设置的 bool 值。\r\n可选的第三个参数是内存顺序标签（将在后面解释）。\r\n返回值：一个 bool，表示操作是否成功。\r\n\r\n失败时的行为：如果原子变量的当前值与 expected\r\n不匹配，CAS\r\n操作失败。关键在于，此时它会用原子变量实际的当前值去更新\r\nexpected\r\n变量。这会告诉你它失败的原因，并为可能的重试准备好\r\nexpected。\r\n\r\ncompare_exchange_weak() (CAS Weak) bool expected = false;bool success = b.compare_exchange_weak(expected, true);\r\n\r\n可能伪失败 (Spurious Failure)：即使值确实匹配\r\nexpected，这个版本也可能失败（返回 false）。这可能发生在某些 CPU\r\n架构上，由于时间问题（例如上下文切换）。但是在某些平台上，它在循环内部可能生成比\r\nstrong 更高效的代码。\r\n用法：由于可能伪失败，compare_exchange_weak\r\n几乎总是用在一个循环中。循环会持续，只要操作失败 并且\r\n失败的原因不是因为值与我们最初（或上一次尝试时）期望的不同。\r\nbool expected = false;// 持续尝试，只要 CAS 失败了 并且 失败的原因不是因为实际值不是我们期望的'false'。while (!b.compare_exchange_weak(expected, true) &amp;&amp; !expected) {    // 如果我们只想在它变为 'false' 时将其设置为 'true'，循环体可以为空。    // 如果 CAS 调用内部将 'expected' 更新为 'true'，那么 &amp;&amp; 条件的后半部分将失败，退出循环。}\r\n\r\ncompare_exchange_strong() (CAS Strong)\r\nbool expected = false;bool success = b.compare_exchange_strong(expected, true);\r\n\r\n无伪失败：这个版本保证只有在原子变量的值确实与 expected\r\n不匹配时才会返回 false。\r\n当你需要明确知道更改是成功还是因为值不匹配而失败，并且不想处理伪失败时使用。你可能仍然需要一个循环（如果你的逻辑需要在值被其他线程更改后重试），但循环逻辑通常比\r\nweak 更简单。\r\n\r\n\r\n内存顺序：所有这些操作 (load, store, exchange, CAS) 都接受可选的\r\nstd::memory_order\r\n参数（将在后面详细解释），用于指定内存同步行为。默认值是\r\nstd::memory_order_seq_cst，这是最强、最安全的选择。\r\n\r\nstd::atomic&lt;T*&gt;:\r\n指针运算\r\nstd::atomic&lt;T*&gt; 除了支持\r\nstd::atomic&lt;bool&gt; 所具有的基本原子操作（load, store,\r\nexchange,\r\ncompare_exchange）之外，它还额外支持原子化的指针算术运算。\r\n它是针对指针类型 T（可以是内置类型指针如\r\nint，也可以是用户定义类型指针如 MyClass*）的 std::atomic\r\n特化版本。\r\n基本操作：与 std::atomic&lt;bool&gt; 类似，它支持： -\r\nis_lock_free() 检查。 - 从 T* 构造和赋值。 -\r\nstd::atomic&lt;int*&gt; p(nullptr); -\r\np = some_int_pointer; // 这调用了 p.store(some_int_pointer);\r\n- load(), store(), exchange(), compare_exchange_weak(),\r\ncompare_exchange_strong() 成员函数，只不过操作的对象和返回的值现在是 T*\r\n类型。 - int* old_ptr = p.exchange(new_ptr); -\r\nint* expected = nullptr; -\r\nbool success = p.compare_exchange_strong(expected, new_ptr);\r\n- 增加了对指针加减运算的原子支持。\r\n原子指针算术运算\r\nstd::atomic&lt;T*&gt;\r\n提供了两组成员函数（和对应的操作符）来实现原子化的指针加减：\r\nfetch_add() 和 fetch_sub(): 这是底层的读-改-写 (RMW)\r\n操作。\r\nT* fetch_add(ptrdiff_t n, std::memory_order = std::memory_order_seq_cst);\r\n\r\n功能：原子性地给存储的指针加上 n\r\n个元素的偏移量（注意：是元素数量，不是字节数）。\r\n返回值：返回指针在执行加法之前的旧值 (T*)。\r\n类比：类似于 p += n，但返回的是 p 加之前的值。\r\n\r\nT* fetch_sub(ptrdiff_t n, std::memory_order = std::memory_order_seq_cst);\r\n\r\n功能：原子性地从存储的指针减去 n\r\n个元素的偏移量。\r\n返回值：返回指针在执行减法之前的旧值 (T*)。\r\n类比：类似于 p -= n，但返回的是 p 减之前的值。\r\n\r\n特性：作为 RMW\r\n操作，它们可以接受任何内存顺序标签。返回的是普通的\r\nT* 值，而不是原子对象的引用。\r\n操作符重载 (+=, -=, ++, –):\r\n为了方便使用，std::atomic&lt;T*&gt;\r\n还重载了常见的指针算术操作符。这些操作符提供了更方便、更熟悉的语法，它们内部会调用相应的\r\nfetch_xxx 操作。\r\np += n / p -= n： - 功能：原子性地加/减 n 个元素。 -\r\n返回值：返回指针加/减之后的新值 (T*)。\r\n++p / --p (前缀)： - 功能：原子性地自增/自减 1 个元素。\r\n- 返回值：返回指针自增/自减之后的新值 (T*)。\r\np++ / p-- (后缀)： - 功能：原子性地自增/自减 1 个元素。\r\n- 返回值：返回指针自增/自减之前的旧值 (T*)。\r\n重要限制：这些重载的操作符不能指定内存顺序。它们总是使用默认的、最强的内存顺序\r\nstd::memory_order_seq_cst。如果你需要更弱的内存顺序（为了性能），你必须使用\r\nfetch_add 或 fetch_sub 成员函数。 - 何时使用\r\nfetch_xxx：当你需要返回旧值，或者需要指定非默认的内存顺序时。 -\r\n何时使用操作符：当你只需要执行操作，并且对返回值（新值或旧值）符合要求，且满足于默认的\r\nseq_cst 内存顺序时，操作符提供了更简洁的语法。\r\n示例\r\nclass Foo{};Foo some_array[5]; // 一个 Foo 类型的数组std::atomic&lt;Foo*&gt; p(some_array); // 原子指针 p 初始化指向数组开头// 1. 使用 fetch_addFoo* x = p.fetch_add(2); // 原子地 p += 2，返回旧值// 结果：assert(x == some_array); // x 得到的是 p 加之前的值 (指向 a[0])assert(p.load() == &amp;some_array[2]); // p 现在指向 a[2]// 2. 使用 -= 操作符x = (p -= 1); // 原子地 p -= 1，返回新值// 结果：assert(x == &amp;some_array[1]); // x 得到的是 p 减之后的值 (指向 a[1])assert(p.load() == &amp;some_array[1]); // p 现在指向 a[1]// 3. 使用 fetch_add 并指定内存顺序p.fetch_add(3, std::memory_order_release); // 原子地 p += 3，使用释放语义\r\n标准的原子整型的相关操作\r\n这一节介绍了除了 std::atomic&lt;bool&gt; 和\r\nstd::atomic&lt;T*&gt;\r\n之外的其他标准原子类型，它们都是原子整数类型（例如\r\nstd::atomic&lt;int&gt;,\r\nstd::atomic&lt;unsigned long long&gt; 等）。\r\n继承通用操作：它们都支持 std::atomic&lt;bool&gt;\r\n所拥有的基本操作集： - load(), store() - exchange() -\r\ncompare_exchange_weak(), compare_exchange_strong() -\r\n不可拷贝/赋值：像所有原子类型一样，它们不能被拷贝构造或拷贝赋值，但可以从对应的非原子整数类型构造或赋值。\r\n- is_lock_free()：同样提供此函数来检查是否无锁。\r\n原子整数类型的专属操作\r\n原子整数类型（包括所有 std::atomic\r\n的特化）在基本操作集之上，增加了算术和位运算的原子支持。\r\n算术运算 (继承自指针类型并扩展)\r\n\r\nfetch_add(integral_value, memory_order = seq_cst)\r\nfetch_sub(integral_value, memory_order = seq_cst)\r\n\r\n功能：原子性地给当前值加上/减去 integral_value。\r\n返回值：返回执行加/减之前的旧值。\r\n内存顺序：作为 RMW 操作，可以指定任何内存顺序。\r\n\r\n+=, -= 操作符\r\n\r\n功能：原子性地加/减 integral_value。\r\n返回值：返回执行加/减之后的新值。\r\n内存顺序：总是 memory_order_seq_cst。\r\n\r\n++, – 操作符 (前缀和后缀)\r\n\r\n功能：原子性地自增/自减 1。\r\n返回值：\r\n\r\n++x / –x (前缀)：返回新值。\r\nx++ / x– (后缀)：返回旧值。\r\n\r\n内存顺序：总是 memory_order_seq_cst。\r\n\r\n\r\n位运算 (原子整数类型专属):\r\n这是原子整数类型区别于原子指针的关键增强。\r\n\r\nfetch_and(integral_value, memory_order = seq_cst)\r\n\r\n功能：原子性地对当前值执行按位与 (&amp;=)\r\n操作：current_value &amp;= integral_value。\r\n返回值：返回执行按位与之前的旧值。\r\n内存顺序：作为 RMW 操作，可以指定任何内存顺序。\r\n\r\nfetch_or(integral_value, memory_order = seq_cst)\r\n\r\n功能：原子性地对当前值执行按位或 (|=) 操作：current_value |=\r\nintegral_value。\r\n返回值：返回执行按位或之前的旧值。\r\n内存顺序：可以指定任何内存顺序。\r\n\r\nfetch_xor(integral_value, memory_order = seq_cst)\r\n\r\n功能：原子性地对当前值执行按位异或 (^=) 操作：current_value ^=\r\nintegral_value。\r\n返回值：返回执行按位异或之前的旧值。\r\n内存顺序：可以指定任何内存顺序。\r\n\r\n&amp;=, |=, ^= 操作符\r\n\r\n功能：原子性地执行相应的按位与/或/异或操作。\r\n返回值：返回执行操作之后的新值。\r\n内存顺序：总是 memory_order_seq_cst。\r\n\r\n\r\n\r\n一般重载运算符都返回新值, 非重载的 fetch_xxx 函数返回旧值,\r\n且返回的都是普通类型, 而不是原子对象的引用。\r\n\r\n不过,\r\n原子整数类型没有提供原子化的乘法、除法和移位操作。因为这些操作在并发场景（如原子计数器、标志位掩码）中不如加减和位运算常用。\r\n替代方案：如果确实需要这些复杂操作的原子版本，可以通过在一个循环中使用\r\ncompare_exchange_weak() 或 compare_exchange_strong()\r\n来实现。例如，原子乘法可以这样实现（伪代码）： std::atomic&lt;int&gt; atomic_val;int multiplier = 5;int old_val = atomic_val.load();int new_val;do {    new_val = old_val * multiplier; } while (!atomic_val.compare_exchange_weak(old_val, new_val)); // compare_exchange 会在失败时自动更新 old_val\r\n这个循环会一直尝试，直到它成功地“捕获”了一个 old_val 并原子地将其替换为\r\nnew_val = old_val * multiplier。如果在 CAS 期间有其他线程修改了\r\natomic_val，CAS 会失败，循环会重试，直到成功。\r\nstd::atomic&lt;&gt; 主要类的模板\r\n前面几节讨论的都是 std::atomic&lt;&gt; 针对内置类型（如 bool, int,\r\nT*）的特化版本 (Specializations)。这些特化版本拥有丰富的操作集（如\r\nfetch_add, fetch_or 等）。\r\n本节讨论的是 std::atomic&lt;&gt; 的主要类模板 (Primary Class\r\nTemplate) 本身。这个模板允许你尝试为用户定义类型 (User-Defined Type,\r\nUDT) 创建原子版本，例如\r\nstd::atomic&lt;MyStruct&gt;。\r\nUDT 的限制条件\r\n首先, std::atomic&lt;UDT&gt; 对 UDT\r\n有着非常严格的限制。并不是任何类或结构体都可以直接放入\r\nstd::atomic&lt;&gt; 中。为了使 std::atomic&lt;UDT&gt;\r\n能够被实例化和使用，UDT 类型必须满足以下条件：\r\n\r\n必须具有平凡的拷贝赋值运算符\r\n(Trivial Copy Assignment Operator)：\r\n\r\n含义：编译器必须能够自动生成 UDT\r\n的拷贝赋值运算符，而不需要调用任何用户自定义的赋值代码。\r\n推论：\r\n\r\nUDT 不能有任何虚函数 (virtual functions)\r\n或虚基类 (virtual base\r\nclasses)。（因为这些会影响对象的内存布局和赋值方式）。\r\nUDT\r\n的所有基类和所有非静态数据成员也必须具有平凡的拷贝赋值运算符。\r\n\r\n本质：这个限制（基本上）允许编译器使用 memcpy()\r\n或等价的按位拷贝操作来实现 UDT 对象的赋值。\r\n\r\n必须是位可比的 (Bitwise Equality Comparable)：\r\n\r\n含义：UDT\r\n类型的两个对象，如果它们的内存表示是一致的（按位相等，memcmp\r\n结果为0），那么它们就必须逻辑相等 (operator==\r\n结果为 true)；反之亦然。\r\n本质：这确保了 compare_exchange\r\n操作可以在底层按位比较对象，而不会产生逻辑错误。\r\n\r\n\r\n为什么有这些严格的限制？这些限制不是随意的，它们背后有深刻的原因，主要与安全和性能有关：\r\n\r\n防止在原子操作内部调用用户代码：\r\n\r\n风险：如果 std::atomic&lt;UDT&gt;\r\n允许用户自定义的赋值或比较运算符，那么原子操作（如 store 或\r\ncompare_exchange）在执行时就必须调用这些用户代码。\r\n问题：std::atomic&lt;UDT&gt;\r\n的实现（尤其是在非无锁的情况下）通常会使用一个内部锁来保证原子性(因为没有单一的\r\nCPU\r\n指令能原子地读取、修改和写入整个结构体。)。如果在持有这个内部锁的同时调用了用户代码，就违反了第3章的指导原则（“不要在持有锁时调用用户提供的代码”），这可能导致死锁或性能问题（用户代码阻塞了所有其他访问该原子变量的线程）。\r\n解决方案：限制 UDT\r\n只能进行按位拷贝/比较，这样编译器就知道原子操作内部不需要执行任何可能阻塞或产生副作用的用户代码。\r\n\r\n为无锁实现提供可能性：\r\n\r\n通过将 UDT 限制为可以按位操作的“类 POD (Plain Old\r\nData)”类型，编译器就有可能为\r\nstd::atomic&lt;UDT&gt; 生成无锁\r\n(lock-free) 的代码，特别是当 sizeof(UDT)\r\n等于平台原生支持的原子类型大小（如 int, void*）时。\r\n对于支持 DWCAS (Double-Word-Compare-and-Swap)\r\n指令的平台，甚至可能对两倍指针大小的 UDT 实现无锁操作。\r\n\r\n保证 compare_exchange 的行为符合预期：\r\n\r\n浮点数陷阱：即使 float 或 double\r\n满足按位拷贝/比较的标准，compare_exchange\r\n也可能失败，即使两个浮点数在逻辑上相等（例如，+0.0 和 -0.0\r\n的位模式不同）。\r\nUDT 陷阱：如果 UDT 定义了自己的 operator==，但其逻辑与 memcmp\r\n不完全一致，compare_exchange（它依赖于位比较）的行为可能会让用户感到意外。\r\n解决方案：限制 UDT 必须是“位可比的”，确保 compare_exchange\r\n的行为是基于内存表示的精确匹配。 ####\r\nstd::atomic&lt;UDT&gt; 的可用操作 (受限接口)\r\n\r\n\r\n由于 UDT 的通用性以及上述限制，std::atomic\r\n的接口比针对内置类型的特化版本要少得多。它只提供那些不依赖于类型具体算术或位运算的操作：\r\n\r\nload()：原子读取。\r\nstore()：原子写入 (也支持从 UDT 赋值)。\r\nexchange()：原子交换。\r\ncompare_exchange_weak()：原子比较并交换 (弱)。\r\ncompare_exchange_strong()：原子比较并交换 (强)。\r\noperator UDT()：原子转换为 UDT 类型 (相当于 load())。\r\noperator=(UDT)：原子赋值 (相当于 store())。\r\nis_lock_free()：检查是否无锁。\r\n\r\n注意：std::atomic 没有 fetch_add, fetch_or, ++, -=\r\n等算术或位运算操作。\r\n关于自定义类型的原子操作, 下面是一些建议:\r\n\r\n非法示例：你不能创建\r\nstd::atomic&lt;std::vector&lt;int&gt;&gt; 或\r\nstd::atomic&lt;std::string&gt;，因为 std::vector 和\r\nstd::string\r\n有非平凡的拷贝构造/赋值（需要管理动态内存）。\r\n何时使用 std::mutex：如果你的 UDT\r\n很复杂，或者你需要对其执行比简单替换/比较更复杂的操作，那么\r\nstd::atomic&lt;UDT&gt;\r\n可能不适合。你应该回到第3章的方法：使用 std::mutex 来保护这个 UDT\r\n对象，并在锁内执行所需的操作。\r\n\r\n总结：std::atomic&lt;UDT&gt;\r\n提供了一种将原子性扩展到简单用户定义类型的机制，但前提是这些类型必须像\r\nPOD\r\n类型一样，可以安全地进行按位拷贝和比较。对于更复杂的类型或操作，互斥锁仍然是必要的工具。\r\n原子自由函数\r\n除了原子类型的成员函数外，C++标准库还提供了一些原子自由函数（Atomic\r\nFree\r\nFunctions），这些函数可以在不需要锁的情况下安全地操作原子变量。常见的原子自由函数包括：\r\n\r\nstd::atomic_load：原子读取。\r\nstd::atomic_store：原子写入。\r\nstd::atomic_exchange：原子交换。\r\nstd::atomic_compare_exchange_weak：原子比较并交换（弱）。\r\nstd::atomic_compare_exchange_strong：原子比较并交换（强）。\r\n\r\n这些函数的使用方式与对应的成员函数类似，但它们是以自由函数的形式提供的。它们的第一个参数是一个指向原子变量的指针，在这个原子变量的基础上执行相应的原子操作。例如:\r\nstd::atomic&lt;int&gt; a(0);int value = std::atomic_load(&amp;a); // 原子读取std::atomic_store(&amp;a, 42); // 原子写入\r\n这样做的好处是，它们可以与非原子类型的变量一起使用，提供了一种更通用的方式来进行原子操作。\r\n为shared_ptr等智能指针提供原子操作\r\nC++11引入了对智能指针（如 std::shared_ptr 和\r\nstd::weak_ptr）的原子操作支持。这些操作允许你在多线程环境中安全地共享和管理智能指针，而无需显式使用互斥锁。\r\n- std::atomic_load(std::shared_ptr* p)：原子读取 shared_ptr。 -\r\nstd::atomic_store(std::shared_ptr* p, std::shared_ptr r)：原子写入\r\nshared_ptr。 - std::atomic_exchange(std::shared_ptr* p,\r\nstd::shared_ptr r)：原子交换 shared_ptr。 -\r\nstd::atomic_compare_exchange_weak(std::shared_ptr* p,\r\nstd::shared_ptr* expected, std::shared_ptr\r\ndesired)：原子比较并交换 shared_ptr（弱）。 -\r\nstd::atomic_compare_exchange_strong(std::shared_ptr* p,\r\nstd::shared_ptr* expected, std::shared_ptr\r\ndesired)：原子比较并交换 shared_ptr（强）。\r\n\r\n为 std::shared_ptr 提供特殊的原子自由函数，是 C++\r\n标准委员会基于实际编程需求和易用性考虑做出的一个务实的决定。shared_ptr\r\n在并发编程中太重要了，更新它的操作又涉及到复杂的引用计数原子性，因此提供一套标准化的、封装好的原子操作接口，可以显著提高开发效率和程序的健壮性，即使这意味着在类型系统上做出一点“让步”。\r\n\r\n同步操作和强制排序\r\n这是C++内存模型中用于建立线程间顺序关系的核心机制。理解它对于理解原子操作如何实现同步至关重要。\r\n同步发生 (Synchronizes-with)\r\n“同步发生” (Synchronizes-with)\r\n是一种只发生在原子类型操作之间的关系。\r\n基本思想：当一个线程对一个原子变量执行写操作，而另一个线程对同一个原子变量执行读操作，并且这个读操作确实读取到了那个写操作写入的值（或者之后的值），那么这两个操作之间就可能建立“同步发生”关系。\r\n更精确的定义是, 一个原子写操作 W（例如 store 或\r\nexchange）在一个原子变量 x 上， 同步于\r\n(Synchronizes-with) 一个原子读操作 R（例如 load 或\r\nexchange）在同一个原子变量 x 上，当且仅当：\r\n\r\nW 和 R\r\n都被“适当标记”（使用了能够建立同步的内存顺序标签）；\r\n并且，操作 R 读取的值是由 W\r\n直接写入的值；\r\n\r\n或者，由 W 之后的同一个线程对 x\r\n的后续原子写操作写入的值；\r\n或者，由一系列原子“读-改-写” (RMW) 操作（例如\r\nfetch_add,\r\ncompare_exchange）构成的一个链条，这个链条的起始值来源于\r\nW，而 R\r\n读取的是这个链条中某个操作写入的值。\r\n\r\n\r\n“同步发生”的意义：建立“线程间先行”关系\r\n“同步发生”本身只是一个技术术语。它真正的威力在于，它是建立“线程间先行发生”\r\n(Inter-thread Happens-before) 关系的桥梁。\r\n规则：如果操作 A（在一个线程上）同步于操作\r\nB（在另一个线程上），那么 A 就线程间先行于 B。\r\n&gt; “同步于”之前的是先执行的, “先行于”之前的也是先执行的.\r\n“先行发生”关系保证了操作 A\r\n的所有内存效果（比如写入非原子变量\r\ndata）对于操作** B 之后的代码（比如读取\r\ndata）是可见且有序的**。\r\n// 线程 A (Writer)data.push_back(42);data_ready.store(true); // W: 原子写 (默认 seq_cst)// 线程 B (Reader)while(!data_ready.load()); // R: 原子读 (默认 seq_cst)，读到 trueuse(data[0]);\r\n这里store(true) 同步于 load()\r\n(因为满足上述条件：store 写入 true，load 读取到直接写入的\r\ntrue，且两者都使用了 seq_cst 内存顺序)。\r\n因此，store(true) 线程间先行于 load()。这就保证了在\r\nload() 返回 true 之后，线程B一定能看到 data.push_back(42) 的效果。\r\n总结:\r\n\r\n“同步发生”是 C++\r\n内存模型定义的一种成对关系，发生在对同一个原子变量的写操作和读操作之间。\r\n它的发生需要满足两个条件：操作被“适当标记”（例如，使用默认的\r\nseq_cst），并且读操作看到了写操作（或其后续）的结果。\r\n“同步发生”是建立跨线程的“先行发生”关系的基础，从而保证内存操作的可见性和顺序性。\r\n它是理解原子操作如何实现线程同步（例如 mutex\r\n的底层原理）的关键。\r\n\r\n先行发生 (Happens-before)\r\n这是C++内存模型中最基本、最核心的顺序关系概念。它定义了在一个并发程序中，一个操作的内存效果（例如写入）何时能保证对另一个操作（例如读取）可见。\r\n如果操作 A 先行于 (Happens-before) 操作 B，那么就意味着：\r\n\r\nA 的执行结果（特别是对内存的写入）必须对 B 的执行是可见的。\r\n在抽象的执行模型中，A 必须在 B 之前完成。\r\n\r\n它是建立程序中基本操作顺序的构建块，尤其是在多线程环境下，用于避免数据竞争并保证程序的逻辑正确性。\r\n如果两个操作（至少一个是写）访问同一个非原子内存位置，并且它们之间没有“先行发生”关系，那么就构成了数据竞争，导致未定义行为。\r\n相比上面的“同步发生”关系，“先行发生”关系更为广泛。它不仅涵盖了线程间的操作，还包括同一线程内的操作顺序。因此，“先行发生”关系主要由两种更基础的关系组合而成：“序前”和“线程间先行”。\r\n“序前”\r\n(Sequenced-before)：单线程内的顺序\r\n这是我们最熟悉的顺序，它描述了同一个线程内部操作之间的顺序。\r\n基本上，如果源代码中操作 A 出现在操作 B\r\n之前（例如，在不同的语句中，或者由分号、逗号操作符、函数调用顺序等分隔），那么\r\nA 就序前于 (Sequenced-before) B。\r\n// writer_thread()data.push_back(42);  // 操作 ③data_ready = true;   // 操作 ④\r\n因为语句③在语句④之前，所以操作③ 序前于 操作④。 foo(get_num(), get_num()); // 两个 get_num() 调用的顺序是“未指定顺序的”\r\n但是这里，对 get_num()\r\n的两次调用之间没有“序前”关系。编译器可以自由选择先调用哪个。这种缺乏“序前”关系的操作被称为“未序\r\n(unsequenced)”。\r\n“线程间先行”\r\n(Inter-thread Happens-before)：跨线程的顺序\r\n这是专门用来描述不同线程之间操作顺序的关系。\r\n如何建立？ 根据上一节所说, “线程间先行”关系必须通过“同步发生”\r\n(Synchronizes-with) 关系来建立。\r\n\r\n如果操作 A（在线程T1上）同步于 (Synchronizes-with) 操作\r\nB（在线程T2上），那么操作 A 就 线程间先行于 (Inter-thread\r\nHappens-before) 操作 B。\r\n\r\n建立线程先行的主要机制有两点：\r\n\r\n原子操作：一个（适当标记的）原子写操作 W\r\n同步于一个（适当标记的）原子读操作 R（如果 R 读到了 W\r\n或其后续写入的值）。\r\n互斥量：mutex.unlock() 操作（内部是一个原子 release\r\n操作）同步于后续在同一个 mutex 上的 lock() 操作（内部是一个原子 acquire\r\n操作）。\r\n\r\n并且, “先行发生”关系是可传递的，这一点极其重要。\r\n\r\n如果 A 先行于 B，并且 B 先行于 C，那么 A 就先行于 C。\r\n\r\n这允许同步效果“穿透”多个操作和线程, 例如:\r\n// 线程 A (Writer 1)data.push_back(42);          // 操作 ①  data_ready.store(true);     // 操作 ② (W)// 线程 B (Writer 2)while(!data_ready.load()); // 操作 ③ (R)more_data.push_back(84);    // 操作 ④data_ready2.store(true);    // 操作 ⑤ (W)// 线程 C (Reader)while(!data_ready2.load()); // 操作 ⑥ (R)use(data[0], more_data[0]); // 操作 ⑦ 在这个例子中： - 操作② 同步于 操作③，因此 ② 线程间先行于\r\n③。 - 操作⑤ 同步于 操作⑥，因此 ⑤ 线程间先行于 ⑥。 - 由于 ② 先行于 ③，且\r\n③ 在同一线程内序前于 ④，且 ④ 序前于 ⑤，因此根据传递性，操作 ② 也先行于\r\n⑤。 - 结合 ⑤ 先行于 ⑥，我们得到 ② 先行于 ⑥。 - 因此，操作\r\n①（data.push_back(42)）的效果对于操作 ⑦（use(data[0],\r\nmore_data[0])）是可见的。\r\n这也是”序前”和”线程间先行”关系结合使用的一个典型例子,\r\n它展示了如何通过多个线程和操作建立起内存可见性。\r\n原子操作的内存顺序(Memory\r\nOrder)\r\n这是这一整章最核心、最复杂的部分。它解释了你在执行原子操作时，可以附加的不同“内存顺序标签”\r\n(Memory Ordering\r\nTags)，以及这些标签如何精确地控制线程间的同步行为和内存可见性。\r\n为什么需要内存顺序？因为如果你不指定，所有原子操作都使用\r\nstd::memory_order_seq_cst。这提供了最强、最直观的保证（排序一致性），但可能是最慢的。\r\n不同的CPU架构对内存操作的排序有不同的硬件支持。强制执行强顺序（如\r\nseq_cst）在某些CPU（特别是多核、弱排序架构如\r\nARM）上可能需要昂贵的CPU指令（内存屏障/栅栏）来确保全局同步。\r\n因此,\r\nC++提供更弱的内存顺序选项，允许专家级程序员在保证程序正确性的前提下，放松排序约束，从而减少同步开销，提升性能。\r\n六种内存顺序标签与三种模型\r\nC++11\r\n定义了六种内存顺序标签，它们可以归纳为三种不同的内存模型：\r\n排序一致 (Sequentially Consistent) 模型\r\n\r\n标签：std::memory_order_seq_cst\r\n\r\n获取-释放 (Acquire-Release) 模型\r\n\r\n标签：std::memory_order_acquire (用于加载或 RMW)\r\n标签：std::memory_order_release (用于存储或 RMW)\r\n标签：std::memory_order_acq_rel (用于 RMW)\r\n\r\n自由 (Relaxed) 模型\r\n\r\n标签：std::memory_order_relaxed\r\n\r\n排序一致序列\r\n(Sequentially Consistent - seq_cst)\r\n\r\n标签：std::memory_order_seq_cst\r\n保证：最强保证。所有被标记为 seq_cst\r\n的原子操作，在所有线程看来，都存在一个单一的、全局的总执行顺序。\r\n行为：程序的行为就像所有线程的操作被简单地交错\r\n(interleaved)\r\n在一个单一的时间线上执行一样。这符合我们对并发程序的直观想象。\r\n易于推理：这是最容易理解的模型。你可以通过列出所有可能的交错执行顺序来分析程序的行为。\r\n禁止重排：编译器和CPU不能对 seq_cst\r\n操作相对于其他 seq_cst 操作进行重排。\r\n同步关系：一个 seq_cst 的存储操作 W 同步于一个 seq_cst 的加载操作\r\nR（如果 R 读取了 W\r\n或其后续写入的值）。这会建立线程间先行发生\r\n(Inter-thread Happens-before) 关系。\r\n全局顺序：seq_cst\r\n提供的保证超越了简单的“同步发生”。它强制所有 seq_cst\r\n操作都必须纳入那个单一的全局顺序中。\r\n\r\n下面是一个示例，展示了 seq_cst 的行为：\r\nstd::atomic&lt;bool&gt; x,y; std::atomic&lt;int&gt; z;// Thread A: write_x() { x.store(true, seq_cst); } // 1// Thread B: write_y() { y.store(true, seq_cst); } // 2// Thread C: read_x_then_y() { while(!x.load(seq_cst)); if(y.load(seq_cst)) ++z; } // 3// Thread D: read_y_then_x() { while(!y.load(seq_cst)); if(x.load(seq_cst)) ++z; } // 4// main() creates threads...assert(z.load() != 0); // 5\r\n在上述的例子中, 断言 5 永远不会失败。为什么？因为 seq_cst\r\n保证了一个单一全局顺序。 - 首先, 线程 A 和线程 B 的 store 操作 (1 和 2)\r\n会以某个顺序出现在全局序列中。可能是 1 在 2 之前，或者\r\n2 在 1 之前。 - 假设 1 在 2 之前，那么线程 C 的 x.load\r\n操作 (3) 会看到 x 为 true，从而跳出循环, 然后它会检查 y。如果 2\r\n已经执行了，那么 y 也为 true，z 会被递增。 - 当然也有可能检查 y\r\n还没执行, 从而线程 C 不会递增 z. 但是此时线程 D 会一直阻塞在 y.load 处,\r\n直到线程 B 执行完毕后 y 为 true, 然后线程 D 会检查 x, 由于线程 A\r\n已经执行完毕 x 为 true, z 也会被递增. - 反之亦然，如果 2 在 1 之前，线程\r\nD 先跳出循环并检查 x，假设 x 也为 true，z 也会被递增。 - 假设 x\r\n还没执行完毕, 线程 C 会阻塞在 x.load 处, 直到线程 A 执行完毕后 x 为\r\ntrue, 然后线程 C 会检查 y, 由于线程 B 已经执行完毕 y 为 true, z\r\n也会被递增. - 因此, 无论哪种情况, z 最终都会被递增至少一次, 断言 5\r\n永远不会失败. - 根本原因就在于 seq_cst 保证了一个单一的全局顺序,\r\n使得至少有一个线程能够看到两个 store 操作的结果. -\r\n代价就是, 在多核弱排序 CPU 上，seq_cst 可能需要昂贵的全局同步指令。\r\n自由序列 (Relaxed - relaxed)\r\n以下都属于非排序一致模型(踏出 seq_cst 的世界).\r\n一旦你放弃 seq_cst，以下直觉不再成立：\r\n\r\n没有单一全局顺序：不同线程可以对其他线程的操作看到不同的相对顺序。\r\n重排是可能的：编译器和CPU（缓存、存储缓冲区）可以更自由地重排指令，只要遵守每个变量自身的修改顺序和明确的同步关系。\r\n线程不必“同意”：不同线程可以对同一组操作看到不同的顺序。\r\n\r\n对于自由序列 (relaxed) ,\r\n编译器带来的同步保证是最少的:\r\n\r\n标签：std::memory_order_relaxed\r\n保证：最弱保证。只保证操作本身的原子性（不会发生数据撕裂）。\r\n行为：\r\n\r\n没有同步关系 (synchronizes-with)。\r\n没有强制的跨线程顺序。\r\n唯一的顺序是：同一个线程对同一个原子变量的操作不能被重排（符合该变量的修改顺序）。\r\n\r\n重排：不同变量上的 relaxed\r\n操作可以被编译器或CPU自由地重排。\r\n\r\nstd::atomic&lt;bool&gt; x,y; std::atomic&lt;int&gt; z;// Thread A: write_x_then_y() { x.store(true, relaxed); /*1*/ y.store(true, relaxed); /*2*/ }// Thread B: read_y_then_x() { while(!y.load(relaxed)); /*3*/ if(x.load(relaxed)) ++z; /*4*/ }// main() creates threads...assert(z.load() != 0); // 5\r\n对于上述例子, 断言 5 可能会失败。为什么？因为\r\nrelaxed 不保证任何跨线程的顺序。 - 在线程 A 中，x.store ① 序前于 y.store\r\n②。 - 但是，因为使用了 relaxed，这两个操作之间没有同步关系传递给线程 B。\r\n- 线程 B 的 y.load ③ 可能先于 x.load ④ 看到\r\ntrue（例如，y 的更新先到达 B 的缓存）。 -\r\n此时，x.load ④ 可能仍然看到\r\nfalse（因为 x 的更新还没到达 B\r\n的缓存，或者指令被重排了）。 - 因此，z 可能保持为 0。 -\r\n上面是线程 A\r\n的写-写（Store-Store）重排（更常见）。或者还有一种可能是线程\r\nB 的读-读（Load-Load）重排，线程 B 的指令被重排，使得\r\nx.load ④ 先于 y.load ③ 执行，此时\r\nx.load ④ 看到 false，导致 z 保持为 0。\r\n- 逻辑上, 线程 B 的 if 语句依赖于 while 循环的结果, 但由于使用了\r\nrelaxed, 编译器/CPU 可以在取值的时候忽略这种依赖关系,\r\n导致重排发生(当然执行时仍然是按逻辑顺序执行的). -\r\n程序执行顺序（控制依赖）：线程B不会在 while 循环 (3) 退出之前去执行 if\r\n语句 (4) 的逻辑判断。这是由控制依赖保证的，这个逻辑顺序是可靠的。 -\r\n内存访问顺序（relaxed 导致的问题）：现代CPU是“乱序执行”的。当CPU在 while\r\n循环 (3) 处等待 y 变为 true\r\n时，它会“空闲”。它会“向前看”，发现哦，我等下（if 里）需要 x 的值。由于\r\n(4) 的 x.load 也是 relaxed\r\n的，CPU认为这个读取操作没有限制，它就可以决定“提前”去内存中把 x\r\n的值取回来（发起 Load 指令），尽管此时 while 循环还没退出。\r\n用途：relaxed\r\n通常用于不需要同步的场景，例如简单的原子计数器（只关心最终结果，不关心中间状态的可见性），或者需要配合栅栏\r\n(fences) 或其他更强顺序的操作一起使用。\r\n获取-释放序列\r\n(Acquire-Release)\r\n这是在性能和易用性之间取得平衡的主要模型。它不提供全局顺序，但允许你在特定操作之间建立成对的同步关系。\r\n\r\n标签：\r\n\r\nstd::memory_order_release\r\n(释放)：用于存储操作 (store) 或读-改-写操作 (exchange,\r\nfetch_add 等)。\r\nstd::memory_order_acquire\r\n(获取)：用于加载操作 (load) 或读-改-写操作。\r\nstd::memory_order_acq_rel\r\n(获取并释放)：仅用于读-改-写操作。\r\n\r\n核心规则 (配对)： 一个 release 存储操作 W\r\n同步于一个 acquire 加载操作\r\nR（在同一个原子变量上），如果 R 读取了由 W 或 W 之后的\r\nRMW 链写入的值。\r\n效果（先行发生）：这种同步会建立线程间先行发生关系 (W\r\nhappens-before R)。\r\n这保证了：在 W (release store)\r\n之前的所有内存写入（包括非原子写入），对于在 R (acquire\r\nload)\r\n之后的所有内存读取（包括非原子读取）都是可见且有序的。\r\n\r\n可以理解为：release 操作“发布”了它之前的内存效果，而 acquire\r\n操作“获取”了这些效果。\r\nrelease\r\n操作在它之后建起了一个“屏障”，防止它之前的操作被重排到它之后。而\r\nacquire\r\n操作在它之前建起了一个“屏障”，防止它之后的操作被重排到它之前。\r\n\r\n\r\nstd::atomic&lt;bool&gt; x,y; std::atomic&lt;int&gt; z;// Thread A: write_x_then_y() { x.store(true, relaxed); /*1*/ y.store(true, release); /*2*/ }// Thread B: read_y_then_x() { while(!y.load(acquire)); /*3*/ if(x.load(relaxed)) ++z; /*4*/ }// main() creates threads...assert(z.load() != 0); // 5\r\n在上述例子中, 断言 5 永远不会失败。为什么？因为 release-acquire\r\n建立了同步关系。 - 在线程 A 中，x.store ① 序前于 y.store ②, 并且 y.store\r\n② 是一个 release 操作。 - 在线程 B 中，y.load ③ 是一个 acquire 操作,\r\n它读取到了 y.store ② 写入的 true。 - 因此，y.store ② 同步于 y.load\r\n③，建立了线程间先行关系 (② happens-before ③)。 - 由于 ①\r\n序前于 ②，并且 ② 先行于 ③，根据传递性，① 也先行于 ③。 -\r\n这保证了 x.store ① 的效果对于 x.load ④ 是可见的。因此，x.load ④\r\n一定会看到 true，z 会被递增。\r\n还有下面这个例子: std::atomic&lt;int&gt; data[5];std::atomic&lt;bool&gt; sync1(false),sync2(false);void thread_1(){  data[0].store(42,std::memory_order_relaxed);  data[1].store(97,std::memory_order_relaxed);  data[2].store(17,std::memory_order_relaxed);  data[3].store(-141,std::memory_order_relaxed);  data[4].store(2003,std::memory_order_relaxed);  sync1.store(true,std::memory_order_release);  // 1.设置sync1}void thread_2(){  while(!sync1.load(std::memory_order_acquire));  // 2.直到sync1设置后，循环结束  sync2.store(true,std::memory_order_release);  // 3.设置sync2}void thread_3(){  while(!sync2.load(std::memory_order_acquire));   // 4.直到sync2设置后，循环结束  assert(data[0].load(std::memory_order_relaxed)==42);  assert(data[1].load(std::memory_order_relaxed)==97);  assert(data[2].load(std::memory_order_relaxed)==17);  assert(data[3].load(std::memory_order_relaxed)==-141);  assert(data[4].load(std::memory_order_relaxed)==2003);} 在这个例子中, thread_3 中对 data\r\n数组的读取操作一定会看到 thread_1 中的写入结果。原因如下： - 在 thread_1\r\n中, sync1.store 是一个 release 操作 (1)。 - 在 thread_2 中, sync1.load\r\n是一个 acquire 操作 (2)，它读取到了 sync1.store 写入的 true。因此,\r\nsync1.store (1) 同步于 sync1.load (2)，建立了线程间先行关系 (1\r\nhappens-before 2)。 - 在 thread_2 中, sync2.store 是一个 release 操作\r\n(3)。 - 在 thread_3 中, sync2.load 是一个 acquire 操作 (4)，它读取到了\r\nsync2.store 写入的 true。因此, sync2.store (3) 同步于 sync2.load\r\n(4)，建立了线程间先行关系 (3 happens-before 4)。 - 由于 (1\r\nhappens-before 2) 且 (2 序前于 3) 且 (3 happens-before 4)，根据传递性,\r\n我们得到 (1 happens-before 4)。 - 这保证了 thread_1 中在 sync1.store\r\n之前对 data 数组的所有写入，对于 thread_3 中在 sync2.load 之后对 data\r\n数组的所有读取，都是可见且有序的。\r\n同时我们也可以看到, 在 thread_1 中对 data 数组的写入使用的是 relaxed\r\n内存顺序，thread_3 中对 data 数组的读取也使用的是 relaxed\r\n内存顺序。这是安全的，因为获取-释放模型只要求在同步点（sync1\r\n和 sync2）使用 acquire 和 release\r\n建立屏障，而在其他地方可以使用\r\nrelaxed，从而提高性能。\r\n而读-改-写 (RMW) 的 acq_rel,\r\n例如my_atomic.fetch_add(1, std::memory_order_acq_rel);,\r\n这个操作同时扮演 acquire 和 release\r\n的角色：\r\n\r\n它与之前对 my_atomic 的 release 存储同步（获取语义）。\r\n它与之后对 my_atomic 的 acquire 加载同步（释放语义）。\r\n\r\n这对于实现锁或在 RMW 链中传递同步非常有用。\r\n总结\r\n内存顺序是 C++\r\n原子编程的核心，它允许你在程序的正确性和性能之间进行权衡：\r\n\r\nseq_cst：最简单，最安全，但可能最慢。提供全局顺序。\r\nacquire-release：性能更好，需要仔细配对 release 和\r\nacquire。提供成对同步和先行发生。\r\nrelaxed：最快，但最危险。只保证原子性，没有同步。通常需要配合其他更强顺序或栅栏使用。\r\n\r\n释放队列与同步 (Release\r\nSequences)\r\n这一节是 “同步发生” (Synchronizes-with)\r\n定义的一个重要扩展和深化。基本的“同步发生”主要描述了单个“写”操作与单个“读”操作之间的直接关系。而“释放序列”则解释了同步关系如何通过一系列的“读-改-写”\r\n(Read-Modify-Write, RMW) 操作传递下去。\r\n考虑以下场景：\r\n\r\n线程 A 执行 store(value_A, release)。(W)\r\n线程 B 执行 old_B = fetch_add(1, acquire)。假设它读取了\r\nvalue_A，写入了 value_B。(RMW1)\r\n线程 C 执行 old_C = fetch_add(1, acquire)。假设它读取了\r\nvalue_B，写入了 value_C。(RMW2)\r\n线程 D 执行 value_D = load(acquire)。假设它读取了\r\nvalue_C。(R)\r\n\r\n没有释放序列规则会怎样？\r\n\r\nW 同步于 RMW1 (因为 RMW1 读取了 W 的值)。\r\n但是，RMW1 本身是 acquire 操作，它没有 release 语义。所以，W\r\n的同步效果似乎在 RMW1 这里就中断了。\r\nRMW2 读取的是 RMW1 的值，而 RMW1 没有 release\r\n语义，所以 RMW2 与 W 似乎没有同步关系。\r\n同理，R 读取的是 RMW2 的值，似乎也与 W 没有同步关系。\r\n\r\n这意味着只有线程 B 能保证看到线程 A 在 W 之前的写入，而线程 C 和 D\r\n则没有保证！这显然不符合我们对原子计数器等模式的期望。\r\n然而,\r\n“释放序列”规则解决了上述问题。一个以写操作 W\r\n开始的释放序列包含：\r\n\r\n起始点：写操作 W 本身，它必须被标记为\r\nmemory_order_release, memory_order_acq_rel, 或\r\nmemory_order_seq_cst (即具有释放语义的操作)。\r\n链条：一系列（零个或多个）在同一个原子变量上执行的原子\r\nRMW 操作（例如 fetch_add, compare_exchange, exchange\r\n等）。\r\n链接条件：链条中的每一个 RMW\r\n操作，都必须读取由序列中前一个操作（起始的 W 或前一个\r\nRMW）写入的值。\r\nRMW 的内存顺序：链条中的 RMW\r\n操作可以使用任何内存顺序（甚至是\r\nmemory_order_relaxed！）。\r\n\r\n起始的 store(release) 已经付出了建立 Release 屏障的代价,\r\n因此它们不需要再建立屏障。\r\n它们只需要保证逻辑连接性（即读取了前一个操作写入的值），从而证明自己是释放序列的一部分。\r\n\r\n\r\n释放序列这一规则的关键点在于：释放序列中的所有 RMW\r\n操作都被视为具有“释放”语义，即使它们本身并没有被标记为\r\nrelease。这是 C++ 内存模型赋予原子 RMW 操作的一个强大“特性”\r\n换句话说：只要 load(acquire) 读取到的值是那个\r\nrelease\r\n链条上的任何一环，它就与链条的起始点\r\n(store(release)) 建立了同步关系！\r\n下面是一个示例，展示了释放序列的作用：\r\n场景：一个生产者线程 populate_queue 准备数据，然后用\r\ncount.store(release) (①)\r\n告知消费者数据量。多个消费者线程 consume_queue_items\r\n通过 count.fetch_sub(acquire) (②) 来原子性地获取一个项目索引。\r\nstd::vector&lt;int&gt; queue_data;std::atomic&lt;int&gt; count;void populate_queue() {  // ... 填充 queue_data ...  count.store(number_of_items, std::memory_order_release); // 1. 起始的 Store-Release (W)}void consume_queue_items() {  while(true) {    int item_index;    // 2. 原子地递减计数器并获取旧值 (RMW with Acquire)    if((item_index = count.fetch_sub(1, std::memory_order_acquire)) &lt;= 0) {       // ... 队列空 ... (3)       continue;    }    // 4. 读取数据 (需要保证可见性)    process(queue_data[item_index - 1]);   }}\r\n\r\n生产者调用 store(release) ①。这是释放序列的起始点 W。\r\n消费者 C1 调用 fetch_sub(acquire) ②。假设它读取了 W 写入的值 N，并将\r\ncount 更新为 N-1。\r\n\r\n根据释放序列规则（链条长度为0），W 同步于 C1 的 fetch_sub。\r\n因此，W 先行于 C1 的 fetch_sub。C1 可以安全地访问 queue_data[N-1]\r\n(④)。\r\nC1 的 fetch_sub 操作本身（即使是 acquire）现在成为释放序列 W\r\n的一部分。\r\n\r\n消费者 C2 调用 fetch_sub(acquire) ②。假设它读取了由 C1 的 fetch_sub\r\n写入的值 N-1，并将 count 更新为 N-2。\r\n\r\nC2 的 load 读取了由 C1 的 RMW 操作写入的值，而 C1 的 RMW\r\n操作是释放序列 W 的一部分。\r\n根据释放序列规则，起始的 store W (①) 同步于 C2 的 fetch_sub！\r\n因此，W 先行于 C2 的 fetch_sub。C2 也可以安全地访问 queue_data[N-2]\r\n(④)。\r\n\r\n\r\n尽管 C1 和 C2 之间没有直接的同步关系（因为 C1 的 fetch_sub 是\r\nacquire，不是 release）, 但它们都与最初生产者的 store(release)\r\n建立了同步关系。\r\n这保证了所有成功获取到项目索引（item_index &gt;\r\n0）的消费者，都能看到生产者在 store(release) 之前对 queue_data\r\n的写入。这正是我们期望的行为！\r\n总结:\r\n“释放序列”是 C++\r\n内存模型的一个重要规则，它允许同步关系通过一系列原子 RMW\r\n操作（即使它们本身没有 release\r\n语义）进行传递。\r\n它确保了在一个由 release 写操作启动、后续由 RMW\r\n操作（如原子计数器增减）延续的链条中，任何读取该链条上任何值的 acquire\r\n读操作，都能与最初的 release 写操作建立同步。\r\n这对于实现高效的多生产者/多消费者模式（例如使用原子计数器管理共享资源）至关重要。\r\n栅栏 (Fences -\r\nstd::atomic_thread_fence)\r\n在之前，我们学习了如何将内存顺序标签（如 acquire, release,\r\nrelaxed）附加到具体的原子操作（如\r\nload, store）上。\r\n本节介绍了一种与之类似但不同的强制排序机制：原子栅栏\r\n(Atomic Fences)，也常被称为内存屏障 (Memory\r\nBarriers)。\r\n\r\n独立于操作：栅栏不是作用于某一个特定的原子变量或操作，而是作为一个独立的指令存在于程序的执行序列中。\r\n“画一条线”：你可以把它想象成在代码中“画了一条线”。这条线具有特定的内存顺序属性（例如\r\nrelease 或 acquire）。\r\n\r\n栅栏之前的所有操作都必须在栅栏之前完成，而栅栏之后的所有操作都必须在栅栏之后开始。\r\n之前的内存标签也是同样的理解，但栅栏的作用范围更广，因为它不依赖于具体的原子变量。\r\n\r\n强制排序：栅栏强制了它之前的操作和它之后的操作之间的相对顺序，防止编译器或CPU将它们重排越过这条“线”。\r\n主要用途：通常与\r\nmemory_order_relaxed\r\n的原子操作配合使用，在需要同步的关键点插入栅栏来强制建立顺序，而在其他地方则允许最大的执行自由度（和性能）。\r\n\r\nC++\r\n中的栅栏：std::atomic_thread_fence\r\n函数原型： void std::atomic_thread_fence( std::memory_order order );\r\n参数 order：栅栏可以接受所有六种内存顺序标签：\r\n\r\nmemory_order_relaxed：这个栅栏什么也不做 (no-op)。\r\nmemory_order_release：释放栅栏。它确保在此栅栏之前的所有内存写入（原子和非原子）都不能被重排到栅栏之后，并且这些写入对于后续看到相关\r\nrelease 效果的 acquire 操作/栅栏是可见的。\r\nmemory_order_acquire：获取栅栏。它确保在此栅栏之后的所有内存读取（原子和非原子）都不能被重排到栅栏之前，并且能看到由与之同步的\r\nrelease 操作/栅栏所“释放”的写入。\r\nmemory_order_acq_rel：获取-释放栅栏。同时具有 acquire 和 release\r\n的效果。\r\nmemory_order_seq_cst：排序一致栅栏。具有 acq_rel\r\n的效果，并且还参与到所有 seq_cst 操作的单一全局总顺序中。\r\n\r\n\r\n基本和之前介绍的内存顺序标签的语义是一样的，只不过栅栏是独立于具体操作的。\r\n\r\n栅栏如何建立同步\r\n栅栏本身不会“凭空”建立同步。它们需要依赖原子变量的读写作为“信使”来传递同步信号。\r\n核心规则： 一个 release 栅栏 F1（在线程 T1 中）\r\n同步于 (Synchronizes-with) 一个 acquire 栅栏 F2（在线程\r\nT2 中）, 当且仅当：\r\n\r\n存在一个原子变量 A；\r\nT1 在栅栏 F1 之后执行了一个对 A\r\n的原子写操作 W（可以是 relaxed）；\r\nT2 在栅栏 F2 之前执行了一个对 A\r\n的原子读操作 R（可以是 relaxed）；\r\n并且，R 读取了由 W（或由 W\r\n开始的释放序列中的某个操作）写入的值。\r\n\r\n简化理解：如果线程 T2（通过 acquire 栅栏）能够“看到”（通过 relaxed\r\nload）一个由线程 T1 在 release 栅栏之后写入的值（通过 relaxed\r\nstore），那么这两个栅栏就同步了。\r\n\r\n类似于原子变量带着 F1 边界内的信息出发,\r\n然后被 F2\r\n边界内的读取操作接收，从而建立起同步关系。\r\n\r\n这个例子展示了如何用栅栏和 relaxed 操作模拟使用 acquire-release\r\n操作达到的效果。 std::atomic&lt;bool&gt; x,y;std::atomic&lt;int&gt; z;void write_x_then_y(){  x.store(true, std::memory_order_relaxed);        // 1. relaxed store x  std::atomic_thread_fence(std::memory_order_release); // 2. Release Fence F1  y.store(true, std::memory_order_relaxed);        // 3. relaxed store y (W)}void read_y_then_x(){  while(!y.load(std::memory_order_relaxed));       // 4. relaxed load y (R)  std::atomic_thread_fence(std::memory_order_acquire); // 5. Acquire Fence F2  if(x.load(std::memory_order_relaxed))            // 6. relaxed load x    ++z;}int main(){  // ... setup and join ...  assert(z.load() != 0); // 7. 断言不会触发} - y.store (③, W) 发生在 release 栅栏 (②,\r\nF1) 之后。 - y.load (④, R) 发生在 acquire 栅栏 (⑤, F2) 之前。 - while\r\n循环确保 y.load (④) 最终会读取到 y.store (③) 写入的 true 值。\r\n根据栅栏同步规则，release 栅栏 (②) 同步于 acquire 栅栏\r\n(⑤)。这建立了栅栏之间的线程间先行发生关系：F1\r\nhappens-before F2。建立先行链如下：\r\n\r\nx.store (①) 序前于 F1 (②) [在 T1 内]\r\nF1 (②) 先行于 F2 (⑤) [跨线程，通过同步]\r\nF2 (⑤) 序前于 x.load (⑥) [在 T2 内]\r\n传递性：因此，x.store (①) 先行于 x.load (⑥)。x.load (⑥) 必须看到\r\ntrue，断言 ⑦ 不会触发。\r\n\r\n\r\n如果没有栅栏 ② 和 ⑤ ，x.store ① 和 x.load ⑥ 之间没有先行关系，x.load\r\n⑥ 可能看到 false，断言可能触发。\r\n\r\n注意事项: -\r\n栅栏的位置至关重要：操作必须位于栅栏的“正确一侧”才能参与排序。如果将\r\nx.store 移动到 release 栅栏之后，那么栅栏就不再保证 x.store 对 x.load\r\n的可见性了。\r\n\r\n需要成对出现：通常需要一个 release 栅栏和一个 acquire 栅栏（或\r\nacquire 操作）配对才能建立同步。\r\n栅栏与其他操作的交互：栅栏不仅与 relaxed\r\n操作交互，也与更强顺序的操作交互。例如，一个 acquire 栅栏也能与之前的\r\nrelease store 同步。\r\n栅栏是全局的（相对线程内）：一个栅栏会影响该线程中所有位于其前/后的原子（甚至非原子）操作的排序，而不仅仅是某一个变量。\r\n\r\n总之, 原子栅栏 (std::atomic_thread_fence)\r\n提供了一种独立于具体原子操作的内存排序机制。它们像代码中的“屏障”，限制编译器和\r\nCPU 的重排。\r\nrelease 栅栏与 acquire 栅栏可以通过跨越栅栏的原子读写（通常是\r\nrelaxed）建立同步和先行发生关系。\r\n它们常用于需要对多个 relaxed\r\n操作进行分组排序，或者需要同步原子操作与非原子操作的场景。\r\n栅栏提供了非常细粒度的控制，但也需要非常仔细的推理来确保正确性。\r\n原子操作对非原子的操作排序\r\n这是理解 C++\r\n内存模型和原子操作的关键所在。它揭示了一个极其重要的原理：原子操作（特别是带有\r\nacquire 和 release\r\n语义的）不仅能同步原子变量本身，还能强制对其周围的非原子操作建立跨线程的顺序关系。这一原理正是\r\nstd::mutex、std::condition_variable\r\n等高级同步原语能够保护非原子共享数据的根本原因。\r\n我们知道，对非原子变量（如普通的 bool\r\nx）进行无同步的并发读写是数据竞争，导致未定义行为。\r\n然而, 我们可以利用原子操作作为“同步点”\r\n(Synchronization\r\nPoints)。只要确保对非原子变量的访问被这些“同步点”恰当地“夹在中间”，就可以为这些非原子访问建立先行发生\r\n(Happens-before)** 关系，从而避免数据竞争。原理在于:\r\n\r\n如果非原子操作 A 序前于 (Sequenced-before) 原子同步操作 S1\r\n(在同一线程)。\r\n并且 S1 同步于 (Synchronizes-with) / 先行于 (Happens-before)\r\n另一个原子同步操作 S2 (在另一线程)。\r\n并且 S2 序前于 非原子操作 B (在 S2 所在的线程)。\r\n那么，通过传递性，非原子操作 A 就先行于非原子操作 B。 #include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;assert.h&gt;bool x = false; // 1. x 现在是一个非原子变量std::atomic&lt;bool&gt; y; // y 仍然是原子变量，用作“信使”std::atomic&lt;int&gt; z;void write_x_then_y(){  x = true; // 2. 非原子写 (A)  std::atomic_thread_fence(std::memory_order_release); // 3. 释放栅栏 (S1)  y.store(true, std::memory_order_relaxed); // 4. 原子写 y (W - 写信)}void read_y_then_x(){  while (!y.load(std::memory_order_relaxed)); // 5. 原子读 y (R - 收信)  std::atomic_thread_fence(std::memory_order_acquire); // 6. 获取栅栏 (S2)  if (x) // 7. 非原子读 (B)    ++z;}int main(){  // ... setup and join ...  assert(z.load() != 0); // 8. 断言不会触发}\r\n如上面代码所示, 尽管 x 本身是非原子的，但由于原子栅栏强制了顺序，对 x\r\n的访问没有数据竞争。读取操作 (⑦) 保证能看到写入操作 (②) 的结果\r\ntrue，因此断言 (⑧) 不会触发。\r\n\r\nstd::mutex 的工作原理\r\n这正是 std::mutex 能够保护非原子数据的核心机制.\r\n一个 std::mutex\r\n内部（至少在概念上）包含一个带有内存标签的原子标志（类似于\r\nstd::atomic_flag 或\r\nstd::atomic）来表示锁的状态（是否被持有）。\r\n\r\nmutex.unlock() (释放操作)：当你调用 unlock()\r\n时，它内部会执行一个原子写操作（例如 flag.clear() 或\r\nflag.store(false)）来标记锁为“可用”。\r\n\r\n这个原子写操作带有 std::memory_order_release\r\n语义。\r\n效果：release 语义保证，在 unlock()\r\n调用之前的所有内存写入（包括对互斥量保护的非原子数据的写入）都不能被重排到\r\nunlock() 之后，并且这些写入的效果对于下一个成功 lock()\r\n该互斥量的线程是可见的, 像是在 unlock()\r\n之后插入了一个“屏障”，防止重排。\r\n\r\nmutex.lock() (获取操作)：当你调用 lock()\r\n时，它内部会执行一个原子读-改-写操作（例如循环 flag.test_and_set() 或\r\ncompare_exchange_weak()）来尝试将锁标记为“被持有”。\r\n\r\n这个（或这些）原子操作带有\r\nstd::memory_order_acquire 语义。\r\n效果：acquire 语义保证，在 lock()\r\n调用成功之后的所有内存读取（包括对互斥量保护的非原子数据的读取）都不能被重排到\r\nlock() 之前，并且能够看到上一个调用 unlock() 的线程所“释放”的内存写入,\r\n像是在 lock() 之前插入了一个“屏障”，防止重排。\r\n\r\n\r\n串联起来： - 线程 T1 调用 lock() (Acquire S1)。 - T1 修改非原子数据\r\nD。 - T1 调用 unlock() (Release S2)。 - 线程 T2 调用 lock() (Acquire\r\nS3)。由于 S2 释放了锁，S3 现在可以成功获取锁。 - T2 读取非原子数据 D。 -\r\nT2 调用 unlock() (Release S4)。\r\n同步链： - T1 对 D 的修改序前于 S2 (Release Unlock)。 - S2 (Release\r\nUnlock) 同步于 S3 (Acquire Lock) —— 因为 S3 观察到了 S2 释放锁的效果。 -\r\nS3 (Acquire Lock) 序前于 T2 对 D 的读取。 - 结论：T1 对 D 的修改 先行于\r\nT2 对 D 的读取！没有数据竞争发生。\r\n例如, 一个可能的实现如下: // 共享的锁状态：0=未锁定, 1=已锁定std::atomic&lt;int&gt; lock_status(0);// ----------------------------------------------------------------------void simple_lock() {    // lock() 概念上是 Acquire：    // 使用 CAS 尝试将 0 设为 1，并使用 Acquire 内存顺序。    int expected = 0;    while (!lock_status.compare_exchange_weak(            expected, 1,            std::memory_order_acquire, // &lt;--- Acquire 语义            std::memory_order_relaxed))     {        expected = 0; // 失败则重试    }}void simple_unlock() {    // unlock() 概念上是 Release：    // 原子地将锁状态设为 0，并使用 Release 内存顺序。    lock_status.store(0, std::memory_order_release); // &lt;--- Release 语义}// ---------------------------------------------------------------------- - simple_unlock()\r\n(Release)：将锁状态 (lock_status) 设置为 0，并带上 Release\r\n标签。这确保了 unlock() 之前的内存写入被同步, 从而类似于在 unlock()\r\n之后插入了一个“屏障”，防止重排, 将临界区的修改挡在 unlock() 之前, 只有在\r\nunlock() 之后的代码才能看到这些修改。\r\n\r\nsimple_lock() (Acquire)：自旋等待，直到它能将 lock_status 从 0 变为\r\n1。成功时，它使用的是 Acquire 标签，这保证了它能看到配对的 Release\r\n操作之前的所有内存写入, 从而类似于在 lock()\r\n之前插入了一个“屏障”，防止重排, 将临界区的修改挡在 lock() 之后, 只有在\r\nlock() 之前的代码才能看到这些修改。\r\n\r\n这就是为什么互斥量能保证锁内代码的内存可见性。\r\n","categories":["language","CPP"],"tags":["language"]},{"title":"函数参数反序入栈","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%87%BD%E6%95%B0/%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E5%8F%8D%E5%BA%8F%E5%85%A5%E6%A0%88/","content":"函数参数反序入栈，也称为从右至左参数压栈，指的是在调用一个函数时，传递给该函数的参数不是按照代码中从左到右的顺序，而是从右到左的顺序依次被推入（push）到程序的调用栈（Call\r\nStack）中。\r\n这是一种由调用约定（Calling\r\nConvention）规定的行为。最常见的采用这种方式的调用约定是\r\ncdecl，它是 C 和 C++ 程序在 x86\r\n上的默认调用约定。\r\n为什么需要反序入栈？\r\n你可能会觉得从左到右的顺序更符合直觉，为什么大多数语言（如C/C++）会选择这种看起来“奇怪”的反序方式呢？最核心的原因是为了支持可变参数函数（Variadic\r\nFunctions）。\r\n可变参数函数是指那些可以接受不定数量参数的函数，最典型的例子就是\r\nC 语言中的 printf 和 scanf 函数。\r\n让我们来看一个 printf 的调用： printf(\"Name: %s, Age: %d, Score: %.2f\\n\", \"Alice\", 20, 95.5);\r\n这个 printf 函数调用了4个参数。但 printf\r\n函数本身在被编译时，并不知道它未来会被多少个参数调用。它唯一能确定的就是第一个参数，即格式化字符串\r\n(“Name: %s, Age: %d, Score: %.2f”)。\r\n函数需要通过解析这个格式化字符串来确定后面还有多少个、以及分别是什么类型的参数。\r\n如果采用顺序（从左到右）入栈： - 栈底(高位) - push “Name: %s, Age:\r\n%d, Score: %.2f” - push “Alice” - push 20 - push 95.5 (栈顶(低位))\r\n在这种情况下，当 printf 函数开始执行时，它能直接访问到的栈顶元素是\r\n95.5。它无法直接定位到最重要的格式化字符串，因为格式化字符串被压在栈的深处，其具体位置依赖于后面参数的数量，而这个数量本身又是未知的,\r\n这使得函数无法确定读取参数读到哪里停止。\r\n如果采用反序（从右到左）入栈（实际情况）： - push 95.5 - push 20 -\r\npush “Alice” - push “Name: %s, Age: %d, Score: %.2f”\r\n在这种情况下，当 printf\r\n函数开始执行时，无论后面有多少个参数，格式化字符串始终位于栈的固定、可预测的位置（紧邻着函数返回地址的上方）。函数可以轻松地访问到这个字符串，通过解析它（发现\r\n%s, %d,\r\n%.2f），就能准确地知道接下来需要从栈上读取一个字符串指针、一个整数和一个浮点数。\r\n因此，反序入栈确保了函数的第一个（或固定）参数的位置是确定的，这为实现可变参数函数提供了基础。\r\ncdecl的其他规则\r\ncdecl（C Declaration 的缩写）是 C\r\n语言中最常见的一种函数调用约定（Calling\r\nConvention）。它定义了函数参数如何传递、栈如何维护、返回值如何传递等规则。\r\n\r\n参数从右到左压栈：在函数调用时，最后一个参数最先被压入栈中，最先被处理。\r\n调用者负责清理栈：函数调用结束后，调用者需要手动调整栈指针，以清理函数调用时压入栈中的参数。\r\n支持可变参数：cdecl\r\n允许函数接受不定数量的参数，这使得它能够支持像 printf\r\n这样的可变参数函数。\r\n返回值: 通过寄存器 eax（对于整数和指针类型）或\r\nst0（对于浮点类型）返回。\r\n函数名修饰：在编译时，函数名通常会被加上一个前缀下划线（_），例如，函数\r\nfoo 在汇编中可能表示为 _foo。\r\n\r\n不同的平台和编译器可能会有不同的调用约定。例如，Windows\r\n平台上常用的调用约定是 stdcall 和 fastcall，它们在参数传递和栈清理方面与\r\ncdecl 有所不同。\r\n而在 RISC-V\r\n等现代架构中，调用约定更倾向于使用寄存器传递参数，以提高性能，减少对栈的依赖。具体内容可以参考RISC-V\r\n的调用约定。\r\n"},{"title":"unique_ptr与auto_ptr","url":"/2025/09/28/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/unique_ptr%E4%B8%8Eauto_ptr/","content":"std::unique_ptr 同样是 C++11\r\n中引入的，用于表示对动态分配对象的独占所有权（Exclusive\r\nOwnership）。\r\nstd::unique_ptr：独占所有权的轻量级管理者\r\n与 shared_ptr 的“共享”理念完全相反，unique_ptr\r\n遵循“独裁”模式：在任何时刻，只能有一个 unique_ptr\r\n指向并拥有一个给定的对象。当这个 unique_ptr\r\n被销毁或重置时，它所拥有的对象也会被立即销毁。\r\n独占所有权 (Exclusive Ownership):\r\n一个资源（内存、文件句柄等）的生命周期由唯一的\r\nunique_ptr\r\n控制。这从根本上杜绝了“谁该删除指针”的混乱问题，所有权模型非常清晰。\r\n轻量级与高性能 (Lightweight &amp; High-Performance):\r\nunique_ptr 是一个零成本抽象（Zero-cost\r\nAbstraction）。它内部没有引用计数，也没有控制块。在大多数情况下，一个\r\nunique_ptr\r\n的大小与一个原始指针完全相同。且它的操作（如访问成员）与操作原始指针一样快，没有任何额外的性能开销。\r\n不可拷贝，但可移动 (Non-copyable, but Movable):\r\n为了保证所有权的“独占性”，unique_ptr\r\n删除了拷贝构造函数和拷贝赋值运算符。你不能像\r\nshared_ptr 那样简单地复制它。 std::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();// std::unique_ptr&lt;MyClass&gt; ptr2 = ptr1; // 紧张拷贝构造, 编译错误！\r\n不过它拥有移动构造函数和移动赋值运算符。这意味着所有权可以被转移（Transfer）。一旦所有权被转移，原来的\r\nunique_ptr 将变为空指针 (nullptr)。 std::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();std::unique_ptr&lt;MyClass&gt; ptr2 = std::move(ptr1); // 正确，所有权从 ptr1 转移到 ptr2// 此后，ptr1 等于 nullptr，ptr2 拥有对象\r\n如何使用\r\n首先是创建 unique_ptr (推荐使用 std::make_unique, C++14 中引入)\r\n#include &lt;memory&gt;class MyClass { /* ... */ };// 推荐方式 (C++14 及以后)// 优点：代码简洁、异常安全std::unique_ptr&lt;MyClass&gt; ptr1 = std::make_unique&lt;MyClass&gt;();// C++11 的方式std::unique_ptr&lt;MyClass&gt; ptr2(new MyClass());\r\n所有权的转移是 unique_ptr\r\n的核心操作模式，最常见的场景是从函数返回。 std::unique_ptr&lt;MyClass&gt; create_widget() {    // 在函数内部创建对象, 对象在堆上    // ...    // 直接返回 unique_ptr，所有权被自动“移动”给调用者    return std::make_unique&lt;MyClass&gt;(); }void process_widget(std::unique_ptr&lt;MyClass&gt; widget) {    // 这个函数通过移动接收了 widget 的所有权    // ...} // 函数结束，widget 在此被销毁，其管理的对象也被销毁int main() {    std::unique_ptr&lt;MyClass&gt; my_widget = create_widget(); // 从工厂函数接收所有权, 因为unique_ptr不可拷贝且移动更高效, 所以直接移动给了my_widget        my_widget-&gt;do_something();        process_widget(std::move(my_widget)); // 将所有权转移给 process_widget 函数        // 此后，main 函数中的 my_widget 变为 nullptr    // if (my_widget == nullptr) { /* ... */ } }\r\n这里在create_widget()函数中, return\r\n语句返回一个临时创建的对象（在例子中是 std::make_unique\r\n的结果）时，这个临时对象被视为一个右值（rvalue）。当用一个右值来初始化一个新的对象时（例如\r\nmy_widget =\r\ncreate_widget()），编译器会优先选择使用移动构造函数，而不是拷贝构造函数。\r\n通过返回值和 std::move，unique_ptr\r\n实现了清晰、安全的所有权在不同作用域之间的传递\r\n\r\n现代 C++\r\n编译器通常会做得更极致。它们会使用一种叫做“返回值优化”的技术。在这种情况下，编译器会发现\r\ncreate_widget 内部创建的指针最终会进入 main 函数的 my_widget\r\n中，于是它会省略掉中间的“移动”步骤，直接在 my_widget\r\n的内存位置上构造那个 unique_ptr。从外部看，就好像 create_widget\r\n函数直接把对象变到了 main 函数里一样。\r\n\r\n此外, 还有一些其他函数:\r\n\r\n访问：像普通指针一样使用 * 和 -&gt;。\r\n获取原始指针：使用 get() 方法，规则和风险与 shared_ptr 的 get()\r\n类似。\r\n释放所有权：调用 release()\r\n方法。它会放弃所有权并返回原始指针，但不会删除对象。调用者需要手动管理返回的指针。\r\n重置：调用 reset()\r\n方法。它会销毁当前拥有的对象，并可以选择性地接管一个新的对象。\r\n\r\n高级特性\r\nunique_ptr 比看起来更灵活，它支持两个强大的高级特性:\r\n自定义删除器 (Custom Deleters)\r\n与 shared_ptr 不同，unique_ptr\r\n的删除器类型是其自身类型的一部分。这使得它仍然是零开销的，但不同删除器类型的\r\nunique_ptr 是不同的类型。这使得 unique_ptr\r\n非常适合用于管理任何需要配对操作的资源，完美实践\r\nRAII（资源获取即初始化）。 管理C风格的文件句柄#include &lt;cstdio&gt;// 自定义删除器结构体, 也可以是其他可调用对象如函数, lambda表达式, 封装的std::functionstruct FileCloser {    void operator()(FILE* file) const {        if (file) {            fclose(file);            std::cout &lt;&lt; \"文件已关闭。\" &lt;&lt; std::endl;        }    }};// 使用 using 让类型名更简洁using UniqueFilePtr = std::unique_ptr&lt;FILE, FileCloser&gt;;   // 将删除器这个可调用对象也传入int main() {    // fopen 返回 FILE*，我们立即将其所有权交给 unique_ptr    UniqueFilePtr file_ptr(fopen(\"test.txt\", \"w\"));    if (file_ptr) {        fputs(\"Hello, unique_ptr!\", file_ptr.get());    }    } // main 结束，file_ptr 被销毁，它的自定义删除器 FileCloser::operator() 会被自动调用，fclose(file) 得以执行\r\n数组支持\r\nunique_ptr\r\n对动态分配的数组有特殊的重载版本，使用时需要加上\r\n[]。\r\n\r\n创建：std::make_unique&lt;T[]&gt;(size)\r\n析构：它会自动调用 delete[] 而不是\r\ndelete，这是正确的数组内存释放方式。\r\n访问：它重载了 operator[]\r\n来访问数组元素，但没有 * 和 -&gt;。 // 创建一个包含 10 个整数的动态数组std::unique_ptr&lt;int[]&gt; arr_ptr = std::make_unique&lt;int[]&gt;(10);// 通过 operator[] 访问元素for (int i = 0; i &lt; 10; ++i) {    arr_ptr[i] = i * i;}// arr_ptr 离开作用域时，会自动调用 delete[] arr_ptr.get();\r\n\r\n黄金法则：默认使用\r\nstd::unique_ptr。\r\n在现代 C++ 中，当你需要动态分配内存时，unique_ptr\r\n应该是你的第一选择。它的所有权模型清晰，性能无损，完全符合 RAII\r\n思想。何时使用 unique_ptr？\r\n\r\n当你需要一个指向动态对象的指针，并且该对象的生命周期应该与这个指针的作用域绑定时。\r\n作为工厂函数的返回值，安全地将新创建对象的所有权转移出去。\r\n在类中作为成员，管理一个只属于该类实例的资源（例如，PIMPL\r\n模式的实现）。\r\n\r\n只有当你明确需要共享一个资源的所有权，即多个独立的观察者都需要延长该资源的生命周期时，才应该“升级”到使用\r\nstd::shared_ptr。\r\nstd::auto_ptr\r\n什么是auto_ptr? 真不熟\r\n\r\nstd::auto_ptr 是 std::unique_ptr 的祖先, 它在 C++11\r\n中被不推荐使用（deprecated），并在 C++17 中被彻底移除,\r\n完全被std::unique_ptr代替。\r\n\r\n"},{"title":"协程","url":"/2025/10/11/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%8D%8F%E7%A8%8B/%E5%8D%8F%E7%A8%8B/","content":"协程,\r\n也可以叫做轻量级的线程或者用户线程,\r\n它是一种执行过程中能够yield(暂停)和resume(恢复)的子程序.\r\n想象一下我们平时写的普通函数（Function/Subroutine）： -\r\n入口只有一个：从函数的第一行代码开始执行。 - 出口只有一个：执行到 return\r\n语句或函数末尾就结束了。 -\r\n中途不记事：一旦函数返回，它内部的所有局部变量都会被销毁，下次再调用，一切都是从头开始。\r\n现在，想象一个“超级函数”，它拥有以下特异功能： -\r\n可以在执行到一半时主动暂停，并把控制权交还给调用者。 -\r\n当它暂停时，会完整地保存自己当前的所有状态（比如局部变量的值、代码执行到哪一行了）。\r\n- 下次调用者想让它继续时，它可以从上次暂停的地方无缝恢复，继续执行。\r\n这个“超级函数”，就是我们要提到的协程\r\n协程的核心思想是在单个线程内实现多任务切换，通过在用户态保存和恢复执行上下文来实现任务间的切换，而不需要操作系统内核的参与。这样可以大幅减少上下文切换的开销，提高并发性能。\r\n\r\n协作式调度 (Cooperative Scheduling):\r\n这是协程与线程最根本的区别。线程的切换是由操作系统内核决定的（抢占式），比如一个线程的时间片用完了，操作系统会强制把它换下来。而协程的切换是由程序自己控制的。一个协程只有在它自己主动调用\r\nyield (或者 await, swapcontext 等) 时，才会放弃CPU控制权。\r\n状态保持 (State Preservation):\r\n当协程暂停时，它的整个调用栈（包括局部变量、参数、程序计数器等）都会被保存下来。当它恢复时，这些状态会被原封不动地还原。\r\n在单线程中运行 (Runs in a Single Thread):\r\n多个协程可以在一个线程中“轮流”执行。这带来了巨大的好处：因为它们不涉及真正的并行，所以访问共享数据时几乎不需要加锁（只要切换点是明确的），极大地简化了编程模型，避免了多线程编程中常见的竞态条件和死锁问题。\r\n\r\n主要优势\r\n\r\n极高的并发能力:\r\n操作系统的线程是重量级资源，创建一个线程需要进入内核，分配几MB的栈内存。一个系统能同时运行的线程数量通常是几百到几千。而协程是用户态的轻量级资源，创建和切换的成本极低（接近于一次函数调用），栈内存通常也只需几KB。一个线程可以轻松管理数万甚至数百万个协程。\r\n极低的切换开销 (Context Switch Cost):\r\n线程切换需要从用户态陷入内核态，保存和恢复大量的寄存器和内核数据结构，成本较高。而协程切换完全在用户态发生，只需保存/恢复少量关键寄存器，速度极快。\r\n用同步的方式编写异步代码:\r\n在协程出现之前，处理高并发I/O通常使用回调函数（Callback），容易形成“回调地狱”，代码可读性和可维护性极差。使用协程，我们可以这样写代码：\r\n\r\n// 同步代码, 需要阻塞等待auto data = readFile(\"config.json\");auto result = parse(data);save(result);// 看起来像同步阻塞代码，但实际上是异步非阻塞的co_await readFile(\"config.json\");   // 读取文件是异步操作, 协程会在这里暂停auto result = co_await parse(data);  // 解析也是异步操作, 协程会在这里暂停co_await save(result);  // 保存也是异步操作, 协程会在这里暂停\r\n当执行到 co_await\r\n时，如果操作未完成，协程会自动暂停并让出CPU，当操作完成后再从这里恢复。代码逻辑清晰，就像写同步代码一样简单。\r\n目前, 协程可以通过多种方式实现：\r\n\r\n底层库支持：如 Linux 的 ucontext\r\n系列函数，提供完整的上下文保存和恢复能力。\r\n汇编：直接操作寄存器，实现最极致的性能，如 Boost.Context。\r\n语言级支持：这是目前最主流的方式。语言内置 async/await、go、yield\r\n等关键字，让编译器和运行时来处理复杂的上下文切换。\r\n\r\nGo: goroutine 是语言的招牌特性。\r\nPython: asyncio 库和 async/await 语法。\r\nC++20: 引入了标准的协程支持 (co_await, co_yield)。\r\n\r\n\r\n对称协程与非对称协程\r\n这两种协程的主要区别在于切换控制权的方式。\r\n非对称协程 (Asymmetric Coroutines):\r\n这是我们最常见到的协程模型，可以理解为一种主从关系或调用者/被调用者关系。\r\n这种协程存在一个明确的“调用者”（通常是主函数或调度器）和一个或多个“被调用者”（协程）。控制权总是在调用者和一个协程之间来回传递,\r\n协程不能将控制权直接交给另一个协程，它只能暂停并把控制权返回给它的调用者。\r\n关键操作: - resume ：调用者启动或恢复一个协程。 - yield\r\n：协程暂停执行，并将控制权和可能的返回值交还给调用者。\r\n对称协程 (Symmetric Coroutines):\r\n所有协程都是平等的对等体 (Peers),\r\n这种模型更加灵活和强大\r\n任何一个协程都可以将控制权直接转移给任何其他一个协程，而不需要经过一个中央调度器或调用者。协程之间没有调用者/被调用者的等级之分。\r\n其只有一个核心操作，通常称为 transfer (或 yield to)。 -\r\ntransfer(target_coroutine)：当前协程暂停，并立即将CPU控制权交给\r\ntarget_coroutine。 - 我们之前了解过的 ucontext 中的\r\nswapcontext(current_ctx, target_ctx) 就是一个 transfer\r\n操作。\r\n有栈协程与无栈协程\r\n这个分类的核心在于：协程暂停时，它的状态（特别是函数调用栈）是如何保存的？\r\n有栈协程 (Stackful Coroutines):\r\n每个协程都拥有一个独立的、完整的执行栈（一块预先分配的内存，通常较大，如几KB到几MB）。当协程切换时，本质上是切换CPU的栈指针（SP寄存器）指向不同的协程栈。因为保存了完整的调用栈，所以协程可以在任意深的嵌套函数调用中暂停。\r\n这种模型非常强大，协程可以像普通函数一样调用其他函数，甚至递归调用自己,\r\n程序员在编写函数时完全不需要手动创建协程或者声明关键字,\r\n这使得协程的使用更加自然和简洁。缺点是每个协程都需要分配一块栈内存，数量多时会占用较多内存。\r\nGo 语言的 goroutine 就是典型的有栈协程。每个\r\ngoroutine 初始栈大小只有几KB，但可以根据需要动态增长。Go\r\n的调度器会在多个 goroutine 之间高效地切换。\r\n// 看上去就是一个普通的网络读取，没有 await 关键字, 但它实际上是一个协程, 可以实现智能阻塞和调度data, err := connection.Read(buffer)\r\n在执行时, Go语言的运行时调度器 (Runtime\r\nScheduler)在背后做了什么：\r\n\r\n函数劫持：调用的 connection.Read\r\n并不是一个天真的、直接的系统调用。它是Go运行时“动过手脚”的版本。\r\n发起非阻塞I/O：这个函数会向操作系统发起一个非阻塞的读请求，并告诉操作系统：“数据准备好后，请通知我的调度器。”\r\n主动让出：然后，这个函数会调用运行时调度器的API，主动告诉调度器：“我这个goroutine（协程）现在要等待数据，请把我暂停，然后去运行队列里的其他goroutine吧。”\r\n上下文切换：调度器接收到通知，保存当前goroutine的整个栈，将其标记为“等待中”，然后从队列里取出另一个“可运行”的goroutine，恢复它的栈，让它继续在同一个OS线程上执行。\r\n\r\n也就是,\r\n在运行时这个调度器把阻塞操作的复杂性完全封装起来了，让程序员感觉不到它的存在。\r\n无栈协程 (Stackless Coroutines):\r\n协程不拥有独立的执行栈，它们都在同一个共享的系统栈上运行。\r\n当一个协程暂停时，它实际上是像普通函数一样 return\r\n了。编译器会在编译时进行“状态机转换”，将协程函数转换成一个对象。这个对象会保存所有局部变量的值和当前执行的位置（状态）。当协程恢复时，实际上是重新调用这个函数，函数根据保存的状态跳转到正确的位置继续执行。\r\n这种模型的优点是内存开销极小，因为不需要为每个协程分配独立的栈空间,\r\n只需在堆上分配一个很小的状态对象，可以创建海量的协程。。缺点是协程只能在函数的顶层暂停，不能在嵌套调用中间暂停。C++20\r\n的协程 (co_await)就是典型的无栈协程。\r\n对于无栈协程, 你必须在函数签名上使用关键字 (如\r\nco_await, async)\r\n来标记这个函数是一个协程。使得在编译阶段,\r\n编译器自动把这个函数转换成一个状态机。\r\n\r\n嘿，编译器，我正在写的这个函数不是一个普通的函数。看到 co_await\r\n这个标记了吗？这代表这里是一个潜在的暂停点。请你不要为我生成普通的函数代码，而是把它转换成一个状态机。”\r\n\r\n编译器做了什么：\r\n\r\n识别标记：编译器扫描代码，co_await 就是它寻找的信号。\r\n转换代码：它将你的协程函数大卸八块，变成一个状态机对象。函数里的每个\r\nco_await 点，都成为状态机的一个状态转换点。\r\n保存状态：它分析出哪些局部变量在 co_await\r\n之后还需要被使用，然后把这些变量从函数栈上“搬家”到堆上分配的协程帧对象里。\r\n生成返回逻辑：在 co_await\r\n的位置，编译器会插入代码，用于保存当前状态、然后 return\r\n控制权给调用者（事件循环）。\r\n\r\n因此, 如果没有 co_await\r\n这个明确的标记，编译器就完全不知道哪里需要暂停，它就会把你的函数当作一个普通的、同步的函数来编译。在这种情况下,\r\n这个函数一旦遇到真正的阻塞I/O就会阻塞整个线程。\r\n\n    What Color is Your Function? \n    \n      2015年，程序员 Bob Nystrom 在博客上发表文章 [What Color is Your\r\nFunction],\r\n以设计编程语言的角度，探讨同步函数与异步函数、以及他们在语言层的最优实现。\r\n想象一下，你的编程语言里有两种颜色的函数：\r\n\r\n蓝色函数 (Blue\r\nFunctions)：这些是普通的、同步的 C++\r\n函数。你调用它，它会执行到底，然后返回一个结果。简单直接。\r\n红色函数 (Red\r\nFunctions)：这些是异步的协程函数。你调用它，它会立即返回一个“承诺”（Promise/Future），而不是最终的结果。要获得最终结果，你必须\r\nawait 这个“承诺”。\r\n\r\n现在，这个世界有一条非常严格且显而易见的规则：红色函数可以调用蓝色函数，但蓝色函数不能调用红色函数。\r\n\r\n为什么？因为蓝色函数（同步）的编写者期望当他调用一个函数时，能立刻得到一个具体的值（比如\r\nint 或\r\nstd::string）。但他调用红色函数时，得到的却是一个“承诺”对象。蓝色函数完全不知道该如何处理这个“承诺”，它没有\r\nawait\r\n的能力，它无法暂停自己去等待这个承诺被兑现。它会卡住，不知所措。为了能处理这个“承诺”，调用者自己也必须有\r\nawait 的能力。而拥有 await（在 C++ 中是\r\nco_await）能力的函数，本身就必须是一个红色函数（协程）。\r\n\r\n假设我们有一个异步的数据库查询函数（它需要等待网络I/O，所以是天然的红色函数）：\r\n// 这是一个红色函数 (Coroutine)task&lt;std::string&gt; fetch_user_name_from_db(int user_id) {  // task 是一个协程返回类型, 类似于 Future/Promise    // ... 内部可能会 co_await 一个网络I/O操作    co_return \"Alice\"; }\r\n现在，我们有一个普通的蓝色函数，它想获取用户名并打印：\r\n// 这是一个蓝色函数 (Synchronous)void process_user(int user_id) {    std::cout &lt;&lt; \"Processing user \" &lt;&lt; user_id &lt;&lt; std::endl;        // --- 问题来了 ---    // 你想调用 fetch_user_name_from_db    // 但它返回的是 task&lt;string&gt;，而不是 string    // 你不能直接用它！        // 错误尝试 1: 直接调用    // std::string name = fetch_user_name_from_db(user_id); // 编译错误！类型不匹配        // 错误尝试 2: 尝试 co_await    // std::string name = co_await fetch_user_name_from_db(user_id); // 编译错误！    // 因为 process_user 不是一个协程，你不能在普通函数里使用 co_await。        std::cout &lt;&lt; \"User name is: \" &lt;&lt; name &lt;&lt; std::endl;}\r\nprocess_user 这个蓝色函数陷入了困境。它无法从红色函数\r\nfetch_user_name_from_db 中获取结果。因此, 唯一的解决方案，就是把\r\nprocess_user 也“染成”红色：\r\n// 把 process_user 也变成红色函数task&lt;void&gt; process_user(int user_id) {    std::cout &lt;&lt; \"Processing user \" &lt;&lt; user_id &lt;&lt; std::endl;        // 现在可以了！    std::string name = co_await fetch_user_name_from_db(user_id);        std::cout &lt;&lt; \"User name is: \" &lt;&lt; name &lt;&lt; std::endl;}\r\n现在 process_user 没问题了。但如果有一个更高层的函数 handle_request\r\n调用了 process_user 呢？\r\n// handle_request 是蓝色的void handle_request(int id) {    // 又遇到了同样的问题！    // 它无法直接调用红色的 process_user 并等待它完成。    process_user(id); // 这只会启动协程，但不会等待它结束}\r\n所以，handle_request 也必须被染成红色…\r\n这种依赖关系会像病毒一样，从最底层的I/O操作，一直向上层调用栈传染，直到你的\r\nmain 函数或者某个顶层的事件循环。\r\n反思一下, 这个问题的实际后果是什么？\r\n\r\n割裂的生态系统：你会发现库被分成了两个世界。“同步库”（比如一个同步的HTTP客户端）和“异步库”（一个异步的HTTP客户端）。在一个红色函数里，你如果调用了一个同步库的阻塞函数，会阻塞整个线程，让你所有的并发优势荡然无存。\r\n调用栈的传染：如上例所示，一旦你决定在某个地方使用异步，这种异步性会不可避免地蔓延到所有调用它的地方。最终，这个红色调用链会到达最顶端，通常是\r\nmain 函数（一个蓝色函数）。你必须在 main\r\n函数里使用一些特殊的“桥接”代码来启动并等待最顶层的红色函数完成。这通常是一个阻塞的\r\n.get() 调用，或者一个事件循环的 run() 方法。\r\n\r\n有栈协程如何解决这个问题？\r\n现在回过头来看，你就能理解有栈协程的强大之处。在使用\r\nucontext 或 Go goroutine 的世界里，没有颜色之分。一个函数，比如\r\nfetch_user_name_from_db，它看起来就是一个普通的蓝色函数：\r\n// 在Go语言中，没有async关键字func fetchUserNameFromDB(userID int) string {    // ... 执行数据库查询    // 这个查询操作在底层会让出CPU，但对调用者透明    return \"Alice\"}\r\n调用它的函数也看起来是蓝色的：\r\nfunc processUser(userID int) {    name := fetchUserNameFromDB(userID) // 看上去就是个普通的函数调用    fmt.Println(\"User name is:\", name)}\r\n为什么可以这样？因为当底层的数据库查询需要等待时，它会通过保存整个调用栈（processUser\r\n和 fetchUserNameFromDB 的栈帧都被完整保存）来暂停整个\r\ngoroutine。调度器会切换到另一个\r\ngoroutine。当数据返回时，调度器会恢复这个栈，程序从暂停点继续执行，就像什么都没发生过一样。\r\n调用者完全不需要知道它调用的函数是阻塞的还是非阻塞的。这就是有栈协程消除了“函数染色”问题的方法。实际上,\r\n所有函数都是“红色”的，因为它们都可能在某个时刻被暂停和恢复，但对程序员来说，它们看起来都是普通的蓝色函数。\r\n\n    \n  \r\n总结一下，有栈协程和无栈协程的主要区别：\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\n无栈协程 (C++20)\r\n有栈协程 (Go)\r\n\r\n\r\n\r\n\r\n谁负责暂停\r\n编译器（根据 co_await 标记）\r\n运行时（在 I/O 函数内部）\r\n\r\n\r\n暂停点\r\n显式（co_await 所在位置）\r\n隐式（在标准库的 I/O 调用中）\r\n\r\n\r\n需要关键字吗\r\n必须需要（co_await），否则无法工作\r\n完全不需要，对程序员透明\r\n\r\n\r\n函数颜色\r\n有颜色（“红色”函数必须被 await）\r\n无颜色（所有函数看起来都一样）\r\n\r\n\r\n实现代价\r\n编译期转换，几乎零运行时开销，内存极小\r\n强大的运行时调度器，内存开销大（独立栈）\r\n\r\n\r\n\r\nC++20 协程示例\r\n"},{"title":"Thread线程库的基本使用","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1.%20Thread%E7%BA%BF%E7%A8%8B%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","content":"C++11\r\n标准的发布是一个里程碑，它首次将线程支持纳入了标准库。这意味着开发者终于可以编写跨平台的、标准化的多线程程序了。\r\n在使用 std::thread 之前，必须包含头文件 :\r\n#include &lt;thread&gt;\r\n创建和启动线程\r\n在 C++11 中，创建一个 std::thread 对象的同时，新线程就已经开始执行了,\r\n同时主线程立即、不阻塞地继续往下执行,新线程和主线程并行执行(这就有可能导致两个线程流同时执行而引发的资源竞争问题)\r\nstd::thread\r\n的构造函数接受一个可调用对象（如函数、Lambda表达式、函数对象等）作为线程的入口点，后面跟着传递给该可调用对象的所有参数,\r\n即std::thread t(function_name, args...); 例如,\r\n下面的例子传入thread的是一个函数\r\n#include &lt;iostream&gt;#include &lt;thread&gt;// 线程要执行的函数void task() {    std::cout &lt;&lt; \"Hello from a new thread!\" &lt;&lt; std::endl;}int main() {    // 1. 创建一个 thread 对象 t，并传入函数名 task    // 2. 线程 t 立刻开始执行 task() 函数    std::thread t(task);    // 等待线程 t 执行完毕（后面会详细讲）    t.join();     return 0;}\r\n我们也可以直接传入lambda表达式 #include &lt;iostream&gt;#include &lt;thread&gt;int main() {    // 直接将 Lambda 表达式作为参数传递    std::thread t([]() {        std::cout &lt;&lt; \"Hello from a lambda thread!\" &lt;&lt; std::endl;    });    t.join();    return 0;}\r\n等待线程完成 (join)\r\n当你需要确保一个线程在主线程继续执行之前完成它的所有工作时，就需要使用\r\njoin() 方法。join()\r\n的行为是：阻塞调用它的线程（例如主线程），直到被调用的线程（例如\r\nt）执行结束。\r\n使用阻塞的好处是,\r\n一方面可以实现同步：确保子线程的工作成果在主线程的后续步骤中是可用的;\r\n另一方面也确保资源安全：防止主线程退出导致整个进程结束，而子线程可能还在执行，从而被强行终止。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;void long_running_task() {    std::cout &lt;&lt; \"Task started...\" &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(2)); // 模拟耗时操作    std::cout &lt;&lt; \"Task finished!\" &lt;&lt; std::endl;}int main() {    std::thread t(long_running_task);    std::cout &lt;&lt; \"Main thread is waiting for the task to finish.\" &lt;&lt; std::endl;    t.join(); // 主线程会在这里阻塞，直到 long_running_task 执行完毕    std::cout &lt;&lt; \"Task has been joined. Main thread continues.\" &lt;&lt; std::endl;    return 0;} 一个 std::thread 对象只能被 join 一次。调用 join()\r\n后，该线程对象不再与任何活动的执行线程相关联，其状态变为“不可加入”\r\n(joinable() 会返回 false)。\r\n检查线程是否可加入 (joinable)\r\njoinable()方法返回一个布尔值，如果线程可以被 join()或\r\ndetach()，则返回true，否则返回\r\nfalse。如果我们试图对一个不可加入的线程调用 join()或\r\ndetach()，则会抛出一个 std::system_error异常。\r\n下面是更安全的做法: #include &lt;iostream&gt;#include &lt;thread&gt;void foo() {        std::cout &lt;&lt; \"Thread started\" &lt;&lt; std::endl;}int main() {        std::thread t(foo);        if (t.joinable()) {        t.join();        }        std::cout &lt;&lt; \"Thread joined\" &lt;&lt; std::endl;        return 0;}\r\n分离线程 (detach)\r\n如果你不关心线程何时结束，也不需要等待它的结果，你可以选择“分离”它。\r\ndetach() 的行为是：将 std::thread 对象与实际执行的线程“断开连接”。\r\n之后，这个线程会在后台独立运行，而 std::thread\r\n对象本身不再代表这个线程。\r\n其优点在于, 主线程无需等待，可以立即继续执行自己的任务。\r\n但是同样具有风险：你失去了对该线程的控制。你无法再 join\r\n它。更重要的是，如果主线程（或整个程序）退出了，所有分离的线程都会被操作系统粗暴地终止，不管它们是否完成了任务。这可能导致资源泄露或数据损坏。\r\n例如, 你有一个分离的线程，它的任务是向一个文件中写入 1000 行日志\r\nvoid log_writer_task() {    std::ofstream log_file(\"my_app.log\");    for (int i = 0; i &lt; 1000; ++i) {        log_file &lt;&lt; \"Log entry \" &lt;&lt; i &lt;&lt; std::endl;        // 假设在这里有一些微小的延迟    }    // 正常情况下，函数结束时 log_file 的析构函数会自动关闭文件}int main() {    std::thread logger(log_writer_task);    logger.detach(); // 分离日志线程    std::cout &lt;&lt; \"Main function finished quickly!\" &lt;&lt; std::endl;    return 0; // main函数立即退出} 当logger 线程被创建并分离，开始向 my_app.log\r\n文件写入数据。然而 main 函数执行得非常快，几乎立刻就结束了,\r\n此时进程开始关闭，操作系统发现 logger\r\n线程还在运行，于是强行终止它。一种可能是情况是 logger 线程只写入了 150\r\n行日志，就被终止了, 造成数据损坏。\r\n再例如, 一个分离的线程在堆上分配了内存，或者获取了一个数据库连接。\r\nvoid resource_task() {    // 1. 获取资源    DatabaseConnection* db_conn = new DatabaseConnection(\"my_db\");        // 2. 使用资源执行一些操作    db_conn-&gt;executeQuery(\"UPDATE users SET last_login = NOW() WHERE id = 1;\");    // 3. 释放资源    delete db_conn; // 关键的清理步骤}int main() {    std::thread t(resource_task);    t.detach();    // main 很快结束    return 0;} main 函数很可能在 resource_task 线程执行到 delete db_conn;\r\n之前就退出了, 线程被终止, 导致delete db_conn;\r\n这行代码永远没有机会被执行, 造成资源泄露.\r\n因此，使用 detach\r\n的基本原则是：只对那些执行非常简单、不访问共享数据、不涉及需要清理的资源，并且允许被随时终止的“辅助性”任务使用。\r\n对于任何核心的、需要确保完成的任务，都应该使用\r\njoin()。\r\nRAII 与 std::thread 的所有权\r\n一个非常重要的规则是：一个 std::thread 对象在析构时，如果它仍然是\r\njoinable()（即既没有被 join 也没被 detach），那么程序的行为是调用\r\nstd::terminate()，导致程序崩溃。\r\n这是为了防止开发者忘记处理线程而导致的资源泄露和未定义行为。\r\n// 错误示例：将导致程序崩溃void problematic_function() {    std::thread t([]() { /* do something */ });    // 函数结束时，t 将被析构    // 因为 t 既没有 join 也没有 detach，程序会调用 std::terminate} 这强制我们必须对创建的每一个 std::thread\r\n对象负责，在其生命周期结束前，明确地调用\r\njoin() 或 detach()。这种思想也体现了\r\nC++ 的 RAII（Resource Acquisition Is\r\nInitialization，资源获取即初始化） 原则。\r\nthread_local 变量\r\nC++11 引入了 thread_local\r\n关键字，用于创建线程私有的、具有静态生命周期的变量。每个线程都会有自己独立的\r\nthread_local 变量实例，互不干扰。\r\n线程私有性 (Thread Privacy): 这是 thread_local\r\n最核心的特性。每个线程都拥有变量的独立实例。一个线程对它的 thread_local\r\n变量进行任何修改，都绝对不会影响到其他线程中的同名变量。\r\n静态存储期 (Static Storage Duration): thread_local\r\n变量的生命周期与它所在的线程绑定。它在线程首次使用该变量时被创建和初始化，并在线程结束时被销毁。这意味着，对于一个特定的线程，这个变量的值在函数调用之间是持久的。\r\n使用范围 (Usage Scope): thread_local\r\n可以用于修饰命名空间作用域的变量（全局变量）、文件静态变量、函数静态变量以及类的静态成员变量。它不能用于修饰非静态的局部变量或类的非静态成员。\r\n它非常适合用于解决那些“需要全局访问，但又不希望线程间共享”的场景，例如：\r\n\r\n线程安全的计数器或日志记录器。\r\n每个线程独立的随机数生成器（避免锁和种子问题）。\r\n线程级别的缓存或错误码。\r\n\r\n在 thread_local\r\n出现之前，我们在多线程编程中处理变量时面临一个两难的境地：\r\n全局变量/静态变量：\r\n\r\n优点：生命周期是整个程序，可以在任何函数中访问。\r\n缺点：所有线程共享同一个实例。如果多个线程同时修改它，就会产生竞争条件\r\n(Race Condition)，必须使用互斥锁 (std::mutex)\r\n等同步机制来保护，这会增加代码复杂性并降低性能。\r\n\r\n局部变量：\r\n\r\n优点：位于函数栈上，是线程私有的，不存在竞争问题。\r\n缺点：生命周期仅限于函数的单次调用。函数返回后，变量就被销毁了，无法在多次函数调用之间为同一个线程保持状态。\r\n\r\n这时就出现了一个需求空白：如果我需要一个变量，它能像全局变量一样在多次函数调用间保持自己的状态，但又希望它像局部变量一样是线程私有的，避免加锁，该怎么办？\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;chrono&gt;// 声明一个线程局部变量thread_local int thread_id = 0;void thread_function(int id) {    thread_id = id; // 每个线程设置自己的 thread_id    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 模拟工作    std::cout &lt;&lt; \"Thread \" &lt;&lt; id &lt;&lt; \" has thread_local id: \" &lt;&lt; thread_id &lt;&lt; std::endl;}int main() {    std::thread t1(thread_function, 1);    std::thread t2(thread_function, 2);    std::thread t3(thread_function, 3);    t1.join();    t2.join();    t3.join();    return 0;}\r\n上述代码中，虽然所有线程都访问同一个 thread_local 变量\r\nthread_id，但每个线程都有自己独立的实例。线程 1 设置\r\nthread_id 为 1，线程 2 设置为 2，线程 3 设置为\r\n3。它们互不干扰，输出结果会显示每个线程的独立值。\r\n同时, 虽然 thread_local 名称中有 “local” 一词,\r\n但它并不是局部变量。它的作用域仍然是声明它的文件或函数内，但它的生命周期是整个线程的运行期间。每个线程在第一次访问\r\nthread_local\r\n变量时，都会初始化它，并且在该线程结束时销毁它。\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"虚函数和虚继承","url":"/2025/10/12/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%87%BD%E6%95%B0/%E8%99%9A%E5%87%BD%E6%95%B0%E5%92%8C%E8%99%9A%E7%BB%A7%E6%89%BF/","content":"虚函数\r\n静态类型与动态类型\r\n为了理解虚函数中的动态绑定，首先必须区分两种“类型”。\r\n\r\n静态类型 (Static Type): 一个对象或指针在 声明时\r\n的类型，它在 编译期间 就已经完全确定，并且永远不会改变\r\n。\r\n\r\nDerive derive; 中，derive 的静态类型是 Derive。\r\nBase* pbase = new Derive(); 中，不管 pbase\r\n实际指向什么，它在声明时是 Base，所以它的 静态类型 就是\r\nBase。\r\n\r\n动态类型 (Dynamic Type): 通常指一个\r\n指针或引用 在\r\n程序运行时 实际所指向的对象的类型\r\n。这个类型是在运行时决定的，并且可以改变 。\r\n\r\nBase* pbase = new Derive(); 中，pbase 的 动态类型 是 Derive。\r\n如果后续代码执行 pbase = new Derive2();，那么 pbase\r\n的动态类型就会变为 Derive2 。\r\n普通对象（如 derive）和未指向任何对象的指针（如 Base*\r\npbase;）没有动态类型的说法 。\r\n\r\n\r\n与之对应的,\r\n函数调用如何确定最终执行哪个函数版本，取决于它的绑定方式。\r\n\r\n静态绑定 (Static Binding): 函数调用在 编译期\r\n就决定了。编译器会根据调用者（对象或指针）的 静态类型 来选择要调用的函数\r\n。普通成员函数 和 函数参数的默认值\r\n都是静态绑定的 。\r\n\r\n函数参数的默认值是静态绑定的, 这会引发一个问题: class Base {public:     virtual void func(int x = 1) { // x 的默认值是 1        std::cout &lt;&lt; \"Base::func, x = \" &lt;&lt; x &lt;&lt; std::endl;    }};class Derive : public Base {public:    void func(int x = 2) override { // x 的默认值是 2        std::cout &lt;&lt; \"Derive::func, x = \" &lt;&lt; x &lt;&lt; std::endl;    }};int main() {    Base* pbase = new Derive();    pbase-&gt;func(); // 调用的是 Derive::func，但传入的 x 是 1    delete pbase;    return 0;} 如上,\r\n虽然 pbase 指向一个 Derive 对象，调用的确实是 Derive::func，但传入的 x\r\n却是 Base::func 中定义的默认值 1\r\n。这是因为默认参数值在编译期就已经确定了，取决于指针的静态类型 Base*\r\n。因此,\r\n为了避免这种混乱，不要在子类中重新定义虚函数的默认参数\r\n。\r\n\r\n动态绑定 (Dynamic Binding): 函数调用在 运行时\r\n才决定。系统会根据指针或引用所指向对象的 动态类型 来选择要调用的函数\r\n。虚函数\r\n(当通过指针或引用调用时) 是动态绑定的\r\n。\r\n\r\n虚函数返回类型协变\r\n返回类型协变 (Covariant Return Types)\r\n是指在一个派生类中重写基类的虚函数时，可以返回一个比基类虚函数返回类型更具体的派生类型的指针或引用。\r\n换句话说，如果基类的一个虚函数返回\r\nBase（基类指针），那么派生类重写这个函数时，可以合法地返回\r\nDerived（派生类指针），只要 Derived 是 Base 的子类。\r\n虚函数底层实现\r\n为了实现动态绑定，编译器通常会使用 虚函数表 (Virtual Function Table,\r\nvtable) 和 虚函数指针 (Virtual Function Pointer, vptr)。\r\n\r\n虚函数表 (vtable):\r\n是一个静态的函数指针数组，它在编译期就已经创建好,\r\n属于 类\r\n而不是对象。每个包含虚函数（或继承自包含虚函数的类）的类都有一个自己的\r\nvtable, 存储在只读数据段(.rodata)中。\r\n\r\n这个表中存储了类中所有虚函数的地址。表中的条目顺序由函数在类中声明的顺序决定。\r\n如何构建：\r\n\r\n基类的 vtable：包含了基类中所有虚函数的地址。\r\n派生类的 vtable：首先，它会复制基类的 vtable。如果派生类 重写\r\n(override) 了某个基类的虚函数，那么派生类 vtable\r\n中对应位置的函数指针会被替换为派生类重写的函数地址。如果派生类定义了新的虚函数，这些新虚函数的地址会被添加到\r\nvtable 的末尾。\r\n\r\n\r\n虚函数指针 (vptr):\r\n是一个隐藏的成员指针，一般存在对象内存布局的开头部分,\r\n在运行期创建。它属于对象。当一个类拥有虚函数时，编译器会自动为该类的每个对象添加一个\r\nvptr(具体实现是在构造函数中初始化)。\r\n\r\n这个指针指向该对象所属类的 vtable。\r\n如何工作：当创建一个对象时（例如 new\r\nDerived()），对象的构造函数会被调用。在构造函数的初始化阶段，对象的 vptr\r\n会被设置为指向该类的 vtable。当调用虚函数时，程序会通过对象的 vptr\r\n找到对应的\r\nvtable，然后根据函数的偏移位置找到正确的函数地址并调用它。\r\n\r\n\r\nvcall thunk 和 Adjustor\r\nthunk\r\n通过前面的分析我们知道，虚函数的调用（通过指针或引用时）依赖于虚函数表。然而，当我们尝试验证这一点时，一个矛盾出现了：\r\n\r\n代码打印的地址：通过 printf(“地址 = %p”, &amp;MYACLS::myvirfunc1);\r\n这样的代码，我们可以打印出虚函数的地址\r\n调试器观察的地址：在调试程序时，我们可以观察到一个具体对象（例如\r\npmyobj）的内存布局，找到其虚函数表指针（vptr），并进一步查看虚函数表（vtable）中为\r\nmyvirfunc1 存储的真实函数地址 。\r\n\r\n关键问题在于：这两者得到的地址有时会完全不同。代码打印出来的地址并不是虚函数表中真正存储的那个地址。\r\n实际上,\r\n代码打印出的地址实际上是一个中间跳转站的地址。这个由编译器生成的、用于辅助虚函数调用的中间代码段，就被称为\r\nvcall thunk 。而虚函数表中的地址,\r\n也未必是直接指向虚函数的实现代码，取决于具体的继承结构。\r\n\r\n如果 this 指针“天生正确”，虚函数表就存储真实地址。 如果 this\r\n指针需要“后天修正”，虚函数表就存储 Adjustor thunk\r\n地址，由 thunk 负责修正后再去调用真实地址。\r\n\r\nvcall 是 “virtual call”（虚调用）的缩写。thunk\r\n是一个计算机术语，通常指一小段用于辅助调用另一段子程序的代码。\r\n而 Adjustor thunk 是 “adjustor thunk” 的缩写，指的是一种特殊类型的\r\nthunk，用于调整传递给函数的 this 指针，以确保它指向正确的对象部分。\r\n在实际多态执行的过程中, 这两类 thunk 的作用如下： - vcall\r\nthunk: 当通过基类指针或引用调用虚函数时，程序首先跳转到 vcall\r\nthunk。这个 thunk 的主要任务是从对象的 vptr 中获取正确的\r\nvtable，然后根据虚函数在类中声明的顺序找到对应的函数地址。接着，thunk\r\n会跳转到这个地址去执行实际的虚函数实现(这个虚函数可能是真实函数地址,\r\n也可能是 Adjustor thunk 地址)。 - Adjustor thunk:\r\n在多重继承或虚继承的情况下,\r\n由于对象的内存布局变得复杂，this\r\n指针可能并不总是指向对象的起始位置。Adjustor thunk\r\n的任务就是在调用实际的虚函数之前，调整 this\r\n指针，使其指向正确的对象部分。调整完成后，thunk\r\n再跳转到真正的虚函数实现。\r\n下面分情况解释这个过程：\r\n\r\n基础情况：单继承 (指针指向起始位置):\r\n在最简单的单继承中，派生类对象的内存布局通常是这样的：\r\n\r\n派生类对象 (Derive)+-------------------------+|  基类子对象 (Base)       |  &lt;-- Base* 指针指向这里|  (包含 vptr在开头)       |+-------------------------+|  派生类自己的成员变量     |+-------------------------+\r\n当执行 Base* pbase = new Derive(); 时，pbase 指针和 new Derive()\r\n返回的指针值是完全相同的。它们都指向整个 Derive\r\n对象的内存起始地址。\r\n在这种情况下，调用虚函数 pbase-&gt;virtual_func() 时，传递给函数的\r\nthis 指针就是对象的起始地址，不需要任何调整, 因此vptr直接指向\r\nvtable 中的虚函数地址即可，调用过程非常直接, vcall thunk\r\n直接跳转到虚函数实现。\r\n\r\n复杂情况一：多重继承 (指针不再指向起始位置): 假设 Derive 同时继承自\r\nBase 和 Base2 。\r\n\r\nDerive 对象的内存布局会像这样： Derive 对象的完整内存块+-------------------------+ 0x1000 (起始地址)|  Base 子对象            |  &lt;-- Base* pbase 指向这里|  (包含 vptr1在开头)      |+-------------------------+ 0x1004 (假设 Base 大小为 4)|  Base2 子对象           |  &lt;-- Base2* pb2 指向这里|  (包含 vptr2在开头)      |+-------------------------+|  Derive 自己的成员       |+-------------------------+ 现在，关键来了：当执行\r\nBase2* pb2 = new Derive(); 时，编译器知道 Base2 子对象并不是从 Derive\r\n对象的起始位置开始的。为了让 pb2 能够正确地访问 Base2\r\n的成员，编译器会自动将 new Derive()\r\n返回的起始地址（0x1000）加上一个偏移量（sizeof(Base)，即4字节），使得\r\npb2 的值变为 0x1004 。\r\n所以，此时 pb2 指针并不指向 Derive 对象的内存起始位置。当我们通过 pb2\r\n调用一个被 Derive 重写的虚析构函数时，比如 delete pb2;\r\n会发生什么？\r\n\r\n调用目标：delete 操作需要调用 Derive 的析构函数 ~Derive()。\r\nthis 指针的期望：Derive 的析构函数期望接收到的 this 指针是整个\r\nDerive\r\n对象的起始地址（0x1000），这样它才能正确地访问和析构所有成员（包括来自\r\nBase 的部分）。\r\n实际传入的指针：但我们现在拥有的指针是 pb2，它的值是\r\n0x1004。如果直接把 0x1004 当作 this 指针传给\r\n~Derive()(任何成员函数的调用都需要传入this指针)，函数就会错误地认为对象是从\r\n0x1004 开始的，从而导致访问越界、内存损坏和程序崩溃 。\r\n\r\n这个问题的解决方案就是 vcall thunk 和 Adjustor thunk ：Derive\r\n对象中与 Base2 对应的虚函数表（vtbl2）里，析构函数那一项存储的不是\r\n~Derive() 的直接地址, 它存储的是一个 thunk 代码块的地址\r\n。\r\n当 delete pb2; 触发析构函数调用时，首先跳转到 vcall\r\nthunk, 接着 vcall thunk 跳转到虚函数表找到对应函数地址, 此时是 adjustor\r\nthunk。这个 thunk\r\n的代码非常简单，其核心操作就是调整指针。减去4字节后，就得到了正确的\r\nDerive 对象起始地址 0x1000。调整完毕后，thunk 再跳转到真正的 ~Derive()\r\n函数去执行，此时传递的 this 指针已经是正确的了 。\r\n同样，当通过派生类指针调用基类函数 pd2-&gt;hBase2();\r\n时，也需要调整。pd2 指向对象开头，但 hBase2 需要一个指向 Base2 子对象的\r\nthis 指针，所以此时 thunk 会将指针向后调整 。\r\n\r\n复杂情况二：虚继承:\r\n在虚继承中，为了共享同一个基类子对象，内存布局变得更加复杂。通常，共享的虚基类会被放在派生类对象的末尾，并通过一个虚基类表指针（vbptr）来定位。\r\nDerive 对象的完整内存块+-------------------------+ 0x2000 (起始地址)|  vbptr (虚基类表指针)   |  &lt;-- Derive* pderive 指向这里+-------------------------+|  Derive 自己的成员      |+-------------------------+|                         ||  ... (内存对齐填充) ... ||                         |+-------------------------+ 0x2008 (某个偏移后)|  共享的 Base 子对象     |  &lt;-- Base* pbase 指向这里|  (包含 vptr)           |+-------------------------+ 当执行 Base* pbase = new Derive(); 时，pbase 必须指向 Base\r\n子对象，所以它的值会是 0x2008。显然，这个 pbase 指针也不指向 Derive\r\n对象的内存起始位置 。\r\n\r\n当通过 pbase 调用虚函数时，首先会跳转到 vcall thunk。vcall thunk\r\n会通过 pbase 的 vptr 找到 Base 的虚函数表，然后找到对应的虚函数地址。\r\n但这个地址可能是一个 Adjustor thunk，因为 this 指针需要调整。Adjustor\r\nthunk 会通过 Derive 对象的 vbptr 找到共享的 Base 子对象在整个 Derive\r\n对象内存中的偏移位置，然后调整 this 指针，使其指向整个 Derive\r\n对象的起始地址。调整完成后，thunk 再跳转到真正的虚函数实现。\r\n总之,\r\n在多重继承和虚继承中，为了保证每个基类指针都能正确工作，它们被调整为指向各自子对象在完整派生类对象内存中的偏移位置，而不是整个对象的起始地址。\r\nvcall thunk 就像一个中间人，负责找到正确的虚函数地址。而 Adjustor\r\nthunk 则像一个翻译官，确保传递给函数的 this\r\n指针是正确的。通过这种机制，C++\r\n实现了强大的多态性，同时保证了内存访问的安全和正确。\r\n为什么析构函数需要虚函数\r\n首先, 我们假设这样一个情境( ): 当 Derive 同时继承 Base 和 Base2\r\n时，其对象的内存布局大致如下： Derive 对象+------------------+ &lt;-- Derive* 和 Base* 指针指向这里|  Base 子对象     ||  (含 vptr1)      |+------------------+|  Base2 子对象    | &lt;-- Base2* 指针指向这里|  (含 vptr2)      |+------------------+|  Derive 成员     |+------------------+\r\n我们已经知道, 当用一个第二基类（Base2）的指针指向一个 Derive\r\n对象时（Base2* pb2 = new Derive();），pb2 指针为了能正确访问 Base2\r\n的成员，其指向的地址会被编译器自动偏移，指向 Base2\r\n子对象的起始位置，而不是整个 Derive 对象的起始位置 。\r\n而如果此时 Base2 的析构函数不是虚函数，那么执行 delete pb2;\r\n将会引发一场灾难：\r\n\r\n静态绑定：由于析构函数非虚，编译器会进行静态绑定，直接决定调用\r\nBase2::~Base2() 。\r\n资源泄露：Derive 的析构函数和 Base 的析构函数完全不会被调用，如果\r\nDerive\r\n在其构造函数中分配了任何资源（如动态内存），这些资源将永久丢失，造成严重的内存泄露。\r\n内存损坏与程序崩溃：更致命的是，系统会尝试从 pb2\r\n指针的位置（对象的中间部分）开始释放内存。这与 new\r\n操作分配的内存块的起始地址不符，会破坏堆的结构，极有可能导致程序立即或在未来的某个时刻崩溃\r\n。\r\n\r\n若将 Base2 的析构函数声明为 virtual，就能完美解决这个问题。delete\r\npb2; 的执行流程变为：\r\n\r\n动态绑定：delete 操作会触发动态绑定，通过 pb2 的 vptr2 查找到 Derive\r\n对象中对应的虚函数表（vtbl2）。\r\nthunk 的介入：在多继承下，vtbl2 中析构函数的位置存放的并不是 Derive\r\n析构函数的直接地址，而是一个被称为 thunk\r\n的一小段特殊汇编代码的地址。\r\nthis 指针的调整：这个 thunk 执行两项关键任务：调整 this 指针, 它会将\r\npb2 的指针值减去 Base 子对象的大小，使其回退到整个 Derive\r\n对象的起始地址。接着调用真实析构函数, 用这个调整好的、正确的 this\r\n指针去调用 Derive 的虚析构函数 Derive::~Derive() 。\r\n\r\n所以正确的析构链是: Derive::~Derive()\r\n首先执行自己的析构代码。然后，它会自动、反向地调用其所有基类的析构函数，即\r\nBase2::~Base2() 和 Base::~Base() 。最后，系统使用由 thunk\r\n调整过的、指向对象真正起始位置的指针来调用 operator\r\ndelete，安全地释放整块内存 。\r\n因此, 任何时候，当你打算通过一个基类指针来 delete\r\n一个派生类对象时（这是多态的常见用法），你必须将该基类的析构函数声明为\r\nvirtual。这保证了无论指针是什么类型，都能通过动态绑定和 thunk\r\n机制正确地调用到最深层派生类的析构函数，从而启动一个完整的、自下而上的析构链，确保所有资源被释放，内存被安全回收。\r\n\r\n这部分内容不同编译器实现细节可能有所不同，但核心原理和机制在所有主流\r\nC++ 编译器中都是类似的。\r\n\r\nRTTI (运行时类型识别)\r\nRTTI (Run-Time Type Information) 是 C++\r\n提供的一种机制，它允许程序在运行时查询一个对象的真实类型。这在处理多态（Polymorphism）时尤其有用，当你通过基类指针或引用操作派生类对象时，RTTI\r\n能帮助你揭示这个指针或引用“背后”的实际类型。\r\n为什么需要\r\nRTTI？设想这样一个场景：你的程序是一个动物园，里面有各种动物。你有一个统一的管理手册，上面写着“所有动物都需要喂食”，这对应于一个基类\r\nAnimal 和一个虚函数 feed()。 class Animal {public:    virtual void feed() { /* 通用喂食方法 */ }    virtual ~Animal() {}};class Monkey : public Animal { /* ... */ };class Lion : public Animal { /* ... */ };class Elephant : public Animal { /* ... */ }; 你可以用一个 Animal*\r\n指针指向任何动物，并调用\r\nfeed()，多态会确保调用正确的喂食方法。这非常优雅。\r\n但是，现在有一个特殊需求：只有当眼前的动物是猴子时，你才能给它一根香蕉。这个\r\ngiveBanana() 方法是 Monkey 类特有的，Animal 基类并不知道。 class Monkey : public Animal {public:    void giveBanana() { /* 给香蕉 */ }};Animal* some_animal = get_random_animal(); // 可能返回 Monkey* 或 Lion*// 如何安全地调用 giveBanana() ?// some_animal-&gt;giveBanana(); // 编译错误！Animal 没有这个方法\r\n当你只有一个 Animal* 指针时，你怎么知道它指向的是不是一只猴子呢？RTTI\r\n就是解决这个问题的工具。它允许你在运行时“询问”some_animal：“嘿，你的真实身份到底是不是\r\nMonkey？”\r\nC++ RTTI 的两大核心工具\r\nC++ 通过两个主要的操作符来实现 RTTI：dynamic_cast 和 typeid。\r\ndynamic_cast：安全地进行向下转型\r\ndynamic_cast 是 RTTI\r\n中最常用也最重要的工具。它的作用是在运行时尝试将一个基类指针或引用安全地转换成派生类的指针或引用。\r\n核心特性：安全。如果转换是非法的（比如你试图将一个指向 Lion 对象的\r\nAnimal* 转换成\r\nMonkey*），它不会导致程序崩溃，而是会给你一个明确的失败信号。\r\n\r\n对于指针：如果转换成功，它返回一个指向派生类对象的有效指针；如果转换失败，它返回\r\nnullptr。\r\n对于引用：如果转换成功，它返回一个指向派生类对象的有效引用；如果转换失败，它会抛出一个\r\nstd::bad_cast 异常。 #include &lt;iostream&gt;// (Animal, Monkey, Lion 类的定义如上)void try_to_give_banana(Animal* animal_ptr) {    if (!animal_ptr) return;    std::cout &lt;&lt; \"正在检查一只动物...\" &lt;&lt; std::endl;        // 步骤说明：使用 dynamic_cast 尝试进行向下转型。    // 这是 RTTI 的核心应用。我们询问：“animal_ptr 指向的对象，    // 其真实类型是 Monkey 或 Monkey 的子类吗？”    Monkey* monkey_ptr = dynamic_cast&lt;Monkey*&gt;(animal_ptr);    // 步骤说明：检查 dynamic_cast 的结果。    // 这是保证类型安全的关键。    if (monkey_ptr != nullptr) {        // 转换成功！现在可以安全地调用 Monkey 的特有方法。        std::cout &lt;&lt; \"哦，这是一只猴子！给它一根香蕉。\" &lt;&lt; std::endl;        monkey_ptr-&gt;giveBanana();    } else {        // 转换失败，说明它不是猴子。        std::cout &lt;&lt; \"这不是猴子，不能给香蕉。\" &lt;&lt; std::endl;    }} 不过dynamic_cast\r\n只能用于具有虚函数的类（即多态类）。因为编译器只为这种类生成\r\nRTTI 所需的类型信息（通常存储在虚函数表 vtable\r\n中）。如果基类没有虚函数，使用\r\ndynamic_cast 会导致编译错误。\r\n\r\ntypeid：获取对象的类型信息\r\ntypeid 操作符返回一个对 std::type_info\r\n对象的常量引用，这个对象包含了特定类型的元信息。主要用途是：\r\n\r\n比较类型：判断两个对象是否为完全相同的类型。\r\n获取类型名称：通过 .name()\r\n方法获取一个表示类型名称的字符串（注意：这个字符串的格式没有跨编译器的标准，可能是“美化”过的，也可能是“混淆”过的）。\r\n\r\n注意, typeid\r\n也只能用于多态类的指针或引用，以确保获取的是对象的动态类型信息。如果对非多态类使用\r\ntypeid，得到的将是静态类型信息。 #include &lt;iostream&gt;#include &lt;typeinfo&gt; // 需要包含这个头文件// (Animal, Monkey, Lion 类的定义如上)void check_exact_type(Animal* animal_ptr) {    if (!animal_ptr) return;    // 步骤说明：使用 typeid 获取指针指向对象的真实类型信息。    // 注意，要对指针解引用 *animal_ptr 才能获取动态类型。    const std::type_info&amp; info = typeid(*animal_ptr);    std::cout &lt;&lt; \"检查类型: \" &lt;&lt; info.name() &lt;&lt; std::endl;    // 步骤说明：将运行时类型与已知的编译时类型进行比较。    if (info == typeid(Monkey)) {        std::cout &lt;&lt; \"这正是一只猴子，不多不少。\" &lt;&lt; std::endl;    } else if (info == typeid(Lion)) {        std::cout &lt;&lt; \"这正是一只狮子。\" &lt;&lt; std::endl;    }}\r\ndynamic_cast 与 typeid 的区别在于:\r\n\r\ndynamic_cast 检查的是“是否可以安全地视为”某种类型（Is-a\r\nrelationship, 包括子类）。\r\ntypeid 检查的是“是否完全就是”某种类型（Exact type）。\r\n\r\n如何看待 RTTI\r\n当然, 天下没有免费的午餐。RTTI 功能是有成本的：\r\n\r\n内存开销：编译器(因此 RTTI\r\n信息是编译器确定的)需要为每个多态类生成额外的类型信息，并将其存储在程序的某个地方(通常存储在\r\nvtable 的某个固定偏移处), 这会稍微增加程序的大小。\r\n\r\n在 Visual Studio 中，它通常位于虚函数表起始地址的前一个位置（vptr -\r\n1）。程序正是通过这个入口点来获取对象的运行时类型信息。\r\n\r\n性能开销：dynamic_cast 和 typeid\r\n的操作是在运行时进行的。尤其是\r\ndynamic_cast，它需要在类的继承体系中进行查找，可能会比一次普通的函数调用慢。\r\n\r\n因此，在性能极其敏感的代码中，开发者可能会选择禁用\r\nRTTI（通过编译器选项，如 GCC/Clang 的 -fno-rtti 或 MSVC 的 /GR-）。\r\n并且, 一个合理的设计原则是: 优先使用虚函数，而不是\r\nRTTI。\r\n如果你的代码里充斥着 if/else if 结构，用 dynamic_cast\r\n来判断对象类型，然后调用不同的函数，这通常是一个糟糕设计的信号。\r\nvoid process_animal(Animal* p) {    if (dynamic_cast&lt;Monkey*&gt;(p)) {        // ... do monkey stuff    } else if (dynamic_cast&lt;Lion*&gt;(p)) {        // ... do lion stuff    } // ... 每增加一种动物，就要修改这里} 更好的做法是利用多态，让每个类自己处理自己的行为：\r\n// 在每个动物类中实现自己的 process 方法class Animal {public:    virtual void process() = 0; // 纯虚函数    // ...};class Monkey : public Animal {public:    void process() override { /* do monkey stuff */ }};class Lion : public Animal {public:    void process() override { /* do lion stuff */ }};// 客户端代码变得极其简单和稳定void process_animal(Animal* p) {    p-&gt;process(); // 不需要知道具体类型，直接调用即可} ## 虚继承\r\n当我们谈论虚继承时，首先必须理解它要解决的问题——菱形继承。\r\n菱形继承的问题\r\n菱形继承是一种继承结构，指一个派生类同时继承了两个基类，而这两个基类又共同继承自同一个更顶层的基类。这种结构在类图上看起来像一个菱形，因此得名。\r\n#include &lt;iostream&gt;// 顶层基类class Base {public:    int m_base_data;    Base() : m_base_data(0) { std::cout &lt;&lt; \"Base constructor\" &lt;&lt; std::endl; }};// 中间派生类class Derived1 : public Base {public:    int m_derived1_data;    Derived1() : m_derived1_data(1) { std::cout &lt;&lt; \"Derived1 constructor\" &lt;&lt; std::endl; }};class Derived2 : public Base {public:    int m_derived2_data;    Derived2() : m_derived2_data(2) { std::cout &lt;&lt; \"Derived2 constructor\" &lt;&lt; std::endl; }};// 底层派生类class Diamond : public Derived1, public Derived2 {public:    int m_diamond_data;    Diamond() : m_diamond_data(3) { std::cout &lt;&lt; \"Diamond constructor\" &lt;&lt; std::endl; }};int main() {    Diamond d;        // 问题1: 访问成员的二义性    // d.m_base_data = 100; // 编译错误！ Ambiguous access        // 我们可以通过指定路径来解决二义性，但这暴露了底层问题    d.Derived1::m_base_data = 100;    d.Derived2::m_base_data = 200;    std::cout &lt;&lt; \"d.Derived1::m_base_data = \" &lt;&lt; d.Derived1::m_base_data &lt;&lt; std::endl;    std::cout &lt;&lt; \"d.Derived2::m_base_data = \" &lt;&lt; d.Derived2::m_base_data &lt;&lt; std::endl;    std::cout &lt;&lt; \"sizeof(Diamond) = \" &lt;&lt; sizeof(Diamond) &lt;&lt; std::endl;    return 0;}\r\n没有虚继承的菱形继承会导致数据冗余和二义性问题:\r\n\r\n数据冗余 (Data Redundancy)：Diamond 类的对象 d 中包含了 两份 Base\r\n类的子对象（成员变量 m_base_data）。一份来自 Derived1 的继承，另一份来自\r\nDerived2 的继承。从 sizeof 的结果和可以分别对 d.Derived1::m_base_data 和\r\nd.Derived2::m_base_data\r\n赋值就可以看出这一点。这浪费了内存，也违背了我们的设计初衷（我们通常希望\r\nDiamond 只有一个 Base 部分）。\r\n访问二义性 (Ambiguity)：由于存在两份 m_base_data，当编译器遇到\r\nd.m_base_data 这样的代码时，它不知道你想要访问的是 Derived1\r\n路径下的那一份，还是 Derived2\r\n路径下的那一份，因此会报编译错误。\r\n\r\n非虚继承下的内存布局示意图： 一个 Diamond 对象在内存中看起来像这样：\r\n+---------------------+|   Base subobject    |  (from Derived1)|  (m_base_data)      |+---------------------+| Derived1's members  ||  (m_derived1_data)  |+---------------------+|   Base subobject    |  (from Derived2)|  (m_base_data)      |+---------------------+| Derived2's members  ||  (m_derived2_data)  |+---------------------+| Diamond's members   ||  (m_diamond_data)   |+---------------------+\r\n解决方案：虚继承 (Virtual\r\nInheritance)\r\n为了解决上述问题，C++ 引入了 虚继承。通过在继承方式前加上 virtual\r\n关键字，我们可以告诉编译器，我希望这个基类在派生类的继承体系中\r\n只保留一个共享的实例。\r\n我们只需要修改中间派生类的继承方式： // 将继承方式改为 virtual publicclass Derived1 : virtual public Base { /* ... */ };class Derived2 : virtual public Base { /* ... */ };// Diamond 类和 Base 类无需改动class Diamond : public Derived1, public Derived2 { /* ... */ };int main() {    Diamond d;        // 现在不再有二义性了！    d.m_base_data = 100; // 编译通过！        std::cout &lt;&lt; \"d.m_base_data = \" &lt;&lt; d.m_base_data &lt;&lt; std::endl;        // 验证 Derived1 和 Derived2 访问的是同一个数据    d.Derived1::m_base_data = 200;    std::cout &lt;&lt; \"d.Derived2::m_base_data = \" &lt;&lt; d.Derived2::m_base_data &lt;&lt; std::endl;    std::cout &lt;&lt; \"sizeof(Diamond) = \" &lt;&lt; sizeof(Diamond) &lt;&lt; std::endl;    return 0;} 此时,\r\nd.m_base_data 不再有歧义，因为 Diamond 对象中现在 只有一个 Base\r\n子对象。\r\n通过 d.Derived1::m_base_data 修改的值，可以通过\r\nd.Derived2::m_base_data 读取出来，证明它们访问的是同一块内存。\r\nsizeof(Diamond) 的大小会比之前非虚继承时要小（因为它少了一份 Base\r\n的数据），但会比简单成员相加要大（因为它增加了额外的指针）。\r\n虚继承的底层实现机制\r\n那么，编译器是如何做到让 Derived1 和 Derived2 共享同一个 Base\r\n子对象的呢？这背后是通过 虚基类指针 (virtual base\r\npointer, vbptr) 和 虚基类表 (virtual base table,\r\nvbtable) 实现的。\r\n对于 Derived1 来说，它无法在编译时确定其基类 Base 的成员 m_base_data\r\n相对于自己的起始地址的偏移量。因为如果 Derived1 被 Diamond 继承，Base\r\n子对象的位置由 Diamond 决定；如果 Derived1 被单独实例化，Base\r\n子对象的位置又不一样。这个偏移量必须在运行时才能确定。\r\n\n    假如不使用虚基类表和虚基类指针 \n    \n      首先，我们看看没有 virtual 的情况，编译器是如何工作的。\r\nclass Base { public: int m_base_data; };class Derived1 : public Base { public: int m_derived1_data; }; 当编译器在编译 Derived1 类的成员函数时（比如一个叫 foo()\r\n的函数），它需要生成访问 m_base_data 的机器码。而只要编译器看到 Derived1\r\n的定义，它能 100% 确定 Derived1 对象的内存布局：Base 子对象总是在最前面,\r\nDerived1 的成员跟在后面。\r\n内存布局如下： +------------------+  &lt;- Derived1 对象的起始地址 (this)|   Base's part    ||  (m_base_data)   |+------------------+|  Derived1's part || (m_derived1_data)|+------------------+\r\n所以，当 Derived1::foo() 访问 m_base_data 时，编译器知道 m_base_data\r\n相对于 Derived1 对象的起始地址（也就是 this 指针的值）的偏移量 永远是\r\n0。这个 “0” 是一个 编译时常量。编译器可以直接生成高效的指令，比如 “从\r\nthis 指针指向的地址读取一个整数”，也就是说编译器可以直接确定\r\nm_base_data 的位置。\r\n现在，我们加上 virtual 关键字：\r\nclass Base { public: int m_base_data; };class Derived1 : virtual public Base { public: int m_derived1_data; };\r\n现在，编译器再次开始编译 Derived1 的成员函数 foo()。它又要生成访问\r\nm_base_data 的机器码。但是，编译器现在面临一个巨大的难题。它只看到了\r\nDerived1 的定义，但它不知道 Derived1\r\n将来会如何被使用。它遇到了两种完全可能且内存布局截然不同的情况：\r\n情况 A：Derived1\r\n被单独实例化Derived1 obj1;\r\n在这种情况下，obj1\r\n是最终的对象。编译器会为它生成一个内存布局。一种常见的实现是这样的：\r\n+--------------------+  &lt;- obj1 的起始地址 (this)|    vbptr_for_D1    |  (指向一个表，表里说 Base 在下面 N 个字节处)+--------------------+|  m_derived1_data   |+--------------------+|   Shared Base      |  &lt;-- 共享的 Base 子对象|   (m_base_data)    |+--------------------+ 在这个布局中，m_base_data 相对于 obj1\r\n起始地址的偏移量可能是，比如说，16 字节（假设 vbptr 和 m_derived1_data\r\n各占 8 字节）。所以，在情况 A 中，偏移量是 16。\r\n情况 B：Derived1 作为 Diamond\r\n的一部分被实例化\r\n// 用户的代码里可能是这样写的：class Derived2 : virtual public Base { /* ... */ };class Diamond : public Derived1, public Derived2 { /* ... */ };Diamond obj_diamond;\r\n在这种情况下，Derived1 只是 Diamond\r\n对象内部的一个组件。Diamond\r\n作为“最远派生类”，它有权决定最终的内存布局，尤其是那个\r\n唯一的、共享的 Base 子对象 应该放在哪里。\r\nobj_diamond 的内存布局可能如下： +--------------------+  &lt;- obj_diamond 的起始地址| Derived1's part:   |  &lt;- 同时也是 obj_diamond 内部 Derived1 子对象的起始地址 (this)|   vbptr_for_D1     ||   m_derived1_data  |+--------------------+| Derived2's part:   ||   ...              |+--------------------+| Diamond's part:    ||   ...              |+--------------------+|   Shared Base      |  &lt;-- 唯一的 Base 子对象被放在了最底下|   (m_base_data)    |+--------------------+\r\n在这个布局中，m_base_data 相对于 obj_diamond 内部 Derived1\r\n子对象起始地址的偏移量可能变成了，比如说，48 字节。所以，在情况 B\r\n中，偏移量是 48。\r\n现在，回到编译器正在编译 Derived1::foo() 的那个时刻。它需要为访问\r\nm_base_data 生成机器码。它应该使用哪个偏移量呢？是 16 还是\r\n48？答案是：它无法知道。\r\n因为在编译 Derived1\r\n这个“组件”的时候，编译器根本不知道这个组件将来是会被单独使用（情况\r\nA），还是被组装进一个更大的 Diamond 对象里（情况 B）。\r\n这就是 “无法在编译时确定其基类…的偏移量”\r\n这句话的精确含义。这个偏移量不再是一个固定的编译时常量，它变成了一个变量，取决于\r\nDerived1 在运行时到底是以何种形式存在的。\r\n既然不能在编译时“写死”一个固定的偏移量，那就只能采用一种能在运行时“查找”偏移量的方法。这就是\r\nvbptr (虚基类指针) 登场的时刻。\r\n编译器生成的机器码不再是：“从 this 地址偏移一个固定的 N 值”,\r\n而是变成了一套更复杂的指令，其逻辑是：“找到 this 指针指向的对象内存里的\r\nvbptr。” (这个 vbptr 的位置是固定的) –&gt; “根据 vbptr 找到虚基类表\r\n(vbtable)。” –&gt; “从表中查出 Base 子对象的偏移量。”\r\n(这个表里的值是由最终对象的构造函数——Derived1() 或\r\nDiamond()——在创建对象时填好的) –&gt; “用 this\r\n的地址加上刚刚查到的偏移量，得到 Base 子对象的实际地址。” –&gt; “访问\r\nm_base_data。”\r\n\n    \n  \r\n为了解决这个运行时定位的问题，编译器引入了间接层来实现间接寻址：\r\n\r\n虚基类指针 (vbptr):\r\n编译器会给每一个虚继承的派生类对象（如 Derived1 和\r\nDerived2 的对象）安插一个隐藏的指针，即\r\nvbptr。这个指针指向一个虚基类表。\r\n虚基类表 (vbtable):\r\n这是一个静态的表，属于类,\r\n存放在数据段 (.data) 或只读数据段 (.rodata)\r\n中。表中存放的是 偏移量 (offset)。这个偏移量指示了从当前 vbptr\r\n的地址出发，需要移动多少字节才能找到共享的虚基类子对象的起始地址。\r\n\r\n例如，Derived1 的 vbtable 中会有一个条目，记录了 Base 子对象相对于\r\nDerived1 对象起始地址的偏移量。\r\n这个偏移量是在 Diamond 对象编译时计算,\r\n并在创建时，由 Diamond 的构造函数设置的(因为 Diamond\r\n是最远派生类，负责最终的内存布局)。\r\n\r\n\r\n当 Derived1 的成员函数要访问 m_base_data 时, 它通过 this\r\n指针找到自身的 vbptr, 又通过 vbptr 找到对应的 vbtable, 从 vbtable\r\n中读取到指向 Base 子对象的偏移量。\r\n将当前对象的地址加上这个偏移量，就得到了共享的 Base 子对象的地址,\r\n最后通过这个计算出的地址去访问 m_base_data。\r\n在虚继承下一个 Diamond\r\n对象的内存布局（一种常见的编译器实现方式）可能如下： +---------------------+| Derived1's part:    ||   vbptr_for_D1      | --&gt; vbtable for D1 (contains offset to Base)|   m_derived1_data   |+---------------------+| Derived2's part:    ||   vbptr_for_D2      | --&gt; vbtable for D2 (contains offset to Base)|   m_derived2_data   |+---------------------+| Diamond's part:     ||   m_diamond_data    |+---------------------+| Shared Base object: |  &lt;-- The single, shared instance|   m_base_data       |+---------------------+ -\r\nBase 子对象被放在了整个 Diamond\r\n对象内存布局的某个位置（通常是末尾）。 - Derived1 和\r\nDerived2 的子对象中都包含一个 vbptr。 - vbptr_for_D1\r\n指向的表告诉程序如何从 Derived1 部分找到 Base 部分。 - vbptr_for_D2\r\n指向的表告诉程序如何从 Derived2 部分找到 Base 部分。\r\n虚继承的重要规则：构造函数\r\n这里有一条重要规则：虚基类的构造函数由 最远派生类\r\n(most-derived class)\r\n的构造函数来调用，而中间派生类的构造函数对虚基类构造函数的调用在某些情况下会被忽略。\r\n在我们的例子中，Diamond 是最远派生类。因此，Diamond\r\n的构造函数负责初始化 Base。 class Base {public:    Base(int i) { /* ... */ }};class Derived1 : virtual public Base {public:    // 这个 : Base(10) 在创建 Diamond 对象时会被忽略    Derived1() : Base(10) { } };class Derived2 : virtual public Base {public:    // 这个 : Base(20) 也会被忽略    Derived2() : Base(20) { }};class Diamond : public Derived1, public Derived2 {public:    // 必须由 Diamond 显式调用 Base 的构造函数    // 如果不写，则会调用 Base 的默认构造函数（如果存在）    Diamond() : Base(30) { } }; 因为 Base\r\n子对象只有一个，它的构造函数也必须只被调用一次。如果允许多个中间派生类都去调用，就会产生冲突。因此，C++\r\n规定这个责任由继承体系中最下层的那个类来承担。\r\n","categories":["CPP","函数"],"tags":["CPP"]},{"title":"Thread线程库中的资源问题","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/2.%20Thread%E7%BA%BF%E7%A8%8B%E5%BA%93%E4%B8%AD%E7%9A%84%E8%B5%84%E6%BA%90%E9%97%AE%E9%A2%98/","content":"在单线程程序中，对象的创建和销毁顺序是可预测的。但在多线程程序中，新线程的执行时机是不确定的。它可能在创建它的函数返回之前、之中或之后才真正开始运行。“数据未定义错误”的根源就是，程序员错误地假设了新线程会比它所需要的数据“死”得更早，但事实往往相反。\r\n下面这些问题的本质原因在于:\r\n线程的生命周期与其访问的数据的生命周期不匹配，导致线程访问了无效的内存\r\n数据未定义的情况\r\n传递临时变量\r\n#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int&amp; x) {    x += 1;}int main() {    std::thread t(foo, 1); // 传递临时变量    t.join();    return 0;}\r\n上述代码中，foo函数接受一个整数引用作为参数，并对其加\r\n1。但在线程创建时，传入的1是一个临时变量，在std::thread解析参数时，该临时变量会被销毁，导致foo访问了已销毁的对象，产生未定义行为。\r\n解决方案是使用 std::ref 传递一个持久化变量的引用：\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;functional&gt;void foo(int&amp; x) {    x += 1;}int main() {    int x = 1;    std::thread t(foo, std::ref(x)); // 传递变量的引用    t.join();    return 0;} 注意这里必须传入引用而不是值，否则根据线程的规则,\r\n线程会访问一个临时对象的副本，而不是原始对象。\r\n\r\nstd::thread 的构造函数在接收参数时，默认情况下会复制\r\n(copy) 或 移动 (move)\r\n传递给它的参数。它会将这些参数的副本存储在线程内部，然后在新的线程上下文中，将这些副本传递给你指定的函数。也就是说,\r\n它是不支持通过变量名直接引用传参的, 如果想实现引用传参, 必须使用\r\nstd::ref 或 std::cref 包装一下。\r\n\r\n传递指针或引用指向局部变量的问题\r\n#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int* ptr) {    std::cout &lt;&lt; *ptr &lt;&lt; std::endl; // 访问完全可能已经被销毁的指针}int main() {    int x = 1;    std::thread t(foo, &amp;x); // 传递指向局部变量的指针    t.detach();    return 0;}\r\n一个解决策略是使用std::shared_ptr，避免手动管理内存 #include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;memory&gt;void foo(std::shared_ptr&lt;int&gt; ptr) {    std::cout &lt;&lt; *ptr &lt;&lt; std::endl;}int main() {    auto ptr = std::make_shared&lt;int&gt;(1);    std::thread t(foo, ptr);    t.join();    return 0;}\r\n这里的 std::shared_ptr\r\n确保了对象的生命周期与线程的生命周期同步，避免了访问已销毁对象的问题。\r\n传递指针或引用指向已释放的内存的问题\r\n#include &lt;iostream&gt;#include &lt;thread&gt;void foo(int&amp; x) {    std::cout &lt;&lt; x &lt;&lt; std::endl;}int main() {    int* ptr = new int(1);    std::thread t(foo, *ptr); // 传递已释放的内存    delete ptr;    t.join();    return 0;}\r\n在线程 t 启动前，ptr有可能已被delete，导致foo访问了已释放的内存，行为未定义.\r\n解决方法是确保在线程的生命周期内，指针或引用指向的内存不被释放,\r\n即对调join()和delete的顺序\r\n类成员函数作为入口函数，类对象被提前释放\r\n#include &lt;iostream&gt;#include &lt;thread&gt;class MyClass {public:    void func() {        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" started\" &lt;&lt; std::endl;        // do some work        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" finished\" &lt;&lt; std::endl;    }};int main() {    MyClass obj;    std::thread t(&amp;MyClass::func, &amp;obj);    return 0;} // obj 被销毁，可能导致线程崩溃\r\n这里在 main 结束时，obj 被销毁，导致 t 访问已销毁的对象，可能崩溃。\r\n解决方法还是使用使用 std::shared_ptr 管理生命周期： #include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;memory&gt;class MyClass {public:    void func() {        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" started\" &lt;&lt; std::endl;        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" finished\" &lt;&lt; std::endl;    }};int main() {    auto obj = std::make_shared&lt;MyClass&gt;();    std::thread t(&amp;MyClass::func, obj);    t.join();    return 0;}\r\n两条时间线\r\n正如开头所说,\r\n这些情况的本质原因在于一个线程尝试访问一个在它访问的那个时刻，其生命周期已经结束（或者可能已经结束）的数据对象。\r\n为了避免这种问题,\r\n在多线程编程中，你必须在脑海里清晰地分出两条并行且速度不一的“时间线”：\r\n数据的时间线：这是指变量或对象从被创建到被销毁的整个过程。这条时间线的终点是由\r\nC++ 的作用域和内存管理规则严格决定的。 -\r\n局部变量/对象：其生命周期严格绑定在创建它的那个作用域 {}\r\n内。函数返回或作用域结束，它就立刻死亡。 -\r\n临时对象：生命周期更短，通常只在创建它的那一个完整语句内有效。语句结束，它就死亡。\r\n- 堆对象 (new)：生命周期从 new 开始，到 delete\r\n被调用时结束。它的死亡时刻由程序员手动决定。\r\n线程的时间线：这是指一个线程从被创建到其任务执行完毕的整个过程。这条时间线的启动和结束相对于创建它的代码来说，是异步的、不确定的。你只知道它在\r\nstd::thread\r\n对象被创建后“某个时间点”开始，在任务执行完毕后“某个时间点”结束。\r\n而上述提到的未定义行为，都爆发于这两条时间线的交叉点上，并且是一场“死亡竞赛”：“数据的死亡”\r\n与 “线程的访问”\r\n之间在赛跑。如果“数据的死亡”先于“线程的访问”到达，程序就会崩溃。\r\n传递局部变量的指针： - 数据的死亡时刻：创建局部变量的函数返回时。 -\r\n线程的访问时刻：不确定，很可能在函数返回之后。 -\r\n竞赛结果：数据几乎总是先死。线程访问的是无效的栈内存。\r\n传递临时变量的指针： - 数据的死亡时刻：创建线程的语句结束时。 -\r\n线程的访问时刻：不确定，但几乎总是在该语句结束之后。 -\r\n竞赛结果：数据总是先死。这是最危险的情况，因为数据生命周期极短。\r\n提前 delete 堆内存： - 数据的死亡时刻：主线程执行到 delete 时。 -\r\n线程的访问时刻：不确定，与主线程并发。 -\r\n竞赛结果：这是一场真正的竞赛。delete\r\n和线程的访问哪个先发生完全不确定。只要有任何可能 delete\r\n先发生，代码就是错误的。\r\n类对象提前释放： - 数据的死亡时刻：类对象所在的作用域结束时。 -\r\n线程的访问时刻：不确定，很可能在作用域结束之后。 -\r\n竞赛结果：和局部变量一样，数据几乎总是先死。线程通过悬空的 this\r\n指针访问成员。\r\n通用的解决方案：强制同步生命周期\r\n既然问题的本质是生命周期不匹配，那么解决方案的本质就是强制让它们的生命周期匹配起来。程序员的责任就是确保这场“死亡竞赛”永远不会发生。\r\n通用的方法是：通过同步机制，确保在线程的整个生命周期内，它所访问的数据的生命周期也持续有效。具体手段包括：\r\n延长数据的生命周期： -\r\n按值传参：不传递指针或引用，而是直接复制一份数据给线程。这样线程就拥有了数据的独立副本，副本的生命周期和线程自身绑定，与原始数据无关。\r\n- 使用智能指针 std::shared_ptr：将堆上的数据交由 std::shared_ptr\r\n管理。只要线程还持有 shared_ptr 的副本，数据就不会被释放。\r\n缩短（或同步）线程的生命周期： - 使用\r\nthread::join()：这是最核心的同步工具。join()\r\n的作用就是强制让“创建者的代码流”停下来，等待“线程的时间线”结束。这样就保证了在函数返回、作用域结束、对象销毁之前，线程一定已经完成了对该数据的访问。\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"C风格线程的基本使用","url":"/2025/10/14/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/0.%20C%E9%A3%8E%E6%A0%BC%E7%BA%BF%E7%A8%8B/","content":"在 C 语言中，线程的创建和管理通常通过 POSIX\r\n线程库（pthread）来实现。\r\n线程的生命周期管理\r\n这部分API用于“启动”和“停止”并发任务。\r\n线程创建 (pthread_create) -\r\n功能：这是启动一个新线程的唯一方法。你可以把它想象成“发起一个并发的函数调用”。\r\nint pthread_create(    pthread_t * thread,         // [出参] 指向线程ID的指针，用于存储新线程的句柄    const pthread_attr_t * attr, // [入参] 线程的属性（如栈大小、调度策略），NULL为默认    void * (*start_routine)(void*), // [入参] 函数指针：新线程要执行的函数, 函数签名必须是 void* func(void*). 如果不是, 需要进行适当的转换    void * arg                    // [入参] 传递给 start_routine 的（单个）参数, 无参时传 NULL); -\r\nthread：这是一个“出参”。你传入一个pthread_t变量的地址，pthread_create会把新线程的ID（句柄）填入其中。你将来会用这个ID来join（等待）该线程。\r\n-\r\nstart_routine：这是新线程的“main函数”。你告诉create：“请在一个新线程里执行这个函数”。\r\n-\r\n函数的返回值类型必须是void，参数类型也必须是void。这是C语言中实现“泛型函数指针”的一种方式。\r\n- 你可以在函数内部将void参数转换为具体类型的指针，然后使用它。 -\r\n返回的void值可以用来传递线程的结果，主线程可以通过pthread_join获取这个返回值。\r\n- void * 和 arg：这是C语言中实现“泛型”的技巧。 - start_routine\r\n必须是一个“接受void*参数，返回void*”的函数。 - arg\r\n则是要传递给start_routine的那个void*参数。 -\r\n返回值：成功返回0，失败返回错误码。\r\n如何传递多个参数？你不能直接传,\r\n标准做法是定义一个struct，把所有参数（如a和b）放进去，然后将这个struct的指针（&amp;args）强制转换为void作为arg传递。线程函数（mythread）接收到void\r\narg后，再将其强制转换回struct *来解包。\r\n例如, 创建一个新线程来执行 threadFunc 函数:\r\n#include &lt;pthread.h&gt;#include &lt;iostream&gt;void* threadFunc(void* arg) {    int* num = static_cast&lt;int*&gt;(arg);    std::cout &lt;&lt; \"Thread number: \" &lt;&lt; *num &lt;&lt; std::endl;    char* ch = static_cast&lt;char*&gt;(arg);    std::cout &lt;&lt; \"Thread character: \" &lt;&lt; *ch &lt;&lt; std::endl;    return nullptr;}int main() {    pthread_t thread;    int threadArg1 = 42;    char threadArg2 = 'A';    // 将多个参数打包到一个结构体中    struct ThreadArgs {        int a;        char b;    }     ThreadArgs threadArg = {threadArg1, threadArg2};    // 创建线程，传递结构体指针作为参数    pthread_create(&amp;thread, nullptr, threadFunc, static_cast&lt;void*&gt;(&amp;threadArg));    pthread_join(thread, nullptr); // 等待线程结束    return 0;} 线程完成/等待 (pthread_join)\r\n功能：让一个线程（通常是主线程）阻塞（睡眠），直到另一个目标线程执行完毕。\r\nint pthread_join(    pthread_t thread,     // [入参] 你要等待的那个线程的ID（由 create 返回）    void **value_ptr      // [出参] 一个指针，用于接收目标线程的返回值); - thread：你要等待的目标。 - void\r\n**value_ptr：这是API中最令人困惑的部分，我们来拆解它： -\r\n目标线程的start_routine返回一个void （这是它的“返回值”）。 -\r\npthread_join函数需要将这个void 返回值写入到main函数的一个变量中。 -\r\n由于C语言中函数参数传递是“值传递”，如果你直接传入一个void\r\n*变量，pthread_join只能修改它的副本，无法修改main函数中的变量。 -\r\n因此，你需要传入这个变量的地址，即一个void\r\n**，这样pthread_join才能通过这个地址修改main函数中的变量。 - 例如：\r\nvoid* retVal; // 用于接收线程的返回值pthread_join(thread, &amp;retVal); // 传入 retVal 的地址（void **） - 返回值：成功返回0，失败返回错误码。\r\n线程终止 (pthread_exit)\r\n功能：这是终止当前线程的唯一方法。你可以在当前线程的任何地方调用它来结束线程的执行。\r\nvoid pthread_exit(void *value_ptr); -\r\nvalue_ptr：这是线程的“返回值”。当线程调用pthread_exit时，它可以传递一个void\r\n*值作为它的结果。这个值可以被其他线程通过pthread_join获取。 -\r\n注意：调用pthread_exit不会终止整个进程，只会终止当前线程。\r\n互斥原语：锁\r\n这组API用于解决竞态条件问题。\r\n功能：提供互斥（Mutual\r\nExclusion），确保一个“临界区”在同一时间只被一个线程执行。 int pthread_mutex_lock(pthread_mutex_t *mutex);  // 加锁, 传入锁对象的指针int pthread_mutex_unlock(pthread_mutex_t *mutex);\r\n-\r\npthread_mutex_lock：尝试获取锁。如果锁已经被其他线程持有，调用线程将阻塞，直到锁可用。\r\n- pthread_mutex_unlock：释放锁。只有持有锁的线程才能调用此函数。 -\r\n返回值：成功返回0，失败返回错误码。\r\n注意, pthread_mutex_t是一个复杂的数据结构，必须在使用前初始化.\r\n可以使用以下两种方式初始化互斥锁: 1. 静态初始化: 用于全局或静态锁\r\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; 2. 动态初始化: 用于堆上或栈上的锁 pthread_mutex_t mutex;pthread_mutex_init(&amp;mutex, nullptr); // 第二个参数为锁属性，通常传入 nullptr 表示默认属性 例如,\r\n使用互斥锁保护临界区: #include &lt;pthread.h&gt;#include &lt;iostream&gt;pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // 静态初始化互斥锁int sharedResource = 0; // 共享资源void* threadFunc(void* arg) {    pthread_mutex_lock(&amp;mutex); // 加锁    // 临界区开始    sharedResource++;    std::cout &lt;&lt; \"Shared Resource: \" &lt;&lt; sharedResource &lt;&lt; std::endl;    // 临界区结束    pthread_mutex_unlock(&amp;mutex); // 解锁    return nullptr;}\r\n协作原语：条件变量\r\n这组API用于解决等待/通知（协作）问题。\r\n功能：允许一个线程睡眠（wait），直到某个“条件”为真，而另一个线程在使该“条件”为真后，通知（signal）睡眠的线程醒来。\r\nint pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);  // 等待条件变量, 传入条件变量和互斥锁的指针int pthread_cond_signal(pthread_cond_t *cond); - pthread_cond_wait(&amp;cond, &amp;lock)\r\n这一行代码会原子地执行以下三步： -\r\n释放传入的锁（&amp;lock）。（这允许“通知者”线程能有机会进入临界区去修改ready）\r\n- 使当前线程睡眠（等待&amp;cond上的信号）。 -\r\n（…当被唤醒后…）重新获取那个锁（&amp;lock），然后才从wait函数返回。 这里\r\nwait 和 signal 的标准模式是:\r\n条件变量必须和一个互斥锁（Mutex）配对使用，以保护“条件”本身（例如一个\r\nready 标志） 等待者（Waiter）的代码：pthread_mutex_lock(&amp;lock);while (ready == 0) { // 必须是 while, 以防虚假唤醒    pthread_cond_wait(&amp;cond, &amp;lock);}// ... 此刻, ready 必然为 1, 且我们持有锁 ...pthread_mutex_unlock(&amp;lock); 通知者（Signaler）的代码：pthread_mutex_lock(&amp;lock);ready = 1; // 改变条件pthread_cond_signal(&amp;cond); // 唤醒一个等待者pthread_mutex_unlock(&amp;lock);\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"内存分区","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%8E%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%88%86%E5%8C%BA/","content":"程序的内存布局 (Process\r\nMemory Layout)\r\n一个程序运行起来后，操作系统会为其分配一块虚拟内存空间。这块空间在逻辑上通常分为以下几个部分：\r\n\r\n栈 (Stack)：\r\n\r\n用途：用于存储函数的局部变量（也叫临时变量）、函数参数、返回地址等。\r\n特点：由编译器自动分配和释放。内存区域通常较小，且向下增长（即从高地址向低地址扩展）。每个线程都有自己独立的栈。\r\n\r\n堆 (Heap)：\r\n\r\n用途：用于程序运行时动态分配的内存，例如通过 new (C++) 或 malloc\r\n(C) 创建的对象。\r\n特点：由程序员手动分配和释放（delete/free）。空间较大，向上增长。\r\n\r\n静态/全局存储区 (Static/Global Storage\r\nArea)：\r\n\r\n这块区域用于存储全局变量和静态变量，生命周期与整个程序相同。它内部又细分为两个子区域：\r\n\r\n.data 段 (Initialized Data\r\nSegment)：存储已初始化且初始值不为0的全局变量和静态变量。\r\n.bss 段 (Uninitialized Data\r\nSegment)：存储未初始化或初始化为0的全局变量和静态变量。\r\n\r\n\r\n这部分内存在程序加载到内存时就已经分配好了，并且在程序的整个生命周期内都不会改变位置。因此，无论你何时访问一个全局变量，它的内存地址都是同一个。\r\n\r\n常量存储区 (Constant Storage Area /\r\n.rodata)：\r\n\r\n用途：存储字符串字面量和被 const\r\n修饰的常量。\r\n特点：只读（Read-Only）。\r\n\r\n代码段 (Code Segment / .text)：\r\n\r\n用途：存储程序的可执行二进制指令。\r\n特点：只读且可共享。\r\n\r\n\r\n变量在内存中的分布\r\n全局/静态变量 vs. 临时变量:\r\n全局变量和静态变量的内存地址是固定的，但临时变量的内存地址，往往不是固定的。”\r\n为什么全局/静态变量地址固定: 因为它们被存储在静态/全局存储区（.data\r\n或 .bss\r\n段）。这部分内存在程序加载到内存时就已经分配好了，并且在程序的整个生命周期内都不会改变位置。因此，无论你何时访问一个全局变量，它的内存地址都是同一个。\r\n为什么临时变量（局部变量）地址不固定: 因为它们被存储在栈\r\n(Stack)上。当一个函数被调用时，系统会在栈顶为这个函数创建一个“栈帧”（Stack\r\nFrame），用来存放它的局部变量。当函数执行完毕返回时，这个栈帧就会被销毁。\r\n如果你在一个循环中多次调用同一个函数，那么每次调用时，该函数内的局部变量都会在一个新的栈帧中被创建，其内存地址也因此会不一样。如果函数发生递归调用，同样会创建多个栈帧，局部变量的地址也各不相同。\r\n静态变量与全局变量的相似性和差异性:\r\n静态变量，除了作用域跟全局变量有所差异外，其存储原则、生命周期跟全局变量类似。”\r\n\r\n相似点：存储原则和生命周期\r\n\r\n存储位置：它们都存储在静态/全局存储区（.data 或 .bss）。\r\n生命周期：它们的生命周期都是整个程序的运行期间。从程序开始执行时被创建，到程序结束时才被销毁。即使是定义在函数内部的静态局部变量（static\r\nlocal\r\nvariable），它也只会被初始化一次，并且在函数调用结束后其值会一直保留，不会被销毁。\r\n\r\n差异点：作用域 (Scope)\r\n\r\n全局变量 (Global\r\nVariable)：作用域是整个程序，可以被多个源文件通过 extern\r\n关键字访问（除非被 static 修饰成文件作用域）。\r\n静态变量 (Static Variable)：\r\n\r\n静态全局变量（在函数外定义）：作用域被限制在定义它的单个源文件内，其他文件无法访问。\r\n静态局部变量（在函数内定义）：作用域被限制在定义它的函数或代码块内，但其生命周期依然是整个程序。\r\n\r\n\r\n\r\n未初始化/零初始化变量与 .bss 段:\r\n无论是全局变量还是静态变量，如果它们没有被初始化，或者被初始化为\r\n0，都会被安置在未初始化数据段(.bss)，一定程度上可以节省二进制文件\r\na.out 的存储空间。\r\n这是一个非常巧妙的编译器和加载器优化。对于 .data 段中的变量（例如 int\r\nglobal_var = 100;），值 100\r\n必须被实际地保存在可执行文件（如\r\na.out）中，因为它是一个非零的特定值。这会占用文件的体积。\r\n但对于 .bss\r\n段，可执行文件只需要记录这个段的总大小，而不需要存储所有这些0。当操作系统加载程序时，它会读取\r\n.bss\r\n段的大小，然后在内存中分配相应大小的区域，并自动将其全部填充为零。\r\n因此，一个拥有大量未初始化或零初始化全局/静态变量的程序，其可执行文件的大小可以显著减小，因为这些“零”并没有被实际存储在文件中，而是由加载器在运行时“创造”出来的。\r\n"},{"title":"条件变量和多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/5.%20%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB/","content":"条件变量 (Condition Variable)\r\n是一种同步原语，它允许一个或多个线程等待（阻塞），直到另一个线程修改了某个共享状态并通知它们。\r\n它的核心思想不是为了“锁住”资源，而是提供一种“等待-通知”\r\n(Wait-Notify) 机制。线程可以高效地等待某个特定条件 (Condition)\r\n变为真，而无需通过循环不断地检查（这种低效的方式称为忙等待\r\n(Busy-Waiting)）。\r\n为了安全地检查和修改这个共享状态，条件变量必须与一个互斥锁 (Mutex)\r\n协同工作。\r\n一个典型的条件变量工作流程包含以下三个核心部分：\r\n\r\n互斥锁\r\n(std::mutex)：用于保护被检查的共享数据（即“条件”）。\r\n共享数据/条件：一个或多个线程需要等待其状态发生改变的变量。例如，一个表示任务队列是否为空的布尔值或整数。\r\n条件变量\r\n(std::condition_variable)：负责阻塞等待线程和唤醒它们。\r\n\r\n其主要操作有两个：\r\n\r\nwait(lock):\r\n等待操作。调用该函数的线程会执行以下原子操作：\r\n\r\n释放传入的 lock（互斥锁）。\r\n阻塞当前线程，使其进入等待状态。\r\n当被其他线程通过 notify 唤醒时，它会重新获取 lock，然后 wait\r\n函数才会返回。\r\n\r\nnotify_one() / notify_all():\r\n通知操作。\r\n\r\nnotify_one():\r\n唤醒一个正在等待的线程。具体唤醒哪一个是不确定的。\r\nnotify_all(): 唤醒所有正在等待的线程。\r\n\r\n\r\n生产者-消费者模型\r\n这是并发编程中最经典的模型之一，用于解耦生产者（创建数据或任务的线程）和消费者（处理数据或任务的线程）。\r\n- 生产者 (Producer)：负责生成数据并将其放入一个共享的缓冲区（如队列）。\r\n- 消费者 (Consumer)：负责从缓冲区中取出数据并进行处理。 - 共享缓冲区\r\n(Shared Buffer)：连接生产者和消费者的中间数据结构。\r\n这个模型需要解决以下两个核心同步问题： -\r\n缓冲区为空时：消费者不能进行消费，必须等待，直到生产者放入了新的数据。 -\r\n缓冲区为满时：生产者不能继续生产，必须等待，直到消费者取走了数据，为新数据腾出空间。\r\n-\r\n互斥访问：任何时刻，只能有一个线程（无论是生产者还是消费者）在访问缓冲区，以避免数据损坏。\r\n互斥锁可以解决第3个问题，而条件变量则完美地解决了第1和第2个问题。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;template&lt;typename T&gt;class BlockingQueue {public:    // 构造函数，指定队列容量    explicit BlockingQueue(size_t capacity) : capacity_(capacity) {}    // 生产者调用：向队列中放入一个元素    void produce(const T&amp; item) {        std::unique_lock&lt;std::mutex&gt; lock(mtx_); // std::unique_lock 是一个 RAII 风格的锁管理器，它在构造时自动加锁，在析构时（即离开作用域时）自动解锁，非常安全        // 等待直到队列不满        // 使用 Lambda 谓词，自动处理虚假唤醒        cond_producer_.wait(lock, [this] {            return buffer_.size() &lt; capacity_;        });        // 将元素放入缓冲区        buffer_.push(item);        std::cout &lt;&lt; \"生产者 \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" 生产了 \" &lt;&lt; item &lt;&lt; \", 队列大小: \" &lt;&lt; buffer_.size() &lt;&lt; std::endl;        // 通知一个等待的消费者        cond_consumer_.notify_one();    }    // 消费者调用：从队列中取出一个元素    T consume() {        std::unique_lock&lt;std::mutex&gt; lock(mtx_);        // 等待直到队列不空, 等待时会释放 lock 锁, 让其他线程有机会修改共享状态        cond_consumer_.wait(lock, [this] {            return !buffer_.empty();        });        // 从缓冲区取出元素        T item = buffer_.front();        buffer_.pop();        std::cout &lt;&lt; \"消费者 \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" 消费了 \" &lt;&lt; item &lt;&lt; \", 队列大小: \" &lt;&lt; buffer_.size() &lt;&lt; std::endl;        // 通知一个等待的生产者        cond_producer_.notify_one();        return item;    }private:    size_t capacity_;    std::queue&lt;T&gt; buffer_;        // 底层使用 std::queue 存储数据（共享资源）    std::mutex mtx_;              // 互斥锁，用于保护对 buffer_ 的访问    std::condition_variable cond_producer_; // 用于生产者等待的条件变量    std::condition_variable cond_consumer_; // 用于消费者等待的条件变量};int main() {    // 创建一个容量为 5 的阻塞队列    BlockingQueue&lt;int&gt; bq(5);    // 创建两个生产者线程    std::thread producer1([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.produce(i);            std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 模拟生产耗时        }    });    std::thread producer2([&amp;]() {        for (int i = 10; i &lt; 20; ++i) {            bq.produce(i);            std::this_thread::sleep_for(std::chrono::milliseconds(150));        }    });    // 创建两个消费者线程    std::thread consumer1([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.consume();            std::this_thread::sleep_for(std::chrono::milliseconds(200)); // 模拟消费耗时        }    });    std::thread consumer2([&amp;]() {        for (int i = 0; i &lt; 10; ++i) {            bq.consume();            std::this_thread::sleep_for(std::chrono::milliseconds(250));        }    });    // 等待所有线程结束    producer1.join();    producer2.join();    consumer1.join();    consumer2.join();    return 0;}\r\n上述示例的cond_producer_.wait(lock, ...)是生产者的核心等待逻辑。wait\r\n函数会检查传入的 Lambda 表达式 [this] { return buffer_.size() &lt;\r\ncapacity_; }。如果条件为真 (队列不满)：wait\r\n函数立即返回，线程继续向下执行; 如果条件为假\r\n(队列已满)：线程会原子地释放 lock, 进入阻塞/等待状态，等待被 notify\r\n唤醒。\r\nnotify_one()\r\n的核心作用是唤醒一个正在等待的线程。它就像一个信号，告诉等待中的线程：“你等待的条件可能已经满足了，快醒来检查一下吧！”.\r\n唤醒的线程会重新获取 lock\r\n锁，然后检查条件是否满足。如果条件满足，线程会继续执行；如果条件不满足，线程会再次进入等待状态。\r\n例如, 如果没有\r\ncond_consumer_.notify_one()，那些因队列为空而睡眠的消费者线程将永远不会知道有新数据到来，它们会一直“睡”下去，导致程序死锁。\r\n虚假唤醒\r\n虚假唤醒指的是，一个正在条件变量上等待 (cv.wait())\r\n的线程，在没有任何其他线程调用 notify_one() 或 notify_all()\r\n的情况下，被意外地唤醒。\r\n换句话说，线程“无缘无故”地从等待状态中醒来，但它所等待的那个条件\r\n(Condition) 实际上仍然不满足。\r\n这是一个真实存在且需要正确处理的并发问题。POSIX 标准和 C++\r\n标准都明确允许这种情况发生，因此程序员必须在代码中防范它。这种情况出现的原因通常与操作系统内核的线程调度实现有关(例如系统中断：等待中的线程可能会被一些不相关的系统事件（如\r\nPOSIX 信号）中断，导致其从内核的等待队列中被唤醒。)\r\n处理虚假唤醒的“黄金法则”是：永远在循环中调用\r\nwait()。下面的一种错误情况是: // 线程可能会在虚假唤醒后错误地继续执行std::unique_lock&lt;std::mutex&gt; lock(mtx);if (buffer_.empty()) {   // 一开始检查过是空, 进入函数体, 等待被 notify 唤醒    cond_consumer_.wait(lock); // 如果在这里被虚假唤醒，if 语句已执行过，不会再次检查, 但是如果是虚假唤醒, 完全有可能还是空}// 危险！程序可能在这里尝试从空队列中取数据T item = buffer_.front();buffer_.pop(); 正确的做法是使用 while\r\n循环来包裹 wait, 确保在被 notify 唤醒后, 条件再次被检查: std::unique_lock&lt;std::mutex&gt; lock(mtx);// 使用 while 循环来包裹 waitwhile (buffer_.empty()) {    cond_consumer_.wait(lock);}// 安全！从 wait 返回后，循环条件会再次被检查。// 只有当 buffer_.empty() 为 false 时，循环才会退出。T item = buffer_.front();buffer_.pop();\r\n更推荐的做法是使用 wait 的谓词版本: C++\r\n标准库为我们提供了更优雅的解决方案, wait\r\n函数有一个重载版本，可以接受一个谓词 (Predicate)，通常是一个 Lambda\r\n表达式。 std::unique_lock&lt;std::mutex&gt; lock(mtx);// 这个 wait 内部已经为我们实现好了 while 循环// 它只会在 lambda 表达式返回 true 时才会返回cond_consumer_.wait(lock, [this] {     return !buffer_.empty(); });// 绝对安全！T item = buffer_.front();buffer_.pop(); 这个版本在功能上等价于 while\r\n循环，但代码更简洁，意图更清晰，并且能有效避免程序员忘记写循环。\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"std::call_once 解决多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/4.%20std%20call_once/","content":"在多线程环境中，我们经常会遇到一个需求：确保某段代码（通常是初始化代码）在整个程序的生命周期中，无论有多少个线程并发调用它，都只被执行一次。一个经典的例子就是线程安全的懒汉式单例模式\r\n(Lazy-Initialized Singleton)。 #include &lt;iostream&gt;class Singleton {public:    static Singleton* getInstance() {        if (instance == nullptr) { // &lt;-- 竞争条件点 1            instance = new Singleton(); // &lt;-- 竞争条件点 2        }        return instance;    }private:    Singleton() { std::cout &lt;&lt; \"Singleton constructed.\\n\"; }    static Singleton* instance;};Singleton* Singleton::instance = nullptr;\r\n这段代码看起来似乎可以实现线程安全的懒汉式单例模式，但是在多线程环境下，它会立即崩溃。这段代码在多线程环境下会立即崩溃,\r\n其原因是： 1. 假设线程 A 和线程 B 同时调用了 getInstance()\r\n方法，且 instance 为 nullptr。 2. 线程 A\r\n先进入 if 语句，发现 instance 为\r\nnullptr，于是它开始创建 Singleton 的实例。 3.\r\n线程 B 也进入 if 语句，发现 instance 为\r\nnullptr，于是它也开始创建 Singleton 的实例。\r\n4. 由于线程 A 和线程 B 都在创建 Singleton\r\n的实例，所以就会发生竞态条件，导致 instance 被创建了两次。\r\n5. 当线程 A 或线程 B 尝试访问 instance\r\n时，就会发生访问冲突，导致程序崩溃。\r\n最终的结果是单例模式被破坏（创建了多个实例），并且造成了内存泄漏（第一个实例的指针被覆盖丢失）。\r\n虽然可以使用 std::mutex\r\n来解决这个问题（这种模式被称为“双重检查锁定”，Double-Checked\r\nLocking），但手动实现起来复杂且容易出错。为了以一种更简单、更高效、更安全的方式解决这类问题，C++11\r\n提供了 std::call_once。\r\nstd::call_once\r\nstd::call_once 是一个函数模板，它配合一个 std::once_flag\r\n对象，能够保证一个函数或可调用对象在多线程环境下只被成功调用一次。其核心部分如下：\r\n\r\nstd::once_flag:这是一个特殊的标记对象,\r\n你可以把它想象成一个一次性的门锁或一次性的门票。它用于 std::call_once\r\n来同步各个线程，并记录目标函数是否已经被调用过。std::once_flag\r\n对象不可复制，也不可移动，通常被定义为\r\nstatic、全局或类的成员变量，以便在多个线程调用点之间共享。\r\n**std::call_once(std::once_flag&amp; flag, Callable&amp;&amp; f,\r\nArgs&amp;&amp;… args):这是执行调用的函数。\r\n\r\nflag：上面定义的 once_flag 对象的引用。\r\nf：你希望只被执行一次的可调用对象（如函数指针、Lambda表达式、函数对象等）。\r\nargs…：传递给可调用对象 f 的参数。\r\n\r\n\r\n另外注意的是, std::call_once 和 std::once_flag 都定义在头文件 \r\n中。\r\n使用 std::call_once 解决懒汉式单例模式的代码如下: #include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt; // 需要包含 &lt;mutex&gt; 头文件#include &lt;vector&gt;class Singleton {public:    static Singleton* getInstance() {        // 所有线程都会尝试调用，但只有第一个线程能执行 Lambda 表达式        std::call_once(flag, []() {            instance = new Singleton();        });        return instance;    }private:    Singleton() { std::cout &lt;&lt; \"Singleton constructed.\\n\"; }        // 必须是 static，以便在所有调用中共享    static Singleton* instance;    static std::once_flag flag; };// 静态成员变量的定义Singleton* Singleton::instance = nullptr;std::once_flag Singleton::flag;// --- 测试代码 ---void create_instance() {    Singleton* s = Singleton::getInstance();    std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" got instance at \" &lt;&lt; s &lt;&lt; std::endl;}int main() {    std::vector&lt;std::thread&gt; threads;    for (int i = 0; i &lt; 10; ++i) {        threads.emplace_back(create_instance);    }    for (auto&amp; th : threads) {        th.join();    }    // 尽管有10个线程调用，\"Singleton constructed.\" 也只会被打印一次    return 0;}\r\n当第一个调用 getInstance() 的线程到达 std::call_once时, 它发现 flag\r\n尚未被“标记”。因此这个线程会独占性地执行传入的 Lambda 表达式（即\r\ninstance = new Singleton();）。\r\n在此期间，如果其他线程也调用了 getInstance() 并到达\r\nstd::call_once，它们会阻塞等待，直到第一个线程的 Lambda\r\n表达式执行完毕。\r\n当第一个线程成功执行完 Lambda 后，std::call_once 会将 flag\r\n永久地标记为“已完成”。所有之前阻塞等待的线程会被唤醒，并从\r\nstd::call_once 返回。它们不会再次执行 Lambda。\r\n此后任何线程再调用 std::call_once 并传入同一个 flag 对象，都会发现\r\nflag 已被标记，于是会立即返回，不做任何事。\r\n它的优势是线程安全：由标准库保证其实现的线程安全性，无需手动加锁;\r\n高效：相比于每次调用都加锁的互斥量方案，std::call_once\r\n在初始化完成后，后续的调用开销极低（通常只是一次无锁的内存读取）,\r\n且代码简洁，意图明确：清晰地表达了“此代码只执行一次”的意图。\r\n主要应用于上述提到的线程安全的懒汉式单例模式和一次性全局初始化(程序中某些模块或资源只需要被初始化一次。例如首次使用时才加载配置文件,\r\n首次需要时才初始化日志系统,\r\n首次访问时才建立一个全局的数据库连接池等)\r\n\r\n下面也提到了, 单例模式的实现可以通过 Magic statics来实现,\r\n但是如果你有更通用的、不局限于静态变量初始化的“执行一次”的需求，std::call_once\r\n依然是那个最合适的、强大的工具。\r\n\r\n单例模式（Singleton Pattern）\r\n单例模式（Singleton\r\nPattern）是一种在软件设计中被广泛使用的创建型设计模式,\r\n核心思想是确保一个类在任何情况下只有一个实例，并为该实例提供一个全局唯一的访问点。\r\n想象一下，系统中有一些组件是“全局唯一”的，比如： -\r\n配置管理器：整个应用程序共享同一份配置信息。 -\r\n日志记录器：所有模块都应该将日志写入同一个日志文件。 -\r\n数据库连接池：管理一组数据库连接，避免频繁创建和销毁连接的开销。 -\r\n线程池：统一管理和调度一组工作线程。\r\n在这些场景下，如果创建多个实例，可能会导致程序行为异常（如配置不一致）、资源过度使用（如过多的数据库连接）或结果不可预测。单例模式正是为了解决这类问题而生的。\r\n单例模式的实现要点\r\n要实现一个标准的单例模式，通常需要满足以下几个关键条件：\r\n私有化构造函数 (Private Constructor): -\r\n为了防止外部代码通过 new\r\n关键字随意创建类的实例。这是保证类实例唯一性的基础。 - 如果构造函数是\r\npublic\r\n的，那么任何地方都可以自由地创建该类的对象，就无法实现“单例”的目标。\r\n私有静态实例变量 (Private Static Instance) -\r\n在类的内部持有那个唯一的实例。 - 使用 static\r\n关键字可以确保这个实例变量属于类本身，而不是类的某个对象，因此它在内存中只有一份。将其设为\r\nprivate 是为了防止外部直接访问和修改它。\r\n公有静态访问方法 (Public Static Access Method) -\r\n提供一个全局唯一的、可供外部访问该实例的入口。这个方法通常被命名为\r\ngetInstance() 或类似名称。 -\r\n这是外部世界获取单例实例的唯一途径。该方法会检查实例是否已经被创建：如果尚未创建，则创建它；如果已经存在，则直接返回。\r\n单例模式主要有两种经典的实现方式：饿汉式（Eager Initialization） 和\r\n懒汉式（Lazy Initialization）。\r\n饿汉式（Eager Initialization）\r\n饿汉式在类加载的时候就立即创建实例，因此它是线程安全的。\r\n优点是实现简单;\r\n且在类加载时就完成了实例化，避免了多线程同步问题，是天然线程安全的。\r\n缺点是如果这个实例从未使用过，会造成内存浪费。因为它不是在需要时才创建，而是一开始就创建了。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;// 饿汉式单例class SingletonEager {public:    // 提供全局访问点, 返回单例对象的指针    static SingletonEager* getInstance() {        return instance;    }    // 禁止外部复制或赋值    SingletonEager(const SingletonEager&amp;) = delete;    SingletonEager&amp; operator=(const SingletonEager&amp;) = delete;    void showMessage() const {        std::cout &lt;&lt; \"Eager Singleton instance address: \" &lt;&lt; this &lt;&lt; std::endl;    }private:    // 1. 私有化构造函数    SingletonEager() {        std::cout &lt;&lt; \"Eager Singleton instance created.\" &lt;&lt; std::endl;    }    // 2. 静态成员变量声明    static SingletonEager* instance;    // 可以在内部定义一个垃圾回收类来自动释放内存    class GarbageCollector {    public:        ~GarbageCollector() {            if (SingletonEager::instance != nullptr) {                std::cout &lt;&lt; \"Eager Singleton instance destroyed.\" &lt;&lt; std::endl;                delete SingletonEager::instance;                SingletonEager::instance = nullptr;            }        }    };    // 静态成员，程序结束时会自动调用其析构函数    // 这是一个巧妙的技巧，用于自动释放 new 出来的单例内存。gc 是一个静态成员对象，它的生命周期是整个程序。当程序结束时，gc 对象会被销毁，此时它的析构函数 ~GarbageCollector() 会被自动调用，从而 delete 掉我们创建的 instance，避免了内存泄漏。    static GarbageCollector gc;};// 3. 在类外初始化静态成员变量，这是饿汉式的关键// 这行代码会在 main 函数执行前被调用, 创建实例, 并将其地址赋给 instance 指针。无论 getInstance() 被调用多少次，都返回这个早已创建好的实例。 SingletonEager* SingletonEager::instance = new SingletonEager();SingletonEager::GarbageCollector SingletonEager::gc;\r\n懒汉式单例\r\n懒汉式在第一次被调用 getInstance()\r\n方法时才创建实例。这种方式延迟了对象的创建时间。\r\n优点是实现了延迟加载（Lazy\r\nLoading），只有在实际需要时才创建实例，节约了资源。\r\n缺点是在多线程环境下，如果不进行同步处理，可能会创建出多个实例，从而破坏单例模式。因此，必须处理线程安全问题。\r\n我们当然可以像上述代码一样使用std::call_once来实现单例模式, 然而在\r\nC++11 及以后，最推荐的懒汉式实现是使用静态局部变量（Meyers’\r\nSingleton），因为它既简洁又线程安全,\r\n并且避免了手动管理裸指针。编译器和标准库在底层为你实现了与\r\nstd::call_once 类似的安全保障。 &gt; #include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;// 懒汉式单例 (C++11 推荐的 Meyers' Singleton 写法)class SingletonLazy {public:    static SingletonLazy&amp; getInstance() {        // C++11 标准保证，静态局部变量的初始化是线程安全的，并且只会发生一次        static SingletonLazy instance;        return instance;    }    // 禁止外部复制或赋值    SingletonLazy(const SingletonLazy&amp;) = delete;    SingletonLazy&amp; operator=(const SingletonLazy&amp;) = delete;    void showMessage() const {        std::cout &lt;&lt; \"Lazy Singleton (Meyers') instance address: \" &lt;&lt; this &lt;&lt; std::endl;    }private:    // 1. 私有化构造函数    SingletonLazy() {        std::cout &lt;&lt; \"Lazy Singleton instance created.\" &lt;&lt; std::endl;    }    // 2. 析构函数    ~SingletonLazy() {        std::cout &lt;&lt; \"Lazy Singleton instance destroyed.\" &lt;&lt; std::endl;    }}; - static\r\nSingletonLazy instance;：这是懒汉式实现的核心。instance 位于\r\ngetInstance() 函数内部，是一个静态局部变量。只有当 getInstance()\r\n函数第一次被调用时，instance\r\n才会在这里被初始化。如果函数从未被调用，实例就永远不会被创建。\r\n\r\n线程安全：C++11\r\n标准明确规定，这种静态局部变量的初始化过程必须是原子性的，即线程安全的。编译器和运行时库会处理好多线程同时首次调用\r\ngetInstance() 的同步问题。\r\n自动内存管理：instance\r\n的生命周期与程序相同，程序结束时它会自动被销毁，无需像饿汉式那样手动管理内存。\r\n\r\n显然,\r\n如果实例的创建成本不高，且在程序启动后肯定会被用到，饿汉式是更简单、更可靠的选择;\r\n如果实例的创建非常耗时或占用大量资源，并且不确定是否会用到它，懒汉式（特别是双重检查锁定版本）是更好的选择。\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"线程池","url":"/2025/09/23/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/6.%20%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"线程池 (Thread Pool)\r\n是一种并发设计模式，它预先创建并维护一组可复用的工作线程，而不是在需要时才创建新线程。这些线程“池化”在一起，等待执行分配给它们的任务。\r\n它的核心思想是将“任务的提交”与“任务的执行”解耦。应用程序的各个部分可以将任务提交给线程池，而无需关心任务具体由哪个线程执行、何时执行。\r\n一个典型的线程池包含以下几个关键部分： - 任务队列\r\n(std::queue)：一个用于存放待执行任务的缓冲区 -\r\n它必须是线程安全的。这通常通过一个互斥锁\r\n(std::mutex) 和一个条件变量 (std::condition_variable)\r\n来实现, 这正是我们之前讨论的生产者-消费者模型的完美应用. -\r\n任务提交者是生产者，将任务放入队列。 -\r\n工作线程是消费者，从队列中取出任务执行。 - 任务类型\r\n(TaskType)：为了让线程池能执行任意类型的任务，通常使用\r\nstd::function&lt;void()&gt;\r\n来包装任务。这使得线程池可以接受普通函数、Lambda\r\n表达式、成员函数等任何可调用对象。 - 工作线程\r\n(std::vector)：一组预先创建的、可以循环执行任务的线程。 -\r\n线程池管理器\r\n(ThreadPool)：一个类，用于封装整个线程池的逻辑,\r\n负责创建、管理和销毁线程池本身，并向任务队列中添加新任务。\r\n为什么要使用线程池\r\n为了理解线程池的价值，我们首先要看看不使用线程池的原始做法有什么问题。原始做法是：“需要时创建，用完后销毁”。\r\nvoid some_task() { /* ... */ }// 每当有一个新任务，就创建一个新线程std::thread t(some_task);t.join(); // 或者 t.detach(); 这种做法存在两个致命的缺陷：\r\n\r\n高昂的资源开销：\r\n\r\n创建开销：线程的创建和销毁是重量级操作，需要调用操作系统内核\r\nAPI，分配和回收线程栈等内存资源，这个过程相对耗时。\r\n上下文切换开销：如果任务数量巨大，短时间内创建大量线程，会导致 CPU\r\n在这些线程之间频繁进行上下文切换，这会消耗大量 CPU\r\n时间，反而降低了程序的整体性能。\r\n\r\n资源耗尽风险：操作系统能够创建的线程数量是有限的。如果不加限制地为每个任务都创建一个线程，当并发请求量激增时，很容易耗尽系统内存和线程资源，最终导致程序崩溃或系统瘫痪。\r\n\r\n线程池正是为了解决以上两个问题而生的。\r\n工作流程\r\n\r\n初始化：\r\n\r\n创建一个线程池对象，并指定线程数量（例如，CPU 核心数）。\r\n线程池立即创建指定数量的工作线程。\r\n每个工作线程都启动并进入一个无限循环，尝试从任务队列中获取任务。\r\n\r\n等待任务：由于任务队列初始为空，所有工作线程都会在条件变量上\r\nwait()，进入阻塞状态，等待新任务的到来。它们不消耗 CPU 时间。\r\n提交任务：外部代码（例如 main 函数）调用线程池的 enqueue()\r\n方法，传入一个任务。\r\n\r\nenqueue() 方法会获取任务队列的锁，将任务 push\r\n进队列，然后释放锁。\r\n之后，它调用条件变量的\r\nnotify_one()，唤醒一个正在等待的工作线程。\r\n\r\n执行任务：\r\n\r\n被唤醒的线程从 wait() 返回，重新获取锁，从队列中 pop\r\n一个任务，然后释放锁。\r\n线程开始执行取出的任务。任务执行完毕后，线程不会退出，而是返回到无限循环的开始，再次尝试从任务队列获取下一个任务，如果队列为空，则再次进入等待状态。\r\n\r\n销毁：\r\n\r\n当程序希望关闭线程池时，会调用 shutdown() 方法(或者析构函数)。\r\n管理器设置一个停止标志位，并调用 notify_all()\r\n唤醒所有工作线程。\r\n工作线程被唤醒后，检查到停止标志，于是退出无限循环。\r\n管理器 join() 所有工作线程，等待它们全部安全退出。\r\n\r\n\r\n线程池示例\r\n#include&lt;iostream&gt;#include&lt;thread&gt;#include&lt;mutex&gt;#include&lt;queue&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;condition_variable&gt;#include&lt;functional&gt;class ThreadPool{public:    ThreadPool(int NumThreads): stop(false){  // 初始化并启动线程池。        for(int i=0;i&lt;NumThreads;i++){            // 这里构造的是多个线程, 因此是并发构造的            threads.emplace_back([this]{  // emplace_back 直接传入参数后自动构造线程对象(就地构造)                while(1){  // while的作用是持续监听任务队列, 让每个工作线程在完成一个任务后，不会立即退出，而是返回到循环的起点，继续尝试从任务队列中获取下一个任务。                    std::unique_lock&lt;std::mutex&gt; lock(mtx); // 有可能要操作任务队列, 所以要加锁                    condition.wait(lock, [this]{                        return !tasks.empty() || stop; // 线程会在此处等待，直到 Lambda 谓词返回 true。在等待期间，lock 会被自动释放，允许其他线程（如 enqueue 函数）获取锁并向队列中添加任务。                    });                    // 线程被唤醒后向下执行                    if(stop&amp;&amp;tasks.empty()) return;                    std::function&lt;void()&gt; task(std::move(tasks.front()));  // 从任务队列中取出一个任务                    tasks.pop();                    lock.unlock(); // 执行任务之前手动解锁。因为任务 task() 的执行可能非常耗时，如果在执行期间一直持有着锁，其他工作线程将无法从队列中获取新任务，会大大降低线程池的并发效率。                    task(); // 执行任务                }            });        }    }    ~ThreadPool(){  // 安全地关闭线程池，确保所有任务执行完毕，所有线程都已退出。        {            std::unique_lock&lt;std::mutex&gt; lock(mtx);            stop = true;        }        condition.notify_all(); // 唤醒所有正在等待的线程。因为有些线程可能因为队列为空而处于睡眠状态，设置 stop 标志后，必须将它们全部唤醒，以便它们能够检查到 stop == true 并进入退出流程。        for(auto&amp; t: threads) t.join();  //遍历所有线程句柄，并对每个线程调用 join()。主线程（执行析构函数的线程）会在此处阻塞，一个一个串行等待, 直到所有工作线程都执行完毕并完全退出。    }    template&lt;class F, class... Args&gt;  // 模板函数使之可以接受任意类型的任务函数和参数    void enqueue(F&amp;&amp; f, Args&amp;&amp; ... args){  // 向线程池提交一个新任务。        // 队列只接受std::function&lt;void()&gt;, 因此使用bind()将所有不同形式的函数调用全部“适配”成了 std::function&lt;void()&gt; 这种统一的、可以被存储在队列中的格式. 当你调用这个新对象时，它会在内部自动用之前绑定的参数去调用原始的函数。        std::function&lt;void()&gt; task = std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);        {            std::unique_lock&lt;std::mutex&gt; lock(mtx); // 加锁, 确保在添加任务到队列时不会被其他线程同时修改            tasks.emplace(std::move(task)); // 将新创建的 task 移动到任务队列 tasks 的末尾。        }        condition.notify_one();  // 通知一个正在 condition.wait() 上等待的工作线程。告诉它“有新任务来了，快醒来工作”。    }private:    std::vector&lt;std::thread&gt; threads;  // 线程容器。存放所有预先创建的工作线程对象。    std::queue&lt;std::function&lt;void()&gt;&gt; tasks; // 任务队列。这是一个线程安全的队列，用于存放待执行的任务。外部代码（生产者）将任务放入此队列，工作线程（消费者）从此队列取出任务。    std::mutex mtx;  // 互斥锁。用于保护对任务队列 tasks 的并发访问，确保线程安全。    std::condition_variable condition;  // 条件变量。用于实现线程间的同步。当任务队列为空时，工作线程在此变量上等待；当新任务被添加时，通过此变量通知等待的线程。    bool stop;  // 停止标志。一个布尔标志，用于通知所有线程池准备关闭，以便它们能够安全退出。};int main(){    ThreadPool pool(4);    for(int i=0;i&lt;10;i++){        pool.enqueue([i]{            std::cout &lt;&lt; \"task :\" &lt;&lt; i &lt;&lt; \"is runing\" &lt;&lt; std::endl;            std::this_thread::sleep_for(std::chrono::seconds(1));            std::cout &lt;&lt; \"task :\" &lt;&lt; i &lt;&lt; \"is done\" &lt;&lt; std::endl;        });    }}\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"互斥量和原子操作解决多线程数据共享","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/3.%20%E4%BA%92%E6%96%A5%E9%87%8F%E5%92%8C%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E8%A7%A3%E5%86%B3%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB/","content":"在多个线程中共享数据时，需要注意线程安全问题。如果多个线程同时访问同一个变量，并且其中至少有一个线程对该变量进行了写操作，那么就会出现数据竞争问题。\r\n数据竞争可能会导致程序崩溃、产生未定义的结果，或者得到错误的结果。为了避免数据竞争问题，需要使用同步机制来确保多个线程之间对共享数据的访问是安全的。常见的同步机制包括互斥量、条件变量、原子操作等。\r\n互斥量\r\n问题的根源：竞争条件 (Race\r\nCondition)\r\n在介绍解决方案之前，我们必须清晰地理解问题所在。当多个线程同时访问和修改同一个共享数据时，就会产生竞争条件。\r\n我们来看一个最经典的例子：多个线程同时对一个全局计数器进行递增操作。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;int g_counter = 0; // 全局共享变量void increment() {    for (int i = 0; i &lt; 100000; ++i) {        g_counter++; // &lt;--- 问题的核心：临界区    }}int main() {    std::vector&lt;std::thread&gt; threads;    for (int i = 0; i &lt; 10; ++i) {        threads.push_back(std::thread(increment));    }    for (auto&amp; th : threads) {        th.join();    }    // 理论上，10个线程每个加10万次，结果应该是 1,000,000    // 但实际运行结果会是一个小于一百万的随机数    std::cout &lt;&lt; \"Final counter value: \" &lt;&lt; g_counter &lt;&lt; std::endl;         return 0;} 实际结果出错的原因在于, g_counter++\r\n这一行代码在底层并不是一个原子操作 (Atomic\r\nOperation)。它至少包含三个步骤： 1. 读取 (Read)：从内存中读取 g_counter\r\n的当前值到一个CPU寄存器。 2. 修改\r\n(Modify)：在CPU寄存器中将该值加 1。 3. 写入\r\n(Write)：将寄存器中的新值写回到内存中的 g_counter。\r\n想象一下两个线程同时执行的场景： - 线程A 读取 g_counter 的值（假设为\r\n100）到它的寄存器。 - 在线程A修改之前, 线程B 也读取 g_counter\r\n的值（此时内存中仍然是 100）到它的寄存器。 - 线程B 在自己的寄存器中加\r\n1（变为 101），并将其写回内存。现在 g_counter 的值是 101。 -\r\n由于线程运行的异步性, 此时线程A才对它自己的寄存器（值仍然是 100）加\r\n1，得到 101。 - 线程A 将 101 写回到内存。g_counter 的值仍然是 101。\r\n最终结果： 两个线程都执行了 ++ 操作，但计数器只增加了\r\n1。这就是数据竞争导致的最终结果不一致。这块访问共享资源的代码\r\ng_counter++，我们称之为临界区 (Critical\r\nSection)。我们的目标就是保护它。\r\n解决方案：互斥量 (std::mutex)\r\n互斥量，顾名思义，就是互斥访问 (Mutual\r\nExclusion)。它就像一把锁，用来保护一段代码（临界区）。其基本规则如下：\r\n\r\n一个线程想要进入临界区，必须先拿到互斥量(锁)。如果锁被其他线程占用，当前线程就会阻塞等待，直到锁被释放。\r\n如果锁可用，当前线程就会拿到锁，进入临界区执行操作。\r\n在此期间，如果其他线程也想进入，它们会发现锁被占用，只能在外面阻塞等待，直到锁被释放。\r\n第一个线程执行完临界区代码后，会释放锁 (unlock)，把锁放回原处。\r\n等待的线程中会有一个拿到锁，进入临界区执行操作。\r\n\r\n通过这种方式，我们保证了在任何时刻，只有一个线程能进入临界区。\r\n互斥量的基本使用\r\n首先需要引入头文件: #include &lt;mutex&gt;\r\n手动调用 lock() 和 unlock()\r\n这是最基本的使用方式，需要在临界区代码前后手动调用\r\nlock() 和 unlock() 方法。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;mutex&gt;int g_counter = 0;std::mutex g_mutex; // 创建一个全局互斥量void safe_increment() {    for (int i = 0; i &lt; 100000; ++i) {        g_mutex.lock();   // 在访问共享数据前加锁        g_counter++;        g_mutex.unlock(); // 在访问结束后解锁    }}// ... main 函数与之前相同，只是调用 safe_increment 但这种手动管理的方式有致命缺陷：如果在 lock() 和 unlock()\r\n之间发生异常，unlock()\r\n就永远不会被调用，导致互斥量被永久锁定，所有其他等待该锁的线程都会被无限期阻塞，这被称为死锁\r\n(Deadlock)。\r\nstd::lock_guard\r\n(推荐的现代方法)\r\n为了解决手动解锁的风险，C++ 标准库提供了\r\nstd::lock_guard，它完美地利用了 RAII (Resource Acquisition Is\r\nInitialization，资源获取即初始化) 的思想。\r\nstd::lock_guard 是一个类模板，它的工作方式是： -\r\n在构造时：它会自动接收一个 std::mutex\r\n对象，并在构造函数调用该对象的 lock() 方法。 -\r\n在析构时：当 lock_guard 对象离开其作用域时（例如，在代码块 {}\r\n的末尾），它的析构函数会自动被调用，并在析构函数中调用\r\nunlock() 方法。 -\r\nstd::lock_guard对象不能复制或移动，因此它只能在局部作用域中使用。 -\r\nstd::lock_guard\r\n的职责是在其生命周期内“拥有”一个互斥锁。如果它能被复制，那么我们就会有两个\r\nlock_guard\r\n对象都认为自己拥有同一个锁。当这两个对象离开作用域时，它们的析构函数都会尝试去调用\r\nunlock()。对一个已经解锁的互斥量再次解锁是未定义行为，会导致程序错误。因此，从逻辑上讲，复制\r\nlock_guard 是不安全的，所以 C++ 禁止了这种行为。 -\r\n“移动”一个对象意味着将资源的所有权从一个对象转移到另一个对象。如果\r\nstd::lock_guard\r\n可以被移动（例如，从一个函数返回），那么“解锁”这个行为的发生地点就不再是创建锁的那个原始、清晰的局部作用域了，而是转移到了一个不确定的新作用域。std::lock_guard\r\n的设计目标就是简单和绝对的安全。它的理念是：“锁在哪里创建，就必须在哪里被释放，绝不允许所有权转移”。禁止移动特性，就是为了强制执行这种简单、可预测、不会出错的模式。\r\n- 正是因为 std::lock_guard\r\n不能被复制或移动，它的应用场景就被严格地限制在了创建它的那个局部作用域\r\n(local scope) 内。这意味着你不能将 std::lock_guard 作为函数参数按值传递;\r\n不能从一个函数返回一个 std::lock_guard 对象; 不能把它存入一个容器（如\r\nstd::vector）;\r\n也不能把它作为一个类的成员变量，然后在不同实例间赋值或转移。 -\r\n这个限制不是一个缺陷，而是一个特性。它通过牺牲灵活性来换取极致的简单和安全，杜绝了因锁的所有权混乱而导致的死锁或未定义行为。它是一个“做一件事并把它做到完美”的工具。****\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;mutex&gt;int g_counter = 0;std::mutex g_mutex;void best_safe_increment() {    for (int i = 0; i &lt; 100000; ++i) {        // 创建 lock_guard 对象，它在构造时自动锁住 g_mutex        std::lock_guard&lt;std::mutex&gt; lock(g_mutex);                g_counter++;                // 当 lock 对象离开这个作用域时（for循环的本次迭代结束），        // 它的析构函数会自动调用 g_mutex.unlock()        // 即使 g_counter++ 抛出异常，也能保证解锁！    }}// ... main 函数与之前相同，只是调用 best_safe_increment 需要注意的是,\r\n我们应该保持临界区简短：加锁会阻塞其他线程，影响并发性能。因此，被锁定的代码块应该尽可能小，只包含必要的操作，然后尽快释放锁\r\nstd::unique_lock\r\n(推荐的现代方法)\r\nstd::unique_lock 是一个更强大、更灵活的锁管理器。它与 std::lock_guard\r\n的核心区别在于：std::unique_lock 实现了可移动 (movable)\r\n的所有权语义，并提供了更丰富的手动操作接口。\r\n可移动，不可复制 (Movable, Non-copyable):\r\nstd::unique_lock 像 std::unique_ptr\r\n一样，遵循唯一所有权模型。你不能复制它，但可以移动它，从而实现锁的所有权转移。\r\nstd::unique_lock&lt;std::mutex&gt; create_lock() {    std::unique_lock&lt;std::mutex&gt; u_lock(g_mutex);    // ... do something ...    return u_lock; // 所有权被转移出去 (隐式移动)    // 此时在析构时不会解锁，因为锁的所有权已经转移}void another_function() {    std::unique_lock&lt;std::mutex&gt; received_lock = create_lock();    // 现在 received_lock 拥有锁，当它离开作用域时会负责解锁}\r\n延迟锁定 (Deferred Locking): std::lock_guard\r\n在构造时必须锁定。而 std::unique_lock\r\n可以选择在构造时不锁定，之后再手动锁定。\r\nstd::unique_lock&lt;std::mutex&gt; u_lock(g_mutex, std::defer_lock);// 此时互斥量 g_mutex 并未被锁定// ... 在未来的某个时刻 ...u_lock.lock(); // 手动加锁\r\n手动控制: std::unique_lock\r\n允许你在其生命周期内手动调用 lock() 和\r\nunlock()。这允许你实现更细粒度的锁定策略：在不需要锁的时候提前释放它，以提高并发性。\r\nstd::unique_lock&lt;std::mutex&gt; u_lock(g_mutex); // 立即锁定// ... 执行一小部分需要锁的代码 ...u_lock.unlock(); // 提前解锁，让其他线程可以工作// ... 执行很长的、不需要锁的代码 ...u_lock.lock(); // 再次加锁// ... 执行另一部分需要锁的代码 ...// 函数结束时，如果 u_lock 仍持有锁，RAII 机制会保证它被解锁// 如果移动了锁的所有权，则不会解锁\r\n与条件变量 (std::condition_variable) 配合使用: 这是\r\nstd::unique_lock 最重要的用途。条件变量的 wait()\r\n方法要求传入一个\r\nstd::unique_lock。因为它需要在等待时原子地解锁互斥量，并在被唤醒后自动重新加锁。std::lock_guard\r\n无法提供这种手动解锁和重新加锁的灵活性。\r\n死锁 (Deadlock) 问题\r\n死锁是指两个或多个线程在执行过程中，因争夺资源而造成的一种互相等待的僵局。在这种状态下，如果没有外力干预，这些线程都将无法向前推进，导致整个程序或系统的相关部分被“冻结”。而在编程中,\r\n死锁争夺的资源就是互斥量 (mutex)。\r\n例如下列代码 #include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;mutex&gt;std::mutex mutex_A;  // 互斥量 Astd::mutex mutex_B;  // 互斥量 Bint account_A = 1000;int account_B = 2000;// 线程1: 尝试从 A 转账到 Bvoid transfer_A_to_B() {    mutex_A.lock(); // 1. 成功锁住 mutex_A    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // 模拟一些操作    mutex_B.lock(); // 3. 尝试锁住 mutex_B，但它被线程2持有，于是线程1开始阻塞等待    // ... 转账操作 ...    mutex_A.unlock();    mutex_B.unlock();}// 线程2: 尝试从 B 转账到 Avoid transfer_B_to_A() {    mutex_B.lock(); // 2. 成功锁住 mutex_B    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // 模拟一些操作    mutex_A.lock(); // 4. 尝试锁住 mutex_A，但它被线程1持有，于是线程2开始阻塞等待    // ... 转账操作 ...    mutex_B.unlock();    mutex_A.unlock();}int main() {    std::thread t1(transfer_A_to_B);    std::thread t2(transfer_B_to_A);    t1.join();    t2.join();    std::cout &lt;&lt; \"All transfers finished.\\n\"; // 这句话可能永远不会被打印    return 0;} 上述示例的结局是线程1 持有 mutex_A，等待\r\nmutex_B; 线程2 持有 mutex_B，等待\r\nmutex_A。两个线程都将永远等待下去，程序被挂起。\r\n死锁的四个必要条件\r\n一个死锁的发生，必须同时满足以下四个条件（因为发表人的原因,\r\n也被称为“Coffman条件”）： - 互斥条件 (Mutual\r\nExclusion)：资源不能被共享，在任意时刻，一个资源只能被一个线程持有。\r\n(互斥量天生就满足此条件) - 持有并等待条件 (Hold and\r\nWait)：一个线程至少持有一个资源，并且正在请求其它线程持有的资源。\r\n(例如，线程1持有A，等待B) - 不可剥夺条件 (No\r\nPreemption)：资源不能被强制地从一个线程中抢占，只能由持有它的线程自愿释放。\r\n(你不能强制线程1释放mutex_A) - 循环等待条件 (Circular\r\nWait)：存在一个线程的等待链，使得 P1 等待 P2 的资源，P2 等待 P3\r\n的资源，… ，Pn 等待 P1 的资源，形成一个环路。 (我们的例子中 T1 -&gt; T2\r\n-&gt; T1 就是一个环)\r\n避免死锁的方法\r\n避免死锁的思路就是破坏这四个条件中的至少一个,\r\n最常见和最实用的方法是破坏“循环等待”条件。 1.\r\n按固定顺序加锁 (最常用的方法)\r\n这是解决死锁问题的黄金法则。规定程序中所有需要同时锁住多个互斥量的地方，都必须严格按照相同的全局顺序来获取锁。\r\n例如，我们可以规定，总是先锁地址较小的那个互斥量。\r\n// 假设 mutex_A 的地址 &lt; mutex_B 的地址void safe_transfer() { // 两个线程都调用这一个函数    // 总是先锁地址较小的 mutex_A，再锁地址较大的 mutex_B    std::lock_guard&lt;std::mutex&gt; lock_a(mutex_A);     std::this_thread::sleep_for(std::chrono::milliseconds(10));    std::lock_guard&lt;std::mutex&gt; lock_b(mutex_B);    // ... 执行转账操作 ...}\r\n在这个修正版中，无论是A到B还是B到A的转账，都会先尝试锁mutex_A，再尝试锁mutex_B。这样，当一个线程成功锁住mutex_A后，另一个线程会因为无法锁住mutex_A而直接等待，它根本没有机会去锁住mutex_B，因此循环等待的条件被破坏，死锁不会发生。\r\n\r\n使用 std::lock (C++11/17 推荐)\r\n手动管理锁的顺序可能很复杂且容易出错。C++标准库提供了一个完美的工具\r\nstd::lock，它可以一次性原子地锁住多个互斥量，并且内部实现了避免死锁的算法。\r\nvoid best_safe_transfer() {    // std::lock 会以一种避免死锁的方式锁住两个互斥量    std::lock(mutex_A, mutex_B);    // 使用 std::adopt_lock 参数告诉 lock_guard，互斥量已经被锁住，    // 它只需要负责在析构时解锁即可。    std::lock_guard&lt;std::mutex&gt; guard_a(mutex_A, std::adopt_lock);    std::lock_guard&lt;std::mutex&gt; guard_b(mutex_B, std::adopt_lock);    // ... 执行转账操作 ...}\r\n这是目前处理多个互斥量加锁问题的最安全、最推荐的方案。\r\n其他策略\r\n\r\n\r\n破坏“持有并等待”：尝试一次性获取所有需要的锁（std::lock就是这样做的），如果不能，就释放所有已持有的锁并重试。这可以使用\r\nstd::unique_lock 的 try_lock 方法实现，但逻辑更复杂。\r\n减少锁的粒度：尽量不要长时间持有锁，尤其不要在持有锁的时候做耗时操作（如文件I/O），让临界区尽可能小。\r\n避免嵌套锁：尽量避免在一个锁的作用域内再去获取另一个锁，如果不可避免，请严格遵守加锁顺序。\r\n\r\n原子操作\r\n上述属于传统的解决方案, 即是使用互斥锁 (std::mutex)\r\n来保护共享数据，确保同一时间只有一个线程可以访问\r\ncounter。然而，互斥锁是操作系统层面的同步原语，涉及系统调用，可能会导致线程阻塞和上下文切换，开销相对较大。\r\nstd::atomic\r\n提供了一种更轻量级、更底层的解决方案。它利用现代 CPU\r\n提供的特殊原子指令（如 LOCK\r\nCMPXCHG），在硬件层面保证单个操作的原子性\r\n(Atomicity)，从而避免数据竞争，且通常比互斥锁性能更高。\r\nstd::atomic&lt;T&gt; 是一个模板类，它包装了一个 T\r\n类型的值，并确保对这个值的所有操作都是原子的。原子操作是指一个从所有其他线程的角度来看不可分割的操作。它要么完全执行，要么完全不执行，不存在任何中间状态被其他线程观察到。\r\n\r\nstd::atomic 定义在 &lt;atomic&gt; 头文件中。\r\n\r\n基本用法与操作\r\n#include &lt;atomic&gt;std::atomic&lt;int&gt; atomic_counter(0);  // 声明一个原子整数并初始化为 0std::atomic&lt;bool&gt; is_ready(false);  // 声明一个原子布尔值并初始化为 false\r\nstd::atomic 的成员函数可以分为几类：\r\n\r\n写入与读取 (Store and Load)\r\n\r\nstore(value): 原子地将 value\r\n写入原子对象(也就是赋值)。\r\nload(): 原子地读取原子对象的值(也就是取值)。\r\n常用的赋值和读取操作符被重载，通常会调用这两个函数。\r\n\r\n读-修改-写 (Read-Modify-Write, RMW) 操作: 这是\r\nstd::atomic\r\n最强大的功能，它将读取、修改、写入三个步骤合并为一个不可分割的原子操作。\r\n\r\nexchange(value): 原子地将原子对象的值替换为\r\nvalue，并返回替换前的旧值。\r\nfetch_add(arg), fetch_sub(arg):\r\n原子地给当前值加上/减去 arg，并返回操作前的旧值。重载的\r\n++, –, +=, -= 等操作符通常调用它们。\r\n\r\ncompare_exchange_strong(expected,\r\ndesired) /\r\ncompare_exchange_weak(expected, desired): 这是最核心的\r\nRMW 操作（比较并交换，CAS）。工作流程：\r\n\r\n比较原子对象的当前值与 expected\r\n的值。\r\n如果相等，则将原子对象的值修改为\r\ndesired，并返回 true。\r\n如果不相等，则将 expected\r\n的值更新为原子对象的当前值，并返回 false。 &gt; strong\r\nvs weak: strong 保证如果值相等，交换就一定成功。weak\r\n版本在某些平台上性能更好，但即使值相等也可能“伪失败”（spurious\r\nfailure），即返回 false。因此 weak 版本通常用在循环中。\r\n\r\n\r\natomic_counter.store(10); // 等同于 atomic_counter = 10;int current_val = atomic_counter.load(); // 等同于 int current_val = atomic_counter;// 解决最开始的计数器问题std::atomic&lt;int&gt; counter(0);counter++; // 原子操作，不会产生数据竞争std::atomic&lt;int&gt; val(10);int expected = 10;int desired = 20;// 尝试将 val 从 10 原子地更新为 20if (val.compare_exchange_strong(expected, desired)) {    // 成功，val 现在是 20} else {    // 失败，可能是因为其他线程修改了 val    // 此时 expected 的值会被更新为 val 的当前值}\r\n内存序 (Memory Ordering)\r\n原子性仅仅保证了单个操作的不可分割性，但并未规定该操作与其他内存读写操作之间的顺序。为了性能，编译器和\r\nCPU\r\n可能会对指令进行重排序。在单线程中，这毫无问题。但在多线程中，这种重排可能会导致灾难性的后果。\r\n// 共享变量int shared_data = 0;std::atomic&lt;bool&gt; data_ready = false;// 线程 A: 生产者void producer() {    shared_data = 42;                   // 操作 A    data_ready.store(true);             // 操作 B}// 线程 B: 消费者void consumer() {    if (data_ready.load()) {            // 操作 C        assert(shared_data == 42);      // 操作 D    }} 从程序员的逻辑来看，producer 中 A 操作一定先于 B\r\n操作。consumer 只有在 C 操作读到 true 之后，才会执行 D\r\n操作。因此，assert 应该永远不会失败。\r\n但现实是, 编译器或 CPU 可能会认为操作 A 和 B\r\n互不依赖，为了优化，可能会将它们的执行顺序重排。producer\r\n的实际执行顺序可能变成： // 重排后的生产者void producer_reordered() {    data_ready.store(true);             // 操作 B    shared_data = 42;                   // 操作 A} 也就是当线程 B 执行\r\nassert(shared_data == 42)时, shared_data 还是 0，断言失败！\r\n内存序就是用来约束这种重排序，确保多线程间操作的可见性顺序。它的本质是一种内存屏障。内存屏障是一种指令，它告诉编译器和\r\nCPU：“任何指令都不能跨越我这个屏障进行重排”。\r\nstd::memory_order 枚举定义了六种内存序模型：\r\n\r\n宽松序 (std::memory_order_relaxed):最弱的内存序,\r\n只保证当前原子操作的原子性，不提供任何额外的同步或排序保证。其他线程可能以任意顺序观察到内存的修改,\r\n指令可以在任意时间点执行, 也可以被重排。\r\n\r\n适用场景:\r\n只关心单个原子变量的修改，不依赖它来同步其他数据。例如，简单地增加一个计数器，只在最后才读取它的值。\r\n\r\n获取-释放语序 (Acquire-Release Semantics):\r\n这是实现线程间同步最常用的模型，通常成对出现。\r\n\r\nstd::memory_order_release:用于写入/存储操作。它确保在当前线程中，所有位于此\r\nrelease\r\n操作之前的内存写入（无论是原子还是非原子的），对于在其他线程中对同一个原子变量执行\r\nacquire 操作的线程都是可见的, 换句话说, 它是一个向上的屏障, 在此\r\nrelease\r\n操作之前的所有内存写入，都不能被重排到这个操作之后(编译期)。\r\n\r\n实际上, 这个命令还有硬件层面的含义,\r\n即将执行该指令的CPU核心（例如核心A）的缓存中，所有在此之前的写入（包括\r\nshared_data = 42），刷新到共享内存系统中。\r\n\r\nstd::memory_order_acquire:用于读取/加载操作。它确保在当前线程中，所有位于此\r\nacquire 操作之后的内存读取，都能看到由其他线程中对同一个原子变量执行\r\nrelease 操作的线程所写入的数据。换句话说, 它是一个向下的屏障,\r\n在此 acquire\r\n操作之后的所有内存读取，都不能被重排到这个操作之前。\r\n\r\n在硬件层面, 执行该指令的CPU核心（例如核心B）在加载 shared_data\r\n的值时，先使自己的本地缓存无效\r\n(invalidate)，然后去共享内存系统中获取最新的值。\r\n一般与 release 配合使用，形成同步点:\r\n读取就用 acquire，写入就用\r\nrelease。\r\n\r\nstd::memory_order_acq_rel:用于读-修改-写操作，同时具备\r\nacquire 和 release 的特性。\r\n\r\n顺序一致性\r\n(std::memory_order_seq_cst):最强的内存序，也是默认的内存序。它不仅提供\r\nacquire-release\r\n的所有保证，还额外保证所有线程都以相同的顺序观察到所有 seq_cst\r\n操作。它在所有线程之间建立了一个单一的、全局的操作总顺序。这个最容易理解，但通常也是性能开销最大的，因为它限制了编译器和\r\nCPU 的优化能力。\r\n\r\n对比\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\nstd::atomic\r\nstd::mutex\r\n\r\n\r\n\r\n\r\n保护对象\r\n单个变量 (如int, bool, 指针)\r\n一段代码块 (临界区)，可包含多个变量和复杂逻辑\r\n\r\n\r\n实现原理\r\n通常是硬件级别的原子指令 (无锁)\r\n通常是操作系统级别的内核对象\r\n(可能涉及线程阻塞)\r\n\r\n\r\n性能开销\r\n较低，适合高频访问\r\n较高，不适合高频、短小的临界区\r\n\r\n\r\n使用场景\r\n简单的标志位、计数器、指针等细粒度同步\r\n保护复杂数据结构或一系列必须整体执行的操作\r\n\r\n\r\n死锁风险\r\n无\r\n有 (如果加锁顺序不当)\r\n\r\n\r\n\r\n当需要保护的是一个独立的、简单的内置类型（如标志、计数器）时，优先使用\r\nstd::atomic。\r\n当需要保护一个复杂的数据结构（如\r\nstd::vector）或需要将一系列操作（例如，从一个 vector\r\n中移除元素并更新大小）作为一个不可分割的事务来执行时，必须使用\r\nstd::mutex。\r\n自旋锁和互斥锁\r\n自旋锁特性： -\r\n实现机制：在用户态忙等待，不断循环检测锁状态\r\n- CPU消耗：高，即使等待也在持续消耗CPU周期 -\r\n上下文切换：无，线程始终保持运行状态 -\r\n响应延迟：低，锁释放后能立即获取 -\r\n实现复杂度：相对简单，通常基于原子操作\r\n互斥锁特性： -\r\n实现机制：通过操作系统内核调度，线程阻塞并进入睡眠\r\n- CPU消耗：低，等待时不消耗CPU资源 -\r\n上下文切换：有，涉及用户态到内核态切换\r\n- 响应延迟：高，需要唤醒睡眠线程 -\r\n实现复杂度：相对复杂，依赖操作系统支持\r\n性能关键因素： - 锁竞争强度：高竞争下自旋锁性能急剧下降 -\r\n临界区大小：短临界区适合自旋锁(锁持有时间小于两次上下文切换时间)，长临界区适合互斥锁\r\n- CPU核心数：多核系统更适合自旋锁 -\r\n调度策略：实时系统可能偏好自旋锁\r\n\r\n\r\nalt text\r\n\r\n下面是一个简单的示例 #include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;iostream&gt;class Spinlock {private:    std::atomic_flag flag = ATOMIC_FLAG_INIT;public:    void lock() {        // 自旋等待，直到成功获取锁        while (flag.test_and_set(std::memory_order_acquire)) {            // 可选的优化：在重度竞争时让出CPU            // std::this_thread::yield();        }    }        void unlock() {        flag.clear(std::memory_order_release);    }};// 使用示例Spinlock spinlock;int shared_data = 0;void spinlock_worker(int id) {    for (int i = 0; i &lt; 1000; ++i) {        spinlock.lock();        shared_data++;  // 短临界区操作        spinlock.unlock();    }    std::cout &lt;&lt; \"Thread \" &lt;&lt; id &lt;&lt; \" finished\" &lt;&lt; std::endl;}//------------------------------------------------------------------------//互斥锁实现#include &lt;mutex&gt;#include &lt;thread&gt;#include &lt;iostream&gt;std::mutex mtx;int shared_data = 0;void mutex_worker(int id) {    for (int i = 0; i &lt; 1000; ++i) {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        shared_data++;  // 短临界区操作        // 模拟较长临界区操作        // std::this_thread::sleep_for(std::chrono::microseconds(10));    }    std::cout &lt;&lt; \"Thread \" &lt;&lt; id &lt;&lt; \" finished\" &lt;&lt; std::endl;}\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"url":"/2025/10/10/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E7%B1%BB/%E7%B1%BB%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","content":"成员变量存储和访问\r\n存储顺序:\r\n成员变量在内存中的存储顺序与它们在类定义中出现的顺序一致。\r\n静态成员：静态成员变量不属于任何一个对象，而是存储在程序的数据段中，因此不占用类对象的内存空间\r\n。\r\n地址连续性：一个类对象的内存空间是连续的，其成员变量的地址也是依次排列的。后声明的成员变量拥有更高的内存地址。\r\n非静态成员变量与成员变量偏移值\r\n(Offset)\r\n非静态成员变量是构成 对象 自身状态的数据。每个对象都有自己的一份副本,\r\n存储在每个对象被分配到的内存块中（可能在栈上、堆上或静态数据区）。其访问机制是\r\nthis 指针与偏移值.\r\n当调用一个对象的非静态成员函数时，编译器会隐式地传递一个指向该对象的指针，这个指针就是\r\nthis。\r\n访问一个成员变量 m_data 的过程如下：\r\n\r\n隐式转换：在成员函数内部，你写的 m_data 会被编译器自动翻译成\r\nthis-&gt;m_data。\r\n偏移值\r\n(Offset)：在编译时，编译器会根据成员变量在类定义中的声明顺序和内存对齐规则，计算出每个成员相对于对象起始地址的偏移值。这是一个固定的、在编译时就已知的常量。\r\n地址计算：在运行时，访问 this-&gt;m_data 的实际操作是：成员地址 =\r\nthis 指针的值 + m_data 的偏移值\r\n\r\n多重继承与 this 指针调整\r\n派生类对象包含了其所有基类的子对象。这些子对象在内存中通常按照继承声明的顺序依次排列。\r\n示例：\r\nC++\r\nclass Base1 { public: int m_base1; }; class Base2 { public: int\r\nm_base2; }; class Derived : public Base1, public Base2 { public: int\r\nm_derived; }; 一个 Derived 对象的内存布局示意图：\r\n+——————-+ &lt;- Derived 对象的起始地址 | Base1 subobject | |\r\n(m_base1) | +——————-+ &lt;- Base2 子对象的起始地址 | Base2 subobject | |\r\n(m_base2) | +——————-+ | Derived’s members | | (m_derived) | +——————-+ 2.\r\nthis 指针调整的必要性 现在，考虑以下代码：\r\nC++\r\nDerived d; Base2* pBase2 = &amp;d; // 指针转换（向上转型）\r\nd.some_Base2_method(); // 调用继承自 Base2 的方法\r\n这里出现了两个关键问题，都需要 this 指针调整来解决：\r\n指针转换 (Base2* pBase2 = &amp;d;):\r\n&amp;d 的地址是 Derived 对象的起始地址，也就是 Base1\r\n子对象的起始地址。\r\n但是 pBase2 必须指向一个 Base2 对象。在 d 的内存布局中，Base2\r\n子对象并不在起始位置。\r\n为了让 pBase2 正确指向 d 内部的 Base2\r\n子对象，编译器必须在赋值时对指针进行调整： pBase2 = (Base2)(\r\n(char)&amp;d + sizeof(Base1) );\r\n这个 地址平移 的过程就是 this 指针调整。\r\n成员函数调用 (d.some_Base2_method()):\r\nsome_Base2_method() 是 Base2 的成员函数。它被编译时，假定其 this\r\n指针会指向一个 Base2 对象的起始地址，以便用正确的偏移量（例如，m_base2\r\n的偏移量为 0）来访问成员。\r\n当通过 d 对象调用它时，d\r\n的地址是整个对象的起始地址。如果直接把这个地址传给 some_Base2_method()\r\n作为 this 指针，函数内部就会错误地把 Base1 的成员 m_base1 当作 m_base2\r\n来访问。\r\n因此，在调用前，编译器会自动生成代码，将 d 的地址进行调整（加上\r\nsizeof(Base1)），然后将这个 调整后 的地址作为 this 指针传递给\r\nsome_Base2_method()。\r\n结论：在多重继承中，当涉及到指向 非首个基类\r\n的指针转换或成员函数调用时，编译器会自动进行 this 指針的平移调整，以确保\r\nthis 指针总是正确地指向相应子对象的起始地址。\r\n成员变量指针重申\r\n对象成员变量的指针 (Pointer to a Data Member of an Object)：\r\n这是一个普通的指针，例如 int*。\r\n它存储的是一个特定对象中某个成员变量的具体内存地址 。例如 int* p1 =\r\n&amp;myobj.m_i; 。\r\n成员变量指针 (Pointer to Member)：\r\n这是一种特殊的指针类型，例如 int MYACLS::* 。\r\n它不存储内存地址，而是存储成员变量在类布局中的偏移值 。\r\n它的 sizeof 值通常与普通指针相同（如4字节） 。\r\nNULL 成员变量指针：\r\n为了区分“指向类第一个成员（偏移值为0）的指针”和“不指向任何成员的空指针”，编译器对空成员变量指针做了特殊处理\r\n。\r\n将一个成员变量指针赋值为 0 或 NULL，其内部表示通常为 -1（即\r\n0xffffffff），而不是 0 。\r\n内存对齐 (Memory Alignment)\r\n内存对齐\r\n是指数据在内存中的存放位置受到一定的限制，并非可以放置在任意地址。通常，一个大小为\r\nN\r\n字节的数据类型，其存放的起始地址必须是\r\nN 的整数倍。\r\n\r\nchar (1字节): 可以在任何地址。\r\nshort (2字节): 存放的起始地址必须是 2 的倍数 (例如 0, 2, 4,\r\n…)。\r\nint, float (4字节): 存放的起始地址必须是 4 的倍数 (例如 0, 4, 8,\r\n…)。\r\nlong long, double, void* (8字节): 存放的起始地址必须是 8 的倍数\r\n(例如 0, 8, 16, …)。\r\n\r\n这主要是出于性能考虑，是硬件（CPU）对内存访问的特性要求。\r\n\r\nCPU 读取效率：CPU\r\n访问内存不是逐字节进行的，而是以一个“字”(Word)为单位进行块读取。一个字的大小通常是\r\n4 字节（32位系统）或 8 字节（64位系统）。\r\n\r\n对齐的访问：如果一个 4 字节的 int 存储在 4 的倍数地址上（例如地址\r\n0x1004），那么 CPU 只需要进行 一次 内存读取操作就可以完整获取数据。\r\n未对齐的访问：如果这个 int 被存储在非 4 的倍数地址上（例如地址\r\n0x1005），它会跨越两个内存读取边界。CPU\r\n为了读取这个数据，可能需要进行两次内存读取，然后还需要进行位移、合并等操作才能得到完整的数据。这会大大降低访问速度。在某些硬件平台上，未对齐的访问甚至会直接导致硬件异常。\r\n\r\n\r\n为了提高性能并避免潜在的硬件问题，编译器会自动进行内存对齐，通过插入一些不使用的字节来调整成员变量的位置，这些被插入的字节被称为填充\r\n(Padding)。\r\n内存对齐的核心规则\r\n一个类或结构体的内存布局主要遵循以下三条规则：\r\n规则 1：成员变量的对齐\r\n成员变量的起始地址 必须是 其自身对齐值 和 指定对齐值中 较小者\r\n的整数倍。\r\n\r\n自身对齐值：该成员变量数据类型本身的大小，例如 int 是 4。\r\n指定对齐值：通常由编译器默认或通过 #pragma pack(n)\r\n设置。我们先假设使用编译器默认值。\r\n\r\n简单来说，每个成员变量的偏移量 (offset)\r\n必须是它自身大小的整数倍。如果当前偏移量不满足，编译器会在前一个成员后面插入填充字节。\r\n规则 2：类的整体对齐\r\n类（或结构体）的最终总大小 必须是\r\n其所有成员变量中最大对齐值 的整数倍。\r\n这个最大的对齐值也称为这个类（或结构体）的对齐模数 (Alignment\r\nModulus)。\r\n如果计算出的总大小不满足此规则，编译器会在最后一个成员变量后面继续插入填充字节，直到满足为止。\r\n规则 3：嵌套结构体的对齐\r\n如果一个结构体 A 包含另一个结构体 B，那么成员 B 的对齐要求以 B\r\n内部最大的成员对齐值为准。\r\nclass MyClass1 {    char a;    // 1 字节    int b;     // 4 字节    char c;    // 1 字节};// 最终内存占用: 12 字节class MyClass2 {    int b;     // 4 字节    char a;    // 1 字节    char c;    // 1 字节};// 最终内存占用: 8 字节\r\nC++ 特性对内存布局的影响\r\n普通继承\r\n在普通继承中，派生类的内存布局通常是基类成员在前，派生类新增成员在后。对齐规则会应用于整个对象。\r\nclass Base {    int x;     // 4    char y;    // 1}; // sizeof(Base) is 8 (padded)class Derived : public Base {    double z;  // 8};// sizeof(Derived) is 16 (padded)\r\n虚函数 (Virtual Functions)\r\n如果类中包含虚函数（或继承自包含虚函数的基类），编译器会为该类的每个对象添加一个虚函数指针\r\n(vptr)。\r\n\r\nvptr 的大小与指针大小相同（32位系统为4字节，64位系统为8字节）。\r\nvptr 通常被放置在 对象内存布局的最前端。\r\nvptr 本身也参与内存对齐计算。 class VirtualClass {    virtual void func() {}    int a; // 4};// sizeof(VirtualClass) is 16 ( 8+4+padded, includes vptr)class VirtualClassDerived : public VirtualClass {    double b; // 8};// sizeof(VirtualClassDerived) is 24 (16+8, includes vptr)\r\n这里父类的vptr被子类继承，子类对象中只有一个vptr。内存布局为\r\n[vptr(8)][a(4)][padding(4)][b(8)]。\r\n\r\n虚继承 (Virtual Inheritance)\r\n虚继承用于解决菱形继承中的数据冗余问题。其实现机制更复杂，通常会引入一个虚基类指针\r\n(vbptr)。vbptr\r\n指向一个虚基类表，表中记录了虚基类子对象相对于\r\nvbptr\r\n地址的偏移量。这导致虚基类的成员不再和派生类成员连续存储。其具体布局因编译器而异，但通常会把共享的虚基类子对象放在派生类对象内存的末尾。\r\n"},{"title":"Volatile 和编译器优化","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/Volatile%E5%92%8C%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%98%E5%8C%96/","content":"编译器优化的核心目标是在不改变程序原始逻辑（即可观察行为）的前提下，对生成的机器码进行修改，以提升程序的运行效率或减小其体积。这些改进通常体现在两个方面：\r\n\r\n执行速度：减少程序运行所需的总时钟周期。\r\n代码体积：减小程序编译后生成的可执行文件的大小。\r\n\r\nGCC\r\n提供了一系列丰富的优化选项，让开发者可以根据具体需求在编译时间、调试便利性、运行速度和代码大小之间做出权衡。\r\n具体操作是通过 -O\r\n系列标志（Flag）来控制。你可以直接在编译命令中加入这些标志。\r\n例如：gcc -O2 -o main main.c\r\nGCC 的主要优化级别\r\nGCC\r\n将大量的具体优化选项组合成了几个预设的优化级别。级别越高，启用的优化项越多，编译所需的时间也越长。\r\n\r\n-O0:\r\n不进行任何优化。这是默认的优化级别（如果你不指定任何 -O 选项）。\r\n\r\n目的：确保编译速度最快，并产生最直接、未经修改的机器码，与源代码的对应关系最强。\r\n适用场景：主要用于开发和调试阶段。因为没有优化，变量的值不会被意外优化掉，代码执行顺序也和源码完全一致，使得\r\nGDB 等调试工具可以准确地跟踪程序的每一步。\r\n\r\n-O1:\r\n基础级别的优化。编译器会尝试在不花费太多编译时间的情况下，执行一些基本的优化。\r\n\r\n目的：在不过分增加编译时间的前提下，提升程序性能。\r\n包含的优化：例如死代码消除（Dead Code\r\nElimination）、常量传播（Constant\r\nPropagation）等。\r\n\r\n\r\n-O2:\r\n推荐的通用优化级别。它开启了几乎所有不涉及“空间换时间”或“时间换空间”权衡的优化选项。\r\n- 目的：在编译时间和生成代码的性能之间取得最佳平衡。\r\n\r\n- 适用场景：软件的正式发布版本（Release Build）。这是最常用、最稳定的优化级别。\r\n\r\n-O3: 最高级别的优化。在 -O2\r\n的基础上，开启了更多、更激进的优化，例如函数内联（Inlining）和循环展开（Loop\r\nUnrolling）等。\r\n\r\n目的：追求极致的运行速度。\r\n潜在问题：编译时间显著增加;\r\n代码体积可能变大，因为一些优化（如循环展开）会用更多的代码来换取更快的速度。在极少数情况下，激进的优化可能会导致代码缓存（Instruction\r\nCache）命中率下降，反而使程序性能降低。\r\n\r\n-Os：优化代码大小（Size）。它会开启 -O2\r\n中所有不会增加代码体积的优化项，并执行一些专门为减小代码体积设计的优化。\r\n\r\n目的：生成尽可能小的可执行文件。\r\n适用场景：嵌入式系统、移动设备或其他存储空间受限的环境。\r\n\r\n-Ofast: 极限但可能不安全的优化。它包含了 -O3\r\n的所有优化，并额外开启了一些可能会违反严格语言标准的优化。\r\n\r\n目的：压榨出最高的性能，不惜牺牲部分标准的符合性。\r\n重要警告：这个级别最显著的特点是会启用 -ffast-math\r\n选项，这会影响浮点数的计算精度，可能不符合 IEEE 754\r\n标准。除非你完全理解其后果，否则不应在对浮点数精度有要求的科学计算或金融应用中使用。\r\n\r\n-Og: 为调试而优化的级别（Optimize for\r\nDebugging）。\r\n\r\n目的：在不严重干扰调试体验的前提下，提供一个合理的性能。它会启用一些不会影响变量跟踪和断点设置的优化。\r\n适用场景：当你希望在调试时也能获得较好的程序性能，但又不想像 -O0\r\n那样完全放弃优化时，这是一个很好的选择。\r\n\r\n\r\n具体的优化技术示例\r\n下面是一些在上述优化级别中常见的具体优化技术，以帮助理解编译器在幕后做了什么。\r\n常量折叠与常量传播 (Constant Folding &amp;\r\nPropagation):\r\n在编译期间直接计算出结果为常量的表达式，并用结果替换该表达式。\r\n这里编译器发现 3.14 * 10 * 10\r\n是一个常量表达式，于是在编译时直接计算出结果 314.0。\r\nint radius = 10;double area = 3.14 * radius * radius;// 优化后，编译器会将 area 直接替换为 314.0double area = 314.0;\r\n死代码消除 (Dead Code Elimination):\r\n移除那些永远不会被执行到的代码。\r\n这里编译器发现 debug 是一个编译时常量 0，因此 if\r\n条件永远为假，其中的代码永远不会执行。 int debug = 0;if (debug) {    printf(\"This is a debug message.\\n\");}// 优化后，编译器会移除整个 if 语句块\r\n函数内联 (Function Inlining):\r\n将一个函数的调用替换为该函数体的实际代码，以消除函数调用的开销（如堆栈操作、参数传递等）。这通常在\r\n-O2 和 -O3 中启用。\r\nint square(int x) {    return x * x;}int main() {    int y = square(5);    return y;}// 优化后，编译器会将函数调用替换为函数体int main() {    int y = 5 * 5; // 直接展开函数体    return y;}\r\n\r\n尾递归优化也属于函数内联的一种特殊形式，编译器会将尾递归调用转换为循环，从而避免函数调用的开销和栈溢出风险。\r\n\r\n循环展开 (Loop Unrolling):\r\n减少循环的迭代次数，但在每次迭代中执行更多的工作。这可以减少循环判断和分支的开销，并为其他优化（如指令级并行）创造机会。这通常在\r\n-O3 中启用。\r\nfor (int i = 0; i &lt; 16; ++i) {    process(data[i]);}// 优化后，编译器可能会将循环展开为for(int i = 0; i &lt; 16; i += 4) {    process(data[i]);    process(data[i + 1]);    process(data[i + 2]);    process(data[i + 3]);}\r\n代价和权衡\r\n虽然优化能带来巨大好处，但也存在一些需要注意的代价和风险：\r\n\r\n编译时间增加：优化级别越高，编译器需要做的分析和转换就越多，导致编译时间变长。\r\n调试难度加大：优化会重排代码、消除变量、内联函数，这使得源码和最终执行的机器码之间的对应关系变得复杂。在\r\n-O2 或 -O3\r\n下调试时，你可能会发现单步执行时代码跳转不符合预期和无法打印某个变量的值等，因为它可能被优化到寄存器中，或者完全被消除了。\r\n可能暴露未定义行为 (Undefined Behavior)：C/C++\r\n标准中一些行为是未定义的（如访问数组越界、有符号整数溢出）。在 -O0\r\n下，这些行为可能恰好能“正常”工作，但在优化后，编译器可能会基于“这种行为永远不会发生”的假设进行优化，从而导致程序崩溃或产生非预期结果。\r\n代码体积问题：-O3\r\n等高级别优化为了速度可能会显著增加代码体积，这在某些场景下是不可接受的。\r\n\r\nvolatile 关键字\r\nvolatile 是 C/C++ 语言中的一个类型限定符（type qualifier），与 const\r\n类似。它的核心作用是告知编译器，被它修饰的变量的值随时都可能被程序本身之外的因素改变。\r\n这个“外部因素”可以是硬件（例如，一个内存映射的状态寄存器）, 操作系统,\r\n另一个线程或者一个信号处理函数。\r\n因此，volatile\r\n的主要目的是抑制编译器的优化，确保对该变量的每一次访问都是直接从内存中读取或写入，而不是使用寄存器中的缓存值。\r\n下面是一个简单的例子，展示了 volatile 的典型用法：\r\n// 假设 0x12345678 是一个硬件状态寄存器的地址unsigned int *status_reg = (unsigned int *)0x12345678;// 等待设备就绪while (*status_reg != 0) {    // 忙等待 (busy-wait)}// 设备已就绪，继续执行...\r\n编译器的优化思路 (-O2 或更高)：\r\n\r\n分析循环：编译器看到 while 循环的条件是 *status_reg != 0。\r\n发现问题：在循环体内，没有任何代码会修改 *status_reg\r\n指向的内存地址的值。\r\n做出假设：因此，编译器假设 *status_reg 的值永远不会改变。\r\n进行优化：它会在循环开始前，**只读取一次 *status_reg\r\n的值并存入一个寄存器**（例如 eax）。然后，while\r\n循环就变成了 while (eax != 0)。\r\n\r\n如果第一次读取的值不为 0，这将变成一个无限循环\r\n(while(true))，即使硬件在稍后将状态寄存器的值更新为\r\n0，程序也永远无法感知到这个变化，因为它一直在检查寄存器里的旧值。\r\n最后优化后的效果：\r\nRISCV    LDR R0, [0x12345678]  ; 只读取一次状态寄存器.L1:    CMP R0, #0            ; 比较寄存器中的值    BNE .L1               ; 如果不为 0，继续循环\r\n现在，我们把 volatile 加上。\r\n// 使用 volatile 告诉编译器，这个地址的值随时可能改变volatile unsigned int *status_reg = (volatile unsigned int *)0x12345678;// 等待设备就绪while (*status_reg != 0) {    // 忙等待}// 设备已就绪，继续执行...\r\n现在, 编译器看到 status_reg 指向一个 volatile\r\n变量后会抑制优化：volatile\r\n关键字像一个指令，告诉编译器：“不要对这个变量做任何假设！它的值随时可能从外部改变。”\r\n因此，编译器会在每一次循环中都生成从内存地址 0x12345678\r\n重新读取值的指令。它不会将这个值缓存到寄存器中。\r\n最终生成的汇编代码可能类似于：\r\nRISCV.L1:    LDR R0, [0x12345678]  ; 每次循环都重新读取状态寄存器    CMP R0, #0            ; 比较寄存器中的值    BNE .L1               ; 如果不为 0，继续循环\r\n这样，当硬件更新了状态寄存器的值后，下一次循环的 mov\r\n指令就能读取到新的值，程序就能正确地跳出循环。\r\n值得注意的是, 一个变量可以同时被 const 和 volatile\r\n修饰，这看似矛盾，但实际上有明确的含义。 volatile const unsigned int *device_timer = (volatile const unsigned int *)0x87654321;\r\n这里的 const 表示程序不能通过这个指针修改\r\ndevice_timer 指向的内存内容（即程序不能写入这个寄存器），而 volatile\r\n则表示该寄存器的值可能随时被外部硬件改变，所以每次访问都必须从内存中重新读取。\r\n这个组合的完美用例是一个只读的硬件寄存器，比如一个硬件计时器或状态寄存器。我们的程序只能读取它的值，但这个值本身会由硬件自动更新。\r\nconst不能保证不被修改,\r\nvolatile真能保证不被优化\r\nconst 关键字在 C/C++\r\n中表示“只读”，即通过该指针或引用不能修改它所指向的数据。然而，const\r\n并不意味着数据本身是不可变的。数据可能会被其他途径修改，例如： - 通过非\r\nconst 指针或引用。 - 通过硬件寄存器（如内存映射 I/O）。 -\r\n通过多线程中的其他线程。 - 通过类型转换（cast）绕过 const 限定符。\r\nint main() {    const int a = 10;    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; // Output may still be 10    cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl; // Output: 20    return 0;}\r\n在这个例子中，我们通过类型转换（cast）绕过了 const 限定符，直接修改了\r\na 的值。虽然这种做法在技术上是可行的，但它违反了 const 的语义\r\n然而值得注意的是 a 的值在输出时仍然是\r\n10，因为声明const int a = 10;这种做法太直接了,\r\n即使在-o0的情况下, 编译器也会将 a 的值直接内联到代码中, 导致修改 a\r\n的值实际上并没有影响到程序的行为。\r\n不过, 通过指针可以看到, 原先 a 的内存地址上的值确实被改成了 20。\r\n第二种情况是, 假如变量a被定义在了全局中: const int a = 10;int main() {    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl;     cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl;     return 0;} 此时,\r\n再执行会发现在运行时直接报错退出, 这是因为 a\r\n是const的全局变量, 被放在了 .rodata 的只读数据段 (Read-Only Data\r\nSegment) 中, 试图修改它会导致访问冲突 (Access\r\nViolation) 或 段错误 (Segmentation Fault)。\r\n现在, 如果我们把第一种情况的 const 换成 volatile const：\r\nint main() {    volatile const int a = 10;    int* p = (int*)&amp;a; // Cast away constness (not recommended in                        // production code)    *p = 20; // Undefined behavior, but often works in practice    cout &lt;&lt; \"a = \" &lt;&lt; a &lt;&lt; endl; // Output will be 20    cout &lt;&lt; \"*p = \" &lt;&lt; *p &lt;&lt; endl; // Output: 20    return 0;} 在这个例子中，a 被声明为 volatile const，这告诉编译器 a\r\n的值可能会被外部因素改变（例如硬件或其他线程）。因此，编译器不会对 a\r\n进行优化，每次访问 a 时都会从内存中重新读取它的值。\r\n因此当我们通过指针修改了 a 的值后，下一次访问 a\r\n时，编译器会重新从内存中读取它的值，这次读取到的值是 20。\r\n总结来说, const只是一种编译时的约束,\r\n它并不能真正保证数据不被修改(像情况2那样真正的约束在于底层硬件中MMU的保护机制)。而\r\nvolatile 则是一种运行时的约束,\r\n它确保每次访问变量时都直接从内存中读取最新的值,\r\n从而防止编译器对其进行优化。\r\n"},{"title":"std jthread","url":"/2025/10/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/8.%20std%20jthread/","content":"\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"异步/并发编程模型","url":"/2025/09/22/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E5%A4%9A%E7%BA%BF%E7%A8%8B/7.%20%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","content":"在C++并发编程中，核心挑战之一是在不同线程间安全、高效地传递数据。特别是当一个线程（生产者/Provider）需要将一个计算结果（值或异常）传递给另一个线程（消费者/Consumer）时。std::future,\r\nstd::promise, std::packaged_task, 和 std::async\r\n共同构成了一个异步编程模型，其设计哲学是关注点分离 (Separation of\r\nConcerns)，将任务的执行、结果的传递和线程的管理清晰地解耦。\r\n核心组件：数据通信的\r\nfoundational elements\r\nstd::future 和 std::promise\r\n是实现异步数据传递最基础的两个构建块，它们分别代表了共享状态的“读取端”和“写入端”。\r\nstd::future：未来的凭证/读取端口\r\nstd::future\r\n是一个模板类，可以看作是一个异步结果的代理或占位符。当你启动一个异步任务时，你会立即得到一个\r\nstd::future\r\n对象。这个对象本身并没有包含计算结果，但它承诺在未来的某个时刻，你可以通过它来获取结果。\r\n主要操作： - get():这是 std::future 最核心的函数,\r\n它会阻塞当前线程，直到异步任务完成并返回结果（或抛出异常）。\r\n- get() 只能被调用一次。调用后，std::future 对象的状态会变为无效。 -\r\nwait():阻塞当前线程，直到结果可用，但不获取结果. 这个函数可以多次调用。\r\n- wait_for() /\r\nwait_until():等待一段时间或等到一个指定的时间点。如果在超时前结果准备好了，它会返回\r\nstd::future_status::ready。 - valid():检查 std::future\r\n对象是否与一个共享状态关联，即是否有效。在调用 get() 之后，valid()\r\n会返回 false。\r\n你不能直接创建一个 std::future，它总是通过以下三种方式之一获得： -\r\nstd::promise 的 get_future() 方法。 - std::packaged_task 的 get_future()\r\n方法。 - std::async 函数的返回值。\r\nstd::promise：一个承诺/写入端口\r\nstd::promise\r\n对象可以被看作是一个可以被写入一次的容器，它承诺在未来的某个时刻会提供一个\r\nT 类型的值(或异常), 从而使关联的 std::future 变为就绪状态。\r\n主要操作:\r\n\r\n关联Future: 调用std::future\r\nget_future()来创建共享状态，并返回一个与该 promise 相关联的 std::future\r\n对象。此方法对于每个 promise 对象只能调用一次。\r\n设置结果:\r\n\r\nvoid set_value(const T&amp; value) / void set_value(T&amp;&amp;\r\nvalue): 将一个值存入共享状态，并使关联的 std::future 变为就绪状态。\r\nvoid set_exception(std::exception_ptr p):\r\n将一个异常存入共享状态，并使关联的 std::future 变为就绪状态。\r\n这些设置操作同样是一次性的。对同一个 promise 多次调用 set_value 或\r\nset_exception 会抛出异常。\r\n\r\n\r\n工作流程： - 在发起任务的线程（消费者线程）中创建一个 std::promise\r\n对象。 - 消费者线程通过调用 promise.get_future() 来获取一个与之关联的\r\nstd::future 对象, 并等待该 future 变为就绪状态。 - 消费者线程将\r\nstd::promise 对象（通常通过移动\r\nstd::move）传递给将要执行异步任务的新线程(生产者线程)。 - 通常通过\r\nstd::thread 的构造函数传递 promise, 此时工作函数需要接收 promise\r\n对象作为参数。 - 新线程执行计算，当得到结果后，调用\r\npromise.set_value(result) 将结果存入 promise。如果发生错误，可以调用\r\npromise.set_exception(exception_ptr) 来存入一个异常。 - 一旦 set_value()\r\n或 set_exception() 被调用，与之关联的 std::future 就会变为“就绪” (ready)\r\n状态。 - 此时，在消费者线程中对 future 调用的 get()\r\n将会立即返回结果（或抛出异常），不再阻塞。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;#include &lt;chrono&gt;void compute_task(std::promise&lt;int&gt; p) {    try {        std::cout &lt;&lt; \"Worker thread is performing calculations...\" &lt;&lt; std::endl;        std::this_thread::sleep_for(std::chrono::seconds(2));        int result = 42;        // 承诺兑现，将结果放入 promise        p.set_value(result);     } catch (...) {        // 如果发生异常，可以将异常放入 promise        p.set_exception(std::current_exception());    }}int main() {  // 消费者线程    // 1. 创建一个 promise 对象    std::promise&lt;int&gt; p;  // 这里的int是任务的返回类型    // 2. 从 promise 获取 future，这是结果的“读取端”    std::future&lt;int&gt; f = p.get_future();  // 连接 promise 和 future    // 3. 创建一个新线程，并将 promise 的所有权转移给它    std::thread worker(compute_task, std::move(p));  // compute_task函数需要接收promise对象作为参数    std::cout &lt;&lt; \"Main thread is waiting for the result...\" &lt;&lt; std::endl;    // 4. 在主线程中调用 get() 等待结果    int result = f.get();  // // 这里会阻塞，直到 worker 线程调用了 p.set_value()    std::cout &lt;&lt; \"The result from worker thread is: \" &lt;&lt; result &lt;&lt; std::endl;    worker.join();    return 0;}\r\n这里的main 线程创建了 promise 和 future，将 promise\r\n移动到子线程，然后自己持有 future 等待结果; worker 线程接收 promise\r\n对象，执行任务，最后通过 p.set_value(42) 履行承诺，这个动作会唤醒在\r\nf.get() 处阻塞的 main 线程。\r\n高级抽象：任务与结果的绑定\r\nstd::packaged_task 和 std::async 是在 promise/future\r\n基础上构建的更高级抽象，它们将任务的执行与结果的传递机制更紧密地结合起来。\r\nstd::packaged_task&lt;T(Args…)&gt;：可调用对象与未来的封装\r\nstd::packaged_task 是一个模板类，它将任意可调用对象\r\n(Callable Object) 与 promise/future\r\n机制进行封装。它的主要目的是将一个函数的执行与其返回值的异步传递自动化。其模板参数是一个函数签名，例如\r\nint(int, double)。\r\n内部机制: - 构造: 当你用一个函数（如 my_func）创建一个\r\nstd::packaged_task&lt;T(Args…)&gt; task(my_func) 时，task 内部会创建一个\r\nstd::promise。 - 获取Future: 调用 task.get_future() 会返回与这个内部\r\npromise 相关联的 std::future。 - 执行: packaged_task\r\n对象本身是可调用的 (operator())。当你执行 task(args…)\r\n时，它会调用其内部包装的函数 my_func(args…), 捕获 my_func 的返回值,\r\n并自动使用该返回值调用内部 promise 的 set_value() 方法。如果 my_func\r\n抛出异常，它会捕获异常并调用 set_exception()。\r\n工作流程： - 创建一个可调用对象（例如一个函数或\r\nLambda）并用这个可调用对象来初始化一个 std::packaged_task。 - 通过\r\ntask.get_future() 获取与之关联的 std::future。 - 将 packaged_task\r\n对象移动到新线程。 - 在新线程中，像普通函数一样执行这个 task 对象。 -\r\n任务执行完毕后，其返回值会自动被 packaged_task 捕获并传递给关联的\r\nfuture。\r\n#include &lt;iostream&gt;#include &lt;thread&gt;#include &lt;future&gt;#include &lt;cmath&gt;// 一个耗时的计算任务long long calculate_factorial(int n) {    long long res = 1;    for (int i = 2; i &lt;= n; ++i) {        res *= i;    }    std::cout &lt;&lt; \"Task finished calculation.\" &lt;&lt; std::endl;    return res;}int main() {    // 1. 将函数包装成一个 packaged_task, 模板参数是函数的签名：long long(int)    std::packaged_task&lt;long long(int)&gt; task(calculate_factorial);    // 2. 从 task 获取 future    std::future&lt;long long&gt; f = task.get_future();    // 3. 将 task 移动到新线程    // 注意：这里传递的是 task 本身，而不是函数    std::thread worker(std::move(task), 10); // 计算 10!    std::cout &lt;&lt; \"Main thread is waiting for the factorial result...\" &lt;&lt; std::endl;    // 4. 等待并获取结果    long long result = f.get();    std::cout &lt;&lt; \"Factorial of 10 is: \" &lt;&lt; result &lt;&lt; std::endl;    worker.join();    return 0;}\r\n相比\r\nstd::async\r\nstd::async\r\n是一个函数模板，用于以异步方式（可能在一个单独的线程中）启动一个任务。它将线程创建、任务执行和结果返回的所有细节都封装了起来,\r\n相比于直接使用 std::thread，std::async\r\n提供了一种更高层次、更方便的抽象，特别适用于那些需要从异步任务中获取返回值的场景。\r\n简单来说，std::async 做了两件事： -\r\n启动一个可调用对象（如函数、lambda表达式）：它允许你安排一个任务去执行，而不必立即等待它完成。\r\n- 返回一个 std::future 对象：这个 std::future\r\n对象是一个“未来的凭证”，它最终会持有异步任务的返回值。你可以通过这个\r\nfuture 在稍后的时间点获取结果。\r\n这种模型被称为基于任务的并行 (Task-Based\r\nParallelism)，你关心的是“要完成什么任务”，而不是“具体要在哪个线程上完成”。\r\n基本用法\r\nstd::async 的基本语法如下： template&lt; class Function, class... Args &gt;std::future&lt;std::result_of_t&lt;std::decay_t&lt;Function&gt;(std::decay_t&lt;Args&gt;...)&gt;&gt;    async( Function&amp;&amp; f, Args&amp;&amp;... args );// 这里std::decay_t是类型萃取, 用于去掉引用、cv限定符和数组类型, 得到原始类型; 最终std::future的模板参数就是传入函数的返回类型\r\n让我们通过一个简单的例子来理解它的工作方式:\r\n假设我们有一个耗时的计算任务，我们不希望主线程被阻塞。 #include &lt;iostream&gt;#include &lt;future&gt;#include &lt;thread&gt;#include &lt;chrono&gt;// 一个模拟耗时计算的函数int time_consuming_calculation(int x) {    std::cout &lt;&lt; \"Worker thread is calculating...\" &lt;&lt; std::endl;    // 模拟耗时2秒    std::this_thread::sleep_for(std::chrono::seconds(2));    return x * x;}int main() {    std::cout &lt;&lt; \"Main thread started.\" &lt;&lt; std::endl;    // 1. 启动异步任务    // 通过 std::async 启动 time_consuming_calculation 函数，并传递参数 5。    // 这会立即返回一个 std::future&lt;int&gt; 对象。    std::future&lt;int&gt; future_result = std::async(time_consuming_calculation, 5);    // 2. 主线程继续执行其他任务    // 在异步任务执行的同时，主线程可以做别的事情。    std::cout &lt;&lt; \"Main thread is doing other work while waiting for the result...\" &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::seconds(1)); // 模拟其他工作    // 3. 获取异步任务的结果    // 调用 future_result.get() 来获取结果。    // 如果此时异步任务还没有完成，.get() 会阻塞当前线程，直到结果可用。    std::cout &lt;&lt; \"Main thread is waiting for the result...\" &lt;&lt; std::endl;    int result = future_result.get(); // .get() 会阻塞直到任务完成    std::cout &lt;&lt; \"The result is: \" &lt;&lt; result &lt;&lt; std::endl;    std::cout &lt;&lt; \"Main thread finished.\" &lt;&lt; std::endl;    return 0;} -\r\nstd::async(time_consuming_calculation, 5)：这行代码请求异步执行\r\ntime_consuming_calculation(5)。它可能会立即创建一个新线程来运行这个函数。\r\n- std::future future_result：std::async 返回一个 std::future\r\n对象。int 类型表示我们期望从异步任务中获得一个整数返回值。 -\r\nfuture_result.get()：这是关键部分。当主线程需要计算结果时，它调用\r\n.get()。 - 如果此时工作线程已经计算完毕，.get() 会立即返回结果。 -\r\n如果工作线程仍在计算，.get() 会阻塞主线程，直到计算完成并返回结果。 -\r\n注意：get() 只能被调用一次。再次调用会导致未定义行为。\r\n启动策略 (Launch Policy)\r\nstd::async\r\n的行为可以通过一个可选的“启动策略”参数来控制。这是一个非常重要的特性。\r\n// 明确指定启动策略auto future = std::async(std::launch::async, my_function); 主要的启动策略有两种： - std::launch::async:\r\n保证异步执行。系统必须创建一个新的线程来执行任务。当你需要真正的并行计算时，这是最常用的策略。\r\n- std::launch::deferred:\r\n延迟执行。任务不会立即在任何线程上启动。相反，它只会在返回的 std::future\r\n对象上调用 .get() 或 .wait() 时，才会在调用 .get()\r\n的那个线程上同步执行。用于实现惰性求值（Lazy\r\nEvaluation），即直到你真正需要结果时才进行计算。\r\n默认策略：std::launch::async | std::launch::deferred\r\n这是 std::async\r\n的默认行为。它给予了标准库实现的灵活性，可以根据系统负载或其他条件自行决定是创建一个新线程（async）还是延迟执行（deferred）。然而,\r\n这种不确定性可能导致程序行为难以预测。如果你需要保证并行性，强烈建议明确指定\r\nstd::launch::async。\r\nstd::async 与 std::thread\r\n的对比\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性\r\nstd::thread\r\nstd::async\r\n\r\n\r\n\r\n\r\n抽象层次\r\n低层次，直接操作线程\r\n高层次，关注于”任务”\r\n\r\n\r\n返回值\r\n没有直接获取返回值的机制（需借助 std::promise 或共享变量）\r\n通过返回的 std::future 对象轻松获取返回值\r\n\r\n\r\n异常处理\r\n如果线程函数抛出异常且未被捕获，程序会调用 std::terminate 终止\r\n异常会被 std::future 捕获，并在调用 .get() 时重新抛出\r\n\r\n\r\n线程管理\r\n需要手动调用 join() 或 detach()，否则程序在 std::thread\r\n对象析构时终止\r\nstd::future\r\n的析构函数会阻塞，直到异步任务完成，避免了线程被意外销毁\r\n\r\n\r\n系统开销\r\n总是创建一个新的操作系统线程\r\n(默认策略下) 可能不会创建新线程，由系统决定，可能更高效\r\n\r\n\r\n\r\n总结\r\n默认选择 std::async:\r\n对于大多数“执行一个函数并获取其结果”的场景，std::async\r\n因其简洁、安全（自动异常传递和资源管理）而成为首选。\r\n需要任务队列时选择 std::packaged_task:\r\n当你需要将任务对象化，以便存储、传递和由通用的执行器（如线程池）稍后执行时，std::packaged_task\r\n是正确的工具。\r\n需要手动信号控制时选择 std::promise:\r\n当结果的产生不与单个函数的返回直接对应，而是取决于复杂的逻辑或外部事件时，std::promise\r\n提供了必要的底层控制能力。\r\n","categories":["language","CPP","多线程"],"tags":["language"]},{"title":"三-五-零法则","url":"/2025/10/01/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/%E4%B8%89-%E4%BA%94-%E9%9B%B6%E6%B3%95%E5%88%99/","content":"这个法则是关于如何正确管理类中的资源（尤其是动态分配的内存），避免内存泄漏和悬挂指针等问题的指导方针。它们是C++语言演化过程中逐步形成的三个阶段性法则。\r\n法则一：三法则 (The\r\nRule of Three) - C++98/03时代\r\n核心思想：如果一个类需要程序员显式地定义析构函数、拷贝构造函数或拷贝赋值运算符\r\n中的任意一个，那么它极有可能也需要定义所有这三个。\r\n\r\n析构函数 (~MyClass())：释放类所拥有的资源。\r\n拷贝构造函数 (MyClass(const MyClass&amp;\r\nother))：用一个已存在的对象来创建一个新对象。\r\n拷贝赋值运算符 (MyClass&amp; operator=(const MyClass&amp;\r\nother))：将一个已存在对象的值赋给另一个已存在的对象。\r\n\r\n这个法则的根源在于手动资源管理。通常，你需要自定义这三个函数的唯一原因，就是你的类通过裸指针管理着动态分配的内存或其他资源（如文件句柄、网络连接等）。\r\n如果你需要 析构函数 -&gt; 说明你需要在对象销毁时释放资源（例如 delete\r\nptr;）。\r\n既然你需要释放资源，那么编译器自动生成的\r\n拷贝构造函数（它只会进行浅拷贝，即直接复制指针地址）就是错误的。因为它会导致两个对象指向同一块内存，造成重复释放。所以，你必须自己写一个深拷贝的版本。\r\n同理，编译器自动生成的\r\n拷贝赋值运算符也是浅拷贝，同样是错误的。它不仅会造成重复释放，还会导致内存泄漏（赋值前没有释放自己原有的内存）。所以，你也必须自己实现它。\r\n#include &lt;cstring&gt;#include &lt;iostream&gt;class String {public:    // 构造函数    String(const char* s = \"\") {        std::cout &lt;&lt; \"构造函数\\n\";        m_data = new char[strlen(s) + 1];        strcpy(m_data, s);    }    // 1. 析构函数 (触发三法则)    ~String() {        std::cout &lt;&lt; \"析构函数\\n\";        delete[] m_data;    }    // 2. 拷贝构造函数 (必须提供，否则会重复释放)    String(const String&amp; other) {        std::cout &lt;&lt; \"拷贝构造函数\\n\";        m_data = new char[strlen(other.m_data) + 1];        strcpy(m_data, other.m_data);    }    // 3. 拷贝赋值运算符 (必须提供，否则会内存泄漏+重复释放)    String&amp; operator=(const String&amp; other) {        std::cout &lt;&lt; \"拷贝赋值运算符\\n\";        if (this == &amp;other) { // 1. 检查自赋值            return *this;        }        delete[] m_data; // 2. 释放旧资源        m_data = new char[strlen(other.m_data) + 1]; // 3. 分配新资源        strcpy(m_data, other.m_data); // 4. 复制数据        return *this;    }private:    char* m_data;};\r\n法则二：五法则 (The\r\nRule of Five) - C++11及以后\r\n由于C++11引入了移动语义 (Move\r\nSemantics)，三法则扩展为了五法则。如果一个类定义了五个特殊成员函数中的任何一个，它应该把它们全部定义（或\r\n=delete 掉）。\r\n新增的两个特殊成员函数：\r\n\r\n移动构造函数\r\n(MyClass(MyClass&amp;&amp; other)\r\nnoexcept)：用一个将要被销毁的临时对象（右值）来创建新对象，通过“窃取”其资源来避免昂贵的拷贝。\r\n移动赋值运算符 (MyClass&amp;\r\noperator=(MyClass&amp;&amp; other)\r\nnoexcept)：从一个临时对象（右值）“窃取”资源。\r\n\r\n移动语义是C++11的重大性能提升。如果你的类管理着资源，你不仅要告诉编译器如何拷贝它，还应该告诉编译器如何移动它。因为移动操作（只是交换指针和设置nullptr）远比深拷贝（分配内存\r\n+ 复制数据）要快得多。\r\n如果你手动定义了拷贝操作（拷贝构造/拷贝赋值）或析构函数，编译器通常不会再自动为你生成移动操作。这会导致在需要移动的场合（例如从函数返回临时对象）被迫降级去执行昂贵的拷贝操作，从而丧失性能。\r\n// ... 在上面的 String 类中增加 ...// 4. 移动构造函数 (高效的资源“窃取”)String(String&amp;&amp; other) noexcept {    std::cout &lt;&lt; \"移动构造函数\\n\";    m_data = other.m_data;   // 1. 直接拿走资源    other.m_data = nullptr; // 2. 将源对象置为空，防止它析构时释放资源}// 5. 移动赋值运算符, 设置 noexcept 表示这个函数不会抛异常String&amp; operator=(String&amp;&amp; other) noexcept {    std::cout &lt;&lt; \"移动赋值运算符\\n\";    if (this == &amp;other) { // 1. 检查自赋值        return *this;    }    delete[] m_data;         // 2. 释放自己的旧资源    m_data = other.m_data;   // 3. 拿走对方的资源    other.m_data = nullptr; // 4. 将源对象置为空    return *this;}\r\n法则三：零法则\r\n(The Rule of Zero) - 现代C++最佳实践\r\n应该优先设计一个类，它不需要程序员编写任何自定义的析构函数、拷贝/移动构造函数或赋值运算符。\r\n因为手动编写这五个函数非常繁琐且极易出错（例如忘记检查自赋值、忘记处理异常安全等）。现代C++提倡将资源管理交给专门的类去做。\r\n具体实现方法, 可以通过使用C++标准库提供的RAII\r\n(Resource Acquisition Is Initialization)\r\n容器和智能指针来管理资源。\r\n\r\n用 std::string 代替 char* 来管理字符串。\r\n用 std::vector 代替裸数组。\r\n用 std::unique_ptr 或 std::shared_ptr\r\n代替裸指针来管理动态分配的对象。\r\n\r\n这些标准库组件本身已经完美地实现了五法则。你的类只需要包含它们作为成员，编译器自动生成的特殊成员函数就会正确地调用这些成员的对应函数。\r\n例如, 之前的 String 类可以简化为：\r\n#include &lt;string&gt;#include &lt;iostream&gt;class String {public:    String(const std::string&amp; s = \"\") : m_data(s) {        std::cout &lt;&lt; \"构造函数\\n\";    }    // ... 其他成员函数 ...    // 不需要写析构函数    // 不需要写拷贝构造函数    // 不需要写拷贝赋值运算符    // 不需要写移动构造函数    // 不需要写移动赋值运算符    // 编译器会为我们自动生成所有这些，并且它们都是正确的！private:    std::string m_data; // 使用 std::string 来管理资源};\r\n通过遵循零法则，你的类会变得更简单、更安全、更易维护，同时也能享受到现代C++的强大功能。\r\n总结\r\n法则 | 何时应用 | 核心内容 | 目标 |\r\n三法则 (遗留代码/C++98) 类中直接用裸指针管理资源。 如果定义了\r\n析构、拷贝构造、拷贝赋值 之一，就要定义全部三个，以实现深拷贝。\r\n避免浅拷贝导致的内存错误。 五法则 (C++11及以后)\r\n类中直接用裸指针管理资源，且需要高性能。 在三法则基础上，增加 移动构造\r\n和 移动赋值，以利用移动语义提升性能。 在安全的基础上，提供更高的性能。\r\n零法则 (现代C++最佳实践) 设计新类时。 不要用裸指针管理资源。使用\r\nstd::string, std::vector, std::unique_ptr\r\n等RAII工具，从而让编译器自动生成所有正确的特殊函数。\r\n让代码更简洁、更安全、更易维护，避免重复造轮子。\r\n"},{"title":"模板","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E6%A8%A1%E6%9D%BF/","content":"模板的哲学在于将一切能够在编译期处理的问题丢到编译期进行处理，仅在运行时处理那些最核心的动态服务，进而大幅优化运行期的性能。\r\n外部模板\r\n外部模板（extern template）\r\n是一种向编译器发出的指令，用于阻止编译器在当前翻译单元（也就是当前的\r\n.cpp\r\n文件）中隐式地实例化一个模板。它告诉编译器：“不必在此处生成这个模板的完整代码，我向你保证，它的代码会在其他某个地方被生成，链接器（Linker）最终会找到它。”\r\n它的主要，也是唯一的目标，就是减少编译时间和避免代码冗余。\r\nC++ 模板的默认工作方式\r\n要理解 extern template 的用处，首先必须了解 C++\r\n模板的默认工作方式，以及它带来的问题\r\n当你在代码中使用一个模板时，比如\r\nstd::vector，编译器会自动为你生成 std::vector 模板针对 int\r\n类型特化的所有代码。这个过程叫做隐式实例化。\r\n问题在于，如果你的项目中有多个 .cpp 文件都包含了 \r\n头文件，并且都使用了 std::vector，那么编译器会在每一个使用它的 .cpp\r\n文件中都生成一份完整的 std::vector 的代码。\r\n\r\na.cpp 使用了 std::vector -&gt; 编译器在 a.o 中生成一份\r\nstd::vector 的代码。\r\nb.cpp 使用了 std::vector -&gt; 编译器在 b.o 中也生成一份\r\nstd::vector 的代码。\r\nc.cpp 使用了 std::vector -&gt; 编译器在 c.o 中又生成一份\r\nstd::vector 的代码。\r\n……\r\n\r\n显然,\r\n这样重复生成同样的代码，不仅浪费了编译时间，还会导致生成的目标文件（.o\r\n文件）体积膨胀，链接器最终只会选择一个模板而丢弃多余的模板.o文件,\r\n最终影响链接时间和可执行文件的大小。\r\n解决方案：extern\r\ntemplate 与 显式实例化 组合拳\r\n为了解决上述问题，C++11 提供了 extern template\r\n关键字，允许你显式地告诉编译器在哪个翻译单元中实例化模板，而在其他翻译单元中则不进行实例化。\r\n\r\n选择一个地方进行显式实例化: 我们创建一个专门的 .cpp 文件（例如\r\ntemplates.cpp），或者在某个主要的 .cpp 文件中，来统一管理模板的实例化。\r\n// templates.cpp#include &lt;vector&gt;#include &lt;string&gt;// 显式实例化定义：强制编译器在此处生成代码template class std::vector&lt;int&gt;;template class std::vector&lt;std::string&gt;;\r\n在其他地方使用 extern template: 在所有其他需要使用这些模板的 .cpp\r\n文件中，使用 extern template 来告诉编译器不要在这些文件中实例化模板。\r\n// a.cpp#include &lt;vector&gt;extern template class std::vector&lt;int&gt;; // 告诉编译器不要在这里实例化void foo() {    std::vector&lt;int&gt; vec; // 使用 std::vector&lt;int&gt;，但不实例化}\r\n\r\n变长模板参数\r\n在 C++11 之前，无论是类模板还是函数模板，都只能按其指定的样子，\r\n接受一组固定数量的模板参数；而 C++11 加入了新的表示方法，\r\n允许任意个数、任意类别的模板参数，同时也不需要在定义时将参数的个数固定。\r\n核心语法\r\n变长模板的核心是一个名为 “参数包” (Parameter Pack)\r\n的概念，其语法中使用了省略号 …\r\n\r\n模板参数包 (Template Parameter Pack):\r\n用于声明一个可以接收零个或多个模板参数的包。\r\ntemplate &lt;typename... Args&gt; // Args 就是一个模板参数包class MyTuple {};\r\n函数参数包 (Function Parameter Pack):\r\n用于声明一个可以接收零个或多个函数参数的包。\r\ntemplate &lt;typename... Args&gt;void my_printf(const char* format, Args... args) { // args 就是一个函数参数包    // ...}\r\n包展开 (Pack Expansion):\r\n这是使用参数包的关键。你不能像遍历数组一样直接访问包中的每一个参数，而是需要通过“展开”的方式来一次性地处理它们,\r\n通过在参数包后面加上省略号 …，可以将参数包展开成多个独立的参数。\r\ntemplate &lt;typename... Args&gt;void my_printf(const char* format, Args... args) {    printf(format, args...); // 展开 args 包, args...将变为&lt;arg1, arg2, arg3, ...&gt;    // 这会被展开成 printf(format, arg1, arg2, arg3, ...);}\r\n获取包的大小: 可以使用 sizeof…(PackName)\r\n运算符来获取参数包中的参数数量 template &lt;typename... Args&gt;void print_num_args(Args... args) {    std::cout &lt;&lt; \"Number of arguments: \" &lt;&lt; sizeof...(args) &lt;&lt; std::endl;}\r\n\r\n如何使用参数包（包展开技巧）\r\n既然不能直接迭代，我们该如何处理包里的每一个参数呢？主要有以下几种方法，从经典到现代。\r\n方法一：递归函数（经典方式）\r\n这是C++11中最常用、最基础的展开方式。它包含两个部分： -\r\n一个处理包中第一个元素，并用剩余元素递归调用自身的递归函数。\r\n-\r\n一个用于终止递归的同名基本函数（当参数包为空时调用）。\r\n#include &lt;iostream&gt;// 3. 当参数包为空时，调用这个基本版本，终止递归void print() {    std::cout &lt;&lt; std::endl;}// 1. 递归模板函数template&lt;typename T, typename... Args&gt;  // 这里为了使得参数至少有一个, 显式指定了第一个参数 Tvoid print(T first, Args... rest) {    // 2. 处理包中的第一个参数    std::cout &lt;&lt; first &lt;&lt; \" \";    // 递归调用 print，传入剩余的参数包    print(rest...); // rest... 在这里被展开}int main() {    print(1, 2.3, \"hello\", 'c'); // 输出: 1 2.3 hello c}// 编译器的展开过程大致如下：// print(1, 2.3, \"hello\", 'c');// -&gt; std::cout &lt;&lt; 1 &lt;&lt; \" \"; print(2.3, \"hello\", 'c');// -&gt; std::cout &lt;&lt; 2.3 &lt;&lt; \" \"; print(\"hello\", 'c');// -&gt; std::cout &lt;&lt; \"hello\" &lt;&lt; \" \"; print('c');// -&gt; std::cout &lt;&lt; 'c' &lt;&lt; \" \"; print(); // 调用基本版本，递归结束\r\n方法二：使用 if constexpr 简化递归（C++17）\r\nC++17 的 if constexpr\r\n可以在编译期进行判断，使得我们可以将递归函数和基本函数合二为一，代码更简洁。\r\n#include &lt;iostream&gt;template&lt;typename T, typename... Args&gt;void print_cpp17(T first, Args... rest) {    std::cout &lt;&lt; first &lt;&lt; \" \";    // 如果 rest 包中还有参数 (sizeof...(rest) &gt; 0)    if constexpr (sizeof...(rest) &gt; 0) {        print_cpp17(rest...); // 递归调用    } else {        std::cout &lt;&lt; std::endl; // 所有参数处理完毕，打印换行    }}int main() {    print_cpp17(1, 2.3, \"hello\", 'c');}\r\n方法三：折叠表达式（C++17，最现代、最推荐）\r\n对于很多常见的操作（如求和、打印），C++17 提供了折叠表达式 (Fold\r\nExpressions)，这是一种极其简洁的包展开语法。 #include &lt;iostream&gt;#include &lt;string&gt;// 使用折叠表达式求和template&lt;typename... Args&gt;auto sum(Args... args) {    return (args + ...); // 对所有参数执行 operator+}// 使用折叠表达式打印，利用逗号运算符template&lt;typename... Args&gt;void print_fold(Args... args) {    // ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...); 的展开过程大致是：    // (std::cout &lt;&lt; arg1 &lt;&lt; \" \"), (std::cout &lt;&lt; arg2 &lt;&lt; \" \"), ...    // 逗号运算符会依次执行每个表达式    ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...);    std::cout &lt;&lt; std::endl;}int main() {    std::cout &lt;&lt; sum(1, 2, 3, 4, 5) &lt;&lt; std::endl; // 输出 15    print_fold(1, 2.3, \"hello\", 'c');             // 输出 1 2.3 hello c }\r\n折叠表达式(Fold Expressions)\r\n折叠表达式的本质，是提供一种极其简洁的语法，来将一个二元操作符\r\n(binary operator)，例如 +, *, &amp;&amp;, ||, ,\r\n等，重复地应用于参数包中的所有元素。\r\n想象一下你想对一包数字 1, 2, 3, 4 求和，你实际上想计算的是 1 + 2 + 3\r\n+ 4。折叠表达式就是让你能够直接表达这个意图的工具。\r\n折叠表达式一共有四种形式，它们在结合性（从左到右还是从右到左计算）和是否提供初始值方面有所不同。\r\n假设我们有一个参数包 pack，包含元素 E1, E2, E3, …\r\nEn，以及一个二元操作符 op。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n形式\r\n语法\r\n展开形式\r\n结合性\r\n\r\n\r\n\r\n\r\n一元右折叠\r\n(pack op ...)\r\nE1 op (E2 op (E3 op E4))\r\n右结合\r\n\r\n\r\n一元左折叠\r\n(... op pack)\r\n(((E1 op E2) op E3) op E4)\r\n左结合\r\n\r\n\r\n二元右折叠\r\n(pack op ... op init)\r\nE1 op (E2 op (E3 op (E4 op init)))\r\n右结合\r\n\r\n\r\n二元左折叠\r\n(init op ... op pack)\r\n((((init op E1) op E2) op E3) op E4)\r\n左结合\r\n\r\n\r\n\r\n\r\n一元折叠 (Unary Folds)：不提供显式的初始值。\r\n二元折叠 (Binary Folds)：提供一个显式的初始值 init。\r\n… 与 pack 的位置决定了展开的顺序（结合性）, … 在 pack\r\n右边是右折叠，在 pack 左边是左折叠。\r\n\r\n实例深度解析\r\n\r\n求和 template&lt;typename... Args&gt;auto sum(Args... args) {    // return (args + ...); // 一元左折叠。如果调用 sum()，编译会失败。    return (args + ... + 0); // 二元右折叠，更安全！    // 或者 return (0 + ... + args); // 二元左折叠，效果相同}// sum(1, 2, 3, 4, 5) 展开为:// 二元右折叠: (1 + (2 + (3 + (4 + (5 + 0)))))// 二元左折叠: (((((0 + 1) + 2) + 3) + 4) + 5)\r\n打印 template&lt;typename... Args&gt;void print_fold(Args... args) {    ((std::cout &lt;&lt; args &lt;&lt; \" \"), ...);  // 一元左折叠}\r\n\r\n\r\n操作符 op：这里是逗号操作符 ,。\r\n表达式：std::cout &lt;&lt; args &lt;&lt; ” ” 是应用到参数包 args\r\n中每个元素 arg 上的表达式。\r\n形式：这是一元右折叠 (pack op …)。\r\n展开过程：假设调用 print_fold(1, “hi”, 3.0)，它会展开成：((std::cout\r\n&lt;&lt; 1 &lt;&lt; ” “), (std::cout &lt;&lt;”hi” &lt;&lt; ” “),\r\n(std::cout &lt;&lt; 3.0 &lt;&lt;” “))\r\n\r\n逗号操作符的特性是“计算左边的表达式，丢弃其结果，然后计算右边的表达式，并返回其结果”。由于C++保证逗号操作符的求值顺序是从左到右的，尽管是右折叠,\r\n依旧完美地实现了按顺序打印每一个元素\r\n\r\n完美转发与函数调用\r\n折叠表达式可以极大地简化对参数包中每个元素执行同一操作的场景，例如将所有参数完美转发给另一个函数。\r\n#include &lt;vector&gt;#include &lt;utility&gt;// 一个将所有参数 push_back 到 vector 的函数template&lt;typename T, typename... Args&gt;void push_all(std::vector&lt;T&gt;&amp; vec, Args&amp;&amp;... args) {    // 对每个参数，调用 vec.push_back，并用逗号操作符连接    (vec.push_back(std::forward&lt;Args&gt;(args)), ...);}int main() {    std::vector&lt;int&gt; v;    push_all(v, 1, 2, 3, 4, 5); // v 中现在是 {1, 2, 3, 4, 5}}\r\n\r\n"},{"title":"类型转换","url":"/2025/09/30/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/","content":"C++ 的类型转换分为两大类：隐式类型转换和显式类型转换\r\n隐式类型转换 (Implicit\r\nType Conversion)\r\n隐式类型转换是由编译器自动进行的，无需程序员显式指定。这通常发生在以下几种情况：\r\n\r\n算术转换 (Arithmetic\r\nConversion)：在混合类型的算术表达式中，较小的类型会被提升（promote）为较大的类型以保证精度。\r\n// 例如：int 和 double 运算时，int 会被自动转换为 double。int i = 5;double d = 3.14;double result = i + d; // i 被隐式转换为 double 5.0，然后与 3.14 相加\r\n赋值转换 (Assignment\r\nConversion)：将一个类型的值赋给另一个类型的变量时。\r\n// 在此处，double 类型转换为 int 类型，会丢失精度，这是一种潜在的数据丢失风险。int i;double d = 9.8;i = d; // d 的值被截断，小数部分丢失，i 的值为 9\r\n指针转换 (Pointer\r\nConversion)：派生类的指针或引用可以被隐式转换为基类的指针或引用。这是支持多态性的基础。\r\nclass Base {};class Derived : public Base {};Derived* p_derived = new Derived();Base* p_base = p_derived; // 派生类指针隐式转换为基类指针Base* p_base2 = new Derived(); // 更多时候，直接 new 一个派生类对象赋给基类指针\r\n\r\n显式类型转换 (Explicit\r\nType Conversion)\r\n显式类型转换，也称为强制类型转换（Casting），是程序员明确要求的转换。C++\r\n从 C\r\n语言继承了强制转换的语法，并增加了四个功能更明确、更安全的转换操作符。\r\nC 风格强制转换 (C-Style Cast)\r\n这是从 C 语言继承来的语法，有两种形式：\r\n\r\n(new_type)expression\r\nnew_type(expression) int a = 10;int b = 4;double result = (double)a / b; // 将 a 转换为 double，结果为 2.5 C\r\n风格转换的缺点在于它过于强大和不安全，可能会执行多种不同类型的转换（如\r\nstatic_cast、const_cast、reinterpret_cast），这使得代码难以理解和维护。\r\n过于粗暴：C\r\n风格的转换符像一把“万能钥匙”，它会依次尝试\r\nstatic_cast、const_cast、reinterpret_cast，直到找到一个可以工作的。这使得它的行为难以预测，可能会执行一些非常危险的转换。\r\n意图不明：当你在代码中看到一个 C\r\n风格转换时，你很难一眼看出程序员的真实意图。他是想进行一个安全的数值转换，还是想进行一个危险的指针类型重解释？\r\n难以搜索：在大型项目中，想要找出所有的类型转换是非常困难的，因为\r\n() 符号在代码中太常见了。而 C++ 的 *_cast\r\n关键字则非常容易搜索。\r\n\r\nC++ 风格转换操作符\r\nC++\r\n引入了四个新的转换操作符，它们的功能更具体，意图更明确，也更安全。\r\nstatic_cast(expression):\r\n用于“良性”或“合理”的转换，其正确性在编译时检查就可以确定。它是最常用的转换操作符。\r\n\r\n相关类型之间的转换：如数值类型之间的转换（int 到\r\ndouble）、void* 指针与其他类型指针之间的转换。\r\n类层次结构中的转换：\r\n\r\n上行转换（安全）：将派生类的指针或引用转换为基类的指针或引用（与隐式转换相同）。\r\n下行转换（不安全）：将基类的指针或引用转换为派生类的指针或引用,\r\n由于这属于多态,\r\n而static_cast不进行运行时检查,\r\n因此这需要程序员自己保证转换是安全的，即基类指针确实指向一个派生类对象。\r\n// 1. 基本类型转换double d = 3.14;int i = static_cast&lt;int&gt;(d); // i 的值为 3// 2. 类层次结构转换 (下行转换)class Base { public: virtual ~Base() {} };class Derived : public Base {};Base* p_base = new Derived();// 程序员确信 p_base 指向的是一个 Derived 对象，可以进行下行转换Derived* p_derived = static_cast&lt;Derived*&gt;(p_base);\r\n\r\n\r\n这里的 static_cast\r\n进行了下行转换。但它不会在运行时进行检查。如果 p_base\r\n实际上指向的不是 Derived 对象，这个操作将导致未定义行为。\r\ndynamic_cast(expression):\r\ndynamic_cast专门用于处理多态类型，在运行时进行类型检查，以确保下行转换的安全性。\r\n主要用于安全的类层次结构下行转换：在多态（基类必须有虚函数）的类继承体系中，将基类指针/引用安全地转换为派生类指针/引用。\r\n\r\n运行时检查：它会检查转换是否有效。\r\n对指针操作：如果转换成功，返回指向派生类对象的指针；如果转换失败（即基类指针并非指向目标派生类对象），返回\r\nnullptr。\r\n对引用操作：如果转换成功，返回派生类的引用；如果转换失败，会抛出\r\nstd::bad_cast 异常。\r\n\r\n\r\n前提：必须用于至少包含一个虚函数（virtual\r\nfunction）的基类，因为它依赖于运行时类型信息（RTTI）。\r\n\r\n#include &lt;iostream&gt;class Base { public: virtual void who() { std::cout &lt;&lt; \"I am Base\\n\"; } };class Derived : public Base { public: void who() override { std::cout &lt;&lt; \"I am Derived\\n\"; } };class Other : public Base { public: void who() override { std::cout &lt;&lt; \"I am Other\\n\"; } };void check_type(Base* p) {    // 尝试将 Base* 转换为 Derived*, 这里 dynamic_cast 是创建一个新的指针变量，而不是改变原来指针的类型, 因此 p 本身的类型仍然是 Base*    Derived* p_derived = dynamic_cast&lt;Derived*&gt;(p);        if (p_derived != nullptr) {        std::cout &lt;&lt; \"Cast to Derived successful.\\n\";        p_derived-&gt;who();    } else {        std::cout &lt;&lt; \"Cast to Derived failed (p is not pointing to a Derived object).\\n\";    }}int main() {    Base* b1 = new Derived();    Base* b2 = new Other();        check_type(b1); // 输出: Cast to Derived successful. I am Derived    check_type(b2); // 输出: Cast to Derived failed (p is not pointing to a Derived object).    delete b1;    delete b2;    return 0;}\r\nconst_cast(expression): 是唯一能修改\r\nconst 或 volatile 属性的转换操作符,\r\n用于去除对象的常量性。它只能添加或移除 const/volatile\r\n属性，不能改变对象的实际类型。\r\n\r\n移除 const 属性：将一个 const 指针/引用转换为非 const\r\n指针/引用。\r\n增加 const 属性：将一个非 const 指针/引用转换为 const\r\n指针/引用（这通常是安全的，可以隐式完成，但也可以显式使用\r\nconst_cast）。\r\n\r\n\r\n使用 const_cast 移除 const 属性后，如果试图修改一个本身被定义为 const\r\n的对象，其行为是未定义的。它主要用于这样的场景：你有一个 const\r\n指针/引用，但你知道它指向的对象本身不是 const\r\n的，你需要调用一个不接受 const 参数的函数。\r\n\r\nvoid legacy_function(int* p) { // 一个老旧的、不接受 const 指针的函数    *p = 20;}int main() {    const int val = 10;    // legacy_function(&amp;val); // 错误：无法将 const int* 转换为 int*        // 警告：对原始的 const 变量进行修改是未定义行为！    // const_cast&lt;int*&gt;(&amp;val) 虽然可以通过编译，但运行时行为未定义！val完全可能存储在只读内存中。    // legacy_function(const_cast&lt;int*&gt;(&amp;val));     int non_const_val = 15;    const int* p_const = &amp;non_const_val;    // 这种情况是安全的，因为 p_const 指向的对象 non_const_val 本身不是 const    legacy_function(const_cast&lt;int*&gt;(p_const));     // 现在 non_const_val 的值是 20}\r\nreinterpret_cast(expression):\r\n用于低级别的重新解释类型，仅仅是重新解释给定的位模式，非常不安全。它通常用于与硬件打交道或进行底层编程。\r\n\r\n不同类型的指针之间转换：如将 int* 转换为 char*。\r\n指针与整数之间的转换：将指针转换为一个足以容纳它的整数类型，反之亦然。\r\n\r\n\r\n这是最危险的转换操作符。它不进行任何类型检查，只是简单地告诉编译器“把这些二进制位当成另一种类型来看待”。它几乎总是不可移植的，应仅在绝对必要时（如与硬件交互的底层代码）使用。\r\n\r\n#include &lt;iostream&gt;int main() {    int value = 0x41424344; // 在小端系统中代表 'D', 'C', 'B', 'A'    int* p_int = &amp;value;    // 将 int* 重新解释为 char*    char* p_char = reinterpret_cast&lt;char*&gt;(p_int);    // 逐字节打印整数的内存表示    for (int i = 0; i &lt; sizeof(int); ++i) {        std::cout &lt;&lt; *(p_char + i);    }    std::cout &lt;&lt; std::endl; // 在小端系统上输出：DCBA    return 0;}\r\n最佳实践：\r\n\r\n优先使用 C++\r\n风格转换：它们更安全、意图更明确、更易于搜索和维护。\r\n尽量避免转换：如果你的代码中充斥着大量的类型转换，这通常是设计不良的信号。考虑使用多态、模板或更好的设计模式来避免转换。\r\n选择最合适的转换符：\r\n\r\n当你需要在相关类型之间进行转换时，static_cast\r\n是首选。\r\n当你需要在多态类体系中安全地进行下行转换时，使用\r\ndynamic_cast。\r\n当你需要处理 const 或 volatile\r\n属性时（通常是为了兼容旧代码），只能使用 const_cast，并要格外小心。\r\n只有在进行非常底层的、与硬件相关的、并且你完全清楚自己在做什么时，才使用\r\nreinterpret_cast。\r\n\r\n\r\n"},{"title":"PIMPL","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/PIMPL/","content":"PIMPL (Pointer to Implementation) - 指向实现的指针,\r\n也被称为“编译防火墙 (Compilation Firewall)”或“不透明指针 (Opaque\r\nPointer)”。它的核心思想是将类的私有成员和私有方法从头文件中完全移除，放到一个独立的、只在\r\n.cpp\r\n文件中定义的实现类（Impl）中。头文件里只保留一个指向该实现类的指针。\r\n通过将类的接口与其实现细节分离，可以解决以下问题：\r\n\r\n降低编译依赖，大幅加快编译速度：这是\r\nPIMPL 最主要的目的。通常，如果一个类的头文件包含了其他头文件（例如\r\n, ），那么任何包含了这个类头文件的 .cpp\r\n文件，都会间接地依赖那些头文件。当你修改类的私有成员时（比如把\r\nstd::vector 换成\r\nstd::list），所有包含了该类头文件的文件都必须重新编译。在大型项目中，这可能意味着几分钟甚至几十分钟的编译时间。使用\r\nPIMPL 后，所有实现细节和依赖的头文件都转移到了 .cpp\r\n文件中。你修改私有实现时，只需要重新编译这个类自己的\r\n.cpp\r\n文件，链接器会处理好剩下的事情，从而极大地提升了编译效率。\r\n隐藏实现细节：头文件只暴露公有接口，所有内部数据结构、使用的第三方库等都被完全隐藏。这对于发布二进制库（SDK）的开发者来说非常有用。\r\n提供稳定的ABI (Application Binary\r\nInterface)：只要公有接口不变，你就可以在不破坏ABI兼容性的前提下，随意修改\r\nImpl\r\n类的内部实现（增删私有成员）。这意味着用户无需重新编译他们的代码，就可以直接使用新版本的动态库/静态库。\r\n\r\n假设我们有一个 Widget 类, 没有使用 PIMPL的情况如下：\r\n// Widget.h#pragma once#include &lt;string&gt; // 编译依赖#include &lt;vector&gt; // 编译依赖class Widget {public:    Widget();    void do_something();private:    std::string m_name;    std::vector&lt;int&gt; m_data;    // 任何包含 Widget.h 的文件都会被迫包含 &lt;string&gt; 和 &lt;vector&gt;    // 修改任何私有成员，所有包含者都需重编};\r\n使用 PIMPL 的版本 (After): // Widget.h#pragma once#include &lt;memory&gt; // 只需要包含智能指针class Widget {public:    Widget();    ~Widget(); // 关键：必须在头文件中声明析构函数    // 移动构造和移动赋值（可选，但推荐）    Widget(Widget&amp;&amp;);    Widget&amp; operator=(Widget&amp;&amp;);        // 拷贝构造和拷贝赋值（如果需要）    Widget(const Widget&amp;);    Widget&amp; operator=(const Widget&amp;);    void do_something();private:    class Impl; // 关键：前向声明实现类，不需要知道它的细节    std::unique_ptr&lt;Impl&gt; m_pimpl; // 关键：一个指向实现的指针};\r\n// Widget.cpp#include \"Widget.h\"#include &lt;string&gt;   // 实现所依赖的头文件只在这里包含#include &lt;vector&gt;   // 不会暴露给外部#include &lt;iostream&gt;// 关键：在这里完整定义实现类 Implclass Widget::Impl {public:    void do_something_impl() {        std::cout &lt;&lt; \"Doing something with \" &lt;&lt; m_name &lt;&lt; std::endl;        m_data.push_back(1);    }private:    std::string m_name;    std::vector&lt;int&gt; m_data;};// 关键：构造函数和析构函数必须在 Impl 类完全定义之后再定义Widget::Widget() : m_pimpl(std::make_unique&lt;Widget::Impl&gt;()) {}// 关键：析构函数必须在这里定义，否则 std::unique_ptr 会因为 Impl 类型不完整而出错Widget::~Widget() = default; // 其他成员函数只是简单地将调用转发给 Impl 对象void Widget::do_something() {    m_pimpl-&gt;do_something_impl();}// 移动和拷贝构造/赋值也需要在这里实现Widget::Widget(Widget&amp;&amp;) = default;Widget&amp; Widget::operator=(Widget&amp;&amp;) = default;// 拷贝构造需要深拷贝Widget::Widget(const Widget&amp; other)     : m_pimpl(std::make_unique&lt;Impl&gt;(*other.m_pimpl)) {} Widget&amp; Widget::operator=(const Widget&amp; other) {    if (this != &amp;other) {        *m_pimpl = *other.m_pimpl;    }    return *this;}\r\n从中我们可以看到，Widget\r\n类的头文件中不再包含任何实现细节和依赖的头文件。所有私有成员都被移到了\r\nImpl 类中，并且 Impl 类只在 Widget.cpp 中定义。 这样，当我们修改 Impl\r\n类的私有成员时，只有 Widget.cpp 需要重新编译，其他包含 Widget.h\r\n的文件不受影响，从而大大提升了编译效率\r\n总之, PIMPL 是一种设计模式，它利用 RAII\r\n技术来管理其实现对象的生命周期。在我们的 PIMPL\r\n示例中，std::unique_ptr m_pimpl;\r\n就是这种关系的体现。std::unique_ptr 是一个 RAII 包装器,\r\n它包装的资源是堆上分配的 Impl 对象。当 Widget 对象被销毁时，它的成员\r\nm_pimpl 也会被销毁。m_pimpl 的析构函数会自动 delete 它所拥有的 Impl\r\n对象，完美地实现了资源的自动管理。\r\n"},{"title":"面向对象","url":"/2025/09/26/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AF%AD%E8%A8%80%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BC%BA%E5%8C%96/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"\r\n"},{"title":"Socket编程","url":"/2025/09/25/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/socket%E7%BC%96%E7%A8%8B/","content":"预备知识\r\n网络字节序\r\n在计算机内存中，当一个数据类型（比如一个 32 位的整数\r\nint）占用多个字节时，就存在一个如何排列这些字节的顺序问题，这就是字节序\r\n(Byte Order) 或 Endianness (端序)。\r\n主要有两种字节序：\r\n\r\n小端字节序\r\n(Little-Endian)：将数据的低位字节存放在内存的低地址处。这是目前绝大多数本地个人电脑（如\r\nIntel, AMD 的 x86/x64 架构）使用的方式。\r\n大端字节序\r\n(Big-Endian)：将数据的高位字节存放在内存的低地址处。这更符合人类的阅读习惯（从高位读到低位）。一些服务器、网络设备和早期的\r\nPowerPC, MIPS 架构使用这种方式。\r\n\r\n举个例子：存储 16 位的整数 0x1234 (十进制的 4660)\r\n这里 0x12 是高位字节, 0x34 是低位字节。\r\n小端存储：内存低地址 -&gt; 0x34; 内存高地址 -&gt; 0x12\r\n大端存储：内存低地址 -&gt; 0x12; 内存高地址 -&gt; 0x34\r\n如果只是本地数据的读取, 小端序或者大端序都可以自洽;\r\n但是假如涉及到不同端序设备的网络通信,\r\n双方的端序不同步会产生难以想象的后果. 为了避免这种混乱，TCP/IP\r\n协议规定：所有在网络上传输的数据都必须统一使用大端字节序。这个统一的标准就被称为\r\n网络字节序 (Network Byte Order)。\r\n操作系统提供了一套标准的函数来在这两种字节序之间进行转换：\r\n| 函数 | 功能 | 说明 | |——|——|——| | htons() | Host to Network Short |\r\n将一个 16\r\n位（short）的数从主机字节序转换到网络字节序。主要用于端口号。|\r\n| htonl() | Host to Network Long | 将一个 32\r\n位（long）的数从主机字节序转换到网络字节序。主要用于 IPv4\r\n地址。| | ntohs() | Network to Host Short | 将一个 16\r\n位的数从网络字节序转换到主机字节序。| | ntohl() | Network to Host Long |\r\n将一个 32 位的数从网络字节序转换到主机字节序。|\r\n核心原则：在发送数据前，所有非字符型数据（如端口号、IP地址整数值）都应该使用\r\nhton() 系列函数转换为网络字节序(操作系统在调用 hton() 和\r\nntoh()\r\n系列函数时，会自动根据主机的字节序进行正确的转换)；在接收到数据后，应该使用\r\nntoh() 系列函数转换回主机字节序再使用。\r\nIP 地址转换函数\r\n我们已经知道，IP 地址(这里还是指传统的IPv4)有两种表示格式：\r\n\r\n点分十进制字符串格式 (Presentation Format)：方便人类阅读，例如\r\n“192.168.10.1”。\r\n整数格式 (Network Format)：方便计算机处理，是一个 32\r\n位的无符号整数，并且是网络字节序。\r\n\r\n我们需要一组函数来在这两种格式之间进行转换, 这些函数定义在\r\n&lt;arpa/inet.h&gt; 中:\r\n\r\nint inet_pton(int af, const char src, void dst);\r\n\r\n功能：将字符串 (p) 格式的 IP 地址转换为网络 (n)\r\n整数格式。pton 即 “IP to net”。\r\naf: 地址族，AF_INET 或 AF_INET6。\r\nsrc: 指向 IP 地址字符串的指针。\r\ndst: 指向转换后存放结果的内存地址（例如 struct in_addr\r\n的地址）。\r\n返回值为1代表成功; 0代表传入的src没有指向一个有效的IP地址;\r\n-1代表失败\r\n\r\nconst char inet_ntop(int af, const void src, char *dst,\r\nsocklen_t size);\r\n\r\n功能：将网络 (n) 整数格式的 IP\r\n地址转换为字符串 (p) 格式。ntop 即 “net to IP”。\r\n\r\n\r\nsockaddr 数据结构\r\nsocket 编程接口（如 bind,\r\nconnect）需要被设计成通用的，以便能够处理多种不同的网络协议（IPv4, IPv6,\r\nUNIX Domain Socket 等）。每种协议的地址结构都不同，例如：\r\n\r\nIPv4 地址需要：协议族、16 位端口号、32 位 IP 地址。\r\nIPv6 地址需要：协议族、16 位端口号、128 位 IP 地址，以及流信息和范围\r\nID。\r\n\r\n如果为每种协议都设计一套独立的函数，如 bind_ipv4(),\r\nbind_ipv6()，那将非常繁琐。\r\n为了解决这个问题，Socket API 设计了一个“基类”结构体 struct\r\nsockaddr。 struct sockaddr {    sa_family_t sa_family;  // 地址族 (AF_INET, AF_INET6, ...)    char        sa_data[14]; // 存放地址数据的区域};\r\n这是一个通用的、但内容模糊的结构体。我们几乎从不直接填充它。它的 sa_data\r\n区域设计得足够大，可以容纳当时最常见的地址类型。\r\n更常见的是, 我们使用专门用于 IPv4 的更清晰的 struct\r\nsockaddr_in: #include &lt;arpa/inet.h&gt; // 需要引入socket头文件struct sockaddr_in {    sa_family_t    sin_family; // 地址族, 必须是 AF_INET    in_port_t      sin_port;   // 16位端口号 (必须是网络字节序, 因此要使用htons转换一下)    struct in_addr sin_addr;   // 32位IP地址结构体 (内含一个整数, 必须是网络字节序)    char           sin_zero[8]; // 填充位, 必须全部置为0(默认不需要处理), 为了让此结构与sockaddr等长};// 这里 struct in_addr 内部只有一个成员：uint32_t s_addr;\r\n在实际使用过程中, 我们需要明确初始化sockaddr_in结构体,\r\n根据客户端和服务端分别初始化如下: #include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;cstring&gt; // for memset// 假设我们已经创建好了 socket 文件描述符 fd// int fd = socket(AF_INET, SOCK_STREAM, 0);// 1. 声明一个 sockaddr_in 结构体变量struct sockaddr_in server_addr;// 2.将结构体清零memset(&amp;server_addr, 0, sizeof(server_addr));// 3. 设置地址族为 IPv4server_addr.sin_family = AF_INET;// 4. 设置服务器的端口号// htons(9527) -&gt; 将端口号从主机字节序转换到网络字节序server_addr.sin_port = htons(9527);// 5. 设置服务器的 IP 地址// 使用 inet_pton 将点分十进制的 IP 字符串转换为网络字节序的整数// 并直接存入 server_addr.sin_addr 结构体中if (inet_pton(AF_INET, \"192.157.22.45\", &amp;server_addr.sin_addr) &lt;= 0) {    // 转换失败处理    perror(\"inet_pton failed\");    // exit or return}// 6. 现在，server_addr 已经准备就绪，可以用于 connect 函数// connect(fd, (struct sockaddr *)&amp;server_addr, sizeof(server_addr)); #include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;cstring&gt; // for memset// 假设我们已经创建好了 socket 文件描述符 fd// int fd = socket(AF_INET, SOCK_STREAM, 0);// 1. 声明一个 sockaddr_in 结构体变量struct sockaddr_in local_addr;// 2.【关键】将结构体清零memset(&amp;local_addr, 0, sizeof(local_addr));// 3. 设置地址族为 IPv4local_addr.sin_family = AF_INET;// 4. 设置服务器要监听的端口号local_addr.sin_port = htons(9527);// 5. 设置服务器的 IP 地址// 使用 INADDR_ANY 这个宏，它代表 \"0.0.0.0\", 这意味着监听本机所有网络接口（如有线网卡、无线网卡）上的连接请求// htonl() 将这个 32 位的地址从主机字节序转换到网络字节序local_addr.sin_addr.s_addr = htonl(INADDR_ANY);// 6. 现在，local_addr 已经准备就绪，可以用于 bind 函数// bind(fd, (struct sockaddr *)&amp;local_addr, sizeof(local_addr));\r\n网络套接字函数\r\nsocket模型创建流程\r\n\r\n如图, 一个完整的通信流程会涉及到(至少)三个socket,其中客户端一个,\r\n服务端两个. 客户端的比较直接, 我们主要关注服务端\r\n具体流程是, 当服务器端调用socket()函数时会产生一个监听套接字\r\n(Listening\r\nSocket)，而accept函数会阻塞监听套接字监听客户端连接，当有客户端过来连接的时候\r\n该函数会返回一个新的套接字, 称作已连接套接字 (Connected\r\nSocket)去和客户端连接\r\n监听套接字 (Listening Socket) - 创建者：socket()\r\n函数。 - 配置者：bind() 和 listen() 函数。 -\r\n核心职责：作为一个“连接工厂”，它的唯一使命是在指定的 IP:Port\r\n上监听并接收客户端发来的连接请求（TCP协议中的 SYN\r\n包）。 -\r\n数据交互：它从不参与应用层数据的收发。你永远不会对一个监听套接字使用\r\nsend() 或 recv() 函数。 -\r\n生命周期：通常在服务器程序启动时创建，并一直存在，直到服务器程序关闭。对于一个服务器而言，一个端口上通常只有一个监听套接字。\r\n已连接套接字 (Connected Socket) - 创建者：accept()\r\n函数。 -\r\n核心职责：作为与某一个特定客户端进行通信的专属通道。所有与该客户端的应用层数据（HTTP\r\n请求、数据库查询、聊天消息等）都通过这个套接字进行 send() 和 recv()。 -\r\n数据交互：它是数据传输的实际执行者。 -\r\n生命周期：当一个客户端连接成功时被创建，当与这个客户端的通信结束时（客户端断开或服务器主动关闭），这个套接字就会被\r\nclose()\r\n销毁。一个繁忙的服务器会频繁地创建和销毁成百上千个这样的套接字。\r\n正是这种“一个监听，多个连接”的模式，构成了所有网络服务器能够高效服务于众多客户端的基础架构。\r\nsocket() 函数\r\nsocket套接字本意是插座,\r\n意味着在数据通信过程中socket必须是成对出现的(客户端和服务端)\r\nsocket()\r\n函数的作用是在操作系统内核中创建一个通信的端点，并返回一个指向该端点的文件描述符\r\n(File Descriptor)。\r\n你可以将这个过程理解为向操作系统申请一部“电话机”。这部“电话机”本身还不知道要打给谁（没有目标地址），也不知道自己的号码（没有绑定端口），但它是后续所有通信操作的基础。在类\r\nUnix 系统（如\r\nLinux）中，这个返回的文件描述符与其他文件（如磁盘文件、管道）的描述符一样，可以被\r\nread(), write(), close() 等函数操作, 本质上也是一个文件。\r\n函数原型 (Function\r\nPrototype)及参数和返回值\r\nsocket() 函数通常在 C 语言的头文件 &lt;sys/socket.h&gt;\r\n中定义。其标准原型如下： #include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt; int socket(int domain, int type, int protocol);\r\n这个函数接收三个整数类型的参数，并返回一个整数。\r\n\r\ndomain：协议族 这个参数用于指定 Socket 使用的协议族 (Protocol\r\nFamily)。它决定了通信的地址格式和底层协议的范畴。\r\n\r\n换句话说, 这个参数告诉操作系统你打算进行哪一类的通信，例如是基于 IPv4\r\n的互联网通信，还是基于 IPv6，或者是仅限于本机内部的通信。\r\n常用值(主要是AF_INET)：\r\n\r\nAF_INET (Address Family Internet): 这是最常用的值，表示使用 IPv4\r\n协议族。网络地址将由 32 位的 IPv4 地址和 16 位的端口号组成。\r\nAF_INET6: 表示使用 IPv6 协议族。网络地址将由 128 位的 IPv6 地址和\r\n16 位的端口号组成。\r\nAF_UNIX (或 AF_LOCAL): 用于本机内部进程间通信\r\n(IPC)。它不使用网络协议，而是通过文件系统中的一个特殊文件（socket\r\n文件）来进行数据交换，效率非常高。\r\n\r\n\r\ntype：套接字类型 这个参数用于指定 Socket 的服务类型 (Service\r\nType)，它决定了通信的语义和行为。使用这个参数需要明确你需要的通信方式是可靠的、面向连接的（像打电话），还是快速的、无连接的（像寄明信片）。\r\n\r\n常用值： - SOCK_STREAM (Stream Socket): 流式套接字,\r\n提供面向连接、可靠的、基于字节流的服务。它通常与 TCP\r\n协议配合使用。 -\r\n数据传输前必须先建立连接。它保证数据传输是有序的、无差错的、无重复的。数据像水流一样，没有边界，你发送\r\n100 字节，对方可能一次性收到 100 字节，也可能先收到 40 字节再收到 60\r\n字节。 - 适用场景：绝大多数应用，如网页浏览 (HTTP)、文件传输\r\n(FTP)、邮件发送等。\r\n\r\nSOCK_DGRAM (Datagram Socket): 数据报套接字,\r\n提供无连接、不可靠的、基于数据报的服务。它通常与\r\nUDP 协议配合使用。\r\n\r\n通信前不需要建立连接。每个数据包（数据报）都是独立的，有自己的目标地址。它不保证数据能到达，也不保证到达的顺序。\r\n适用场景：对实时性要求高、能容忍少量丢包的场景，如在线游戏、视频直播、DNS\r\n查询。\r\n\r\n\r\n\r\nprotocol：具体协议\r\n这个参数用于指定在前两个参数确定的协议族和套接字类型下，还想进一步使用的具体协议。因为在某些协议族中，可能有多种协议支持同一种套接字类型。这个参数允许你精确指定。\r\n\r\n不过大部分情况下使用 0 即可：这是最常用的值。表示让操作系统根据\r\ndomain 和 type 的组合自动选择默认的协议, 等同于下列手动指定:\r\nsocket(AF_INET, SOCK_STREAM, IPPROTO_TCP); // 创建tcp的sock\r\nsocket(AF_INET, SOCK_DGRAM, IPPROTO_UDP); //\r\n创建udp的sock\r\n\r\n返回值 (Return Value)\r\n\r\n成功时：返回一个非负整数，这个整数就是套接字描述符\r\n(Socket Descriptor)，也常被称为文件描述符。它是这个新创建的 Socket\r\n的唯一标识。后续所有的 Socket 相关函数（如 bind(), connect(), listen()\r\n等）都将使用这个描述符作为参数。\r\n失败时：返回 -1。同时，全局变量 errno\r\n会被设置为一个特定的错误码，以指示失败的原因。我们可以通过 perror()\r\n函数或 strerror(errno)\r\n来查看具体的错误信息。常见的错误原因包括：权限不足、协议不支持、系统资源耗尽等。\r\nsocket()函数简单示例\r\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;errno.h&gt; // For errno variable#include &lt;string.h&gt; // For strerror functionint main() {    int tcp_socket_fd;    int udp_socket_fd;    // --- 1. 创建一个用于 IPv4 的 TCP 套接字 ---    // 步骤说明：调用 socket 函数，指定协议族为 AF_INET (IPv4)，    // 类型为 SOCK_STREAM (TCP)，协议让系统自动选择 (0)。    tcp_socket_fd = socket(AF_INET, SOCK_STREAM, 0);    // 步骤说明：检查返回值。如果为 -1，则表示创建失败。    // 使用 perror 可以打印出更详细的错误原因。    if (tcp_socket_fd == -1) {        perror(\"Create TCP socket failed\");        exit(EXIT_FAILURE);    }    printf(\"TCP socket created successfully! File Descriptor: %d\\n\", tcp_socket_fd);    // --- 2. 创建一个用于 IPv4 的 UDP 套接字 ---    // 步骤说明：与上面类似，只是将套接字类型改为 SOCK_DGRAM (UDP)。    udp_socket_fd = socket(AF_INET, SOCK_DGRAM, 0);        if (udp_socket_fd == -1) {        perror(\"Create UDP socket failed\");        exit(EXIT_FAILURE);    }    printf(\"UDP socket created successfully! File Descriptor: %d\\n\", udp_socket_fd);    // ... 之后可以对这两个 socket_fd 进行 bind, connect, send, recv 等操作 ...        // 最后需要关闭套接字    // close(tcp_socket_fd);    // close(udp_socket_fd);    return 0;}\r\nbind()函数\r\nbind 函数的作用是给套接字“绑定”一个地址。在我们之前的比喻中，socket()\r\n函数只是创建了一个“电话机”，而 bind\r\n函数就是向电信局申请一个具体的电话号码（IP 地址 +\r\n端口号）并分配给这部电话机。\r\n对于服务器来说，这是一个必须的步骤，因为客户端必须知道服务器的“地址”才能发起连接。\r\n函数原型及参数解释如下: #include &lt;sys/socket.h&gt;int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); - int sockfd: 由 socket()\r\n函数返回的套接字文件描述符。 - const struct sockaddr addr:\r\n由const可知是传入参数, 是一个指向 sockaddr\r\n结构体的指针。这正是我们之前讨论过的“预备知识”的应用。我们通常会创建一个\r\nstruct sockaddr_in (for IPv4) 变量，填充好 sin_family, sin_port (端口)\r\n和 sin_addr (IP 地址)，然后将其指针强制转换为 (struct sockaddr )\r\n再传递给 bind。 - socklen_t addrlen: addr\r\n指向的地址结构体的确切大小，通常使用 sizeof(struct sockaddr_in)。 -\r\n返回值: 成功返回 0; 失败返回 -1，并设置全局变量\r\nerrno。常见的失败原因包括：端口已被占用 (EADDRINUSE)、没有权限绑定该地址\r\n(EACCES)等。\r\n需要注意的是, bind 是服务器端专用的函数（客户端通常不需要），它在\r\nsocket() 创建套接字之后、listen() 开始监听之前被调用。\r\nlisten() 函数\r\nlisten\r\n函数的作用是让套接字进入“被动监听”模式以及设置最多同时连接数。一个普通的套接字（由\r\nsocket()\r\n创建）既可以主动发起连接（作为客户端），也可以被动接收连接（作为服务器）。一旦调用\r\nlisten，这个套接字就从一个“主动”套接字转变为一个“被动”的、专门用于接收连接请求的监听套接字。\r\n在我们之前的比喻中，这相当于把公司的总机电话设置为“等待来电”状态，并告诉交换机系统，可以开始向这个号码派发来电了。\r\n函数原型及参数解释: #include &lt;sys/socket.h&gt;int listen(int sockfd, int backlog); - int sockfd:: 已经被 bind()\r\n绑定了地址的套接字文件描述符。 - int\r\nbacklog:一个非常重要的参数，它规定了内核为这个监听套接字维护的“待处理连接队列”的最大长度。当服务器非常繁忙，来不及\r\naccept()\r\n新的连接时，新来的连接请求会先被放入这个队列中排队。如果队列已满，新的客户端连接请求可能会被拒绝。这个值的大小需要根据服务器的负载能力来设置，一个常见的值是\r\nSOMAXCONN (一个由系统定义的较大值)。 - 返回值: 成功返回 0; 失败返回\r\n-1，并设置 errno。\r\n同样, listen 也是服务器端专用的函数，在 bind() 之后、accept()\r\n之前被调用。\r\naccept() 函数\r\naccept\r\n函数是服务器从“待处理连接队列”中取出一个连接请求，并创建一个全新的套接字来与该客户端通信。accept\r\n接收的 sockfd 是监听套接字，而它返回的是一个全新的已连接套接字。\r\n这是一个阻塞函数：如果队列中没有已完成的连接，程序会在这里暂停，直到有客户端连接进来为止。\r\n函数原型及参数解释: #include &lt;sys/socket.h&gt;int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); - int sockfd:\r\n正在监听的那个监听套接字的文件描述符。 - struct sockaddr addr\r\n(可选): 没有const, 因此很大可能(实际上也就是)传出参数, 是一个指向\r\nsockaddr\r\n结构体的指针，用于接收客户端的地址信息。当函数成功返回时，内核会把发起连接的客户端的\r\nIP 和端口填充到这个结构体中。如果你不关心客户端的地址，可以把它设为\r\nNULL。 - socklen_t addrlen (可选): 一个指向 socklen_t\r\n变量的指针。在调用前，你需要把它指向的变量设置为 addr\r\n指向的缓冲区的最大长度 (sizeof(struct\r\nsockaddr_in))。函数返回后，这个变量的值会变为客户端地址结构体的实际长度。如果\r\naddr 是 NULL，这个参数也应为 NULL。 - 返回值;\r\n成功返回一个新的非负整数，这个整数就是新创建的已连接套接字的文件描述符。后续与该客户端的所有通信（send/recv）都将使用这个新的描述符;\r\n失败返回 -1，并设置 errno。\r\naccept 也是服务器端专用的函数，通常在 listen()\r\n之后的一个主循环中被反复调用。\r\nconnect() 函数\r\nconnect\r\n函数由客户端调用，用于向指定的服务器地址发起一个主动的连接请求。\r\n这个函数会触发 TCP\r\n协议的三次握手过程。它也是一个阻塞函数，在三次握手成功建立连接、或者超时/失败之前，程序会一直等待。\r\n函数原型及参数解释: #include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); - int sockfd: 客户端自己的、由\r\nsocket() 创建的套接字文件描述符。 - const struct sockaddr *addr:\r\n传入参数, 一个指向 sockaddr\r\n结构体的指针，里面包含了服务器的 IP\r\n地址和端口号。客户端必须准确地填充这个结构体，才能找到正确的服务器。 -\r\nsocklen_t addrlen: addr 指向的服务器地址结构体的确切大小。 - 返回值:\r\n成功返回 0。此时 TCP 连接已成功建立; 失败返回 -1，并设置\r\nerrno。常见的失败原因包括：服务器拒绝连接 (ECONNREFUSED)、网络不可达\r\n(ENETUNREACH)、连接超时 (ETIMEDOUT)等。\r\nconnect 是客户端专用的函数，在 socket() 创建套-接字之后被调用。\r\nClient-Server 示例\r\n下面是一个简单的 TCP 客户端-服务器示例，展示了如何使用上述的 socket\r\n函数进行基本的网络通信。 服务端/* * 程序名：server.cpp，一个简单的TCP回显服务器。 * 功能：接收客户端的请求报文，将其转换为大写后，再发回给客户端。 */#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;// 处理业务的主函数void HandleRequest(int client_sockfd);int main(int argc, char *argv[]){    if (argc != 2)    {        std::cout &lt;&lt; \"Using: ./server port\\nExample: ./server 5005\\n\\n\";        return -1;    }    // 第1步：创建服务端的socket。    int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_sockfd == -1)    {        perror(\"socket\");        return -1;    }    // 第2步：把服务端用于通信的地址和端口绑定到socket上。    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 任意ip地址    serv_addr.sin_port = htons(atoi(argv[1]));     // 指定端口    if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0)    {        perror(\"bind\");        close(listen_sockfd);        return -1;    }    // 第3步：把socket设置为监听模式。    if (listen(listen_sockfd, 5) != 0)    {        perror(\"listen\");        close(listen_sockfd);        return -1;    }    std::cout &lt;&lt; \"Server is listening on port \" &lt;&lt; argv[1] &lt;&lt; \"...\" &lt;&lt; std::endl;    // 第4步：接受客户端的连接。    while (true) // 主循环，使服务器可以一直接收新的连接    {        struct sockaddr_in client_addr;        socklen_t len = sizeof(client_addr);        // accept()会阻塞，直到有客户端连接上来        int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);  // 当有客户端连接时，accept() 函数会把客户端的地址信息（如 IP 和端口）填充到 client_addr 结构体里, 可以用于后续日志、鉴权等操作。        if (client_sockfd &lt; 0)        {            perror(\"accept\");            continue; // 继续等待下一个连接        }        char ipstr[INET_ADDRSTRLEN];        inet_ntop(AF_INET, &amp;client_addr.sin_addr, ipstr, sizeof(ipstr));        std::cout &lt;&lt; \"Client \" &lt;&lt; ipstr &lt;&lt; \" connected.\" &lt;&lt; std::endl;        // 调用主函数处理与客户端的通信        HandleRequest(client_sockfd);        // 然而只有HandleRequest函数返回后，才会继续回到这里，等待下一个客户端连接, 这意味着服务器是串行处理每个客户端的请求的    }    // 在实际应用中，服务器通常不会执行到这里，除非有明确的关闭指令    close(listen_sockfd);    return 0;}// 主函数，与客户端进行读写交互void HandleRequest(int client_sockfd){    char buffer[1024];    while (true)    {        memset(buffer, 0, sizeof(buffer));        // 接收客户端的请求报文 (read)        ssize_t bytes_received = read(client_sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0)        {            std::cout &lt;&lt; \"Received from client: \" &lt;&lt; buffer &lt;&lt; std::endl;            // 处理请求：将字符串转换为大写            for (int i = 0; buffer[i]; ++i)            {                buffer[i] = toupper(buffer[i]);            }            // 回应数据给客户端 (write)            if (write(client_sockfd, buffer, strlen(buffer)) &lt;= 0)            {                perror(\"write\");                break;            }            std::cout &lt;&lt; \"Sent to client: \" &lt;&lt; buffer &lt;&lt; std::endl;        }        else if (bytes_received == 0)        {            // read()返回0表示客户端已关闭连接            std::cout &lt;&lt; \"Client disconnected.\" &lt;&lt; std::endl;            break;        }        else        {            // read()返回-1表示发生错误            perror(\"read\");            break;        }    }    // 结束连接 (close)    close(client_sockfd);} 客户端/* * 程序名：client.cpp，一个简单的TCP客户端。 * 功能：向服务端发送请求，并接收服务端的回应。 */#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char *argv[]){    if (argc != 3)    {        std::cout &lt;&lt; \"Using: ./client ip port\\nExample: ./client 127.0.0.1 5005\\n\\n\";        return -1;    }    // 第1步：创建客户端的socket。    int sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (sockfd == -1)    {        perror(\"socket\");        return -1;    }    // 第2步：向服务器发起连接请求。    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(atoi(argv[2])); // 服务器端口    if (inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr) &lt;= 0)    {        perror(\"inet_pton\");        close(sockfd);        return -1;    }    // connect()会阻塞，直到连接成功或失败    if (connect(sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0)    {        perror(\"connect\");        close(sockfd);        return -1;    }    std::cout &lt;&lt; \"Connected to server \" &lt;&lt; argv[1] &lt;&lt; \":\" &lt;&lt; argv[2] &lt;&lt; std::endl;    // 第3步：与服务端通讯。    char buffer[1024];    std::string input;        std::cout &lt;&lt; \"Enter a message (or 'exit' to quit): \";    while (getline(std::cin, input) &amp;&amp; input != \"exit\")    {        // 请求数据 (write)        if (write(sockfd, input.c_str(), input.length()) &lt;= 0)        {            perror(\"write\");            break;        }        // 接收服务端的回应报文 (read)        memset(buffer, 0, sizeof(buffer));        ssize_t bytes_received = read(sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0)        {            std::cout &lt;&lt; \"Server response: \" &lt;&lt; buffer &lt;&lt; std::endl;        }        else if (bytes_received == 0)        {            std::cout &lt;&lt; \"Server disconnected.\" &lt;&lt; std::endl;            break;        }        else        {            perror(\"read\");            break;        }        std::cout &lt;&lt; \"\\nEnter a message (or 'exit' to quit): \";    }    // 第4步：关闭socket，结束连接。    close(sockfd);    std::cout &lt;&lt; \"Connection closed.\" &lt;&lt; std::endl;    return 0;}\r\n端口复用\r\n在开发和测试服务器程序时，肯定会遇到一个经典问题：第一次启动了服务器，它成功\r\nbind() 到 5005 端口并开始 listen(); 接着通过 Ctrl+C 强制关闭了服务器;\r\n然后立刻尝试重新启动服务器。\r\n此时，bind() 函数调用失败，程序打印出错误信息：bind: Address already\r\nin\r\nuse。我们不得不等待几十秒甚至几分钟后，才能再次成功启动服务器。这个问题在开发调试阶段非常影响效率，在生产环境中也可能导致服务中断时间变长。\r\n这个现象的根本原因在于 TCP 协议的一个重要状态：TIME_WAIT。\r\n回想TCP 四次挥手：当一个 TCP\r\n连接被关闭时（例如服务器或客户端程序退出），主动关闭连接的一方会进入\r\nTIME_WAIT 状态。这个状态会持续一段时间，通常是 2 * MSL (Maximum Segment\r\nLifetime，报文最大生存时间)，在 Linux 系统上一般是 60 秒。\r\n当我们的服务器程序关闭后，它所使用的套接字（绑定了例如\r\n127.0.0.1:5005）就进入了 TIME_WAIT\r\n状态。在此期间，操作系统认为这个端口仍然是“被占用的”，因此不允许任何新的套接字再次\r\nbind() 到完全相同的地址和端口上。\r\n为了解决这个问题，Socket API\r\n提供了一个非常有用的选项：SO_REUSEADDR。\r\n在设置 SO_REUSEADDR 选项后，它会告诉操作系统内核：“请允许我\r\nbind()到一个正处于 TIME_WAIT 状态的端口”。它放宽了 bind\r\n函数的校验规则，使得服务器可以在关闭后立刻重启，绕过 TIME_WAIT 状态对\r\nbind 的限制。\r\n这对于需要高可用性和快速重启的服务器应用程序来说，是必须设置的一个选项。\r\n要启用端口复用，我们需要在 bind() 函数被调用之前，使用 setsockopt()\r\n函数来设置监听套接字的属性, 其函数原型如下: #include &lt;sys/socket.h&gt;int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); - int sockfd:\r\n要设置的套接字文件描述符（这里是我们的 listen_sockfd）。 - int level:\r\n选项所在的协议层。对于端口复用，应设置为\r\nSOL_SOCKET，表示在通用套接字层进行设置。 - int optname:\r\n选项的名称。这里我们使用 SO_REUSEADDR。 - const void *optval:\r\n一个指向变量的指针，该变量包含了我们想设置的选项的值。对于开关型选项\r\nSO_REUSEADDR，我们通常用一个值为 1 的 int\r\n变量来表示“开启”。 - socklen_t optlen: optval\r\n指向的变量的大小，即 sizeof(int)。\r\n下面是一个启用端口复用的示例代码片段，展示了如何在创建监听套接字后、调用\r\nbind() 之前设置 SO_REUSEADDR 选项: /* * server.cpp 中 main 函数的相关部分 */// 第1步：创建服务端的socket。int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);if (listen_sockfd == -1){    perror(\"socket\");    return -1;}// ======================= 在这里添加端口复用设置 =======================// 作用：允许服务器在关闭后立即重启，而不会因为 TIME_WAIT 状态导致 \"Address already in use\"int opt = 1;if (setsockopt(listen_sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt)) != 0){    perror(\"setsockopt\");    close(listen_sockfd);    return -1;}// ====================================================================// 第2步：把服务端用于通信的地址和端口绑定到socket上。struct sockaddr_in serv_addr;// ... (后面的 bind, listen, accept 代码与之前完全相同)if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0){    // ...}\r\n总之, 端口复用 (SO_REUSEADDR) 是一个健壮的 TCP\r\n服务器程序必备的特性。它通过 setsockopt\r\n函数进行设置，允许程序重新绑定到处于 TIME_WAIT\r\n状态的端口，从而解决了服务器因异常关闭而无法立即重启的问题，极大地提高了开发效率和服务的可用性。\r\n","categories":["web","language","C++"],"tags":["web","C++"]},{"title":"多路IO转接/IO Multiplexing（I/O 多路复用）","url":"/2025/10/02/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5/%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5/","content":"在我们之前创建的最基础的 Client-Server\r\n模型中，服务器是迭代式的：它一次只能处理一个客户端。当\r\nHandleRequest 函数正在为一个客户端服务时，其他所有新的客户端都必须在\r\naccept 的队列中等待。这在实际应用中是完全不可接受的。\r\n而进一步为了解决并发问题，我们实现了两种朴素的思路：\r\n\r\n多进程模型：主进程负责 accept 连接，每当有新连接到来时，就\r\nfork() 一个新的子进程去专门处理这个连接。\r\n\r\n缺点：fork()\r\n的开销非常大，每个进程都有独立的内存空间，进程间通信复杂，系统能创建的进程数量有限。\r\n\r\n多线程模型：主线程负责 accept\r\n连接，每当有新连接到来时，就创建一个新的线程去处理。\r\n\r\n缺点：虽然比进程轻量，但线程仍然需要消耗系统资源（如栈内存）。当连接数达到成千上万时，创建同样数量的线程会消耗巨大内存，并且\r\nCPU\r\n需要花费大量时间在这些线程之间进行上下文切换，导致性能下降。\r\n\r\n\r\n这两种模型的共同问题是：一个执行流（进程/线程）绑定一个连接（Socket）。当连接数非常多时，这种模型的资源开销是无法承受的。\r\n而多路 I/O 转接（也常被称为“事件驱动\r\nI/O”）从根本上改变了这种模式。它的核心思想是：用一个进程（或线程）同时监视多个文件描述符（Socket），一旦其中一个或多个描述符的\r\nI/O\r\n条件就绪（例如，数据可读或可写），就能够得到通知，然后进行相应的处理。\r\n多路 I/O 转接的实现机制\r\n多路 I/O 转接的实现依赖于操作系统提供的特定机制，常见的有以下几种: -\r\nselect：最早的多路 I/O\r\n转接机制，支持监视多个文件描述符的读写状态。它使用一个位图来表示文件描述符集合，但有文件描述符数量的限制（通常是\r\n1024）。 - poll：类似于\r\nselect，但没有文件描述符数量的限制，使用一个数组来表示文件描述符集合，性能更好一些。\r\n- epoll（Linux 特有）：是对 poll\r\n的改进，支持更高效的事件通知机制，适合处理大量并发连接。epoll\r\n使用事件驱动模型，只有在文件描述符状态发生变化时才进行通知，避免了轮询所有文件描述符的开销。\r\n使用 select 实现多路 I/O 转接\r\nselect\r\n的核心功能是：允许程序同时监视多个文件描述符，等待一个或多个描述符进入“就绪”状态。\r\n核心数据结构：fd_set\r\n要使用 select，首先必须学会操作它的核心数据结构\r\nfd_set，即“文件描述符集合”。你可以把它理解为一个比特位图\r\n(bitmap)，其中每一位对应一个文件描述符的编号。\r\n操作系统提供了一组标准的宏来安全地操作 fd_set：\r\n\r\n**void FD_ZERO(fd_set *set)**;\r\n清空/置零整个集合。在每次使用前，这通常是第一步。\r\n**void FD_SET(int fd, fd_set *set)**: 将一个文件描述符 fd 添加到集合\r\nset 中。\r\n**void FD_CLR(int fd, fd_set *set)**: 将一个文件描述符 fd 从集合 set\r\n中移除。\r\n**int FD_ISSET(int fd, fd_set *set)**: 检查文件描述符 fd\r\n是否仍然在集合 set 中。这在 select 函数返回后使用，用于判断某个 fd\r\n是否是“就绪”的。\r\n\r\nselect 函数原型\r\n#include &lt;sys/select.h&gt;int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);\r\n\r\nint nfds:\r\n这是一个非常容易误解的参数。它不是你要监视的文件描述符的总数，而是所有被监视的文件描述符中最大值加\r\n1。例如，如果你要监视的 fd 是 3, 5, 8，那么 nfds 的值就应该是 8\r\n+ 1 = 9。\r\n\r\n原因：内核是以位图方式检查 fd_set\r\n的，这个参数告诉内核它需要检查到哪一位就可以了，以提高效率。\r\n\r\nfd_set *readfds: 指向一个 fd_set\r\n结构的指针，包含了所有你关心其“可读”事件的文件描述符。例如可以监听套接字看是否有新的连接请求到来;\r\n监听已连接套接字检查是否有数据从客户端发来。如果不关心任何“可读”事件，可以设为\r\nNULL。\r\nfd_set *writefds: 指向一个 fd_set\r\n结构的指针，包含了所有你关心其“可写”事件的文件描述符。一个套接字“可写”通常意味着它的\r\nTCP 发送缓冲区有足够的空间来接收新的数据。如果不关心，可以设为\r\nNULL。\r\nfd_set *exceptfds: 指向一个 fd_set\r\n结构的指针，用于监视异常条件。这在 TCP\r\n中用得较少，例如接收到带外数据。如果不关心，可以设为 NULL。\r\n\r\n重要的是, readfds, writefds, exceptfds\r\n这三个参数是传入传出参数。传入时, 你告诉内核你关心哪些\r\nfd ; 传出时（select返回后）, 内核会修改这些 fd_set，把其中没有就绪的 fd\r\n全部清除，只留下那些已经就绪的\r\nfd。这意味着，每次在循环中调用 select\r\n之前，你都必须重新设置这些 fd_set。\r\n\r\nstruct timeval *timeout: 用于设置 select\r\n的超时时间。struct timeval 结构包含秒和微秒。\r\n\r\n设为 NULL：永久阻塞，直到至少有一个 fd 就绪。\r\ntimeout 值为\r\n0：完全不阻塞，立即返回。这相当于进行一次非阻塞的轮询。\r\ntimeout 值大于 0：在指定的时间内阻塞等待。如果超时，select 会返回\r\n0。\r\n\r\n返回值: 如果 &gt; 0 表示就绪的文件描述符的总数就是返回值;\r\n返回0表示超时，没有任何文件描述符就绪; 返回-1表示发生错误，需要检查\r\nerrno。\r\n\r\n使用 select 的典型流程\r\n\r\n初始化 fd_set 集合，使用 FD_ZERO 清空集合，然后使用 FD_SET\r\n将所有需要监视的文件描述符添加进去。\r\n调用 select 函数，传入 nfds 和 fd_set 集合。\r\nselect 返回后，检查返回值:\r\n\r\n如果返回值 &gt; 0，表示有文件描述符就绪。使用 FD_ISSET\r\n检查每个文件描述符，找出哪些是就绪的，并进行相应的读写操作。\r\n如果返回值 == 0，表示超时，没有任何文件描述符就绪。\r\n如果返回值 == -1，表示发生错误，检查 errno 以确定错误类型。\r\n\r\n重复上述过程，通常在一个循环中不断调用 select\r\n以持续监视文件描述符。\r\n\r\n#include &lt;vector&gt;#include &lt;algorithm&gt; // For std::max// ... (socket, bind, listen a listen_sockfd) ...fd_set master_fds; // 用于保存所有需要监视的 fdFD_ZERO(&amp;master_fds);FD_SET(listen_sockfd, &amp;master_fds); // 将监听 socket 加入集合int max_fd = listen_sockfd; // nfds 参数需要while (true) {    // 1. 准备工作：select会修改集合，所以每次都需要从 master 复制一份    fd_set read_fds = master_fds;    // fd_set write_fds = ... (if needed)    // 2. 调用 select，阻塞等待事件    int ready_count = select(max_fd + 1, &amp;read_fds, NULL, NULL, NULL);    if (ready_count &lt; 0) {        perror(\"select\");        break;    }    // 3. 遍历所有可能的 fd，检查是哪个就绪了    for (int i = 0; i &lt;= max_fd; ++i) {        if (FD_ISSET(i, &amp;read_fds)) { // 检查 fd i 是否在返回的就绪集合中                        if (i == listen_sockfd) {                // 3a. 如果是监听 socket 就绪，表示有新连接                struct sockaddr_in client_addr;                socklen_t len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);                if (client_sockfd &lt; 0) { /* error */ }                // 将新的客户端 socket 添加到 master 集合中                FD_SET(client_sockfd, &amp;master_fds);                // 更新 max_fd                if (client_sockfd &gt; max_fd) {                    max_fd = client_sockfd;                }            } else {                // 3b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = i;                char buffer[1024];                ssize_t n = read(client_sockfd, buffer, sizeof(buffer));                                if (n &lt;= 0) {                    // 客户端断开连接或出错                    close(client_sockfd);                    // 将其从 master 集合中移除                    FD_CLR(client_sockfd, &amp;master_fds);                } else {                    // 处理数据...                    // write(client_sockfd, ...);                }            }        }    }}\r\nselect 的缺点\r\n尽管 select\r\n非常通用，但它的设计存在几个固有缺陷，导致其不适合大规模高并发场景：\r\n\r\n连接数限制：fd_set 的大小由 FD_SETSIZE 宏定义，通常是\r\n1024(因为单个进程文件描述符最大就是1024)，这硬性限制了服务器能处理的最大并发连接数。\r\n性能开销：\r\n\r\n重复拷贝：每次调用 select，都需要将包含所有 fd 的 fd_set\r\n从用户空间拷贝到内核空间(因为select是系统调用), 这在 fd\r\n数量很大时开销显著。\r\n无法直接定位触发事件的文件描述符,\r\n需要线性扫描：内核需要遍历所有传入的 fd\r\n来检查状态；select 返回后，用户程序也需要从 0 到 max_fd\r\n遍历一次，才能找出哪些 fd 真正就绪。这两个扫描的开销都与 max_fd\r\n的大小成正比。\r\n\r\n\r\n但优点是可以跨平台使用, 具有良好的兼容性。\r\n正是由于这些缺点，Linux 平台才引入了性能更优越的 epoll。但 select\r\n的编程模型——即将所有描述符放入一个集合，等待事件，然后处理就绪的描述符——是所有\r\nI/O 多路转接技术的基础。\r\n\r\n注意: 上述实现只是一个单线程 Reactor 模式, 并没有实现真正的并发处理.\r\n也就是说, 虽然一个线程可以同时监视多个连接的 I/O 事件, 但在事件处理阶段,\r\n仍然是串行处理每个就绪的连接. select 实现了 I/O\r\n等待的并发，但事件处理是串行的. 要实现真正的并发处理,\r\n仍然需要结合线程池等技术. ### 使用 poll 实现多路 I/O 转接\r\n\r\npoll 的核心功能与 select\r\n完全相同：允许程序在一个地方阻塞，同时监视多个文件描述符的 I/O\r\n事件。\r\n核心数据结构：struct pollfd\r\npoll 不再使用繁琐的 fd_set 和宏，而是引入了一个更直观的结构体 struct\r\npollfd。你需要为每一个你关心的文件描述符创建一个这样的结构体。\r\n#include &lt;poll.h&gt;struct pollfd {    int   fd;         /* file descriptor: 你要监视的文件描述符 */    short events;     /* requested events: 你关心的事件 (输入参数) */    short revents;    /* returned events:  实际发生的事件 (输出参数) */}; - int fd: 你要监视的文件描述符的编号。如果你想让 poll\r\n忽略这个 pollfd 元素，可以将 fd 设置为 -1。 - short events:\r\n这是一个输入参数，由你来设置。它是一个位掩码，用来告诉内核你对这个 fd\r\n关心哪些事件。常用事件包括： - POLLIN:\r\n普通或优先级数据可读。 - POLLOUT:\r\n普通数据可写。 - POLLERR: 发生错误。 - short revents:\r\n这是一个输出参数，由内核来设置。当 poll\r\n函数返回后，内核会修改这个成员，用一个位掩码来表明该 fd\r\n上实际发生了哪些事件。你可以通过位运算来检查 revents\r\n中是否包含你关心的事件，例如 if (pfd.revents &amp;\r\nPOLLIN)。\r\npoll 函数原型及示例\r\nint poll(struct pollfd *fds, nfds_t nfds, int timeout);\r\n\r\nstruct pollfd *fds: 一个指向 pollfd\r\n结构体数组的第一个元素的指针。这个数组包含了所有你希望监视的文件描述符及其事件。\r\nnfds_t nfds: fds\r\n数组中元素的总数量。这个参数比 select 的 nfds 直观得多。\r\nint timeout: poll 函数的超时时间，单位是毫秒\r\n(milliseconds)。\r\n\r\n-1: 永久阻塞，直到有事件发生。\r\n0: 完全不阻塞，立即返回。\r\n某个数 &gt; 0: 在指定的毫秒数内阻塞等待。\r\n\r\n返回值: &gt;0 表示 fds 数组中 revents 成员不为 0\r\n的元素个数，即已就绪的文件描述符的数量; 0\r\n表示超时，没有任何文件描述符就绪; -1 表示发生错误，需要检查 errno。\r\n\r\n使用 poll 的服务器逻辑比 select\r\n更清晰，特别是当需要动态增删文件描述符时。使用 std::vector 来管理 pollfd\r\n数组非常方便。\r\n#include &lt;vector&gt;#include &lt;poll.h&gt;// ... (socket, bind, listen a listen_sockfd) ...std::vector&lt;struct pollfd&gt; poll_fds;// 将监听 socket 加入监视struct pollfd listen_pfd;listen_pfd.fd = listen_sockfd;listen_pfd.events = POLLIN; // 关心可读事件 (新连接)poll_fds.push_back(listen_pfd);while (true) {    // 1. 调用 poll，阻塞等待事件    // poll_fds.data() 获取指向 vector 内部数组的指针    int ready_count = poll(poll_fds.data(), poll_fds.size(), -1); // 永久阻塞    if (ready_count &lt; 0) {        perror(\"poll\");        break;    }    // 2. 遍历所有被监视的 fd，检查是哪个就绪了    for (size_t i = 0; i &lt; poll_fds.size(); ++i) {        if (poll_fds[i].revents &amp; POLLIN) { // 检查 revents 字段            if (poll_fds[i].fd == listen_sockfd) {                // 2a. 如果是监听 socket 就绪，表示有新连接                struct sockaddr_in client_addr;                socklen_t len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;len);                if (client_sockfd &lt; 0) { /* error */ }                // 将新的客户端 socket 添加到监视列表                struct pollfd client_pfd;                client_pfd.fd = client_sockfd;                client_pfd.events = POLLIN;                poll_fds.push_back(client_pfd);            } else {                // 2b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = poll_fds[i].fd;                char buffer[1024];                ssize_t n = read(client_sockfd, buffer, sizeof(buffer));                if (n &lt;= 0) {                    // 客户端断开连接或出错                    close(client_sockfd);                    // 将其从监视列表中移除 (简单起见，这里设置为-1，实践中可能需要更高效的移除方式)                    poll_fds[i].fd = -1;                 } else {                    // 处理数据...                    // write(client_sockfd, ...);                }            }        }    }    // (实践中，可以在循环后清理所有 fd 为 -1 的元素)}\r\npoll 相对于 select 的优缺点\r\n优点:\r\n解决了连接数限制：poll 使用 pollfd 数组，而不是\r\nfd_set\r\n位图，因此它监视的文件描述符数量只受限于系统资源（如内存大小、进程最大文件描述符数），没有了\r\nselect 的 1024 个硬性限制。\r\n数据结构更清晰：pollfd 结构体将 fd、关心的 events\r\n和发生的 revents 整合在一起，比 select 分离的三个 fd_set\r\n更易于管理。\r\n无需每次重置：poll 的 events 字段是输入参数，revents\r\n是输出参数，两者是分开的。内核不会修改 events\r\n字段，因此在循环中你不需要像 select\r\n那样每次都重置你关心的事件列表（除非你的确想动态改变它）。\r\n依然存在的缺点:\r\npoll 和 select 在本质上是同一种工作模式，因此它们有共同的性能瓶颈,\r\n主要是性能开销例如重复拷贝, 每次调用 poll，都需要将整个 pollfd\r\n数组从用户空间完整地拷贝到内核空间; 还有线性扫描.\r\n当连接数非 常多时（例如上万个），内核为了找出就绪的\r\nfd，仍然需要遍历整个数组。poll 返回后，用户程序也需要遍历整个数组来检查\r\nrevents 字段。这个 O(n) 的开销在大并发场景下是致命的。\r\n总之, poll 是 select\r\n的一个直接且有效的改进版，主要解决了连接数限制的问题。但它并没有解决核心的性能问题，而\r\nepoll 则通过完全不同的事件通知机制，从根本上解决了这两个性能瓶颈。\r\n使用 epoll 实现多路 I/O 转接\r\nepoll 的出现，标志着 I/O\r\n事件通知从“轮询模式”向“通知模式”的根本性转变。\r\n\r\nselect/poll 的模式：“你好，内核。请帮我看看我这一大堆 Socket\r\n里，有没有人准备好了？我在这里等着你检查完告诉我。”\r\n(应用进程主动轮询)\r\nepoll 的模式：“你好，内核。这是我关心的所有 Socket\r\n列表，你先记一下。以后哪个 Socket\r\n准备好了，你再主动通知我。我先去忙别的了。” (内核主动通知)\r\n\r\nepoll 之所以高效，主要得益于两个核心机制，完美解决了 select/poll\r\n的两大性能瓶颈。\r\n\r\n解决“内存拷贝”：内核与用户空间共享内存 (mmap)\r\n当你调用 epoll_create 创建 epoll\r\n实例时，内核不仅会创建一个事件表，还会开辟一块特殊的内核缓冲区，并通过内存映射\r\n(mmap)\r\n技术与用户空间共享。这个区域专门用来存放“已就绪”的文件描述符列表。当\r\nepoll_wait\r\n返回时，它不需要从内核空间向用户空间拷贝整个庞大的列表，而是直接让用户空间可以访问这块共享内存，大大提高了效率。\r\n解决“线性扫描”：基于回调的事件通知机制 当你使用\r\nepoll_ctl 将一个 Socket fd 注册到 epoll 实例时，内核会将这个 fd 与 epoll\r\n实例关联，并在这个 Socket 的内部等待队列上注册一个“回调函数”。当这个\r\nSocket\r\n接收到数据时，会触发一个中断，内核在处理这个中断时，会执行这个回调函数。这个回调函数的任务很简单：将这个就绪的\r\nSocket fd 添加到 epoll\r\n实例的“就绪列表”中（就是上面提到的那块共享内存区域）。\r\n因此，epoll_wait\r\n函数的工作就变得极其简单：它只需要检查一下“就绪列表”是否为空。如果不为空，就将列表返回给用户程序并唤醒进程。这个过程的时间复杂度是\r\nO(1)，与你监视的连接总数完全无关！\r\n\r\nepoll 的三大核心函数\r\nepoll 的所有操作都围绕这三个函数展开。\r\nint epoll_create(int size): -\r\n功能：在内核中创建一个 epoll\r\n实例，并返回一个指向该实例的文件描述符（epoll fd）。 - size\r\n参数在早期版本的 Linux\r\n内核中用于提示内核事件表的大小，但在现代内核中此参数已被忽略，只要是一个正数即可。\r\n- 这个返回的 epfd 是后续所有 epoll\r\n操作的句柄。\r\n**int epoll_ctl(int epfd, int op, int fd, struct epoll_event\r\n*event): - 功能：epoll 的控制接口，用于向 epfd\r\n指向的 epoll\r\n实例中添加、修改或删除被监视的文件描述符。\r\n- epfd: epoll_create 返回的句柄。 - op:\r\n操作类型，主要有三种： - EPOLL_CTL_ADD: 添加一个新的 fd\r\n到 epoll 实例中。 - EPOLL_CTL_MOD: 修改一个已经存在的\r\nfd 的监听事件。 - EPOLL_CTL_DEL: 从 epoll\r\n实例中删除一个 fd。 - fd: 所要监视的目标文件描述符（如 listen_sockfd 或\r\nclient_sockfd）。 - struct epoll_event *event:\r\n指向一个结构体，描述了你对 fd 关心的事件类型**。 struct epoll_event {    uint32_t     events;      /* Epoll events (bit mask) */    epoll_data_t data;        /* User data variable */};union epoll_data {    void        *ptr;    int          fd;    uint32_t     u32;    uint64_t     u64;};\r\n- events: 事件的位掩码，如 EPOLLIN (可读), EPOLLOUT (可写), EPOLLET\r\n(边缘触发)等。 - data: 一个联合体，这是 epoll\r\n的一大亮点。你可以将自定义数据（如 fd\r\n本身、一个指向对象/结构体的指针等）与事件关联起来。当 epoll_wait\r\n返回这个事件时，你也能拿到这个数据，极大地简化了编程。\r\n**int epoll_wait(int epfd, struct epoll_event *events, int maxevents,\r\nint timeout): - 功能：等待 epfd 上的 I/O\r\n事件。这是服务器主循环中唯一需要阻塞的地方。 -\r\nepfd: epoll_create 返回的句柄。 - struct epoll_event\r\n*events: 一个由用户程序分配的 epoll_event\r\n数组。当函数成功返回时，内核会将所有就绪的事件拷贝到这个数组中。\r\n- 注意它不是像上面的 epoll_ctl那样传入一个单独的 event\r\n结构体指针，而是传入一个数组，允许一次返回多个就绪事件。\r\n- maxevents: events\r\n数组**的大小，告诉内核最多可以返回多少个事件。 - timeout:\r\n超时时间（毫秒），与 poll 类似\r\n红黑树和就绪链表\r\nepoll 内部使用了两种非常高效的数据结构来管理文件描述符： 1.\r\n红黑树 (Red-Black Tree):\r\n用于存储所有被监视的文件描述符及其相关信息。红黑树是一种自平衡的二叉搜索树，能够在\r\nO(log n) 时间内完成插入、删除和查找操作。当你调用 epoll_ctl\r\n添加、修改或删除一个 fd 时，内核会在这棵红黑树上进行相应的操作。 -\r\n我们调用 epoll_create 创建 epoll 实例时，内核会初始化这棵红黑树, 返回的\r\nepoll fd 就是这棵树的根节点。 2. 就绪链表 (Ready List):\r\n用于存储所有当前就绪的文件描述符。当某个 fd 的 I/O\r\n条件满足时（例如数据可读），内核会将这个 fd 添加到就绪链表中。epoll_wait\r\n只需要检查这个链表，而不需要遍历所有被监视的 fd。\r\nepoll 使用示例\r\n/* * 程序名：epoll_server.cpp, 一个基于 Epoll 的高并发 TCP 服务器。 * 功能：接收客户端的连接，并将客户端发来的消息原封不动地返回（Echo）。 * 特点：非阻塞 I/O + I/O 多路复用 (epoll)。 */#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt; // for fcntl#define MAX_EVENTS 1024 // epoll_wait 返回的最大事件数// 设置文件描述符为非阻塞模式void setnonblocking(int sockfd) {    fcntl(sockfd, F_SETFL, fcntl(sockfd, F_GETFL, 0) | O_NONBLOCK);    // fcntl 函数用于操作文件描述符的属性，这里我们通过 F_SETFL 设置文件状态标志为非阻塞 (O_NONBLOCK)}int main(int argc, char *argv[]) {    if (argc != 2) {        std::cout &lt;&lt; \"Usage: ./epoll_server port\\n\";        return -1;    }    // 1. 创建监听 socket    int listen_sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_sockfd &lt; 0) {        perror(\"socket\");        return -1;    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(listen_sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定地址和端口    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);    serv_addr.sin_port = htons(atoi(argv[1]));    if (bind(listen_sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {        perror(\"bind\");        close(listen_sockfd);        return -1;    }    // 3. 开始监听    if (listen(listen_sockfd, SOMAXCONN) &lt; 0) {        perror(\"listen\");        close(listen_sockfd);        return -1;    }    std::cout &lt;&lt; \"Epoll Server is listening on port \" &lt;&lt; argv[1] &lt;&lt; \"...\" &lt;&lt; std::endl;    // 4. 创建 epoll 实例, 从这里开始使用 epoll    int epoll_fd = epoll_create1(0);    if (epoll_fd &lt; 0) {        perror(\"epoll_create1\");        close(listen_sockfd);        return -1;    }    // 这里的epoll_create1是epoll_create的增强版, 参数为0即可设定默认模式, 不需要像epoll_create那样传入size    struct epoll_event ev;    ev.events = EPOLLIN; // 监听可读事件    ev.data.fd = listen_sockfd;    // 这里的data的其余成员暂时不使用, 直接用fd即可    // 5. 将监听 socket 添加到 epoll 实例中    if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, listen_sockfd, &amp;ev) &lt; 0) {        perror(\"epoll_ctl: listen_sockfd\");        close(listen_sockfd);        close(epoll_fd);        return -1;    }    // 用于接收就绪事件的数组    std::vector&lt;struct epoll_event&gt; events(MAX_EVENTS);    // 6. 主事件循环    while (true) {        int num_events = epoll_wait(epoll_fd, events.data(), MAX_EVENTS, -1); // 永久阻塞, 返回就绪事件数        if (num_events &lt; 0) {            perror(\"epoll_wait\");            continue;        }        // 数组中的每一个事件都是就绪的事件        for (int i = 0; i &lt; num_events; ++i) {            if (events[i].data.fd == listen_sockfd) {                // 6a. 如果是监听 socket 就绪，表示有新客户端连接                struct sockaddr_in client_addr;                socklen_t client_len = sizeof(client_addr);                int client_sockfd = accept(listen_sockfd, (struct sockaddr *)&amp;client_addr, &amp;client_len);                                if (client_sockfd &lt; 0) {                    perror(\"accept\");                    continue;                }                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr) &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                // 将新的客户端 socket 设置为非阻塞, 这是使用 epoll 的推荐做法                setnonblocking(client_sockfd);                // 将新的客户端 socket 添加到 epoll 实例中                // 注意：对于ET模式，这里需要加上 EPOLLET                ev.events = EPOLLIN; // | EPOLLET;                ev.data.fd = client_sockfd;                if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, client_sockfd, &amp;ev) &lt; 0) {                    perror(\"epoll_ctl: client_sockfd\");                    close(client_sockfd);                }            } else {                // 6b. 如果是已连接 socket 就绪，表示有数据可读                int client_sockfd = events[i].data.fd;                char buffer[1024];                memset(buffer, 0, sizeof(buffer));                // 注意：如果是ET模式，这里需要循环读取，直到返回EAGAIN                ssize_t bytes_received = read(client_sockfd, buffer, sizeof(buffer));                if (bytes_received &lt;= 0) {                    // 如果 read 返回 0 或 -1，表示客户端断开或出错                    if (bytes_received == 0) {                        std::cout &lt;&lt; \"Client \" &lt;&lt; client_sockfd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;                    } else {                        perror(\"read\");                    }                    // 从 epoll 实例中移除并关闭 socket                    epoll_ctl(epoll_fd, EPOLL_CTL_DEL, client_sockfd, NULL);                    close(client_sockfd);                } else {                    // 原封不动地将数据写回客户端（Echo）                    if (write(client_sockfd, buffer, bytes_received) != bytes_received) {                        perror(\"write\");                    }                }            }        }    }    close(listen_sockfd);    close(epoll_fd);    return 0;}\r\n/* * 程序名：client.cpp，一个简单的TCP客户端。(用于测试epoll服务器) */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;int main(int argc, char *argv[]){    if (argc != 3)    {        std::cout &lt;&lt; \"Using: ./client ip port\\nExample: ./client 127.0.0.1 5005\\n\\n\";        return -1;    }    int sockfd = socket(AF_INET, SOCK_STREAM, 0);    if (sockfd == -1) { perror(\"socket\"); return -1; }    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(atoi(argv[2]));    if (inet_pton(AF_INET, argv[1], &amp;serv_addr.sin_addr) &lt;= 0) {        perror(\"inet_pton\"); close(sockfd); return -1;    }    if (connect(sockfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) != 0) {        perror(\"connect\"); close(sockfd); return -1;    }    std::cout &lt;&lt; \"Connected to server \" &lt;&lt; argv[1] &lt;&lt; \":\" &lt;&lt; argv[2] &lt;&lt; std::endl;    char buffer[1024];    std::string input;        std::cout &lt;&lt; \"Enter a message (or 'exit' to quit): \";    while (getline(std::cin, input) &amp;&amp; input != \"exit\")    {        std::string message_to_send = input + \"\\n\";        if (write(sockfd, message_to_send.c_str(), message_to_send.length()) &lt;= 0) {            perror(\"write\"); break;        }        memset(buffer, 0, sizeof(buffer));        ssize_t bytes_received = read(sockfd, buffer, sizeof(buffer) - 1);        if (bytes_received &gt; 0) {            std::cout &lt;&lt; \"Server echo: \" &lt;&lt; buffer; // buffer中自带换行        } else {            std::cout &lt;&lt; \"Server disconnected or error.\" &lt;&lt; std::endl; break;        }        std::cout &lt;&lt; \"\\nEnter a message (or 'exit' to quit): \";    }    close(sockfd);    std::cout &lt;&lt; \"Connection closed.\" &lt;&lt; std::endl;    return 0;}\r\nepoll\r\n的两种工作模式：水平触发 (LT) 与边缘触发 (ET)\r\n这是 epoll 的一个高级但非常重要的特性。\r\n\r\n水平触发 (Level Triggered, LT)\r\n- 默认模式\r\n\r\n行为：只要文件描述符的缓冲区中还有数据可读，epoll_wait\r\n每次被调用都会返回这个事件。\r\n特点：编程更简单、更安全，与 poll\r\n的行为类似。即使你这次没有把数据全部读完，下次循环调用 epoll_wait\r\n时内核还会“提醒”你。\r\n\r\n边缘触发 (Edge Triggered, ET) -\r\n高性能模式\r\n\r\n行为：只有当文件描述符的状态发生变化（例如，数据从无到有）时，epoll_wait\r\n才会通知一次。\r\n特点：效率更高，因为它避免了对同一事件的重复通知。但编程要求也更高：你必须在收到通知后，在一个循环中一次性将缓冲区的数据全部读取完毕（直到\r\nread 返回 EAGAIN 错误），否则剩下的数据可能再也得不到处理机会了。Nginx\r\n等高性能服务器都工作在 ET 模式下。\r\n\r\n\r\n在接口的使用上，ET 模式只需要在注册事件时，将 EPOLLET\r\n标志加上即可：\r\nev.events = EPOLLIN | EPOLLET; // 监听可读事件，使用边缘触发模式\r\n而LT模式则不需要额外设置，默认就是LT。 ev.events = EPOLLIN; // 监听可读事件，使用默认的水平触发模式\r\nfcntl\r\nfcntl 是 “file control” 的缩写，意为文件控制。它是 POSIX\r\n标准中定义的一个系统调用，功能非常强大，可以用一个函数来对文件描述符\r\n(file descriptor) 执行各种各样的控制操作。\r\n在 Unix/Linux “一切皆文件” 的哲学中，socket\r\n也是通过文件描述符来表示的，因此 fcntl 自然也可以用来控制 socket\r\n的属性和行为。\r\n它的主要作用是在程序运行时，动态地获取或修改一个已打开文件描述符的属性。\r\nfcntl 函数的声明在头文件 &lt;fcntl.h&gt;\r\n中。它的原型比较特殊，是一个可变参数函数： #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* arg */ ); - int fd:\r\n目标文件描述符，即你想要控制的那个文件或 socket 的句柄。\r\n\r\nint cmd: 命令 (command)，这是 fcntl 的核心。你通过这个参数告诉\r\nfcntl 你具体想做什么操作。cmd 的值是一系列预定义的宏。\r\n… /* arg */:\r\n一个可选的、可变的第三个参数。这个参数的类型和含义完全取决于 cmd\r\n的值。有些命令需要这个参数，有些则不需要。\r\n\r\nfcntl 的常用命令 (cmd)\r\nfcntl\r\n的功能非常多，我们重点介绍在网络和系统编程中最常用的几个命令。\r\nF_GETFL 和\r\nF_SETFL：获取和设置文件状态标志. 这是 fcntl\r\n在网络编程中最重要、最常用的功能，主要用于设置文件描述符的 I/O\r\n模式，例如非阻塞 I/O。\r\n\r\nF_GETFL (Get File Status Flags):\r\n\r\n功能：获取 fd 当前的文件状态标志。\r\n用法：int flags = fcntl(fd, F_GETFL, 0);\r\n解释：这个调用会返回一个整数，其中包含了描述 fd\r\n状态的多个标志位（例如 O_RDONLY, O_APPEND 等）。\r\n\r\nF_SETFL (Set File Status Flags):\r\n\r\n功能：设置 fd 的文件状态标志。\r\n用法：fcntl(fd, F_SETFL, new_flags);\r\n\r\n\r\nF_DUPFD：复制一个现有的文件描述符\r\nfd，返回一个新的文件描述符。新描述符是大于或等于第三个参数 arg\r\n的最小可用编号。\r\n用法：newfd = fcntl(fd, F_DUPFD, start_fd);\r\n应用：常用于 shell 的重定向功能。\r\nF_GETLK, F_SETLK, F_SETLKW：文件锁,\r\n用于对文件的某个区域进行加锁或解锁，以协调多个进程对同一文件的访问。 -\r\nF_GETLK: 测试锁。 - F_SETLK: 设置锁（非阻塞）。 - F_SETLKW:\r\n设置锁（阻塞）。\r\n应用：在多进程数据库、日志系统等需要精确文件访问控制的场景中使用。对于网络编程，通常使用其他同步机制。\r\nET和非阻塞IO\r\n现在我们回到最初的场景。为什么在高性能 epoll 服务器(ET模式)中，将\r\nlisten_sockfd 和 client_sockfd 设置为非阻塞是如此重要？\r\n对于 listen_sockfd：在 epoll 的 ET (边缘触发)\r\n模式下，如果多个客户端连接请求同时到达，内核只会通知你一次。你必须在一个循环中持续调用\r\naccept()，直到它返回 -1 并且 errno 为 EAGAIN 或\r\nEWOULDBLOCK，这表示所有已到达的连接都已被处理完毕。\r\n\r\n如果 listen_sockfd\r\n是阻塞的，那么当你处理完所有排队的连接后，最后一次 accept()\r\n调用就会永远阻塞在那里，导致你的整个事件循环被卡住，服务器彻底失去响应。\r\n\r\n对于 client_sockfd：同样，在 ET 模式下，当 epoll_wait\r\n通知你某个客户端 socket 可读时，你必须在一个循环中持续调用\r\nread()，直到把内核缓冲区中的数据全部读完。\r\n\r\n如果 client_sockfd 是阻塞的，那么当你读完所有数据后，最后一次 read()\r\n调用就会永远阻塞，等待该客户端的下一批数据，同样会卡死事件循环。\r\n\r\nwrite() 操作同理，当发送缓冲区满时，阻塞的 write()\r\n会卡住整个服务器。\r\n因此, 在上述的ET模式下, 我们使用了setnonblocking函数将 socket\r\n设置为非阻塞模式：\r\n#include &lt;fcntl.h&gt;void setnonblocking(int sockfd) {    // 1. 读取当前的状态标志    int flags = fcntl(sockfd, F_GETFL, 0);    if (flags &lt; 0) {        perror(\"fcntl(F_GETFL)\");        return;    }    // 2. 添加 O_NONBLOCK 标志    flags |= O_NONBLOCK;    // 3. 将新的标志设置回去    if (fcntl(sockfd, F_SETFL, flags) &lt; 0) {        perror(\"fcntl(F_SETFL)\");    }}\r\n注意, 如果你想把一个 socket 设置为非阻塞模式，绝对不能直接用\r\nfcntl(fd, F_SETFL, O_NONBLOCK). 因为这样做会覆盖掉\r\nfd原有的所有其他状态标志。\r\n正确的做法是采用“读取-修改-写入”三部曲：\r\n\r\n读取：先用 F_GETFL 获取当前所有的标志位。\r\n修改：在获取到的标志位基础上，使用位或 | 运算来添加\r\nO_NONBLOCK 标志。\r\n写入：最后用 F_SETFL\r\n将这个新的、包含了所有标志位的整数值设置回去。\r\n\r\nepoll 相对于 select/poll\r\n的优缺点\r\n优点: - 高并发处理能力：epoll\r\n可以轻松处理成千上万个并发连接，而不会像 select/poll\r\n那样因为线性扫描而导致性能瓶颈。 -\r\n低延迟：由于内核与用户空间共享内存，减少了内存拷贝的开销，epoll_wait\r\n的响应速度更快。 - 灵活的事件通知机制：支持 LT 和 ET\r\n两种模式，开发者可以根据应用需求选择合适的模式。 -\r\n更好的资源利用率：epoll\r\n采用了事件驱动的方式，避免了无效的轮询，能够更高效地利用系统资源。\r\n- 简化的编程模型：与传统的 select/poll 相比，epoll\r\n提供了更简单的编程接口，减少了复杂的状态管理。\r\n缺点: - Linux 专有：epoll 是 Linux\r\n特有的接口，无法跨平台使用。如果需要在不同操作系统上运行，必须使用\r\nselect 或 poll。 - 编程复杂度：尤其是在 ET\r\n模式下，要求开发者必须非常小心地处理 I/O\r\n操作，否则容易出现数据丢失或服务器卡死的情况。\r\n总结\r\n总之, 多路 I/O 转接是解决\r\nC10K（单机同时处理上万连接）问题的关键技术。它通过一个线程管理大量连接的方式，将服务器从繁重的线程/进程创建和调度中解放出来，将\r\nCPU 的精力集中在实际的 I/O 数据处理上。像 Nginx、Redis、Node.js\r\n等著名的高性能软件，其底层都无一例外地使用了 epoll 或类似的 I/O\r\n转接技术。\r\n然而,\r\nI/O多路复用并不能实现真正的并行。它仍然是单线程在轮询多个连接的状态，CPU\r\n依然是串行地处理每个连接的数据。对于 CPU\r\n密集型任务，I/O\r\n多路复用并不能带来性能提升，反而可能因为单线程阻塞而拖慢整体速度。\r\n为了实现真正的并行处理，现代高性能服务器通常会结合使用多线程/多进程和I/O\r\n多路复用。例如： - 主从 Reactor\r\n模式：主线程负责监听和接受新连接，多个工作线程负责处理已连接的客户端\r\nI/O 事件。每个工作线程内部使用 epoll 来管理它所负责的一组连接。 -\r\n线程池 + I/O 多路复用：使用线程池来处理\r\nCPU密集型任务，而 I/O 事件仍然由单个线程通过 epoll 来管理。\r\n","categories":["web","language","C++"],"tags":["web","C++"]},{"title":"Ractor","url":"/2025/10/10/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E9%AB%98%E5%B9%B6%E5%8F%91/Ractor/","content":"Reactor 模式，也称为“反应器模式”或“分发者模式”（Dispatcher\r\nPattern），是一种用于处理并发服务请求的事件驱动设计模式。它的核心思想是将所有事件（如\r\nI/O\r\n事件、定时器事件等）的监听和分发任务交给一个中心化的组件（Reactor），当事件发生时，Reactor\r\n负责将事件分发给预先注册的、特定的处理程序（Event\r\nHandler）来进行处理。\r\n这种模式特别适用于需要高效处理大量并发、短时连接的 I/O\r\n密集型应用，例如网络服务器。\r\n\r\n它是一种设计模式，而IO多路复用+线程池则是Reactor模式的一种具体实现技术。\r\n这里中心化的组件就是epoll, 而预先注册的处理程序就是线程池中的线程。\r\n\r\n组件\r\nReactor 模式主要由以下五个组件构成：\r\n\r\n句柄（Handle）: 代表一个可以产生事件的 I/O\r\n资源。在网络编程中，这通常是一个文件描述符（File\r\nDescriptor, fd），例如一个 socket 连接。它是操作系统内核用来唯一标识 I/O\r\n资源的整数。\r\n同步事件多路分发器（Synchronous Event\r\nDemultiplexer）: 这是 Reactor\r\n模式的引擎。它是一个系统调用，能够同时监听多个句柄上的事件。这个调用是同步阻塞的，即程序会在这里等待，直到至少有一个句柄上发生了它所关心的事件。\r\n\r\n为何需要它：这是避免忙轮询（busy-waiting）的关键。如果没有它，程序就需要不断地轮询所有句柄，极大地浪费\r\nCPU 资源。\r\n常见实现：Linux 系统下的 select、poll、epoll，以及 BSD/macOS 下的\r\nkqueue。其中 epoll 是目前 Linux 上性能最高的实现, 因此下面主要以\r\nepoll 为例进行说明。\r\n\r\n事件处理器接口（Event Handler）:\r\n定义了一系列用于处理不同类型事件的方法（回调函数）的接口。例如，handle_read()、handle_write()、handle_error()\r\n等。它是一个抽象的基类，具体的业务逻辑由其子类实现。\r\n具体事件处理器（Concrete Event Handler）:\r\n实现了事件处理器接口的类。它负责执行与特定事件相关的具体业务逻辑。例如，一个\r\nHttpEventHandler 在 handle_read() 方法中可能会读取 HTTP\r\n请求数据、解析请求头，然后在 handle_write() 中发送 HTTP\r\n响应。例如在网络模型中, 有至少下列两种具体处理器:\r\n\r\nAcceptor (接收器)：一种特殊的\r\nHandler，它只与监听套接字 (listen_sockfd)\r\n绑定。它的唯一职责就是处理“新连接”事件，即调用\r\naccept()，然后创建一个新的 Connection Handler 来处理这个新连接。\r\nConnection Handler\r\n(连接处理器)：与客户端套接字 (client_sockfd)\r\n绑定。它负责处理这个连接上的所有读写事件：解析请求、执行业务逻辑、准备并发送响应。\r\n在具体实现中, 这些函数会在一个新的线程中执行,\r\n以避免阻塞主事件循环。\r\n\r\n反应器（Reactor）:\r\n模式的中心组件，扮演着“分发者”的角色。它主要负责以下工作：\r\n\r\n注册与注销：提供接口，让应用程序可以将一个事件处理器和其关心的句柄绑定（注册）到\r\nReactor 上，或是在不需要时解绑（注销）。\r\n运行事件循环（Event Loop）：Reactor\r\n内部包含一个循环。在每次循环中，它会调用“同步事件多路分发器”来等待事件的发生。\r\n事件分发：当“同步事件多路分发器”返回时，表明有事件发生。Reactor\r\n会根据返回的句柄和事件类型，查找之前注册的事件处理器，并调用其对应的方法来处理事件。\r\n\r\n\r\n工作流程\r\n下面是 Reactor 模式的典型工作流程，以一个网络服务器为例：\r\n\r\n初始化：服务器启动，创建一个 Reactor\r\n对象和一个用于监听新连接的句柄（listen_fd）。\r\n注册处理器：服务器创建一个\r\nAcceptorEventHandler（一个具体的事件处理器），并将其与\r\nlisten_fd 上 READ\r\n事件一起注册到 Reactor 中。这是在告诉 Reactor，如果\r\nlisten_fd 上有新连接请求（表现为可读事件），就调用 AcceptorEventHandler\r\n的处理方法。\r\n启动事件循环：服务器调用 Reactor 的 event_loop()\r\n方法，启动事件循环。\r\n等待事件：Reactor 在循环中调用\r\nepoll_wait()（同步事件多路分发器），阻塞程序，等待事件发生。\r\n事件发生与分发：\r\n\r\n一个客户端发起连接，listen_fd 变为可读。\r\nepoll_wait() 从阻塞中返回，并告知 Reactor listen_fd 上有 READ\r\n事件。\r\nReactor 查找注册表，发现这个事件应该由 AcceptorEventHandler\r\n处理。\r\nReactor 调用 AcceptorEventHandler\r\n的 handle_read() 方法。\r\n\r\n处理连接事件：AcceptorEventHandler 的 handle_read() 方法内部调用\r\naccept() 函数，接受新的客户端连接，并获得一个新的句柄\r\nclient_fd。然后，它会创建一个新的\r\nConnectionEventHandler（用于处理与该客户端的数据交互），并将其与\r\nclient_fd 上的 READ 或 WRITE 事件一起注册到同一个\r\nReactor 中。\r\n处理数据事件：\r\n\r\n如果客户端发送数据，client_fd 变为可读。\r\nepoll_wait() 再次返回，告知 Reactor client_fd 上有 READ 事件。\r\nReactor 分发事件给 ConnectionEventHandler，调用其 handle_read()\r\n方法来读取和处理数据。\r\n\r\n循环往复：Reactor 不断重复第 4 到第 7\r\n步，持续地等待和分发事件。\r\n\r\nReactor 的几种演进模型\r\n根据线程模型的不同，Reactor 模式可以分为以下几种：\r\n\r\n\r\nalt text\r\n\r\n单线程 Reactor 模型:\r\n所有操作（接受连接、事件分发、I/O\r\n读写、业务逻辑处理）都在同一个线程中完成。\r\n优点在于实现简单，没有多线程带来的锁竞争和上下文切换开销;\r\n逻辑清晰，所有状态都在一个线程内管理。\r\n缺点是无法利用多核 CPU\r\n的性能。如果某个业务逻辑处理非常耗时（例如数据库查询），会阻塞整个事件循环，导致其他所有客户端的请求都无法被及时响应。\r\n适用于业务逻辑非常简单、快速的场景。例如，Redis\r\n就是一个典型的单线程 Reactor\r\n模型，因为它的绝大部分操作都是内存操作，速度极快。\r\n\r\n\r\nalt text\r\n\r\n多线程 Reactor 模型:\r\n一个主线程（Reactor\r\n线程）负责监听和分发事件（accept、demultiplex、dispatch）,\r\n业务逻辑的处理（非 I/O\r\n操作）则交给一个工作线程池（Worker Thread\r\nPool）来执行。\r\n主线程在接收到 I/O\r\n事件后，将数据读取出来，封装成一个任务，然后提交给工作线程池。工作线程池中的线程执行完业务逻辑后，可能会将结果交还给主线程去发送。\r\n优点是充分利用了多核 CPU 的计算能力, 将耗时的业务逻辑与 I/O\r\n处理分离，避免了 I/O 线程的阻塞。\r\n缺点是引入了多线程，需要处理线程安全问题（如共享数据的同步）。而且主线程仍然是性能瓶颈，因为它需要处理所有连接的\r\nI/O 事件。\r\n\r\n\r\nalt text\r\n\r\n主从 Reactor 模型（Main-Sub Reactor）:\r\n这是对多线程模型的一种优化，也是现代高性能网络框架（如\r\nNetty）普遍采用的模型。\r\n其 Reactor 部分由两部分组成：\r\n\r\n主 Reactor（Main\r\nReactor）：一个独立的线程，只负责一件事——监听并接受新的客户端连接\r\n(accept)。\r\n从 Reactor（Sub\r\nReactors）：一个或多个独立的线程，每个从 Reactor\r\n都有自己的事件多路分发器(epoll实例), 负责处理已连接客户端的 I/O\r\n事件（读写）。\r\n\r\n也就是说, 主 Reactor\r\n接受新连接后，不自己处理，而是通过某种负载均衡策略（如轮询）将这个新的连接分配给一个从\r\nReactor。被选中的从 Reactor\r\n将这个连接的句柄加入到自己的事件监听集合中。之后，这个连接上所有的 I/O\r\n事件（读、写）都由这个从 Reactor 来负责处理。\r\n而业务逻辑可以由从 Reactor\r\n线程自己执行，也可以再分发给另外的工作线程池。\r\n优点：职责单一, 主 Reactor 只管连接，从 Reactor 只管 I/O，职责清晰;\r\n扩展性强, 可以通过增加从 Reactor\r\n的数量来线性地提升处理能力，充分利用多核 CPU; 性能优异：主\r\nReactor 不会因为处理 I/O 而成为瓶颈，从 Reactors\r\n之间也基本没有数据竞争。\r\n代表实现是Netty、Memcached 等。\r\n单线程 Reactor 示例\r\n/* * 程序名：reactor_server.cpp * 功能：一个完整的、基于 Epoll ET模式 + 非阻塞IO 的 Reactor 模型服务器。 * 业务：一个 Echo 服务器，将客户端发来的消息转为大写后返回。 */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt;#include &lt;cerrno&gt;#include &lt;cctype&gt;// 前向声明 Reactor 类，因为 EventHandler 中会用到它class Reactor;// 抽象事件处理器基类 (Handler)// 提供统一的接口，让不同类型的事件（监听 socket、客户端 socket）都能被 Reactor 调度。// 所有具体的事件处理器（Acceptor, ConnectionHandler）都继承自它。class EventHandler {public:    virtual ~EventHandler() {}    // 纯虚函数，由子类实现，用于处理具体的事件    virtual void handle_event(uint32_t events) = 0;    // 纯虚函数，由子类实现，用于获取该处理器关联的文件描述符    virtual int get_fd() const = 0;};// Reactor 核心类 (反应器/调度器)// 负责管理 epoll 实例，运行事件循环，并将事件分发给对应的 EventHandler。class Reactor {private:    int epoll_fd; // epoll 实例的文件描述符    // 使用哈希表存储 fd 到其对应 EventHandler 指针的映射    std::unordered_map&lt;int, EventHandler*&gt; handlers;public:    // 构造函数：创建 epoll 实例    Reactor() {        epoll_fd = epoll_create1(0);        if (epoll_fd &lt; 0) {            perror(\"epoll_create1\");            exit(EXIT_FAILURE);        }    }    // 析构函数：关闭 epoll 文件描述符    ~Reactor() {        close(epoll_fd);    }    // 注册事件处理器    void register_handler(EventHandler* handler, uint32_t events) {        int fd = handler-&gt;get_fd();        struct epoll_event ev;  // 作用是描述要监听的事件, epoll_event的结构是:         // struct epoll_event {        //     uint32_t     events;      /* Epoll events (bit mask) */        //     epoll_data_t data;        /* User data variable */        // };            ev.events = events;        ev.data.ptr = handler; // 核心：将 handler 指针存入 data.ptr，实现 fd 和 handler 的绑定        if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &amp;ev) &lt; 0) {  // Epoll得以监听该 fd, 关心可读事件 (EPOLLIN)和边缘触发 (EPOLLET)            perror(\"epoll_ctl: add\");            return;        }        handlers[fd] = handler; // 将 fd 和 handler 的映射关系存入哈希表    }    // 修改事件处理器监听的事件    void modify_handler(EventHandler* handler, uint32_t events) {        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler;        if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &amp;ev) &lt; 0) {            perror(\"epoll_ctl: mod\");        }    }    // 移除事件处理器    void remove_handler(EventHandler* handler) {        int fd = handler-&gt;get_fd();        if (epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL) &lt; 0) {            perror(\"epoll_ctl: del\");        }        handlers.erase(fd); // 从哈希表中移除映射关系        // 注意：这里由调用者负责 delete handler 对象，Reactor 本身不管理其生命周期    }    // 事件循环 (Event Loop)    void event_loop() {        std::vector&lt;struct epoll_event&gt; ready_events(1024);  // 用于存储就绪事件的数组        while (true) {            // 阻塞等待事件发生            int n = epoll_wait(epoll_fd, ready_events.data(), ready_events.size(), -1);            if (n &lt; 0) {                if (errno == EINTR) continue; // 被信号中断，继续等待                perror(\"epoll_wait\");                break;            }            // 遍历所有就绪的事件            for (int i = 0; i &lt; n; ++i) {                // 从 data.ptr 中取回 handler 指针，并进行类型转换                EventHandler* handler = static_cast&lt;EventHandler*&gt;(ready_events[i].data.ptr);                // 调用 handler 的方法处理事件                handler-&gt;handle_event(ready_events[i].events);            }        }    }};// 工具函数：设置文件描述符为非阻塞模式bool set_nonblocking(int fd) {    int flags = fcntl(fd, F_GETFL, 0);    if (flags == -1) {        perror(\"fcntl: F_GETFL\");        return false;    }    if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) {        perror(\"fcntl: F_SETFL\");        return false;    }    return true;}// 具体事件处理器：处理已连接客户端的读写事件 (Connection Handler)class ConnectionHandler : public EventHandler {private:    int fd;             // 客户端 socket fd    Reactor* reactor;   // 指向 Reactor 的指针，用于修改或移除自身    std::string read_buffer;  // 读缓冲区    std::string write_buffer; // 写缓冲区public:    ConnectionHandler(int cfd, Reactor* r) : fd(cfd), reactor(r) {}    ~ConnectionHandler() {        close(fd);    }    int get_fd() const override { return fd; }    // 事件处理入口    void handle_event(uint32_t events) override {        if (events &amp; (EPOLLHUP | EPOLLERR)) { // 发生挂起或错误            handle_close();            return;        }        if (events &amp; EPOLLIN) { // 可读事件            handle_read();        }        if (events &amp; EPOLLOUT) { // 可写事件            handle_write();        }    }private:    // 处理读事件    void handle_read() {        char buf[1024];        ssize_t n;        // ET 模式，必须循环读取直到返回 EAGAIN        while ((n = read(fd, buf, sizeof(buf))) &gt; 0) {            read_buffer.append(buf, n);        }        if (n == 0) { // 客户端关闭连接            handle_close();        } else if (n &lt; 0) {            if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 真正的错误                perror(\"read\");                handle_close();            }        }        // 收到数据后，进行业务处理并准备发送        if (!read_buffer.empty()) {            // 业务逻辑：将接收到的字符转为大写            for (char &amp;c : read_buffer) {                c = toupper(c);            }            write_buffer += read_buffer; // 将处理后的数据放入写缓冲区            read_buffer.clear();            // 数据已准备好，注册写事件，以便在 socket 可写时发送            reactor-&gt;modify_handler(this, EPOLLIN | EPOLLOUT | EPOLLET);        }    }    // 处理写事件    void handle_write() {        ssize_t n;        // 循环写入，直到写缓冲区为空或 socket 发送缓冲区满        while (!write_buffer.empty()) {            n = write(fd, write_buffer.c_str(), write_buffer.length());            if (n &gt; 0) {                write_buffer.erase(0, n); // 从写缓冲区中移除已发送的数据            } else if (n &lt; 0) {                if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 真正的错误                    perror(\"write\");                    handle_close();                }                break; // 发送缓冲区满了，等待下一次 EPOLLOUT 通知            }        }        // 如果数据都写完了，就不再关心写事件，避免 epoll_wait 忙轮询        if (write_buffer.empty()) {            reactor-&gt;modify_handler(this, EPOLLIN | EPOLLET);        }    }        // 处理关闭连接    void handle_close() {        std::cout &lt;&lt; \"Client \" &lt;&lt; fd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;        reactor-&gt;remove_handler(this); // 从 Reactor 中移除自己        delete this; // 自我销毁，释放资源    }};// 具体事件处理器：处理新连接的接收事件 (Acceptor)class Acceptor : public EventHandler {private:    int listen_fd;    // 监听 socket fd    Reactor* reactor; // 指向 Reactor 的指针public:    Acceptor(int lfd, Reactor* r) : listen_fd(lfd), reactor(r) {}    int get_fd() const override { return listen_fd; }    // 处理新连接事件    void handle_event(uint32_t events) override {        if (events &amp; EPOLLIN) {            struct sockaddr_in client_addr;            socklen_t len = sizeof(client_addr);            int client_fd;            // ET 模式，必须循环 accept 直到返回 EAGAIN            while ((client_fd = accept(listen_fd, (struct sockaddr*)&amp;client_addr, &amp;len)) &gt; 0) {                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr)                           &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                                set_nonblocking(client_fd); // 将新连接设置为非阻塞                                // 为新连接创建一个 ConnectionHandler 并注册到 Reactor                ConnectionHandler* handler = new ConnectionHandler(client_fd, reactor);                reactor-&gt;register_handler(handler, EPOLLIN | EPOLLET); // 初始只关心读事件            }            if (client_fd == -1 &amp;&amp; (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK)) {                perror(\"accept\");            }        }    }};// 主函数int main(int argc, char* argv[]) {    if (argc != 2) {        std::cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" &lt;port&gt;\\n\";        return 1;    }    // 1. 创建、绑定、监听 socket    int port = atoi(argv[1]);    int listen_fd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_fd &lt; 0) { perror(\"socket\"); return 1; }    int opt = 1;    setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);    serv_addr.sin_port = htons(port);    if (bind(listen_fd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {        perror(\"bind\"); return 1;    }    if (listen(listen_fd, SOMAXCONN) &lt; 0) {        perror(\"listen\"); return 1;    }        // 2. 将监听 socket 设置为非阻塞，配合 ET 模式    set_nonblocking(listen_fd);    // -------------3. 初始化 Reactor 和 Acceptor--------------    Reactor reactor;    Acceptor acceptor(listen_fd, &amp;reactor);        // 4. 将 Acceptor 注册到 Reactor，监听新连接事件    reactor.register_handler(&amp;acceptor, EPOLLIN | EPOLLET);    // 5. 启动服务器    std::cout &lt;&lt; \"Reactor Server is running on port \" &lt;&lt; port &lt;&lt; \"...\" &lt;&lt; std::endl;    reactor.event_loop(); // 进入事件循环    close(listen_fd);    return 0;}\r\n多线程 Reactor 示例\r\n/* * 程序名：reactor_server_multithread.cpp * 功能：一个基于 Epoll ET + 非阻塞IO 的多线程 Reactor 模型服务器。 * I/O 线程负责读写，业务逻辑交由独立的线程池处理。 * 业务：一个 Echo 服务器，将客户端发来的消息转为大写后返回。 */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;         // POSIX 标准操作系统 API，如 read, write, close#include &lt;sys/socket.h&gt;     // 套接字编程 API#include &lt;sys/epoll.h&gt;      // Epoll API#include &lt;netinet/in.h&gt;     // Internet 地址族#include &lt;arpa/inet.h&gt;      // IP 地址转换函数#include &lt;fcntl.h&gt;          // 文件控制，如设置非阻塞#include &lt;cerrno&gt;           // 错误码#include &lt;cctype&gt;           // 字符处理函数，如 toupper#include &lt;memory&gt;           // 智能指针#include &lt;thread&gt;           // 线程库#include &lt;mutex&gt;            // 互斥锁#include &lt;condition_variable&gt; // 条件变量#include &lt;queue&gt;            // 队列#include &lt;functional&gt;       // std::function// --- 线程池实现 ---// 一个简单的固定大小的线程池class ThreadPool {private:    std::vector&lt;std::thread&gt; workers;           // 存储工作线程的容器    std::queue&lt;std::function&lt;void()&gt;&gt; tasks;    // 任务队列，存储待执行的任务    std::mutex queue_mutex;                     // 保护任务队列的互斥锁    std::condition_variable condition;          // 条件变量，用于唤醒等待的线程    bool stop;                                  // 线程池停止标志public:    // 构造函数，创建指定数量的线程    ThreadPool(size_t threads) : stop(false) {        for (size_t i = 0; i &lt; threads; ++i) {            // emplace_back 直接在容器末尾构造线程对象            workers.emplace_back([this] {                // 工作线程的无限循环                while (true) {                    std::function&lt;void()&gt; task;                    {                        // 使用 unique_lock 管理互斥锁                        std::unique_lock&lt;std::mutex&gt; lock(this-&gt;queue_mutex);                        // 等待条件：线程池停止 或 任务队列不为空                        // wait 会原子地解锁并阻塞，被唤醒后重新加锁并检查条件                        // 最终线程全部阻塞在这里等待任务到来                        this-&gt;condition.wait(lock, [this] { return this-&gt;stop || !this-&gt;tasks.empty(); });                                                // 如果线程池停止且任务队列为空，则线程退出                        if (this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) return;                                                // 从队列中取出一个任务                        task = std::move(this-&gt;tasks.front());                        this-&gt;tasks.pop();                    }                    // 执行任务（此时锁已释放，不阻塞其他线程取任务）                    task();                }            });        }    }    // 提交任务到线程池    template&lt;class F&gt;    void submit_task(F&amp;&amp; f) {        {            std::unique_lock&lt;std::mutex&gt; lock(queue_mutex);            // 如果线程池已停止，则不允许提交新任务            if (stop) throw std::runtime_error(\"submit on stopped ThreadPool\");            // 将任务添加到队列            tasks.emplace(std::forward&lt;F&gt;(f));        }        // 唤醒一个正在等待的线程来处理任务        condition.notify_one();    }    // 析构函数，优雅地关闭线程池    ~ThreadPool() {        {            std::unique_lock&lt;std::mutex&gt; lock(queue_mutex);            stop = true; // 设置停止标志        }        // 唤醒所有线程，让他们能够检查到 stop 标志并退出        condition.notify_all();        // 等待所有工作线程执行完毕        for (std::thread &amp;worker : workers) {            worker.join();        }    }};// --- Reactor 框架 ---class Reactor;// 事件处理器接口（抽象基类）class EventHandler {public:    virtual ~EventHandler() {}    // 事件处理函数，由子类实现    virtual void handle_event(uint32_t events) = 0;    // 获取文件描述符    virtual int get_fd() const = 0;};// Reactor 类，负责事件的分发class Reactor {private:    int epoll_fd; // epoll 实例的文件描述符    // 使用智能指针管理 EventHandler 的生命周期    // 键是文件描述符，值是对应的事件处理器    std::unordered_map&lt;int, std::shared_ptr&lt;EventHandler&gt;&gt; handlers;    std::mutex mtx; // 保护 handlers 的互斥锁，防止多线程并发修改public:    Reactor() {        epoll_fd = epoll_create1(0); // 创建 epoll 实例        if (epoll_fd &lt; 0) { perror(\"epoll_create1\"); exit(EXIT_FAILURE); }    }    ~Reactor() { close(epoll_fd); }    // 注册、修改、移除 handler 都需要加锁以保证线程安全    void register_handler(std::shared_ptr&lt;EventHandler&gt; handler, uint32_t events) {        std::lock_guard&lt;std::mutex&gt; lock(mtx); // 自动加锁和解锁        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events; // 设置要监听的事件        ev.data.ptr = handler.get(); // 存储裸指针，用于快速查找        if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &amp;ev) &lt; 0) {            perror(\"epoll_ctl: add\");            return;        }        handlers[fd] = handler; // 将 handler 的所有权交给 map    }    void modify_handler(std::shared_ptr&lt;EventHandler&gt; handler, uint32_t events) {        // modify_handler 可能会被工作线程调用，所以必须是线程安全的        std::lock_guard&lt;std::mutex&gt; lock(mtx);        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler.get();        if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &amp;ev) &lt; 0) {            perror(\"epoll_ctl: mod\");        }    }    void remove_handler(std::shared_ptr&lt;EventHandler&gt; handler) {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        int fd = handler-&gt;get_fd();        // 从 epoll 中移除监听        if (epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL) &lt; 0) {            perror(\"epoll_ctl: del\");        }        // 从 map 中移除 handler，shared_ptr 的引用计数会减少        handlers.erase(fd);    }    // 事件循环，Reactor 的核心    void event_loop() {        std::vector&lt;struct epoll_event&gt; ready_events(1024);        while (true) {            // 等待事件发生，-1 表示无限等待            int n = epoll_wait(epoll_fd, ready_events.data(), ready_events.size(), -1);            if (n &lt; 0) {                if (errno == EINTR) continue; // 被信号中断，继续等待                perror(\"epoll_wait\");                break;            }            // 遍历所有就绪的事件            for (int i = 0; i &lt; n; ++i) {                // 从 epoll_event 中获取之前存储的裸指针                EventHandler* handler_ptr = static_cast&lt;EventHandler*&gt;(ready_events[i].data.ptr);                std::shared_ptr&lt;EventHandler&gt; handler;                {                    // 从 map 中获取 shared_ptr，保证在处理事件期间对象不会被销毁                    // 这是一个关键的线程安全操作                    std::lock_guard&lt;std::mutex&gt; lock(mtx);                    auto it = handlers.find(handler_ptr-&gt;get_fd());                    if (it != handlers.end()) {                        handler = it-&gt;second; // 复制 shared_ptr，增加引用计数                    }                }                if (handler) {                    // 调用对应的事件处理函数                    handler-&gt;handle_event(ready_events[i].events);                }            }        }    }};// 工具函数：设置文件描述符为非阻塞模式bool set_nonblocking(int fd) {    int flags = fcntl(fd, F_GETFL, 0);    if (flags == -1) { perror(\"fcntl: F_GETFL\"); return false; }    if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) { perror(\"fcntl: F_SETFL\"); return false; }    return true;}// 连接处理器，负责处理单个客户端连接的读写事件class ConnectionHandler : public EventHandler, public std::enable_shared_from_this&lt;ConnectionHandler&gt; {private:    int fd;                 // 客户端连接的 socket fd    Reactor* reactor;       // 指向所属 Reactor 的指针    ThreadPool* thread_pool; // 指向业务线程池的指针    std::string read_buffer;  // 读缓冲区    std::string write_buffer; // 写缓冲区    std::mutex mtx;           // 保护 write_buffer，因为工作线程和I/O线程都可能访问它public:    ConnectionHandler(int cfd, Reactor* r, ThreadPool* tp) : fd(cfd), reactor(r), thread_pool(tp) {}    ~ConnectionHandler() { close(fd); } // 析构时关闭 socket    int get_fd() const override { return fd; }    // 事件分发    void handle_event(uint32_t events) override {        if (events &amp; (EPOLLHUP | EPOLLERR)) { handle_close(); return; } // 错误或挂起        if (events &amp; EPOLLIN) { handle_read(); }   // 可读事件        if (events &amp; EPOLLOUT) { handle_write(); } // 可写事件    }private:    // 处理读事件    void handle_read() {        char buf[1024];        ssize_t n;        // ET 模式，必须循环读取直到返回 EAGAIN 或 EWOULDBLOCK        while ((n = read(fd, buf, sizeof(buf))) &gt; 0) {            read_buffer.append(buf, n);        }        if (n == 0) { // 对端关闭连接            handle_close();         } else if (n &lt; 0) {            if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 发生真实错误                perror(\"read\");                handle_close();            }        }        if (!read_buffer.empty()) {            // 将业务逻辑提交给线程池            std::string data = std::move(read_buffer); // 移动数据，避免拷贝            read_buffer.clear();            // 使用 shared_from_this() 获取自身的 shared_ptr，安全地传递给工作线程            auto self = shared_from_this();            thread_pool-&gt;submit_task([self, data] {                self-&gt;process_and_send(data);            });        }    }        // 该函数由工作线程执行，处理业务逻辑并准备发送数据    void process_and_send(std::string data) {        // 1. 执行业务逻辑（转为大写）        for (char &amp;c : data) {            c = toupper(c);        }                // 2. 将结果放入写缓冲区，并注册写事件        {            std::lock_guard&lt;std::mutex&gt; lock(mtx);            write_buffer += data;        }        // 通知 Reactor，该连接现在对写事件也感兴趣        reactor-&gt;modify_handler(shared_from_this(), EPOLLIN | EPOLLOUT | EPOLLET);    }    // 处理写事件    void handle_write() {        std::lock_guard&lt;std::mutex&gt; lock(mtx); // 写操作前加锁        ssize_t n;        // ET 模式，循环写入        while (!write_buffer.empty()) {            n = write(fd, write_buffer.c_str(), write_buffer.length());            if (n &gt; 0) {                write_buffer.erase(0, n); // 从缓冲区移除已发送的数据            } else if (n &lt; 0) {                if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { // 真实错误                    perror(\"write\");                    handle_close();                }                break; // 如果是 EAGAIN，则等待下一次 EPOLLOUT 通知            }        }        // 如果写缓冲区已空，说明数据已全部发送，取消对写事件的关注        if (write_buffer.empty()) {            reactor-&gt;modify_handler(shared_from_this(), EPOLLIN | EPOLLET);        }    }        // 处理连接关闭    void handle_close() {        std::cout &lt;&lt; \"Client \" &lt;&lt; fd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;        reactor-&gt;remove_handler(shared_from_this());        // 对象由 shared_ptr 自动管理，当所有 shared_ptr 失效时，对象会被销毁    }};// 连接接收器，负责接受新的客户端连接class Acceptor : public EventHandler, public std::enable_shared_from_this&lt;Acceptor&gt; {private:    int listen_fd;      // 监听 socket    Reactor* reactor;   // 指向所属 Reactor    ThreadPool* thread_pool; // 指向线程池public:    Acceptor(int lfd, Reactor* r, ThreadPool* tp) : listen_fd(lfd), reactor(r), thread_pool(tp) {}    int get_fd() const override { return listen_fd; }    // 只处理读事件（即新连接到来）    void handle_event(uint32_t events) override {        if (events &amp; EPOLLIN) {            struct sockaddr_in client_addr;            socklen_t len = sizeof(client_addr);            int client_fd;            // ET 模式，循环 accept 直到返回 EAGAIN            while ((client_fd = accept(listen_fd, (struct sockaddr*)&amp;client_addr, &amp;len)) &gt; 0) {                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr)                           &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                                set_nonblocking(client_fd); // 将新连接设置为非阻塞                                // 为新连接创建一个 ConnectionHandler                auto handler = std::make_shared&lt;ConnectionHandler&gt;(client_fd, reactor, thread_pool);                // 将新连接注册到 Reactor，监听读事件                reactor-&gt;register_handler(handler, EPOLLIN | EPOLLET);            }            if (client_fd == -1 &amp;&amp; (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK)) {                perror(\"accept\");            }        }    }};int main(int argc, char* argv[]) {    if (argc != 2) {        std::cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" &lt;port&gt;\\n\";        return 1;    }    int port = atoi(argv[1]);    int listen_fd = socket(AF_INET, SOCK_STREAM, 0);    if (listen_fd &lt; 0) { perror(\"socket\"); return 1; }    // 设置地址重用，方便服务器快速重启    int opt = 1;    setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 监听所有网络接口    serv_addr.sin_port = htons(port);    if (bind(listen_fd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) {        perror(\"bind\"); return 1;    }    if (listen(listen_fd, SOMAXCONN) &lt; 0) {        perror(\"listen\"); return 1;    }        set_nonblocking(listen_fd); // 将监听 socket 设置为非阻塞    // --------- 初始化 Reactor, ThreadPool, Acceptor ---------    Reactor reactor;    // 获取硬件支持的线程数，创建相应数量的工作线程    unsigned int num_threads = std::thread::hardware_concurrency();    ThreadPool pool(num_threads &gt; 0 ? num_threads : 4); // 如果获取失败，默认4个    // 使用智能指针管理 Acceptor 的生命周期, 注意和单线程版本的区别    auto acceptor = std::make_shared&lt;Acceptor&gt;(listen_fd, &amp;reactor, &amp;pool);        // 将 Acceptor 注册到 Reactor，监听新连接事件    reactor.register_handler(acceptor, EPOLLIN | EPOLLET);    std::cout &lt;&lt; \"Multi-threaded Reactor Server is running on port \" &lt;&lt; port &lt;&lt; \" with \" &lt;&lt; num_threads &lt;&lt; \" worker threads...\" &lt;&lt; std::endl;    reactor.event_loop(); // 主线程进入事件循环，成为 I/O 线程    close(listen_fd);    return 0;}\r\n主从 Reactor 示例\r\n/* * 程序名：reactor_server_full.cpp * 功能：一个完整的主从 Reactor + 线程池模型服务器。 * Main Reactor (主线程) 负责 accept 连接并分发。 * Sub Reactors (I/O 线程) 负责网络 I/O 读写。 * Worker Thread Pool (工作线程) 负责业务逻辑处理。 * 业务：一个 Echo 服务器，将客户端发来的消息转为大写后返回。 */#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;sys/eventfd.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;fcntl.h&gt;#include &lt;cerrno&gt;#include &lt;cctype&gt;#include &lt;memory&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;queue&gt;#include &lt;functional&gt;#include &lt;atomic&gt;// --- 线程池实现 (与多线程 Reactor 版本相同) ---class ThreadPool {private:    std::vector&lt;std::thread&gt; workers;           // 存储工作线程的容器    std::queue&lt;std::function&lt;void()&gt;&gt; tasks;    // 任务队列    std::mutex queue_mutex;                     // 保护任务队列的互斥锁    std::condition_variable condition;          // 用于唤醒等待任务的线程的条件变量    bool stop;                                  // 线程池停止标志public:    // 构造函数：创建指定数量的工作线程    ThreadPool(size_t threads) : stop(false) {        for (size_t i = 0; i &lt; threads; ++i) {            workers.emplace_back([this] {                // 工作线程的执行循环                while (true) {                    std::function&lt;void()&gt; task;                    {                        std::unique_lock&lt;std::mutex&gt; lock(this-&gt;queue_mutex);                        // 等待条件：线程池停止 或 任务队列不为空                        this-&gt;condition.wait(lock, [this] { return this-&gt;stop || !this-&gt;tasks.empty(); });                        // 如果线程池已停止且任务队列为空，则线程可以安全退出                        if (this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) return;                        // 从队列中获取一个任务                        task = std::move(this-&gt;tasks.front());                        this-&gt;tasks.pop();                    }                    // 执行任务（在锁之外，避免阻塞其他工作线程）                    task();                }            });        }    }    // 提交任务到线程池    template&lt;class F&gt;    void submit_task(F&amp;&amp; f) {        {            std::unique_lock&lt;std::mutex&gt; lock(queue_mutex);            if (stop) throw std::runtime_error(\"submit on stopped ThreadPool\");            tasks.emplace(std::forward&lt;F&gt;(f));        }        // 唤醒一个等待的线程来处理新任务        condition.notify_one();    }    // 析构函数：优雅地关闭线程池    ~ThreadPool() {        {            std::unique_lock&lt;std::mutex&gt; lock(queue_mutex);            stop = true; // 设置停止标志        }        condition.notify_all(); // 唤醒所有线程，让他们检查到 stop 标志并退出        for (std::thread &amp;worker : workers) {            worker.join(); // 等待所有线程执行完毕        }    }};// --- 前向声明 ---class SubReactor;class EventHandler;// 工具函数：设置文件描述符为非阻塞模式bool set_nonblocking(int fd) {    int flags = fcntl(fd, F_GETFL, 0);    if (flags == -1) { perror(\"fcntl: F_GETFL\"); return false; }    if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) { perror(\"fcntl: F_SETFL\"); return false; }    return true;}// --- 事件处理器基类 (接口) ---class EventHandler {public:    virtual ~EventHandler() {}    // 纯虚函数，处理事件的接口，由子类实现    virtual void handle_event(uint32_t events) = 0;    // 纯虚函数，获取文件描述符的接口    virtual int get_fd() const = 0;};// --- 连接处理器 (负责处理单个客户端连接的读写，由 SubReactor 管理) ---class ConnectionHandler : public EventHandler, public std::enable_shared_from_this&lt;ConnectionHandler&gt; {private:    int fd;                     // 客户端连接的 socket fd    SubReactor* owner_reactor;  // 指向管理它的 SubReactor    ThreadPool* thread_pool;    // 指向业务逻辑处理的线程池    std::string read_buffer;    // 读缓冲区    std::string write_buffer;   // 写缓冲区    std::mutex mtx;             // 保护 write_buffer，因为它会被 I/O 线程和工作线程访问public:    ConnectionHandler(int cfd, SubReactor* reactor, ThreadPool* pool)         : fd(cfd), owner_reactor(reactor), thread_pool(pool) {}    ~ConnectionHandler() { close(fd); } // 析构时自动关闭 socket    int get_fd() const override { return fd; }    // 事件分发器，根据 epoll 返回的事件类型调用不同的处理函数    void handle_event(uint32_t events) override;private:    void handle_read();    // 处理读事件（在 I/O 线程中执行）    void handle_write();   // 处理写事件（在 I/O 线程中执行）    void handle_close();   // 处理关闭事件（在 I/O 线程中执行）    void process_data(std::string data); // 处理业务逻辑（在工作线程中执行）};// --- SubReactor (运行在 I/O 线程中，负责处理网络 I/O) ---class SubReactor {private:    int epoll_fd;       // 每个 SubReactor 拥有自己的 epoll 实例    int wakeup_fd;      // 用于主线程唤醒此 Reactor 的 eventfd    ThreadPool* thread_pool; // 指向共享的业务线程池    std::unordered_map&lt;int, std::shared_ptr&lt;EventHandler&gt;&gt; handlers; // 管理此 Reactor 上的所有事件处理器    std::thread worker_thread; // 运行 event_loop 的 I/O 线程    std::mutex mtx;            // 保护 handlers 的互斥锁    // 用于暂存主线程发来的新连接 fd 的队列    std::vector&lt;int&gt; pending_fds;    std::mutex pending_fds_mtx; // 保护 pending_fds 的互斥锁public:    SubReactor(ThreadPool* pool) : thread_pool(pool) {        epoll_fd = epoll_create1(0);        if (epoll_fd &lt; 0) { perror(\"SubReactor epoll_create1\"); exit(EXIT_FAILURE); }                // 创建一个 eventfd 用于跨线程唤醒        wakeup_fd = eventfd(0, EFD_NONBLOCK | EFD_CLOEXEC);        if (wakeup_fd &lt; 0) { perror(\"SubReactor eventfd\"); exit(EXIT_FAILURE); }        // 为 wakeup_fd 创建一个专门的处理器，以便在 epoll 中监听它        struct WakeupHandler : EventHandler {            SubReactor* self;            WakeupHandler(SubReactor* s) : self(s) {}            int get_fd() const override { return self-&gt;wakeup_fd; }            void handle_event(uint32_t events) override {                uint64_t one;                // 读取 eventfd 的数据，清除事件通知，否则会一直触发                ssize_t n = read(self-&gt;wakeup_fd, &amp;one, sizeof(one));            }        };        // 将 wakeup_handler 注册到 epoll 中，监听读事件        register_handler(std::make_shared&lt;WakeupHandler&gt;(this), EPOLLIN);    }        ~SubReactor() {        close(epoll_fd);        close(wakeup_fd);    }    // 启动 I/O 线程，开始事件循环    void start() {        worker_thread = std::thread(&amp;SubReactor::event_loop, this);    }    // 等待 I/O 线程结束    void join() {        if(worker_thread.joinable()) worker_thread.join();    }    // 在 SubReactor 自己的 I/O 线程中，将一个新连接注册到 epoll    void add_new_connection(int client_fd) {        set_nonblocking(client_fd);        // 创建 ConnectionHandler，并传递线程池指针        auto handler = std::make_shared&lt;ConnectionHandler&gt;(client_fd, this, thread_pool);        register_handler(handler, EPOLLIN | EPOLLET); // 监听读事件和边缘触发    }    // 供 MainReactor 调用的接口，用于投递新连接（跨线程）    void post_new_connection(int fd) {        {            // 将新连接的 fd 放入待处理队列            std::lock_guard&lt;std::mutex&gt; lock(pending_fds_mtx);            pending_fds.push_back(fd);        }        // 向 wakeup_fd 写入数据，以唤醒阻塞在 epoll_wait 的 I/O 线程        uint64_t one = 1;        ssize_t n = write(wakeup_fd, &amp;one, sizeof(one));        if (n != sizeof(one)) {            perror(\"SubReactor write to wakeup_fd\");        }    }    // 注册事件处理器到 epoll（线程安全）    void register_handler(std::shared_ptr&lt;EventHandler&gt; handler, uint32_t events) {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler.get();        if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &amp;ev) &lt; 0) { perror(\"SubReactor epoll_ctl: add\"); return; }        handlers[fd] = handler;    }        // 修改 epoll 中已注册的事件（线程安全）    void modify_handler(std::shared_ptr&lt;EventHandler&gt; handler, uint32_t events) {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler.get();        if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &amp;ev) &lt; 0) { perror(\"SubReactor epoll_ctl: mod\"); }    }    // 从 epoll 中移除事件处理器（线程安全）    void remove_handler(std::shared_ptr&lt;EventHandler&gt; handler) {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        int fd = handler-&gt;get_fd();        if (epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL) &lt; 0) { perror(\"SubReactor epoll_ctl: del\"); }        handlers.erase(fd);    }    // 事件循环，运行在 I/O 线程中    void event_loop() {        std::vector&lt;struct epoll_event&gt; ready_events(1024);        while (true) {            int n = epoll_wait(epoll_fd, ready_events.data(), ready_events.size(), -1);            if (n &lt; 0) { if (errno == EINTR) continue; perror(\"SubReactor epoll_wait\"); break; }            // 检查是否有从主线程发来的新连接需要处理            {                std::vector&lt;int&gt; new_fds;                std::lock_guard&lt;std::mutex&gt; lock(pending_fds_mtx);                new_fds.swap(pending_fds); // 高效交换，减少锁内时间                for (int fd : new_fds) {                    add_new_connection(fd); // 注册新连接                }            }            // 遍历处理所有就绪的 I/O 事件            for (int i = 0; i &lt; n; ++i) {                EventHandler* handler_ptr = static_cast&lt;EventHandler*&gt;(ready_events[i].data.ptr);                // 如果是唤醒事件，其 handler 已经处理过了，这里跳过                if (handler_ptr-&gt;get_fd() == wakeup_fd) continue;                // 从 map 中安全地获取 shared_ptr，确保 handler 在处理期间不会被销毁                std::shared_ptr&lt;EventHandler&gt; handler;                {                    std::lock_guard&lt;std::mutex&gt; lock(mtx);                    auto it = handlers.find(handler_ptr-&gt;get_fd());                    if (it != handlers.end()) handler = it-&gt;second;                }                if (handler) handler-&gt;handle_event(ready_events[i].events);            }        }    }};// --- ConnectionHandler 成员函数实现 ---void ConnectionHandler::handle_event(uint32_t events) {    if (events &amp; (EPOLLHUP | EPOLLERR)) { handle_close(); return; }    if (events &amp; EPOLLIN) { handle_read(); }    if (events &amp; EPOLLOUT) { handle_write(); }}void ConnectionHandler::handle_read() {    char buf[1024];    ssize_t n;    // ET 模式，必须循环读取直到返回 EAGAIN    while ((n = read(fd, buf, sizeof(buf))) &gt; 0) {        read_buffer.append(buf, n);    }    if (n == 0) { handle_close(); }     else if (n &lt; 0) { if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { perror(\"read\"); handle_close(); }}        // 如果读取到了数据，则将其提交给线程池处理    if (!read_buffer.empty()) {        std::string data = std::move(read_buffer);        read_buffer.clear();        // 使用 shared_from_this() 获取自身的 shared_ptr，安全地传递给工作线程        auto self = shared_from_this();        thread_pool-&gt;submit_task([self, data] {            self-&gt;process_data(data);        });    }}// 此函数由工作线程执行void ConnectionHandler::process_data(std::string data) {    // 1. 执行耗时的业务逻辑（这里是转为大写）    for (char &amp;c : data) {        c = toupper(c);    }    // 2. 将处理结果放入写缓冲区（需要加锁保护）    {        std::lock_guard&lt;std::mutex&gt; lock(mtx);        write_buffer += data;    }    // 3. 通知 I/O 线程（SubReactor），该连接现在有数据要写    //    通过修改 epoll 监听事件，增加对 EPOLLOUT 的关注    owner_reactor-&gt;modify_handler(shared_from_this(), EPOLLIN | EPOLLOUT | EPOLLET);}// 此函数由 I/O 线程执行void ConnectionHandler::handle_write() {    std::lock_guard&lt;std::mutex&gt; lock(mtx); // 保护 write_buffer    ssize_t n;    // ET 模式，循环写入直到缓冲区为空或遇到 EAGAIN    while (!write_buffer.empty()) {        n = write(fd, write_buffer.c_str(), write_buffer.length());        if (n &gt; 0) { write_buffer.erase(0, n); }         else if (n &lt; 0) { if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK) { perror(\"write\"); handle_close(); } break; }    }    // 如果写缓冲区已空，取消对写事件的关注，避免 CPU 空转    if (write_buffer.empty()) {        owner_reactor-&gt;modify_handler(shared_from_this(), EPOLLIN | EPOLLET);    }}void ConnectionHandler::handle_close() {    std::cout &lt;&lt; \"Client \" &lt;&lt; fd &lt;&lt; \" disconnected.\" &lt;&lt; std::endl;    owner_reactor-&gt;remove_handler(shared_from_this());}// --- Acceptor (属于 MainReactor，负责接受新连接并分发) ---class Acceptor : public EventHandler {private:    int listen_fd;    std::vector&lt;SubReactor*&gt;&amp; sub_reactors; // 持有所有 SubReactor 的指针    std::atomic&lt;size_t&gt; next_sub_reactor_idx; // 用于轮询分发新连接的原子索引public:    Acceptor(int lfd, std::vector&lt;SubReactor*&gt;&amp; subs) : listen_fd(lfd), sub_reactors(subs), next_sub_reactor_idx(0) {}    int get_fd() const override { return listen_fd; }    void handle_event(uint32_t events) override {        if (events &amp; EPOLLIN) {            struct sockaddr_in client_addr;            socklen_t len = sizeof(client_addr);            int client_fd;            // ET 模式，循环 accept 直到返回 EAGAIN            while ((client_fd = accept(listen_fd, (struct sockaddr*)&amp;client_addr, &amp;len)) &gt; 0) {                std::cout &lt;&lt; \"Accepted connection from \" &lt;&lt; inet_ntoa(client_addr.sin_addr) &lt;&lt; \":\" &lt;&lt; ntohs(client_addr.sin_port) &lt;&lt; std::endl;                // 使用轮询（Round-Robin）策略选择一个 SubReactor                size_t idx = next_sub_reactor_idx.fetch_add(1) % sub_reactors.size();                // 将新连接的 fd 投递给选中的 SubReactor                sub_reactors[idx]-&gt;post_new_connection(client_fd);            }            if (client_fd == -1 &amp;&amp; (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK)) { perror(\"accept\"); }        }    }};// --- MainReactor (运行在主线程，只负责 accept) ---class MainReactor {private:    int epoll_fd;    std::unordered_map&lt;int, std::shared_ptr&lt;EventHandler&gt;&gt; handlers; // 只管理 Acceptorpublic:    MainReactor() {        epoll_fd = epoll_create1(0);        if (epoll_fd &lt; 0) { perror(\"MainReactor epoll_create1\"); exit(EXIT_FAILURE); }    }    ~MainReactor() { close(epoll_fd); }    void register_handler(std::shared_ptr&lt;EventHandler&gt; handler, uint32_t events) {        int fd = handler-&gt;get_fd();        struct epoll_event ev;        ev.events = events;        ev.data.ptr = handler.get();        if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &amp;ev) &lt; 0) { perror(\"MainReactor epoll_ctl: add\"); }        handlers[fd] = handler;    }    // 主 Reactor 的事件循环，非常简单，只处理 Acceptor 的事件    void event_loop() {        std::vector&lt;struct epoll_event&gt; ready_events(16);        while (true) {            int n = epoll_wait(epoll_fd, ready_events.data(), ready_events.size(), -1);            for (int i = 0; i &lt; n; ++i) {                EventHandler* handler = static_cast&lt;EventHandler*&gt;(ready_events[i].data.ptr);                handler-&gt;handle_event(ready_events[i].events);            }        }    }};// --- 主函数 ---int main(int argc, char* argv[]) {    if (argc != 2) {        std::cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" &lt;port&gt;\\n\";        return 1;    }    int port = atoi(argv[1]);    int listen_fd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK | SOCK_CLOEXEC, 0);    if (listen_fd &lt; 0) { perror(\"socket\"); return 1; }    int opt = 1;    setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    struct sockaddr_in serv_addr;    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);    serv_addr.sin_port = htons(port);    if (bind(listen_fd, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)) &lt; 0) { perror(\"bind\"); return 1; }    if (listen(listen_fd, SOMAXCONN) &lt; 0) { perror(\"listen\"); return 1; }    unsigned int num_io_threads = std::thread::hardware_concurrency();    if (num_io_threads == 0) num_io_threads = 4;    // 1. 创建 Worker 线程池    ThreadPool pool(num_io_threads * 2); // 通常工作线程数可以多于 I/O 线程    // 2. 创建 SubReactors 并启动它们的线程    std::vector&lt;std::unique_ptr&lt;SubReactor&gt;&gt; sub_reactors_pool; // 使用 unique_ptr 管理生命周期    std::vector&lt;SubReactor*&gt; sub_reactors_ptr_pool; // 存储裸指针，方便传递    for (unsigned int i = 0; i &lt; num_io_threads; ++i) {        // 将线程池指针传递给每个 SubReactor        auto sub_reactor = std::make_unique&lt;SubReactor&gt;(&amp;pool);        sub_reactors_ptr_pool.push_back(sub_reactor.get());        sub_reactor-&gt;start(); // 启动 I/O 线程        sub_reactors_pool.push_back(std::move(sub_reactor));    }        // 3. 创建 MainReactor 和 Acceptor    MainReactor main_reactor;    auto acceptor = std::make_shared&lt;Acceptor&gt;(listen_fd, sub_reactors_ptr_pool);    main_reactor.register_handler(acceptor, EPOLLIN | EPOLLET);    std::cout &lt;&lt; \"Full Reactor Server is running on port \" &lt;&lt; port               &lt;&lt; \" with \" &lt;&lt; num_io_threads &lt;&lt; \" I/O threads and \" &lt;&lt; num_io_threads * 2 &lt;&lt; \" worker threads...\" &lt;&lt; std::endl;    // 4. MainReactor 进入事件循环 (阻塞主线程，使其成为 Acceptor 线程)    main_reactor.event_loop();        // 等待所有子线程结束（实际上 event_loop 是死循环，这里不会执行到）    for(auto&amp; sub : sub_reactors_pool) {        sub-&gt;join();    }        close(listen_fd);    return 0;}\r\n主 Reactor (Main Reactor)：1 个线程。\r\n\r\n它只负责一件事：bind、listen，并 epoll_wait 在 listen_fd 上。\r\n它的 handle_event 只调用 accept()。\r\n它不处理任何 read/write。\r\n\r\n从 Reactors (Sub-Reactors)：N 个线程（通常等于 CPU 核心数）。\r\n\r\n每个“从 Reactor” 线程都有自己的 epoll 实例和自己的事件循环。\r\n当主 Reactor accept 一个新连接 client_fd 后，它不会把这个 client_fd\r\n注册到自己的 epoll 里。\r\n相反，它会（例如通过轮询）选择一个“从 Reactor” 线程，并把这个\r\nclient_fd “移交” 过去。\r\n“从 Reactor” 线程收到这个 client_fd 后，将其注册到自己的 epoll\r\n实例中，开始监听 EPOLLIN 和 EPOLLOUT。\r\n\r\n这样, accept 的负载被主 Reactor 承担。所有 read 和 write\r\n的负载被平均分配到了 N 个“从 Reactor” 线程上。\r\n这就把 I/O 操作本身的 CPU 开销分散到了多个 CPU 核心上，实现了真正的\r\nI/O 并行处理。\r\nproactor 模式\r\nProactor 模式，也称为“主动器模式”，是另一种处理并发 I/O\r\n事件的设计模式。如果说 Reactor 是基于“就绪通知”（Readiness\r\nNotification）的模式，那么 Proactor 则是基于“完成通知”（Completion\r\nNotification）的模式。\r\n它的核心思想是：应用程序发起一个异步 I/O\r\n操作，然后立即继续执行其他任务；当这个 I/O\r\n操作由操作系统（OS）在后台完成后，操作系统会通知应用程序，应用程序再对操作的结果进行处理。\r\nProactor 模式通常包含以下几个关键角色：\r\n\r\n句柄（Handle）: 与 Reactor 中一样，代表一个 I/O\r\n资源，如 socket 文件描述符。\r\n异步操作处理器（Asynchronous Operation\r\nProcessor）: 这是 Proactor\r\n模式的引擎，通常由操作系统内核提供。它负责执行异步\r\nI/O\r\n操作，并在操作完成后，将结果放入一个完成事件队列中。\r\n异步操作（Asynchronous Operation）:\r\n指应用程序发起的非阻塞 I/O 请求，例如 async_read 或\r\nasync_write。这个请求包含了执行 I/O\r\n所需的所有信息，如句柄、数据缓冲区、操作类型等。\r\n完成处理器（Completion Handler）:\r\n这是一个由应用程序定义的回调函数或对象，用于处理已完成的异步\r\nI/O 操作的结果。它包含了 I/O\r\n操作成功或失败后的业务逻辑。\r\n主动器（Proactor）:\r\n模式的中心组件，扮演“事件完成分发者”的角色。它在一个独立的线程中运行，主要负责：从“异步操作处理器”的完成事件队列中获取已完成的事件,\r\n以及根据完成的事件，调用与之关联的“完成处理器”的相应方法。这个过程通常被称为“分发”（Dispatch）。\r\n发起者（Initiator）:\r\n应用程序的主体部分。它负责创建异步操作和完成处理器，并通过调用异步 I/O\r\n接口来发起操作。发起后，它不会等待操作完成。\r\n\r\n典型工作流程\r\nProactor 模式的典型工作流程如下：\r\n\r\n发起操作：应用程序（Initiator）调用一个异步\r\nI/O 接口（如\r\nasync_read）来发起一个读操作。在调用时，它会提供：要操作的句柄（socket_fd）,\r\n一个用于存放数据的缓冲区（buffer）。一个完成处理器（CompletionHandler），用于在操作完成后被回调。\r\n操作托管给 OS：调用立即返回，应用程序线程不会被阻塞。这个 I/O\r\n请求被交给操作系统内核（Asynchronous Operation Processor）。\r\nOS 执行\r\nI/O：操作系统内核在后台独立地执行这个读操作。它会等待数据到达，并将数据从内核空间直接拷贝到应用程序提供的\r\nbuffer 中。\r\n等待完成通知：与此同时，Proactor\r\n在自己的事件循环中阻塞等待，监听内核的完成事件队列。\r\nI/O 完成：当数据被成功拷贝到 buffer\r\n中后，操作系统内核会将一个“完成事件”放入完成队列。\r\nProactor 被唤醒：Proactor\r\n检测到完成队列中有事件，从阻塞状态被唤醒。\r\n分发事件：Proactor\r\n从队列中取出完成事件，并根据事件信息（例如是哪个句柄上的什么操作完成了）找到对应的\r\nCompletionHandler。\r\n执行回调：Proactor 调用 CompletionHandler 的回调方法。\r\n处理数据：CompletionHandler\r\n在其回调方法中执行业务逻辑。此时，数据已经位于它之前提供的 buffer\r\n中，可以直接使用，无需再进行 read 调用。\r\n\r\nReactor vs Proactor 对比\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n对比维度\r\nReactor 模式 (同步 I/O)\r\nProactor 模式 (异步 I/O)\r\n\r\n\r\n\r\n\r\n核心思想\r\n就绪通知 (Readiness Notification)\r\n完成通知 (Completion Notification)\r\n\r\n\r\n通知内容\r\n“文件描述符 fd 已准备好进行读/写操作。”\r\n“你发起的读/写操作已经完成。”\r\n\r\n\r\n谁执行 I/O\r\n应用程序线程。收到通知后，调用 read()/write()\r\n操作系统内核。应用程序只需发起请求，内核负责所有 I/O\r\n\r\n\r\n数据流\r\n收到通知后，应用程序主动从内核缓冲区读取数据\r\n内核直接将数据读到应用程序缓冲区，通知时数据已备好\r\n\r\n\r\n编程模型\r\n同步事件处理，应用程序主动执行 I/O 操作\r\n异步事件处理，应用程序被动等待 I/O 完成通知\r\n\r\n\r\n生活比喻\r\n我告诉你菜备好了，你来炒\r\n我把菜炒好了端给你，你直接吃\r\n\r\n\r\n平台适用性\r\n非常适合 Linux 的 epoll 机制\r\n非常适合 Windows 的 IOCP 机制\r\n\r\n\r\n\r\nProactor 模式的优缺点\r\n优点:\r\n更高的并发性：I/O\r\n操作由内核完成，不会占用或阻塞应用线程，使得应用线程可以专注于业务逻辑，理论上能达到更高的性能和并发。\r\n简化的应用逻辑：应用程序的逻辑被清晰地分离到“发起操作”和“处理结果”两个部分，代码通常更简洁，避免了复杂的\r\nI/O 就绪状态管理。\r\nCPU\r\n缓存友好：在数据拷贝方面，异步模型可能提供更优化的路径，减少\r\nCPU 缓存失效。\r\n缺点与挑战:\r\n平台依赖性强：真正的 Proactor\r\n模式严重依赖操作系统提供的底层异步 I/O（AIO）支持。Windows 通过 IOCP\r\n提供了完美的 Proactor 模型支持。而Linux虽然有 AIO 接口，但长期以来对网络\r\nsocket 的支持不完善或效率不高。因此，在 Linux\r\n上，高性能网络编程几乎都采用基于 epoll 的 Reactor 模式。\r\n实现复杂：底层的 Proactor\r\n模式实现起来非常复杂，需要深入理解操作系统内核机制。\r\n调试困难：基于回调的异步编程模型可能导致“回调地狱”（Callback\r\nHell），内存管理和状态跟踪也比同步模型更复杂，调试难度较大。\r\n在这里还需要指明的是, proactor 模式将IO操作交给操作系统内核,\r\n引发了与Reactor相比执行上下文的不同：\r\n\r\nReactor：当 epoll\r\n通知你的应用程序“可以读了”，你的应用程序线程需要发起一个 read()\r\n系统调用。这个调用会导致一次上下文切换（从用户态切换到内核态），由内核将数据从它的缓冲区拷贝到你的用户态缓冲区，然后再进行一次上下文切换（从内核态返回用户态）。这个过程虽然很快，但上下文切换是有成本的。\r\nProactor：你发起异步 async_read\r\n后，这个请求就交给了内核。内核会在后台处理这一切——等待数据、从网卡 DMA\r\n到内核缓冲区、再拷贝到你指定的用户态缓冲区。整个过程都在内核空间完成，直到全部结束后，才通过一次完成通知回到用户态。它用一次更“重”的内核内部处理，换取了多次用户态/内核态之间切换的开销。\r\n\r\n因此, Proactor\r\n模式消耗的资源总量可能并不少，但它通过减少上下文切换和更有效地利用硬件（如\r\nDMA），使得资源消耗的方式更高效，从而将 CPU 从繁琐的 I/O\r\n等待和数据拷贝中解放出来。\r\n而且, Proactor 模式在某些场景下还可以带来额外的性能提升：\r\n\r\n更高的 CPU 缓存命中率：由于应用线程不必亲自处理\r\nI/O，它可以持续地执行业务逻辑计算。这使得 CPU\r\n的指令缓存和数据缓存更可能保持“热”状态，从而提高计算密集型业务的性能。而在\r\nReactor 模式中，I/O 代码和业务逻辑代码交替执行，可能会污染 CPU\r\n缓存。\r\n更优的线程调度：在 Proactor 模式下，应用线程池里的线程只在 I/O\r\n完成后才被唤醒去处理业务逻辑，线程的利用率非常高。而在 Reactor\r\n模式中，I/O 线程既要处理 I/O\r\n也要处理业务逻辑（或分发任务），职责相对不纯粹。\r\n\r\n总结\r\nProactor 模式是一种理想的、性能极高的并发设计模式，它将 I/O\r\n操作的负担完全交给了操作系统，从而解放了应用程序。它的设计哲学是“让专业的人做专业的事”，操作系统负责\r\nI/O，应用程序负责业务。\r\n然而，由于操作系统的支持度不同，Proactor 模式在实践中的应用远没有\r\nReactor 模式广泛。在 Windows 服务器开发中，基于 IOCP 的 Proactor\r\n是主流选择。但在 Linux 世界，基于 epoll 的 Reactor 模式（特别是主从\r\nReactor 模型） 才是构建高性能网络服务的王者。\r\n有趣的是，很多现代网络库（如 Boost.Asio）会在上层提供 Proactor\r\n风格的异步 API，但在 Linux 底层，它们常常是通过 Reactor (epoll) +\r\n线程池来模拟 Proactor 的行为。\r\n","categories":["web","system"],"tags":["web"]},{"title":"信号量","url":"/2025/10/11/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E9%AB%98%E5%B9%B6%E5%8F%91/%E4%BF%A1%E5%8F%B7%E9%87%8F/","content":"信号量（Semaphore）是一种用于多线程或多进程编程中的同步机制，主要用于控制对共享资源的访问。它可以用来防止资源竞争和确保线程安全,\r\n一般可以实现为一个特殊的整数计数器，用于管理对有限资源的访问。它代表了可用资源的数量。\r\n\r\n当计数值大于0时，表示有可用的资源。\r\n当计数值等于0时，表示没有可用的资源。\r\n\r\n信号量的基本操作\r\n信号量主要有两个基本操作：P（Proberen，测试）和V（Verhogen，增加），也称为\r\nwait 和 signal 操作。\r\nP操作的核心逻辑是：尝试获取一个资源。\r\n\r\n检查资源：检查信号量(count)的值。\r\n分配资源：如果信号量的值大于0（count &gt;\r\n0），意味着有可用资源。此时，操作会成功，并将信号量的值减1（count–），表示一个资源已被占用。线程可以继续执行。\r\n等待资源：如果信号量的值等于0（count ==\r\n0），意味着没有可用资源。此时，请求资源的线程必须阻塞（即暂停执行），进入等待队列，直到有其他线程释放资源。`\r\n\r\n// P操作 - 等待信号量，获取资源void wait() {    // 1. 加锁：为了保证对 count 的检查和修改是原子操作，防止竞态条件。    std::unique_lock&lt;std::mutex&gt; lock(mtx);    // 2. 检查资源并等待：    //    使用 while 循环而不是 if 是为了防止“虚假唤醒”(spurious wakeup), 即线程被唤醒后，条件仍然不满足的情况。    //    当 count == 0 时，表示没有资源可用。    while (count == 0) {         // 3. 阻塞线程：        //    cv.wait(lock) 会原子地完成两件事：        //    a. 释放互斥锁 lock。        //    b. 将当前线程置于等待状态。        //    当线程被唤醒后，它会重新获取锁，并再次检查 while 的条件。        cv.wait(lock);  // 这里的cv是一个条件变量    }    // 4. 获取资源：    //    当线程跳出循环时，说明 count &gt; 0，有可用资源。    //    将 count 减一，表示成功获取了一个资源。    count--;}\r\nV操作的核心逻辑是：释放一个资源。\r\n\r\n增加资源计数：将信号量的值加1（count++），表示一个资源已被释放，现在可用。\r\n唤醒等待者：如果此时有其他线程因为等待该资源而被阻塞，V操作会唤醒其中一个等待的线程，让它可以尝试再次获取资源。\r\n\r\n// V操作 - 释放信号量，释放资源void signal() {    // 1. 加锁：同样是为了保证对 count 的修改和通知操作的原子性。    std::unique_lock&lt;std::mutex&gt; lock(mtx);    // 2. 释放资源：    //    将 count 加一，表示一个资源被释放了。    count++;    // 3. 唤醒等待的线程：    //    cv.notify_one() 会唤醒一个（如果有的话）正在 cv.wait() 上等待的线程。    //    被唤醒的线程会从 wait() 函数中醒来，尝试重新获取锁并继续执行。    cv.notify_one();}\r\n","categories":["web","system"],"tags":["web"]},{"title":"线程池","url":"/2025/09/25/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E9%AB%98%E5%B9%B6%E5%8F%91/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;condition_variable&gt;#include &lt;functional&gt;#include &lt;atomic&gt;#include &lt;chrono&gt;#include &lt;string&gt;// 使用 std::function 重新定义任务，使其可以接受任何可调用对象（函数、lambda等）using Task = std::function&lt;void()&gt;;// 一个线程安全的、阻塞的任务队列class SafeTaskQueue {private:    std::queue&lt;Task&gt; m_queue;    std::mutex m_mutex;    std::condition_variable m_cond;    bool m_shutdown = false;public:    // 添加任务到队列    void addTask(Task task) {        // 使用 lock_guard 自动管理锁的生命周期        std::lock_guard&lt;std::mutex&gt; lock(m_mutex);        m_queue.push(std::move(task));        // 唤醒一个可能正在等待的线程        m_cond.notify_one();    }    // 从队列中取出一个任务    Task takeTask() {        // unique_lock 功能比 lock_guard 更强大，可以配合 condition_variable 使用        std::unique_lock&lt;std::mutex&gt; lock(m_mutex);        // wait 会阻塞当前线程，直到条件满足或被唤醒        // 使用 lambda 表达式作为等待条件，可以防止伪唤醒        m_cond.wait(lock, [this] { return m_shutdown || !m_queue.empty(); });        if (m_shutdown &amp;&amp; m_queue.empty()) {            return nullptr;        }        Task task = std::move(m_queue.front());        m_queue.pop();        return task;    }        // 关闭队列，唤醒所有等待的线程    void shutdown() {        {            std::lock_guard&lt;std::mutex&gt; lock(m_mutex);            m_shutdown = true;        }        m_cond.notify_all();    }        // 获取队列大小（主要用于manager）    size_t size() {        std::lock_guard&lt;std::mutex&gt; lock(m_mutex);        return m_queue.size();    }};class ThreadPool {private:    int m_minNum;    int m_maxNum;    std::atomic&lt;int&gt; m_busyNum;    std::atomic&lt;int&gt; m_aliveNum;    std::atomic&lt;bool&gt; m_shutdown;    std::vector&lt;std::thread&gt; m_workers;    std::thread m_manager;    SafeTaskQueue m_taskQ;    // 工作线程的任务函数    void worker() {        while (!m_shutdown) {            Task task = m_taskQ.takeTask();            // 如果取出的任务为空函数，说明是时候退出了            if (task == nullptr) {                break;            }            m_busyNum++;            task(); // 执行任务            m_busyNum--;        }        m_aliveNum--;        std::cout &lt;&lt; \"Thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; \" exiting...\" &lt;&lt; std::endl;    }    // 管理者线程的任务函数    void manager() {        while (!m_shutdown) {            std::this_thread::sleep_for(std::chrono::seconds(5));            int queueSize = m_taskQ.size();            int liveNum = m_aliveNum.load();            int busyNum = m_busyNum.load();            // 扩容：任务数 &gt; 存活数 &amp;&amp; 存活数 &lt; 最大数            const int NUMBER = 2;            if (queueSize &gt; liveNum &amp;&amp; liveNum &lt; m_maxNum) {                int count = 0;                 // 一次最多创建 NUMBER 个线程                for (int i = 0; i &lt; m_maxNum &amp;&amp; count &lt; NUMBER &amp;&amp; m_aliveNum &lt; m_maxNum; ++i) {                   m_workers.emplace_back(&amp;ThreadPool::worker, this);                   m_aliveNum++;                   count++;                }            }            // 缩容：忙碌数*2 &lt; 存活数 &amp;&amp; 存活数 &gt; 最小数            // (注意：这是一个简化的缩容逻辑，实际工程中需要更复杂的机制来安全地 join 线程)            if (busyNum * 2 &lt; liveNum &amp;&amp; liveNum &gt; m_minNum) {                // 在这个简化模型中，我们不再实现动态缩容，因为安全地终止和join一个正在运行的std::thread比较复杂。                // 生产环境的线程池通常在析构时统一清理。            }        }    }public:    ThreadPool(int minNum, int maxNum)         : m_minNum(minNum), m_maxNum(maxNum), m_busyNum(0), m_aliveNum(0), m_shutdown(false) {                m_aliveNum = minNum;        for (int i = 0; i &lt; minNum; ++i) {            // emplace_back 直接在 vector 中构造线程对象            m_workers.emplace_back(&amp;ThreadPool::worker, this);        }        // 创建管理者线程        m_manager = std::thread(&amp;ThreadPool::manager, this);    }    ~ThreadPool() {        m_shutdown = true;        m_manager.join(); // 等待管理者线程退出                m_taskQ.shutdown(); // 通知所有工作线程准备退出        for (auto&amp; t : m_workers) {            if (t.joinable()) {                t.join(); // 等待所有工作线程执行完毕并退出            }        }    }    // 添加任务    template&lt;class F, class... Args&gt;    void addTask(F&amp;&amp; f, Args&amp;&amp;... args) {        if (m_shutdown) return;        // 使用 std::bind 和完美转发来创建任务        Task task = std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);        m_taskQ.addTask(std::move(task));    }    int getBusyNumber() const { return m_busyNum; }    int getAliveNumber() const { return m_aliveNum; }};// ================== 测试代码 ==================void my_task_function(int id, int sleep_ms) {    std::cout &lt;&lt; \"Task \" &lt;&lt; id &lt;&lt; \" is running in thread \" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;    std::this_thread::sleep_for(std::chrono::milliseconds(sleep_ms));}int main() {    ThreadPool pool(3, 10);    // 添加多个任务    for (int i = 0; i &lt; 20; ++i) {        pool.addTask(my_task_function, i, 500);    }    std::cout &lt;&lt; \"All tasks have been added.\" &lt;&lt; std::endl;    // 等待一段时间观察线程池活动    std::this_thread::sleep_for(std::chrono::seconds(10));        std::cout &lt;&lt; \"Main thread is preparing to shutdown.\" &lt;&lt; std::endl;        // 析构函数会自动被调用，完成线程池的优雅关闭    return 0;}\r\n","categories":["web","system"],"tags":["web"]},{"title":"多进程并发和多线程并发","url":"/2025/10/02/system/linux/Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/%E9%AB%98%E5%B9%B6%E5%8F%91/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91/","content":"\r\n并发是指在单个CPU核心上，通过快速切换任务，使得多个任务看起来像在同时进行。\r\n并行是指在多个CPU核心上，多个任务真正在物理上同时进行。\r\n\r\n这两种都是经典的并发服务器设计模式，它们的核心目标相同：同时处理多个客户端请求,\r\n实现并发处理, 提高服务器的吞吐量和响应速度。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n特性维度\r\n多进程模型 (Fork)\r\n多线程模型 (Pthread)\r\n\r\n\r\n\r\n\r\n基本单元\r\n进程 (Process)\r\n线程 (Thread)\r\n\r\n\r\n资源开销\r\n高。创建进程是重型操作，内存和CPU开销大，切换慢。\r\n低。创建线程是轻型操作，资源占用少，切换快。\r\n\r\n\r\n数据共享与通信\r\n困难。进程地址空间独立，通信需借助IPC（管道、共享内存等）。\r\n简单。所有线程共享同一地址空间（全局变量、堆、静态变量等）。\r\n\r\n\r\n稳定性与隔离性\r\n高。一个子进程崩溃不会影响父进程或其他子进程。\r\n低。任何一个线程的非法操作都可能导致整个进程崩溃。\r\n\r\n\r\n文件描述符\r\n独立。fork后父子进程各有独立的文件描述符表。\r\n共享。所有线程共享同一张文件描述符表，一个线程关闭会影响所有线程。\r\n\r\n\r\n编程模型与挑战\r\n编程相对简单，主要挑战在于进程间通信（IPC）的实现。\r\n编程更复杂，主要挑战在于处理线程安全和数据同步（如互斥锁）。\r\n\r\n\r\n并发能力\r\n受限于系统进程数上限，通常只能支持几百个并发连接。\r\n理论上可支持成千上万个并发连接，是高并发服务器的主流选择。\r\n\r\n\r\n\r\n多进程并发\r\n多进程并发服务器模型通过创建多个子进程来处理客户端请求。每当有新的客户端连接时，服务器会调用\r\nfork()\r\n系统调用创建一个新的子进程，这个子进程专门负责与该客户端进行通信和处理请求。父进程继续监听新的连接请求。\r\n基本流程如下：\r\n\r\n服务器启动，创建一个监听套接字 (listening\r\nsocket)，绑定到指定端口，并开始监听连接请求。\r\n当有新的客户端连接时，服务器调用 fork() 创建一个新的子进程\r\n子进程继承父进程的资源（如文件描述符），并专门处理该客户端的请求。\r\n父进程继续监听新的连接请求，重复上述过程。\r\n子进程处理完客户端请求后，关闭连接并退出。\r\n父进程通过 wait() 或 waitpid()\r\n回收子进程资源，防止僵尸进程(这里可以使用信号处理 SIGCHLD\r\n来自动回收)。\r\n\r\n示例代码: #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/wait.h&gt;#include &lt;signal.h&gt;#include &lt;errno.h&gt;#define PORT 8888#define BUFFER_SIZE 1024/* * 信号捕捉函数，用于回收子进程 * 这是处理 SIGCHLD 信号的回调函数 */void recycle_child(int signum) {    // 使用 while 循环和 waitpid 是为了处理多个子进程在短时间内同时结束的情况    // WNOHANG 选项表示非阻塞，如果没有已退出的子进程，则立即返回，不会卡住    while (waitpid(-1, NULL, WNOHANG) &gt; 0) {        printf(\"A child process has been recycled.\\n\");    }}int main() {    int lfd, cfd; // lfd: 监听文件描述符; cfd: 连接文件描述符    struct sockaddr_in serv_addr, cli_addr;    socklen_t cli_addr_len;    pid_t pid;    char buf[BUFFER_SIZE];    int n;    // 1. 创建监听套接字    lfd = socket(AF_INET, SOCK_STREAM, 0);    if (lfd == -1) {        perror(\"socket error\");        exit(1);    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(lfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定IP地址和端口    // bzero(&amp;serv_addr, sizeof(serv_addr)); // bzero 已不推荐使用，改用 memset    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(PORT);    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 监听本机所有IP地址    if (bind(lfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) == -1) {        perror(\"bind error\");        exit(1);    }    // 3. 设置监听上限    if (listen(lfd, 128) == -1) {        perror(\"listen error\");        exit(1);    }    // 4. 注册 SIGCHLD 信号捕捉函数，用于回收子进程    struct sigaction sa;    sa.sa_handler = recycle_child;    sigemptyset(&amp;sa.sa_mask);    sa.sa_flags = SA_RESTART; // 自动重启被信号中断的系统调用    if (sigaction(SIGCHLD, &amp;sa, NULL) == -1) {        perror(\"sigaction error\");        exit(1);    }        printf(\"Server is running on port %d, waiting for connections...\\n\", PORT);    // 5. 主循环，接收客户端连接    while (1) {        cli_addr_len = sizeof(cli_addr);        cfd = accept(lfd, (struct sockaddr *)&amp;cli_addr, &amp;cli_addr_len);        if (cfd == -1) {            // 如果是被信号中断，则继续 accept，否则报错退出            if (errno == EINTR) {                continue;            } else {                perror(\"accept error\");                exit(1);            }        }                // 打印客户端连接信息        char client_ip[16];        inet_ntop(AF_INET, &amp;cli_addr.sin_addr.s_addr, client_ip, sizeof(client_ip));        printf(\"Received connection from %s at port %d\\n\", client_ip, ntohs(cli_addr.sin_port));        // 6. 创建子进程        pid = fork();        if (pid &lt; 0) {            perror(\"fork error\");            exit(1);        }                 // 7. 子进程的工作        else if (pid == 0) {             // 子进程不需要监听，关闭监听文件描述符            close(lfd);                         while ((n = read(cfd, buf, sizeof(buf))) &gt; 0) {                // 将接收到的数据转换为大写                for (int i = 0; i &lt; n; i++) {                    buf[i] = toupper(buf[i]);                }                // 将处理后的数据写回客户端                write(cfd, buf, n);            }            if (n == 0) {                printf(\"Client %s closed the connection.\\n\", client_ip);            } else if (n &lt; 0) {                perror(\"read error\");            }                        // 关闭连接描述符，并退出子进程            close(cfd);            exit(0);         }                 // 8. 父进程的工作        else {            // 父进程不需要与客户端通信，关闭连接文件描述符            close(cfd);             // 继续循环，等待下一个客户端连接            // 子进程的回收由信号处理函数完成, 无需在这里调用 wait()        }    }        // 关闭监听描述符（实际上主循环是死循环，代码不会执行到这里）    close(lfd);    return 0;}\r\n多线程并发\r\n多线程并发服务器模型通过创建多个线程来处理客户端请求。每当有新的客户端连接时，服务器会创建一个新的线程，这个线程专门负责与该客户端进行通信和处理请求。主线程继续监听新的连接请求。\r\n基本流程如下： 1. 服务器启动，创建一个监听套接字 (listening\r\nsocket)，绑定到指定端口，并开始监听连接请求。 2.\r\n当有新的客户端连接时，服务器创建一个新的线程，这个线程专门处理该客户端的请求\r\n3. 主线程继续监听新的连接请求，重复上述过程。\r\n#include &lt;stdio.h&gt;  #include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;pthread.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;errno.h&gt;#define PORT 8888#define BUFFER_SIZE 1024// 线程处理函数void* handle_client(void* arg) {    int cfd = *(int*)arg; // 获取连接文件描述符    free(arg); // 释放动态分配的内存    char buf[BUFFER_SIZE];    int n;    while ((n = read(cfd, buf, sizeof(buf))) &gt; 0) {        // 将接收到的数据转换为大写        for (int i = 0; i &lt; n; i++) {            buf[i] = toupper(buf[i]);        }        // 将处理后的数据写回客户端        write(cfd, buf, n);    }    if (n == 0) {        printf(\"Client closed the connection.\\n\");    } else if (n &lt; 0) {        perror(\"read error\");    }    close(cfd); // 关闭连接描述符    return NULL; // 线程退出}int main() {    int lfd, cfd; // lfd: 监听文件描述符; cfd: 连接文件描述符    struct sockaddr_in serv_addr, cli_addr;    socklen_t cli_addr_len;    pthread_t tid;    // 1. 创建监听套接字    lfd = socket(AF_INET, SOCK_STREAM, 0);    if (lfd == -1) {        perror(\"socket error\");        exit(1);    }    // 设置端口复用，以便服务器快速重启    int opt = 1;    setsockopt(lfd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt));    // 2. 绑定IP地址和端口    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family = AF_INET;    serv_addr.sin_port = htons(PORT);    serv_addr.sin_addr.s_addr = htonl(INADDR_ANY); // 监听本机所有IP地址    if (bind(lfd, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr)) == -1) {        perror(\"bind error\");        exit(1);    }    // 3. 设置监听上限    if (listen(lfd, 128) == -1) {        perror(\"listen error\");        exit(1);    }    printf(\"Server is running on port %d, waiting for connections...\\n\", PORT);    // 4. 主循环，接收客户端连接    while (1) {        cli_addr_len = sizeof(cli_addr);        cfd = accept(lfd, (struct sockaddr *)&amp;cli_addr, &amp;cli_addr_len);        if (cfd == -1) {            // 如果是被信号中断，则继续 accept，否则报错退出            if (errno == EINTR) {                continue;            } else {                perror(\"accept error\");                exit(1);            }        }        // 打印客户端连接信息        char client_ip[16];        inet_ntop(AF_INET, &amp;cli_addr.sin_addr.s_addr, client_ip, sizeof(client_ip));        printf(\"Received connection from %s at port %d\\n\", client_ip, ntohs(cli_addr.sin_port));        // 动态分配内存保存连接文件描述符，传递给线程函数        int* p_cfd = malloc(sizeof(int));        *p_cfd = cfd;        // 创建线程处理客户端请求        if (pthread_create(&amp;tid, NULL, handle_client, p_cfd) !=            0) {            perror(\"pthread_create error\");            close(cfd);            free(p_cfd);            continue;        }        // 分离线程，避免僵尸线程        pthread_detach(tid);        // 主线程继续监听新的连接请求    }    // 关闭监听描述符（实际上主循环是死循环，代码不会执行到这里）    close(lfd);    return 0;}\r\n线程池和任务队列\r\n线程池是一种预先创建一定数量线程的技术，这些线程在需要时可以被重复使用来处理多个任务，从而避免了频繁创建和销毁线程的开销。任务队列则是一个线程安全的数据结构，用于存储待处理的任务，工作线程从中取出任务并执行。\r\n","categories":["web","language","C++"],"tags":["web","C++"]},{"title":"IP协议","url":"/2025/10/13/web/Computer%20Network/%E7%BD%91%E7%BB%9C%E5%B1%82/IP%E5%8D%8F%E8%AE%AE/IP%E5%8D%8F%E8%AE%AE/","content":"IP协议是网络层的核心协议，负责在不同网络之间传输数据包。在网络层中,\r\n与IP协议密切相关的还有ICMP协议和ARP协议, 即Internet Control Message\r\nProtocol (ICMP) 和 Address Resolution Protocol\r\n(ARP)。前者用于传递控制信息和错误报告，后者用于将IP地址解析为物理地址（MAC地址）。\r\n\r\n\r\nalt text\r\n\r\n\r\n这里的IGMP是Internet Group Management Protocol,\r\n用于管理主机组成员资格, 主要用于IP多播通信中,\r\n允许主机动态加入或离开多播组。而RARP已经基本被废弃,\r\n现在主要使用DHCP来实现类似功能。\r\n\r\n异构网络互连\r\n因特网并非一个单一的网络，而是由全球数以百万计的、拓扑结构、性能和协议各不相同的异构网络，通过路由器互连而成的\r\n。要让这些千差万别的网络能够顺畅通信，就需要解决诸如不同的寻址方案、路由技术、最大分组长度等问题\r\n。\r\nIP协议正是解决这个问题的关键。通过让所有异构网络都使用相同的网际协议（IP），从网络层的角度看，整个因特网就好像是一个统一的、无缝的\r\nIP网\r\n。当主机在这个IP网上通信时，它们无需关心底层网络的具体异构细节，就好像在一个单一网络上通信一样\r\n。\r\n\r\n\r\nalt text\r\n\r\nIPv4地址及其编址方法\r\nIPv4地址是分配给IP网上每一个主机或路由器接口的一个全球唯一的32比特标识符。为了方便人类读写，32位的二进制地址通常采用\r\n点分十进制\r\n表示。即将32位二进制数每8位为一组，将每组转换为十进制数，并用点号.分隔。\r\n例如：二进制 00001010 11110000 00001111 10101010 转换为点分十进制就是\r\n10.240.15.170 。\r\nIPv4地址的编址方法经历了三个历史阶段：分类编址 (Classful\r\nAddressing)–&gt;划分子网 (Subnetting)–&gt;无分类编址 (Classless\r\nInter-Domain Routing, CIDR)\r\n分类编址\r\n这是最古老的编址方法，将32位IP地址分为 网络号 和\r\n主机号 两部分。\r\n网络号用于标识主机所在的网络，主机号用于标识网络中的具体主机。同一个网络内的所有主机具有相同的网络号,\r\n而主机号则唯一标识该网络中的每一台主机。\r\n分类编址将IP地址划分为A、B、C、D、E五类,\r\n其中A、B、C类地址用于主机寻址, D类地址用于多播,\r\nE类地址保留供将来使用。\r\n\r\nA类地址: 网络号占8位, 主机号占24位, 适用于超大型网络,\r\n其中网络号的首位固定为0。\r\nB类地址: 网络号占16位, 主机号占16位, 适用于中到大型网络,\r\n其中网络号的前两位固定为10。\r\nC类地址: 网络号占24位, 主机号占8位, 适用于小型网络,\r\n其中网络号的前三位固定为110。\r\nD类地址: 用于多播, 网络号占前4位, 其余位用于标识多播组,\r\n其中网络号的前四位固定为1110。\r\nE类地址: 保留地址, 供将来使用, 其中网络号的前四位固定为1111。\r\n\r\n除此之外, 还要注意主机号全为0的地址是\r\n网络地址，全为1的地址是\r\n广播地址，都不能分配给具体设备。网络号127被保留用于\r\n本地环回测试, 不能用于实际网络通信。\r\n\r\n\r\nalt text\r\n\r\nA类地址：\r\n结构：8位网络号，24位主机号 。首位固定为0。\r\n网络范围：1.0.0.0 至 126.0.0.0。\r\n主机容量：每个网络可容纳约1677万台主机 (2 24 −2) 。\r\n用途：为极少数超大型网络设计。\r\nB类地址：\r\n结构：16位网络号，16位主机号 。前两位固定为10。\r\n网络范围：128.0.0.0 至 191.255.0.0。\r\n主机容量：每个网络可容纳65,534台主机 (2 16 −2) 。\r\n用途：为中到大型网络设计。\r\nC类地址：\r\n结构：24位网络号，8位主机号 。前三位固定为110。\r\n网络范围：192.0.0.0 至 223.255.255.0。\r\n主机容量：每个网络可容纳254台主机 (2 8 −2) 。\r\n用途：为大量的小型网络设计。\r\n重要规则：主机号全为0的地址是 网络地址，全为1的地址是\r\n广播地址，都不能分配给具体设备 。网络号127被保留用于 本地环回测试 。\r\n划分子网 (Subnetting)\r\n\r\n假如一个C类网络\r\n(例如192.168.1.0/24)，它的主机号部分有8位，去掉网络地址和广播地址后可用的主机地址是254个,\r\n而现在有一个小型办公室只有10台主机, 这就浪费了244个地址;\r\n另一个大型企业有1000台主机, 但C类网络最多只能容纳254台主机,\r\n这就不够用了, 需要使用B类地址, 但B类地址又太大, 浪费了很多地址。\r\n\r\n为了解决分类编址不够灵活、容易浪费地址的问题，引入了划分子网技术\r\n。\r\n\r\n\r\nalt text\r\n\r\n核心思想是：从原有分类地址的主机号部分借用若干位作为子网号，将一个大的网络划分成多个更小的子网。这使得IP地址从二级结构（网络号+主机号）演变为三级结构（网络号+子网号+主机号）。\r\n子网掩码 (Subnet\r\nMask)：一个32位的数值，用于指明IP地址中哪些位是网络号和子网号，哪些位是主机号。子网掩码中连续的1对应网络号和子网号，连续的0对应主机号。我们只需要将一个IP地址与其子网掩码进行按位与（AND）运算，可以得到该IP地址所在的子网的网络地址\r\n。\r\n下面是使用子网掩码划分子网的一个例子：\r\n\r\n\r\nalt text\r\n\r\n默认子网掩码指的是分类编址中每类地址的标准掩码,\r\n这可以看作是子网掩码的特殊情况, 即没有借用主机号位作为子网号。\r\n无分类编址 (CIDR)\r\n划分子网的方法虽然提高了地址利用率，但仍然存在灵活性不足的问题。例如C类地址的主机号部分只有8位，最多只能划分出256个子网，而每个子网的主机数越划分越少，这仍然不够灵活。为此，引入了无分类编址\r\n(Classless Inter-Domain Routing, CIDR)。\r\nCIDR是目前因特网正在使用的编址方法，它消除了A、B、C类的概念，可以更有效地分配IP地址。\r\n核心思想是：IP地址再次回归二级结构，但更加灵活：网络前缀\r\n(Network-Prefix) + 主机号。网络前缀的长度是可变的。\r\n一般采用的记法是CIDR记法（斜线记法）：在IP地址后面加上斜线/和网络前缀的位数来表示地址块。例如：128.14.35.7/20\r\n表示前20位是网络前缀，后12位是主机号,\r\n转换为二进制是10000000.00001110.00100011.00000111,\r\n其中前20位 10000000.00001110.0010 是网络前缀，后12位\r\n0011.00000111 是主机号。\r\n\r\n\r\nalt text\r\n\r\n使用CIDR的一个好处是可以更灵活地划分网络。例如，假设一个组织需要一个包含1000台主机的网络。使用CIDR，可以选择一个合适的前缀长度来满足这个需求。\r\n另一个好处是CIDR支持路由聚合 (Route\r\nAggregation)，也称为构造超网(Supernetting),\r\n可以根据共同前缀将多个连续的网络地址块合并成一个更大的地址块，从而减少路由表的规模，提高路由效率。\r\nIPv4地址的应用规划\r\nIPv4地址的应用规划，指的是将一个给定的IPv4地址块（无论是传统的分类网络还是CIDR地址块），根据实际网络拓扑的需求，将其划分成若干个更小的地址块（即子网），然后将这些子网分配给互联网中的不同网络，并最终为各网络中的主机和路由器接口配置具体的IP地址的过程\r\n。\r\n这个规划过程主要有两种方法 ：\r\n\r\n采用定长的子网掩码 (Fixed Length Subnet Mask,\r\nFLSM)\r\n采用变长的子网掩码 (Variable Length Subnet Mask,\r\nVLSM)\r\n\r\n定长的子网掩码 (FLSM)\r\n在使用定长子网掩码（FLSM）进行子网划分时，所有划分出的子网都必须使用同一个子网掩码\r\n。这意味着每个子网分配到的IP地址数量是完全相同的，这种“一刀切”的方式虽然简单，但非常容易造成IP地址资源的浪费。\r\n假设我们申请到了一个C类网络\r\n218.75.230.0，需要为下图所示的5个网络进行地址分配。\r\n\r\n\r\nalt text\r\n\r\n第一步：统计各网络地址需求:\r\n我们需要计算每个网络总共需要多少个IP地址（包括主机、路由器接口、网络地址和广播地址）。\r\n第二步：确定子网掩码:\r\n确定所需子网数量：我们总共有5个独立的网络，需要划分出至少5个子网。我们需要从C类地址的8位主机号中借位来创建子网。如果借用n位作为子网号，则可以划分出2n\r\n个子网。因此，必须借3位，这样可以划分出 2^3 =8 个子网，满足需求。\r\nC类网络的默认掩码是 255.255.255.0 (即\r\n/24)。从主机位借走3位后，新的子网掩码变为 /27 (24+3=27)。/27\r\n对应的二进制掩码是 11111111.11111111.11111111.11100000,\r\n转换成点分十进制就是\r\n255.255.255.224。在FLSM中，所有5个网络都将使用这个掩码 。\r\n第三步：分配子网: 借用3位后，每个子网的主机位还剩下 8−3=5\r\n位，因此每个子网的大小为 2^5 =32\r\n个地址。我们可以从划分出的8个子网中任选5个进行分配 。 - 子网1 (000):\r\n218.75.230.0/27 (地址范围 .0 - .31) -&gt; 分配给网络1 - 子网2 (001):\r\n218.75.230.32/27 (地址范围 .32 - .63) -&gt; 分配给网络4 - 子网3 (010):\r\n218.75.230.64/27 (地址范围 .64 - .95) -&gt; 分配给网络2 …以此类推\r\nFLSM的缺点: 这种方法的弊端非常明显：地址浪费严重。以\r\n网络5\r\n为例，它实际只需要4个IP地址，但我们却不得不分配给它一个包含32个地址的子网，造成了28个地址的巨大浪费\r\n。\r\n变长的子网掩码 (VLSM)\r\n变长子网掩码（VLSM）允许对同一个主网络划分出的不同子网使用不同的子网掩码。这样就可以根据每个子网的实际需求来精确分配地址数量，从而最大限度地减少地址浪费。\r\n同样是上面的网络需求，但这次我们使用VLSM来从地址块 218.75.230.0/24\r\n进行规划。\r\n第一步：按需求排序并确定各子网所需的前缀长度\r\n我们通常将需求按从大到小的顺序排列，以方便划分，避免地址碎片。\r\n网络2 (需28个地址)：需要一个至少包含28个地址的块。2^5\r\n=32，满足需求。主机位需要5位，因此网络前缀为 32 - 5 = 27，即 /27。\r\n网络3 (需15个地址)：需要一个至少包含15个地址的块。2^4\r\n=16，满足需求。主机位需要4位，因此网络前缀为 32 - 4 = 28，即 /28。\r\n网络4 (需13个地址)：同样需要一个16个地址的块，前缀为 /28 。\r\n网络1 (需9个地址)：同样需要一个16个地址的块，前缀为 /28。\r\n网络5 (需4个地址)：需要一个至少包含4个地址的块。2^2\r\n=4，满足需求。主机位需要2位，因此网络前缀为 32 - 2 = 30，即 /30 。\r\n第二步：从大到小，依次划分地址块\r\n我们从 218.75.230.0/24\r\n这个大地址池中，像切蛋糕一样，一块一块地切分出去 。\r\n\r\n分配给网络2 (/27)：切出第一个块 218.75.230.0/27 (范围 .0 - .31),\r\n变成二进制是\r\n11011010.01001011.11100110.000xxxxx，其中前27位\r\n11011010.01001011.11100110.000 是网络前缀，后5位\r\nxxxxx 是主机号。\r\n分配给网络1 (/28)：从未分配的地址（从 .32 开始）中切出第二个块\r\n218.75.230.32/28 (范围 .32 - .47)。变成二进制是\r\n11011010.01001011.11100110.0010xxxx，其中前28位\r\n11011010.01001011.11100110.0010 是网络前缀，后4位\r\nxxxx 是主机号。\r\n分配给网络3 (/28)：继续切出第三个块 218.75.230.48/28 (范围 .48 -\r\n.63)。 变成二进制是\r\n11011010.01001011.11100110.0011xxxx，其中前28位\r\n11011010.01001011.11100110.0011 是网络前缀，后4位\r\nxxxx 是主机号。\r\n分配给网络4 (/28)：继续切出第四个块 218.75.230.64/28 (范围 .64 -\r\n.79) 。\r\n分配给网络5 (/30)：最后切出第五个块 218.75.230.80/30 (范围 .80 -\r\n.83) 。\r\n\r\nVLSM的优点:\r\n通过这种方式，每个子网都得到了大小最合适的地址块，实现了按需分配。网络5\r\n只需要4个地址，我们就精确地给了它一个包含4个地址的 /30\r\n块，完全没有造成地址浪费\r\n。剩余的172个地址（从.84到.255）可以留作未来扩展使用\r\n，极大地提高了IP地址的利用率。\r\nIPv4地址与MAC地址对比\r\n首先，我们需要理解这两种地址在TCP/IP协议体系结构中的位置。\r\nIP地址工作在网络层,\r\n它是一个逻辑地址，用于在整个因特网范围内唯一标识一台主机或路由器。在封装数据时，源IP地址\r\n和 目的IP地址 被封装在 IP数据报的首部 中 。\r\nMAC地址工作在网络接口层中的数据链路层。它是一个物理地址或硬件地址，固化在网络接口卡（网卡）上，用于在同一个局域网（或同一段链路）内标识一个具体的网络设备。在封装数据时，源MAC地址\r\n和 目的MAC地址 被封装在帧的首部中。\r\n如下图所示，应用层的数据逐层向下封装，IP地址在网络层添加，而MAC地址在更下一层的数据链路层添加。\r\n\r\n\r\nalt text\r\n\r\n并且,\r\n当一个数据包从源主机H1发送到不同网络的目的主机H2，途中经过路由器R1和R2时，两种地址的变化规律是截然不同的。\r\nIP地址：始终不变. 在整个传输过程中，IP数据报首部中的 源IP地址 (IP1)\r\n和目的IP地址 (IP2) 始终保持不变\r\n。它们标识的是通信的最初发起者和最终接收者。\r\nMAC地址：逐跳改变.\r\n数据链路层的帧首部中的源MAC地址和目的MAC地址在每一“跳”（hop）都会改变\r\n。它们标识的是当前这一段链路上的发送者和接收者。\r\n也就是说,\r\nIP地址负责“全程导航”（从起点到终点），而MAC地址负责“分段带路”（从当前一站到下一站）。\r\n\r\n\r\nalt text\r\n\r\n到这里,\r\n可能一个常见的问题是：既然最终数据是在链路上靠MAC地址找到设备的，为什么不直接只用MAC地址通信，而要引入IP地址呢？结论是,\r\n如果仅使用MAC地址进行通信，将会面临巨大的挑战 ：\r\n\r\n路由表爆炸：全世界每台路由器的路由表中，都必须记录因特网上所有主机和路由器接口的MAC地址\r\n。这是一个天文数字，完全不具备可扩展性。\r\n管理极其困难：手工配置如此庞大的路由表是不可能的。即使使用路由协议自动构建，海量的MAC地址信息也会严重占用网络带宽和路由器的存储空间\r\n。\r\n\r\n而使用IP地址则完美地解决了这个问题。IP地址的层级结构（网络号+主机号）使得路由器只需记录到目标网络的路由，而无需记录网络内每一台主机的地址。这使得路由表的规模大大减小。\r\n但是这就引出了另一个问题：路由器根据目的IP地址查路由表，知道了下一跳路由器的IP地址，但它不知道下一跳的MAC地址，数据链路层无法封装帧，怎么办？\r\n这个“IP地址到MAC地址的最后一公里映射问题”，正是由地址解析协议（ARP）来解决的\r\n。ARP负责在局域网内动态地查询IP地址对应的MAC地址，从而将网络层的IP寻址和数据链路层的MAC寻址无缝地衔接起来。\r\nARP 协议\r\nARP (Address Resolution Protocol)，即“地址解析协议”,\r\n用于在一个局域网（LAN）内，将一个已知的IP地址（逻辑地址）解析（翻译）成对应的MAC地址（物理地址）。\r\n当主机A想要给同一局域网内的主机B发送数据时，主机A通常只知道主机B的IP地址（例如，你在ping\r\n192.168.1.101）。但是，数据在局域网内最终是以数据帧的形式传播的，而帧的头部必须包含目标MAC地址。交换机根据这个MAC地址来转发帧。因此，主机A在发送数据之前，必须先获得主机B的MAC地址。\r\nARP的工作原理\r\nARP的工作过程可以分为两个核心步骤：ARP请求 和\r\nARP应答。我们通过一个例子来说明。\r\n假设局域网内有两台主机：\r\n\r\n主机A: IP地址 192.168.1.100，MAC地址 AA-AA-AA-AA-AA-AA\r\n主机B: IP地址 192.168.1.101，MAC地址 BB-BB-BB-BB-BB-BB\r\n\r\n现在，主机A 想要向 主机B 发送数据。\r\n步骤1：检查ARP缓存\r\n主机A首先会检查自己的 ARP缓存表（ARP\r\nCache）。这是一个存储了近期IP地址与MAC地址映射关系的动态表格(为了提高效率，避免每次通信都进行一次广播查询)。\r\n如果找到 192.168.1.101\r\n对应的MAC地址，则直接使用该地址封装数据帧并发送，整个ARP过程结束;\r\n如果没有找到，则进入下一步。\r\n步骤2：发送ARP请求（广播）\r\n主机A会在局域网内发送一个 ARP请求（ARP Request）\r\n报文。\r\n这个请求的核心信息是：“谁的IP地址是 192.168.1.101？请告诉我的IP地址\r\n192.168.1.100，我的MAC地址是 AA-AA-AA-AA-AA-AA”。\r\n这个ARP请求报文会被封装在一个以太网帧中。这个帧的特殊之处在于源MAC地址是主机A的MAC地址\r\n(AA-AA-AA-AA-AA-AA),\r\n目标MAC地址却是一个特殊的广播地址\r\n(FF-FF-FF-FF-FF-FF)。使用广播地址意味着这个帧会被发送到该局域网内的所有设备。\r\n步骤3：网络中所有主机处理ARP请求\r\n局域网内的所有设备（包括主机B和其他主机）都会接收到这个广播帧。\r\n其他主机会检查ARP请求中的目标IP地址（192.168.1.101），发现与自身的IP地址不符，因此会静默丢弃这个请求，不作任何响应。\r\n而主机发现ARP请求中的目标IP地址正是自己的IP地址, 执行下一个阶段。\r\n步骤4：发送ARP应答（单播）\r\n主机B在确认请求是发给自己的之后，会构造一个 ARP应答（ARP Reply）\r\n报文。\r\n报文内容：应答的核心信息是：“我就是 192.168.1.101，我的MAC地址是\r\nBB-BB-BB-BB-BB-BB”。\r\n这个ARP应答报文也会被封装在一个以太网帧中，但这次是单播：源MAC地址是主机B的MAC地址\r\n(BB-BB-BB-BB-BB-BB), 目标MAC地址是主机A的MAC地址\r\n(AA-AA-AA-AA-AA-AA)。主机B之所以知道主机A的MAC地址，是因为它在最初的ARP请求中已经包含了。\r\n单播可以直接将应答信息发送给请求者（主机A），而不需要再打扰网络中的其他设备。\r\n步骤5：更新ARP缓存并通信\r\n主机A收到主机B的ARP应答后，就获取了 192.168.1.101 对应的MAC地址\r\nBB-BB-BB-BB-BB-BB。\r\n接着,\r\n主机A会将这个映射关系存入自己的ARP缓存表，并设置一个老化时间（例如2分钟）。在老化时间内，再次向\r\n192.168.1.101\r\n发送数据时，就可以直接从缓存中查找，无需再次发送ARP请求。\r\n主机A现在可以愉快地将数据封装成以太网帧（目标MAC为BB-BB-BB-BB-BB-BB），并通过交换机准确地发送给主机B了。\r\n总之, ARP\r\n协议可以认为是网络层在与数据链路层交互时所使用的一个“工具”或“接口”,\r\n利用网络层的IP地址获取数据链路层的MAC地址，以便在物理网络上进行通信\r\nARP高速缓存表\r\nARP缓存表中的记录分为两种类型 ：\r\n\r\n动态\r\n(Dynamic)：通过ARP协议自动获取的记录。它们有一个生命周期（例如2分钟），到期后会自动删除，以适应网络中可能发生的变化（如某台主机的网卡更换导致MAC地址改变）。\r\n静态 (Static)：由网络管理员手动配置的记录，通常不会自动过期\r\n。\r\n\r\nARP的范围限制\r\n一个非常重要的概念是，ARP协议只能在同一个局域网（或同一个广播域）上使用，不能跨网络（即跨路由器）工作\r\n。\r\n当主机H1要给另一个网络的主机H2发送数据时，它实际上是使用ARP来查找它的\r\n默认网关（路由器R1）\r\n的MAC地址。数据包在跨越多个网络的每一段链路（例如 H1\r\n-&gt; R1, R1 -&gt; R2, R2 -&gt;\r\nH2）上，都会独立地使用一次ARP协议来解析下一跳的MAC地址 。\r\nIP数据报的发送和转发过程\r\n该过程包含两个主要部分：主机如何发送IP数据报，以及路由器如何转发IP数据报。\r\n主机发送IP数据报:\r\n主机发送IP数据报时，首先需要判断目的主机是在同一个网络还是在不同的网络，这决定了数据报的交付方式\r\n。\r\n\r\n直接交付：当源主机和目的主机在同一个网络中时，它们之间可以直接通信。\r\n\r\n源主机会通过ARP协议获取目的主机的MAC地址，然后将IP数据报封装成帧直接发送给对方\r\n\r\n间接交付：当源主机和目的主机位于不同网络时，通信需要通过它们的默认网关（路由器）来中转。\r\n\r\n源主机会将IP数据报发送给自己的\r\n默认网关，由网关来负责后续的转发。\r\n\r\n\r\n至于如何判断目的主机是否在同一网络，源主机会通过一个简单的计算来判断:\r\n将源主机的IP地址和子网掩码进行按位与运算，得到源主机的网络地址；然后将目的主机的IP地址和同样的子网掩码进行按位与运算，得到目的主机的网络地址。如果两个网络地址相同，则说明两台主机在同一个网络中；否则，它们在不同的网络中。\r\n路由器转发IP数据报:\r\n当路由器收到一个IP数据报后，如果数据报是有效的（首部无误码且生存时间未耗尽），它会基于数据报首部中的目的IP地址，在自己的路由表中进行查询\r\n。\r\n\r\n如果查询到匹配的路由条目，就按照该条目的指示进行转发 。\r\n如果查询不到匹配的条目，路由器会丢弃该IP数据报，并向源主机发送一个ICMP差错报告报文\r\n\r\n路由器查表转发过程: 假设主机A向主机D发送一个IP数据报，其源地址为\r\n192.168.0.1，目的地址为 192.168.0.129\r\n。该数据报通过间接交付被发送到路由器R。\r\n\r\n\r\nalt text\r\n\r\n首先,\r\n路由器R收到数据报后，首先检查数据报的完整性和生存时间。如果数据报有效，R会提取目的IP地址\r\n192.168.0.129\r\n。然后，R会在自己的路由表中查找该目的地址的最佳匹配条目。\r\n逐条匹配路由表：路由器R会用路由表中每条条目的地址掩码与数据报的目的地址进行按位与运算，并将结果与该条目的目的网络地址进行比较。\r\n\r\n匹配第一条：将 192.168.0.129 与第一条路由的掩码 255.255.255.128\r\n(/25) 进行“与”运算，结果是 192.168.0.128 。这个结果与第一条的目的网络\r\n192.168.0.0 不匹配 。\r\n匹配第二条：将 192.168.0.129 与第二条路由的掩码 255.255.255.128\r\n(/25) 进行“与”运算，结果是 192.168.0.128 。这个结果与第二条的目的网络\r\n192.168.0.128 匹配 。\r\n\r\n执行转发：路由器R找到了匹配的第二条路由条目,\r\n该条目的“下一跳”指示为“接口1直连”\r\n。这意味着目的主机D就在路由器R的接口1所连接的网络上。路由器R会通过ARP协议获取主机D的MAC地址，然后将IP数据报封装成帧，从接口1直接交付给主机D\r\n。\r\n对广播数据报的处理:\r\n路由器是隔离广播域的。如果路由器收到的是一个目的地址为广播地址（如\r\n192.168.0.127 或\r\n255.255.255.255）的IP数据报，它不会对这种数据报进行转发。这样做是为了防止广播数据报在整个因特网中泛滥，造成巨大的网络风暴和资源浪费。\r\nIP数据报的首部格式\r\nIP数据报的首部格式及其内容是实现IP协议所有功能的基础\r\n。IPv4数据报的首部由一个 20字节的固定部分 和一个最大 40字节的可变部分\r\n组成\r\n。固定部分是每个IPv4数据报都必须包含的，而可变部分（可选字段）则用于增加一些特殊功能，但很少被使用\r\n。\r\n在TCP/IP标准中，数据格式常以32比特（4字节）为单位来描述，首部格式的每一行都代表4个字节\r\n\r\n\r\nalt text\r\n\r\n以下是IPv4数据报首部中各个字段的详细含义：\r\n\r\n版本 (Version)\r\n\r\n长度：4比特 。\r\n功能：用来表示IP协议的版本 。通信双方使用的IP协议版本必须一致\r\n。目前广泛使用的版本号为4，即IPv4 。\r\n\r\n首部长度 (Header Length)、可选字段和填充\r\n\r\n首部长度：\r\n\r\n长度：4比特 。\r\n功能：该字段的取值以 4字节 为单位，用来表示整个IPv4数据报首部的长度\r\n。\r\n取值范围：最小值为二进制0101（即十进制5），表示首部长度为 5×4=20\r\n字节，此时首部只包含固定部分\r\n。最大值为二进制1111（即十进制15），表示首部长度为 15×4=60 字节 。\r\n\r\n可选字段 (Options)：\r\n\r\n长度：从1字节到40字节不等 。\r\n功能：用来支持排错、测量以及安全等措施\r\n。但由于它会增加路由器处理数据报的开销，因此很少被使用 。\r\n\r\n填充 (Padding)：\r\n\r\n功能：由于可选字段的长度可变，可能导致首部总长度不是4字节的整数倍。填充字段用全0来补足，以确保首部长度始终是4字节的整数倍\r\n。\r\n\r\n\r\n区分服务 (Differentiated Services)\r\n\r\n长度：8比特 。\r\n功能：用来获得更好的服务质量（QoS）\r\n。这个字段在旧标准中被称为服务类型（ToS），但一直未被广泛使用\r\n。一般情况下不使用该字段 。\r\n\r\n总长度 (Total Length)\r\n\r\n长度：16比特 。\r\n功能：该字段的取值以 字节\r\n为单位，用来表示整个IPv4数据报的长度（即首部长度\r\n+ 数据载荷长度） 。\r\n取值范围：最大值为 216\r\n−1 = 65535 字节 。\r\n\r\n标识 (Identification)、标志 (Flags) 和 片偏移 (Fragment Offset)\r\n这三个字段共同用于IP数据报的 分片与重组\r\n。当一个IP数据报的长度超过了链路的最大传送单元（MTU）时，就必须将其分割成更小的片段（分片）进行传输\r\n。\r\n\r\n标识 (Identification)：\r\n\r\n长度：16比特 。\r\n功能：这是一个唯一的标识符。当一个数据报被分片后，所有这些分片都具有\r\n相同的标识值，这样目的主机就能知道哪些分片属于同一个原始数据报 。\r\n\r\n标志 (Flags)：\r\n\r\n长度：3比特 。\r\n功能：\r\n\r\n最低位 (MF - More Fragments)：MF=1 表示后面还有分片；MF=0\r\n表示这是最后一个分片 。\r\n中间位 (DF - Don’t Fragment)：DF=1 表示不允许分片；DF=0 表示允许分片\r\n。\r\n最高位：保留位，必须为0 。\r\n\r\n\r\n片偏移 (Fragment Offset)：\r\n\r\n长度：13比特 。\r\n功能：该字段的取值以 8字节\r\n为单位，用于指明当前分片的数据载荷部分相对于原始数据报数据载荷部分的起始位置\r\n。\r\n\r\n\r\n生存时间 (Time To Live, TTL)\r\n\r\n长度：8比特 。\r\n功能：该字段的目的是防止IP数据报在网络中因路由环路而无限循环 。\r\n工作机制：每经过一个路由器，该字段的值就 减1\r\n。当TTL的值变为0时，路由器会丢弃该数据报，并向源主机发送一个ICMP时间超过的差错报告\r\n。\r\n\r\n协议 (Protocol)\r\n\r\n长度：8比特 。\r\n功能：用来指明该IP数据报的数据载荷部分封装的是哪一种上层协议的数据单元（PDU）\r\n。\r\n常用协议值：TCP为6，UDP为17，ICMP为1，OSPF为89 。\r\n\r\n首部检验和 (Header Checksum)\r\n\r\n长度：16比特 。\r\n功能：用于检测IPv4数据报的首部在传输过程中是否出现了差错。它不检验数据载荷部分，以减少计算量。\r\n工作机制：\r\n\r\n发送方：将首部划分为多个16比特的字，然后用反码算术运算求和，最后将结果的反码写入检验和字段\r\n。\r\n接收方/路由器：将收到的首部所有16比特字（包括检验和字段本身）再次用反码算术运算求和。如果结果为全1（取反码后为0），则表示首部没有出错；否则表示出现差错，丢弃该数据报\r\n。\r\n由于TTL字段在每经过一个路由器时都会改变，所以\r\n每个路由器都必须重新计算首部检验和 。\r\n\r\n在IPv6中，取消了首部检验和字段，以简化路由器的处理流程，提高转发效率\r\n。\r\n\r\n源IP地址 (Source IP Address) 和 目的IP地址 (Destination IP\r\nAddress)\r\n\r\n长度：均为32比特 。\r\n功能：分别用来填写发送该IP数据报的源主机的IP地址和接收该IP数据报的目的主机的IP地址\r\n。\r\n\r\n\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"路由","url":"/2025/10/13/web/Computer%20Network/%E7%BD%91%E7%BB%9C%E5%B1%82/%E8%B7%AF%E7%94%B1/%E8%B7%AF%E7%94%B1/","content":"路由器\r\n路由器（Router）是一种计算机网络设备，它工作在OSI模型和TCP/IP模型中的第三层——网络层\r\n(Network Layer)。它拥有多个输入端口和输出端口,\r\n专门用于连接不同的网络，并负责在这些网络之间转发数据包 (Packet) 。\r\n与工作在第二层（数据链路层）的交换机（Switch）不同：\r\n\r\n交换机：主要负责在同一个局域网（LAN）内部转发数据，它根据设备的物理地址（MAC地址）来做决策\r\n路由器：则负责连接不同的网络（例如，你家的局域网与互联网），它根据逻辑地址（IP地址）来做决策\r\n\r\n网络层的两大功能是分组转发和路由选择,\r\n而路由器的所有功能都围绕这两个问题展开，具体体现在以下几个方面：\r\n逻辑寻址 (Logical Addressing):\r\n网络层使用IP地址作为设备的逻辑地址。这个地址是分层的，包含了网络部分和主机部分，这使得路由器能够判断一个设备是否属于同一个网络。\r\n当路由器收到一个数据包时，它会检查其“信封”上的目的IP地址。这是路由器做出所有决策的基础。它通过这个地址来识别数据包最终要去往的那个遥远的网络。\r\n路径选择\r\n(Path Determination / Routing)\r\n这是路由器最“智能”的部分。路由器内部维护着一张名为路由表\r\n(Routing\r\nTable)的动态地图。这张表详细记录了去往各个已知网络的路径信息。\r\n一张路由表通常包含以下关键信息： - 目标网络 (Destination\r\nNetwork)：要去往的网络的地址。 - 子网掩码 (Subnet\r\nMask)：用于确定目标网络的范围。 - 下一跳 (Next\r\nHop)：要到达目标网络，应该将数据包交给的下一个路由器的IP地址。 - 出接口\r\n(Outgoing Interface)：将数据包从本路由器的哪个物理端口（如\r\nGigabitEthernet0/1）发出去。 - 度量值\r\n(Metric)：一个衡量路径“好坏”的数值。度量值越小，路径通常越优。\r\n路由器通过三种方式学习并构建这张“地图”：\r\n\r\n直连网络 (Directly\r\nConnected)：路由器启动后，会自动识别与其物理端口直接相连的网络。\r\n静态路由 (Static\r\nRouting)：由网络管理员手动配置的永久性路由。适用于网络结构简单且固定的场景。\r\n动态路由 (Dynamic\r\nRouting)：路由器之间通过运行特定的路由协议（如OSPF,\r\nBGP,\r\nRIP等）来自动交换路由信息，动态地学习网络拓扑结构，并自动计算出最佳路径。这是大型网络保持高效运行的关键。\r\n\r\n\r\n此外, 转发表 (Forwarding Table)\r\n是路由器用来实际执行数据包转发的表格。它通常是从路由表中提取和优化而来，结构更简单，便于快速查找。\r\n\r\n\r\n\r\nalt text\r\n\r\n数据包转发 (Packet\r\nForwarding)\r\n一个数据分组从进入路由器到离开的完整流程如下：\r\n\r\n输入端口接收：\r\n\r\n物理层：信号从某个输入端口进入路由器，物理层将其从电信号转换为比特流\r\n。\r\n数据链路层：数据链路层从比特流中识别出完整的帧，去掉帧头和帧尾后，将内部的数据分组（IP数据报）向上交付给网络层处理\r\n。\r\n\r\n网络层处理：网络层会根据分组的类型进行不同的处理：\r\n\r\n情况一：普通待转发的数据分组\r\n\r\n查表转发：网络层会提取分组首部中的目的IP地址，在 转发表\r\n中进行快速查找 。\r\n\r\n如果找不到匹配的转发条目，该分组将被丢弃 。\r\n如果找到匹配条目，则按照条目中指示的输出端口进行转发 。\r\n\r\n首部更新：在转发前，网络层会更新数据分组首部中的某些字段，最典型的就是将\r\n生存时间 (TTL) 减1 。\r\n交付输出：更新后的分组被向下交付给相应输出端口的数据链路层\r\n。\r\n\r\n情况二：携带路由报文的路由分组\r\n\r\n当网络层识别出这是一个路由协议的分组时（如RIP或OSPF报文），它不会被转发，而是被送交给路由选择处理机\r\n。\r\n路由选择处理机根据路由报文的内容来更新自己的路由表 。\r\n\r\n\r\n交换结构 (Switching\r\nFabric)：这是路由器的关键构件，负责将分组从输入端口物理地传送到正确的输出端口,\r\n其速率对路由器的整体性能至关重要 。\r\n输出端口发送：\r\n\r\n数据链路层：从网络层接收到数据分组后，将其重新封装成帧（添加新的帧头和帧尾）\r\n。\r\n物理层：将帧看作比特流，并将其转换为相应的电信号，通过物理链路发送出去\r\n。\r\n\r\n\r\n此外, 路由器还具备输入缓冲区,\r\n用于暂存新进入路由器但还来不及处理的分组, 和输出缓冲区,\r\n用于暂存已经处理完毕但还来不及发送的分组，例如当输出链路繁忙时。\r\n静态路由配置\r\n静态路由配置是指由用户或网络运维人员通过路由器的相关命令，手动为路由器添加路由表条目的一种方式。这种方式不依赖于任何路由选择协议，路由信息不会自动更新或交换，完全由人工维护。\r\n优点：这种方法实现简单，对路由器的处理开销小 。\r\n缺点：它不能自动适应网络状态（如流量、拓扑结构等）的变化。因此通常只在小规模的网络中采用\r\n。\r\n直连路由\r\n(Directly Connected Route)和非直连路由 (Non-Directly Connected\r\nRoute)\r\n当网络运维人员为路由器的各个接口配置了IP地址和地址掩码后，路由器能够自行得出它直接连接了哪些网络。这些由路由器自动生成的、指向其直连网络的路由条目，就称为直连路由\r\n。\r\n\r\n\r\nalt text\r\n\r\n如图, 路由器R1的接口0配置了IP地址\r\n192.168.1.254/24，因此R1自动知道它与网络 192.168.1.0/24 是直连的 。\r\n同样，R1的接口1配置了IP地址 10.0.0.1/30，因此它也自动知道与网络\r\n10.0.0.0/30 是直连的 。\r\n这两条路由被自动记录在R1的路由表中，类型为“直连” 。\r\n而对于那些不是直接连接的网络，路由器无法自动知道如何到达。此时，需要通过人工配置（即静态路由配置）或动态路由选择协议来告诉路由器如何到达这些网络。通过人工配置的条目就是非直连的静态路由。\r\n在上图中, 路由器R1并不知道如何到达网络\r\n192.168.2.0/24，因为它与该网络非直连 。\r\n网络管理员需要手动为R1配置一条静态路由，告诉它：“要去往目的网络\r\n192.168.2.0/24，下一跳地址是 10.0.0.2（即R2的接口地址）” 。\r\n这条手动添加的路由条目就属于非直连路由，类型为“静态” 。\r\n默认路由和特定主机路由\r\n除了上述两种路由，运维人员还可以配置两种特殊的静态路由：默认路由和特定主机路由\r\n。\r\n默认路由 (Default Route):\r\n当路由器在路由表中查找一个目的地址，但找不到任何匹配的路由条目时，如果没有默认路由，它会丢弃该数据包\r\n。如果配置了默认路由，路由器就会按照默认路由条目中指示的“下一跳”地址进行转发\r\n。\r\n它是一种特殊的路由条目，用于匹配所有未在路由表中明确列出的目的网络地址。它相当于一个“兜底”的选项，确保路由器不会因为找不到匹配的路由而丢弃数据包\r\n。\r\n优点：使用默认路由可以极大地减少路由表的大小和搜索路由表所耗费的时间。\r\n配置方式：默认路由的目的网络地址通常被配置为\r\n0.0.0.0/0 。其中 0.0.0.0 代表任意网络，而网络前缀 /0\r\n是最短的网络前缀，这意味着它的匹配优先级最低，只有在所有其他路由都不匹配时才会被使用\r\n。\r\n特定主机路由 (Specific Host Route):\r\n这是一种专门为某一台特定的主机配置的路由条目，通常用于网络管理、测试或出于安全考虑\r\n。\r\n配置方式：特定主机路由的目的网络地址被配置为该主机的IP地址，并且网络前缀为\r\n/32（地址掩码为 255.255.255.255） 。/32\r\n是最长的网络前缀，根据“最长前缀匹配”原则，这条路由的匹配优先级是最高的。\r\n优点：特定主机路由允许网络管理员为某个主机指定一条独特的路径，绕过常规的路由选择逻辑。这在某些情况下非常有用，例如需要对某个服务器进行特殊的流量管理或监控时。\r\n因特网采用分层次的路由选择协议\r\n因特网/Internet\r\n是全球规模最大的互联网，要在如此庞大的网络中高效、准确地找到数据传输的路径，单一的路由选择策略是不可行的。因此，因特网采用了具有以下三个主要特点的路由选择协议\r\n：\r\n\r\n自适应\r\n(Adaptive)：因特网采用动态路由选择，能够根据网络流量和拓扑结构的变化自动调整路由，而不是依赖人工干预\r\n。\r\n分布式\r\n(Distributed)：因特网中的路由器通过相互交换信息，共同协作来完成路由的计算和更新，而不是由一个中央控制器来决定所有路径\r\n。\r\n分层次\r\n(Hierarchical)：这是最关键的特点。它将整个庞大的因特网划分为许多较小的、可管理的部分，称为\r\n自治系统 (Autonomous System, AS) 。\r\n\r\n一个自治系统（AS）是在一个单一技术管理机构下的路由器和网络的集合。例如，一个大型的互联网服务提供商（ISP）、一所大学或一个大型公司的网络都可以被视为一个自治系统\r\n。\r\n目的：通过将因特网划分为多个AS，可以将复杂的路由问题分解为两个层次来处理：自治系统内部的路由选择和自治系统之间的路由选择。\r\n\r\n\r\n两种层次的路由选择协议\r\n基于自治系统的划分，路由选择协议也被相应地分为了两大类 ：\r\n域内路由选择 (Intradomain Routing):\r\n在一个自治系统内部进行的路由选择。\r\n\r\n使用的协议：内部网关协议 (Interior Gateway\r\nProtocol, IGP)。\r\n常见的IGP协议：路由信息协议\r\n(RIP)、开放最短路径优先 (OSPF)。\r\n特点：每个自治系统可以自由选择适合自己的IGP，而无需考虑其他AS使用什么协议。例如，图4-61中，自治系统AS1内部使用RIP协议，而AS2内部使用OSPF协议，它们互不影响。\r\n\r\n\r\n\r\nalt text\r\n\r\n域间路由选择 (Interdomain Routing):\r\n在不同的自治系统之间进行的路由选择。\r\n\r\n使用的协议：外部网关协议 (External Gateway\r\nProtocol, EGP)。\r\n常见的EGP协议：边界网关协议 (BGP)\r\n是目前事实上的标准。\r\n特点：EGP负责在各个AS的边界路由器之间交换可达性信息，从而将整个因特网连接成一个整体。\r\n\r\n\r\n在早期的RFC文档中，“路由器”被称为“网关”(Gateway)。因此，协议名称中的“网关”实际上指的就是“路由器”。所以，IGP和EGP也可以被称为内部路由协议（IRP）和外部路由协议（ERP）。\r\n\r\n通过这种分层次的结构，因特网的路由问题被有效地简化了。AS内部的路由器只需关注内部网络的拓扑细节，而AS之间的路由器则只需关注如何到达其他AS，无需了解对方内部的复杂情况。这种“内部精细，外部概括”的策略，是因特网能够扩展到全球规模的关键所在。\r\n路由信息协议\r\n(Routing Information Protocol, RIP)\r\n路由信息协议（RIP）是最早得到广泛使用的内部网关协议（IGP）之一。它是一种基于距离向量\r\n(Distance-Vector) 算法的协议。\r\n下面是几个RIP的关键概念：\r\n\r\n距离向量：RIP要求自治系统内的每个路由器都维护一张路由表，表中记录了从它自己到AS内其他每一个网络的“距离”\r\n。\r\n距离度量 (Metric)：RIP使用 跳数\r\n(Hop Count)\r\n作为衡量到达目的网络距离的度量。路由器到其直连网络的距离定义为 1,\r\n到非直连网络的距离定义为所经过的路由器数量加1 。\r\n\r\n且 RIP 规定一条路径最多只能包含15个路由器，即最大跳数为15\r\n。当距离达到 16\r\n时，即被认为是不可达。这个限制使得RIP只适用于小型互联网。\r\n\r\n路由更新：RIP路由器通过周期性地（通常每隔30秒）向其所有邻居路由器广播自己的完整路由表来交换路由信息\r\n。此外，当网络拓扑发生变化时，路由器会立即发送更新信息，这被称为触发更新\r\n。\r\n最佳路由选择：RIP认为“好”的路由就是“距离短”的路由，也就是所经过路由器数量最少的路径。即使某条路径带宽更高、速度更快，但只要其经过的路由器数量多，RIP也不会认为它是最佳路径。\r\n等价负载均衡：当到达同一个目的网络有多条距离（跳数）相等的路径时，RIP可以将通信流量均衡地分布到这几条等价的路径上。\r\n\r\nRIP的三个重要特点：\r\n\r\n和谁交换信息：仅和相邻的路由器交换信息（即中间没有其他路由器的直连路由器）\r\n。\r\n交换什么信息：交换的信息是路由器 自己的完整路由表 。\r\n何时交换信息：周期性地（例如每隔30秒）交换\r\n。此外，当网络拓扑发生变化时，路由器会立即发送更新信息，这被称为触发更新。\r\n\r\nRIP的基本工作过程\r\n\r\n初始化：路由器刚开始工作时，它的路由表中只包含到达其直连网络的信息，距离为1。\r\n信息交换与更新：每个路由器周期性地向其所有相邻路由器发送自己的路由表。收到信息的路由器会根据后述的距离向量算法来更新自己的路由表\r\n。\r\n收敛：经过若干次交换和更新后，网络中所有的路由器最终都会学习到到达本自治系统内所有网络的最短距离和下一跳地址。这个所有路由表都达到稳定、一致状态的过程，称为收敛。\r\n\r\nRIP的距离向量算法\r\n当一个路由器（如D）收到其相邻路由器（如C）发来的RIP更新报文（即C的路由表）后，它会按以下规则更新自己的路由表：\r\n\r\n修改收到的路由信息：路由器D首先会对收到的C的路由表进行修改：将所有路由条目的下一跳地址改为C，并将所有条目的距离（跳数）加1。这是因为D要通过C才能到达那些网络，所以距离自然要增加一跳。\r\n更新自己的路由表：然后，D将修改后的信息与自己的现有路由表进行比较，并按以下规则更新：\r\n\r\n新网络：如果收到的路由信息中包含一个D的路由表中没有的网络，则直接添加这条新路由。\r\n相同下一跳：如果到达某个目的网络的下一跳本来就是C，那么无论C通告来的新距离是变大还是变小，D都更新为这个最新的距离。\r\n\r\n这会保持路由信息的最新性，但也可能引入不稳定性（如路由环路）。\r\n\r\n不同下一跳：如果到达某个目的网络的下一跳不是C，则根据新距离与原距离的比较，采取不同的更新策略：\r\n\r\n距离更短：如果通过C到达的新距离比原来的距离更短，则D更新路由条目，将下一跳改为C，并更新距离。\r\n距离相等：如果通过C到达的距离与原来的距离相等，则D添加这条新路由，用于等价负载均衡。\r\n距离更长：如果通过C到达的新距离比原来的距离更长，则不更新，保留原来的更优路径。\r\n\r\n\r\n\r\n\r\n\r\nalt text\r\n\r\nRIP存在的问题\r\nRIP最著名的问题是\r\n“坏消息传播得慢”，也称为路由环路或距离无穷计数问题\r\n。\r\n问题成因：当网络中某个链路出现故障（“坏消息”）时，路由器可能不会立即收到这个故障信息，反而会从邻居那里收到一个基于旧拓扑的、错误的“好”路由信息。这会导致两个或多个路由器之间形成一个数据包的转发环路\r\n。它们会相互更新路由，导致到达目标网络的距离不断增加，直到达到16（不可达）为止\r\n。这个过程可能持续数分钟，严重影响网络收敛速度 。\r\n\r\n\r\nalt text\r\n\r\n如图, R1已经无法到达网络N1,\r\n但是当R1收到R2发来的路由信息时，R1会被误导, 认为还可以通过R2到达网络,\r\n因此R1会更新自己的路由表, 将到达网络的下一跳改为R2, 并将距离加1.\r\n然而实际上, R2本来就是通过R1到达该网络的, 但是由于不知道R1那边已经断开,\r\n错误地发送了更新报文, 而R1对于距离更短的报文是一律接受的.\r\n现在R1又通过R2到达该网络, 这样就形成了一个环路.\r\n数据包会在R1和R2之间不断循环, 跳数也会不断增加, 直到达到16（不可达）为止\r\n。\r\n解决措施： -\r\n限制最大跳数：将最大距离限制为15，使得距离可以快速增长到16（不可达），从而打破环路\r\n。 -\r\n触发更新：当路由表变化时立即发送更新，而不是等待周期计时器\r\n。 - 水平分割 (Split\r\nHorizon)：路由器不应将从一个接口学到的路由信息再通过同一个接口发回\r\n。\r\n注意：这些措施只能减少问题发生的概率，但无法从根本上彻底解决距离向量算法的这个固有问题\r\n。\r\n现在总结一下RIP的优缺点：\r\n优点： - 实现简单，对路由器开销小 。 -\r\n“好消息”（发现更短的路径）传播得很快 。\r\n缺点： - 最大15跳的限制使得网络规模受限 。 -\r\n交换的是完整路由表，随着网络规模扩大，开销也随之增加 。 -\r\n“坏消息传播得慢”，导致收敛时间过长\r\n。因此，对于规模较大的网络，应使用OSPF协议\r\n开放最短路径优先\r\n(Open Shortest Path First, OSPF)\r\n开放最短路径优先 (OSPF) 协议是为了克服路由信息协议 (RIP)\r\n的缺点而开发的一种内部网关协议 (IGP) 。它基于链路状态\r\n(Link State)\r\n算法，而不是RIP所使用的距离向量算法，这从根本上保证了不会产生路由环路\r\n。OSPF具有更新效率高、收敛速度快且不限制网络规模的特点 。\r\nOSPF的几个关键概念：\r\n\r\n链路状态 (Link\r\nState)：指本路由器与哪些路由器相邻，以及到每个相邻路由器的链路“代价(cost)”是多少\r\n。\r\n代价\r\n(Cost)：是一个用于衡量路径优劣的指标，可以代表费用、距离、时延或带宽等，由网络管理员决定。例如,\r\n代价可以根据链路带宽计算（100Mb/s 除以链路带宽,\r\n带宽越大，代价越小）\r\n邻居关系的建立：OSPF路由器之间通过周期性地交互问候\r\n(Hello) 分组来发现和维护邻居关系\r\n。Hello分组通常每10秒发送一次，如果40秒内未收到邻居的Hello分组，则认为该邻居不可达\r\n。\r\n链路状态通告\r\n(LSA)：每个路由器都会产生链路状态通告\r\n(LSA)，其中包含了该路由器直连网络的链路状态信息以及其所有邻居路由器的链路状态信息\r\n。\r\n链路状态更新 (LSU)\r\n与洪泛法(Flooding)：LSA被封装在链路状态更新分组 (LSU)\r\n中，并采用洪泛法 (Flooding)\r\n在整个区域内发送。洪泛法指路由器将信息从所有接口发送给所有邻居，邻居再继续转发，最终使得区域内所有路由器都收到该信息\r\n。\r\n链路状态数据库\r\n(LSDB)：每个运行OSPF的路由器都有一个链路状态数据库\r\n(LSDB)，用于存储收集到的所有LSA\r\n。通过洪泛，最终区域内所有路由器的LSDB将达到一致和同步\r\n。\r\n最短路径优先计算：当LSDB同步后，每个路由器都会基于这个完整的拓扑数据库，使用\r\nDijkstra提出的最短路径算法，计算出以自己为根节点到区域内所有其他节点的最短路径，从而构建出自己的路由表\r\n。\r\n\r\n\r\n\r\nalt text\r\n\r\nOSPF的五种分组类型\r\nOSPF协议定义了五种不同类型的分组来完成其工作 ：\r\n\r\n问候 (Hello) 分组：用于发现和维护邻居路由器的可达性 。\r\n数据库描述 (DBD)\r\n分组：向邻居路由器发送自己LSDB中所有链路状态项目的摘要信息 。\r\n链路状态请求 (LSR) 分组：向邻居请求发送某些链路状态项目的详细信息\r\n。\r\n链路状态更新 (LSU) 分组：用于洪泛发送具体的链路状态信息 。\r\n链路状态确认 (LSAck) 分组：对收到的LSU分组进行确认 。\r\n\r\nOSPF的基本工作过程\r\n下图是OSPF的基本工作流程： \r\n\r\n邻居发现与建立：路由器通过发送Hello分组来发现和建立邻居关系。收到Hello分组的路由器会回复一个Hello分组，确认邻居关系的建立。\r\n数据库同步：邻居关系建立后，路由器会通过数据库描述 (DBD)\r\n分组交换各自的链路状态信息，确保彼此的链路状态数据库 (LSDB) 一致。\r\n假设路由器R1收到R2的DBD分组，发现R2有一些R1没有的链路状态信息，于是R1发送链路状态请求\r\n(LSR) 分组，向R2请求这些缺失的LSA。\r\nR2收到LSR后，会将缺失的LSA封装在链路状态更新 (LSU)\r\n分组中，发送给R1。\r\nR1收到LSU后，更新自己的LSDB，并发送链路状态确认 (LSAck)\r\n分组给R2，确认已收到这些LSA。\r\n假如R1的LSDB发生了变化（例如，某个链路状态改变），它会生成新的LSA，并通过LSU分组洪泛发送给所有邻居。邻居收到后，更新自己的LSDB，并继续洪泛转发，直到整个区域内的所有路由器都收到该信息。\r\n当LSDB同步完成后，每个路由器都会使用Dijkstra最短路径算法，基于LSDB计算出从自己到区域内所有其他节点的最短路径，并更新自己的路由表。\r\n\r\nOSPF划分区域\r\n(Area)和在多点接入网络中的优化\r\n在以太网这样的多点接入网络中，如果所有路由器都互相建立邻居关系，将会产生大量的Hello分组和LSU分组，造成不必要的开销\r\n。\r\n为了减少分组数量，OSPF会选举一个指定路由器\r\n(Designated Router, DR) 和一个备用的指定路由器 (Backup\r\nDesignated Router,\r\nBDR)。网络中所有其他的普通路由器只与DR和BDR建立邻居关系并交换信息，而不再互相通信。这大大减少了网络中的邻居关系数量和路由更新流量。\r\n同时,\r\n为了使OSPF能够应用于规模非常大的网络，OSPF允许将一个自治系统（AS）再划分为若干个更小的范围，称为区域\r\n(Area)。划分区域后，LSA的洪泛范围被限制在每个区域内部，而不是整个AS，这极大地减少了网络上的路由通信量\r\n。\r\n\r\n主干区域 (Backbone\r\nArea)：所有区域都必须连接到一个特殊的核心区域，即主干区域（区域0或0.0.0.0）。主干区域负责连通所有其他非主干区域\r\n。\r\n路由器角色也根据其所在区域的不同而有所区别：\r\n\r\n区域内路由器：所有接口都在同一个区域内的路由器,\r\n只负责该区域内的路由选择和转发 。\r\n主干路由器：至少有一个接口连接到主干区域的路由器\r\n。它们负责在主干区域和其他非主干区域之间传递路由信息 。\r\n区域边界路由器\r\n(ABR)：连接主干区域和一个或多个非主干区域的路由器。它们负责在不同区域之间传递路由信息\r\n。\r\n自治系统边界路由器\r\n(ASBR)：负责与本AS之外的其他AS交换路由信息的路由器\r\n。\r\n\r\n\r\n\r\n\r\nalt text\r\n\r\n边界网关协议 (Border\r\nGateway Protocol, BGP)\r\n边界网关协议 (BGP) 属于外部网关协议 (EGP) 类别，专门用于在不同的\r\n自治系统 (AS) 之间进行路由选择。\r\n首先, 我们需要明确一个概念: BGP 寻找的并非“最佳路由”.\r\n在不同的自治系统之间，寻找一条统一标准下的“最佳”路由是无意义的，主要原因如下：\r\n\r\n度量标准不统一：不同的自治系统可能使用完全不同的标准来衡量路径的好坏。例如，AS1可能以“时延”为度量，AS2以“跳数”为度量，而AS3则以“带宽”为度量\r\n。由于没有统一的度量单位，因此无法在多条跨越不同AS的路径之间进行优劣比较。\r\n策略驱动路由：AS之间的路由选择必须考虑很多路由协议本身之外的策略因素\r\n。这些策略通常由网络管理员根据政治、经济、安全等需求进行设置 。\r\n\r\n安全策略：例如，一个国家内部的两个站点通信时，应避免数据报绕道经过某些有安全威胁的国家\r\n。\r\n经济策略：例如，AS3可能不愿意让不相关的AS4和AS5的数据报免费穿过自己的网络，而AS2则可能提供付费的\r\ntransit (中转) 服务 。\r\n\r\n\r\n因此，BGP协议的设计目标是力求寻找一条能够到达目的网络且比较好的、不会兜圈子的路由，而不是寻找一条绝对的“最佳”路由。\r\nBGP 发言人 (BGP Speaker)\r\n在配置BGP时，每个AS的管理员需要选择至少一个路由器作为该AS的“BGP发言人”\r\n。这个发言人通常就是位于AS边界的BGP边界路由器。不同AS的BGP发言人之间通过以下步骤交换路由信息\r\n：\r\n\r\n建立TCP连接：首先在两个发言人之间建立一个TCP连接，使用的端口号为179。\r\n\r\n使用TCP连接交换路由信息的两个BGP发言人，彼此称为对方的邻站\r\n(neighbor) 或 对等站 (peer) 。\r\n\r\n建立BGP会话：在此TCP连接之上交换BGP报文，以建立BGP会话 。\r\n交换路由信息：利用BGP会话来交换路由信息，例如通告新路由、撤销过时路由等。\r\n\r\nBGP发言人除了运行BGP协议外，还必须运行其所在AS内部使用的IGP协议（如RIP或OSPF）。\r\n\r\n\r\n\r\n\r\nalt text\r\n\r\n我们要知道,\r\nBGP发言人交换的是“网络可达性信息”，即要到达某个目标网络所需要经过的一系列自治系统。这个AS序列被称为路径向量。当BGP发言人互相交换了路径向量信息后，每个发言人就可以根据这些信息来构建自己的路由表,\r\n即构造出到达各个目的网络的路径。\r\n此外,\r\n路径向量机制可以非常有效地避免路由环路。当一个BGP发言人收到一条路由信息时，它会检查其路径向量。如果发现路径向量中已经包含了自身的AS号，那么就说明采用这条路径会形成环路，因此会丢弃这条路由信息。\r\nBGP-4 的四种报文\r\nBGP-4是目前使用最广泛的版本。它规定了四种主要的报文类型 ：\r\n\r\nOPEN (打开)\r\n报文：用于与相邻的另一个BGP发言人建立对等关系，进行通信初始化 。\r\nUPDATE (更新)\r\n报文：这是BGP的核心报文，用于通告新的路由信息，或撤销多条过时的路由\r\n。一个UPDATE报文可以撤销多条路由，但一次只能增加一条新路由 。\r\nKEEPALIVE (保活)\r\n报文：在BGP会话建立后，双方会周期性地（通常每30秒）发送KEEPALIVE报文，以确认邻站的连通性，维持会话状态\r\n。\r\nNOTIFICATION (通知) 报文：用于在检测到差错时，向对等站发送通知\r\n。\r\n\r\nBGP在刚运行时会交换整个BGP路由表，但在之后仅在路由发生变化时才发送UPDATE报文，这样做可以节省网络带宽和路由器的处理开销\r\n。\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"23种设计模式","url":"/2025/10/18/lang/CPP/%E7%8E%B0%E4%BB%A3C++/%E8%AE%BE%E8%AE%A1/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"设计模式（Design\r\nPatterns）是在软件设计过程中，针对特定问题或场景的、经过反复验证的、可复用的解决方案。它们不是具体的代码，而是一套思想、蓝图或最佳实践，可以帮助开发者编写出更易于理解、维护和扩展的代码。\r\n这23种设计模式源于“四人帮”（Gang of Four, GoF）——Erich Gamma、Richard\r\nHelm、Ralph Johnson和John\r\nVlissides——合著的经典书籍《设计模式：可复用面向对象软件的基础》。\r\n这些模式根据其目的和范围，被分为三大类：创建型模式、结构型模式和行为型模式。\r\n创建型模式 (Creational\r\nPatterns)\r\n工厂方法模式 (Factory\r\nMethod Pattern)\r\n工厂模式的核心在于将对象的创建过程与使用过程分离。\r\n在没有使用工厂模式的情况下，客户端代码通常需要这样创建对象：\r\n// 客户端代码直接依赖具体的实现类Product* product = new ConcreteProductA();product-&gt;use(); 这种写法的问题是，客户端代码与具体的 ConcreteProductA\r\n类的构造紧密耦合。如果将来客户端想创建\r\nConcreteProductB，就必须修改所有创建对象的客户端代码，这违反了软件设计中的开闭原则（对扩展开放，对修改关闭）。\r\n同时,\r\n在上面的情况中实体类的使用者必须知道实际的子类名称，以及会使程序的扩展性和维护变得越来越困难。\r\n工厂模式通过引入一个“工厂”来解决这个问题。客户端不再直接 new\r\n对象，而是向工厂请求一个对象, 从而实现了下面两大好处: -\r\n封装对象的创建，避免客户端直接依赖具体类。 -\r\n具体化类的工作延迟到了子类中。\r\n\r\n\r\nalt text\r\n\r\n// 抽象产品：咖啡class Coffee {public:    virtual void show() = 0;    virtual ~Coffee() {}};// 具体产品：美式咖啡class Americano : public Coffee {public:    void show() override { std::cout &lt;&lt; \"一杯美式咖啡\" &lt;&lt; std::endl; }};// 具体产品：拿铁class Latte : public Coffee {public:    void show() override { std::cout &lt;&lt; \"一杯拿铁\" &lt;&lt; std::endl; }};// 抽象工厂class CoffeeFactory {public:    // 这是核心的工厂方法    virtual Coffee* createCoffee() = 0;    virtual ~CoffeeFactory() {}};// 具体工厂A：专门生产美式咖啡class AmericanoFactory : public CoffeeFactory {public:    Coffee* createCoffee() override {        // 步骤说明：这里是具体化的实现，由子类决定实例化哪一个具体产品。        return new Americano();    }};// 具体工厂B：专门生产拿铁class LatteFactory : public CoffeeFactory {public:    Coffee* createCoffee() override {        return new Latte();    }};// 客户端代码int main() {    // 我想要一杯拿铁，所以我去找拿铁工厂    CoffeeFactory* latteFactory = new LatteFactory();    Coffee* myCoffee = latteFactory-&gt;createCoffee();    myCoffee-&gt;show();    delete myCoffee;    delete latteFactory;        // 如果想换成美式，只需要改变工厂即可，客户端其他代码不变    CoffeeFactory* americanoFactory = new AmericanoFactory();    myCoffee = americanoFactory-&gt;createCoffee();    myCoffee-&gt;show();        delete myCoffee;    delete americanoFactory;        return 0;}\r\n理解将“对象的选择和创建”与“对象的使用”分离\r\n在上面的示例代码中, 为了得到一杯拿铁，new Latte() 其实比 new\r\nLatteFactory() 然后再 createCoffee() 要简单直接得多。\r\n那么，为什么我们还要推崇工厂模式呢？\r\n关键在于，软件设计的优劣，看的不是在 main\r\n函数里写几行测试代码的复杂度，而是在大型、复杂、需要长期维护和扩展的系统中的表现,\r\n这就是工厂模式的核心:\r\n将“对象的选择和创建”与“对象的使用”分离。\r\n在上面的例子中，“决定要一杯拿铁”和“使用这杯拿铁”这两件事都发生在同一个地方（main\r\n函数）。但在真实项目中，这两件事通常发生在系统的不同模块、不同层次。\r\n\r\n使用方\r\n(Client)：这是系统的业务逻辑部分。它只关心“我需要一个Coffee对象”，然后调用它的show()方法。它不应该，也不想关心这个Coffee对象具体是Latte还是Americano。使用方依赖的是抽象。\r\n创建方\r\n(Creator/Assembler)：这是系统的配置或初始化部分。它的职责是根据某些条件（如配置文件、用户输入、环境变量等）来决定到底应该创建哪一个具体的工厂。创建方负责处理具体实现。\r\n\r\n一个更实际的场景是,\r\n假设我们正在开发一个咖啡店点单系统。系统的启动逻辑（main函数或某个初始化模块）会读取一个配置文件\r\nconfig.txt, 其内容可能是CoffeeType = Latte\r\n那么，系统的初始化代码和业务端的代码会是这样的: #include &lt;string&gt;#include &lt;iostream&gt;// 这是系统的“配置/创建”部分CoffeeFactory* initialize_factory_from_config(const std::string&amp; configFile) {    std::string type = read_config(configFile); // 一个读取配置文件的函数    // 根据配置文件决定实例化哪个具体的工厂。    // 这个决策点被集中在了这一个地方。    if (type == \"Latte\") {        return new LatteFactory();    } else if (type == \"Americano\") {        return new AmericanoFactory();    }    // ... 其他咖啡种类    return nullptr;}// 这是系统的“业务逻辑/使用”部分void run_business_logic(CoffeeFactory* factory) {    // 这里的代码完全不知道它处理的是什么咖啡    // 它只知道它有一个能生产咖啡的工厂    std::cout &lt;&lt; \"顾客点了一杯咖啡...\" &lt;&lt; std::endl;    Coffee* coffee = factory-&gt;createCoffee();    coffee-&gt;show();    // ... 其他业务逻辑 ...    delete coffee;}int main() {    // 1. 初始化阶段：创建具体的工厂    CoffeeFactory* factory = initialize_factory_from_config(\"config.txt\");    // 2. 运行阶段：将工厂传入业务逻辑中使用    if (factory) {        run_business_logic(factory);        delete factory;    }    return 0;}CoffeeFactory* initialize_factory_from_config(const std::string&amp; configFile) {    std::string type = read_config(configFile); // 一个读取配置文件的函数    // 根据配置文件决定实例化哪个具体的工厂。    // 这个决策点被集中在了这一个地方。    if (type == \"Latte\") {        return new LatteFactory();    } else if (type == \"Americano\") {        return new AmericanoFactory();    }    // ... 其他咖啡种类    return nullptr;}// 这是系统的“业务逻辑/使用”部分void run_business_logic(CoffeeFactory* factory) {    // 这里的代码完全不知道它处理的是什么咖啡    // 它只知道它有一个能生产咖啡的工厂    std::cout &lt;&lt; \"顾客点了一杯咖啡...\" &lt;&lt; std::endl;    Coffee* coffee = factory-&gt;createCoffee();    coffee-&gt;show();        // ... 其他业务逻辑 ...        delete coffee;}int main() {    // 1. 初始化阶段：创建具体的工厂    CoffeeFactory* factory = initialize_factory_from_config(\"config.txt\");    // 2. 运行阶段：将工厂传入业务逻辑中使用    if (factory) {        run_business_logic(factory);        delete factory;    }    return 0;}\r\n现在，我们来看看这样做的好处：\r\n\r\n客户端（run_business_logic函数）完全解耦：它只认识抽象的\r\nCoffeeFactory 和 Coffee。它根本不知道 Latte 或 LatteFactory\r\n的存在。你可以把这个函数打包成一个库给别人用，别人只需要提供一个\r\nCoffeeFactory 的实现就能工作。\r\n易于扩展：现在我想增加一种“卡布奇诺”（Cappuccino）。我需要做什么？\r\n\r\n创建 Cappuccino 类和 CappuccinoFactory 类。\r\n只需要在 initialize_factory_from_config 函数里增加一个 else if\r\n(type == “Cappuccino”) 的分支。\r\nrun_business_logic 函数的代码一行都不用改！\r\n这就是开闭原则的体现。\r\n\r\n\r\n如果不用工厂模式，run_business_logic 里面就必须写 if/else 来 new\r\n不同的咖啡，那么每次增加新品种，都得修改这个核心业务函数。\r\n工厂模式通过牺牲一点点“初始的简单性”（需要多定义几个工厂类），换来了整个系统长期的解耦、灵活性和可维护性,\r\n使得客户端不必了解它要使用的具体类，只需要”无脑”地通过工厂接口来获取对象,\r\n从而使得高层模块（业务逻辑）不依赖于底层模块（具体实现）而是依赖于抽象。\r\n\r\n另一方面, 工厂模式也能封装复杂的创建过程,\r\n因为有时候，创建一个对象不仅仅是 new\r\n一下那么简单。可能需要从数据库获取配置信息, 检查库存,\r\n初始化多个内部组件, 记录创建日志等,\r\n这些复杂的逻辑如果散落在客户端代码的各个角落，将是一场维护的噩梦。\r\n而使用工厂模式，就可以把这些复杂的逻辑全部封装在\r\nLatteFactory::createCoffee() 方法里。客户端只需要简单地调用\r\nfactory-&gt;createCoffee()，代码会变得非常干净。\r\n\r\n抽象工厂模式 (Abstract\r\nFactory Pattern)\r\n工厂方法模式是针对一个产品的创建，而抽象工厂模式是它的升级版：它处理的是一族（或一个系列）相互关联的产品。因此，它也被称为“工厂的工厂”（Factory\r\nof Factories）。\r\n抽象工厂模式的核心目的是提供一个接口，用于创建一系列相关或相互依赖的对象，而无需指定它们具体的类。\r\n想象一下，我们不只是要生产一杯咖啡，而是要生产一整套风格统一的“下午茶套餐”，这个套餐里包括：一杯饮品\r\n(Drink)和一份甜点 (Dessert). 现在有两种风格的套餐：\r\n\r\n意式风情 (Italian Style)：包含 Espresso (浓缩咖啡) 和 Tiramisu\r\n(提拉米苏)。\r\n美式风情 (American Style)：包含 Americano (美式咖啡) 和\r\nCheesecake (芝士蛋糕)。\r\n\r\n这里的关键点是：Espresso 必须和 Tiramisu 搭配，Americano 必须和\r\nCheesecake 搭配。你不能把 Espresso 和 Cheesecake\r\n混在一个套餐里，这样会破坏风格的一致性。\r\n抽象工厂模式就是为了解决这个问题而生的。它能确保你创建的所有产品都属于同一个“产品族”，从而保证它们之间是相互兼容和匹配的。\r\n结构组成\r\n抽象工厂模式的结构比工厂方法模式更复杂一些，它包含以下角色：\r\n\r\nAbstractFactory\r\n(抽象工厂)：声明一组用于创建不同抽象产品的方法。例如，createDrink() 和\r\ncreateDessert()。\r\nConcreteFactory\r\n(具体工厂)：实现抽象工厂的接口，负责创建一族具体的产品。例如，ItalianDessertFactory\r\n会实现 createDrink() 来返回 Espresso，实现 createDessert() 来返回\r\nTiramisu。\r\nAbstractProduct (抽象产品)：为某一类产品声明接口。例如，Drink\r\n接口和 Dessert 接口。\r\nConcreteProduct\r\n(具体产品)：实现抽象产品的接口，是由具体工厂创建的实例。例如，Espresso,\r\nTiramisu, Americano, Cheesecake。\r\nClient\r\n(客户端)：使用抽象工厂和抽象产品的接口。客户端只与抽象层交互，从而与具体的产品实现解耦。\r\n\r\n\r\n示例代码\r\n上面情境的代码实现如下：\r\n#include &lt;iostream&gt;#include &lt;string&gt;// ===== 1. 抽象产品 (Abstract Products) =====// 抽象饮品class Drink {public:    virtual void taste() = 0;    virtual ~Drink() {}};// 抽象甜点class Dessert {public:    virtual void show() = 0;    virtual ~Dessert() {}};// ===== 2. 具体产品 (Concrete Products) =====// 具体产品族 A: 意式class Espresso : public Drink {public:    void taste() override { std::cout &lt;&lt; \"品尝意式浓缩咖啡\" &lt;&lt; std::endl; }};class Tiramisu : public Dessert {public:    void show() override { std::cout &lt;&lt; \"展示意式提拉米苏\" &lt;&lt; std::endl; }};// 具体产品族 B: 美式class Americano : public Drink {public:    void taste() override { std::cout &lt;&lt; \"品尝美式咖啡\" &lt;&lt; std::endl; }};class Cheesecake : public Dessert {public:    void show() override { std::cout &lt;&lt; \"展示美式芝士蛋糕\" &lt;&lt; std::endl; }};// ===== 3. 抽象工厂 (Abstract Factory) =====class DessertFactory {public:    // 步骤说明：定义创建一族产品的接口，但不实现。    virtual Drink* createDrink() = 0;    virtual Dessert* createDessert() = 0;    virtual ~DessertFactory() {}};// ===== 4. 具体工厂 (Concrete Factories) =====// 具体工厂 A: 专门生产意式风情套餐class ItalianDessertFactory : public DessertFactory {public:    Drink* createDrink() override {        // 步骤说明：返回产品族A的饮品。        return new Espresso();    }    Dessert* createDessert() override {        // 步骤说明：返回产品族A的甜点。        return new Tiramisu();    }};// 具体工厂 B: 专门生产美式风情套餐class AmericanDessertFactory : public DessertFactory {public:    Drink* createDrink() override {        return new Americano();    }    Dessert* createDessert() override {        return new Cheesecake();    }};// ===== 5. 客户端 (Client) =====// 客户端代码只依赖于抽象工厂和抽象产品, 并且不应该出现需要修改的地方(只增不改)void client_code(DessertFactory* factory) {    Drink* drink = factory-&gt;createDrink();    Dessert* dessert = factory-&gt;createDessert();    std::cout &lt;&lt; \"--- 下午茶套餐 ---\" &lt;&lt; std::endl;    drink-&gt;taste();    dessert-&gt;show();        delete drink;    delete dessert;}int main() {    std::cout &lt;&lt; \"客户端配置了意式工厂:\" &lt;&lt; std::endl;    DessertFactory* italianFactory = new ItalianDessertFactory();    // 步骤说明：客户端传入一个具体的工厂。    // 之后的所有操作都通过抽象接口进行，保证了产品风格的一致性。    client_code(italianFactory);    delete italianFactory;    std::cout &lt;&lt; \"\\n客户端配置了美式工厂:\" &lt;&lt; std::endl;    DessertFactory* americanFactory = new AmericanDessertFactory();    // 步骤说明：只需更换具体工厂，客户端代码`client_code`无需任何改动，    // 就能获得一整套不同风格的产品。    client_code(americanFactory);    delete americanFactory;    return 0;}\r\n这里的client_code 函数是我们的使用方。它只认识抽象的\r\nDessertFactory，并用它来创建 Drink 和 Dessert。它完全不知道\r\nItalianDessertFactory 或 Espresso 的存在。\r\n在 main 函数中，我们作为配置方，决定了今天是用\r\nItalianDessertFactory 还是 AmericanDessertFactory。一旦工厂被选定并传入\r\nclient_code，客户端创建的所有产品（饮品和甜点）都保证是同一个风格（产品族）的，实现了风格的统一和强制约束。\r\n对比上面的工厂方法模式，如果你的系统只需要根据不同情况创建不同版本的同一种对象，用工厂方法。\r\n如果你的系统需要创建一整套对象，并且要保证这套对象互相兼容、风格统一，用抽象工厂。\r\n单例模式 (Singleton Pattern)\r\n单例模式 (Singleton Pattern)是 GoF\r\n23种设计模式中最著名也最简单的一种，但同时也是在实际应用中充满争议的一种。\r\n单例模式的核心目的是：确保一个类在任何情况下都绝对只有一个实例，并提供一个全局访问点来获取这个唯一的实例。换句话说，单例模式做了三件事：\r\n\r\n保证唯一性：一个类只能创建一个对象。\r\n自我创建：这个唯一的对象由类自己来创建。\r\n提供全局访问：必须提供一个公共的方法，让系统中的任何其他代码都能访问到这个对象。\r\n\r\n而要在 C++\r\n中实现一个单例类，必须满足以下几个关键条件，以“堵死”所有可能创建多个实例的途径：\r\n\r\n私有化构造函数 (Private Constructor)：阻止外部代码通过 new\r\nSingleton()\r\n的方式自由地创建实例。只有类自己内部才能调用构造函数。\r\n禁用拷贝构造函数和赋值运算符 (Delete Copy Constructor &amp;\r\nAssignment Operator)：防止通过拷贝 Singleton s2 = s1; 或赋值 s2 = s1;\r\n的方式创建出新的实例副本。在 C++11 及以后，通常使用 = delete;\r\n关键字来明确禁用它们。\r\n提供一个静态的公共访问方法 (Public Static getInstance\r\nMethod)：这是外界获取唯一实例的唯一途径。通常命名为 getInstance() 或\r\ninstance()。\r\n在类内部持有一个静态的私有实例指针/对象 (Private Static\r\nInstance)：用于保存那个独一无二的实例。\r\n\r\nC++ 中的实现方式\r\n单例模式的实现有多种变体，主要区别在于实例化的时机（“懒汉式” vs\r\n“饿汉式”）和线程安全性。\r\n\r\n懒汉式 (Lazy Initialization) - 非线程安全 这种方式在第一次调用\r\ngetInstance() 时才创建实例，比较“懒惰”。 #include &lt;iostream&gt; class Singleton { private:     // 1. 私有化构造函数     Singleton() {         std::cout &lt;&lt; \"单例对象已创建\" &lt;&lt; std::endl;     }     // 4. 持有静态私有实例指针     static Singleton* m_instance; public:     // 2. 禁用拷贝和赋值     Singleton(const Singleton&amp;) = delete;     Singleton&amp; operator=(const Singleton&amp;) = delete;     // 3. 提供静态公共访问方法     static Singleton* getInstance() {         // 步骤说明：只有当实例不存在时，才进行创建。         if (m_instance == nullptr) {             m_instance = new Singleton();         }         return m_instance;     } }; // 在类外初始化静态成员 Singleton* Singleton::m_instance = nullptr; // 客户端代码 int main() {     Singleton* s1 = Singleton::getInstance();     Singleton* s2 = Singleton::getInstance();     if (s1 == s2) {         std::cout &lt;&lt; \"s1 和 s2 是同一个实例。\" &lt;&lt; std::endl;     }     // 注意：这种简单的实现需要手动释放内存，否则会造成内存泄漏。     // delete s1; // 但这又会带来新的问题，比如悬挂指针     return 0; }\r\n这种实现的优点是实现了延迟加载，只有在需要时才创建实例，节省了资源。\r\n不过缺点是线程不安全：在多线程环境下，两个线程可能同时进入 if\r\n(m_instance == nullptr) 判断，导致创建出两个实例。\r\n而且也存在内存泄漏风险：需要手动管理 new\r\n出来的内存，容易忘记释放。\r\n线程安全的懒汉式 (使用 std::mutex 或 std::call_once)\r\n为了解决线程安全问题，一个常见的思路是加锁。 #include &lt;mutex&gt; // 引入互斥锁头文件class Singleton {private:    Singleton() {}    static Singleton* m_instance;    static std::mutex m_mutex; // 引入互斥锁public:    Singleton(const Singleton&amp;) = delete;    Singleton&amp; operator=(const Singleton&amp;) = delete;    static Singleton* getInstance() {        // 使用双重检查锁定 (Double-Checked Locking) 优化性能        if (m_instance == nullptr) {             std::lock_guard&lt;std::mutex&gt; lock(m_mutex); // 自动加锁和解锁            if (m_instance == nullptr) {                m_instance = new Singleton();            }        }        return m_instance;    }};Singleton* Singleton::m_instance = nullptr;  // 初始化静态成员std::mutex Singleton::m_mutex;\r\n这种方式通过互斥锁保证了在多线程环境下只有一个线程能创建实例，解决了线程安全问题。\r\n但缺点是每次调用 getInstance() 都需要加锁，可能会影响性能。\r\nMeyers’ Singleton(懒汉式, C++11 及以后) 这种方式利用了 C++11\r\n引入的局部静态变量的线程安全特性，实现了简单且高效的单例模式。\r\nclass Singleton {private:    Singleton() {}public:    Singleton(const Singleton&amp;) = delete;    Singleton&amp; operator=(const Singleton&amp;) = delete;    // 步骤说明：返回一个静态局部对象的引用。    // C++11标准保证，这个静态局部对象的初始化是懒惰的、线程安全的，    // 且在程序结束时会自动销毁。    static Singleton&amp; getInstance() {        static Singleton instance; // 核心！        return instance;    }    void showMessage() {        std::cout &lt;&lt; \"Hello from Singleton!\" &lt;&lt; std::endl;    }}; 这种实现方式非常简洁，实现了延迟加载,\r\n不需要手动管理内存(因为保存在静态存储区,\r\n其生命周期由程序管理，会在程序结束时自动析构)，也不需要显式加锁，性能较好。\r\n饿汉式 (Eager Initialization)\r\n这种方式在程序启动时就创建实例，适用于实例创建开销不大且一定会被使用的场景,\r\n通常是程序开始执行 main\r\n函数之前，作为静态成员变量初始化的一部分。\r\nclass Singleton {private:    // 1. 私有化构造函数    Singleton() {        std::cout &lt;&lt; \"单例对象已创建\" &lt;&lt; std::endl;    }    // 4. 持有静态私有实例对象    static Singleton m_instance;public:    // 2. 禁用拷贝和赋值    Singleton(const Singleton&amp;) = delete;    Singleton&amp; operator=(const Singleton&amp;) = delete;    // 3. 提供静态公共访问方法    static Singleton&amp; getInstance() {        return m_instance;    }};// 在类外初始化静态成员Singleton Singleton::m_instance;// 客户端代码int main() {    Singleton&amp; s1 = Singleton::getInstance();    Singleton&amp; s2 = Singleton::getInstance();    if (&amp;s1 == &amp;s2) {        std::cout &lt;&lt; \"s1 和 s2 是同一个实例。\" &lt;&lt; std::endl;    }    return 0;}\r\n饿汉式的优点是实现简单，线程安全(这是它最大的优点。因为实例是在程序启动阶段、进入多线程环境之前，由主线程在静态初始化阶段创建的。当后续多个线程调用\r\ngetInstance()\r\n时，它们只是在读取一个已经被初始化的变量，不存在竞争条件（Race\r\nCondition），因此完全不需要加锁。)\r\n缺点是无法延迟加载，如果实例创建开销较大且不一定会被使用，可能会浪费资源。\r\n&gt; 还有一个值得注意的风险是“静态初始化顺序灾难” (Static Initialization\r\nOrder Fiasco)：在复杂的 C++\r\n项目中，如果一个静态对象（饿汉式单例）的构造函数依赖于另一个不同编译单元（.cpp\r\n文件）中的静态对象，C++\r\n标准不保证它们的初始化顺序。这可能导致在构造单例时，其依赖的另一个对象还未被创建，从而引发程序崩溃。\r\n\r\n当开发环境是 C++11 或更高版本时，强烈推荐使用 Meyers’\r\nSingleton（即函数内静态变量的实现方式），因为它完美结合了懒汉式的优点（延迟加载）和饿汉式的优点（实现简单、线程安全）。\r\n单例模式的优缺点\r\n尽管单例模式很常用，但它也像一个“全局变量”，因此备受争议。\r\n优点：\r\n\r\n资源共享与控制：确保了对唯一实例的受控访问，可以严格控制客户怎样以及何时访问它。\r\n节省资源：由于只有一个实例，避免了对资源的多重占用。\r\n延迟加载：懒汉式实现可以在需要时才创建对象。\r\n\r\n缺点：\r\n\r\n违反单一职责原则：一个类既要负责其核心业务逻辑，又要负责保证自己是单例，职责不单一。\r\n难以测试：单例模式引入了全局状态，使得单元测试变得困难。因为测试用例之间会相互影响，无法轻松地用一个模拟（mock）对象来替换单例实例。\r\n扩展性差：单例的实现是硬编码的，如果想扩展成一个类允许有N个实例，就需要大幅修改代码。\r\n隐藏依赖：代码的调用方可能不知道自己依赖了一个全局的单例对象，使得模块间的耦合关系变得不明确。\r\n\r\n总之,\r\n单例模式是一个强大的工具，但应谨慎使用。在确实需要一个全局唯一的对象（如全局配置、日志服务）时，它非常有用。但在其他情况下，最好优先考虑依赖注入（Dependency\r\nInjection）等其他方案来管理对象的生命周期和依赖关系。\r\n依赖注入（Dependency Injection,\r\nDI）\r\n依赖注入（Dependency Injection,\r\nDI）是一种设计原则，用于实现控制反转（Inversion\r\nof Control,\r\nIoC）。它通过将对象的依赖关系从内部创建转移到外部提供，从而提高代码的灵活性和可测试性。\r\n与单例模式相比，依赖注入允许更灵活地管理对象的生命周期和作用域，避免了全局状态带来的问题。\r\n什么是依赖\r\n为了理解依赖注入，我们首先要理解什么是“依赖”。\r\n\r\n依赖 (Dependency)：如果类 A 的一个方法中使用了类 B\r\n的一个实例，那么我们就说类 A 依赖于类 B。\r\n\r\n传统方式\r\n(没有依赖注入)：在传统的编程模式中，一个对象通常会自己负责创建它所依赖的对象。\r\n// 日志类class Logger {public:    void log(const std::string&amp; message) {        std::cout &lt;&lt; \"[LOG]: \" &lt;&lt; message &lt;&lt; std::endl;    }};// 引擎类class Engine {public:    void start() {        std::cout &lt;&lt; \"引擎启动...\" &lt;&lt; std::endl;    }};// 汽车类 (Car) 自己创建它依赖的 Engine 和 Loggerclass Car {private:    Engine* m_engine;    Logger* m_logger;public:    Car() {        // 步骤说明：Car类在其构造函数中，主动地、硬编码地创建了它所依赖的对象。        // 这种行为叫做“高耦合”(Tight Coupling)。        m_engine = new Engine();         m_logger = new Logger();    }    void drive() {        m_logger-&gt;log(\"开始驾驶\");        m_engine-&gt;start();        // ...    }        ~Car() {        delete m_engine;        delete m_logger;    }};int main() {    Car myCar;    myCar.drive();} 这种方式的问题：\r\n\r\n高耦合：Car 类和 Engine、Logger\r\n这两个具体类焊死在了一起。如果我想给 Car 换一个依赖类\r\nV8Engine (V8引擎)，或者换一个 FileLogger\r\n(记录到文件的日志)，我必须修改 Car\r\n类的源代码。这违反了开闭原则。\r\n难以测试：我想对 Car\r\n类进行单元测试，但我不想在测试时真的启动一个复杂的 Engine\r\n对象。我希望能用一个假的 MockEngine\r\n来代替。在上面的代码中，这几乎是不可能的，因为 Car 自己锁死了 Engine\r\n的创建。\r\n\r\n依赖注入的实现方式\r\n依赖注入的核心思想正好相反：一个对象不应该自己创建它所依赖的对象，而应该由外部的“容器”或“框架”来创建这些依赖，并通过某种方式“注入”给它。对象的控制权发生了反转：\r\n\r\n之前：对象自己控制、创建依赖。\r\n现在：对象的依赖由外部控制和提供。 这就是控制反转 (IoC)。\r\n\r\n注入依赖的主要方式是以下两种:\r\n\r\n构造函数注入 (Constructor Injection):\r\n这是最常用、也是最推荐的一种方式。依赖通过类的构造函数传入。\r\n// ===== 首先，我们依赖于抽象而非具体 =====class IEngine { // 引擎接口public:    virtual void start() = 0;    virtual ~IEngine() {}};class ILogger { // 日志接口public:    virtual void log(const std::string&amp; message) = 0;    virtual ~ILogger() {}};// ===== 具体的实现 =====class V6Engine : public IEngine { ... }; // V6引擎class FileLogger : public ILogger { ... }; // 文件日志// ===== 汽车类 (Car) 通过构造函数接收依赖 =====class Car {private:    IEngine* m_engine;    ILogger* m_logger;public:    // 步骤说明：依赖关系通过构造函数的参数被“注入”进来。    // Car类不再关心engine和logger是如何被创建的，它只知道自己需要它们。    Car(IEngine* engine, ILogger* logger)         : m_engine(engine), m_logger(logger) {        if (!m_engine || !m_logger) {            throw std::invalid_argument(\"Engine and Logger must not be null.\");        }    }    void drive() {        m_logger-&gt;log(\"开始驾驶\");        m_engine-&gt;start();    }};// ===== “组装层” 或 “配置层” (main函数) =====int main() {    // 步骤说明：对象的创建和组装工作由外部完成。    // 这里是整个系统的配置中心。    V6Engine myEngine;    FileLogger myLogger;    // 将具体的依赖注入到Car中    Car myCar(&amp;myEngine, &amp;myLogger);    myCar.drive();        // 如果我想换一个V8引擎和控制台日志，只需要改变这里即可    // V8Engine v8;    // ConsoleLogger consoleLogger;    // Car mySuperCar(&amp;v8, &amp;consoleLogger);    // mySuperCar.drive();}\r\n注意这里从原先的构造函数自己创建了具体类,\r\n变成了构造函数接收外部的抽象类,\r\n从而实现了依赖抽象+控制反转,\r\n通过构造函数的参数，从外部接收一个已经创建好的 IEngine\r\n实例。创建依赖的控制权被反转给了外部的调用者（组装层）。\r\n优点：\r\n\r\n依赖明确：构造函数清晰地表明了这个类“必须拥有”哪些依赖才能正常工作。\r\n保证不变性：一旦对象被创建，其核心依赖就无法被更改，状态更加稳定。\r\n\r\n缺点：如果依赖项过多，构造函数会变得很长。\r\nSetter 注入 (Setter Injection): 通过公共的 setter\r\n方法将依赖注入到对象中。这种方式相对灵活，但可能导致对象在创建后处于不完整状态。\r\nclass Car {private:    IEngine* m_engine = nullptr; // 必须的依赖    ILogger* m_logger = nullptr; // 可选的依赖public:    // 必须的依赖仍然通过构造函数注入    Car(IEngine* engine) : m_engine(engine) {}    // 步骤说明：为可选的依赖提供一个Setter方法。    void setLogger(ILogger* logger) {        m_logger = logger;    }    void drive() {        // 步骤说明：在使用可选依赖前，最好进行检查。        if (m_logger) {            m_logger-&gt;log(\"开始驾驶\");        }        m_engine-&gt;start();    }};int main() {    V6Engine myEngine;    FileLogger myLogger;        Car myCar(&amp;myEngine); // 先创建Car对象    myCar.setLogger(&amp;myLogger); // 然后注入可选的依赖    myCar.drive();} 通过公开的 set\r\n方法来注入依赖。这种方式通常用于可选的依赖。 优点：\r\n\r\n灵活性高：可以在对象的生命周期内随时更改依赖。\r\n解决了构造函数参数过多的问题。\r\n\r\n缺点：\r\n\r\n对象可能处于一个“不完整”的状态（比如忘记调用\r\nsetLogger）。\r\n依赖关系被隐藏在代码内部，不如构造函数注入那样一目了然。\r\n\r\n\r\n总结\r\n依赖注入的巨大优势在于: - 降低耦合度 (Decoupling):\r\n这是最核心的优势。类不再依赖于具体的实现，而是依赖于抽象（接口）。这使得替换具体实现变得轻而易举，大大提高了代码的灵活性和可维护性。\r\n\r\n极大地提升了可测试性 (Testability):\r\n在单元测试中，我们可以轻松地创建一个“模拟对象”（Mock\r\nObject），并将其注入到被测试的类中。这样，我们就可以在完全隔离的环境下测试一个类的逻辑，而不用担心其依赖项的干扰。\r\n促进并行开发 (Parallel Development):\r\n团队成员可以先定义好接口，然后各自独立地开发实现这些接口的具体组件。只要接口不变，大家就可以并行工作，最后再通过依赖注入将它们“组装”在一起。\r\n集中管理配置:\r\n对象的创建和依赖关系的管理被集中到了一个或少数几个地方（“组装层”）。这使得整个应用的配置和结构一目了然，易于管理和修改。\r\n\r\n依赖注入不是目的，而是手段。\r\n它的最终目的是为了构建一个低耦合、高内聚、易于测试和维护的软件系统。\r\n简单来说，就是把“我需要什么，我自己去拿”的思维方式，转变为“我需要什么，你给我什么，我就用什么”的思维方式。这种控制权的反转，是现代软件架构设计的基石之一。\r\n"},{"title":"网络层","url":"/2025/09/30/web/Computer%20Network/%E7%BD%91%E7%BB%9C%E5%B1%82/%E7%BD%91%E7%BB%9C%E5%B1%82/%E7%BD%91%E7%BB%9C%E5%B1%82/","content":"网络层概述\r\n网络层在OSI体系结构中是自下而上的第三层，其最核心的任务是将数据分组从源主机，经过多个网络和多段链路，最终传输到目的主机。这个核心任务可以被分解为两个关键功能：分组转发和路由选择\r\n。\r\n分组转发 (Forwarding)\r\n当一台路由器从其某个接口所连接的链路上接收到一个数据分组后，它会根据分组首部中的信息，在自己的转发表中进行查询，并依据查询结果将该分组从一个合适的接口发送给下一跳路由器或目的主机\r\n。\r\n工作机制：\r\n\r\n每个路由器都维护一个转发表 (Forwarding Table)\r\n。\r\n路由器依据分组首部中的转发标识（可能是目的地址或连接指示符）来查询转发表\r\n。\r\n根据查询结果所指示的接口来执行转发操作 。\r\n\r\n\r\n\r\nalt text\r\n\r\n如图所示，路由器R1在其接口1收到了一个首部转发标识为”A”的分组。R1查询自己的转发表，发现标识”A”对应的出口是接口2，于是将该分组从接口2转发出去\r\n。\r\n路由选择 (Routing)\r\n由于源主机和目的主机之间可能存在多条路径，网络层需要决定选择哪一条路径来传送分组，这个决策过程就是路由选择。路由选择方式主要有以下三种\r\n：\r\n\r\n集中式路由选择：由一个中央网络控制中心执行路由计算，并将路由信息下载给每个路由器\r\n。\r\n分布式路由选择：每个路由器上都运行路由选择协议，通过相互交换路由信息来各自计算路由\r\n。\r\n人工路由选择：由网络运维人员手动配置路由信息\r\n。\r\n\r\n路由表与转发表的关系：路由选择过程会生成路由表 (Routing\r\nTable)，它通常只包含从目的网络到下一跳的映射关系。而转发表是由路由表得出的，其结构被优化，以便于快速查找。为了简化讨论，在路由选择原理的探讨中，通常不严格区分二者\r\n网络层向其上层提供的两种服务\r\n网络层可以向其上层（传输层）提供两种截然不同的服务：面向连接的虚电路服务和无连接的数据报服务\r\n。\r\n\r\n面向连接的虚电路服务 (Virtual Circuit\r\nService)\r\n\r\n核心思想：“可靠通信应由网络自身来保证” 。\r\n工作流程：\r\n\r\n建立连接：通信双方在开始通信前，首先需要建立一条网络层的逻辑连接，即虚电路\r\n(Virtual Circuit, VC)，以确保通信所需的网络资源 。\r\n数据传输：所有分组都沿着这条已建立的虚电路按序进行存储转发传输。在连接建立后，每个分组的首部只需携带一个较短的虚电路编号，而无需完整的目的地址\r\n。\r\n释放连接：通信结束后，需要释放之前建立的虚电路 。\r\n\r\n特点：这是一种面向连接的服务,\r\n能够保证分组无差错、按序到达、不丢失、不重复;\r\n分组沿着同一条逻辑路径进行转发,\r\n如果路径上的某个节点出现故障，所有通过该节点的虚电路都将无法工作 。\r\n应用实例：曾经的X.25、帧中继(Frame\r\nRelay)和异步传输模式(ATM)等广域分组交换网使用此服务 。\r\n\r\n无连接的数据报服务 (Datagram Service)\r\n\r\n核心思想：“可靠通信应当由用户主机来保证” 。\r\n工作流程：\r\n\r\n无需建立连接：网络层在通信前不需要建立任何连接 。\r\n数据传输：每个分组都独立选择路径，因此每个分组的首部都必须携带完整的目的主机地址\r\n。\r\n无需释放连接：通信结束后，没有连接需要释放 。\r\n\r\n特点：这是一种无连接的服务\r\n。网络本身不提供端到端的可靠传输保证，分组可能出现误码、丢失、重复和失序\r\n。\r\n\r\n\r\n因特网(Internet)的设计思想是将复杂的网络处理功能（如可靠性保证）放在网络边缘的用户主机上(而不是路由器)，而网络核心则提供相对简单的、尽最大努力（不可靠）的分组交付功能。这种设计使得网络中的路由器可以做得比较简单，造价低廉，运行方式灵活。因此，因特网采用的是无连接的数据报服务。\r\n网络控制报文协议(ICMP)\r\n网络控制报文协议 (Internet Control Message Protocol, ICMP)\r\n是互联网协议族中的一个重要协议，主要用于在IP主机、路由器之间传递控制信息和差错报告。ICMP工作在网络层，通常被视为IP协议的一个组成部分。\r\nICMP的报文分为两大类：ICMP差错报告报文 和 ICMP询问报文 。\r\nICMP差错报告报文\r\nICMP差错报告报文用于向源主机或路由器报告在数据传输过程中遇到的差错情况。共有以下五种类型：\r\n\r\n终点不可达 (Destination Unreachable)\r\n\r\n功能：当路由器或主机无法交付一个IP数据报时，就会向源主机发送“终点不可达”报文\r\n。\r\n触发情景：例如，路由器R1收到一个发往网络N3的数据报，但在其路由表中找不到任何关于如何到达网络N3的路由条目（包括特定路由、网络路由或默认路由）。此时，R1会丢弃该数据报，并向源主机H1发送此差错报告\r\n。\r\n细分类型：该报文还可以根据代码字段细分为目的网络不可达、目的主机不可达、目的协议不可达等13种具体错误\r\n。\r\n\r\n源点抑制 (Source Quench)\r\n\r\n功能：当路由器或主机由于网络拥塞而丢弃IP数据报时，会向源主机发送“源点抑制”报文，通知源主机应该降低其数据报的发送速率\r\n。\r\n触发情景：\r\n\r\n路由器拥塞：数据报在传输途中经过的路由器R2因为过于繁忙而丢弃了该数据报\r\n。\r\n主机拥塞：目的主机H2自身因为拥塞而丢弃了收到的数据报 。\r\n\r\n\r\n时间超过 (Time Exceeded / Timeout)\r\n\r\n功能：用于通知源主机数据报因生存时间耗尽而被丢弃 。\r\n触发情景：\r\n\r\nTTL为0：路由器收到一个IP数据报后，会将其首部中的生存时间（TTL）字段的值减1\r\n。如果减1后结果为0，路由器必须丢弃该数据报，并向源主机发送“时间超过”报文\r\n。\r\n分片重组超时：当目的主机在预设的时间内未能收到一个被分片的数据报的所有分片时，它会丢弃已收到的分片，并向源主机发送此报文\r\n。\r\n\r\n\r\n参数问题 (Parameter Problem)\r\n\r\n功能：当路由器或目的主机收到一个IP数据报，并发现其首部在传输过程中出现了误码时，会发送此报文\r\n。\r\n触发情景：路由器R1在检查收到的IP数据报时，通过计算首部检验和发现首部字段有错误\r\n。此时，R1会丢弃该数据报，并向源主机发送“参数问题”报文 。\r\n\r\n改变路由 (Redirect)\r\n\r\n功能：路由器使用此报文来通知主机，有另一条更好的路径可以到达目的地址\r\n。\r\n触发情景：主机H1的默认网关是R1\r\n。当H1向网络N2发送数据报时，R1收到后发现，直接通过路由器R4到达N2的路径更优\r\n。于是，R1会将数据报正常转发，但同时向H1发送一个“改变路由”报文，告知H1下次应直接将发往N2的数据报发送给R4\r\n。\r\n\r\n\r\n当然, 在某些情况下不应发送\r\nICMP差错报告报文，例如：对ICMP差错报告报文本身、对分片数据报的后续分片、对多播或特殊地址（如127.0.0.0）的数据报等\r\n。\r\nICMP询问报文\r\nICMP询问报文用于主机或路由器之间的诊断和管理，帮助网络管理员了解网络状态和排除故障。常用的ICMP询问报文有两种\r\n：\r\n\r\n回送请求和回答 (Echo Request and Reply)\r\n\r\n功能：由主机或路由器向一个特定的目的主机或路由器发出“回送请求”报文，收到请求的主机或路由器必须回复一个“回送回答”报文\r\n。\r\n用途：这种询问报文主要用于测试目的站点是否可达以及了解其相关状态\r\n。这是 PING 应用的基础。\r\n\r\n时间戳请求和回答 (Timestamp Request and Reply)\r\n\r\n功能：用于请求某个主机或路由器回答当前的日期和时间 。\r\n用途：回答报文中包含一个从1900年1月1日起到当前时刻的总秒数，可被用来进行时钟同步和测量网络传输时间\r\n。\r\n\r\n\r\nICMP的典型应用\r\nICMP协议虽然主要用于差错报告，但其询问报文机制也催生了两个非常著名且实用的网络诊断工具：分组网间探测（PING）\r\n和 跟踪路由（traceroute/tracert）。\r\n分组网间探测 (PING): PING（Packet InterNet\r\nGroper）是用于测试主机或路由器之间连通性的最基本工具。它能告诉我们目标设备是否在线（可达），以及数据包往返所需的时间。\r\n工作原理：PING是一个应用层程序，但它不使用TCP或UDP，而是直接利用网络层的ICMP。其工作原理非常简单：\r\n\r\n源主机向目标主机发送一个 ICMP回送请求（Echo Request） 报文。\r\n目标主机在收到该请求后，必须回复一个 ICMP回送回答（Echo Reply）\r\n报文。\r\n\r\n注意：出于安全考虑，有些服务器或防火墙会设置不响应ICMP回送请求，这会导致PING不通，但这并不一定意味着目标主机不在线。\r\n跟踪路由 (traceroute / tracert):\r\ntraceroute（在Windows中为tracert）用于探测IP数据报从源主机到目的主机所经过的路由器路径。\r\n\r\nUNIX/Linux\r\n(traceroute)：通常在运输层使用UDP协议，并利用ICMP的“终点不可达”差错报告报文。\r\nWindows\r\n(tracert)：直接使用ICMP协议，它同时利用了ICMP的“回送请求/回答”报文和“时间超过”差错报告报文。\r\n\r\ntracert 的巧妙之处在于它利用了IP数据报首部中的 TTL（生存时间）\r\n字段和ICMP的 “时间超过” 报文。\r\n假设主机H1要探测到H2的路径：\r\n\r\n探测第一跳：H1发送第一个IP数据报，其内部封装了一个ICMP回送请求，并将IP首部的\r\nTTL设置为1。当这个数据报到达路径上的第一个路由器R1时，R1将TTL减1，变为0。由于TTL为0，R1会丢弃该数据报，并向源主机H1发送一个\r\nICMP时间超过的差错报告报文。H1收到这个来自R1的报文后，就知道了路径上的第一个路由器是R1。\r\n探测第二跳：H1发送第二个IP数据报，这次将\r\nTTL设置为2。数据报到达R1，TTL减为1，被继续转发。数据报到达第二个路由器R2，R2将TTL减为0，丢弃数据报，并向H1发回一个\r\nICMP时间超过\r\n报文。H1收到这个来自R2的报文后，就知道了路径上的第二个路由器是R2。\r\n依此类推：H1继续发送数据报，每次将TTL的值加1（TTL=3, 4,\r\n5…），从而依次获得路径上第三个、第四个、第五个…路由器的IP地址。\r\n探测结束：当H1发送的某个数据报（例如TTL=99）的TTL值足够大，能够成功到达最终的目的主机H2时。H2收到的是一个ICMP回送请求报文，因此它不会发送“时间超过”报文，而是会回复一个\r\nICMP回送回答\r\n报文。当源主机H1收到这个“回送回答”报文时，就知道已经到达了终点，跟踪过程结束。\r\n\r\n虚拟专用网(VPN)和网络地址转换(NAT)\r\n虚拟专用网(VPN)\r\nVPN，全称为 虚拟专用网络 (Virtual Private\r\nNetwork)，是一种通过公共网络（通常是互联网）来建立安全、加密连接的技术。\r\n我们可以通过一个比喻来理解它：想象一下，你要从家里寄一个非常重要的包裹到公司的总部。\r\n\r\n不使用VPN：你就像是把这个包裹直接交给了一个普通的快递公司。包裹在运输途中可能会经过很多个中转站，任何人都有机会看到包裹上的收件人信息，甚至可以偷偷打开看看里面的内容。\r\n使用VPN：这相当于你先把包裹放进一个坚固的、不透明的保险箱里（加密），然后再把这个保险箱交给一个专门的、只走秘密路线的安保运输队（隧道）。这个运输队会直接把保险箱送到公司总部的指定接收人手中。外界只能看到安保公司的车辆在公共道路上行驶，但完全不知道车里装的是什么，也不知道它的最终具体目的地是总部的哪个部门。\r\n\r\n总结来说，VPN的核心作用就是在你和你的访问目标之间，建立一个临时的、安全的、私密的“信息隧道”。\r\nVPN的核心工作原理\r\nVPN的魔力主要来源于三大核心技术的结合：隧道技术、加密技术和身份验证。\r\n\r\n隧道技术 (Tunneling)\r\n\r\n这是VPN实现“虚拟专用”的基础。隧道技术指的是将原始的数据包（Packet）进行“再包装”或“封装”（Encapsulation）的过程。\r\n\r\n工作流程：\r\n\r\n你的设备（如电脑或手机）准备发送一个普通的数据包，上面有你的真实IP作为源地址，目标网站作为目的地址。\r\n在数据包离开你的设备之前，VPN客户端软件会拦截它。\r\nVPN软件会将这个整个原始数据包（包括其头部信息）当作“货物”，塞进一个新的数据包（我们称之为“外部数据包”）的“集装箱”里。\r\n这个新的外部数据包的“信封”上，写的源地址是你自己，但目的地址不再是最终的网站，而是远程的VPN服务器。最终VPN服务器会代替你去访问真正的网站。\r\n\r\n如果是远程接入VPN (Remote Access\r\nVPN)，外部数据包的目的地址是VPN服务器的IP地址,\r\n源地址是你的真实IP地址。\r\n如果是站点到站点VPN (Site-to-Site\r\nVPN)，外部数据包的目的地址是另一个局域网的网关路由器的IP地址,\r\n源地址是你所在局域网的网关路由器的IP地址\r\n\r\n\r\n效果：你的互联网服务提供商（ISP）或者本地网络管理员，只能看到你正在和一台VPN服务器进行通信，但完全不知道你通过这台VPN服务器最终访问了什么网站。原始数据的真正目的地被隐藏在了这个“隧道”之中。\r\n\r\n\r\n加密技术 (Encryption)\r\n\r\n如果说隧道技术隐藏了你的目的地，那么加密技术就是保护你的数据内容本身。\r\n工作流程：\r\n\r\n在将原始数据包封装进隧道之前，VPN会使用复杂的加密算法（如AES-256）和密钥\r\n(Key)\r\n将数据包的内容从可读的明文（Plaintext）转换成无法识别的乱码（Ciphertext）。\r\n这个被加密过的数据包随后被放入隧道，通过互联网传输到VPN服务器。\r\n只有拥有正确密钥的VPN服务器才能解密 (Decrypt)\r\n这些乱码，将其恢复成原始数据。\r\n然后，VPN服务器会代替你，将解密后的原始数据包发送到你真正想访问的目标网站。\r\n\r\n即使有黑客在传输过程中截获了你的数据，他们得到的也只是一堆毫无意义的乱码，无法窃取你的密码、银行信息或浏览内容。\r\n\r\n身份验证 (Authentication)\r\n\r\n为了确保你连接的是一个合法的VPN服务器，而不是某个黑客设置的假冒服务器，并且也为了让VPN服务器确认你是合法的付费用户，双方需要进行身份验证。\r\n在你与VPN服务器建立安全隧道之前，你的VPN客户端和服务器会交换并验证彼此的数字证书或凭据（如用户名和密码）。这个过程确保了通信双方都是可信的，从而建立起一个安全的连接起点。\r\n\r\n\r\nalt text\r\n\r\n如图就是IP隧道技术的示例,\r\n不过需要注意的是这里的VPN技术不是我们上面提到的远程接入VPN (Remote\r\nAccess VPN), 而是站点到站点VPN (Site-to-Site VPN),\r\n它通常用于连接两个不同的局域网,\r\n因此需要使用网关路由器来实现隧道的封装和解封装\r\n专用地址 (Private Address)\r\n专用地址 (Private Address)\r\n是指在专用网络（如企业内部网络或家庭网络）中使用的IP地址，这些地址在公共因特网中是不可路由的。这些IP地址仅在机构内部有效，可以由机构自行分配，无需向因特网管理机构申请。\r\n地址范围：RFC 1918规定了三个地址块作为专用地址 ： - 10.0.0.0 ~\r\n10.255.255.255 (CIDR地址块 10/8) - 172.16.0.0 ~ 172.31.255.255\r\n(CIDR地址块 172.16/12) - 192.168.0.0 ~ 192.168.255.255 (CIDR地址块\r\n192.168/16)\r\n因特网中的所有路由器都被配置为不转发目的地址是专用地址的IP数据报，从而保证了专用网络与公共因特网的隔离。\r\n在上述示例中, 部门A和B的局域网就使用了专用地址,\r\n这些地址在因特网上是不可路由的,\r\n只有通过VPN服务器的转换才能访问公共因特网\r\n一次完整的VPN访问流程\r\n让我们把所有原理串起来，看看当你连接VPN并访问网站时，发生了什么：\r\n\r\n启动连接：你在设备上打开VPN应用，选择一个服务器（例如，位于日本的服务器），然后点击“连接”。\r\n身份验证：你的设备与日本的VPN服务器进行身份验证，确认彼此的合法性。\r\n建立加密隧道：验证通过后，你的设备和VPN服务器之间建立起一个加密的通信隧道。\r\n发送请求：你在浏览器中输入\r\nwww.google.com。这个请求数据包被VPN软件加密，然后封装在一个新的数据包里，发往日本的VPN服务器。\r\n服务器中转：日本的VPN服务器收到数据包后，进行解密，看到了你真正的请求——访问谷歌。\r\n代替访问：VPN服务器以它自己（日本的IP地址）的身份，向谷歌服务器发送访问请求。\r\n谷歌响应：谷歌服务器将网站数据返回给日本的VPN服务器（在谷歌看来，访问者就来自日本）。\r\n安全返回：VPN服务器将收到的谷歌网站数据再次进行加密，通过安全隧道发回给你的设备。\r\n本地解密：你的VPN客户端收到加密数据后进行解密，最终在你的浏览器上显示出谷歌的网页。\r\n\r\n整个过程中，你的所有网络流量都受到了端到端的保护，你的真实身份和位置也得到了完美的隐藏。\r\n网络地址转换\r\n(Network Address Translation, NAT)\r\n网络地址转换（NAT）技术于1994年被提出，其主要目的是为了缓解IPv4地址空间即将耗尽的问题\r\n。NAT允许大量使用内部专用地址的专用网络用户，通过共享少量外部全球地址来访问因特网\r\n。\r\n这项技术需要在连接专用网络和因特网的路由器上安装NAT软件，这种路由器被称为\r\nNAT路由器 。NAT路由器至少拥有一个有效的外部全球IP地址\r\n。当所有使用内部专用地址的主机与外部因特网通信时，它们的内部地址都必须在NAT路由器上被转换成这个全球IP地址\r\n。\r\n最基本的NAT方法\r\n这是NAT最基础的工作方式，只转换IP地址。基本工作流程如下:\r\n出站过程（从专用网到因特网）：\r\n\r\n专用网内的主机A（使用专用地址\r\nIP_A）向因特网上的主机B（使用全球地址\r\nIP_B）发送一个IP数据报。该数据报的源地址是 IP_A，目的地址是\r\nIP_B。\r\n当NAT路由器收到这个数据报后，它会从自己的全球地址池中选择一个临时的全球地址\r\nIP_G。\r\n路由器将数据报首部中的源地址从 IP_A 修改为\r\nIP_G。\r\n同时，路由器会在自己的 NAT转换表 中记录下 IP_A 与 IP_G\r\n的对应关系。\r\n最后，将修改过源地址的数据报转发到因特网。 \r\n\r\n入站过程（从因特网到专用网）：\r\n\r\n主机B回复一个IP数据报，其源地址是\r\nIP_B，目的地址是NAT路由器为A选择的临时全球地址 IP_G。\r\n当NAT路由器收到这个数据报时，它会查询NAT转换表。\r\n根据表中的记录，NAT路由器知道这个数据报是发给主机A的。\r\n路由器将数据报首部中的目的地址从 IP_G 修改回主机A的专用地址\r\nIP_A，然后将其在专用网内转发给主机A。\r\n\r\n\r\n\r\nalt text\r\n\r\n这种最基本的NAT方法有一个限制：如果NAT路由器拥有n个全球IP地址，那么专用网内最多只能同时有n台主机接入因特网。\r\n网络地址与端口号转换 (NAPT)\r\n为了更有效地利用全球IP地址，现在普遍采用的是一种将NAT与传输层端口号结合使用的方法，称为\r\n网络地址与端口号转换 (Network Address and Port\r\nTranslation, NAPT)\r\n。尽管技术上称为NAPT，但人们仍习惯将其简称为NAT 。\r\nNAPT允许大量使用专用地址的内部主机，共同使用NAT路由器上的一个全球IP地址，同时与因特网上的不同主机进行通信。工作原理如下：\r\n出站过程（内网到外网的NAPT转换）\r\n\r\nNAPT路由器收到内部主机（如192.168.0.6）发来的IP数据报 。\r\n路由器不仅将其源IP地址（专用地址）修改为自己的外部全球地址（113.218.175.235），还会将其传输层PDU的源端口号（如30000）修改为一个由NAPT路由器动态分配的新的端口号（如50001）\r\n。\r\n路由器将这个包含 (内部地址:内部端口) -&gt; (外部地址:外部端口)\r\n的映射关系记录到自己的 NAPT转换表 中 。\r\n最后，将修改过源地址和源端口号的IP数据报转发到因特网 。 \r\n\r\n入站过程（外网到内网的NAPT转换）\r\n\r\n当NAPT路由器从因特网收到主机C发回的数据报时，它会检查数据报的目的地址和目的端口号\r\n。\r\n根据NAPT转换表中的记录（如 113.218.175.235:50001\r\n对应\r\n192.168.0.6:30000），路由器就能知道这个数据报应该发给专用网中的哪台主机的哪个应用\r\n。\r\n路由器将数据报首部中的目的地址和运输层PDU的目的端口号，按照NAPT转换表中的记录进行修改\r\n。\r\n最后，将数据报转发给内部的主机A 。 \r\n\r\nNAT/NAPT的特点与问题\r\n\r\n通信必须由专用网内部发起 。\r\nNAT对网络应用并不完全透明，可能会对某些应用产生影响 。\r\n拥有内部专用地址的主机不能直接充当因特网中的服务器 。\r\n对于P2P这类需要外网主机主动与内网主机通信的应用，在通过NAT时会遇到问题，需要使用特殊的NAT穿透技术来解决\r\n。\r\n\r\nIP多播\r\n随着因特网传输能力的提升和音视频压缩技术的发展，网上音视频业务（如视频点播、视频会议等）变得日益重要\r\n。这些业务具有数据量大、对时延敏感的特点\r\n。为了以最小的资源和时间来传输这些数据，需要采用不同于传统单播和广播的转发机制，IP多播技术因此应运而生\r\n。\r\n多播（Multicast），也称为组播，是一种实现“一对多”通信的技术。在因特网上进行的多播，则称为IP多播。与传统的“一对一”单播通信相比，多播可以极大地节省网络资源。\r\n假如一个视频服务器需要向60个主机传送节目:\r\n单播\r\n(Unicast)：视频服务器需要为每一个接收视频的主机单独发送一份视频节目。如果要向60个主机传送，服务器就需要发送60个独立的视频节目副本，这会消耗大量的服务器和网络带宽资源。\r\n多播 (Multicast)：视频服务器只需向一个特定的多播组发送 一个\r\n视频节目副本即可。\r\n数据流在网络中传输时，只有在路径的分叉点，路由器才会根据需要复制数据包。例如，路由器R1在转发时，会将视频节目复制成2个副本，分别发往R2和R3。\r\n当数据包到达目的局域网时，可以利用局域网自身的硬件多播功能，无需复制即可让该网络上的所有多播组成员都收到这个视频节目。\r\n因此,\r\n当多播组的成员数量很大时，采用多播方式可以显著地减少网络中各种资源的消耗。要在因特网上实现多播，网络中的路由器必须具备多播功能，这涉及到IP多播数据报的寻址以及多播路由选择协议。\r\nIP多播地址和多播组\r\nIP多播通信必须依赖于IP多播地址。在IPv4中，D类地址\r\n被指定为多播地址。\r\n我们已经知道, D类IPv4地址的左起前4个比特固定为 1110,\r\n剩余的28个比特可以任意变化，因此总共有 2^28\r\n个IPv4多播地址。其点分十进制的范围是从 224.0.0.0 到 239.255.255.255\r\n。\r\n地址分类：根据[RFC3330]文档，D类地址可以进一步分为三类：\r\n\r\n预留的多播地址（永久多播地址）：例如 224.0.0.1\r\n指代本子网上所有参加多播的主机和路由器，224.0.0.2\r\n指代所有参加多播的路由器，224.0.0.5 用于OSPF路由器。\r\n全球范围可用的多播地址：可以在整个因特网范围内使用。\r\n本地管理的多播地址：仅在特定的本地范围内有效。\r\n\r\n\r\n\r\nalt text\r\n\r\n多播地址只能用作IP数据报的目的地址，不能用作源地址。每一个D类地址都用来标识一个多播组。所有使用同一个IP多播地址来接收多播数据报的主机，就构成了一个多播组\r\n。\r\n\r\n参与多播通信的主机，其 IP 地址始终是它本身在局域网内的单播 IP\r\n地址（例如 192.168.1.100）。 多播地址（例如\r\n239.1.1.1）仅用作数据包的目标地址，它代表的是一个“通信频道”或“群组”，而不是网络中任何一台具体的物理设备。\r\n\r\n成员特性：\r\n\r\n多播组的成员是可以随时动态变动的，一台主机可以随时加入或离开多播组。\r\n多播组成员的数量和所在的地理位置不受限制 。\r\n一台主机可以同时属于几个不同的多播组 。\r\n\r\n发送者特性：非多播组的成员也可以向任何一个多播组发送IP多播数据报\r\n。\r\n服务质量：IP多播数据报的传输遵循“尽最大努力交付”的原则，不保证一定能够成功交付给多播组内的所有成员。\r\n在局域网上进行硬件多播\r\n在因特网上进行IP多播的最后阶段，通常需要将多播数据报在本地局域网（如以太网）上交付给多播组的所有成员。幸运的是，局域网本身就支持硬件多播，即在数据链路层使用多播MAC地址进行“一对多”的帧传输。\r\n为了利用这一功能，核心任务是将网络层的\r\nIPv4多播地址（D类地址）映射成数据链路层的硬件多播地址（多播MAC地址）。\r\nIP多播地址到MAC地址的映射规则\r\n因特网号码指派管理局（IANA）专门为此保留了一段以太网MAC地址，范围是从\r\n01-00-5E-00-00-00 到 01-00-5E-7F-FF-FF。 \r\n这些多播MAC地址的结构有一个特点：其左起前25个比特是固定的，只有剩余的23个比特可以任意变化。\r\n因此，总共有 2^23 个以太网多播MAC地址。\r\n映射规则是：将D类IP地址中可变的28个比特中的低23位，直接复制到多播MAC地址中可变的23位部分。\r\n不过,\r\n这个映射规则存在一个重要的问题：映射关系并不是唯一的。\r\n因为一个D类IP地址有28个比特是可变的，而用于映射的多播MAC地址只有23个比特是可变的。\r\n这意味着IP多播地址中，除了固定的1110外，前5个可变比特无法被映射到MAC地址中。\r\n由于有5个比特的信息丢失了，多个不同的IP多播地址（最多 2^5 =32\r\n个）可能会映射到同一个MAC地址。 \r\n#### 在网络层进行软件过滤\r\n由于映射关系不唯一，仅仅依靠硬件（网卡）根据MAC地址来接收多播帧是不够的。因此，收到多播数据报的主机还需要在\r\n网际层利用软件进行二次过滤。\r\n\r\n硬件（MAC层）过滤：当一个多播帧在局域网上传播时，所有加入了对应硬件多播组（拥有相同多播MAC地址）的主机网卡都会接收这个帧。\r\n其他主机则在MAC层直接丢弃该帧。\r\n软件（网际层）过滤：接收了该帧的主机将帧解封装，把IP数据报向上传递给网际层。网际层会检查IP数据报首部中的目的IP地址。\r\n\r\n主机将这个目的IP地址与自己真正加入的IP多播组地址进行比较。如果地址不匹配，说明这个数据报虽然MAC地址正确，但并非发给自己的，于是将其丢弃。\r\n只有当目的IP地址也匹配时，才会最终接受该数据报。\r\n\r\n\r\n通过这种“硬件粗过滤 +\r\n软件精过滤”的两层机制，即使存在地址映射冲突，也能保证只有正确的IP多播组成员才能最终收到并处理数据报。\r\n\r\n\r\nalt text\r\n\r\nIP多播需要的两种协议\r\n要在因特网上实现IP多播，仅仅有IP多播地址是不够的。多播路由器必须能够智能地转发多播数据报，即只将数据报转发到那些确实有该多播组成员存在的网络中。\r\n为了实现这一目标，需要两种协议协同工作：网络组管理协议\r\n(IGMP) 和多播路由选择协议（PIM）。\r\n网络组管理协议\r\n(Internet Group Management Protocol, IGMP)\r\nIGMP用于让连接在 本地局域网\r\n上的多播路由器，知道本局域网上是否有主机（或主机中的某个进程）加入或退出了某个多播组。\r\n\r\n它解决了“最后一公里”的成员关系问题。例如，在图4-112中，路由器R1和R2需要知道它们各自连接的局域网上有226.128.9.26这个多播组的成员，而R3需要知道它自己的局域网上没有该组的成员。\r\n这个信息正是通过IGMP来获取的。\r\nIGMP有三种主要的报文类型 ： - 成员报告报文 (Membership Report) -\r\n成员查询报文 (Membership Query) - 离开组报文 (Leave Group)\r\nIGMP报文被封装在IP数据报中进行传送,\r\nIP数据报首部中的协议字段的值为2，表示其数据载荷是IGMP报文。\r\n由于IGMP仅在本网络(局域网)有效，封装有IGMP报文的IP多播数据报，其首部中\r\n生存时间 (TTL) 字段的值被设置为1，以避免被路由器转发到其他网络 。\r\nIGMP的基本工作原理\r\n\r\n加入多播组\r\n\r\n主机操作：当一个主机希望加入某个多播组时，它会向其所在的网络发送一个封装有IGMP成员报告报文的IP多播数据报,\r\nIGMP成员报告报文中包含要加入的IP多播组的地址,\r\n这个IP多播数据报的目的地址也设置为要加入的IP多播组的地址\r\n。\r\n网络响应：该网络中所有该多播组的成员以及多播路由器都会收到这个报文\r\n。如果本网络中还有同组的其他成员正准备发送加入报告，它们监听到这个报文后就会取消自己的发送，以减少网络冗余\r\n。\r\n路由器操作：多播路由器会维护一个多播组列表，记录其直连网络中存在成员的多播组地址\r\n。如果路由器收到一个未知多播组的成员报告，它就会将该多播组的地址添加到自己的列表中\r\n。路由器只关心网络中有哪些多播组，而不关心具体有哪些成员。\r\n\r\n监视多播组的成员变化\r\n\r\n路由器查询：多播路由器会周期性地（默认每隔125秒）向其直连网络发送一个IGMP成员查询报文,\r\n该查询报文被封装在IP多播数据报中，目的地址为特殊的IP多播地址\r\n224.0.0.1，这意味着本网络中所有参加多播的主机和路由器都会收到该报文\r\n。\r\n主机响应：收到查询报文的多播组成员会发送一个IGMP成员报告报文作为应答。为了避免不必要的重复应答，主机采用\r\n延迟响应策略：在1到10秒的随机时间内等待后再响应\r\n。如果在此期间监听到同组其他成员已发送报告，则取消自己的响应 。\r\n路由器更新列表：如果多播路由器长时间没有收到某个特定多播组的成员报告，它就会将该多播组从自己的多播组列表中删除，认为本网络中已没有该组的成员\r\n。\r\n在一个网络中若有多个多播路由器，它们会选举出一个查询路由器（通常是IP地址最小的那个），由它来负责发送成员查询报文，以避免重复查询\r\n。\r\n\r\n退出多播组\r\n\r\n主机操作：当一个主机要退出某个多播组时，它可以主动发送一个离开组报文，而无需等待路由器的查询\r\n。\r\n离开组报文被封装在IP多播数据报中，目的地址为特殊多播地址\r\n224.0.0.2，这个地址指向本网络中的所有多播路由器 。\r\n路由器操作：收到离开组报文后，路由器不能立即删除该多播组，因为网络中可能还有该组的其他成员。路由器会立即针对该特定多播组发送一个IGMP成员查询报文，以确认是否还有其他成员存在\r\n。\r\n\r\n如果在预定时间内没有收到任何该组的成员报告报文，路由器才会将该多播组从自己的多播组列表中删除\r\n。\r\n\r\n\r\n\r\n正因为IGMP\r\n仅在本网络中有效。它不能告诉路由器多播组包含了多少成员，也不能知道这些成员都分布在因特网的哪些网络中。因此，仅使用IGMP并不能在整个因特网上进行多播。要实现这一目标，还需要多播路由选择协议。\r\n多播路由选择协议\r\n(Multicast Routing Protocol)\r\n多播路由选择协议用于在因特网上的多播路由器之间协同工作，以便用最小的代价将多播数据报传送给所有的组成员。\r\n其主要任务是为每一个多播组建立一个多播转发树\r\n(multicast forwarding\r\ntree)。这个转发树连接了多播源和所有拥有该多播组成员的路由器。\r\n\r\nIP多播数据报只要沿着这个已经建好的转发树进行洪泛，就能被准确地传送到所有需要它的多播路由器。之后，在多播路由器所直连的局域网内，路由器再通过硬件多播将IP多播数据报发送给所有该多播组的成员。\r\n\r\n需要注意的是, 为了覆盖所有的多播组成员,\r\n多播转发树通常会包含一些没有该多播组成员的路由器和网络,\r\n这是因为这些路由器和网络位于源和其他多播组成员之间的路径上,\r\n它们是连接源和其他多播组成员的桥梁\r\n\r\n目前有两种主流的方法来构建多播转发树：\r\n\r\n基于源树 (Source-Based Tree) 多播路由选择\r\n组共享树 (Group-Shared Tree) 多播路由选择\r\n\r\n基于源树的多播路由选择\r\n这种方法最典型的算法是 反向路径多播 (Reverse Path\r\nMulticasting, RPM) 。RPM算法包含两个关键步骤：\r\n步骤一：利用反向路径广播 (RPB) 建立广播转发树\r\n首先创建一个覆盖所有路由器的无环路的广播转发树，以避免广播分组在有环路网络中无限兜圈。\r\n当一个路由器收到一个广播分组时，它会先检查该分组是否是从源点沿着最短路径传送来的。\r\n-\r\n检查方法：判断发送该分组的邻居路由器，是否就是自己到源点的最短路径上的第一个路由器\r\n- 转发决策： -\r\n是：如果路径正确，则将该分组从除了接收接口之外的所有其他接口转发出去 。\r\n- 否：如果路径不正确（即分组来自一个非最短路径），则丢弃该分组，不再转发\r\n。\r\n通过这个机制，可以确保每个路由器只接收并转发一份来自最短路径的广播分组，从而形成一个以源点为根的、无环路的广播转发树\r\n。\r\n步骤二：利用剪枝 (Pruning) 算法获得多播转发树\r\nRPB建立的是一个广播树，会把数据发送给所有路由器\r\n。为了实现多播，需要从这个广播树上“剪掉”那些不需要接收数据的分支。\r\n如果多播转发树上的某个路由器（叶节点）发现自己所连接的网络中没有该多播组的成员，并且它也没有下游路由器，它就会向上游路由器发送一个**\r\n剪枝报文** (Pruning message) 。\r\n上游路由器收到剪枝报文后，就会将通往该下游路由器的分支从转发树上剪除\r\n。\r\n嫁接\r\n(Grafting)：如果之后被剪枝的路由器又通过IGMP发现了新的多播组成员，它可以向上游路由器发送一个\r\n嫁接报文 (Grafting message)，重新加入到多播转发树中 。 \r\n组共享树多播路由选择\r\n这种方法不为每个源都建立一棵树，而是让一个多播组的所有成员共享一棵树。\r\n核心思想：在每个多播组中指定一个\r\n核心 (core) 路由器\r\n。以这个核心路由器为根，建立一棵连接该多播组所有成员路由器的生成树，作为多播转发树\r\n。\r\n建树过程：\r\n\r\n当一个成员路由器想要加入多播组时，它会向该组的核心路由器单播一个\r\n加入报文 。\r\n这个加入报文会沿着单播路径朝核心路由器前进，直到它遇到核心路由器或某个已经属于该多播转发树的节点\r\n。\r\n这个加入报文所经过的路径，就成为一个新的分支，被“嫁接”到现有的多播转发树上\r\n。\r\n\r\n源主机发送数据：如果一个不属于该多播组的源主机要发送多播数据，它会将多播分组封装在单播分组中，利用\r\nIP隧道技术 发送给核心路由器\r\n。核心路由器收到后再解封，并在多播转发树上进行洪泛 。 \r\n不过,\r\n目前还没有一个在整个因特网范围统一使用的多播路由选择协议。一些被建议使用的协议包括：\r\n\r\n距离向量多播路由选择协议 (DVMRP)\r\n开放最短路径优先的多播扩展 (MOSPF)\r\n协议无关多播-稀疏方式 (PIM-SM)\r\n协议无关多播-密集方式 (PIM-DM)\r\n基于核心的转发树 (CBT)\r\n\r\n而且,\r\n至今IP多播在因特网上仍未得到大规模应用，主要应用在一些局部的园区网或专用网络中。目前，P2P技术的广泛应用推动了应用层多播技术的发展\r\n。\r\n总之, 这两种协议的角色分工明确且互为补充。IGMP 负责 “自下而上”\r\n地向本地路由器报告成员情况，而 多播路由选择协议\r\n则负责在路由器之间 “横向”\r\n地构建高效的数据分发路径（多播转发树）。只有将两者结合，才能在庞大的因特网上实现高效、准确的IP多播。\r\n移动IP技术\r\n所谓移动IP (Mobile IP)\r\n技术，是指允许移动设备（如智能手机、笔记本电脑等）在不同的网络之间切换时，仍然能够保持其IP地址不变，从而实现无缝的网络连接和通信。\r\n例如这样一个场景:\r\n用户在行驶的汽车中，设备从一个Wi-Fi网络无缝切换到另一个Wi-Fi网络，同时希望能不中断文件下载任务\r\n。\r\n核心矛盾：\r\n\r\n必须改变IP地址：当设备进入一个新的网络时，它的IP地址必须改变，否则数据包将无法被正确路由到这个新位置\r\n。路由器会把发往其旧IP地址的数据包都路由到原来的网络 。\r\n不能改变IP地址：如果IP地址改变了，上层建立的TCP连接（如下载任务）会因为地址变化而失效，导致通信中断\r\n。\r\n\r\n移动IP技术正是为了解决这个“既要改变地址以实现路由，又不能改变地址以维持连接”的矛盾而设计的。它使得移动主机在不同网络间漫游时，能够保持其原来的IP地址不变。它通过引入一套新的角色和地址来实现这一目标，并且设计上无需改变非移动主机或大多数路由器的软件。\r\n几个关键概念：\r\n\r\n归属网络、归属地址和归属代理\r\n\r\n归属网络 (Home\r\nNetwork)：每个移动主机都有一个默认连接或初始申请接入的网络。\r\n归属地址 (Home\r\nAddress)：移动主机在归属网络中拥有的一个永久IP地址，在整个移动通信过程中始终不变。\r\n归属代理 (Home Agent,\r\nHA)：位于归属网络中的一个实体（通常是路由器），负责执行移动管理功能\r\n。当移动主机离开归属网络时，归属代理会为它代收所有数据报\r\n。\r\n\r\n外地网络、外地代理和转交地址\r\n\r\n外地网络 (Foreign\r\nNetwork)：移动主机当前漫游所在的网络，也称被访网络。\r\n外地代理 (Foreign Agent,\r\nFA)：位于外地网络中的一个实体（通常是路由器），帮助移动主机执行移动管理功能。\r\n转交地址 (Care-of Address,\r\nCoA)：由外地代理提供给移动主机的一个临时IP地址，该地址属于外地网络,\r\n用于标识移动主机在外地网络中的位置。\r\n移动IP技术的基本工作原理\r\n移动IP的整个工作过程可以分为几个步骤：\r\n\r\n代理发现与注册\r\n\r\n移动主机A从其归属网络漫游到一个外地网络。\r\n移动主机A通过“代理发现协议”与外地网络中的外地代理建立联系，并从外地代理处获得一个临时的转交地址（例如\r\n175.1.1.1/16）。\r\n移动主机A（或通过外地代理）向其归属网络中的归属代理进行注册，告知自己的永久地址和当前的转交地址。\r\n归属代理记录下移动主机的转交地址，此后开始代替移动主机接收所有发往其永久地址的数据报。\r\n\r\n固定主机向移动主机发送IP数据报（间接路由）\r\n\r\n发送到归属网络：固定主机B像往常一样，将IP数据报发送到移动主机A的永久地址\r\n(218.75.230.16) 。数据报被正常路由到A的归属网络 。\r\n隧道转发：归属代理截获这个数据报，然后使用IP隧道技术（也称IP-in-IP封装）将其重新封装在一个新的IP数据报中\r\n。这个新数据报的目的地址是移动主机A的转交地址\r\n(175.1.1.1) 。这个过程对固定主机B是完全透明的 。\r\n交付移动主机：封装后的数据报通过因特网被路由到外地代理\r\n。外地代理收到后，解封，取出原始的IP数据报，然后将其在外地网络中直接转发给移动主机A\r\n。\r\n\r\n移动主机向固定主机发送IP数据报（直接路由）\r\n\r\n移动主机A向固定主机B发送数据时，无需绕道归属代理 。\r\n它可以直接将IP数据报发送出去，源地址仍然填写其永久地址\r\n。\r\n由于路由器转发数据报时只关心目的地址，不关心源地址，因此这个数据报会被直接路由到固定主机B\r\n。\r\n\r\n三角形路由问题 (Triangle Routing Problem)\r\n\r\n不过,\r\n容易看出上述通信路径是不对称的。从固定主机到移动主机的数据报必须先绕道归属网络，再通过隧道转发，形成一个“三角形”的低效路径\r\n。\r\n即使固定主机B和移动主机A位于同一个外地网络，B发给A的数据包仍然要先发送到遥远的归属网络，再被转发回来，造成极大的延迟和资源浪费\r\n。\r\n解决方案：一种方法是让固定主机也配置一个通信代理，该代理先从归属代理获取移动主机的最新转交地址，然后直接通过隧道将数据发送过去。但这会增加复杂性，并破坏了对固定主机透明的原则\r\n。\r\n下一代互联网协议 (IPv6)\r\n","categories":["web"],"tags":["web","computer network"]},{"title":"网格图 DFS 与 BFS","url":"/2025/10/09/algorithms/Coding%E6%8A%80%E5%B7%A7/%E7%BD%91%E6%A0%BC%E5%9B%BE/","content":"网格图 (Grid Graph)\r\n是一种特殊的图结构，节点排列成二维矩阵的形式，每个节点与其上下左右（有时包括对角线方向）的邻居节点相连。\r\n它本质上是图论问题，但比图论更“友好”，因为它是一个“隐式图”。你不需要自己构建邻接表，一个\r\n(r, c) 单元格的邻居就是 (r+1, c), (r-1, c) 等。\r\n这一章的核心是考察你对两种最基本图遍历算法的理解和应用： - DFS\r\n(深度优先搜索) - BFS (广度优先搜索) 选择 DFS 还是 BFS\r\n不是随意的，而是由题目的核心诉求决定的。\r\n\r\n选择 DFS (深度优先搜索)\r\n\r\n“不撞南墙不回头”。它会沿着一个方向“走到底”，然后再回溯。\r\n机制：依赖递归或者栈（函数调用栈）。\r\n何时使用？当题目问的是“连通性”、“有多少块”、“这一块有多大”、“能不能到达”时。\r\n\r\n(岛屿数量)：DFS 非常适合“淹没”一个连通块。\r\n\r\n优点：代码通常更简洁（递归天然处理了回溯）。\r\n\r\n选择 BFS (广度优先搜索)\r\n\r\n“一圈一圈往外扩”。像水波纹一样，先访问所有距离为 1\r\n的，再访问所有距离为 2 的…\r\n机制：依赖队列 (Queue)。\r\n何时使用？当题目问的是“最短”路径、“最少”步数、“最快”时间时（在无权图中）。\r\n\r\n(01 矩阵)：求每个点到最近的 0 的距离。\r\n\r\n优点：天然地保证找到的路径是最短的。\r\n\r\n\r\n网格图 DFS (连通性问题)\r\n这是网格图的基础,\r\n适用于解决“连通性”问题，比如“岛屿数量”、“最大岛屿面积”、“是否存在路径”等。\r\n例题分析：200. 岛屿数量 ：给你一个 m x n 的、由 ‘1’（陆地）和\r\n‘0’（水）组成的网格图，返回岛屿的数量。\r\n解题思路 (DFS)： - 主函数：写一个双层 for 循环遍历所有单元格 (r, c)。\r\n- int island_count = 0; - 循环的核心逻辑： - if (grid[r][c] == ‘1’)： -\r\n解释：我们找到了一个新岛屿的“一角”，它还没有被访问过。 - island_count++;\r\n（答案加 1） - dfs(grid, r, c); （调用 DFS，把与 (r, c)\r\n相连的整座岛全部“淹没”, 即标记为’0’） - return island_count;\r\nint numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) {    int m = grid.size();    if (m == 0) return 0; // 处理空网格    int n = grid[0].size();        int sum = 0;    // (步骤说明)：遍历网格中的每一个单元格    for (int i = 0; i &lt; m; ++i) {        for (int j = 0; j &lt; n; ++j) {            // 如果找到一块陆地 ('1')            if (grid[i][j] == '1') {                                sum++;   // 我们发现了一个新岛屿，计数器加 1                // (步骤说明)：调用 DFS 将这个岛屿上的所有 '1'                // 全部“淹没” (改成 '0')，这样它们就不会被重复计算                dfs(grid, i, j);            }        }    }    return sum;}// 辅助函数：深度优先搜索 (DFS), 用于“淹没”与 (r, c) 相连的所有陆地void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int r, int c) {    int m = grid.size();    int n = grid[0].size();    // (步骤说明)：Base Case 1: 检查是否越界    if (r &lt; 0 || r &gt;= m || c &lt; 0 || c &gt;= n) {        return;    }    // (步骤说明)：Base Case 2: 检查是否为水或已访问 (已沉没)    if (grid[r][c] != '1') {        return;    }    // (步骤说明)：淹没当前陆地格    // 也可以使用其他标记方式，比如 bool visited[m][n] 数组 来标记已访问    grid[r][c] = '0';     // (步骤说明)：向四个方向递归，淹没所有相连的陆地    dfs(grid, r + 1, c); // 下    dfs(grid, r - 1, c); // 上    dfs(grid, r, c + 1); // 右    dfs(grid, r, c - 1); // 左}\r\n网格图 BFS (最短路径问题)\r\n核心思想： - 队列\r\n(Queue)：std::queue&lt;std::pair&lt;int, int&gt;&gt; q;\r\n存储待访问的坐标 (r, c)。 - 层级 (Level)：BFS\r\n的关键是“一层一层”地遍历。你需要一个 while (!q.empty())\r\n循环处理该位置可能的所有邻居，并在内部再用一个 for\r\n循环来处理当前层的所有节点。 - 访问数组 (Visited\r\nArray)：必须要有, 而且BFS 的 visited 标记必须在入队 (push) 时就标记\r\n例如, 二进制矩阵中最短路径问题 (LC 1091) class Solution {public:    int shortestPathBinaryMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {        if(grid[0][0]==1) return -1;           int n = grid.size();        if(n==1) return 1;          queue&lt;vector&lt;int&gt;&gt; q;  // 队列存储当前坐标和步数        vector&lt;vector&lt;bool&gt;&gt; isvisted(n, vector&lt;bool&gt;(n, false));    // 访问数组                q.push({0,0,1});        isvisted[0][0] = true;        vector&lt;vector&lt;int&gt;&gt; dirs = {{-1,-1},{-1,0},{-1,1},{0,-1},{0,1},{1,-1},{1,0},{1,1}};  // 将八个方向都考虑进去, 且写成数组方便遍历        while(!q.empty()){             vector&lt;int&gt; curr = q.front();              q.pop();            int r = curr[0];            int c = curr[1];            int step = curr[2];            if(r==n-1&amp;&amp;c==n-1) return step;  // 到达终点, 返回步数                        for(auto&amp; dir:dirs){  // 遍历八个方向                int next_r = r+dir[0];                int next_c = c+dir[1];                if(next_r&lt;0||next_c&lt;0||next_r&gt;=n||next_c&gt;=n                        ||isvisted[next_r][next_c]||grid[next_r][next_c]==1){                    continue;                }  // 越界或已访问或障碍, 直接跳过                q.push({next_r,next_c,step+1});  // 入队列, 步数加1, 下一轮会处理                isvisted[next_r][next_c] = true;             }        }        return -1;    }}; 再例如,\r\n腐烂的橘子 (LC 994) int orangesRotting(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {    int m = grid.size();    int n = grid[0].size();        // 1. 初始化：队列、方向数组、统计新鲜橘子    queue&lt;pair&lt;int, int&gt;&gt; q;    // BFS 队列, 主要保存坐标信息    vector&lt;vector&lt;int&gt;&gt; dirs = {{1,0}, {-1,0}, {0,1}, {0,-1}};    int fresh_count = 0; // 统计新鲜橘子数量    int minutes = 0;     // 记录分钟数，即 BFS 的层数    // 2. 初始扫描：入队所有腐烂橘子(源头)，统计所有新鲜橘子    for(int i = 0; i &lt; m; i++) {        for(int j = 0; j &lt; n; j++) {            if (grid[i][j] == 2) {                q.push({i, j});            } else if (grid[i][j] == 1) {                fresh_count++;            }        }    }    // 3. 边缘情况处理：如果一开始就没有新鲜橘子    if (fresh_count == 0) {        return 0;    }    // 4. BFS 主循环 (按层遍历)    while (!q.empty()) {        // 核心：锁定当前层级的节点数量        int size = q.size();         // 5. 处理当前层的所有节点        for (int i = 0; i &lt; size; i++) {            int r = q.front().first;            int c = q.front().second;            q.pop();            // 探索4个方向            for (auto&amp; dir : dirs) {                int r_new = r + dir[0];                int c_new = c + dir[1];                // 检查新坐标是否有效 且 是否为新鲜橘子                if (r_new &gt;= 0 &amp;&amp; r_new &lt; m &amp;&amp; c_new &gt;= 0 &amp;&amp; c_new &lt; n &amp;&amp; grid[r_new][c_new] == 1) {                    // 腐烂它                    grid[r_new][c_new] = 2;                    q.push({r_new, c_new}); // 加入队列，供下一分钟处理                                        // 更新新鲜橘子计数                    fresh_count--;                 }            }        }                // 6. 关键：更新时间        // 如果队列非空(说明还有下一层)，则时间+1        if (!q.empty()) {            minutes++;        }    }    // 7. 最终结果判断 (使用优化后的计数)    return (fresh_count == 0) ? minutes : -1;}\r\n思考题\r\nBFS 队列 vs. DFS\r\n递归栈的最大空间？两者最坏情况都是 O(m × n)。\r\n\r\nBFS\r\n队列：当图是一个“稠密”的棋盘格时，从角落出发，队列在中间某一层会包含近\r\nO(m × n)\r\n个节点。\r\nDFS\r\n栈：当图的构造是一个“蛇形”路径，它填满了所有单元格。DFS\r\n会从头一口气走到尾，递归深度（栈空间）为 O(m × n)。\r\n\r\n如何构造让 DFS 递归深度最大？蛇形/螺旋形路径。起点\r\n(0,0)：构造一个“贪吃蛇”路径，例如： 1 1 1 1 10 0 0 0 11 1 1 0 11 0 1 1 11 0 0 0 0  (假设 1 是路径，0\r\n是墙)。DFS 会从 (0,0) 沿着 1 一直走到 (4,0)，深度 O(mn)。起点\r\n(i,j)：以 (i,j) 为起点，构造一个螺旋形或蛇形路径占满整个图。\r\n一般图\r\n有时候题目并没有给出网格图，而是给出一些非图的信息,\r\n你需要自己构造图的邻接关系, 然后再用 DFS 或 BFS 来遍历。\r\n常见的建图方式有： - 邻接矩阵 (Adjacency Matrix):\r\n二维数组表示节点间的连接关系, 例如 A[i][j] = 1 表示节点 i 和 j\r\n之间有边相连。 - 对于无向图, 矩阵是对称的; 而对于有向图, A[i][j] = 1\r\n表示从 i 指向 j 有一条边。 - 邻接表 (Adjacency List):\r\n每个节点维护一个链表或数组，存储所有相邻节点。 - 对于无向图, 如果节点 i\r\n和 j 相连, 那么 j 会出现在 i 的邻接表中, 同时 i 也会出现在 j\r\n的邻接表中。 - 对于有向图, 只有 j 会出现在 i 的邻接表中。 -\r\n入度数组往往和邻接表一起使用, 用于记录每个节点的入度\r\n(有多少条边指向它)。这在拓扑排序等算法中非常有用。\r\n例如, LC 207. 课程表: 你这个学期必须选修 numCourses 门课程，记为 0 到\r\nnumCourses - 1 。在选修某些课程之前需要一些先修课程。 先修课程按数组\r\nprerequisites 给出，其中 prerequisites[i] = [ai, bi]\r\n，表示如果要学习课程 ai 则 必须 先学习课程 bi\r\n。请你判断是否可能完成所有课程的学习？如果可以，返回 true ；否则，返回\r\nfalse 。 bool canFinish(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) {        // 1. 初始化邻接表和入度数组    // 邻接表 adj[bi] 存储所有以 bi 为先修课的课程 ai    vector&lt;vector&lt;int&gt;&gt; adj(numCourses);    // 在我之后学的课程    // indegree[ai] 存储课程 ai 有多少门先修课    vector&lt;int&gt; indegree(numCourses, 0);    // 在我之前必须学的课程数    // 遍历所有先修关系, 从所给的条件中构建邻接表和入度数组    for (const auto&amp; pre : prerequisites) {        int course = pre[0];   // 课程 ai        int prereq = pre[1];   // 课程 bi                // 建立一条从 bi 到 ai 的边        adj[prereq].push_back(course);                 // 课程 ai 的入度（先修课数量）加 1        indegree[course]++;    }    // 2. 初始化队列，将所有入度为 0 的节点（课程）入队    queue&lt;int&gt; q;    for (int i = 0; i &lt; numCourses; ++i) {        if (indegree[i] == 0) {            q.push(i);        }    }    int count = 0; // 记录已修完的课程数量    // 3. 执行 BFS    while (!q.empty()) {        // 从队列中取出一门课，代表我们“修完了”这门课        int course = q.front();        q.pop();        count++; // 修完的课程数 +1        // 遍历所有以 'course' 为先修课的后续课程 'nextCourse'        for (int nextCourse : adj[course]) {            // 'nextCourse' 的一门先修课 'course' 已经修完            // 因此 'nextCourse' 的入度减 1            indegree[nextCourse]--;            // 检查：如果 'nextCourse' 的所有先修课都已修完（入度变为 0）            if (indegree[nextCourse] == 0) {                // 那么 'nextCourse' 现在可以学习了，将其入队                q.push(nextCourse);            }        }    }    // 4. 判断结果    // 如果修完的课程总数等于总课程数，说明没有环，可以完成    // 否则，说明存在环，无法完成    return count == numCourses;}\r\n","categories":["algorithms"],"tags":["algorithms"]},{"title":"二叉树","url":"/2025/10/09/algorithms/Coding%E6%8A%80%E5%B7%A7/%E4%BA%8C%E5%8F%89%E6%A0%91/","content":"二叉树\r\n二叉树是一种非常适合递归处理的数据结构,\r\n因为每个节点都可以看作是一个子树的根节点.\r\n必须回答的三个核心问题（递归的灵魂）\r\n下面是二叉树递归的三个核心问题。每当你面对一个新的二叉树问题时，都要问自己这三个问题，从而设计出合适的递归函数。\r\n递归边界：nullptr\r\nvs. 叶子节点？ - if (root == nullptr)（空节点边界） -\r\n这是最常用、最健壮的边界,\r\n几乎所有二叉树递归都应该使用它作为基础边界条件(但不一定是唯一边界条件)。\r\n-\r\n含义：“我这个递归函数被要求去处理一个不存在的节点，我什么也不用做，直接\r\nreturn（或 return 0, return true 等默认值）。” -\r\n优点：它能统一处理所有情况，包括： - 整个树为空（dfs(head) 一开始 head\r\n就是 nullptr）。 - 一个节点只有左孩子（dfs(root-&gt;right) 时会触发）。\r\n- 一个节点是叶子节点（dfs(root-&gt;left) 和 dfs(root-&gt;right)\r\n都会触发）。 - if (root-&gt;left == nullptr &amp;&amp; root-&gt;right ==\r\nnullptr)（叶子节点边界） -\r\n这是极少数情况，只在问题逻辑必须在“叶子”处终止时才使用,\r\n但也需要额外加上 if (root == nullptr) 作为基础边界。 - 含义：“我这个 dfs\r\n函数在到达子节点时，就要停止‘递’，开始‘归’。” - 典型案例： - (112.\r\n路径总和)：你必须在叶子节点处判断 sum == targetSum，而不是在 nullptr\r\n处。 - (404. 左叶子之和)：你必须从父节点判断 parent-&gt;left 是\r\n一个叶子，才能累加。 - 结论：永远默认使用 if (root == nullptr)\r\n作为递归边界。\r\n只有当题目（如“路径总和”）明确要求你必须在叶子节点做判断时，才额外增加对叶子节点的判断。\r\n返回类型: void vs. 有返回值？ - void dfs(…)\r\n(无返回值) - 含义：你不需要从子节点获取“答案”。 - 用途 1\r\n(自顶向下)：父节点向子节点传递信息。比如 dfs(root,\r\ncurrentSum)，父节点把“当前的路径和”传给子节点。 - 用途 2\r\n(外部变量)：你使用一个类成员变量或引用传递的变量来存储最终答案。\r\n-\r\nvoid dfs(root, vector&lt;int&gt;&amp; path, vector&lt;vector&lt;int&gt;&gt;&amp; op),\r\n或者是类成员变量 vector&lt;vector&lt;int&gt;&gt; results;。\r\n- 在递归过程中不断更新 path，当到达叶子节点时，把 path 加入 results。 -\r\n典型案例： - 回溯 (113. 路径总和 II)：你需要一个 path\r\n变量一路传下去。 - 自顶向下 (129. 求根节点到叶节点数字之和)：dfs(root,\r\ncurrentNum * 10 + root-&gt;val)。 - T dfs(…) (有返回值，如 int, bool,\r\nTreeNode)\r\n-\r\n含义：父节点必须等到子节点的递归调用返回一个结果后，才能计算出父节点“自己”的结果。这是“自底向上”的核心。\r\n- 典型案例： - (104. 二叉树的最大深度)： - int dfs(root) - int leftDepth\r\n= dfs(root-&gt;left); - int rightDepth = dfs(root-&gt;right); -\r\nreturn 1 + std::max(leftDepth, rightDepth); -\r\n(父节点的答案依赖于子节点的答案) - (110. 平衡二叉树)：int\r\ndfs(root)（返回高度，如果-1则表示不平衡）。 - (236.\r\n最近公共祖先)：TreeNode dfs(root, …)（返回 p 或 q 或 nullptr）。 -\r\n结论：问自己：“父节点的答案，是否依赖于子节点的计算结果？”\r\n- 是 → 有返回值\r\n(自底向上)。 - 否 →\r\nvoid (自顶向下，或使用外部变量)。\r\n自顶向下 (Top-Down) vs. 自底向上\r\n(Bottom-Up)？ - 这是对上面“返回类型”的进一步理解。 - 自顶向下 (Pre-order\r\n/ 先序遍历) - 执行顺序：1. 处理 root →\r\n2. 递归 left → 3. 递归 right -\r\n含义：“继承”——父节点处理完自己的逻辑，然后把信息传递给子节点。\r\n- 代码模板 (104. 最大深度 - Top-Down 解法)： int maxDepth = 0; // 类成员变量或外部变量void dfs(TreeNode* node, int currentDepth) {    if (node == nullptr) {        maxDepth = std::max(maxDepth, currentDepth);        return;    }    dfs(node-&gt;left, currentDepth + 1);    dfs(node-&gt;right, currentDepth + 1);} - 自底向上\r\n(Post-order / 后序遍历) - 执行顺序：1. 递归 left (拿结果) → 2. 递归 right (拿结果) → 3. 处理 root (汇总) -\r\n含义：“聚合”——父节点必须等待左右子树的结果，才能计算出自己的结果。\r\n- 代码模板 (104. 最大深度 - Bottom-Up 解法)： int dfs(TreeNode* node) {    if (node == nullptr) {        return 0;    }    int leftDepth = dfs(node-&gt;left);    int rightDepth = dfs(node-&gt;right);    return 1 + std::max(leftDepth, rightDepth);} -\r\n一般来说，自底向上更常见，因为大多数二叉树问题都需要汇总子节点的结果来计算父节点的答案。\r\n-\r\n结论：问自己：“父节点的答案，是否依赖于子节点的计算结果？”\r\n- 是 → 自底向上 (有返回值)。 - 否 → 自顶向下 (void 或外部变量)。\r\n二叉树的遍历\r\n二叉树的遍历主要有三种方式: 前序遍历 (Preorder), 中序遍历 (Inorder),\r\n后序遍历 (Postorder). 这三种遍历方式的区别在于访问节点的顺序不同,\r\n名称反映的是访问根节点的时机\r\n三种遍历都可以使用递归实现, 较为简单. 例如:\r\n// 前序遍历 (根-左-右)void preorder(TreeNode* root, vector&lt;int&gt;&amp; result) {    if (root == nullptr) return;    // 访问根节点    result.push_back(root-&gt;val);    // 遍历左子树    preorder(root-&gt;left, result);    // 遍历右子树    preorder(root-&gt;right, result);}\r\n使用迭代实现时, 通常需要借助栈 (Stack)\r\n来手动模拟递归调用栈的行为.\r\n迭代遍历\r\n对于前序遍历, 迭代实现相对简单, 只需要一个栈来辅助即可.\r\n不过需要注意的是, 前序遍历中,\r\n我们需要先将右子节点入栈, 再将左子节点入栈,\r\n这样才能保证左子节点先被访问.(访问顺序和入栈顺序相反) std::vector&lt;int&gt; preorderIterative(TreeNode* root) {    std::vector&lt;int&gt; result;    if (root == nullptr) {        return result;    }    std::stack&lt;TreeNode*&gt; s;    s.push(root); // 1. 首先将根节点入栈    while (!s.empty()) {        TreeNode* node = s.top(); // 2. 取出栈顶元素        s.pop();        result.push_back(node-&gt;val); // 3. 访问该节点（根）        // 4. 关键：先将 右 子节点入栈，再将 左 子节点入栈        // 这样能确保 左 子节点在 右 子节点之前被访问        if (node-&gt;right != nullptr) {            s.push(node-&gt;right);        }        if (node-&gt;left != nullptr) {            s.push(node-&gt;left);        }    }    return result;}\r\n对于后序遍历, 迭代实现相对复杂一些,\r\n因为我们需要确保根节点在左右子节点之后被访问.\r\n这里有两种常见的做法: 1. 将后序遍历转换为“根-右-左”的前序遍历,\r\n然后再将结果反转. 2.\r\n使用一个栈和一个指针:\r\n通过一个指针来追踪上一个访问的节点,\r\n以判断当前节点的右子树是否已经被访问过. 这里我们展示第二种方法:\r\nstd::vector&lt;int&gt; postorderIterative(TreeNode* root) {    std::vector&lt;int&gt; result;    if (root == nullptr) {        return result;    }    std::stack&lt;TreeNode*&gt; s;    TreeNode* curr = root;    TreeNode* lastVisited = nullptr; // 记录上一个访问的节点    while (curr != nullptr || !s.empty()) {        // 1. 一直向左走, 将路径上的节点入栈        while (curr != nullptr) {            s.push(curr);            curr = curr-&gt;left;        }        // 2. 查看栈顶节点        TreeNode* node = s.top();        // 3. 判断右子树是否已经访问过        if (node-&gt;right == nullptr || node-&gt;right == lastVisited) {            // 如果没有右子树或右子树已经访问过, 则访问当前节点            result.push_back(node-&gt;val);            s.pop();            lastVisited = node; // 更新上一个访问的节点            curr = nullptr; // 防止再次进入左子树        } else {            // 如果有右子树且未访问过, 则转向右子树            curr = node-&gt;right;        }    }    return result;} 另一种更简单的方式是使用“前序遍历变形”方法:\r\nstd::vector&lt;int&gt; postorderIterative(TreeNode* root) {    std::vector&lt;int&gt; result;    if (root == nullptr) {        return result;    }    std::stack&lt;TreeNode*&gt; s;    s.push(root);    while (!s.empty()) {        TreeNode* node = s.top();        s.pop();        result.push_back(node-&gt;val); // 先访问根节点        // 先将左子节点入栈, 再将右子节点入栈        if (node-&gt;left != nullptr) {            s.push(node-&gt;left);        }        if (node-&gt;right != nullptr) {            s.push(node-&gt;right);        }    }    // 最后反转结果以获得后序遍历顺序    std::reverse(result.begin(), result.end());    return result;}\r\n对于中序遍历,\r\n我们需要模拟“一路向左，直到尽头；访问；然后转向右子树”的过程。\r\n\r\n使用一个 curr 指针指向当前节点，初始为 root。\r\n外层循环：只要 curr 不为空 或 栈不为空，就继续。\r\n\r\n步骤 A (深入左子树)：while (curr !=\r\nnullptr)：只要当前节点不为空，说明它有（或它就是）一个需要稍后访问的“根”。\r\n\r\n将其入栈（表示“我稍后会回来访问你”）。\r\ncurr = curr-&gt;left;（继续深入左子树）。\r\n\r\n步骤 B (访问根并转向右)：当 while 循环结束时，curr\r\n必定为空，表示我们已到达最左侧的尽头。\r\n\r\n此时从栈中弹出一个节点（这个节点是“左-根-右”中的根）。\r\n访问它（加入结果列表）。\r\ncurr = popped_node-&gt;right;（将 curr\r\n指针转向该节点的右子树，准备在下一轮外层循环中处理右子树）。\r\nstd::vector&lt;int&gt; inorderIterative(TreeNode* root) {    std::vector&lt;int&gt; result;    std::stack&lt;TreeNode*&gt; s;    TreeNode* curr = root; // 使用一个指针来追踪当前节点    // 循环条件：当前节点不为空（表示还有子树待处理）    // 或者 栈不为空（表示还有已入栈的父节点待访问）    while (curr != nullptr || !s.empty()) {                // 1. 深入左子树：不断将当前节点入栈，并向左下方移动        // 直到 curr 为空，表示到达了最左侧        while (curr != nullptr) {            s.push(curr);       // 将路径上的“根”节点入栈            curr = curr-&gt;left;        }        // 2. 访问根节点：当curr为空时，从栈中弹出节点        // 这是\"左-根-右\"中的\"根\"，也是最左侧的节点        curr = s.top();        s.pop();        result.push_back(curr-&gt;val); // 访问根节点        // 3. 转向右子树：将当前节点指向右子树        // 在下一轮循环中，将对这个右子树重复“步骤1”        curr = curr-&gt;right;    }    return result;}\r\n\r\n\r\n\r\n层序遍历 (Level-order)\r\n还有一种遍历是层序遍历 (Level-order), 也称为广度优先遍历 (BFS).\r\n这是唯一的主流非递归解法。当你需要按层处理问题时，BFS\r\n是首选。\r\n层序遍历通常使用队列 (Queue) 来实现,\r\n通过逐层访问节点来实现. 实现代码如下: class Solution {public:    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) {        vector&lt;vector&lt;int&gt;&gt; results;        if(!root) return results;        queue&lt;TreeNode*&gt; que;  // 使用队列来辅助层序遍历        que.push(root);        while(!que.empty()){  // 每层循环处理一层节点, 由上一层节点入队列            int size = que.size();            vector&lt;int&gt; path;            for(int i=0;i&lt;size;i++){  // 处理当前层的所有节点                TreeNode* node = que.front();                path.push_back(node-&gt;val);                que.pop();                if(node-&gt;left) que.push(node-&gt;left);  // 将下一层节点入队列                if(node-&gt;right) que.push(node-&gt;right);            }            results.push_back(path);        }        return results;    }}; ### 二叉搜索树\r\n(BST)\r\n特点是: 对于每个节点, 左子树的所有节点值都小于该节点值,\r\n右子树的所有节点值都大于该节点值.\r\n一般使用中序遍历来处理二叉搜索树的问题,\r\n因为中序遍历会得到一个有序序列.\r\n最近公共祖先 (LCA)\r\n最近公共祖先问题是二叉树中一个经典问题,\r\n其核心思想是使用递归来查找两个节点的公共祖先. 这是一个经典的自底向上\r\n(后序遍历) 递归。(LC 236) - dfs(root, p, q)\r\n函数的语义（返回值）是：“在以 root 为根的子树中，我能找到 p 还是 q\r\n还是它俩的 LCA？” - 如果找到了 p 或 q，返回对应的节点指针。 - 如果找到了\r\nLCA，返回 LCA 节点指针。 - 如果都没找到，返回 nullptr。\r\nTreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {    // 1. 边界: 空节点，或找到了 p 或 q    if (root == nullptr || root == p || root == q) {        return root;    }    // 2. 递归 left (拿结果)    TreeNode* left_result = lowestCommonAncestor(root-&gt;left, p, q);    // 3. 递归 right (拿结果)    TreeNode* right_result = lowestCommonAncestor(root-&gt;right, p, q);    // 4. 处理 root (汇总)    // 解释: p 和 q 分布在 root 的两侧，    // 那么 root 就是 LCA    if (left_result != nullptr &amp;&amp; right_result != nullptr) {        return root;    }else if (left_result != nullptr) { // 只有左子树找到了 p 或 q        return left_result;  // 返回左子树的结果, 可能是 p, q, 或 LCA    } else {        return right_result;    }}\r\n从…构造二叉树\r\n从前序和中序遍历构造二叉树是一个经典问题,\r\n其核心思想是利用前序遍历确定根节点, 然后利用中序遍历划分左右子树. (LC\r\n105)\r\n从前序和中序遍历构造二叉树\r\n\r\n先序遍历 (Preorder): [ 根节点, [左子树…], [右子树…] ]\r\n\r\npreorder 数组的第一个元素（preorder[0]）永远是整棵树的根节点\r\n(Root)。\r\n\r\n中序遍历 (Inorder): [ […左子树…], 根节点, […右子树…] ]\r\n\r\ninorder 数组中根节点 (Root)\r\n的位置，恰好划分了哪些节点属于左子树，哪些节点属于右子树。\r\n根节点左边的所有元素都在左子树,\r\n根节点右边的所有元素都在右子树。\r\n\r\n\r\nunordered_map&lt;int, int&gt; inorderMap; // (步骤说明)：一个全局索引，用于追踪先序遍历数组int preorderIndex;  // 它始终指向下一个将被用作“根”的元素TreeNode* buildTreeHelper(const vector&lt;int&gt;&amp; preorder, int inorderLeft, int inorderRight) {    // (步骤说明)：Base Case:     // 如果左边界大于右边界，说明中序遍历的窗口为空，    // 这是一个空子树。    if (inorderLeft &gt; inorderRight) {        return nullptr;    }    // --- 1. 找到并创建根节点 ---        // (步骤说明)：根据先序遍历的性质，preorderIndex 指向的    // 元素就是当前子树的根节点。    int rootVal = preorder[preorderIndex];        // (步骤说明)：将 preorderIndex 后移，    // 准备为接下来的左子树或右子树提供根节点。    preorderIndex++;        TreeNode* root = new TreeNode(rootVal);    // --- 2. 划分左右子树 ---        // (步骤说明)：使用哈希表 O(1) 查找到根节点在中序遍历中的位置    int inorderRootIndex = inorderMap[rootVal];        // --- 3. 递归构建左右子树 ---        // (步骤说明)：递归构建左子树    // 左子树的中序遍历范围是 [inorderLeft, inorderRootIndex - 1]    root-&gt;left = buildTreeHelper(preorder, inorderLeft, inorderRootIndex - 1);        // (步骤说明)：递归构建右子树    // 右子树的中序遍历范围是 [inorderRootIndex + 1, inorderRight]    root-&gt;right = buildTreeHelper(preorder, inorderRootIndex + 1, inorderRight);    // (步骤说明)：返回构建完成的根节点    return root;}TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) {    // (步骤说明)：初始化先序遍历的索引，从 0 (第一个元素) 开始    preorderIndex = 0;        // (步骤说明)：构建中序遍历的 (值 -&gt; 索引) 映射， O(n)    for (int i = 0; i &lt; inorder.size(); ++i) {        inorderMap[inorder[i]] = i;    }    // (步骤说明)：启动递归    // 初始的中序遍历窗口是整个数组 [0, n-1]    return buildTreeHelper(preorder, 0, inorder.size() - 1);}\r\n","categories":["algorithms"],"tags":["algorithms"]},{"url":"/2025/10/30/misc/%E8%BD%AF%E6%8A%80%E8%83%BD/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","content":"针对内存层面，一种代码有好几种写法，可能实现的功能都差不多，但是性能可能会有很大的差异，关于这点具体有什么要注意的地方\r\n几乎所有 C++\r\n的性能差异，最终都归结于硬件（尤其是\r\nCPU\r\nCache）是如何与我们的内存访问模式进行交互的。在现代\r\nC++ 中，“高性能程序 =\r\n贴合缓存的数据结构 + 算法”。C++\r\n几乎是唯一一个允许你（也要求你）精细控制内存布局的现代语言。\r\n\r\n缓存为王：连续内存（std::vector） 碾压\r\n指针跳转（std::list）\r\n\r\nCPU\r\n从内存读取数据不是一个字节一个字节读的，而是以“缓存行”（Cache\r\nLine）为单位（通常是 64\r\n字节）来批量读取的。这是利用了空间局部性（Spatial Locality）：\r\n当你访问一个内存地址时，CPU 会自动把它和它后面相邻的 63\r\n个字节一起加载到高速缓存（L1 Cache）中。\r\n性能差异：std::vector&lt;int&gt;内存完全连续。当你遍历\r\nvector 时，第一次访问 v[0]，CPU 会把 v[0] 到 v[15]（假设 int 是 4\r\n字节，64/4=16）全部加载到缓存。接下来的 15 次访问将直接命中 L1\r\n缓存，速度极快（几乎 0 延迟）。\r\nstd::list&lt;int&gt;内存完全不连续。每个节点 Node 包含\r\nint value 和 Node* next。当你遍历 list 时，访问 node1，CPU\r\n加载了它。然后你需要通过 node1-&gt;next\r\n指针跳转到一个完全随机的内存地址去访问 node2。\r\n结果：vector 遍历是一次内存访问 + 15 次缓存命中。list 遍历是 16\r\n次“缓存未命中”（Cache Miss）。后者比前者慢 1~2 个数量级（10x ~\r\n100x）。\r\n结论：永远优先使用\r\nstd::vector。只有当你需要在集合中间频繁地插入/删除（这会导致\r\nvector 移动大量元素）时，才考虑使用 std::list 或 std::map。\r\n\r\n堆栈之别：避免热循环中的内存分配\r\n\r\n栈（Stack）分配： int a[100];。速度极快。它仅仅是把栈顶指针\r\nrsp 向下移动几百个字节，这是一个单条 CPU 指令。\r\n堆（Heap）分配： int* a = new int[100];。速度非常慢。它需要调用\r\nmalloc()，malloc\r\n必须去加锁（因为堆是全局共享的）、查找一个合适大小的空闲内存块（可能涉及复杂的算法,\r\n如果不足还涉及到系统调用 mmap 或\r\nsbrk）、记录元数据，最后才返回指针。\r\n结论：“不要在热循环（Hot Loop）中 new / delete”。\r\n如果一个函数需要一个临时缓冲区，优先使用栈（如果大小确定且不大，如\r\nstd::array），或者在循环外 new\r\n一次，在循环内复用（Reuse）它。\r\n对于需要频繁创建和销毁的小对象（如金融数据包），使用“对象池”（Object\r\nPool）或“内存池”（Memory Pool）来绕过\r\nmalloc，这是高频交易和量化中非常常见的优化。 -\r\n这是一种“预先分配、循环使用”的自定义内存管理方案. 内存池 (Memory\r\nPool)在启动前预分配 (Pre-allocation), 执行一次（或几次）巨大的\r\nmalloc，从操作系统那里“批发”一大块连续的内存。接着把这块大内存切成 N\r\n个固定大小（例如，刚好能容纳一个“金融数据包”对象）的小块。 -\r\n然后通过一个空闲列表 (Free List),\r\n一个非常简单的数据结构（比如一个链表，称为“空闲列表”）把所有这些小块串起来。\r\n- 对象池是基于内存池的一种更上层的封装。内存池 (Memory\r\nPool)只管理原始内存 (raw memory), 给你返回一个 void*\r\n指针。你需要自己负责在这块内存上构造对象（使用 placement new）。 -\r\n而对象池 (Object\r\nPool)管理完整的对象。acquire()：它从池中拿出一个对象，这个对象可能已经构造好了（或者池会帮你调用构造函数）。release(obj)：你归还一个对象时，池可能会帮你调用它的析构函数（或者更常见的，调用一个\r\nreset() 方法将其重置为初始状态），然后将其放回空闲列表。\r\n\r\n拷贝之痛：const&amp;、移动语义（Move）和写时复制（COW）\r\n\r\nconst&amp;： 对于“只读”的大对象（如\r\nstd::string, std::vector），永远使用 const&amp;\r\n传参，避免不必要的深拷贝。\r\n移动语义（Move）： 如果函数需要“接管”这个资源（例如\r\nSetData(std:string s) { this-&gt;s_ = s;\r\n}），那么使用按值传参（SetData(std::string s)）并 std::move（this-&gt;s_\r\n= std::move(s);）。这允许调用者自动选择拷贝或移动。\r\n写时复制（Copy-on-Write）： 这是一种旧的（C++11前）优化。例如，string\r\ns2 = s1。s2 不会立刻复制 s1 的数据，而是共享它。只有当 s2\r\n尝试修改数据时，它才会真正执行拷贝。\r\n注意： std::string 在 C++11 后放弃了 COW，因为 COW\r\n在多线程环境下需要原子引用计数，其开销（同步）比直接移动（Move）更大。\r\n虚函数调用造成的 cache miss\r\n虚函数（多态）的本质是在运行时才决定具体调用哪个函数。CPU\r\n无法在编译时或执行前提前知道确切的函数地址。这种运行时的不确定性破坏了\r\nCPU 缓存赖以高效工作的局部性原理，从而导致两种主要的 Cache Miss。\r\n首先，现代 CPU 内部的 L1 缓存通常被分为两种：\r\n\r\nL1d (Data\r\nCache)：数据缓存。专门用于存储程序运行时需要读写的数据（例如变量、对象、vtable\r\n本身）。\r\nL1i (Instruction Cache)：指令缓存。专门用于存储\r\nCPU 即将执行的代码（即函数体内的机器指令）。\r\n\r\n这两种缓存是物理上分离的。\r\n\r\n数据缓存未命中 (Data Cache Miss)\r\n\r\n这是“查找函数地址”过程导致的。执行步骤：\r\n\r\n当调用 ptr-&gt;doWork() 时，CPU 必须执行一次间接查找。\r\n访问 ptr 指向的对象内存，读取其 vptr (虚函数表指针)。\r\n根据 vptr 的地址，跳转去访问对应的 vtable (虚函数表)。\r\n从 vtable 中取出 doWork() 的真实函数地址。\r\n\r\n问题所在：vptr 指向的 vtable\r\n通常位于内存中完全不同的区域（例如只读数据段），它和当前正在处理的对象数据在内存上不相邻。访问这个\r\nvtable 的操作很大概率不在 CPU 的 L1/L2 数据缓存中，导致 Data\r\nCache Miss。CPU 必须暂停，去主内存 (RAM) 读取\r\nvtable。\r\n\r\n指令缓存未命中 (Instruction Cache Miss)\r\n\r\n这是“跳转执行函数代码”过程导致的。执行步骤： CPU 成功获取了 doWork()\r\n的真实地址（例如，它现在知道要去执行 Derived2::doWork()）。\r\n问题所在：CPU 会将即将执行的指令（代码）加载到指令缓存 (Instruction\r\nCache) 中。 如果 Derived2::doWork\r\n这个函数最近没有被执行过（例如，循环中上一次执行的是\r\nDerived1::doWork），它的代码就不在 L1i 缓存中，导致一次\r\nInstruction Cache Miss。CPU 必须再次暂停，去 L2/L3/RAM\r\n中把函数代码取回来。\r\n同时,\r\n假如如果程序（例如在一个循环中）交替调用不同的派生类实例（一会是\r\nDerived1，一会是 Derived2），CPU 的指令缓存就会“抖动” (Thrashing)。CPU\r\n刚加载了 Derived1::doWork 的代码，下次循环又要把它踢出去，换上\r\nDerived2::doWork 的代码（导致 Instruction Cache Miss）。\r\n这种无法预测的跳转目标也会导致严重的分支预测失败\r\n(Branch Misprediction)，其惩罚（清空 CPU 流水线）甚至比 Cache Miss\r\n更大。\r\n"},{"url":"/2025/10/30/system/DataBase/ACID/","content":"ACID\r\nACID\r\n是数据库系统中用于描述事务特性的四个关键属性的首字母缩写，分别代表原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。这些属性确保了数据库在处理事务时能够保持数据的完整性和可靠性。\r\n日志\r\n这里的日志指的是预写式日志（Write-Ahead Logging, WAL）, 它是实现 ACID\r\n特性的重要机制之一。\r\n数据库系统通常使用日志（Log）来记录事务的操作，以便在系统崩溃或故障时能够恢复数据。\r\n日志记录了事务的开始、修改的数据以及事务的提交或回滚信息。\r\n通过日志，数据库可以在发生故障后重新执行已提交的事务，确保数据的一致性和持久性。\r\n核心思想：先写日志，再写真实数据\r\nWAL\r\n的核心思想是：在对实际数据进行任何修改之前，必须先将这个“修改意图”记录到一个单独的、仅追加（Append-only）的日志文件中，并确保这个日志已经安全地落盘（持久化）。\r\n假如系统在运行中断电,\r\n当系统从断电中重启时，恢复程序会执行以下操作：\r\n\r\n读取日志： 系统会检查日志文件。\r\n分析日志：\r\n它会查看哪些操作（事务）在日志中被标记为“已提交（Committed）”（即转账的两个步骤都已记录在日志中），哪些操作是“未提交”的（比如只记录了A-100，没有后续B+100的记录）。\r\n执行“重做”（REDO）和“撤销”（UNDO）：\r\n\r\n对于“已提交”的事务：\r\n恢复程序会重新执行日志中记录的所有操作（例如，A-100,\r\nB+100）。这保证了操作的持久性。\r\n即使数据文件在断电时只写了一半，日志里有完整的记录，所以可以重做一遍来保证数据是完整的。这个重做操作被设计为幂等（Idempotent）的（即做一遍和做五遍的结果相同）。\r\n对于“未提交”的事务：\r\n恢复程序会撤销该事务已经执行的所有操作（例如，把A-100的操作给“滚”回去，让A的余额+100）。这保证了操作的原子性。\r\n\r\n\r\n通过“先写日志”这个规则，系统把一个“非原子的多步操作（修改真实数据）”转换成了一个“原子的单步操作（往日志末尾追加一条记录并落盘）”。只要日志写入成功（提交），系统就承诺这个操作“一定”会发生，即使中途断电，重启后也能通过日志来恢复。\r\n"},{"url":"/2025/10/30/misc/%E8%BD%AF%E6%8A%80%E8%83%BD/%E9%9D%A2%E8%AF%95%E6%9D%82%E8%B0%88/","content":"对于算法题, 给出一种解决方案后一定要考虑其时间复杂度和空间复杂度,\r\n并思考是否可以优化任意一个方面\r\n代码题先处理边界情况, 或者最后处理边界情况, 但一定不要忘记\r\n"},{"url":"/2025/10/30/system/computer-architecture/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/CPU%E8%99%9A%E6%8B%9F%E5%8C%96/","content":"这一章关注的是 CPU 虚拟化化技术, 也就是操作系统如何通过进程管理来实现\r\nCPU 资源的虚拟化.\r\n进程\r\n用户希望同时运行多个程序（浏览器、邮件、游戏…），但物理计算机通常只有少量（例如1个或4个）CPU。操作系统如何欺骗用户，让他们感觉自己拥有（几乎）无限多的CPU，可以同时运行上百个程序？\r\n解决方案：虚拟化CPU (Virtualizing the CPU).\r\n操作系统通过时分共享（Time\r\nSharing）技术来实现这一点：\r\n\r\n它让一个进程在CPU上运行一小段时间（一个时间片）。\r\n然后，它停止这个进程，保存它的状态。\r\n接着，它恢复另一个进程的状态，让另一个进程运行一小段时间。\r\n\r\n这个过程（停止一个，启动另一个）被称为上下文切换（Context\r\nSwitch）。通过在多个进程之间极快地来回切换，操作系统创造了所有进程同时在运行的假象（Illusion）。\r\n开销：代价是性能。每个进程的运行速度都会减慢，因为它们只能分时共享CPU。\r\n\r\n机制（Mechanism）与策略（Policy）的分离:\r\n本章提出了一个贯穿全书的核心设计原则： - 机制\r\n(Mechanism)：实现某个功能的底层方法或协议。 -\r\n回答“如何（How）”：例如，操作系统如何执行一次上下文切换？（这需要保存寄存器、切换页表等）。\r\n- 策略 (Policy)：在操作系统中做出决策的算法或智能。 -\r\n回答“哪个（Which）”：例如，现在有10个就绪进程，操作系统应该选择哪个进程来运行？（这就是调度策略）。\r\n分离的好处：将两者分离（模块化）是优秀的软件设计。这意味着我们可以改变策略（例如，从“轮转”调度改为“优先级”调度）而无需重新设计底层的“上下文切换”机制。\r\n\r\n进程的构成\r\n要虚拟化CPU，OS首先必须理解一个进程是由什么组成的。 -\r\n非正式定义：进程 = 运行中的程序。 - 正式定义：进程 =\r\n程序在运行时的机器状态（Machine State）。\r\n机器状态包括： - 内存（地址空间）： -\r\n程序代码（指令）。 -\r\n程序数据（全局变量、堆、栈）。 -\r\n寄存器（Registers）： - 通用寄存器（如EAX,\r\nEBX）：用于计算。 - 特殊寄存器： -\r\n程序计数器\r\n(PC)：最重要的，记录着“当前执行到哪条指令了”。 -\r\n栈指针 (Stack Pointer)：管理函数调用栈。 -\r\nI/O状态： -\r\n例如，当前打开的文件列表（文件描述符）。\r\n对于任何的进程,\r\n都要有一组通用的、OS必须提供的用于管理进程的API（即“系统调用”的抽象）：\r\n- 创建 (Create)：启动一个新进程（例如，双击图标）。 -\r\n销毁 (Destroy)：强制终止一个进程（例如，任务管理器中的“结束任务”）。 -\r\n等待 (Wait)：一个进程（通常是父进程）等待另一个进程（子进程）执行完毕。\r\n- 其他控制 (Miscellaneous\r\nControl)：例如，暂停（Suspend）和恢复（Resume）进程。 - 状态\r\n(Status)：获取进程信息（例如，它运行了多久）。\r\n进程创建的详细步骤\r\n在“双击图标”这个简单的动作背后，OS所做的复杂工作：\r\n\r\n加载（Load）代码和静态数据：\r\n\r\nOS从磁盘上的可执行文件（例如\r\na.out）中读取程序的指令和已初始化的全局变量。\r\n将这些字节加载到物理内存中，并为它们设置好进程的地址空间。\r\n（提示：现代OS是“惰性”加载的，即只在需要时才通过页错误加载，但这将在内存虚拟化章节详述。）\r\n\r\n创建和初始化栈（Stack）：\r\n\r\nOS必须为进程分配一块内存作为其运行时栈（用于局部变量、函数参数等）。\r\nOS会将命令行参数（argc, argv）填入这个栈的底部，以便 main\r\n函数可以访问它们。\r\n\r\n创建和初始化堆（Heap）：\r\n\r\nOS为进程分配一小块内存作为堆（用于 malloc()）。\r\n当程序请求更多内存时，堆可以增长。\r\n\r\n初始化I/O：\r\n\r\nOS执行其他I/O相关的设置。\r\n（在UNIX中）默认打开三个文件描述符：0（标准输入）、1（标准输出）、2（标准错误）。\r\n\r\n启动进程：\r\n\r\nOS将进程的状态设置为“就绪”（Ready），并将其放入就绪队列中。\r\n当CPU空闲时，调度程序从就绪队列中选择一个进程来运行。\r\nCPU的程序计数器（PC）被设置为指向程序的入口点（即 main()\r\n函数）。\r\n进程开始运行。\r\n\r\n\r\n进程状态\r\n一个进程在其生命周期中，并不会总是在运行。它会在几种核心状态之间切换：\r\n\r\n运行（Running）：\r\n\r\n定义：进程当前正在CPU上执行指令。\r\n数量：在一个单核CPU上，任何时刻最多只有1个进程处于此状态。\r\n\r\n就绪（Ready）：\r\n\r\n定义：进程已经准备好运行，但被OS（调度程序）暂停了，正在等待轮到它使用CPU。\r\n数量：可以有多个进程在此状态（在“就绪队列”中排队）。\r\n\r\n阻塞（Blocked）（也叫睡眠，Sleeping）：\r\n\r\n定义：进程无法运行，即使给它CPU也没用。它在等待某个外部事件发生（例如，等待磁盘I/O完成、等待网络数据包、等待一个锁）。\r\n数量：可以有多个进程在此状态。\r\n\r\n\r\n运行 -&gt;\r\n就绪：进程的“时间片”用完了，被OS取消调度（Descheduled）。\r\n就绪 -&gt;\r\n运行：OS的调度程序选择了这个进程，将其调度（Scheduled）上CPU。\r\n运行 -&gt; 阻塞：进程主动发起了一个缓慢的操作（例如 read()\r\n磁盘），它必须等待。\r\n阻塞 -&gt;\r\n就绪：进程等待的事件已完成（例如，磁盘I/O完成了，发送了一个中断）。该进程不能直接变为“运行”，它必须先进入“就绪”队列，等待调度程序选择它。\r\n操作系统的数据结构\r\n为了管理进程，操作系统维护了一些关键的数据结构：\r\n\r\n进程控制块（Process Control Block, PCB）：\r\n\r\n每个进程都有一个对应的PCB，包含该进程的所有信息。\r\n所有 PCB 都存在于内核空间的一块全局数据结构中（例如 Linux 的\r\ntask_struct 链表）\r\n它存储了该进程的所有上下文信息，包括：\r\n\r\n进程状态（就绪、运行、阻塞）。\r\n程序计数器（PC）的值。\r\nCPU寄存器的值。\r\n内存管理信息（页表、段表等）。\r\nI/O状态信息（打开的文件、设备等）。\r\n\r\n\r\n进程列表（Process List）：\r\n\r\nOS维护一个（或多个）列表，用于跟踪所有的进程。例如，一个“就绪队列”和一个“阻塞队列”。\r\n这些队列本质上是指向一系列 PCB（或\r\ntask_struct）的指针集合\r\n就绪队列（Ready Queue）：\r\n\r\n定义：所有就绪状态的进程都在这个队列中等待CPU。\r\n实现：通常使用链表或队列数据结构。\r\n\r\n阻塞队列（Blocked Queue）：\r\n\r\n定义：所有阻塞状态的进程都在这个队列中等待某个事件。\r\n实现：通常使用链表或队列数据结构。\r\n\r\n\r\n\r\n这些数据结构就保存在内存的内核空间中,\r\n内核空间是全局唯一的,\r\n在不同进程的地址空间共享,\r\n以便于操作系统高效地管理和调度进程。\r\n进程API\r\n机制：受限直接执行\r\n根据上文介绍, 如何提供有许多CPU的假象？基本思想是时分共享（Time\r\nSharing）：运行一个进程一会儿，再运行另一个一会儿。\r\n但在实现上，这带来了两个根本性的、相互冲突的挑战：\r\n\r\n性能（Performance）：要快。进程的代码应该尽可能直接在硬件CPU上运行，任何操作系统的介入（Overhead）都会拖慢它。\r\n控制（Control）：要安全。操作系统必须始终保持对机器的控制权。它不能允许一个进程为所欲为（例如，访问不属于它的内存、独占CPU不放手、或操作硬件）。\r\n\r\n关键问题：如何高效、可控地虚拟化CPU？操作系统如何在实现高性能（让进程直接运行）的同时，保持对系统的完全控制（限制进程的行为）？\r\n本章提出的解决方案叫做受限直接执行（Limited Direct\r\nExecution, LDE）。\r\n“直接执行（Direct Execution）”（为了性能）：\r\n\r\nOS将程序代码加载到内存。\r\nOS将CPU的程序计数器（PC）指向程序的 main() 函数。\r\n进程的指令直接在物理CPU上运行。\r\n优点：速度快，几乎等同于裸机性能。\r\n\r\n“受限（Limited）”（为了控制）： -\r\n上述“直接执行”有两个致命问题，LDE必须解决它们。\r\nLDE的问题1：如何执行受限制的操作？\r\n如果一个进程在“直接执行”时，想做一件“危险”的事（比如读写磁盘、分配内存），该怎么办？如果允许它做，它就能绕过OS的所有保护（例如，读取其他进程的文件）。\r\n解决方案：双模式操作（Dual-Mode\r\nOperation），这是硬件和OS的精妙协作。\r\n硬件支持：用户模式 vs. 内核模式\r\n\r\n用户模式 (User Mode)：这是CPU的“受限”模式。\r\n\r\n限制：在此模式下，CPU禁止执行“特权指令（Privileged\r\nInstructions）”（如\r\nDisableInterrupts、Halt、磁盘I/O指令、修改陷阱表等）。\r\n谁用：所有用户程序（如浏览器、游戏）都在此模式下运行。\r\n\r\n内核模式 (Kernel\r\nMode)（也叫特权模式）：CPU的“全能”模式。\r\n\r\n限制：没有限制。可以执行所有指令，访问所有内存和硬件。\r\n谁用：只有操作系统（OS Kernel）在此模式下运行。\r\n\r\n\r\n协作机制：系统调用（System\r\nCall）\r\n问题：运行在“用户模式”的进程，如何请求“内核模式”的OS帮它执行一次I/O操作？系统调用（System\r\nCall）。机制为： - TRAP\r\n指令：硬件提供一条特殊的trap（陷阱）指令。\r\n- C库封装：程序员调用的 read() 或 open()\r\n并非系统调用本身，而是一个C库函数。这个函数负责： -\r\n把参数（如文件名、缓冲区地址）放到约定的寄存器或栈上。\r\n-\r\n把“系统调用号”（例如，5代表open）放到一个特定寄存器。\r\n- 执行 TRAP 指令。 - TRAP 的原子操作：TRAP 指令会自动、原子地： -\r\n将CPU模式从用户模式切换到内核模式。 -\r\n保存当前进程的上下文（PC、寄存器等）到内核栈（Kernel Stack）。 -\r\n跳转到OS内核中一个预先指定的处理函数。\r\n\r\nRETURN-FROM-TRAP 指令：\r\n\r\n当OS处理完毕，它会执行return-from-trap指令。\r\n这条指令原子地：\r\n\r\n恢复进程的上下文。\r\n将CPU模式从内核模式切换回用户模式。\r\n跳转回用户程序（TRAP指令的下一条），继续执行。\r\n\r\n\r\n\r\nOS的职责：陷阱表（Trap Table）\r\n问题：TRAP 指令如何知道该跳转到OS的哪段代码？通过陷阱表（Trap\r\nTable）。流程为：\r\n\r\nOS在启动时（在内核模式下）创建一个陷阱表（一个函数指针数组），并使用特权指令告诉硬件：“陷阱表在内存地址X处”。\r\n\r\n例如，OS设置\r\n表[索引 128] = sys_call_handler，表[索引 14] = page_fault_handler\r\n等。\r\n\r\n当用户进程执行TRAP（例如，系统调用号为128）时，硬件自动查找该表，并将控制权交给\r\nsys_call_handler。\r\n关键：用户进程无法指定跳转地址，它只能触发陷阱，由硬件和OS预设的陷阱表来决定后续流程，从而保证了受保护的控制权转移（Protected\r\nControl Transfer）。\r\n\r\nLDE的问题2：如何在进程之间切换？\r\n问题：如果一个进程陷入了无限循环（while(1){}），它既不进行系统调用，也不出错，那么它将永远“直接执行”下去。OS（它没在运行）如何才能重新夺回CPU的控制权，去调度其他进程？\r\n方案一：协作方式（Cooperative） -\r\n思想：OS相信进程会“合作”。 -\r\n机制：进程必须主动、定期地调用 yield()\r\n系统调用，“自愿”放弃CPU。 -\r\n缺陷：致命的缺陷。一个恶意或有bug的进程（无限循环）将饿死所有其他进程，并搞垮整个系统。唯一的解决方案就是重启。\r\n方案二：非协作方式（Preemptive） -\r\n思想：OS不相信任何进程，它必须能强制（Preemptively）夺回控制权。\r\n- 硬件支持：时钟中断（Timer Interrupt）。 -\r\nOS在启动时（在内核模式下）启动一个硬件时钟设备（Timer）。\r\n- OS使用特权指令对时钟编程：“请每隔 10\r\n毫秒（一个时间片）给我发送一个中断（Interrupt）”。 - OS启动用户进程A。 -\r\n… 10毫秒后 … -\r\n时钟硬件“叮”的一声，强制产生一个中断，这无论进程A在做什么。这个中断的行为和\r\nTRAP 一模一样： - CPU模式从用户模式切换到内核模式。 -\r\n保存进程A的上下文。 - 跳转到OS的“时钟中断处理程序”（地址由陷阱表指定）。\r\n- OS 重新获得了 CPU 的控制权！ -\r\nOS的时钟中断处理程序会调用调度程序（Scheduler）。调度程序（Policy）决定：“进程A的时间片用完了，现在该运行进程B了”。\r\n- OS执行上下文切换（Context Switch）。\r\n通过时钟中断，OS可以强制从任何进程手中夺回CPU控制权，从而实现真正的多任务处理。\r\n核心机制：上下文切换 (Context\r\nSwitch)\r\n上下文切换是OS停止进程A并启动进程B的底层机制。时序：\r\n\r\n（A在用户模式） 运行… -&gt; 时钟中断\r\n\r\n也可以是其他中断（I/O中断、系统调用等）触发上下文切换，但时钟中断是最常见的。\r\n\r\n（硬件） 自动将A的用户寄存器（PC, flags,\r\neax…）保存到A的内核栈上,\r\n也就是保存了A在用户态下的执行状态.\r\n（硬件） 切换到内核模式，跳转到“时钟中断处理程序”。\r\n\r\n此时寄存器中保存的值变成了内核模式下的值, 即A的内核寄存器.\r\n\r\n（OS） OS的C代码运行… 调用调度程序… 决定从A切换到B。\r\n（OS） OS调用 switch() 汇编例程。\r\n（switch()） 明确地将A的内核寄存器（esp,\r\nebp…）保存到A的进程控制块（PCB）中。\r\n\r\n使得A的内核态执行状态被保存, 在下次切换回A时可以恢复.\r\n内核态执行状态包括内核栈指针等, 以便内核代码可以正确运行.\r\n\r\n（switch()）\r\n明确地从B的PCB中恢复B的内核寄存器。\r\n（switch()） 切换内核栈！CPU的栈指针现在指向B的内核栈。\r\n\r\n因为上次B被切换出去时,\r\n硬件已经把B的用户寄存器保存到B的内核栈上了,\r\n这里有B的返回地址.\r\n\r\n（switch()） 执行 ret\r\n指令，此时它返回的是B上次调用switch时的位置。\r\n（OS） OS（现在在B的上下文中）执行 return-from-trap。\r\n（硬件） 自动从B的内核栈中恢复B的用户寄存器。\r\n（B在用户模式） 恢复运行…\r\n\r\n两种寄存器保存/恢复： - 用户态 &lt;-&gt; 内核态（由\r\ntrap / return-from-trap\r\n触发）：硬件自动保存/恢复用户寄存器到内核栈。\r\n- 用户寄存器指的是进程在用户态下的寄存器状态。 -\r\n这里主要保护的是用户程序的执行状态（PC, 通用寄存器等）,\r\n使得用户程序返回后可以无缝地继续执行. - 进程A &lt;-&gt; 进程B（由\r\nswitch()\r\n触发）：OS软件明确保存/恢复内核寄存器到PCB。\r\n- 内核寄存器指的是进程在内核态下的寄存器状态。 -\r\n这里主要保护的是内核态下的执行状态（esp, ebp等）,\r\n使得内核代码可以在不同进程间切换时保持正确的栈状态。\r\n总之,\r\n受限直接执行（LDE）是实现CPU虚拟化的基石。它完美地平衡了性能和控制：\r\n- 性能（Direct\r\nExecution）：进程大部分时间都在用户模式下直接运行在CPU上。\r\n-\r\n控制（Limited）：OS通过在启动时设置陷阱表和时钟中断，为CPU“宝宝防护”（Baby-proofing）。\r\n- 系统调用（TRAP）：允许进程受控地请求内核服务（如I/O）。 -\r\n时钟中断（Interrupt）：确保OS能强制地（非协作地）夺回CPU控制权，以实现时分共享。\r\n通过这套机制，OS得以安全、高效地在多个进程间切换，创造了“多个CPU”的假象。\r\n进程调度\r\n这一章开启了“调度策略（Policy）”部分的讨论。在第6章中，我们学习了实现CPU虚拟化所需的机制（Mechanism）——受限直接执行、上下文切换等。现在，本章关注的是：当机制就位后，操作系统该如何决策（Policy）？\r\n我们引入了两个关键的、且常常相互冲突的性能指标： -\r\n指标1：周转时间 (Turnaround Time) -\r\n定义：任务从到达系统到系统完成所花费的总时间\r\n- 公式：T周转时间 = T完成时间 − T到达时间\r\n- 目标：最小化平均周转时间（提升系统吞吐量）。 -\r\n指标2：响应时间 (Response Time) -\r\n定义：任务从到达系统到首次运行所花费的时间。\r\n- 公式：T响应时间 = T首次运行时间 − T到达时间\r\n- 目标：最小化平均响应时间（提升系统交互性）。\r\n常见策略\r\n策略一：先进先出 (First-In-First-Out, FIFO) -\r\n策略：也称为“先到先服务 (FCFS)”。按任务到达的顺序进行调度。 -\r\n行为：这是一个非抢占式（Non-preemptive）算法。一旦一个工作开始运行，它会一直运行直到完成（基于假设3）。\r\n- 护航效应 (Convoy\r\nEffect)：FIFO的核心问题。一个“重量级”（长耗时）的任务（如A）会堵塞住所有“轻量级”（短耗时）的任务（如B,\r\nC），导致平均周转时间急剧恶化。\r\n策略二：最短任务优先 (Shortest Job First, SJF) -\r\n策略：非抢占式。从所有等待的任务中，选择运行时间最短的那个任务，并运行它直到完成。\r\n- 目标：明确为了解决FIFO的“护航效应”。 - 评价:\r\n在“所有任务同时到达”的假设下，SJF是最优的。 - 假设任务非同时到达： - A在\r\nt = 0 到达 (运行100s)。 - B, C\r\n在 t = 10 到达 (各运行10s)。 -\r\n调度过程： - t = 0\r\n时，只有A在，OS运行A。 - t = 10 时，B,\r\nC到达。但因为SJF是非抢占式的，OS必须等待A（它还在运行）完成。 - t = 100 时，A完成, OS从B,\r\nC中选择（都是10s），运行B。 - t = 110 时，B完成, 运行C。 - t = 120 时，C完成。 - 周转时间：A =\r\n(100 - 0) = 100s；B = (110 - 10) = 100s；C = (120 - 10) = 110s。 -\r\n平均周转时间 = (100 + 100 + 110) / 3 = 103.33s。 -\r\n结论：护航效应又回来了！因为非抢占，一个先到的长任务（A）依然会堵塞后到的短任务（B,\r\nC）。\r\n策略三：最短完成时间优先 (Shortest Time to\r\nCompletion First, STCF) -\r\n策略：也称为抢占式最短任务优先 (PSJF)。 -\r\n行为：这是一个抢占式（Preemptive）算法。每当一个新任务到达时，调度程序会比较“新任务的运行时间”和“当前任务的剩余运行时间”。如果新任务更短，OS会立即抢占（Preempt）当前任务，转而运行新任务。\r\n- 评价: STCF在周转时间这个指标上是“最优”的。 -\r\n问题：STCF虽然周转时间短，但交互性（响应时间）可能很差。例如\r\nA (5s), B (5s), C (5s) 同时到达, 执行顺序是 A -&gt; B -&gt; C,\r\nB的响应时间是5s, C的响应时间是10s, 这对交互式系统来说是不可接受的.\r\n策略四：轮转 (Round-Robin, RR) -\r\n策略：抢占式。RR维护一个任务队列。它运行队列头部的任务，但只运行一个固定的时间片（Time\r\nSlice）（例如1s）。 - 如果任务在时间片内完成，OS将其移出队列。 -\r\n如果任务在时间片结束时仍未完成，OS抢占它，将其移到队列尾部，然后调度队列头部的新任务。\r\n\r\n评价（A=5s, B=5s, C=5s; 时间片=1s）：\r\n\r\n调度顺序：A, B, C, A, B, C, A, B, C, …\r\n响应时间：A=0s, B=1s, C=2s。平均 = (0+1+2)/3 = 1s。（非常好！）\r\n周转时间：A在13s完成, B在14s完成, C在15s完成。平均 = (13+14+15)/3 =\r\n14s。（非常糟糕！）\r\n\r\n结论：RR在响应时间上表现出色，但在周转时间上却很糟糕。这是因为RR频繁地切换任务，导致每个任务完成所需的总时间增加。\r\nRR 和 STCF 的结合: 我们可以将 STCF 的 “最短剩余时间优先”策略与 RR\r\n的时间片机制结合起来。也就是说, 每当一个新任务到达时,\r\n如果它的运行时间小于当前任务的剩余时间, 则立即抢占当前任务. 否则,\r\n当前任务继续运行直到时间片结束.\r\n这样可以在一定程度上兼顾周转时间和响应时间.\r\n\r\n但是这是不现实的.\r\n我们可能永远无法准确知道一个新任务的运行时间到底是多少.\r\n因为任务的运行时间往往是不可预测的.\r\n\r\n\r\n对比上述策略: - SJF/STCF：优化周转时间，但牺牲了响应时间（不公平）。\r\n- RR：优化响应时间，但牺牲了周转时间（很公平）。\r\n也就是说,\r\n性能（周转时间）和公平（响应时间）在调度中往往是相互冲突的。\r\n并且从 RR 策略可以看出, 核心权衡是时间片长度 - 短时间片（例如 1ms）：\r\n- 优点：响应时间极好。 - 缺点：上下文切换（Context\r\nSwitch）的开销（Overhead）占比过高。如果上下文切换本身要 1ms，那么CPU\r\n50% 的时间都浪费在了切换上，而不是做有效工作。\r\n\r\n长时间片（例如 100ms）：\r\n\r\n优点：上下文切换的开销被摊销（Amortized）了，CPU效率高。\r\n缺点：响应时间变差。\r\n\r\n结论：时间片是一个权衡（Trade-off）。它必须远大于上下文切换的开销，但又必须足够短以保证系统的响应性。\r\n\r\n调度策略:\r\n多级反馈队列 (Multilevel Feedback Queue, MLFQ)\r\n在上面，我们遇到了一个核心的“权衡（Trade-off）”：\r\n\r\nSJF/STCF 策略能实现最优的周转时间（吞吐量高）。\r\nRR（轮转） 策略能实现最优的响应时间（交互性好）。\r\n\r\n但SJF/STCF有一个致命缺陷：它需要预知未来，即OS必须提前知道每个工作的总运行时间，这在现实中是不可能的。\r\n本章介绍的多级反馈队列（MLFQ）就是为了解决这个“无法预知未来”的问题而设计的。\r\nMLFQ的核心思想：从历史中学习（Learn from history）。\r\nMLFQ不再试图“预知”未来，而是通过观察一个进程“过去”的行为，来预测它“未来”的行为，并动态地调整其优先级。\r\nMLFQ不是一个队列，而是多个不同优先级的队列。它的调度逻辑基于下列规则：\r\n\r\n规则1： 如果 A 的优先级 &gt; B 的优先级，运行 A（抢占\r\nB）。\r\n规则2： 如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。\r\n规则3：\r\n工作进入系统时，放在最高优先级（最上层队列）。\r\n规则4：\r\n一旦工作用完了其在某一层中的时间配额，就降低其优先级。\r\n规则5：\r\n经过一段时间S，就将系统中所有工作重新加入最高优先级队列。\r\n\r\n它通过这套复杂的规则，同时实现了两个看似矛盾的目标： -\r\n（近似SJF）：新任务（短任务）在最高优先级被执行，周转时间短。 -\r\n（近似RR）：交互式任务（I/O型）保持在高优先级，并进行轮转，响应时间快。\r\n多处理器调度（高级）\r\n在前面几章，我们所有的讨论都基于单CPU模型。但现代计算机（甚至手机）都有多个CPU（“核”）。单CPU的调度策略（如SJF,\r\nMLFQ）还能用吗？多CPU带来了哪些全新的问题？我们需要什么新机制或新策略？\r\n多处理器带来的三大新挑战\r\n与单CPU系统相比，多处理器系统引入了三个必须理解的根本性挑战。\r\n挑战一：硬件背景与缓存一致性\r\n\r\n单CPU缓存：在单CPU系统中，缓存（Cache）是CPU的私有小内存，它利用时间局部性和空间局部性来加速内存访问。它对OS是透明的，且总能保证正确性。\r\n多CPU缓存：在多CPU系统中，每个CPU都有各自的私有缓存，但它们共享同一个主内存。\r\n\r\n问题：缓存一致性（Cache Coherence）： - 进程在 CPU 1\r\n上运行，从内存地址 A 读取值 D。CPU 1 的缓存中存有 A=D。 - 进程修改 A\r\n的值为 D’。CPU 1\r\n只更新了它自己的缓存（A=D’）。为了速度，它不会立即写回主内存。 -\r\n（上下文切换） 进程被迁移（Migrate）到 CPU 2 上运行。 -\r\n进程在 CPU 2 上尝试读取地址 A。 - CPU 2 在自己的缓存中找不到\r\nA，于是它去主内存中读取，读到了旧的、过时的值 D，而不是正确的 D’。 -\r\n结果：程序出错！\r\n硬件解决方案：现代多核硬件通过总线窥探（Bus\r\nSnooping）等机制自动解决了这个问题。当 CPU 1 更新其缓存中的 A\r\n时，硬件会广播一个消息，通知其他CPU（如 CPU\r\n2）“使无效（Invalidate）”或“更新（Update）”它们自己缓存中的 A 的副本。\r\n&gt;\r\n还有别的解决方案，如目录式缓存一致性（Directory-Based\r\nCache\r\nCoherence），它通过一个中心目录来跟踪哪些缓存行被哪些CPU缓存，适用于大规模多核/分布式系统\r\n结论：硬件保证了“一致性”，即任何CPU读取内存地址 A\r\n都会获得其最新的值。\r\n挑战二：同步（Synchronization）\r\n问题：既然硬件保证了“缓存一致性”，我们（OS或应用程序）还需要担心并发问题吗？答案：绝对需要！\r\n\r\n硬件一致性只保证了“一次内存读/写操作”的原子性。它不能保证多条指令的原子性。\r\n示例：\r\n\r\nCPU 1 上的线程T1执行 tmp = head;\r\nCPU 2 上的线程T2同时执行 tmp = head;\r\n（由于硬件一致性）T1和T2都正确地读到了相同的 head 值。\r\nT1继续执行，释放了head指向的节点。\r\nT2也继续执行，再次释放了同一个节点（head指向的节点）。\r\n结果：竞态条件（Race Condition），导致重复释放、数据损坏。\r\n\r\n\r\n结论：只要多个CPU（线程）共享数据结构（如队列、链表、计数器），就必须使用互斥原语（例如锁）来保护“临界区”。\r\n挑战三：缓存亲和度 (Cache Affinity)\r\n问题：当一个进程在 CPU 1 上运行时，它会在 CPU 1\r\n的缓存中建立起大量的“热”状态（它最近使用的指令和数据）。\r\n\r\n如果下次该进程再次在 CPU 1\r\n上运行，它会非常快（因为所需数据已在缓存中）。\r\n如果它被迁移到 CPU 2 上运行，它会非常慢（CPU 2\r\n的缓存是“冷”的，它必须从主内存重新加载所有数据）。\r\n\r\n结论：调度程序应该尽可能地将一个进程保持在同一个CPU上运行，以利用缓存亲和度。\r\n多处理器调度策略\r\n多处理器调度策略必须同时解决上述三个挑战。以下是两种常见的策略：\r\n解决方案一：单队列多处理器调度 (Single Queue\r\nMultiprocessor Scheduling), 这是最简单的方案。 - 机制： -\r\n只有一个全局的“就绪队列”。 -\r\n当一个CPU空闲时，它会锁定（lock）这个全局队列,\r\n从队列中取出“最好”的进程, 再解锁（unlock）队列,\r\n然后运行该进程。\r\n\r\n优点：\r\n\r\n简单：重用了所有单CPU的调度逻辑（如SJF, MLFQ）。\r\n负载均衡（Load\r\nBalancing）：自动且完美。只要队列里有工作，就绝不会有CPU空闲。\r\n\r\n缺点：\r\n\r\n可扩展性（Scalability）极差：那个全局锁成为了系统瓶颈。假设有32个CPU，它们会（在每个时间片结束时）疯狂地争抢这一把锁。CPU越多，在“等待锁”上浪费的时间就越多，真正“干活”的时间就越少。\r\n缓存亲和度极差：当进程A运行完一个时间片后，它被放回全局队列。下一个空闲的CPU（可能是\r\nCPU 1，也可能是 CPU\r\n5）会把它取走。进程会随机地在所有CPU之间“迁移（Migrate）”或“弹跳（Bounce）”，导致缓存亲和度被完全破坏。\r\n\r\n\r\n解决方案二：多队列多处理器调度 (Multiple Queue\r\nMultiprocessor Scheduling), 为解决SQMS的缺点而设计。 - 机制： -\r\n每个CPU都有一个自己的私有“就绪队列”。\r\n-\r\n当一个新进程（A）进入系统时，OS会（基于某种策略）将其永久地分配给一个队列（例如\r\nCPU 0 的队列）。 - 常见的策略有：轮转分配（Round-Robin\r\nAssignment）（第一个进程给 CPU 0，第二个给 CPU\r\n1，依此类推）；或基于负载的分配（Load-Based\r\nAssignment）（将新进程分配给当前负载最轻的CPU）。 -\r\n每个CPU只从自己的私有队列中取工作来运行（例如，CPU 0 只运行 CPU 0\r\n队列中的任务）。\r\n\r\n优点：\r\n\r\n可扩展性（Scalability）极好：CPU之间零共享（或极少共享）, CPU 0\r\n取工作不需要和 CPU 1 竞争锁, 锁的争抢问题被彻底解决。\r\n缓存亲和度（Cache Affinity）极好：进程A被分配到 CPU 0\r\n队列后，它永远只会在 CPU 0 上运行。它的缓存亲和度得到了完美的保障。\r\n\r\n缺点：\r\n\r\n负载不均（Load Imbalance）：这是MQMS引入的新的、根本性的问题。示例：\r\n\r\nCPU 0 的队列：{A, B, C, D}\r\nCPU 1 的队列：{E}\r\nCPU 1 很快完成了E，然后进入空闲（Idle）状态。\r\nCPU 0 却还在忙碌地处理A, B, C, D。\r\n结果：系统利用率低下，且A, B, C, D的响应时间很差，而 CPU 1\r\n却在“无所事事”。\r\n\r\n\r\n解决MQMS的负载不均：迁移 (Migration)\r\n\r\n机制：工作窃取 (Work Stealing). 当一个CPU（例如 CPU\r\n1）的队列变空时，它会主动地去“偷看”其他CPU的队列。如果它发现\r\nCPU 0 的队列“过满”（例如有4个工作），CPU 1\r\n就会“窃取”一个（或一半）工作（例如D）到自己的队列中来运行。\r\n新的权衡：“偷看”的频率：\r\n\r\n太频繁：导致CPU间争抢“目标队列锁”，又回到了SQMS的可扩展性问题。\r\n太不频繁：导致负载不均持续存在。\r\n\r\n\r\n\r\n多处理器调度没有完美的答案。它是一个在可扩展性、缓存亲和度和负载均衡之间的复杂权衡（Trade-off）。\r\n现在的多核操作系统（如Linux,\r\nWindows）通常采用多队列调度，并结合工作窃取等机制，以在实际应用中取得良好的性能表现。\r\n"},{"url":"/2025/10/30/system/computer-architecture/%E5%B9%B6%E5%8F%91/%E5%B9%B6%E5%8F%91/","content":"什么是线程\r\n线程（Thread）它是一个程序内的多个执行点（Multiple\r\nPoints of Execution）。\r\n\r\n状态：每个线程都有自己独立的状态，必须被OS管理。这包括：\r\n\r\n程序计数器 (PC)：记录自己“执行到哪里了”。\r\n寄存器 (Registers)：记录自己“正在计算什么”。\r\n栈\r\n(Stack)：记录自己的函数调用历史、局部变量等。\r\n\r\n共享资源：同一进程内的多个线程共享进程的资源，如代码段、数据段、堆等\r\nTCB：线程的状态保存在线程控制块（Thread Control Block,\r\nTCB）中。\r\n\r\n锁\r\n并发带来的核心问题——竞态条件（Race\r\nCondition），即多个线程同时访问临界区（Critical\r\nSection）导致了错误和不确定的结果。为了解决这个问题，引入了锁（Lock）机制。\r\n锁是一种抽象数据类型，它是一个变量，用于强制实现互斥（Mutual\r\nExclusion）。\r\n状态：锁只有两种状态： - 可用的（Available /\r\nUnlocked）：没有线程持有它。 - 被占用的（Acquired /\r\nLocked）：有且仅有一个线程（称为“持有者”）持有它。\r\nAPI（应用程序接口）： - lock(&amp;mutex)：尝试获取锁。 -\r\n如果锁可用，当前线程立即获取锁，成为持有者，并进入临界区。 -\r\n如果锁被占用，当前线程将卡住（阻塞或自旋），直到锁变为可用。 -\r\nunlock(&amp;mutex)：只有锁的持有者才能调用。调用后，锁的状态变回“可用”。\r\n程序员的视角：锁提供了一种最小的调度控制。通过在临界区前后加上\r\nlock 和 unlock，程序员可以确保这段代码（例如 balance = balance +\r\n1;）如同单条原子指令一样执行，从而解决了竞态条件。\r\n评价锁实现的三个核心标准： -\r\n正确性（Correctness）：这是最基本的要求。它是否真正提供了互斥？是否在任何情况下都能阻止多个线程同时进入临界区？\r\n-\r\n公平性（Fairness）：当锁被释放时，等待的线程是否有公平的机会获取它？还是说某个线程可能会饿死（Starve），即永远也拿不到锁？\r\n- 性能（Performance）：使用锁的开销有多大？ -\r\n无竞争时：单个线程 lock -&gt; unlock 的开销。 -\r\n有竞争时：多个线程（在单CPU或多CPU上）争抢同一个锁时的开销。\r\n"}]